Train, Epoch: 1, Batch: 1, Step num: 1, Learning rate: 0.00000003, Avg batch loss: 1.6833, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 2, Step num: 2, Learning rate: 0.00000007, Avg batch loss: 1.8009, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 3, Step num: 3, Learning rate: 0.00000010, Avg batch loss: 1.6983, Avg batch acc: 0.0015
Train, Epoch: 1, Batch: 4, Step num: 4, Learning rate: 0.00000014, Avg batch loss: 1.6868, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 5, Step num: 5, Learning rate: 0.00000017, Avg batch loss: 1.6257, Avg batch acc: 0.0013
Train, Epoch: 1, Batch: 6, Step num: 6, Learning rate: 0.00000021, Avg batch loss: 1.7694, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 7, Step num: 7, Learning rate: 0.00000024, Avg batch loss: 1.9054, Avg batch acc: 0.0011
Train, Epoch: 1, Batch: 8, Step num: 8, Learning rate: 0.00000028, Avg batch loss: 1.5730, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 9, Step num: 9, Learning rate: 0.00000031, Avg batch loss: 1.6612, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 10, Step num: 10, Learning rate: 0.00000035, Avg batch loss: 1.7223, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 11, Step num: 11, Learning rate: 0.00000038, Avg batch loss: 1.7860, Avg batch acc: 0.0002
Train, Epoch: 1, Batch: 12, Step num: 12, Learning rate: 0.00000042, Avg batch loss: 1.6574, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 13, Step num: 13, Learning rate: 0.00000045, Avg batch loss: 1.5631, Avg batch acc: 0.0015
Train, Epoch: 1, Batch: 14, Step num: 14, Learning rate: 0.00000049, Avg batch loss: 1.6487, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 15, Step num: 15, Learning rate: 0.00000052, Avg batch loss: 1.7669, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 16, Step num: 16, Learning rate: 0.00000056, Avg batch loss: 1.7318, Avg batch acc: 0.0020
Train, Epoch: 1, Batch: 17, Step num: 17, Learning rate: 0.00000059, Avg batch loss: 1.8853, Avg batch acc: 0.0002
Train, Epoch: 1, Batch: 18, Step num: 18, Learning rate: 0.00000063, Avg batch loss: 1.8701, Avg batch acc: 0.0002
Train, Epoch: 1, Batch: 19, Step num: 19, Learning rate: 0.00000066, Avg batch loss: 1.6031, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 20, Step num: 20, Learning rate: 0.00000070, Avg batch loss: 1.6806, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 21, Step num: 21, Learning rate: 0.00000073, Avg batch loss: 1.6696, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 22, Step num: 22, Learning rate: 0.00000077, Avg batch loss: 1.6400, Avg batch acc: 0.0025
Train, Epoch: 1, Batch: 23, Step num: 23, Learning rate: 0.00000080, Avg batch loss: 1.6119, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 24, Step num: 24, Learning rate: 0.00000084, Avg batch loss: 1.6855, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 25, Step num: 25, Learning rate: 0.00000087, Avg batch loss: 1.7531, Avg batch acc: 0.0002
Train, Epoch: 1, Batch: 26, Step num: 26, Learning rate: 0.00000091, Avg batch loss: 1.8143, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 27, Step num: 27, Learning rate: 0.00000094, Avg batch loss: 1.5484, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 28, Step num: 28, Learning rate: 0.00000098, Avg batch loss: 1.7131, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 29, Step num: 29, Learning rate: 0.00000101, Avg batch loss: 1.7764, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 30, Step num: 30, Learning rate: 0.00000105, Avg batch loss: 1.7188, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 31, Step num: 31, Learning rate: 0.00000108, Avg batch loss: 1.7678, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 32, Step num: 32, Learning rate: 0.00000112, Avg batch loss: 1.6695, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 33, Step num: 33, Learning rate: 0.00000115, Avg batch loss: 1.7488, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 34, Step num: 34, Learning rate: 0.00000119, Avg batch loss: 1.5468, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 35, Step num: 35, Learning rate: 0.00000122, Avg batch loss: 1.7015, Avg batch acc: 0.0023
Train, Epoch: 1, Batch: 36, Step num: 36, Learning rate: 0.00000126, Avg batch loss: 1.8348, Avg batch acc: 0.0003
Train, Epoch: 1, Batch: 37, Step num: 37, Learning rate: 0.00000129, Avg batch loss: 1.7042, Avg batch acc: 0.0002
Train, Epoch: 1, Batch: 38, Step num: 38, Learning rate: 0.00000133, Avg batch loss: 1.8176, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 39, Step num: 39, Learning rate: 0.00000136, Avg batch loss: 1.7815, Avg batch acc: 0.0014
Train, Epoch: 1, Batch: 40, Step num: 40, Learning rate: 0.00000140, Avg batch loss: 1.7299, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 41, Step num: 41, Learning rate: 0.00000143, Avg batch loss: 1.8526, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 42, Step num: 42, Learning rate: 0.00000147, Avg batch loss: 1.6606, Avg batch acc: 0.0014
Train, Epoch: 1, Batch: 43, Step num: 43, Learning rate: 0.00000150, Avg batch loss: 1.6541, Avg batch acc: 0.0011
Train, Epoch: 1, Batch: 44, Step num: 44, Learning rate: 0.00000154, Avg batch loss: 1.6972, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 45, Step num: 45, Learning rate: 0.00000157, Avg batch loss: 1.7995, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 46, Step num: 46, Learning rate: 0.00000161, Avg batch loss: 1.7392, Avg batch acc: 0.0022
Train, Epoch: 1, Batch: 47, Step num: 47, Learning rate: 0.00000164, Avg batch loss: 1.6467, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 48, Step num: 48, Learning rate: 0.00000168, Avg batch loss: 1.6791, Avg batch acc: 0.0013
Train, Epoch: 1, Batch: 49, Step num: 49, Learning rate: 0.00000171, Avg batch loss: 1.6474, Avg batch acc: 0.0003
Train, Epoch: 1, Batch: 50, Step num: 50, Learning rate: 0.00000175, Avg batch loss: 1.6242, Avg batch acc: 0.0022
Train, Epoch: 1, Batch: 51, Step num: 51, Learning rate: 0.00000178, Avg batch loss: 1.8266, Avg batch acc: 0.0002
Train, Epoch: 1, Batch: 52, Step num: 52, Learning rate: 0.00000182, Avg batch loss: 1.7283, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 53, Step num: 53, Learning rate: 0.00000185, Avg batch loss: 1.5616, Avg batch acc: 0.0016
Train, Epoch: 1, Batch: 54, Step num: 54, Learning rate: 0.00000189, Avg batch loss: 1.7116, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 55, Step num: 55, Learning rate: 0.00000192, Avg batch loss: 1.5655, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 56, Step num: 56, Learning rate: 0.00000196, Avg batch loss: 1.6072, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 57, Step num: 57, Learning rate: 0.00000199, Avg batch loss: 1.5914, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 58, Step num: 58, Learning rate: 0.00000203, Avg batch loss: 1.5606, Avg batch acc: 0.0019
Train, Epoch: 1, Batch: 59, Step num: 59, Learning rate: 0.00000206, Avg batch loss: 1.6708, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 60, Step num: 60, Learning rate: 0.00000210, Avg batch loss: 1.6204, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 61, Step num: 61, Learning rate: 0.00000213, Avg batch loss: 1.7405, Avg batch acc: 0.0017
Train, Epoch: 1, Batch: 62, Step num: 62, Learning rate: 0.00000217, Avg batch loss: 1.6941, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 63, Step num: 63, Learning rate: 0.00000220, Avg batch loss: 1.7266, Avg batch acc: 0.0017
Train, Epoch: 1, Batch: 64, Step num: 64, Learning rate: 0.00000224, Avg batch loss: 1.7120, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 65, Step num: 65, Learning rate: 0.00000227, Avg batch loss: 1.6153, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 66, Step num: 66, Learning rate: 0.00000231, Avg batch loss: 1.7146, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 67, Step num: 67, Learning rate: 0.00000234, Avg batch loss: 1.6105, Avg batch acc: 0.0013
Train, Epoch: 1, Batch: 68, Step num: 68, Learning rate: 0.00000238, Avg batch loss: 1.4966, Avg batch acc: 0.0014
Train, Epoch: 1, Batch: 69, Step num: 69, Learning rate: 0.00000241, Avg batch loss: 1.7707, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 70, Step num: 70, Learning rate: 0.00000245, Avg batch loss: 1.6865, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 71, Step num: 71, Learning rate: 0.00000248, Avg batch loss: 1.5472, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 72, Step num: 72, Learning rate: 0.00000252, Avg batch loss: 1.7646, Avg batch acc: 0.0013
Train, Epoch: 1, Batch: 73, Step num: 73, Learning rate: 0.00000255, Avg batch loss: 1.6118, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 74, Step num: 74, Learning rate: 0.00000259, Avg batch loss: 1.7915, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 75, Step num: 75, Learning rate: 0.00000262, Avg batch loss: 1.6656, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 76, Step num: 76, Learning rate: 0.00000266, Avg batch loss: 1.6515, Avg batch acc: 0.0018
Train, Epoch: 1, Batch: 77, Step num: 77, Learning rate: 0.00000269, Avg batch loss: 1.6896, Avg batch acc: 0.0017
Train, Epoch: 1, Batch: 78, Step num: 78, Learning rate: 0.00000273, Avg batch loss: 1.6022, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 79, Step num: 79, Learning rate: 0.00000276, Avg batch loss: 1.7130, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 80, Step num: 80, Learning rate: 0.00000280, Avg batch loss: 1.5384, Avg batch acc: 0.0018
Train, Epoch: 1, Batch: 81, Step num: 81, Learning rate: 0.00000283, Avg batch loss: 1.6530, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 82, Step num: 82, Learning rate: 0.00000286, Avg batch loss: 1.5947, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 83, Step num: 83, Learning rate: 0.00000290, Avg batch loss: 1.6322, Avg batch acc: 0.0019
Train, Epoch: 1, Batch: 84, Step num: 84, Learning rate: 0.00000293, Avg batch loss: 1.6608, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 85, Step num: 85, Learning rate: 0.00000297, Avg batch loss: 1.6432, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 86, Step num: 86, Learning rate: 0.00000300, Avg batch loss: 1.6312, Avg batch acc: 0.0013
Train, Epoch: 1, Batch: 87, Step num: 87, Learning rate: 0.00000304, Avg batch loss: 1.6741, Avg batch acc: 0.0031
Train, Epoch: 1, Batch: 88, Step num: 88, Learning rate: 0.00000307, Avg batch loss: 1.6732, Avg batch acc: 0.0014
Train, Epoch: 1, Batch: 89, Step num: 89, Learning rate: 0.00000311, Avg batch loss: 1.7671, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 90, Step num: 90, Learning rate: 0.00000314, Avg batch loss: 1.6630, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 91, Step num: 91, Learning rate: 0.00000318, Avg batch loss: 1.5768, Avg batch acc: 0.0017
Train, Epoch: 1, Batch: 92, Step num: 92, Learning rate: 0.00000321, Avg batch loss: 1.7497, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 93, Step num: 93, Learning rate: 0.00000325, Avg batch loss: 1.9101, Avg batch acc: 0.0011
Train, Epoch: 1, Batch: 94, Step num: 94, Learning rate: 0.00000328, Avg batch loss: 1.6914, Avg batch acc: 0.0021
Train, Epoch: 1, Batch: 95, Step num: 95, Learning rate: 0.00000332, Avg batch loss: 1.7050, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 96, Step num: 96, Learning rate: 0.00000335, Avg batch loss: 1.8100, Avg batch acc: 0.0029
Train, Epoch: 1, Batch: 97, Step num: 97, Learning rate: 0.00000339, Avg batch loss: 1.7271, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 98, Step num: 98, Learning rate: 0.00000342, Avg batch loss: 1.6805, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 99, Step num: 99, Learning rate: 0.00000346, Avg batch loss: 1.9599, Avg batch acc: 0.0017
Train, Epoch: 1, Batch: 100, Step num: 100, Learning rate: 0.00000349, Avg batch loss: 1.6816, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 101, Step num: 101, Learning rate: 0.00000353, Avg batch loss: 1.6157, Avg batch acc: 0.0020
Train, Epoch: 1, Batch: 102, Step num: 102, Learning rate: 0.00000356, Avg batch loss: 1.7325, Avg batch acc: 0.0013
Train, Epoch: 1, Batch: 103, Step num: 103, Learning rate: 0.00000360, Avg batch loss: 1.7978, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 104, Step num: 104, Learning rate: 0.00000363, Avg batch loss: 1.6345, Avg batch acc: 0.0038
Train, Epoch: 1, Batch: 105, Step num: 105, Learning rate: 0.00000367, Avg batch loss: 1.5833, Avg batch acc: 0.0016
Train, Epoch: 1, Batch: 106, Step num: 106, Learning rate: 0.00000370, Avg batch loss: 1.5902, Avg batch acc: 0.0029
Train, Epoch: 1, Batch: 107, Step num: 107, Learning rate: 0.00000374, Avg batch loss: 1.7076, Avg batch acc: 0.0011
Train, Epoch: 1, Batch: 108, Step num: 108, Learning rate: 0.00000377, Avg batch loss: 1.7940, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 109, Step num: 109, Learning rate: 0.00000381, Avg batch loss: 1.7451, Avg batch acc: 0.0016
Train, Epoch: 1, Batch: 110, Step num: 110, Learning rate: 0.00000384, Avg batch loss: 1.7123, Avg batch acc: 0.0017
Train, Epoch: 1, Batch: 111, Step num: 111, Learning rate: 0.00000388, Avg batch loss: 1.6120, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 112, Step num: 112, Learning rate: 0.00000391, Avg batch loss: 1.6150, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 113, Step num: 113, Learning rate: 0.00000395, Avg batch loss: 1.6912, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 114, Step num: 114, Learning rate: 0.00000398, Avg batch loss: 1.7992, Avg batch acc: 0.0015
Train, Epoch: 1, Batch: 115, Step num: 115, Learning rate: 0.00000402, Avg batch loss: 1.5743, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 116, Step num: 116, Learning rate: 0.00000405, Avg batch loss: 1.6269, Avg batch acc: 0.0020
Train, Epoch: 1, Batch: 117, Step num: 117, Learning rate: 0.00000409, Avg batch loss: 1.6281, Avg batch acc: 0.0013
Train, Epoch: 1, Batch: 118, Step num: 118, Learning rate: 0.00000412, Avg batch loss: 1.6108, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 119, Step num: 119, Learning rate: 0.00000416, Avg batch loss: 1.6576, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 120, Step num: 120, Learning rate: 0.00000419, Avg batch loss: 1.6348, Avg batch acc: 0.0016
Train, Epoch: 1, Batch: 121, Step num: 121, Learning rate: 0.00000423, Avg batch loss: 1.6272, Avg batch acc: 0.0027
Train, Epoch: 1, Batch: 122, Step num: 122, Learning rate: 0.00000426, Avg batch loss: 1.7992, Avg batch acc: 0.0021
Train, Epoch: 1, Batch: 123, Step num: 123, Learning rate: 0.00000430, Avg batch loss: 1.6821, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 124, Step num: 124, Learning rate: 0.00000433, Avg batch loss: 1.6419, Avg batch acc: 0.0014
Train, Epoch: 1, Batch: 125, Step num: 125, Learning rate: 0.00000437, Avg batch loss: 1.6593, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 126, Step num: 126, Learning rate: 0.00000440, Avg batch loss: 1.6659, Avg batch acc: 0.0015
Train, Epoch: 1, Batch: 127, Step num: 127, Learning rate: 0.00000444, Avg batch loss: 1.8119, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 128, Step num: 128, Learning rate: 0.00000447, Avg batch loss: 1.6397, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 129, Step num: 129, Learning rate: 0.00000451, Avg batch loss: 1.6299, Avg batch acc: 0.0032
Train, Epoch: 1, Batch: 130, Step num: 130, Learning rate: 0.00000454, Avg batch loss: 1.6933, Avg batch acc: 0.0016
Train, Epoch: 1, Batch: 131, Step num: 131, Learning rate: 0.00000458, Avg batch loss: 1.6575, Avg batch acc: 0.0013
Train, Epoch: 1, Batch: 132, Step num: 132, Learning rate: 0.00000461, Avg batch loss: 1.7701, Avg batch acc: 0.0022
Train, Epoch: 1, Batch: 133, Step num: 133, Learning rate: 0.00000465, Avg batch loss: 1.6843, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 134, Step num: 134, Learning rate: 0.00000468, Avg batch loss: 1.7618, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 135, Step num: 135, Learning rate: 0.00000472, Avg batch loss: 1.7237, Avg batch acc: 0.0021
Train, Epoch: 1, Batch: 136, Step num: 136, Learning rate: 0.00000475, Avg batch loss: 1.5723, Avg batch acc: 0.0015
Train, Epoch: 1, Batch: 137, Step num: 137, Learning rate: 0.00000479, Avg batch loss: 1.6804, Avg batch acc: 0.0045
Train, Epoch: 1, Batch: 138, Step num: 138, Learning rate: 0.00000482, Avg batch loss: 1.7703, Avg batch acc: 0.0013
Train, Epoch: 1, Batch: 139, Step num: 139, Learning rate: 0.00000486, Avg batch loss: 1.6977, Avg batch acc: 0.0046
Train, Epoch: 1, Batch: 140, Step num: 140, Learning rate: 0.00000489, Avg batch loss: 1.7551, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 141, Step num: 141, Learning rate: 0.00000493, Avg batch loss: 1.5966, Avg batch acc: 0.0024
Train, Epoch: 1, Batch: 142, Step num: 142, Learning rate: 0.00000496, Avg batch loss: 1.6931, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 143, Step num: 143, Learning rate: 0.00000500, Avg batch loss: 1.6529, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 144, Step num: 144, Learning rate: 0.00000503, Avg batch loss: 1.6969, Avg batch acc: 0.0034
Train, Epoch: 1, Batch: 145, Step num: 145, Learning rate: 0.00000507, Avg batch loss: 1.7446, Avg batch acc: 0.0046
Train, Epoch: 1, Batch: 146, Step num: 146, Learning rate: 0.00000510, Avg batch loss: 1.5956, Avg batch acc: 0.0032
Train, Epoch: 1, Batch: 147, Step num: 147, Learning rate: 0.00000514, Avg batch loss: 1.5788, Avg batch acc: 0.0046
Train, Epoch: 1, Batch: 148, Step num: 148, Learning rate: 0.00000517, Avg batch loss: 1.6130, Avg batch acc: 0.0045
Train, Epoch: 1, Batch: 149, Step num: 149, Learning rate: 0.00000521, Avg batch loss: 1.6937, Avg batch acc: 0.0031
Train, Epoch: 1, Batch: 150, Step num: 150, Learning rate: 0.00000524, Avg batch loss: 1.7006, Avg batch acc: 0.0036
Train, Epoch: 1, Batch: 151, Step num: 151, Learning rate: 0.00000528, Avg batch loss: 1.6113, Avg batch acc: 0.0043
Train, Epoch: 1, Batch: 152, Step num: 152, Learning rate: 0.00000531, Avg batch loss: 1.6572, Avg batch acc: 0.0038
Train, Epoch: 1, Batch: 153, Step num: 153, Learning rate: 0.00000535, Avg batch loss: 1.7937, Avg batch acc: 0.0040
Train, Epoch: 1, Batch: 154, Step num: 154, Learning rate: 0.00000538, Avg batch loss: 1.6399, Avg batch acc: 0.0047
Train, Epoch: 1, Batch: 155, Step num: 155, Learning rate: 0.00000542, Avg batch loss: 1.6979, Avg batch acc: 0.0036
Train, Epoch: 1, Batch: 156, Step num: 156, Learning rate: 0.00000545, Avg batch loss: 1.6255, Avg batch acc: 0.0046
Train, Epoch: 1, Batch: 157, Step num: 157, Learning rate: 0.00000549, Avg batch loss: 1.5748, Avg batch acc: 0.0055
Train, Epoch: 1, Batch: 158, Step num: 158, Learning rate: 0.00000552, Avg batch loss: 1.7574, Avg batch acc: 0.0065
Train, Epoch: 1, Batch: 159, Step num: 159, Learning rate: 0.00000556, Avg batch loss: 1.6229, Avg batch acc: 0.0034
Train, Epoch: 1, Batch: 160, Step num: 160, Learning rate: 0.00000559, Avg batch loss: 1.5830, Avg batch acc: 0.0088
Train, Epoch: 1, Batch: 161, Step num: 161, Learning rate: 0.00000563, Avg batch loss: 1.6131, Avg batch acc: 0.0051
Train, Epoch: 1, Batch: 162, Step num: 162, Learning rate: 0.00000566, Avg batch loss: 1.6578, Avg batch acc: 0.0094
Train, Epoch: 1, Batch: 163, Step num: 163, Learning rate: 0.00000569, Avg batch loss: 1.7111, Avg batch acc: 0.0065
Train, Epoch: 1, Batch: 164, Step num: 164, Learning rate: 0.00000573, Avg batch loss: 1.7812, Avg batch acc: 0.0049
Train, Epoch: 1, Batch: 165, Step num: 165, Learning rate: 0.00000576, Avg batch loss: 1.7498, Avg batch acc: 0.0098
Train, Epoch: 1, Batch: 166, Step num: 166, Learning rate: 0.00000580, Avg batch loss: 1.7572, Avg batch acc: 0.0121
Train, Epoch: 1, Batch: 167, Step num: 167, Learning rate: 0.00000583, Avg batch loss: 1.7164, Avg batch acc: 0.0098
Train, Epoch: 1, Batch: 168, Step num: 168, Learning rate: 0.00000587, Avg batch loss: 1.6967, Avg batch acc: 0.0090
Train, Epoch: 1, Batch: 169, Step num: 169, Learning rate: 0.00000590, Avg batch loss: 1.7640, Avg batch acc: 0.0039
Train, Epoch: 1, Batch: 170, Step num: 170, Learning rate: 0.00000594, Avg batch loss: 1.8122, Avg batch acc: 0.0058
Train, Epoch: 1, Batch: 171, Step num: 171, Learning rate: 0.00000597, Avg batch loss: 1.6362, Avg batch acc: 0.0088
Train, Epoch: 1, Batch: 172, Step num: 172, Learning rate: 0.00000601, Avg batch loss: 1.7654, Avg batch acc: 0.0065
Train, Epoch: 1, Batch: 173, Step num: 173, Learning rate: 0.00000604, Avg batch loss: 1.7460, Avg batch acc: 0.0077
Train, Epoch: 1, Batch: 174, Step num: 174, Learning rate: 0.00000608, Avg batch loss: 1.5668, Avg batch acc: 0.0088
Train, Epoch: 1, Batch: 175, Step num: 175, Learning rate: 0.00000611, Avg batch loss: 1.6618, Avg batch acc: 0.0068
Train, Epoch: 1, Batch: 176, Step num: 176, Learning rate: 0.00000615, Avg batch loss: 1.6335, Avg batch acc: 0.0094
Train, Epoch: 1, Batch: 177, Step num: 177, Learning rate: 0.00000618, Avg batch loss: 1.7471, Avg batch acc: 0.0116
Train, Epoch: 1, Batch: 178, Step num: 178, Learning rate: 0.00000622, Avg batch loss: 1.8385, Avg batch acc: 0.0141
Train, Epoch: 1, Batch: 179, Step num: 179, Learning rate: 0.00000625, Avg batch loss: 1.7176, Avg batch acc: 0.0128
Train, Epoch: 1, Batch: 180, Step num: 180, Learning rate: 0.00000629, Avg batch loss: 1.6721, Avg batch acc: 0.0090
Train, Epoch: 1, Batch: 181, Step num: 181, Learning rate: 0.00000632, Avg batch loss: 1.7490, Avg batch acc: 0.0130
Train, Epoch: 1, Batch: 182, Step num: 182, Learning rate: 0.00000636, Avg batch loss: 1.6829, Avg batch acc: 0.0121
Train, Epoch: 1, Batch: 183, Step num: 183, Learning rate: 0.00000639, Avg batch loss: 1.6949, Avg batch acc: 0.0108
Train, Epoch: 1, Batch: 184, Step num: 184, Learning rate: 0.00000643, Avg batch loss: 1.6298, Avg batch acc: 0.0112
Train, Epoch: 1, Batch: 185, Step num: 185, Learning rate: 0.00000646, Avg batch loss: 1.4827, Avg batch acc: 0.0173
Train, Epoch: 1, Batch: 186, Step num: 186, Learning rate: 0.00000650, Avg batch loss: 1.5974, Avg batch acc: 0.0118
Train, Epoch: 1, Batch: 187, Step num: 187, Learning rate: 0.00000653, Avg batch loss: 1.7598, Avg batch acc: 0.0136
Train, Epoch: 1, Batch: 188, Step num: 188, Learning rate: 0.00000657, Avg batch loss: 1.8094, Avg batch acc: 0.0198
Train, Epoch: 1, Batch: 189, Step num: 189, Learning rate: 0.00000660, Avg batch loss: 1.5385, Avg batch acc: 0.0206
Train, Epoch: 1, Batch: 190, Step num: 190, Learning rate: 0.00000664, Avg batch loss: 1.6677, Avg batch acc: 0.0182
Train, Epoch: 1, Batch: 191, Step num: 191, Learning rate: 0.00000667, Avg batch loss: 1.7012, Avg batch acc: 0.0162
Train, Epoch: 1, Batch: 192, Step num: 192, Learning rate: 0.00000671, Avg batch loss: 1.6664, Avg batch acc: 0.0167
Train, Epoch: 1, Batch: 193, Step num: 193, Learning rate: 0.00000674, Avg batch loss: 1.7383, Avg batch acc: 0.0182
Train, Epoch: 1, Batch: 194, Step num: 194, Learning rate: 0.00000678, Avg batch loss: 1.6287, Avg batch acc: 0.0219
Train, Epoch: 1, Batch: 195, Step num: 195, Learning rate: 0.00000681, Avg batch loss: 1.5753, Avg batch acc: 0.0222
Train, Epoch: 1, Batch: 196, Step num: 196, Learning rate: 0.00000685, Avg batch loss: 1.5480, Avg batch acc: 0.0233
Train, Epoch: 1, Batch: 197, Step num: 197, Learning rate: 0.00000688, Avg batch loss: 1.8140, Avg batch acc: 0.0174
Train, Epoch: 1, Batch: 198, Step num: 198, Learning rate: 0.00000692, Avg batch loss: 1.6397, Avg batch acc: 0.0238
Train, Epoch: 1, Batch: 199, Step num: 199, Learning rate: 0.00000695, Avg batch loss: 1.5956, Avg batch acc: 0.0215
Train, Epoch: 1, Batch: 200, Step num: 200, Learning rate: 0.00000699, Avg batch loss: 1.6527, Avg batch acc: 0.0271
Train, Epoch: 1, Batch: 201, Step num: 201, Learning rate: 0.00000702, Avg batch loss: 1.5496, Avg batch acc: 0.0187
Train, Epoch: 1, Batch: 202, Step num: 202, Learning rate: 0.00000706, Avg batch loss: 1.5897, Avg batch acc: 0.0294
Train, Epoch: 1, Batch: 203, Step num: 203, Learning rate: 0.00000709, Avg batch loss: 1.8046, Avg batch acc: 0.0270
Train, Epoch: 1, Batch: 204, Step num: 204, Learning rate: 0.00000713, Avg batch loss: 1.5321, Avg batch acc: 0.0357
Train, Epoch: 1, Batch: 205, Step num: 205, Learning rate: 0.00000716, Avg batch loss: 1.7066, Avg batch acc: 0.0249
Train, Epoch: 1, Batch: 206, Step num: 206, Learning rate: 0.00000720, Avg batch loss: 1.6244, Avg batch acc: 0.0364
Train, Epoch: 1, Batch: 207, Step num: 207, Learning rate: 0.00000723, Avg batch loss: 1.6775, Avg batch acc: 0.0430
Train, Epoch: 1, Batch: 208, Step num: 208, Learning rate: 0.00000727, Avg batch loss: 1.6036, Avg batch acc: 0.0322
Train, Epoch: 1, Batch: 209, Step num: 209, Learning rate: 0.00000730, Avg batch loss: 1.6368, Avg batch acc: 0.0435
Train, Epoch: 1, Batch: 210, Step num: 210, Learning rate: 0.00000734, Avg batch loss: 1.7980, Avg batch acc: 0.0426
Train, Epoch: 1, Batch: 211, Step num: 211, Learning rate: 0.00000737, Avg batch loss: 1.6142, Avg batch acc: 0.0451
Train, Epoch: 1, Batch: 212, Step num: 212, Learning rate: 0.00000741, Avg batch loss: 1.5639, Avg batch acc: 0.0464
Train, Epoch: 1, Batch: 213, Step num: 213, Learning rate: 0.00000744, Avg batch loss: 1.6444, Avg batch acc: 0.0410
Train, Epoch: 1, Batch: 214, Step num: 214, Learning rate: 0.00000748, Avg batch loss: 1.6099, Avg batch acc: 0.0467
Train, Epoch: 1, Batch: 215, Step num: 215, Learning rate: 0.00000751, Avg batch loss: 1.4997, Avg batch acc: 0.0520
Train, Epoch: 1, Batch: 216, Step num: 216, Learning rate: 0.00000755, Avg batch loss: 1.6307, Avg batch acc: 0.0480
Train, Epoch: 1, Batch: 217, Step num: 217, Learning rate: 0.00000758, Avg batch loss: 1.7477, Avg batch acc: 0.0552
Train, Epoch: 1, Batch: 218, Step num: 218, Learning rate: 0.00000762, Avg batch loss: 1.7881, Avg batch acc: 0.0568
Train, Epoch: 1, Batch: 219, Step num: 219, Learning rate: 0.00000765, Avg batch loss: 1.7189, Avg batch acc: 0.0540
Train, Epoch: 1, Batch: 220, Step num: 220, Learning rate: 0.00000769, Avg batch loss: 1.5812, Avg batch acc: 0.0620
Train, Epoch: 1, Batch: 221, Step num: 221, Learning rate: 0.00000772, Avg batch loss: 1.7898, Avg batch acc: 0.0659
Train, Epoch: 1, Batch: 222, Step num: 222, Learning rate: 0.00000776, Avg batch loss: 1.8225, Avg batch acc: 0.0609
Train, Epoch: 1, Batch: 223, Step num: 223, Learning rate: 0.00000779, Avg batch loss: 1.6815, Avg batch acc: 0.0697
Train, Epoch: 1, Batch: 224, Step num: 224, Learning rate: 0.00000783, Avg batch loss: 1.6834, Avg batch acc: 0.0578
Train, Epoch: 1, Batch: 225, Step num: 225, Learning rate: 0.00000786, Avg batch loss: 1.6256, Avg batch acc: 0.0685
Train, Epoch: 1, Batch: 226, Step num: 226, Learning rate: 0.00000790, Avg batch loss: 1.6535, Avg batch acc: 0.0781
Train, Epoch: 1, Batch: 227, Step num: 227, Learning rate: 0.00000793, Avg batch loss: 1.5805, Avg batch acc: 0.0664
Train, Epoch: 1, Batch: 228, Step num: 228, Learning rate: 0.00000797, Avg batch loss: 1.6202, Avg batch acc: 0.0723
Train, Epoch: 1, Batch: 229, Step num: 229, Learning rate: 0.00000800, Avg batch loss: 1.6422, Avg batch acc: 0.0846
Train, Epoch: 1, Batch: 230, Step num: 230, Learning rate: 0.00000804, Avg batch loss: 1.7856, Avg batch acc: 0.0828
Train, Epoch: 1, Batch: 231, Step num: 231, Learning rate: 0.00000807, Avg batch loss: 1.7055, Avg batch acc: 0.0715
Train, Epoch: 1, Batch: 232, Step num: 232, Learning rate: 0.00000811, Avg batch loss: 1.5796, Avg batch acc: 0.0839
Train, Epoch: 1, Batch: 233, Step num: 233, Learning rate: 0.00000814, Avg batch loss: 1.7502, Avg batch acc: 0.0779
Train, Epoch: 1, Batch: 234, Step num: 234, Learning rate: 0.00000818, Avg batch loss: 1.8295, Avg batch acc: 0.0829
Train, Epoch: 1, Batch: 235, Step num: 235, Learning rate: 0.00000821, Avg batch loss: 1.4925, Avg batch acc: 0.0994
Train, Epoch: 1, Batch: 236, Step num: 236, Learning rate: 0.00000825, Avg batch loss: 1.7541, Avg batch acc: 0.0875
Train, Epoch: 1, Batch: 237, Step num: 237, Learning rate: 0.00000828, Avg batch loss: 1.6882, Avg batch acc: 0.0940
Train, Epoch: 1, Batch: 238, Step num: 238, Learning rate: 0.00000832, Avg batch loss: 1.6046, Avg batch acc: 0.0978
Train, Epoch: 1, Batch: 239, Step num: 239, Learning rate: 0.00000835, Avg batch loss: 1.6671, Avg batch acc: 0.0926
Train, Epoch: 1, Batch: 240, Step num: 240, Learning rate: 0.00000839, Avg batch loss: 1.6688, Avg batch acc: 0.0995
Train, Epoch: 1, Batch: 241, Step num: 241, Learning rate: 0.00000842, Avg batch loss: 1.7218, Avg batch acc: 0.0972
Train, Epoch: 1, Batch: 242, Step num: 242, Learning rate: 0.00000846, Avg batch loss: 1.7424, Avg batch acc: 0.0984
Train, Epoch: 1, Batch: 243, Step num: 243, Learning rate: 0.00000849, Avg batch loss: 1.6431, Avg batch acc: 0.1023
Train, Epoch: 1, Batch: 244, Step num: 244, Learning rate: 0.00000853, Avg batch loss: 1.5548, Avg batch acc: 0.1035
Train, Epoch: 1, Batch: 245, Step num: 245, Learning rate: 0.00000856, Avg batch loss: 1.5441, Avg batch acc: 0.1142
Train, Epoch: 1, Batch: 246, Step num: 246, Learning rate: 0.00000859, Avg batch loss: 1.5714, Avg batch acc: 0.1119
Train, Epoch: 1, Batch: 247, Step num: 247, Learning rate: 0.00000863, Avg batch loss: 1.5951, Avg batch acc: 0.1149
Train, Epoch: 1, Batch: 248, Step num: 248, Learning rate: 0.00000866, Avg batch loss: 1.5662, Avg batch acc: 0.1069
Train, Epoch: 1, Batch: 249, Step num: 249, Learning rate: 0.00000870, Avg batch loss: 1.6302, Avg batch acc: 0.1107
Train, Epoch: 1, Batch: 250, Step num: 250, Learning rate: 0.00000873, Avg batch loss: 1.6386, Avg batch acc: 0.1140
Train, Epoch: 1, Batch: 251, Step num: 251, Learning rate: 0.00000877, Avg batch loss: 1.6926, Avg batch acc: 0.1135
Train, Epoch: 1, Batch: 252, Step num: 252, Learning rate: 0.00000880, Avg batch loss: 1.5370, Avg batch acc: 0.1200
Train, Epoch: 1, Batch: 253, Step num: 253, Learning rate: 0.00000884, Avg batch loss: 1.6232, Avg batch acc: 0.1291
Train, Epoch: 1, Batch: 254, Step num: 254, Learning rate: 0.00000887, Avg batch loss: 1.6108, Avg batch acc: 0.1160
Train, Epoch: 1, Batch: 255, Step num: 255, Learning rate: 0.00000891, Avg batch loss: 1.5890, Avg batch acc: 0.1332
Train, Epoch: 1, Batch: 256, Step num: 256, Learning rate: 0.00000894, Avg batch loss: 1.6381, Avg batch acc: 0.1261
Train, Epoch: 1, Batch: 257, Step num: 257, Learning rate: 0.00000898, Avg batch loss: 1.5058, Avg batch acc: 0.1244
Train, Epoch: 1, Batch: 258, Step num: 258, Learning rate: 0.00000901, Avg batch loss: 1.6624, Avg batch acc: 0.1253
Train, Epoch: 1, Batch: 259, Step num: 259, Learning rate: 0.00000905, Avg batch loss: 1.7667, Avg batch acc: 0.1133
Train, Epoch: 1, Batch: 260, Step num: 260, Learning rate: 0.00000908, Avg batch loss: 1.6468, Avg batch acc: 0.1429
Train, Epoch: 1, Batch: 261, Step num: 261, Learning rate: 0.00000912, Avg batch loss: 1.7074, Avg batch acc: 0.1196
Train, Epoch: 1, Batch: 262, Step num: 262, Learning rate: 0.00000915, Avg batch loss: 1.7045, Avg batch acc: 0.1243
Train, Epoch: 1, Batch: 263, Step num: 263, Learning rate: 0.00000919, Avg batch loss: 1.6723, Avg batch acc: 0.1240
Train, Epoch: 1, Batch: 264, Step num: 264, Learning rate: 0.00000922, Avg batch loss: 1.4222, Avg batch acc: 0.1430
Train, Epoch: 1, Batch: 265, Step num: 265, Learning rate: 0.00000926, Avg batch loss: 1.6375, Avg batch acc: 0.1197
Train, Epoch: 1, Batch: 266, Step num: 266, Learning rate: 0.00000929, Avg batch loss: 1.5971, Avg batch acc: 0.1364
Train, Epoch: 1, Batch: 267, Step num: 267, Learning rate: 0.00000933, Avg batch loss: 1.6519, Avg batch acc: 0.1315
Train, Epoch: 1, Batch: 268, Step num: 268, Learning rate: 0.00000936, Avg batch loss: 1.7228, Avg batch acc: 0.1295
Train, Epoch: 1, Batch: 269, Step num: 269, Learning rate: 0.00000940, Avg batch loss: 1.6589, Avg batch acc: 0.1361
Train, Epoch: 1, Batch: 270, Step num: 270, Learning rate: 0.00000943, Avg batch loss: 1.6203, Avg batch acc: 0.1192
Train, Epoch: 1, Batch: 271, Step num: 271, Learning rate: 0.00000947, Avg batch loss: 1.6136, Avg batch acc: 0.1476
Train, Epoch: 1, Batch: 272, Step num: 272, Learning rate: 0.00000950, Avg batch loss: 1.5976, Avg batch acc: 0.1386
Train, Epoch: 1, Batch: 273, Step num: 273, Learning rate: 0.00000954, Avg batch loss: 1.6021, Avg batch acc: 0.1392
Train, Epoch: 1, Batch: 274, Step num: 274, Learning rate: 0.00000957, Avg batch loss: 1.6181, Avg batch acc: 0.1399
Train, Epoch: 1, Batch: 275, Step num: 275, Learning rate: 0.00000961, Avg batch loss: 1.6863, Avg batch acc: 0.1418
Train, Epoch: 1, Batch: 276, Step num: 276, Learning rate: 0.00000964, Avg batch loss: 1.6115, Avg batch acc: 0.1488
Train, Epoch: 1, Batch: 277, Step num: 277, Learning rate: 0.00000968, Avg batch loss: 1.4905, Avg batch acc: 0.1425
Train, Epoch: 1, Batch: 278, Step num: 278, Learning rate: 0.00000971, Avg batch loss: 1.4906, Avg batch acc: 0.1527
Train, Epoch: 1, Batch: 279, Step num: 279, Learning rate: 0.00000975, Avg batch loss: 1.6188, Avg batch acc: 0.1405
Train, Epoch: 1, Batch: 280, Step num: 280, Learning rate: 0.00000978, Avg batch loss: 1.7923, Avg batch acc: 0.1423
Train, Epoch: 1, Batch: 281, Step num: 281, Learning rate: 0.00000982, Avg batch loss: 1.5364, Avg batch acc: 0.1494
Train, Epoch: 1, Batch: 282, Step num: 282, Learning rate: 0.00000985, Avg batch loss: 1.5439, Avg batch acc: 0.1473
Train, Epoch: 1, Batch: 283, Step num: 283, Learning rate: 0.00000989, Avg batch loss: 1.6085, Avg batch acc: 0.1370
Train, Epoch: 1, Batch: 284, Step num: 284, Learning rate: 0.00000992, Avg batch loss: 1.6342, Avg batch acc: 0.1429
Train, Epoch: 1, Batch: 285, Step num: 285, Learning rate: 0.00000996, Avg batch loss: 1.5146, Avg batch acc: 0.1520
Train, Epoch: 1, Batch: 286, Step num: 286, Learning rate: 0.00000999, Avg batch loss: 1.5462, Avg batch acc: 0.1542
Train, Epoch: 1, Batch: 287, Step num: 287, Learning rate: 0.00001003, Avg batch loss: 1.5891, Avg batch acc: 0.1543
Train, Epoch: 1, Batch: 288, Step num: 288, Learning rate: 0.00001006, Avg batch loss: 1.4972, Avg batch acc: 0.1447
Train, Epoch: 1, Batch: 289, Step num: 289, Learning rate: 0.00001010, Avg batch loss: 1.7580, Avg batch acc: 0.1435
Train, Epoch: 1, Batch: 290, Step num: 290, Learning rate: 0.00001013, Avg batch loss: 1.6818, Avg batch acc: 0.1309
Train, Epoch: 1, Batch: 291, Step num: 291, Learning rate: 0.00001017, Avg batch loss: 1.6328, Avg batch acc: 0.1565
Train, Epoch: 1, Batch: 292, Step num: 292, Learning rate: 0.00001020, Avg batch loss: 1.6039, Avg batch acc: 0.1293
Train, Epoch: 1, Batch: 293, Step num: 293, Learning rate: 0.00001024, Avg batch loss: 1.4850, Avg batch acc: 0.1583
Train, Epoch: 1, Batch: 294, Step num: 294, Learning rate: 0.00001027, Avg batch loss: 1.6748, Avg batch acc: 0.1516
Train, Epoch: 1, Batch: 295, Step num: 295, Learning rate: 0.00001031, Avg batch loss: 1.5678, Avg batch acc: 0.1505
Train, Epoch: 1, Batch: 296, Step num: 296, Learning rate: 0.00001034, Avg batch loss: 1.6305, Avg batch acc: 0.1514
Train, Epoch: 1, Batch: 297, Step num: 297, Learning rate: 0.00001038, Avg batch loss: 1.5983, Avg batch acc: 0.1420
Train, Epoch: 1, Batch: 298, Step num: 298, Learning rate: 0.00001041, Avg batch loss: 1.4731, Avg batch acc: 0.1564
Train, Epoch: 1, Batch: 299, Step num: 299, Learning rate: 0.00001045, Avg batch loss: 1.4890, Avg batch acc: 0.1513
Train, Epoch: 1, Batch: 300, Step num: 300, Learning rate: 0.00001048, Avg batch loss: 1.4831, Avg batch acc: 0.1403
Train, Epoch: 1, Batch: 301, Step num: 301, Learning rate: 0.00001052, Avg batch loss: 1.5719, Avg batch acc: 0.1455
Train, Epoch: 1, Batch: 302, Step num: 302, Learning rate: 0.00001055, Avg batch loss: 1.5873, Avg batch acc: 0.1492
Train, Epoch: 1, Batch: 303, Step num: 303, Learning rate: 0.00001059, Avg batch loss: 1.6263, Avg batch acc: 0.1295
Train, Epoch: 1, Batch: 304, Step num: 304, Learning rate: 0.00001062, Avg batch loss: 1.3556, Avg batch acc: 0.1487
Train, Epoch: 1, Batch: 305, Step num: 305, Learning rate: 0.00001066, Avg batch loss: 1.5494, Avg batch acc: 0.1385
Train, Epoch: 1, Batch: 306, Step num: 306, Learning rate: 0.00001069, Avg batch loss: 1.5698, Avg batch acc: 0.1456
Train, Epoch: 1, Batch: 307, Step num: 307, Learning rate: 0.00001073, Avg batch loss: 1.5272, Avg batch acc: 0.1493
Train, Epoch: 1, Batch: 308, Step num: 308, Learning rate: 0.00001076, Avg batch loss: 1.6459, Avg batch acc: 0.1529
Train, Epoch: 1, Batch: 309, Step num: 309, Learning rate: 0.00001080, Avg batch loss: 1.5243, Avg batch acc: 0.1424
Train, Epoch: 1, Batch: 310, Step num: 310, Learning rate: 0.00001083, Avg batch loss: 1.4955, Avg batch acc: 0.1434
Train, Epoch: 1, Batch: 311, Step num: 311, Learning rate: 0.00001087, Avg batch loss: 1.6136, Avg batch acc: 0.1396
Train, Epoch: 1, Batch: 312, Step num: 312, Learning rate: 0.00001090, Avg batch loss: 1.5687, Avg batch acc: 0.1347
Train, Epoch: 1, Batch: 313, Step num: 313, Learning rate: 0.00001094, Avg batch loss: 1.4922, Avg batch acc: 0.1395
Train, Epoch: 1, Batch: 314, Step num: 314, Learning rate: 0.00001097, Avg batch loss: 1.5501, Avg batch acc: 0.1398
Train, Epoch: 1, Batch: 315, Step num: 315, Learning rate: 0.00001101, Avg batch loss: 1.5336, Avg batch acc: 0.1441
Train, Epoch: 1, Batch: 316, Step num: 316, Learning rate: 0.00001104, Avg batch loss: 1.5193, Avg batch acc: 0.1379
Train, Epoch: 1, Batch: 317, Step num: 317, Learning rate: 0.00001108, Avg batch loss: 1.4142, Avg batch acc: 0.1369
Train, Epoch: 1, Batch: 318, Step num: 318, Learning rate: 0.00001111, Avg batch loss: 1.5283, Avg batch acc: 0.1355
Train, Epoch: 1, Batch: 319, Step num: 319, Learning rate: 0.00001115, Avg batch loss: 1.5628, Avg batch acc: 0.1417
Train, Epoch: 1, Batch: 320, Step num: 320, Learning rate: 0.00001118, Avg batch loss: 1.5539, Avg batch acc: 0.1585
Train, Epoch: 1, Batch: 321, Step num: 321, Learning rate: 0.00001122, Avg batch loss: 1.5168, Avg batch acc: 0.1475
Train, Epoch: 1, Batch: 322, Step num: 322, Learning rate: 0.00001125, Avg batch loss: 1.4462, Avg batch acc: 0.1551
Train, Epoch: 1, Batch: 323, Step num: 323, Learning rate: 0.00001129, Avg batch loss: 1.4592, Avg batch acc: 0.1484
Train, Epoch: 1, Batch: 324, Step num: 324, Learning rate: 0.00001132, Avg batch loss: 1.5363, Avg batch acc: 0.1390
Train, Epoch: 1, Batch: 325, Step num: 325, Learning rate: 0.00001136, Avg batch loss: 1.5430, Avg batch acc: 0.1421
Train, Epoch: 1, Batch: 326, Step num: 326, Learning rate: 0.00001139, Avg batch loss: 1.4706, Avg batch acc: 0.1467
Train, Epoch: 1, Batch: 327, Step num: 327, Learning rate: 0.00001142, Avg batch loss: 1.4727, Avg batch acc: 0.1425
Train, Epoch: 1, Batch: 328, Step num: 328, Learning rate: 0.00001146, Avg batch loss: 1.4579, Avg batch acc: 0.1476
Train, Epoch: 1, Batch: 329, Step num: 329, Learning rate: 0.00001149, Avg batch loss: 1.5825, Avg batch acc: 0.1398
Train, Epoch: 1, Batch: 330, Step num: 330, Learning rate: 0.00001153, Avg batch loss: 1.4555, Avg batch acc: 0.1516
Train, Epoch: 1, Batch: 331, Step num: 331, Learning rate: 0.00001156, Avg batch loss: 1.4403, Avg batch acc: 0.1339
Train, Epoch: 1, Batch: 332, Step num: 332, Learning rate: 0.00001160, Avg batch loss: 1.4626, Avg batch acc: 0.1462
Train, Epoch: 1, Batch: 333, Step num: 333, Learning rate: 0.00001163, Avg batch loss: 1.5159, Avg batch acc: 0.1422
Train, Epoch: 1, Batch: 334, Step num: 334, Learning rate: 0.00001167, Avg batch loss: 1.5639, Avg batch acc: 0.1349
Train, Epoch: 1, Batch: 335, Step num: 335, Learning rate: 0.00001170, Avg batch loss: 1.5863, Avg batch acc: 0.1626
Train, Epoch: 1, Batch: 336, Step num: 336, Learning rate: 0.00001174, Avg batch loss: 1.4161, Avg batch acc: 0.1452
Train, Epoch: 1, Batch: 337, Step num: 337, Learning rate: 0.00001177, Avg batch loss: 1.6047, Avg batch acc: 0.1426
Train, Epoch: 1, Batch: 338, Step num: 338, Learning rate: 0.00001181, Avg batch loss: 1.3886, Avg batch acc: 0.1468
Train, Epoch: 1, Batch: 339, Step num: 339, Learning rate: 0.00001184, Avg batch loss: 1.3453, Avg batch acc: 0.1549
Train, Epoch: 1, Batch: 340, Step num: 340, Learning rate: 0.00001188, Avg batch loss: 1.4623, Avg batch acc: 0.1477
Train, Epoch: 1, Batch: 341, Step num: 341, Learning rate: 0.00001191, Avg batch loss: 1.6157, Avg batch acc: 0.1390
Train, Epoch: 1, Batch: 342, Step num: 342, Learning rate: 0.00001195, Avg batch loss: 1.3605, Avg batch acc: 0.1445
Train, Epoch: 1, Batch: 343, Step num: 343, Learning rate: 0.00001198, Avg batch loss: 1.5169, Avg batch acc: 0.1432
Train, Epoch: 1, Batch: 344, Step num: 344, Learning rate: 0.00001202, Avg batch loss: 1.4453, Avg batch acc: 0.1489
Train, Epoch: 1, Batch: 345, Step num: 345, Learning rate: 0.00001205, Avg batch loss: 1.4341, Avg batch acc: 0.1448
Train, Epoch: 1, Batch: 346, Step num: 346, Learning rate: 0.00001209, Avg batch loss: 1.4507, Avg batch acc: 0.1493
Train, Epoch: 1, Batch: 347, Step num: 347, Learning rate: 0.00001212, Avg batch loss: 1.4550, Avg batch acc: 0.1388
Train, Epoch: 1, Batch: 348, Step num: 348, Learning rate: 0.00001216, Avg batch loss: 1.4127, Avg batch acc: 0.1401
Train, Epoch: 1, Batch: 349, Step num: 349, Learning rate: 0.00001219, Avg batch loss: 1.3652, Avg batch acc: 0.1468
Train, Epoch: 1, Batch: 350, Step num: 350, Learning rate: 0.00001223, Avg batch loss: 1.3397, Avg batch acc: 0.1481
Train, Epoch: 1, Batch: 351, Step num: 351, Learning rate: 0.00001226, Avg batch loss: 1.5048, Avg batch acc: 0.1376
Train, Epoch: 1, Batch: 352, Step num: 352, Learning rate: 0.00001230, Avg batch loss: 1.3430, Avg batch acc: 0.1438
Train, Epoch: 1, Batch: 353, Step num: 353, Learning rate: 0.00001233, Avg batch loss: 1.4965, Avg batch acc: 0.1375
Train, Epoch: 1, Batch: 354, Step num: 354, Learning rate: 0.00001237, Avg batch loss: 1.3500, Avg batch acc: 0.1447
Train, Epoch: 1, Batch: 355, Step num: 355, Learning rate: 0.00001240, Avg batch loss: 1.2820, Avg batch acc: 0.1507
Train, Epoch: 1, Batch: 356, Step num: 356, Learning rate: 0.00001244, Avg batch loss: 1.4415, Avg batch acc: 0.1465
Train, Epoch: 1, Batch: 357, Step num: 357, Learning rate: 0.00001247, Avg batch loss: 1.3835, Avg batch acc: 0.1388
Train, Epoch: 1, Batch: 358, Step num: 358, Learning rate: 0.00001251, Avg batch loss: 1.4475, Avg batch acc: 0.1629
Train, Epoch: 1, Batch: 359, Step num: 359, Learning rate: 0.00001254, Avg batch loss: 1.3831, Avg batch acc: 0.1391
Train, Epoch: 1, Batch: 360, Step num: 360, Learning rate: 0.00001258, Avg batch loss: 1.4838, Avg batch acc: 0.1423
Train, Epoch: 1, Batch: 361, Step num: 361, Learning rate: 0.00001261, Avg batch loss: 1.3386, Avg batch acc: 0.1508
Train, Epoch: 1, Batch: 362, Step num: 362, Learning rate: 0.00001265, Avg batch loss: 1.5355, Avg batch acc: 0.1381
Train, Epoch: 1, Batch: 363, Step num: 363, Learning rate: 0.00001268, Avg batch loss: 1.4234, Avg batch acc: 0.1519
Train, Epoch: 1, Batch: 364, Step num: 364, Learning rate: 0.00001272, Avg batch loss: 1.4542, Avg batch acc: 0.1500
Train, Epoch: 1, Batch: 365, Step num: 365, Learning rate: 0.00001275, Avg batch loss: 1.4161, Avg batch acc: 0.1455
Train, Epoch: 1, Batch: 366, Step num: 366, Learning rate: 0.00001279, Avg batch loss: 1.4483, Avg batch acc: 0.1421
Train, Epoch: 1, Batch: 367, Step num: 367, Learning rate: 0.00001282, Avg batch loss: 1.2256, Avg batch acc: 0.1447
Train, Epoch: 1, Batch: 368, Step num: 368, Learning rate: 0.00001286, Avg batch loss: 1.6053, Avg batch acc: 0.1322
Train, Epoch: 1, Batch: 369, Step num: 369, Learning rate: 0.00001289, Avg batch loss: 1.2939, Avg batch acc: 0.1682
Train, Epoch: 1, Batch: 370, Step num: 370, Learning rate: 0.00001293, Avg batch loss: 1.5359, Avg batch acc: 0.1399
Train, Epoch: 1, Batch: 371, Step num: 371, Learning rate: 0.00001296, Avg batch loss: 1.3582, Avg batch acc: 0.1445
Train, Epoch: 1, Batch: 372, Step num: 372, Learning rate: 0.00001300, Avg batch loss: 1.4691, Avg batch acc: 0.1389
Train, Epoch: 1, Batch: 373, Step num: 373, Learning rate: 0.00001303, Avg batch loss: 1.4924, Avg batch acc: 0.1426
Train, Epoch: 1, Batch: 374, Step num: 374, Learning rate: 0.00001307, Avg batch loss: 1.3762, Avg batch acc: 0.1452
Train, Epoch: 1, Batch: 375, Step num: 375, Learning rate: 0.00001310, Avg batch loss: 1.3644, Avg batch acc: 0.1395
Train, Epoch: 1, Batch: 376, Step num: 376, Learning rate: 0.00001314, Avg batch loss: 1.3936, Avg batch acc: 0.1472
Train, Epoch: 1, Batch: 377, Step num: 377, Learning rate: 0.00001317, Avg batch loss: 1.2893, Avg batch acc: 0.1516
Train, Epoch: 1, Batch: 378, Step num: 378, Learning rate: 0.00001321, Avg batch loss: 1.3530, Avg batch acc: 0.1327
Train, Epoch: 1, Batch: 379, Step num: 379, Learning rate: 0.00001324, Avg batch loss: 1.4681, Avg batch acc: 0.1326
Train, Epoch: 1, Batch: 380, Step num: 380, Learning rate: 0.00001328, Avg batch loss: 1.4597, Avg batch acc: 0.1339
Train, Epoch: 1, Batch: 381, Step num: 381, Learning rate: 0.00001331, Avg batch loss: 1.4918, Avg batch acc: 0.1350
Train, Epoch: 1, Batch: 382, Step num: 382, Learning rate: 0.00001335, Avg batch loss: 1.3582, Avg batch acc: 0.1409
Train, Epoch: 1, Batch: 383, Step num: 383, Learning rate: 0.00001338, Avg batch loss: 1.3848, Avg batch acc: 0.1355
Train, Epoch: 1, Batch: 384, Step num: 384, Learning rate: 0.00001342, Avg batch loss: 1.2068, Avg batch acc: 0.1260
Train, Epoch: 1, Batch: 385, Step num: 385, Learning rate: 0.00001345, Avg batch loss: 1.2916, Avg batch acc: 0.1466
Train, Epoch: 1, Batch: 386, Step num: 386, Learning rate: 0.00001349, Avg batch loss: 1.5371, Avg batch acc: 0.1419
Train, Epoch: 1, Batch: 387, Step num: 387, Learning rate: 0.00001352, Avg batch loss: 1.3744, Avg batch acc: 0.1213
Train, Epoch: 1, Batch: 388, Step num: 388, Learning rate: 0.00001356, Avg batch loss: 1.3904, Avg batch acc: 0.1299
Train, Epoch: 1, Batch: 389, Step num: 389, Learning rate: 0.00001359, Avg batch loss: 1.3072, Avg batch acc: 0.1412
Train, Epoch: 1, Batch: 390, Step num: 390, Learning rate: 0.00001363, Avg batch loss: 1.3700, Avg batch acc: 0.1255
Train, Epoch: 1, Batch: 391, Step num: 391, Learning rate: 0.00001366, Avg batch loss: 1.4992, Avg batch acc: 0.1299
Train, Epoch: 1, Batch: 392, Step num: 392, Learning rate: 0.00001370, Avg batch loss: 1.3134, Avg batch acc: 0.1526
Train, Epoch: 1, Batch: 393, Step num: 393, Learning rate: 0.00001373, Avg batch loss: 1.2583, Avg batch acc: 0.1346
Train, Epoch: 1, Batch: 394, Step num: 394, Learning rate: 0.00001377, Avg batch loss: 1.3444, Avg batch acc: 0.1272
Train, Epoch: 1, Batch: 395, Step num: 395, Learning rate: 0.00001380, Avg batch loss: 1.2824, Avg batch acc: 0.1332
Train, Epoch: 1, Batch: 396, Step num: 396, Learning rate: 0.00001384, Avg batch loss: 1.3119, Avg batch acc: 0.1218
Train, Epoch: 1, Batch: 397, Step num: 397, Learning rate: 0.00001387, Avg batch loss: 1.2867, Avg batch acc: 0.1244
Train, Epoch: 1, Batch: 398, Step num: 398, Learning rate: 0.00001391, Avg batch loss: 1.4017, Avg batch acc: 0.1245
Train, Epoch: 1, Batch: 399, Step num: 399, Learning rate: 0.00001394, Avg batch loss: 1.2837, Avg batch acc: 0.1228
Train, Epoch: 1, Batch: 400, Step num: 400, Learning rate: 0.00001398, Avg batch loss: 1.3167, Avg batch acc: 0.1268
Train, Epoch: 1, Batch: 401, Step num: 401, Learning rate: 0.00001401, Avg batch loss: 1.3466, Avg batch acc: 0.1309
Train, Epoch: 1, Batch: 402, Step num: 402, Learning rate: 0.00001405, Avg batch loss: 1.3422, Avg batch acc: 0.1398
Train, Epoch: 1, Batch: 403, Step num: 403, Learning rate: 0.00001408, Avg batch loss: 1.3181, Avg batch acc: 0.1325
Train, Epoch: 1, Batch: 404, Step num: 404, Learning rate: 0.00001412, Avg batch loss: 1.2841, Avg batch acc: 0.1377
Train, Epoch: 1, Batch: 405, Step num: 405, Learning rate: 0.00001415, Avg batch loss: 1.4143, Avg batch acc: 0.1270
Train, Epoch: 1, Batch: 406, Step num: 406, Learning rate: 0.00001419, Avg batch loss: 1.4662, Avg batch acc: 0.1258
Train, Epoch: 1, Batch: 407, Step num: 407, Learning rate: 0.00001422, Avg batch loss: 1.3544, Avg batch acc: 0.1214
Train, Epoch: 1, Batch: 408, Step num: 408, Learning rate: 0.00001425, Avg batch loss: 1.3621, Avg batch acc: 0.1298
Train, Epoch: 1, Batch: 409, Step num: 409, Learning rate: 0.00001429, Avg batch loss: 1.3065, Avg batch acc: 0.1384
Train, Epoch: 1, Batch: 410, Step num: 410, Learning rate: 0.00001432, Avg batch loss: 1.3450, Avg batch acc: 0.1158
Train, Epoch: 1, Batch: 411, Step num: 411, Learning rate: 0.00001436, Avg batch loss: 1.2122, Avg batch acc: 0.1316
Train, Epoch: 1, Batch: 412, Step num: 412, Learning rate: 0.00001439, Avg batch loss: 1.2538, Avg batch acc: 0.1266
Train, Epoch: 1, Batch: 413, Step num: 413, Learning rate: 0.00001443, Avg batch loss: 1.3251, Avg batch acc: 0.1305
Train, Epoch: 1, Batch: 414, Step num: 414, Learning rate: 0.00001446, Avg batch loss: 1.3071, Avg batch acc: 0.1090
Train, Epoch: 1, Batch: 415, Step num: 415, Learning rate: 0.00001450, Avg batch loss: 1.2682, Avg batch acc: 0.1292
Train, Epoch: 1, Batch: 416, Step num: 416, Learning rate: 0.00001453, Avg batch loss: 1.3411, Avg batch acc: 0.1210
Train, Epoch: 1, Batch: 417, Step num: 417, Learning rate: 0.00001457, Avg batch loss: 1.3045, Avg batch acc: 0.1373
Train, Epoch: 1, Batch: 418, Step num: 418, Learning rate: 0.00001460, Avg batch loss: 1.2928, Avg batch acc: 0.1229
Train, Epoch: 1, Batch: 419, Step num: 419, Learning rate: 0.00001464, Avg batch loss: 1.3732, Avg batch acc: 0.1233
Train, Epoch: 1, Batch: 420, Step num: 420, Learning rate: 0.00001467, Avg batch loss: 1.3164, Avg batch acc: 0.1223
Train, Epoch: 1, Batch: 421, Step num: 421, Learning rate: 0.00001471, Avg batch loss: 1.2087, Avg batch acc: 0.1234
Train, Epoch: 1, Batch: 422, Step num: 422, Learning rate: 0.00001474, Avg batch loss: 1.4269, Avg batch acc: 0.1107
Train, Epoch: 1, Batch: 423, Step num: 423, Learning rate: 0.00001478, Avg batch loss: 1.3347, Avg batch acc: 0.1261
Train, Epoch: 1, Batch: 424, Step num: 424, Learning rate: 0.00001481, Avg batch loss: 1.3596, Avg batch acc: 0.1197
Train, Epoch: 1, Batch: 425, Step num: 425, Learning rate: 0.00001485, Avg batch loss: 1.3329, Avg batch acc: 0.1279
Train, Epoch: 1, Batch: 426, Step num: 426, Learning rate: 0.00001488, Avg batch loss: 1.1840, Avg batch acc: 0.1304
Train, Epoch: 1, Batch: 427, Step num: 427, Learning rate: 0.00001492, Avg batch loss: 1.3771, Avg batch acc: 0.1172
Train, Epoch: 1, Batch: 428, Step num: 428, Learning rate: 0.00001495, Avg batch loss: 1.3271, Avg batch acc: 0.1167
Train, Epoch: 1, Batch: 429, Step num: 429, Learning rate: 0.00001499, Avg batch loss: 1.2288, Avg batch acc: 0.1157
Train, Epoch: 1, Batch: 430, Step num: 430, Learning rate: 0.00001502, Avg batch loss: 1.2545, Avg batch acc: 0.1396
Train, Epoch: 1, Batch: 431, Step num: 431, Learning rate: 0.00001506, Avg batch loss: 1.3024, Avg batch acc: 0.1133
Train, Epoch: 1, Batch: 432, Step num: 432, Learning rate: 0.00001509, Avg batch loss: 1.3431, Avg batch acc: 0.1050
Train, Epoch: 1, Batch: 433, Step num: 433, Learning rate: 0.00001513, Avg batch loss: 1.2492, Avg batch acc: 0.1295
Train, Epoch: 1, Batch: 434, Step num: 434, Learning rate: 0.00001516, Avg batch loss: 1.3240, Avg batch acc: 0.1208
Train, Epoch: 1, Batch: 435, Step num: 435, Learning rate: 0.00001520, Avg batch loss: 1.2888, Avg batch acc: 0.1158
Train, Epoch: 1, Batch: 436, Step num: 436, Learning rate: 0.00001523, Avg batch loss: 1.2430, Avg batch acc: 0.1272
Train, Epoch: 1, Batch: 437, Step num: 437, Learning rate: 0.00001527, Avg batch loss: 1.3639, Avg batch acc: 0.1129
Train, Epoch: 1, Batch: 438, Step num: 438, Learning rate: 0.00001530, Avg batch loss: 1.2199, Avg batch acc: 0.1334
Train, Epoch: 1, Batch: 439, Step num: 439, Learning rate: 0.00001534, Avg batch loss: 1.3369, Avg batch acc: 0.1189
Train, Epoch: 1, Batch: 440, Step num: 440, Learning rate: 0.00001537, Avg batch loss: 1.3771, Avg batch acc: 0.1161
Train, Epoch: 1, Batch: 441, Step num: 441, Learning rate: 0.00001541, Avg batch loss: 1.1582, Avg batch acc: 0.1216
Train, Epoch: 1, Batch: 442, Step num: 442, Learning rate: 0.00001544, Avg batch loss: 1.2657, Avg batch acc: 0.1144
Train, Epoch: 1, Batch: 443, Step num: 443, Learning rate: 0.00001548, Avg batch loss: 1.2981, Avg batch acc: 0.1206
Train, Epoch: 1, Batch: 444, Step num: 444, Learning rate: 0.00001551, Avg batch loss: 1.3630, Avg batch acc: 0.1100
Train, Epoch: 1, Batch: 445, Step num: 445, Learning rate: 0.00001555, Avg batch loss: 1.3952, Avg batch acc: 0.1319
Train, Epoch: 1, Batch: 446, Step num: 446, Learning rate: 0.00001558, Avg batch loss: 1.2179, Avg batch acc: 0.1312
Train, Epoch: 1, Batch: 447, Step num: 447, Learning rate: 0.00001562, Avg batch loss: 1.2825, Avg batch acc: 0.1278
Train, Epoch: 1, Batch: 448, Step num: 448, Learning rate: 0.00001565, Avg batch loss: 1.2943, Avg batch acc: 0.1246
Train, Epoch: 1, Batch: 449, Step num: 449, Learning rate: 0.00001569, Avg batch loss: 1.2174, Avg batch acc: 0.1266
Train, Epoch: 1, Batch: 450, Step num: 450, Learning rate: 0.00001572, Avg batch loss: 1.2443, Avg batch acc: 0.1231
Train, Epoch: 1, Batch: 451, Step num: 451, Learning rate: 0.00001576, Avg batch loss: 1.2940, Avg batch acc: 0.1129
Train, Epoch: 1, Batch: 452, Step num: 452, Learning rate: 0.00001579, Avg batch loss: 1.1910, Avg batch acc: 0.1276
Train, Epoch: 1, Batch: 453, Step num: 453, Learning rate: 0.00001583, Avg batch loss: 1.3478, Avg batch acc: 0.1136
Train, Epoch: 1, Batch: 454, Step num: 454, Learning rate: 0.00001586, Avg batch loss: 1.2084, Avg batch acc: 0.1305
Train, Epoch: 1, Batch: 455, Step num: 455, Learning rate: 0.00001590, Avg batch loss: 1.2274, Avg batch acc: 0.1270
Train, Epoch: 1, Batch: 456, Step num: 456, Learning rate: 0.00001593, Avg batch loss: 1.2550, Avg batch acc: 0.1138
Train, Epoch: 1, Batch: 457, Step num: 457, Learning rate: 0.00001597, Avg batch loss: 1.2820, Avg batch acc: 0.1232
Train, Epoch: 1, Batch: 458, Step num: 458, Learning rate: 0.00001600, Avg batch loss: 1.2502, Avg batch acc: 0.1203
Train, Epoch: 1, Batch: 459, Step num: 459, Learning rate: 0.00001604, Avg batch loss: 1.3082, Avg batch acc: 0.1122
Train, Epoch: 1, Batch: 460, Step num: 460, Learning rate: 0.00001607, Avg batch loss: 1.2435, Avg batch acc: 0.1113
Train, Epoch: 1, Batch: 461, Step num: 461, Learning rate: 0.00001611, Avg batch loss: 1.1787, Avg batch acc: 0.1242
Train, Epoch: 1, Batch: 462, Step num: 462, Learning rate: 0.00001614, Avg batch loss: 1.1759, Avg batch acc: 0.1185
Train, Epoch: 1, Batch: 463, Step num: 463, Learning rate: 0.00001618, Avg batch loss: 1.2850, Avg batch acc: 0.1077
Train, Epoch: 1, Batch: 464, Step num: 464, Learning rate: 0.00001621, Avg batch loss: 1.2403, Avg batch acc: 0.1182
Train, Epoch: 1, Batch: 465, Step num: 465, Learning rate: 0.00001625, Avg batch loss: 1.2086, Avg batch acc: 0.1191
Train, Epoch: 1, Batch: 466, Step num: 466, Learning rate: 0.00001628, Avg batch loss: 1.2394, Avg batch acc: 0.1206
Train, Epoch: 1, Batch: 467, Step num: 467, Learning rate: 0.00001632, Avg batch loss: 1.2085, Avg batch acc: 0.1279
Train, Epoch: 1, Batch: 468, Step num: 468, Learning rate: 0.00001635, Avg batch loss: 1.2361, Avg batch acc: 0.1201
Train, Epoch: 1, Batch: 469, Step num: 469, Learning rate: 0.00001639, Avg batch loss: 1.3034, Avg batch acc: 0.1289
Train, Epoch: 1, Batch: 470, Step num: 470, Learning rate: 0.00001642, Avg batch loss: 1.3237, Avg batch acc: 0.1118
Train, Epoch: 1, Batch: 471, Step num: 471, Learning rate: 0.00001646, Avg batch loss: 1.2935, Avg batch acc: 0.1231
Train, Epoch: 1, Batch: 472, Step num: 472, Learning rate: 0.00001649, Avg batch loss: 1.2847, Avg batch acc: 0.1253
Train, Epoch: 1, Batch: 473, Step num: 473, Learning rate: 0.00001653, Avg batch loss: 1.2574, Avg batch acc: 0.1232
Train, Epoch: 1, Batch: 474, Step num: 474, Learning rate: 0.00001656, Avg batch loss: 1.2131, Avg batch acc: 0.1324
Train, Epoch: 1, Batch: 475, Step num: 475, Learning rate: 0.00001660, Avg batch loss: 1.1544, Avg batch acc: 0.1295
Train, Epoch: 1, Batch: 476, Step num: 476, Learning rate: 0.00001663, Avg batch loss: 1.2345, Avg batch acc: 0.1247
Train, Epoch: 1, Batch: 477, Step num: 477, Learning rate: 0.00001667, Avg batch loss: 1.2220, Avg batch acc: 0.1207
Train, Epoch: 1, Batch: 478, Step num: 478, Learning rate: 0.00001670, Avg batch loss: 1.2762, Avg batch acc: 0.1271
Train, Epoch: 1, Batch: 479, Step num: 479, Learning rate: 0.00001674, Avg batch loss: 1.1451, Avg batch acc: 0.1309
Train, Epoch: 1, Batch: 480, Step num: 480, Learning rate: 0.00001677, Avg batch loss: 1.2688, Avg batch acc: 0.1243
Train, Epoch: 1, Batch: 481, Step num: 481, Learning rate: 0.00001681, Avg batch loss: 1.2990, Avg batch acc: 0.1177
Train, Epoch: 1, Batch: 482, Step num: 482, Learning rate: 0.00001684, Avg batch loss: 1.2437, Avg batch acc: 0.1272
Train, Epoch: 1, Batch: 483, Step num: 483, Learning rate: 0.00001688, Avg batch loss: 1.2123, Avg batch acc: 0.1279
Train, Epoch: 1, Batch: 484, Step num: 484, Learning rate: 0.00001691, Avg batch loss: 1.3554, Avg batch acc: 0.1157
Train, Epoch: 1, Batch: 485, Step num: 485, Learning rate: 0.00001695, Avg batch loss: 1.2308, Avg batch acc: 0.1319
Train, Epoch: 1, Batch: 486, Step num: 486, Learning rate: 0.00001698, Avg batch loss: 1.2545, Avg batch acc: 0.1212
Train, Epoch: 1, Batch: 487, Step num: 487, Learning rate: 0.00001702, Avg batch loss: 1.2226, Avg batch acc: 0.1163
Train, Epoch: 1, Batch: 488, Step num: 488, Learning rate: 0.00001705, Avg batch loss: 1.2187, Avg batch acc: 0.1244
Train, Epoch: 1, Batch: 489, Step num: 489, Learning rate: 0.00001708, Avg batch loss: 1.3340, Avg batch acc: 0.1239
Train, Epoch: 1, Batch: 490, Step num: 490, Learning rate: 0.00001712, Avg batch loss: 1.0878, Avg batch acc: 0.1219
Train, Epoch: 1, Batch: 491, Step num: 491, Learning rate: 0.00001715, Avg batch loss: 1.2489, Avg batch acc: 0.1159
Train, Epoch: 1, Batch: 492, Step num: 492, Learning rate: 0.00001719, Avg batch loss: 1.1435, Avg batch acc: 0.1302
Train, Epoch: 1, Batch: 493, Step num: 493, Learning rate: 0.00001722, Avg batch loss: 1.2077, Avg batch acc: 0.1268
Train, Epoch: 1, Batch: 494, Step num: 494, Learning rate: 0.00001726, Avg batch loss: 1.1499, Avg batch acc: 0.1337
Train, Epoch: 1, Batch: 495, Step num: 495, Learning rate: 0.00001729, Avg batch loss: 1.2707, Avg batch acc: 0.1251
Train, Epoch: 1, Batch: 496, Step num: 496, Learning rate: 0.00001733, Avg batch loss: 1.2624, Avg batch acc: 0.1213
Train, Epoch: 1, Batch: 497, Step num: 497, Learning rate: 0.00001736, Avg batch loss: 1.1903, Avg batch acc: 0.1228
Train, Epoch: 1, Batch: 498, Step num: 498, Learning rate: 0.00001740, Avg batch loss: 1.2698, Avg batch acc: 0.1219
Train, Epoch: 1, Batch: 499, Step num: 499, Learning rate: 0.00001743, Avg batch loss: 1.1799, Avg batch acc: 0.1150
Train, Epoch: 1, Batch: 500, Step num: 500, Learning rate: 0.00001747, Avg batch loss: 1.1761, Avg batch acc: 0.1194
Train, Epoch: 1, Batch: 501, Step num: 501, Learning rate: 0.00001750, Avg batch loss: 1.2047, Avg batch acc: 0.1331
Train, Epoch: 1, Batch: 502, Step num: 502, Learning rate: 0.00001754, Avg batch loss: 1.2858, Avg batch acc: 0.1277
Train, Epoch: 1, Batch: 503, Step num: 503, Learning rate: 0.00001757, Avg batch loss: 1.2106, Avg batch acc: 0.1173
Train, Epoch: 1, Batch: 504, Step num: 504, Learning rate: 0.00001761, Avg batch loss: 1.1785, Avg batch acc: 0.1314
Train, Epoch: 1, Batch: 505, Step num: 505, Learning rate: 0.00001764, Avg batch loss: 1.2239, Avg batch acc: 0.1217
Train, Epoch: 1, Batch: 506, Step num: 506, Learning rate: 0.00001768, Avg batch loss: 1.1795, Avg batch acc: 0.1219
Train, Epoch: 1, Batch: 507, Step num: 507, Learning rate: 0.00001771, Avg batch loss: 1.2592, Avg batch acc: 0.1245
Train, Epoch: 1, Batch: 508, Step num: 508, Learning rate: 0.00001775, Avg batch loss: 1.2118, Avg batch acc: 0.1180
Train, Epoch: 1, Batch: 509, Step num: 509, Learning rate: 0.00001778, Avg batch loss: 1.1843, Avg batch acc: 0.1290
Train, Epoch: 1, Batch: 510, Step num: 510, Learning rate: 0.00001782, Avg batch loss: 1.2567, Avg batch acc: 0.1167
Train, Epoch: 1, Batch: 511, Step num: 511, Learning rate: 0.00001785, Avg batch loss: 1.0772, Avg batch acc: 0.1182
Train, Epoch: 1, Batch: 512, Step num: 512, Learning rate: 0.00001789, Avg batch loss: 1.2144, Avg batch acc: 0.1212
Train, Epoch: 1, Batch: 513, Step num: 513, Learning rate: 0.00001792, Avg batch loss: 1.2193, Avg batch acc: 0.1184
Train, Epoch: 1, Batch: 514, Step num: 514, Learning rate: 0.00001796, Avg batch loss: 1.2110, Avg batch acc: 0.1181
Train, Epoch: 1, Batch: 515, Step num: 515, Learning rate: 0.00001799, Avg batch loss: 1.2091, Avg batch acc: 0.1117
Train, Epoch: 1, Batch: 516, Step num: 516, Learning rate: 0.00001803, Avg batch loss: 1.2334, Avg batch acc: 0.1188
Train, Epoch: 1, Batch: 517, Step num: 517, Learning rate: 0.00001806, Avg batch loss: 1.2693, Avg batch acc: 0.1238
Train, Epoch: 1, Batch: 518, Step num: 518, Learning rate: 0.00001810, Avg batch loss: 1.0804, Avg batch acc: 0.1138
Train, Epoch: 1, Batch: 519, Step num: 519, Learning rate: 0.00001813, Avg batch loss: 1.2303, Avg batch acc: 0.1227
Train, Epoch: 1, Batch: 520, Step num: 520, Learning rate: 0.00001817, Avg batch loss: 1.1525, Avg batch acc: 0.1214
Train, Epoch: 1, Batch: 521, Step num: 521, Learning rate: 0.00001820, Avg batch loss: 1.1351, Avg batch acc: 0.1189
Train, Epoch: 1, Batch: 522, Step num: 522, Learning rate: 0.00001824, Avg batch loss: 1.1795, Avg batch acc: 0.1327
Train, Epoch: 1, Batch: 523, Step num: 523, Learning rate: 0.00001827, Avg batch loss: 1.1498, Avg batch acc: 0.1377
Train, Epoch: 1, Batch: 524, Step num: 524, Learning rate: 0.00001831, Avg batch loss: 1.2013, Avg batch acc: 0.1245
Train, Epoch: 1, Batch: 525, Step num: 525, Learning rate: 0.00001834, Avg batch loss: 1.2233, Avg batch acc: 0.1277
Train, Epoch: 1, Batch: 526, Step num: 526, Learning rate: 0.00001838, Avg batch loss: 1.1765, Avg batch acc: 0.1234
Train, Epoch: 1, Batch: 527, Step num: 527, Learning rate: 0.00001841, Avg batch loss: 1.2230, Avg batch acc: 0.1150
Train, Epoch: 1, Batch: 528, Step num: 528, Learning rate: 0.00001845, Avg batch loss: 1.1525, Avg batch acc: 0.1228
Train, Epoch: 1, Batch: 529, Step num: 529, Learning rate: 0.00001848, Avg batch loss: 1.2109, Avg batch acc: 0.1179
Train, Epoch: 1, Batch: 530, Step num: 530, Learning rate: 0.00001852, Avg batch loss: 1.1930, Avg batch acc: 0.1206
Train, Epoch: 1, Batch: 531, Step num: 531, Learning rate: 0.00001855, Avg batch loss: 1.2460, Avg batch acc: 0.1098
Train, Epoch: 1, Batch: 532, Step num: 532, Learning rate: 0.00001859, Avg batch loss: 1.2626, Avg batch acc: 0.1178
Train, Epoch: 1, Batch: 533, Step num: 533, Learning rate: 0.00001862, Avg batch loss: 1.1299, Avg batch acc: 0.1193
Train, Epoch: 1, Batch: 534, Step num: 534, Learning rate: 0.00001866, Avg batch loss: 1.2180, Avg batch acc: 0.1344
Train, Epoch: 1, Batch: 535, Step num: 535, Learning rate: 0.00001869, Avg batch loss: 1.1344, Avg batch acc: 0.1279
Train, Epoch: 1, Batch: 536, Step num: 536, Learning rate: 0.00001873, Avg batch loss: 1.1453, Avg batch acc: 0.1347
Train, Epoch: 1, Batch: 537, Step num: 537, Learning rate: 0.00001876, Avg batch loss: 1.1958, Avg batch acc: 0.1218
Train, Epoch: 1, Batch: 538, Step num: 538, Learning rate: 0.00001880, Avg batch loss: 1.2069, Avg batch acc: 0.1235
Train, Epoch: 1, Batch: 539, Step num: 539, Learning rate: 0.00001883, Avg batch loss: 1.1799, Avg batch acc: 0.1217
Train, Epoch: 1, Batch: 540, Step num: 540, Learning rate: 0.00001887, Avg batch loss: 1.1396, Avg batch acc: 0.1372
Train, Epoch: 1, Batch: 541, Step num: 541, Learning rate: 0.00001890, Avg batch loss: 1.1570, Avg batch acc: 0.1346
Train, Epoch: 1, Batch: 542, Step num: 542, Learning rate: 0.00001894, Avg batch loss: 1.1257, Avg batch acc: 0.1322
Train, Epoch: 1, Batch: 543, Step num: 543, Learning rate: 0.00001897, Avg batch loss: 1.1866, Avg batch acc: 0.1272
Train, Epoch: 1, Batch: 544, Step num: 544, Learning rate: 0.00001901, Avg batch loss: 1.1072, Avg batch acc: 0.1241
Train, Epoch: 1, Batch: 545, Step num: 545, Learning rate: 0.00001904, Avg batch loss: 1.2603, Avg batch acc: 0.1200
Train, Epoch: 1, Batch: 546, Step num: 546, Learning rate: 0.00001908, Avg batch loss: 1.1246, Avg batch acc: 0.1384
Train, Epoch: 1, Batch: 547, Step num: 547, Learning rate: 0.00001911, Avg batch loss: 1.1537, Avg batch acc: 0.1212
Train, Epoch: 1, Batch: 548, Step num: 548, Learning rate: 0.00001915, Avg batch loss: 1.0850, Avg batch acc: 0.1293
Train, Epoch: 1, Batch: 549, Step num: 549, Learning rate: 0.00001918, Avg batch loss: 1.2540, Avg batch acc: 0.1204
Train, Epoch: 1, Batch: 550, Step num: 550, Learning rate: 0.00001922, Avg batch loss: 1.2133, Avg batch acc: 0.1298
Train, Epoch: 1, Batch: 551, Step num: 551, Learning rate: 0.00001925, Avg batch loss: 1.1002, Avg batch acc: 0.1250
Train, Epoch: 1, Batch: 552, Step num: 552, Learning rate: 0.00001929, Avg batch loss: 1.1376, Avg batch acc: 0.1254
Train, Epoch: 1, Batch: 553, Step num: 553, Learning rate: 0.00001932, Avg batch loss: 1.1575, Avg batch acc: 0.1236
Train, Epoch: 1, Batch: 554, Step num: 554, Learning rate: 0.00001936, Avg batch loss: 1.1445, Avg batch acc: 0.1245
Train, Epoch: 1, Batch: 555, Step num: 555, Learning rate: 0.00001939, Avg batch loss: 1.1020, Avg batch acc: 0.1208
Train, Epoch: 1, Batch: 556, Step num: 556, Learning rate: 0.00001943, Avg batch loss: 1.1075, Avg batch acc: 0.1176
Train, Epoch: 1, Batch: 557, Step num: 557, Learning rate: 0.00001946, Avg batch loss: 1.1893, Avg batch acc: 0.1232
Train, Epoch: 1, Batch: 558, Step num: 558, Learning rate: 0.00001950, Avg batch loss: 1.2771, Avg batch acc: 0.1231
Train, Epoch: 1, Batch: 559, Step num: 559, Learning rate: 0.00001953, Avg batch loss: 1.2327, Avg batch acc: 0.1196
Train, Epoch: 1, Batch: 560, Step num: 560, Learning rate: 0.00001957, Avg batch loss: 1.1595, Avg batch acc: 0.1241
Train, Epoch: 1, Batch: 561, Step num: 561, Learning rate: 0.00001960, Avg batch loss: 1.1984, Avg batch acc: 0.1259
Train, Epoch: 1, Batch: 562, Step num: 562, Learning rate: 0.00001964, Avg batch loss: 1.1538, Avg batch acc: 0.1302
Train, Epoch: 1, Batch: 563, Step num: 563, Learning rate: 0.00001967, Avg batch loss: 1.2647, Avg batch acc: 0.1266
Train, Epoch: 1, Batch: 564, Step num: 564, Learning rate: 0.00001971, Avg batch loss: 1.2284, Avg batch acc: 0.1169
Train, Epoch: 1, Batch: 565, Step num: 565, Learning rate: 0.00001974, Avg batch loss: 1.1117, Avg batch acc: 0.1180
Train, Epoch: 1, Batch: 566, Step num: 566, Learning rate: 0.00001978, Avg batch loss: 1.0876, Avg batch acc: 0.1359
Train, Epoch: 1, Batch: 567, Step num: 567, Learning rate: 0.00001981, Avg batch loss: 1.1279, Avg batch acc: 0.1287
Train, Epoch: 1, Batch: 568, Step num: 568, Learning rate: 0.00001985, Avg batch loss: 1.1539, Avg batch acc: 0.1245
Train, Epoch: 1, Batch: 569, Step num: 569, Learning rate: 0.00001988, Avg batch loss: 1.2504, Avg batch acc: 0.1097
Train, Epoch: 1, Batch: 570, Step num: 570, Learning rate: 0.00001991, Avg batch loss: 1.1467, Avg batch acc: 0.1307
Train, Epoch: 1, Batch: 571, Step num: 571, Learning rate: 0.00001995, Avg batch loss: 1.1083, Avg batch acc: 0.1299
Train, Epoch: 1, Batch: 572, Step num: 572, Learning rate: 0.00001998, Avg batch loss: 1.1273, Avg batch acc: 0.1331
Train, Epoch: 1, Batch: 573, Step num: 573, Learning rate: 0.00002002, Avg batch loss: 1.1750, Avg batch acc: 0.1250
Train, Epoch: 1, Batch: 574, Step num: 574, Learning rate: 0.00002005, Avg batch loss: 1.2184, Avg batch acc: 0.1141
Train, Epoch: 1, Batch: 575, Step num: 575, Learning rate: 0.00002009, Avg batch loss: 1.0796, Avg batch acc: 0.1289
Train, Epoch: 1, Batch: 576, Step num: 576, Learning rate: 0.00002012, Avg batch loss: 1.1561, Avg batch acc: 0.1278
Train, Epoch: 1, Batch: 577, Step num: 577, Learning rate: 0.00002016, Avg batch loss: 1.1163, Avg batch acc: 0.1239
Train, Epoch: 1, Batch: 578, Step num: 578, Learning rate: 0.00002019, Avg batch loss: 1.0181, Avg batch acc: 0.1327
Train, Epoch: 1, Batch: 579, Step num: 579, Learning rate: 0.00002023, Avg batch loss: 1.1674, Avg batch acc: 0.1303
Train, Epoch: 1, Batch: 580, Step num: 580, Learning rate: 0.00002026, Avg batch loss: 1.0897, Avg batch acc: 0.1410
Train, Epoch: 1, Batch: 581, Step num: 581, Learning rate: 0.00002030, Avg batch loss: 1.1296, Avg batch acc: 0.1301
Train, Epoch: 1, Batch: 582, Step num: 582, Learning rate: 0.00002033, Avg batch loss: 1.1556, Avg batch acc: 0.1377
Train, Epoch: 1, Batch: 583, Step num: 583, Learning rate: 0.00002037, Avg batch loss: 1.2083, Avg batch acc: 0.1297
Train, Epoch: 1, Batch: 584, Step num: 584, Learning rate: 0.00002040, Avg batch loss: 1.1383, Avg batch acc: 0.1252
Train, Epoch: 1, Batch: 585, Step num: 585, Learning rate: 0.00002044, Avg batch loss: 1.1794, Avg batch acc: 0.1302
Train, Epoch: 1, Batch: 586, Step num: 586, Learning rate: 0.00002047, Avg batch loss: 1.0403, Avg batch acc: 0.1299
Train, Epoch: 1, Batch: 587, Step num: 587, Learning rate: 0.00002051, Avg batch loss: 1.1502, Avg batch acc: 0.1292
Train, Epoch: 1, Batch: 588, Step num: 588, Learning rate: 0.00002054, Avg batch loss: 1.1831, Avg batch acc: 0.1328
Train, Epoch: 1, Batch: 589, Step num: 589, Learning rate: 0.00002058, Avg batch loss: 1.1571, Avg batch acc: 0.1265
Train, Epoch: 1, Batch: 590, Step num: 590, Learning rate: 0.00002061, Avg batch loss: 1.1019, Avg batch acc: 0.1372
Train, Epoch: 1, Batch: 591, Step num: 591, Learning rate: 0.00002065, Avg batch loss: 1.1892, Avg batch acc: 0.1242
Train, Epoch: 1, Batch: 592, Step num: 592, Learning rate: 0.00002068, Avg batch loss: 1.1646, Avg batch acc: 0.1208
Train, Epoch: 1, Batch: 593, Step num: 593, Learning rate: 0.00002072, Avg batch loss: 1.1781, Avg batch acc: 0.1310
Train, Epoch: 1, Batch: 594, Step num: 594, Learning rate: 0.00002075, Avg batch loss: 1.1528, Avg batch acc: 0.1262
Train, Epoch: 1, Batch: 595, Step num: 595, Learning rate: 0.00002079, Avg batch loss: 1.1665, Avg batch acc: 0.1227
Train, Epoch: 1, Batch: 596, Step num: 596, Learning rate: 0.00002082, Avg batch loss: 1.0985, Avg batch acc: 0.1328
Train, Epoch: 1, Batch: 597, Step num: 597, Learning rate: 0.00002086, Avg batch loss: 1.0707, Avg batch acc: 0.1313
Train, Epoch: 1, Batch: 598, Step num: 598, Learning rate: 0.00002089, Avg batch loss: 1.1143, Avg batch acc: 0.1242
Train, Epoch: 1, Batch: 599, Step num: 599, Learning rate: 0.00002093, Avg batch loss: 1.0336, Avg batch acc: 0.1329
Train, Epoch: 1, Batch: 600, Step num: 600, Learning rate: 0.00002096, Avg batch loss: 1.1299, Avg batch acc: 0.1292
Train, Epoch: 1, Batch: 601, Step num: 601, Learning rate: 0.00002100, Avg batch loss: 1.1686, Avg batch acc: 0.1358
Train, Epoch: 1, Batch: 602, Step num: 602, Learning rate: 0.00002103, Avg batch loss: 1.1534, Avg batch acc: 0.1298
Train, Epoch: 1, Batch: 603, Step num: 603, Learning rate: 0.00002107, Avg batch loss: 1.1349, Avg batch acc: 0.1257
Train, Epoch: 1, Batch: 604, Step num: 604, Learning rate: 0.00002110, Avg batch loss: 1.1174, Avg batch acc: 0.1457
Train, Epoch: 1, Batch: 605, Step num: 605, Learning rate: 0.00002114, Avg batch loss: 1.1883, Avg batch acc: 0.1280
Train, Epoch: 1, Batch: 606, Step num: 606, Learning rate: 0.00002117, Avg batch loss: 1.2295, Avg batch acc: 0.1264
Train, Epoch: 1, Batch: 607, Step num: 607, Learning rate: 0.00002121, Avg batch loss: 1.1281, Avg batch acc: 0.1328
Train, Epoch: 1, Batch: 608, Step num: 608, Learning rate: 0.00002124, Avg batch loss: 1.0395, Avg batch acc: 0.1380
Train, Epoch: 1, Batch: 609, Step num: 609, Learning rate: 0.00002128, Avg batch loss: 1.2054, Avg batch acc: 0.1224
Train, Epoch: 1, Batch: 610, Step num: 610, Learning rate: 0.00002131, Avg batch loss: 1.1825, Avg batch acc: 0.1281
Train, Epoch: 1, Batch: 611, Step num: 611, Learning rate: 0.00002135, Avg batch loss: 1.1480, Avg batch acc: 0.1296
Train, Epoch: 1, Batch: 612, Step num: 612, Learning rate: 0.00002138, Avg batch loss: 1.0857, Avg batch acc: 0.1300
Train, Epoch: 1, Batch: 613, Step num: 613, Learning rate: 0.00002142, Avg batch loss: 1.1007, Avg batch acc: 0.1289
Train, Epoch: 1, Batch: 614, Step num: 614, Learning rate: 0.00002145, Avg batch loss: 1.1343, Avg batch acc: 0.1297
Train, Epoch: 1, Batch: 615, Step num: 615, Learning rate: 0.00002149, Avg batch loss: 1.0238, Avg batch acc: 0.1412
Train, Epoch: 1, Batch: 616, Step num: 616, Learning rate: 0.00002152, Avg batch loss: 1.0709, Avg batch acc: 0.1243
Train, Epoch: 1, Batch: 617, Step num: 617, Learning rate: 0.00002156, Avg batch loss: 1.1673, Avg batch acc: 0.1223
Train, Epoch: 1, Batch: 618, Step num: 618, Learning rate: 0.00002159, Avg batch loss: 1.0521, Avg batch acc: 0.1385
Train, Epoch: 1, Batch: 619, Step num: 619, Learning rate: 0.00002163, Avg batch loss: 1.1947, Avg batch acc: 0.1257
Train, Epoch: 1, Batch: 620, Step num: 620, Learning rate: 0.00002166, Avg batch loss: 1.0878, Avg batch acc: 0.1271
Train, Epoch: 1, Batch: 621, Step num: 621, Learning rate: 0.00002170, Avg batch loss: 1.0948, Avg batch acc: 0.1279
Train, Epoch: 1, Batch: 622, Step num: 622, Learning rate: 0.00002173, Avg batch loss: 1.0537, Avg batch acc: 0.1355
Train, Epoch: 1, Batch: 623, Step num: 623, Learning rate: 0.00002177, Avg batch loss: 0.9995, Avg batch acc: 0.1373
Train, Epoch: 1, Batch: 624, Step num: 624, Learning rate: 0.00002180, Avg batch loss: 1.0946, Avg batch acc: 0.1254
Train, Epoch: 1, Batch: 625, Step num: 625, Learning rate: 0.00002184, Avg batch loss: 1.0999, Avg batch acc: 0.1302
Train, Epoch: 1, Batch: 626, Step num: 626, Learning rate: 0.00002187, Avg batch loss: 1.1072, Avg batch acc: 0.1245
Train, Epoch: 1, Batch: 627, Step num: 627, Learning rate: 0.00002191, Avg batch loss: 1.2029, Avg batch acc: 0.1223
Train, Epoch: 1, Batch: 628, Step num: 628, Learning rate: 0.00002194, Avg batch loss: 1.0538, Avg batch acc: 0.1427
Train, Epoch: 1, Batch: 629, Step num: 629, Learning rate: 0.00002198, Avg batch loss: 1.1086, Avg batch acc: 0.1323
Train, Epoch: 1, Batch: 630, Step num: 630, Learning rate: 0.00002201, Avg batch loss: 1.0799, Avg batch acc: 0.1284
Train, Epoch: 1, Batch: 631, Step num: 631, Learning rate: 0.00002205, Avg batch loss: 1.1136, Avg batch acc: 0.1327
Train, Epoch: 1, Batch: 632, Step num: 632, Learning rate: 0.00002208, Avg batch loss: 1.0699, Avg batch acc: 0.1386
Train, Epoch: 1, Batch: 633, Step num: 633, Learning rate: 0.00002212, Avg batch loss: 1.0092, Avg batch acc: 0.1421
Train, Epoch: 1, Batch: 634, Step num: 634, Learning rate: 0.00002215, Avg batch loss: 1.1603, Avg batch acc: 0.1331
Train, Epoch: 1, Batch: 635, Step num: 635, Learning rate: 0.00002219, Avg batch loss: 1.0453, Avg batch acc: 0.1327
Train, Epoch: 1, Batch: 636, Step num: 636, Learning rate: 0.00002222, Avg batch loss: 1.0485, Avg batch acc: 0.1371
Train, Epoch: 1, Batch: 637, Step num: 637, Learning rate: 0.00002226, Avg batch loss: 1.1070, Avg batch acc: 0.1354
Train, Epoch: 1, Batch: 638, Step num: 638, Learning rate: 0.00002229, Avg batch loss: 1.1354, Avg batch acc: 0.1285
Train, Epoch: 1, Batch: 639, Step num: 639, Learning rate: 0.00002233, Avg batch loss: 1.1166, Avg batch acc: 0.1389
Train, Epoch: 1, Batch: 640, Step num: 640, Learning rate: 0.00002236, Avg batch loss: 0.9919, Avg batch acc: 0.1443
Train, Epoch: 1, Batch: 641, Step num: 641, Learning rate: 0.00002240, Avg batch loss: 1.0752, Avg batch acc: 0.1357
Train, Epoch: 1, Batch: 642, Step num: 642, Learning rate: 0.00002243, Avg batch loss: 1.1783, Avg batch acc: 0.1324
Train, Epoch: 1, Batch: 643, Step num: 643, Learning rate: 0.00002247, Avg batch loss: 1.1574, Avg batch acc: 0.1282
Train, Epoch: 1, Batch: 644, Step num: 644, Learning rate: 0.00002250, Avg batch loss: 1.1388, Avg batch acc: 0.1354
Train, Epoch: 1, Batch: 645, Step num: 645, Learning rate: 0.00002254, Avg batch loss: 1.1516, Avg batch acc: 0.1286
Train, Epoch: 1, Batch: 646, Step num: 646, Learning rate: 0.00002257, Avg batch loss: 1.0928, Avg batch acc: 0.1291
Train, Epoch: 1, Batch: 647, Step num: 647, Learning rate: 0.00002261, Avg batch loss: 1.0862, Avg batch acc: 0.1360
Train, Epoch: 1, Batch: 648, Step num: 648, Learning rate: 0.00002264, Avg batch loss: 1.0979, Avg batch acc: 0.1522
Train, Epoch: 1, Batch: 649, Step num: 649, Learning rate: 0.00002268, Avg batch loss: 1.1359, Avg batch acc: 0.1281
Train, Epoch: 1, Batch: 650, Step num: 650, Learning rate: 0.00002271, Avg batch loss: 1.1329, Avg batch acc: 0.1350
Train, Epoch: 1, Batch: 651, Step num: 651, Learning rate: 0.00002275, Avg batch loss: 1.1163, Avg batch acc: 0.1436
Train, Epoch: 1, Batch: 652, Step num: 652, Learning rate: 0.00002278, Avg batch loss: 1.1125, Avg batch acc: 0.1301
Train, Epoch: 1, Batch: 653, Step num: 653, Learning rate: 0.00002281, Avg batch loss: 1.1106, Avg batch acc: 0.1435
Train, Epoch: 1, Batch: 654, Step num: 654, Learning rate: 0.00002285, Avg batch loss: 1.0471, Avg batch acc: 0.1427
Train, Epoch: 1, Batch: 655, Step num: 655, Learning rate: 0.00002288, Avg batch loss: 1.1023, Avg batch acc: 0.1412
Train, Epoch: 1, Batch: 656, Step num: 656, Learning rate: 0.00002292, Avg batch loss: 1.1122, Avg batch acc: 0.1389
Train, Epoch: 1, Batch: 657, Step num: 657, Learning rate: 0.00002295, Avg batch loss: 0.9780, Avg batch acc: 0.1480
Train, Epoch: 1, Batch: 658, Step num: 658, Learning rate: 0.00002299, Avg batch loss: 1.1406, Avg batch acc: 0.1384
Train, Epoch: 1, Batch: 659, Step num: 659, Learning rate: 0.00002302, Avg batch loss: 1.0297, Avg batch acc: 0.1461
Train, Epoch: 1, Batch: 660, Step num: 660, Learning rate: 0.00002306, Avg batch loss: 1.1357, Avg batch acc: 0.1303
Train, Epoch: 1, Batch: 661, Step num: 661, Learning rate: 0.00002309, Avg batch loss: 1.0594, Avg batch acc: 0.1406
Train, Epoch: 1, Batch: 662, Step num: 662, Learning rate: 0.00002313, Avg batch loss: 1.1501, Avg batch acc: 0.1438
Train, Epoch: 1, Batch: 663, Step num: 663, Learning rate: 0.00002316, Avg batch loss: 1.0822, Avg batch acc: 0.1454
Train, Epoch: 1, Batch: 664, Step num: 664, Learning rate: 0.00002320, Avg batch loss: 1.1262, Avg batch acc: 0.1449
Train, Epoch: 1, Batch: 665, Step num: 665, Learning rate: 0.00002323, Avg batch loss: 1.1086, Avg batch acc: 0.1497
Train, Epoch: 1, Batch: 666, Step num: 666, Learning rate: 0.00002327, Avg batch loss: 1.1849, Avg batch acc: 0.1404
Train, Epoch: 1, Batch: 667, Step num: 667, Learning rate: 0.00002330, Avg batch loss: 1.1393, Avg batch acc: 0.1433
Train, Epoch: 1, Batch: 668, Step num: 668, Learning rate: 0.00002334, Avg batch loss: 1.1010, Avg batch acc: 0.1435
Train, Epoch: 1, Batch: 669, Step num: 669, Learning rate: 0.00002337, Avg batch loss: 1.2034, Avg batch acc: 0.1372
Train, Epoch: 1, Batch: 670, Step num: 670, Learning rate: 0.00002341, Avg batch loss: 1.1306, Avg batch acc: 0.1432
Train, Epoch: 1, Batch: 671, Step num: 671, Learning rate: 0.00002344, Avg batch loss: 1.0659, Avg batch acc: 0.1403
Train, Epoch: 1, Batch: 672, Step num: 672, Learning rate: 0.00002348, Avg batch loss: 1.0744, Avg batch acc: 0.1393
Train, Epoch: 1, Batch: 673, Step num: 673, Learning rate: 0.00002351, Avg batch loss: 1.2473, Avg batch acc: 0.1265
Train, Epoch: 1, Batch: 674, Step num: 674, Learning rate: 0.00002355, Avg batch loss: 1.0024, Avg batch acc: 0.1463
Train, Epoch: 1, Batch: 675, Step num: 675, Learning rate: 0.00002358, Avg batch loss: 1.0613, Avg batch acc: 0.1449
Train, Epoch: 1, Batch: 676, Step num: 676, Learning rate: 0.00002362, Avg batch loss: 1.0052, Avg batch acc: 0.1493
Train, Epoch: 1, Batch: 677, Step num: 677, Learning rate: 0.00002365, Avg batch loss: 1.0912, Avg batch acc: 0.1433
Train, Epoch: 1, Batch: 678, Step num: 678, Learning rate: 0.00002369, Avg batch loss: 1.1803, Avg batch acc: 0.1410
Train, Epoch: 1, Batch: 679, Step num: 679, Learning rate: 0.00002372, Avg batch loss: 1.0758, Avg batch acc: 0.1406
Train, Epoch: 1, Batch: 680, Step num: 680, Learning rate: 0.00002376, Avg batch loss: 1.0736, Avg batch acc: 0.1520
Train, Epoch: 1, Batch: 681, Step num: 681, Learning rate: 0.00002379, Avg batch loss: 1.0388, Avg batch acc: 0.1499
Train, Epoch: 1, Batch: 682, Step num: 682, Learning rate: 0.00002383, Avg batch loss: 1.0472, Avg batch acc: 0.1443
Train, Epoch: 1, Batch: 683, Step num: 683, Learning rate: 0.00002386, Avg batch loss: 1.0471, Avg batch acc: 0.1481
Train, Epoch: 1, Batch: 684, Step num: 684, Learning rate: 0.00002390, Avg batch loss: 1.0813, Avg batch acc: 0.1463
Train, Epoch: 1, Batch: 685, Step num: 685, Learning rate: 0.00002393, Avg batch loss: 1.0558, Avg batch acc: 0.1617
Train, Epoch: 1, Batch: 686, Step num: 686, Learning rate: 0.00002397, Avg batch loss: 1.1296, Avg batch acc: 0.1363
Train, Epoch: 1, Batch: 687, Step num: 687, Learning rate: 0.00002400, Avg batch loss: 0.9560, Avg batch acc: 0.1552
Train, Epoch: 1, Batch: 688, Step num: 688, Learning rate: 0.00002404, Avg batch loss: 1.0567, Avg batch acc: 0.1474
Train, Epoch: 1, Batch: 689, Step num: 689, Learning rate: 0.00002407, Avg batch loss: 1.0047, Avg batch acc: 0.1582
Train, Epoch: 1, Batch: 690, Step num: 690, Learning rate: 0.00002411, Avg batch loss: 1.0731, Avg batch acc: 0.1502
Train, Epoch: 1, Batch: 691, Step num: 691, Learning rate: 0.00002414, Avg batch loss: 1.0782, Avg batch acc: 0.1473
Train, Epoch: 1, Batch: 692, Step num: 692, Learning rate: 0.00002418, Avg batch loss: 1.0162, Avg batch acc: 0.1520
Train, Epoch: 1, Batch: 693, Step num: 693, Learning rate: 0.00002421, Avg batch loss: 1.1099, Avg batch acc: 0.1451
Train, Epoch: 1, Batch: 694, Step num: 694, Learning rate: 0.00002425, Avg batch loss: 1.0742, Avg batch acc: 0.1383
Train, Epoch: 1, Batch: 695, Step num: 695, Learning rate: 0.00002428, Avg batch loss: 1.1214, Avg batch acc: 0.1459
Train, Epoch: 1, Batch: 696, Step num: 696, Learning rate: 0.00002432, Avg batch loss: 1.0579, Avg batch acc: 0.1480
Train, Epoch: 1, Batch: 697, Step num: 697, Learning rate: 0.00002435, Avg batch loss: 1.0347, Avg batch acc: 0.1555
Train, Epoch: 1, Batch: 698, Step num: 698, Learning rate: 0.00002439, Avg batch loss: 1.1586, Avg batch acc: 0.1500
Train, Epoch: 1, Batch: 699, Step num: 699, Learning rate: 0.00002442, Avg batch loss: 0.9983, Avg batch acc: 0.1572
Train, Epoch: 1, Batch: 700, Step num: 700, Learning rate: 0.00002446, Avg batch loss: 1.0133, Avg batch acc: 0.1652
Train, Epoch: 1, Batch: 701, Step num: 701, Learning rate: 0.00002449, Avg batch loss: 1.1215, Avg batch acc: 0.1610
Train, Epoch: 1, Batch: 702, Step num: 702, Learning rate: 0.00002453, Avg batch loss: 1.1124, Avg batch acc: 0.1693
Train, Epoch: 1, Batch: 703, Step num: 703, Learning rate: 0.00002456, Avg batch loss: 1.0518, Avg batch acc: 0.1645
Train, Epoch: 1, Batch: 704, Step num: 704, Learning rate: 0.00002460, Avg batch loss: 1.1301, Avg batch acc: 0.1660
Train, Epoch: 1, Batch: 705, Step num: 705, Learning rate: 0.00002463, Avg batch loss: 0.9683, Avg batch acc: 0.1763
Train, Epoch: 1, Batch: 706, Step num: 706, Learning rate: 0.00002467, Avg batch loss: 0.9768, Avg batch acc: 0.1671
Train, Epoch: 1, Batch: 707, Step num: 707, Learning rate: 0.00002470, Avg batch loss: 1.1848, Avg batch acc: 0.1564
Train, Epoch: 1, Batch: 708, Step num: 708, Learning rate: 0.00002474, Avg batch loss: 1.0853, Avg batch acc: 0.1497
Train, Epoch: 1, Batch: 709, Step num: 709, Learning rate: 0.00002477, Avg batch loss: 1.0311, Avg batch acc: 0.1731
Train, Epoch: 1, Batch: 710, Step num: 710, Learning rate: 0.00002481, Avg batch loss: 0.9873, Avg batch acc: 0.1734
Train, Epoch: 1, Batch: 711, Step num: 711, Learning rate: 0.00002484, Avg batch loss: 1.0707, Avg batch acc: 0.1625
Train, Epoch: 1, Batch: 712, Step num: 712, Learning rate: 0.00002488, Avg batch loss: 1.0203, Avg batch acc: 0.1588
Train, Epoch: 1, Batch: 713, Step num: 713, Learning rate: 0.00002491, Avg batch loss: 1.0486, Avg batch acc: 0.1634
Train, Epoch: 1, Batch: 714, Step num: 714, Learning rate: 0.00002495, Avg batch loss: 0.9638, Avg batch acc: 0.1736
Train, Epoch: 1, Batch: 715, Step num: 715, Learning rate: 0.00002498, Avg batch loss: 1.0203, Avg batch acc: 0.1741
Train, Epoch: 1, Batch: 716, Step num: 716, Learning rate: 0.00002502, Avg batch loss: 0.9446, Avg batch acc: 0.1716
Train, Epoch: 1, Batch: 717, Step num: 717, Learning rate: 0.00002505, Avg batch loss: 1.0316, Avg batch acc: 0.1702
Train, Epoch: 1, Batch: 718, Step num: 718, Learning rate: 0.00002509, Avg batch loss: 0.9827, Avg batch acc: 0.1700
Train, Epoch: 1, Batch: 719, Step num: 719, Learning rate: 0.00002512, Avg batch loss: 1.0794, Avg batch acc: 0.1706
Train, Epoch: 1, Batch: 720, Step num: 720, Learning rate: 0.00002516, Avg batch loss: 1.0553, Avg batch acc: 0.1664
Train, Epoch: 1, Batch: 721, Step num: 721, Learning rate: 0.00002519, Avg batch loss: 0.9890, Avg batch acc: 0.1796
Train, Epoch: 1, Batch: 722, Step num: 722, Learning rate: 0.00002523, Avg batch loss: 1.0469, Avg batch acc: 0.1743
Train, Epoch: 1, Batch: 723, Step num: 723, Learning rate: 0.00002526, Avg batch loss: 1.0326, Avg batch acc: 0.1721
Train, Epoch: 1, Batch: 724, Step num: 724, Learning rate: 0.00002530, Avg batch loss: 1.2378, Avg batch acc: 0.1585
Train, Epoch: 1, Batch: 725, Step num: 725, Learning rate: 0.00002533, Avg batch loss: 1.0574, Avg batch acc: 0.1867
Train, Epoch: 1, Batch: 726, Step num: 726, Learning rate: 0.00002537, Avg batch loss: 0.9725, Avg batch acc: 0.2031
Train, Epoch: 1, Batch: 727, Step num: 727, Learning rate: 0.00002540, Avg batch loss: 1.0899, Avg batch acc: 0.1681
Train, Epoch: 1, Batch: 728, Step num: 728, Learning rate: 0.00002544, Avg batch loss: 1.1110, Avg batch acc: 0.1738
Train, Epoch: 1, Batch: 729, Step num: 729, Learning rate: 0.00002547, Avg batch loss: 1.0033, Avg batch acc: 0.1901
Train, Epoch: 1, Batch: 730, Step num: 730, Learning rate: 0.00002551, Avg batch loss: 1.0590, Avg batch acc: 0.1818
Train, Epoch: 1, Batch: 731, Step num: 731, Learning rate: 0.00002554, Avg batch loss: 0.9651, Avg batch acc: 0.1872
Train, Epoch: 1, Batch: 732, Step num: 732, Learning rate: 0.00002558, Avg batch loss: 1.0172, Avg batch acc: 0.1829
Train, Epoch: 1, Batch: 733, Step num: 733, Learning rate: 0.00002561, Avg batch loss: 1.0442, Avg batch acc: 0.1721
Train, Epoch: 1, Batch: 734, Step num: 734, Learning rate: 0.00002564, Avg batch loss: 1.1276, Avg batch acc: 0.1746
Train, Epoch: 1, Batch: 735, Step num: 735, Learning rate: 0.00002568, Avg batch loss: 1.0477, Avg batch acc: 0.1761
Train, Epoch: 1, Batch: 736, Step num: 736, Learning rate: 0.00002571, Avg batch loss: 1.0221, Avg batch acc: 0.1898
Train, Epoch: 1, Batch: 737, Step num: 737, Learning rate: 0.00002575, Avg batch loss: 1.0331, Avg batch acc: 0.1923
Train, Epoch: 1, Batch: 738, Step num: 738, Learning rate: 0.00002578, Avg batch loss: 1.0710, Avg batch acc: 0.1833
Train, Epoch: 1, Batch: 739, Step num: 739, Learning rate: 0.00002582, Avg batch loss: 1.0672, Avg batch acc: 0.1932
Train, Epoch: 1, Batch: 740, Step num: 740, Learning rate: 0.00002585, Avg batch loss: 1.0265, Avg batch acc: 0.1863
Train, Epoch: 1, Batch: 741, Step num: 741, Learning rate: 0.00002589, Avg batch loss: 1.0970, Avg batch acc: 0.1880
Train, Epoch: 1, Batch: 742, Step num: 742, Learning rate: 0.00002592, Avg batch loss: 1.0467, Avg batch acc: 0.1796
Train, Epoch: 1, Batch: 743, Step num: 743, Learning rate: 0.00002596, Avg batch loss: 1.0916, Avg batch acc: 0.1785
Train, Epoch: 1, Batch: 744, Step num: 744, Learning rate: 0.00002599, Avg batch loss: 1.0037, Avg batch acc: 0.1982
Train, Epoch: 1, Batch: 745, Step num: 745, Learning rate: 0.00002603, Avg batch loss: 1.0616, Avg batch acc: 0.1912
Train, Epoch: 1, Batch: 746, Step num: 746, Learning rate: 0.00002606, Avg batch loss: 1.0305, Avg batch acc: 0.1856
Train, Epoch: 1, Batch: 747, Step num: 747, Learning rate: 0.00002610, Avg batch loss: 0.9690, Avg batch acc: 0.1791
Train, Epoch: 1, Batch: 748, Step num: 748, Learning rate: 0.00002613, Avg batch loss: 1.1015, Avg batch acc: 0.1950
Train, Epoch: 1, Batch: 749, Step num: 749, Learning rate: 0.00002617, Avg batch loss: 1.0157, Avg batch acc: 0.1989
Train, Epoch: 1, Batch: 750, Step num: 750, Learning rate: 0.00002620, Avg batch loss: 1.0827, Avg batch acc: 0.1933
Train, Epoch: 1, Batch: 751, Step num: 751, Learning rate: 0.00002624, Avg batch loss: 0.9675, Avg batch acc: 0.1915
Train, Epoch: 1, Batch: 752, Step num: 752, Learning rate: 0.00002627, Avg batch loss: 1.0569, Avg batch acc: 0.1789
Train, Epoch: 1, Batch: 753, Step num: 753, Learning rate: 0.00002631, Avg batch loss: 0.9842, Avg batch acc: 0.1951
Train, Epoch: 1, Batch: 754, Step num: 754, Learning rate: 0.00002634, Avg batch loss: 1.0874, Avg batch acc: 0.1920
Train, Epoch: 1, Batch: 755, Step num: 755, Learning rate: 0.00002638, Avg batch loss: 1.0095, Avg batch acc: 0.1962
Train, Epoch: 1, Batch: 756, Step num: 756, Learning rate: 0.00002641, Avg batch loss: 0.9861, Avg batch acc: 0.2054
Train, Epoch: 1, Batch: 757, Step num: 757, Learning rate: 0.00002645, Avg batch loss: 1.0870, Avg batch acc: 0.1949
Train, Epoch: 1, Batch: 758, Step num: 758, Learning rate: 0.00002648, Avg batch loss: 0.9462, Avg batch acc: 0.1861
Train, Epoch: 1, Batch: 759, Step num: 759, Learning rate: 0.00002652, Avg batch loss: 0.9859, Avg batch acc: 0.2078
Train, Epoch: 1, Batch: 760, Step num: 760, Learning rate: 0.00002655, Avg batch loss: 1.0184, Avg batch acc: 0.2015
Train, Epoch: 1, Batch: 761, Step num: 761, Learning rate: 0.00002659, Avg batch loss: 1.0717, Avg batch acc: 0.1844
Train, Epoch: 1, Batch: 762, Step num: 762, Learning rate: 0.00002662, Avg batch loss: 0.9787, Avg batch acc: 0.2060
Train, Epoch: 1, Batch: 763, Step num: 763, Learning rate: 0.00002666, Avg batch loss: 0.9725, Avg batch acc: 0.2177
Train, Epoch: 1, Batch: 764, Step num: 764, Learning rate: 0.00002669, Avg batch loss: 1.0178, Avg batch acc: 0.1937
Train, Epoch: 1, Batch: 765, Step num: 765, Learning rate: 0.00002673, Avg batch loss: 0.9722, Avg batch acc: 0.1936
Train, Epoch: 1, Batch: 766, Step num: 766, Learning rate: 0.00002676, Avg batch loss: 1.0273, Avg batch acc: 0.1885
Train, Epoch: 1, Batch: 767, Step num: 767, Learning rate: 0.00002680, Avg batch loss: 0.9744, Avg batch acc: 0.2039
Train, Epoch: 1, Batch: 768, Step num: 768, Learning rate: 0.00002683, Avg batch loss: 1.0515, Avg batch acc: 0.1791
Train, Epoch: 1, Batch: 769, Step num: 769, Learning rate: 0.00002687, Avg batch loss: 0.9898, Avg batch acc: 0.2112
Train, Epoch: 1, Batch: 770, Step num: 770, Learning rate: 0.00002690, Avg batch loss: 1.0370, Avg batch acc: 0.1951
Train, Epoch: 1, Batch: 771, Step num: 771, Learning rate: 0.00002694, Avg batch loss: 0.9801, Avg batch acc: 0.2105
Train, Epoch: 1, Batch: 772, Step num: 772, Learning rate: 0.00002697, Avg batch loss: 0.9703, Avg batch acc: 0.2018
Train, Epoch: 1, Batch: 773, Step num: 773, Learning rate: 0.00002701, Avg batch loss: 1.0527, Avg batch acc: 0.2036
Train, Epoch: 1, Batch: 774, Step num: 774, Learning rate: 0.00002704, Avg batch loss: 1.0468, Avg batch acc: 0.1973
Train, Epoch: 1, Batch: 775, Step num: 775, Learning rate: 0.00002708, Avg batch loss: 1.0047, Avg batch acc: 0.1956
Train, Epoch: 1, Batch: 776, Step num: 776, Learning rate: 0.00002711, Avg batch loss: 0.9871, Avg batch acc: 0.1983
Train, Epoch: 1, Batch: 777, Step num: 777, Learning rate: 0.00002715, Avg batch loss: 1.0593, Avg batch acc: 0.1896
Train, Epoch: 1, Batch: 778, Step num: 778, Learning rate: 0.00002718, Avg batch loss: 0.9706, Avg batch acc: 0.2023
Train, Epoch: 1, Batch: 779, Step num: 779, Learning rate: 0.00002722, Avg batch loss: 1.0694, Avg batch acc: 0.2067
Train, Epoch: 1, Batch: 780, Step num: 780, Learning rate: 0.00002725, Avg batch loss: 0.9558, Avg batch acc: 0.2166
Train, Epoch: 1, Batch: 781, Step num: 781, Learning rate: 0.00002729, Avg batch loss: 1.0503, Avg batch acc: 0.1957
Train, Epoch: 1, Batch: 782, Step num: 782, Learning rate: 0.00002732, Avg batch loss: 1.0325, Avg batch acc: 0.2154
Train, Epoch: 1, Batch: 783, Step num: 783, Learning rate: 0.00002736, Avg batch loss: 1.0316, Avg batch acc: 0.1976
Train, Epoch: 1, Batch: 784, Step num: 784, Learning rate: 0.00002739, Avg batch loss: 1.0367, Avg batch acc: 0.2050
Train, Epoch: 1, Batch: 785, Step num: 785, Learning rate: 0.00002743, Avg batch loss: 0.9637, Avg batch acc: 0.2082
Train, Epoch: 1, Batch: 786, Step num: 786, Learning rate: 0.00002746, Avg batch loss: 1.0493, Avg batch acc: 0.2127
Train, Epoch: 1, Batch: 787, Step num: 787, Learning rate: 0.00002750, Avg batch loss: 1.0168, Avg batch acc: 0.2194
Train, Epoch: 1, Batch: 788, Step num: 788, Learning rate: 0.00002753, Avg batch loss: 0.9988, Avg batch acc: 0.2253
Train, Epoch: 1, Batch: 789, Step num: 789, Learning rate: 0.00002757, Avg batch loss: 1.1568, Avg batch acc: 0.2107
Train, Epoch: 1, Batch: 790, Step num: 790, Learning rate: 0.00002760, Avg batch loss: 1.0847, Avg batch acc: 0.2026
Train, Epoch: 1, Batch: 791, Step num: 791, Learning rate: 0.00002764, Avg batch loss: 0.9381, Avg batch acc: 0.2179
Train, Epoch: 1, Batch: 792, Step num: 792, Learning rate: 0.00002767, Avg batch loss: 1.0807, Avg batch acc: 0.2048
Train, Epoch: 1, Batch: 793, Step num: 793, Learning rate: 0.00002771, Avg batch loss: 1.0072, Avg batch acc: 0.2211
Train, Epoch: 1, Batch: 794, Step num: 794, Learning rate: 0.00002774, Avg batch loss: 1.0036, Avg batch acc: 0.2131
Train, Epoch: 1, Batch: 795, Step num: 795, Learning rate: 0.00002778, Avg batch loss: 1.0381, Avg batch acc: 0.2123
Train, Epoch: 1, Batch: 796, Step num: 796, Learning rate: 0.00002781, Avg batch loss: 1.0713, Avg batch acc: 0.2109
Train, Epoch: 1, Batch: 797, Step num: 797, Learning rate: 0.00002785, Avg batch loss: 1.0016, Avg batch acc: 0.2248
Train, Epoch: 1, Batch: 798, Step num: 798, Learning rate: 0.00002788, Avg batch loss: 0.9473, Avg batch acc: 0.2247
Train, Epoch: 1, Batch: 799, Step num: 799, Learning rate: 0.00002792, Avg batch loss: 1.0587, Avg batch acc: 0.2141
Train, Epoch: 1, Batch: 800, Step num: 800, Learning rate: 0.00002795, Avg batch loss: 0.9289, Avg batch acc: 0.2229
Train, Epoch: 1, Batch: 801, Step num: 801, Learning rate: 0.00002799, Avg batch loss: 0.9830, Avg batch acc: 0.2125
Train, Epoch: 1, Batch: 802, Step num: 802, Learning rate: 0.00002802, Avg batch loss: 1.0049, Avg batch acc: 0.2109
Train, Epoch: 1, Batch: 803, Step num: 803, Learning rate: 0.00002806, Avg batch loss: 1.0342, Avg batch acc: 0.2204
Train, Epoch: 1, Batch: 804, Step num: 804, Learning rate: 0.00002809, Avg batch loss: 1.0318, Avg batch acc: 0.2380
Train, Epoch: 1, Batch: 805, Step num: 805, Learning rate: 0.00002813, Avg batch loss: 1.0256, Avg batch acc: 0.2279
Train, Epoch: 1, Batch: 806, Step num: 806, Learning rate: 0.00002816, Avg batch loss: 0.9687, Avg batch acc: 0.2225
Train, Epoch: 1, Batch: 807, Step num: 807, Learning rate: 0.00002820, Avg batch loss: 1.0238, Avg batch acc: 0.2054
Train, Epoch: 1, Batch: 808, Step num: 808, Learning rate: 0.00002823, Avg batch loss: 0.9757, Avg batch acc: 0.2242
Train, Epoch: 1, Batch: 809, Step num: 809, Learning rate: 0.00002827, Avg batch loss: 0.9511, Avg batch acc: 0.2328
Train, Epoch: 1, Batch: 810, Step num: 810, Learning rate: 0.00002830, Avg batch loss: 0.9880, Avg batch acc: 0.2265
Train, Epoch: 1, Batch: 811, Step num: 811, Learning rate: 0.00002834, Avg batch loss: 0.9349, Avg batch acc: 0.2391
Train, Epoch: 1, Batch: 812, Step num: 812, Learning rate: 0.00002837, Avg batch loss: 0.9884, Avg batch acc: 0.2255
Train, Epoch: 1, Batch: 813, Step num: 813, Learning rate: 0.00002841, Avg batch loss: 0.9222, Avg batch acc: 0.2292
Train, Epoch: 1, Batch: 814, Step num: 814, Learning rate: 0.00002844, Avg batch loss: 0.9894, Avg batch acc: 0.2447
Train, Epoch: 1, Batch: 815, Step num: 815, Learning rate: 0.00002847, Avg batch loss: 1.0653, Avg batch acc: 0.2175
Train, Epoch: 1, Batch: 816, Step num: 816, Learning rate: 0.00002851, Avg batch loss: 0.9430, Avg batch acc: 0.2419
Train, Epoch: 1, Batch: 817, Step num: 817, Learning rate: 0.00002854, Avg batch loss: 1.0912, Avg batch acc: 0.2339
Train, Epoch: 1, Batch: 818, Step num: 818, Learning rate: 0.00002858, Avg batch loss: 0.9898, Avg batch acc: 0.2297
Train, Epoch: 1, Batch: 819, Step num: 819, Learning rate: 0.00002861, Avg batch loss: 1.0046, Avg batch acc: 0.2369
Train, Epoch: 1, Batch: 820, Step num: 820, Learning rate: 0.00002865, Avg batch loss: 1.0318, Avg batch acc: 0.2368
Train, Epoch: 1, Batch: 821, Step num: 821, Learning rate: 0.00002868, Avg batch loss: 0.9618, Avg batch acc: 0.2193
Train, Epoch: 1, Batch: 822, Step num: 822, Learning rate: 0.00002872, Avg batch loss: 0.8952, Avg batch acc: 0.2416
Train, Epoch: 1, Batch: 823, Step num: 823, Learning rate: 0.00002875, Avg batch loss: 1.0013, Avg batch acc: 0.2142
Train, Epoch: 1, Batch: 824, Step num: 824, Learning rate: 0.00002879, Avg batch loss: 0.9576, Avg batch acc: 0.2343
Train, Epoch: 1, Batch: 825, Step num: 825, Learning rate: 0.00002882, Avg batch loss: 1.0158, Avg batch acc: 0.2186
Train, Epoch: 1, Batch: 826, Step num: 826, Learning rate: 0.00002886, Avg batch loss: 1.0919, Avg batch acc: 0.2303
Train, Epoch: 1, Batch: 827, Step num: 827, Learning rate: 0.00002889, Avg batch loss: 1.0257, Avg batch acc: 0.2420
Train, Epoch: 1, Batch: 828, Step num: 828, Learning rate: 0.00002893, Avg batch loss: 0.9980, Avg batch acc: 0.2224
Train, Epoch: 1, Batch: 829, Step num: 829, Learning rate: 0.00002896, Avg batch loss: 1.0231, Avg batch acc: 0.2369
Train, Epoch: 1, Batch: 830, Step num: 830, Learning rate: 0.00002900, Avg batch loss: 1.0187, Avg batch acc: 0.2220
Train, Epoch: 1, Batch: 831, Step num: 831, Learning rate: 0.00002903, Avg batch loss: 1.0008, Avg batch acc: 0.2277
Train, Epoch: 1, Batch: 832, Step num: 832, Learning rate: 0.00002907, Avg batch loss: 0.9564, Avg batch acc: 0.2471
Train, Epoch: 1, Batch: 833, Step num: 833, Learning rate: 0.00002910, Avg batch loss: 0.9217, Avg batch acc: 0.2255
Train, Epoch: 1, Batch: 834, Step num: 834, Learning rate: 0.00002914, Avg batch loss: 0.9668, Avg batch acc: 0.2354
Train, Epoch: 1, Batch: 835, Step num: 835, Learning rate: 0.00002917, Avg batch loss: 0.9606, Avg batch acc: 0.2408
Train, Epoch: 1, Batch: 836, Step num: 836, Learning rate: 0.00002921, Avg batch loss: 1.1390, Avg batch acc: 0.2326
Train, Epoch: 1, Batch: 837, Step num: 837, Learning rate: 0.00002924, Avg batch loss: 1.0311, Avg batch acc: 0.2173
Train, Epoch: 1, Batch: 838, Step num: 838, Learning rate: 0.00002928, Avg batch loss: 0.9880, Avg batch acc: 0.2235
Train, Epoch: 1, Batch: 839, Step num: 839, Learning rate: 0.00002931, Avg batch loss: 0.9754, Avg batch acc: 0.2484
Train, Epoch: 1, Batch: 840, Step num: 840, Learning rate: 0.00002935, Avg batch loss: 0.9664, Avg batch acc: 0.2316
Train, Epoch: 1, Batch: 841, Step num: 841, Learning rate: 0.00002938, Avg batch loss: 0.9582, Avg batch acc: 0.2123
Train, Epoch: 1, Batch: 842, Step num: 842, Learning rate: 0.00002942, Avg batch loss: 0.9804, Avg batch acc: 0.2466
Train, Epoch: 1, Batch: 843, Step num: 843, Learning rate: 0.00002945, Avg batch loss: 1.1076, Avg batch acc: 0.2131
Train, Epoch: 1, Batch: 844, Step num: 844, Learning rate: 0.00002949, Avg batch loss: 0.9539, Avg batch acc: 0.2390
Train, Epoch: 1, Batch: 845, Step num: 845, Learning rate: 0.00002952, Avg batch loss: 0.9915, Avg batch acc: 0.2205
Train, Epoch: 1, Batch: 846, Step num: 846, Learning rate: 0.00002956, Avg batch loss: 1.0547, Avg batch acc: 0.2289
Train, Epoch: 1, Batch: 847, Step num: 847, Learning rate: 0.00002959, Avg batch loss: 0.9646, Avg batch acc: 0.2272
Train, Epoch: 1, Batch: 848, Step num: 848, Learning rate: 0.00002963, Avg batch loss: 0.9289, Avg batch acc: 0.2454
Train, Epoch: 1, Batch: 849, Step num: 849, Learning rate: 0.00002966, Avg batch loss: 0.9285, Avg batch acc: 0.2324
Train, Epoch: 1, Batch: 850, Step num: 850, Learning rate: 0.00002970, Avg batch loss: 1.0011, Avg batch acc: 0.2354
Train, Epoch: 1, Batch: 851, Step num: 851, Learning rate: 0.00002973, Avg batch loss: 0.9483, Avg batch acc: 0.2375
Train, Epoch: 1, Batch: 852, Step num: 852, Learning rate: 0.00002977, Avg batch loss: 0.9231, Avg batch acc: 0.2263
Train, Epoch: 1, Batch: 853, Step num: 853, Learning rate: 0.00002980, Avg batch loss: 0.8688, Avg batch acc: 0.2471
Train, Epoch: 1, Batch: 854, Step num: 854, Learning rate: 0.00002984, Avg batch loss: 0.9314, Avg batch acc: 0.2239
Train, Epoch: 1, Batch: 855, Step num: 855, Learning rate: 0.00002987, Avg batch loss: 0.9529, Avg batch acc: 0.2334
Train, Epoch: 1, Batch: 856, Step num: 856, Learning rate: 0.00002991, Avg batch loss: 0.9434, Avg batch acc: 0.2524
Train, Epoch: 1, Batch: 857, Step num: 857, Learning rate: 0.00002994, Avg batch loss: 0.9914, Avg batch acc: 0.2220
Train, Epoch: 1, Batch: 858, Step num: 858, Learning rate: 0.00002998, Avg batch loss: 0.8922, Avg batch acc: 0.2490
Train, Epoch: 1, Batch: 859, Step num: 859, Learning rate: 0.00003001, Avg batch loss: 0.9376, Avg batch acc: 0.2432
Train, Epoch: 1, Batch: 860, Step num: 860, Learning rate: 0.00003005, Avg batch loss: 0.9653, Avg batch acc: 0.2202
Train, Epoch: 1, Batch: 861, Step num: 861, Learning rate: 0.00003008, Avg batch loss: 0.8374, Avg batch acc: 0.2465
Train, Epoch: 1, Batch: 862, Step num: 862, Learning rate: 0.00003012, Avg batch loss: 0.9556, Avg batch acc: 0.2283
Train, Epoch: 1, Batch: 863, Step num: 863, Learning rate: 0.00003015, Avg batch loss: 1.0051, Avg batch acc: 0.2312
Train, Epoch: 1, Batch: 864, Step num: 864, Learning rate: 0.00003019, Avg batch loss: 0.9416, Avg batch acc: 0.2466
Train, Epoch: 1, Batch: 865, Step num: 865, Learning rate: 0.00003022, Avg batch loss: 0.9318, Avg batch acc: 0.2508
Train, Epoch: 1, Batch: 866, Step num: 866, Learning rate: 0.00003026, Avg batch loss: 0.8707, Avg batch acc: 0.2318
Train, Epoch: 1, Batch: 867, Step num: 867, Learning rate: 0.00003029, Avg batch loss: 0.9701, Avg batch acc: 0.2380
Train, Epoch: 1, Batch: 868, Step num: 868, Learning rate: 0.00003033, Avg batch loss: 0.9488, Avg batch acc: 0.2268
Train, Epoch: 1, Batch: 869, Step num: 869, Learning rate: 0.00003036, Avg batch loss: 0.9420, Avg batch acc: 0.2457
Train, Epoch: 1, Batch: 870, Step num: 870, Learning rate: 0.00003040, Avg batch loss: 0.9038, Avg batch acc: 0.2454
Train, Epoch: 1, Batch: 871, Step num: 871, Learning rate: 0.00003043, Avg batch loss: 0.9713, Avg batch acc: 0.2392
Train, Epoch: 1, Batch: 872, Step num: 872, Learning rate: 0.00003047, Avg batch loss: 1.0569, Avg batch acc: 0.2364
Train, Epoch: 1, Batch: 873, Step num: 873, Learning rate: 0.00003050, Avg batch loss: 0.9759, Avg batch acc: 0.2281
Train, Epoch: 1, Batch: 874, Step num: 874, Learning rate: 0.00003054, Avg batch loss: 1.0117, Avg batch acc: 0.2282
Train, Epoch: 1, Batch: 875, Step num: 875, Learning rate: 0.00003057, Avg batch loss: 0.9568, Avg batch acc: 0.2476
Train, Epoch: 1, Batch: 876, Step num: 876, Learning rate: 0.00003061, Avg batch loss: 0.9651, Avg batch acc: 0.2571
Train, Epoch: 1, Batch: 877, Step num: 877, Learning rate: 0.00003064, Avg batch loss: 0.9225, Avg batch acc: 0.2508
Train, Epoch: 1, Batch: 878, Step num: 878, Learning rate: 0.00003068, Avg batch loss: 0.9821, Avg batch acc: 0.2444
Train, Epoch: 1, Batch: 879, Step num: 879, Learning rate: 0.00003071, Avg batch loss: 0.9858, Avg batch acc: 0.2634
Train, Epoch: 1, Batch: 880, Step num: 880, Learning rate: 0.00003075, Avg batch loss: 0.9623, Avg batch acc: 0.2382
Train, Epoch: 1, Batch: 881, Step num: 881, Learning rate: 0.00003078, Avg batch loss: 0.9628, Avg batch acc: 0.2566
Train, Epoch: 1, Batch: 882, Step num: 882, Learning rate: 0.00003082, Avg batch loss: 0.9907, Avg batch acc: 0.2395
Train, Epoch: 1, Batch: 883, Step num: 883, Learning rate: 0.00003085, Avg batch loss: 0.9559, Avg batch acc: 0.2449
Train, Epoch: 1, Batch: 884, Step num: 884, Learning rate: 0.00003089, Avg batch loss: 0.9958, Avg batch acc: 0.2434
Train, Epoch: 1, Batch: 885, Step num: 885, Learning rate: 0.00003092, Avg batch loss: 0.9456, Avg batch acc: 0.2346
Train, Epoch: 1, Batch: 886, Step num: 886, Learning rate: 0.00003096, Avg batch loss: 0.9135, Avg batch acc: 0.2347
Train, Epoch: 1, Batch: 887, Step num: 887, Learning rate: 0.00003099, Avg batch loss: 0.9298, Avg batch acc: 0.2403
Train, Epoch: 1, Batch: 888, Step num: 888, Learning rate: 0.00003103, Avg batch loss: 0.9871, Avg batch acc: 0.2610
Train, Epoch: 1, Batch: 889, Step num: 889, Learning rate: 0.00003106, Avg batch loss: 0.9665, Avg batch acc: 0.2448
Train, Epoch: 1, Batch: 890, Step num: 890, Learning rate: 0.00003110, Avg batch loss: 0.9239, Avg batch acc: 0.2549
Train, Epoch: 1, Batch: 891, Step num: 891, Learning rate: 0.00003113, Avg batch loss: 0.9818, Avg batch acc: 0.2332
Train, Epoch: 1, Batch: 892, Step num: 892, Learning rate: 0.00003117, Avg batch loss: 0.9605, Avg batch acc: 0.2312
Train, Epoch: 1, Batch: 893, Step num: 893, Learning rate: 0.00003120, Avg batch loss: 0.8487, Avg batch acc: 0.2508
Train, Epoch: 1, Batch: 894, Step num: 894, Learning rate: 0.00003124, Avg batch loss: 0.8697, Avg batch acc: 0.2496
Train, Epoch: 1, Batch: 895, Step num: 895, Learning rate: 0.00003127, Avg batch loss: 0.9661, Avg batch acc: 0.2445
Train, Epoch: 1, Batch: 896, Step num: 896, Learning rate: 0.00003130, Avg batch loss: 0.9254, Avg batch acc: 0.2466
Train, Epoch: 1, Batch: 897, Step num: 897, Learning rate: 0.00003134, Avg batch loss: 0.9263, Avg batch acc: 0.2536
Train, Epoch: 1, Batch: 898, Step num: 898, Learning rate: 0.00003137, Avg batch loss: 0.9534, Avg batch acc: 0.2484
Train, Epoch: 1, Batch: 899, Step num: 899, Learning rate: 0.00003141, Avg batch loss: 0.9558, Avg batch acc: 0.2378
Train, Epoch: 1, Batch: 900, Step num: 900, Learning rate: 0.00003144, Avg batch loss: 0.9449, Avg batch acc: 0.2258
Train, Epoch: 1, Batch: 901, Step num: 901, Learning rate: 0.00003148, Avg batch loss: 0.9093, Avg batch acc: 0.2485
Train, Epoch: 1, Batch: 902, Step num: 902, Learning rate: 0.00003151, Avg batch loss: 0.9143, Avg batch acc: 0.2403
Train, Epoch: 1, Batch: 903, Step num: 903, Learning rate: 0.00003155, Avg batch loss: 0.8367, Avg batch acc: 0.2542
Train, Epoch: 1, Batch: 904, Step num: 904, Learning rate: 0.00003158, Avg batch loss: 0.8701, Avg batch acc: 0.2451
Train, Epoch: 1, Batch: 905, Step num: 905, Learning rate: 0.00003162, Avg batch loss: 0.8846, Avg batch acc: 0.2500
Train, Epoch: 1, Batch: 906, Step num: 906, Learning rate: 0.00003165, Avg batch loss: 0.8852, Avg batch acc: 0.2514
Train, Epoch: 1, Batch: 907, Step num: 907, Learning rate: 0.00003169, Avg batch loss: 0.9345, Avg batch acc: 0.2365
Train, Epoch: 1, Batch: 908, Step num: 908, Learning rate: 0.00003172, Avg batch loss: 0.9495, Avg batch acc: 0.2370
Train, Epoch: 1, Batch: 909, Step num: 909, Learning rate: 0.00003176, Avg batch loss: 0.9005, Avg batch acc: 0.2397
Train, Epoch: 1, Batch: 910, Step num: 910, Learning rate: 0.00003179, Avg batch loss: 0.8754, Avg batch acc: 0.2452
Train, Epoch: 1, Batch: 911, Step num: 911, Learning rate: 0.00003183, Avg batch loss: 0.9263, Avg batch acc: 0.2471
Train, Epoch: 1, Batch: 912, Step num: 912, Learning rate: 0.00003186, Avg batch loss: 0.9482, Avg batch acc: 0.2620
Train, Epoch: 1, Batch: 913, Step num: 913, Learning rate: 0.00003190, Avg batch loss: 0.8989, Avg batch acc: 0.2360
Train, Epoch: 1, Batch: 914, Step num: 914, Learning rate: 0.00003193, Avg batch loss: 0.9828, Avg batch acc: 0.2363
Train, Epoch: 1, Batch: 915, Step num: 915, Learning rate: 0.00003197, Avg batch loss: 1.0234, Avg batch acc: 0.2458
Train, Epoch: 1, Batch: 916, Step num: 916, Learning rate: 0.00003200, Avg batch loss: 0.9634, Avg batch acc: 0.2594
Train, Epoch: 1, Batch: 917, Step num: 917, Learning rate: 0.00003204, Avg batch loss: 0.8434, Avg batch acc: 0.2522
Train, Epoch: 1, Batch: 918, Step num: 918, Learning rate: 0.00003207, Avg batch loss: 0.8745, Avg batch acc: 0.2396
Train, Epoch: 1, Batch: 919, Step num: 919, Learning rate: 0.00003211, Avg batch loss: 0.9482, Avg batch acc: 0.2443
Train, Epoch: 1, Batch: 920, Step num: 920, Learning rate: 0.00003214, Avg batch loss: 0.9785, Avg batch acc: 0.2559
Train, Epoch: 1, Batch: 921, Step num: 921, Learning rate: 0.00003218, Avg batch loss: 0.8692, Avg batch acc: 0.2589
Train, Epoch: 1, Batch: 922, Step num: 922, Learning rate: 0.00003221, Avg batch loss: 0.9773, Avg batch acc: 0.2469
Train, Epoch: 1, Batch: 923, Step num: 923, Learning rate: 0.00003225, Avg batch loss: 0.8861, Avg batch acc: 0.2613
Train, Epoch: 1, Batch: 924, Step num: 924, Learning rate: 0.00003228, Avg batch loss: 0.9795, Avg batch acc: 0.2379
Train, Epoch: 1, Batch: 925, Step num: 925, Learning rate: 0.00003232, Avg batch loss: 0.9614, Avg batch acc: 0.2551
Train, Epoch: 1, Batch: 926, Step num: 926, Learning rate: 0.00003235, Avg batch loss: 0.8316, Avg batch acc: 0.2601
Train, Epoch: 1, Batch: 927, Step num: 927, Learning rate: 0.00003239, Avg batch loss: 0.8624, Avg batch acc: 0.2611
Train, Epoch: 1, Batch: 928, Step num: 928, Learning rate: 0.00003242, Avg batch loss: 0.8973, Avg batch acc: 0.2510
Train, Epoch: 1, Batch: 929, Step num: 929, Learning rate: 0.00003246, Avg batch loss: 0.8730, Avg batch acc: 0.2516
Train, Epoch: 1, Batch: 930, Step num: 930, Learning rate: 0.00003249, Avg batch loss: 0.9442, Avg batch acc: 0.2522
Train, Epoch: 1, Batch: 931, Step num: 931, Learning rate: 0.00003253, Avg batch loss: 0.8920, Avg batch acc: 0.2553
Train, Epoch: 1, Batch: 932, Step num: 932, Learning rate: 0.00003256, Avg batch loss: 0.9201, Avg batch acc: 0.2683
Train, Epoch: 1, Batch: 933, Step num: 933, Learning rate: 0.00003260, Avg batch loss: 0.9496, Avg batch acc: 0.2448
Train, Epoch: 1, Batch: 934, Step num: 934, Learning rate: 0.00003263, Avg batch loss: 0.8609, Avg batch acc: 0.2424
Train, Epoch: 1, Batch: 935, Step num: 935, Learning rate: 0.00003267, Avg batch loss: 0.9403, Avg batch acc: 0.2481
Train, Epoch: 1, Batch: 936, Step num: 936, Learning rate: 0.00003270, Avg batch loss: 0.9021, Avg batch acc: 0.2589
Train, Epoch: 1, Batch: 937, Step num: 937, Learning rate: 0.00003274, Avg batch loss: 0.9604, Avg batch acc: 0.2594
Train, Epoch: 1, Batch: 938, Step num: 938, Learning rate: 0.00003277, Avg batch loss: 0.9078, Avg batch acc: 0.2711
Train, Epoch: 1, Batch: 939, Step num: 939, Learning rate: 0.00003281, Avg batch loss: 1.0096, Avg batch acc: 0.2403
Train, Epoch: 1, Batch: 940, Step num: 940, Learning rate: 0.00003284, Avg batch loss: 0.8902, Avg batch acc: 0.2611
Train, Epoch: 1, Batch: 941, Step num: 941, Learning rate: 0.00003288, Avg batch loss: 0.9071, Avg batch acc: 0.2573
Train, Epoch: 1, Batch: 942, Step num: 942, Learning rate: 0.00003291, Avg batch loss: 0.8664, Avg batch acc: 0.2751
Train, Epoch: 1, Batch: 943, Step num: 943, Learning rate: 0.00003295, Avg batch loss: 0.9609, Avg batch acc: 0.2608
Train, Epoch: 1, Batch: 944, Step num: 944, Learning rate: 0.00003298, Avg batch loss: 0.8767, Avg batch acc: 0.2586
Train, Epoch: 1, Batch: 945, Step num: 945, Learning rate: 0.00003302, Avg batch loss: 0.9562, Avg batch acc: 0.2490
Train, Epoch: 1, Batch: 946, Step num: 946, Learning rate: 0.00003305, Avg batch loss: 0.8562, Avg batch acc: 0.2452
Train, Epoch: 1, Batch: 947, Step num: 947, Learning rate: 0.00003309, Avg batch loss: 0.8787, Avg batch acc: 0.2578
Train, Epoch: 1, Batch: 948, Step num: 948, Learning rate: 0.00003312, Avg batch loss: 0.9043, Avg batch acc: 0.2632
Train, Epoch: 1, Batch: 949, Step num: 949, Learning rate: 0.00003316, Avg batch loss: 0.9041, Avg batch acc: 0.2598
Train, Epoch: 1, Batch: 950, Step num: 950, Learning rate: 0.00003319, Avg batch loss: 0.8602, Avg batch acc: 0.2708
Train, Epoch: 1, Batch: 951, Step num: 951, Learning rate: 0.00003323, Avg batch loss: 0.9344, Avg batch acc: 0.2543
Train, Epoch: 1, Batch: 952, Step num: 952, Learning rate: 0.00003326, Avg batch loss: 0.8188, Avg batch acc: 0.2605
Train, Epoch: 1, Batch: 953, Step num: 953, Learning rate: 0.00003330, Avg batch loss: 0.8661, Avg batch acc: 0.2695
Train, Epoch: 1, Batch: 954, Step num: 954, Learning rate: 0.00003333, Avg batch loss: 0.8384, Avg batch acc: 0.2734
Train, Epoch: 1, Batch: 955, Step num: 955, Learning rate: 0.00003337, Avg batch loss: 0.8512, Avg batch acc: 0.2552
Train, Epoch: 1, Batch: 956, Step num: 956, Learning rate: 0.00003340, Avg batch loss: 0.9611, Avg batch acc: 0.2457
Train, Epoch: 1, Batch: 957, Step num: 957, Learning rate: 0.00003344, Avg batch loss: 0.9196, Avg batch acc: 0.2711
Train, Epoch: 1, Batch: 958, Step num: 958, Learning rate: 0.00003347, Avg batch loss: 0.9164, Avg batch acc: 0.2659
Train, Epoch: 1, Batch: 959, Step num: 959, Learning rate: 0.00003351, Avg batch loss: 0.8836, Avg batch acc: 0.2702
Train, Epoch: 1, Batch: 960, Step num: 960, Learning rate: 0.00003354, Avg batch loss: 0.8951, Avg batch acc: 0.2625
Train, Epoch: 1, Batch: 961, Step num: 961, Learning rate: 0.00003358, Avg batch loss: 0.9047, Avg batch acc: 0.2645
Train, Epoch: 1, Batch: 962, Step num: 962, Learning rate: 0.00003361, Avg batch loss: 0.7707, Avg batch acc: 0.2835
Train, Epoch: 1, Batch: 963, Step num: 963, Learning rate: 0.00003365, Avg batch loss: 0.8990, Avg batch acc: 0.2665
Train, Epoch: 1, Batch: 964, Step num: 964, Learning rate: 0.00003368, Avg batch loss: 0.9421, Avg batch acc: 0.2588
Train, Epoch: 1, Batch: 965, Step num: 965, Learning rate: 0.00003372, Avg batch loss: 0.8860, Avg batch acc: 0.2718
Train, Epoch: 1, Batch: 966, Step num: 966, Learning rate: 0.00003375, Avg batch loss: 0.9640, Avg batch acc: 0.2662
Train, Epoch: 1, Batch: 967, Step num: 967, Learning rate: 0.00003379, Avg batch loss: 0.8621, Avg batch acc: 0.2625
Train, Epoch: 1, Batch: 968, Step num: 968, Learning rate: 0.00003382, Avg batch loss: 0.8704, Avg batch acc: 0.2632
Train, Epoch: 1, Batch: 969, Step num: 969, Learning rate: 0.00003386, Avg batch loss: 0.9127, Avg batch acc: 0.2603
Train, Epoch: 1, Batch: 970, Step num: 970, Learning rate: 0.00003389, Avg batch loss: 0.9231, Avg batch acc: 0.2578
Train, Epoch: 1, Batch: 971, Step num: 971, Learning rate: 0.00003393, Avg batch loss: 0.9250, Avg batch acc: 0.2825
Train, Epoch: 1, Batch: 972, Step num: 972, Learning rate: 0.00003396, Avg batch loss: 0.8430, Avg batch acc: 0.2693
Train, Epoch: 1, Batch: 973, Step num: 973, Learning rate: 0.00003400, Avg batch loss: 0.8339, Avg batch acc: 0.2792
Train, Epoch: 1, Batch: 974, Step num: 974, Learning rate: 0.00003403, Avg batch loss: 0.8925, Avg batch acc: 0.2643
Train, Epoch: 1, Batch: 975, Step num: 975, Learning rate: 0.00003407, Avg batch loss: 0.9718, Avg batch acc: 0.2493
Train, Epoch: 1, Batch: 976, Step num: 976, Learning rate: 0.00003410, Avg batch loss: 0.8238, Avg batch acc: 0.2665
Train, Epoch: 1, Batch: 977, Step num: 977, Learning rate: 0.00003413, Avg batch loss: 0.8855, Avg batch acc: 0.2713
Train, Epoch: 1, Batch: 978, Step num: 978, Learning rate: 0.00003417, Avg batch loss: 0.9030, Avg batch acc: 0.2552
Train, Epoch: 1, Batch: 979, Step num: 979, Learning rate: 0.00003420, Avg batch loss: 0.8641, Avg batch acc: 0.2641
Train, Epoch: 1, Batch: 980, Step num: 980, Learning rate: 0.00003424, Avg batch loss: 0.9116, Avg batch acc: 0.2509
Train, Epoch: 1, Batch: 981, Step num: 981, Learning rate: 0.00003427, Avg batch loss: 0.7956, Avg batch acc: 0.2610
Train, Epoch: 1, Batch: 982, Step num: 982, Learning rate: 0.00003431, Avg batch loss: 0.8895, Avg batch acc: 0.2561
Train, Epoch: 1, Batch: 983, Step num: 983, Learning rate: 0.00003434, Avg batch loss: 0.9155, Avg batch acc: 0.2756
Train, Epoch: 1, Batch: 984, Step num: 984, Learning rate: 0.00003438, Avg batch loss: 0.8237, Avg batch acc: 0.2803
Train, Epoch: 1, Batch: 985, Step num: 985, Learning rate: 0.00003441, Avg batch loss: 0.8512, Avg batch acc: 0.2685
Train, Epoch: 1, Batch: 986, Step num: 986, Learning rate: 0.00003445, Avg batch loss: 0.9022, Avg batch acc: 0.2594
Train, Epoch: 1, Batch: 987, Step num: 987, Learning rate: 0.00003448, Avg batch loss: 0.8882, Avg batch acc: 0.2612
Train, Epoch: 1, Batch: 988, Step num: 988, Learning rate: 0.00003452, Avg batch loss: 0.8443, Avg batch acc: 0.2694
Train, Epoch: 1, Batch: 989, Step num: 989, Learning rate: 0.00003455, Avg batch loss: 0.9044, Avg batch acc: 0.2634
Train, Epoch: 1, Batch: 990, Step num: 990, Learning rate: 0.00003459, Avg batch loss: 0.7664, Avg batch acc: 0.2566
Train, Epoch: 1, Batch: 991, Step num: 991, Learning rate: 0.00003462, Avg batch loss: 0.8932, Avg batch acc: 0.2881
Train, Epoch: 1, Batch: 992, Step num: 992, Learning rate: 0.00003466, Avg batch loss: 0.7951, Avg batch acc: 0.2787
Train, Epoch: 1, Batch: 993, Step num: 993, Learning rate: 0.00003469, Avg batch loss: 0.8178, Avg batch acc: 0.2853
Train, Epoch: 1, Batch: 994, Step num: 994, Learning rate: 0.00003473, Avg batch loss: 0.8822, Avg batch acc: 0.2747
Train, Epoch: 1, Batch: 995, Step num: 995, Learning rate: 0.00003476, Avg batch loss: 0.8017, Avg batch acc: 0.2720
Train, Epoch: 1, Batch: 996, Step num: 996, Learning rate: 0.00003480, Avg batch loss: 0.8706, Avg batch acc: 0.2564
Train, Epoch: 1, Batch: 997, Step num: 997, Learning rate: 0.00003483, Avg batch loss: 0.8950, Avg batch acc: 0.2844
Train, Epoch: 1, Batch: 998, Step num: 998, Learning rate: 0.00003487, Avg batch loss: 0.8382, Avg batch acc: 0.2767
Train, Epoch: 1, Batch: 999, Step num: 999, Learning rate: 0.00003490, Avg batch loss: 0.8558, Avg batch acc: 0.2996
Train, Epoch: 1, Batch: 1000, Step num: 1000, Learning rate: 0.00003494, Avg batch loss: 0.8497, Avg batch acc: 0.2610
Train, Epoch: 1, Batch: 1001, Step num: 1001, Learning rate: 0.00003497, Avg batch loss: 0.8737, Avg batch acc: 0.2767
Train, Epoch: 1, Batch: 1002, Step num: 1002, Learning rate: 0.00003501, Avg batch loss: 0.8277, Avg batch acc: 0.2804
Train, Epoch: 1, Batch: 1003, Step num: 1003, Learning rate: 0.00003504, Avg batch loss: 0.8747, Avg batch acc: 0.2795
Train, Epoch: 1, Batch: 1004, Step num: 1004, Learning rate: 0.00003508, Avg batch loss: 0.8143, Avg batch acc: 0.2630
Train, Epoch: 1, Batch: 1005, Step num: 1005, Learning rate: 0.00003511, Avg batch loss: 0.9364, Avg batch acc: 0.2729
Train, Epoch: 1, Batch: 1006, Step num: 1006, Learning rate: 0.00003515, Avg batch loss: 0.7674, Avg batch acc: 0.2988
Train, Epoch: 1, Batch: 1007, Step num: 1007, Learning rate: 0.00003518, Avg batch loss: 0.8150, Avg batch acc: 0.2892
Train, Epoch: 1, Batch: 1008, Step num: 1008, Learning rate: 0.00003522, Avg batch loss: 0.9052, Avg batch acc: 0.2644
Train, Epoch: 1, Batch: 1009, Step num: 1009, Learning rate: 0.00003525, Avg batch loss: 0.8971, Avg batch acc: 0.2707
Train, Epoch: 1, Batch: 1010, Step num: 1010, Learning rate: 0.00003529, Avg batch loss: 0.9002, Avg batch acc: 0.2829
Train, Epoch: 1, Batch: 1011, Step num: 1011, Learning rate: 0.00003532, Avg batch loss: 0.8983, Avg batch acc: 0.2707
Train, Epoch: 1, Batch: 1012, Step num: 1012, Learning rate: 0.00003536, Avg batch loss: 0.8903, Avg batch acc: 0.2673
Train, Epoch: 1, Batch: 1013, Step num: 1013, Learning rate: 0.00003539, Avg batch loss: 0.8382, Avg batch acc: 0.2740
Train, Epoch: 1, Batch: 1014, Step num: 1014, Learning rate: 0.00003543, Avg batch loss: 0.9000, Avg batch acc: 0.2805
Train, Epoch: 1, Batch: 1015, Step num: 1015, Learning rate: 0.00003546, Avg batch loss: 0.8853, Avg batch acc: 0.2751
Train, Epoch: 1, Batch: 1016, Step num: 1016, Learning rate: 0.00003550, Avg batch loss: 0.8064, Avg batch acc: 0.2598
Train, Epoch: 1, Batch: 1017, Step num: 1017, Learning rate: 0.00003553, Avg batch loss: 0.8675, Avg batch acc: 0.2680
Train, Epoch: 1, Batch: 1018, Step num: 1018, Learning rate: 0.00003557, Avg batch loss: 0.8548, Avg batch acc: 0.2671
Train, Epoch: 1, Batch: 1019, Step num: 1019, Learning rate: 0.00003560, Avg batch loss: 0.8869, Avg batch acc: 0.2622
Train, Epoch: 1, Batch: 1020, Step num: 1020, Learning rate: 0.00003564, Avg batch loss: 0.9127, Avg batch acc: 0.2606
Train, Epoch: 1, Batch: 1021, Step num: 1021, Learning rate: 0.00003567, Avg batch loss: 0.8625, Avg batch acc: 0.2565
Train, Epoch: 1, Batch: 1022, Step num: 1022, Learning rate: 0.00003571, Avg batch loss: 0.8374, Avg batch acc: 0.2605
Train, Epoch: 1, Batch: 1023, Step num: 1023, Learning rate: 0.00003574, Avg batch loss: 0.8131, Avg batch acc: 0.2855
Train, Epoch: 1, Batch: 1024, Step num: 1024, Learning rate: 0.00003578, Avg batch loss: 0.8410, Avg batch acc: 0.2725
Train, Epoch: 1, Batch: 1025, Step num: 1025, Learning rate: 0.00003581, Avg batch loss: 0.8563, Avg batch acc: 0.2701
Train, Epoch: 1, Batch: 1026, Step num: 1026, Learning rate: 0.00003585, Avg batch loss: 0.8792, Avg batch acc: 0.2835
Train, Epoch: 1, Batch: 1027, Step num: 1027, Learning rate: 0.00003588, Avg batch loss: 0.7526, Avg batch acc: 0.2879
Train, Epoch: 1, Batch: 1028, Step num: 1028, Learning rate: 0.00003592, Avg batch loss: 0.8318, Avg batch acc: 0.2714
Train, Epoch: 1, Batch: 1029, Step num: 1029, Learning rate: 0.00003595, Avg batch loss: 0.8288, Avg batch acc: 0.2844
Train, Epoch: 1, Batch: 1030, Step num: 1030, Learning rate: 0.00003599, Avg batch loss: 0.8530, Avg batch acc: 0.2942
Train, Epoch: 1, Batch: 1031, Step num: 1031, Learning rate: 0.00003602, Avg batch loss: 0.8459, Avg batch acc: 0.2887
Train, Epoch: 1, Batch: 1032, Step num: 1032, Learning rate: 0.00003606, Avg batch loss: 0.8608, Avg batch acc: 0.2689
Train, Epoch: 1, Batch: 1033, Step num: 1033, Learning rate: 0.00003609, Avg batch loss: 0.7942, Avg batch acc: 0.2911
Train, Epoch: 1, Batch: 1034, Step num: 1034, Learning rate: 0.00003613, Avg batch loss: 0.8645, Avg batch acc: 0.2716
Train, Epoch: 1, Batch: 1035, Step num: 1035, Learning rate: 0.00003616, Avg batch loss: 0.8085, Avg batch acc: 0.2869
Train, Epoch: 1, Batch: 1036, Step num: 1036, Learning rate: 0.00003620, Avg batch loss: 0.8217, Avg batch acc: 0.2807
Train, Epoch: 1, Batch: 1037, Step num: 1037, Learning rate: 0.00003623, Avg batch loss: 0.8381, Avg batch acc: 0.2788
Train, Epoch: 1, Batch: 1038, Step num: 1038, Learning rate: 0.00003627, Avg batch loss: 0.8708, Avg batch acc: 0.2903
Train, Epoch: 1, Batch: 1039, Step num: 1039, Learning rate: 0.00003630, Avg batch loss: 0.8462, Avg batch acc: 0.2605
Train, Epoch: 1, Batch: 1040, Step num: 1040, Learning rate: 0.00003634, Avg batch loss: 0.8331, Avg batch acc: 0.2675
Train, Epoch: 1, Batch: 1041, Step num: 1041, Learning rate: 0.00003637, Avg batch loss: 0.7858, Avg batch acc: 0.2905
Train, Epoch: 1, Batch: 1042, Step num: 1042, Learning rate: 0.00003641, Avg batch loss: 0.7945, Avg batch acc: 0.2788
Train, Epoch: 1, Batch: 1043, Step num: 1043, Learning rate: 0.00003644, Avg batch loss: 0.8315, Avg batch acc: 0.2825
Train, Epoch: 1, Batch: 1044, Step num: 1044, Learning rate: 0.00003648, Avg batch loss: 0.8068, Avg batch acc: 0.2768
Train, Epoch: 1, Batch: 1045, Step num: 1045, Learning rate: 0.00003651, Avg batch loss: 0.8126, Avg batch acc: 0.2817
Train, Epoch: 1, Batch: 1046, Step num: 1046, Learning rate: 0.00003655, Avg batch loss: 0.8347, Avg batch acc: 0.2850
Train, Epoch: 1, Batch: 1047, Step num: 1047, Learning rate: 0.00003658, Avg batch loss: 0.8099, Avg batch acc: 0.2888
Train, Epoch: 1, Batch: 1048, Step num: 1048, Learning rate: 0.00003662, Avg batch loss: 0.7972, Avg batch acc: 0.2724
Train, Epoch: 1, Batch: 1049, Step num: 1049, Learning rate: 0.00003665, Avg batch loss: 0.7876, Avg batch acc: 0.2878
Train, Epoch: 1, Batch: 1050, Step num: 1050, Learning rate: 0.00003669, Avg batch loss: 0.7830, Avg batch acc: 0.3009
Train, Epoch: 1, Batch: 1051, Step num: 1051, Learning rate: 0.00003672, Avg batch loss: 0.8167, Avg batch acc: 0.2792
Train, Epoch: 1, Batch: 1052, Step num: 1052, Learning rate: 0.00003676, Avg batch loss: 0.8444, Avg batch acc: 0.2853
Train, Epoch: 1, Batch: 1053, Step num: 1053, Learning rate: 0.00003679, Avg batch loss: 0.8586, Avg batch acc: 0.2755
Train, Epoch: 1, Batch: 1054, Step num: 1054, Learning rate: 0.00003683, Avg batch loss: 0.9479, Avg batch acc: 0.2617
Train, Epoch: 1, Batch: 1055, Step num: 1055, Learning rate: 0.00003686, Avg batch loss: 0.7943, Avg batch acc: 0.2975
Train, Epoch: 1, Batch: 1056, Step num: 1056, Learning rate: 0.00003690, Avg batch loss: 0.8325, Avg batch acc: 0.2682
Train, Epoch: 1, Batch: 1057, Step num: 1057, Learning rate: 0.00003693, Avg batch loss: 0.8024, Avg batch acc: 0.2791
Train, Epoch: 1, Batch: 1058, Step num: 1058, Learning rate: 0.00003696, Avg batch loss: 0.8024, Avg batch acc: 0.2786
Train, Epoch: 1, Batch: 1059, Step num: 1059, Learning rate: 0.00003700, Avg batch loss: 0.8038, Avg batch acc: 0.2835
Train, Epoch: 1, Batch: 1060, Step num: 1060, Learning rate: 0.00003703, Avg batch loss: 0.8443, Avg batch acc: 0.2744
Train, Epoch: 1, Batch: 1061, Step num: 1061, Learning rate: 0.00003707, Avg batch loss: 0.8338, Avg batch acc: 0.2756
Train, Epoch: 1, Batch: 1062, Step num: 1062, Learning rate: 0.00003710, Avg batch loss: 0.7654, Avg batch acc: 0.2951
Train, Epoch: 1, Batch: 1063, Step num: 1063, Learning rate: 0.00003714, Avg batch loss: 0.8312, Avg batch acc: 0.2768
Train, Epoch: 1, Batch: 1064, Step num: 1064, Learning rate: 0.00003717, Avg batch loss: 0.8242, Avg batch acc: 0.2893
Train, Epoch: 1, Batch: 1065, Step num: 1065, Learning rate: 0.00003721, Avg batch loss: 0.8156, Avg batch acc: 0.2817
Train, Epoch: 1, Batch: 1066, Step num: 1066, Learning rate: 0.00003724, Avg batch loss: 0.8850, Avg batch acc: 0.2774
Train, Epoch: 1, Batch: 1067, Step num: 1067, Learning rate: 0.00003728, Avg batch loss: 0.7434, Avg batch acc: 0.3047
Train, Epoch: 1, Batch: 1068, Step num: 1068, Learning rate: 0.00003731, Avg batch loss: 0.8273, Avg batch acc: 0.2858
Train, Epoch: 1, Batch: 1069, Step num: 1069, Learning rate: 0.00003735, Avg batch loss: 0.8302, Avg batch acc: 0.2833
Train, Epoch: 1, Batch: 1070, Step num: 1070, Learning rate: 0.00003738, Avg batch loss: 0.8082, Avg batch acc: 0.2679
Train, Epoch: 1, Batch: 1071, Step num: 1071, Learning rate: 0.00003742, Avg batch loss: 0.9036, Avg batch acc: 0.2658
Train, Epoch: 1, Batch: 1072, Step num: 1072, Learning rate: 0.00003745, Avg batch loss: 0.8459, Avg batch acc: 0.2792
Train, Epoch: 1, Batch: 1073, Step num: 1073, Learning rate: 0.00003749, Avg batch loss: 0.8112, Avg batch acc: 0.2779
Train, Epoch: 1, Batch: 1074, Step num: 1074, Learning rate: 0.00003752, Avg batch loss: 0.8475, Avg batch acc: 0.2931
Train, Epoch: 1, Batch: 1075, Step num: 1075, Learning rate: 0.00003756, Avg batch loss: 0.8087, Avg batch acc: 0.2944
Train, Epoch: 1, Batch: 1076, Step num: 1076, Learning rate: 0.00003759, Avg batch loss: 0.8437, Avg batch acc: 0.2764
Train, Epoch: 1, Batch: 1077, Step num: 1077, Learning rate: 0.00003763, Avg batch loss: 0.8079, Avg batch acc: 0.2862
Train, Epoch: 1, Batch: 1078, Step num: 1078, Learning rate: 0.00003766, Avg batch loss: 0.7793, Avg batch acc: 0.2915
Train, Epoch: 1, Batch: 1079, Step num: 1079, Learning rate: 0.00003770, Avg batch loss: 0.8222, Avg batch acc: 0.2729
Train, Epoch: 1, Batch: 1080, Step num: 1080, Learning rate: 0.00003773, Avg batch loss: 0.8471, Avg batch acc: 0.2887
Train, Epoch: 1, Batch: 1081, Step num: 1081, Learning rate: 0.00003777, Avg batch loss: 0.7952, Avg batch acc: 0.2782
Train, Epoch: 1, Batch: 1082, Step num: 1082, Learning rate: 0.00003780, Avg batch loss: 0.7749, Avg batch acc: 0.2802
Train, Epoch: 1, Batch: 1083, Step num: 1083, Learning rate: 0.00003784, Avg batch loss: 0.8658, Avg batch acc: 0.2881
Train, Epoch: 1, Batch: 1084, Step num: 1084, Learning rate: 0.00003787, Avg batch loss: 0.8869, Avg batch acc: 0.2774
Train, Epoch: 1, Batch: 1085, Step num: 1085, Learning rate: 0.00003791, Avg batch loss: 0.8217, Avg batch acc: 0.2860
Train, Epoch: 1, Batch: 1086, Step num: 1086, Learning rate: 0.00003794, Avg batch loss: 0.7819, Avg batch acc: 0.3106
Train, Epoch: 1, Batch: 1087, Step num: 1087, Learning rate: 0.00003798, Avg batch loss: 0.7430, Avg batch acc: 0.2890
Train, Epoch: 1, Batch: 1088, Step num: 1088, Learning rate: 0.00003801, Avg batch loss: 0.8156, Avg batch acc: 0.2938
Train, Epoch: 1, Batch: 1089, Step num: 1089, Learning rate: 0.00003805, Avg batch loss: 0.8214, Avg batch acc: 0.2974
Train, Epoch: 1, Batch: 1090, Step num: 1090, Learning rate: 0.00003808, Avg batch loss: 0.7884, Avg batch acc: 0.2731
Train, Epoch: 1, Batch: 1091, Step num: 1091, Learning rate: 0.00003812, Avg batch loss: 0.8494, Avg batch acc: 0.2836
Train, Epoch: 1, Batch: 1092, Step num: 1092, Learning rate: 0.00003815, Avg batch loss: 0.8019, Avg batch acc: 0.2818
Train, Epoch: 1, Batch: 1093, Step num: 1093, Learning rate: 0.00003819, Avg batch loss: 0.7826, Avg batch acc: 0.2927
Train, Epoch: 1, Batch: 1094, Step num: 1094, Learning rate: 0.00003822, Avg batch loss: 0.8485, Avg batch acc: 0.2624
Train, Epoch: 1, Batch: 1095, Step num: 1095, Learning rate: 0.00003826, Avg batch loss: 0.8246, Avg batch acc: 0.2880
Train, Epoch: 1, Batch: 1096, Step num: 1096, Learning rate: 0.00003829, Avg batch loss: 0.8246, Avg batch acc: 0.2871
Train, Epoch: 1, Batch: 1097, Step num: 1097, Learning rate: 0.00003833, Avg batch loss: 0.8356, Avg batch acc: 0.2821
Train, Epoch: 1, Batch: 1098, Step num: 1098, Learning rate: 0.00003836, Avg batch loss: 0.7724, Avg batch acc: 0.3026
Train, Epoch: 1, Batch: 1099, Step num: 1099, Learning rate: 0.00003840, Avg batch loss: 0.8828, Avg batch acc: 0.2745
Train, Epoch: 1, Batch: 1100, Step num: 1100, Learning rate: 0.00003843, Avg batch loss: 0.8610, Avg batch acc: 0.2702
Train, Epoch: 1, Batch: 1101, Step num: 1101, Learning rate: 0.00003847, Avg batch loss: 0.8223, Avg batch acc: 0.3015
Train, Epoch: 1, Batch: 1102, Step num: 1102, Learning rate: 0.00003850, Avg batch loss: 0.8207, Avg batch acc: 0.2956
Train, Epoch: 1, Batch: 1103, Step num: 1103, Learning rate: 0.00003854, Avg batch loss: 0.8062, Avg batch acc: 0.2855
Train, Epoch: 1, Batch: 1104, Step num: 1104, Learning rate: 0.00003857, Avg batch loss: 0.8402, Avg batch acc: 0.2743
Train, Epoch: 1, Batch: 1105, Step num: 1105, Learning rate: 0.00003861, Avg batch loss: 0.8487, Avg batch acc: 0.2719
Train, Epoch: 1, Batch: 1106, Step num: 1106, Learning rate: 0.00003864, Avg batch loss: 0.7550, Avg batch acc: 0.3160
Train, Epoch: 1, Batch: 1107, Step num: 1107, Learning rate: 0.00003868, Avg batch loss: 0.8313, Avg batch acc: 0.2769
Train, Epoch: 1, Batch: 1108, Step num: 1108, Learning rate: 0.00003871, Avg batch loss: 0.8426, Avg batch acc: 0.2842
Train, Epoch: 1, Batch: 1109, Step num: 1109, Learning rate: 0.00003875, Avg batch loss: 0.8243, Avg batch acc: 0.2988
Train, Epoch: 1, Batch: 1110, Step num: 1110, Learning rate: 0.00003878, Avg batch loss: 0.8126, Avg batch acc: 0.2882
Train, Epoch: 1, Batch: 1111, Step num: 1111, Learning rate: 0.00003882, Avg batch loss: 0.7839, Avg batch acc: 0.3002
Train, Epoch: 1, Batch: 1112, Step num: 1112, Learning rate: 0.00003885, Avg batch loss: 0.8462, Avg batch acc: 0.2725
Train, Epoch: 1, Batch: 1113, Step num: 1113, Learning rate: 0.00003889, Avg batch loss: 0.8009, Avg batch acc: 0.2792
Train, Epoch: 1, Batch: 1114, Step num: 1114, Learning rate: 0.00003892, Avg batch loss: 0.7880, Avg batch acc: 0.2959
Train, Epoch: 1, Batch: 1115, Step num: 1115, Learning rate: 0.00003896, Avg batch loss: 0.7932, Avg batch acc: 0.2897
Train, Epoch: 1, Batch: 1116, Step num: 1116, Learning rate: 0.00003899, Avg batch loss: 0.8372, Avg batch acc: 0.3045
Train, Epoch: 1, Batch: 1117, Step num: 1117, Learning rate: 0.00003903, Avg batch loss: 0.8329, Avg batch acc: 0.2915
Train, Epoch: 1, Batch: 1118, Step num: 1118, Learning rate: 0.00003906, Avg batch loss: 0.7606, Avg batch acc: 0.3085
Train, Epoch: 1, Batch: 1119, Step num: 1119, Learning rate: 0.00003910, Avg batch loss: 0.7591, Avg batch acc: 0.2996
Train, Epoch: 1, Batch: 1120, Step num: 1120, Learning rate: 0.00003913, Avg batch loss: 0.7377, Avg batch acc: 0.3004
Train, Epoch: 1, Batch: 1121, Step num: 1121, Learning rate: 0.00003917, Avg batch loss: 0.7315, Avg batch acc: 0.3100
Train, Epoch: 1, Batch: 1122, Step num: 1122, Learning rate: 0.00003920, Avg batch loss: 0.7777, Avg batch acc: 0.2972
Train, Epoch: 1, Batch: 1123, Step num: 1123, Learning rate: 0.00003924, Avg batch loss: 0.7647, Avg batch acc: 0.2969
Train, Epoch: 1, Batch: 1124, Step num: 1124, Learning rate: 0.00003927, Avg batch loss: 0.7926, Avg batch acc: 0.2911
Train, Epoch: 1, Batch: 1125, Step num: 1125, Learning rate: 0.00003931, Avg batch loss: 0.7936, Avg batch acc: 0.2963
Train, Epoch: 1, Batch: 1126, Step num: 1126, Learning rate: 0.00003934, Avg batch loss: 0.7787, Avg batch acc: 0.2930
Train, Epoch: 1, Batch: 1127, Step num: 1127, Learning rate: 0.00003938, Avg batch loss: 0.7470, Avg batch acc: 0.3066
Train, Epoch: 1, Batch: 1128, Step num: 1128, Learning rate: 0.00003941, Avg batch loss: 0.7788, Avg batch acc: 0.2876
Train, Epoch: 1, Batch: 1129, Step num: 1129, Learning rate: 0.00003945, Avg batch loss: 0.7658, Avg batch acc: 0.2935
Train, Epoch: 1, Batch: 1130, Step num: 1130, Learning rate: 0.00003948, Avg batch loss: 0.7938, Avg batch acc: 0.3124
Train, Epoch: 1, Batch: 1131, Step num: 1131, Learning rate: 0.00003952, Avg batch loss: 0.7683, Avg batch acc: 0.3021
Train, Epoch: 1, Batch: 1132, Step num: 1132, Learning rate: 0.00003955, Avg batch loss: 0.7688, Avg batch acc: 0.2867
Train, Epoch: 1, Batch: 1133, Step num: 1133, Learning rate: 0.00003959, Avg batch loss: 0.8640, Avg batch acc: 0.2733
Train, Epoch: 1, Batch: 1134, Step num: 1134, Learning rate: 0.00003962, Avg batch loss: 0.7869, Avg batch acc: 0.2987
Train, Epoch: 1, Batch: 1135, Step num: 1135, Learning rate: 0.00003966, Avg batch loss: 0.7735, Avg batch acc: 0.2886
Train, Epoch: 1, Batch: 1136, Step num: 1136, Learning rate: 0.00003969, Avg batch loss: 0.8260, Avg batch acc: 0.2985
Train, Epoch: 1, Batch: 1137, Step num: 1137, Learning rate: 0.00003973, Avg batch loss: 0.8281, Avg batch acc: 0.2881
Train, Epoch: 1, Batch: 1138, Step num: 1138, Learning rate: 0.00003976, Avg batch loss: 0.7778, Avg batch acc: 0.3065
Train, Epoch: 1, Batch: 1139, Step num: 1139, Learning rate: 0.00003980, Avg batch loss: 0.8176, Avg batch acc: 0.2908
Train, Epoch: 1, Batch: 1140, Step num: 1140, Learning rate: 0.00003983, Avg batch loss: 0.8737, Avg batch acc: 0.2904
Train, Epoch: 1, Batch: 1141, Step num: 1141, Learning rate: 0.00003986, Avg batch loss: 0.8226, Avg batch acc: 0.2800
Train, Epoch: 1, Batch: 1142, Step num: 1142, Learning rate: 0.00003990, Avg batch loss: 0.7539, Avg batch acc: 0.2704
Train, Epoch: 1, Batch: 1143, Step num: 1143, Learning rate: 0.00003993, Avg batch loss: 0.8626, Avg batch acc: 0.2891
Train, Epoch: 1, Batch: 1144, Step num: 1144, Learning rate: 0.00003997, Avg batch loss: 0.8650, Avg batch acc: 0.2844
Train, Epoch: 1, Batch: 1145, Step num: 1145, Learning rate: 0.00004000, Avg batch loss: 0.8196, Avg batch acc: 0.2876
Train, Epoch: 1, Batch: 1146, Step num: 1146, Learning rate: 0.00004004, Avg batch loss: 0.8138, Avg batch acc: 0.2915
Train, Epoch: 1, Batch: 1147, Step num: 1147, Learning rate: 0.00004007, Avg batch loss: 0.7999, Avg batch acc: 0.3000
Train, Epoch: 1, Batch: 1148, Step num: 1148, Learning rate: 0.00004011, Avg batch loss: 0.7668, Avg batch acc: 0.3185
Train, Epoch: 1, Batch: 1149, Step num: 1149, Learning rate: 0.00004014, Avg batch loss: 0.8282, Avg batch acc: 0.2928
Train, Epoch: 1, Batch: 1150, Step num: 1150, Learning rate: 0.00004018, Avg batch loss: 0.8558, Avg batch acc: 0.3032
Train, Epoch: 1, Batch: 1151, Step num: 1151, Learning rate: 0.00004021, Avg batch loss: 0.7727, Avg batch acc: 0.2983
Train, Epoch: 1, Batch: 1152, Step num: 1152, Learning rate: 0.00004025, Avg batch loss: 0.8455, Avg batch acc: 0.2776
Train, Epoch: 1, Batch: 1153, Step num: 1153, Learning rate: 0.00004028, Avg batch loss: 0.8285, Avg batch acc: 0.3020
Train, Epoch: 1, Batch: 1154, Step num: 1154, Learning rate: 0.00004032, Avg batch loss: 0.7794, Avg batch acc: 0.2945
Train, Epoch: 1, Batch: 1155, Step num: 1155, Learning rate: 0.00004035, Avg batch loss: 0.7562, Avg batch acc: 0.3061
Train, Epoch: 1, Batch: 1156, Step num: 1156, Learning rate: 0.00004039, Avg batch loss: 0.8256, Avg batch acc: 0.3035
Train, Epoch: 1, Batch: 1157, Step num: 1157, Learning rate: 0.00004042, Avg batch loss: 0.7212, Avg batch acc: 0.3157
Train, Epoch: 1, Batch: 1158, Step num: 1158, Learning rate: 0.00004046, Avg batch loss: 0.6842, Avg batch acc: 0.2889
Train, Epoch: 1, Batch: 1159, Step num: 1159, Learning rate: 0.00004049, Avg batch loss: 0.7984, Avg batch acc: 0.2944
Train, Epoch: 1, Batch: 1160, Step num: 1160, Learning rate: 0.00004053, Avg batch loss: 0.7952, Avg batch acc: 0.2912
Train, Epoch: 1, Batch: 1161, Step num: 1161, Learning rate: 0.00004056, Avg batch loss: 0.7520, Avg batch acc: 0.3043
Train, Epoch: 1, Batch: 1162, Step num: 1162, Learning rate: 0.00004060, Avg batch loss: 0.8404, Avg batch acc: 0.2821
Train, Epoch: 1, Batch: 1163, Step num: 1163, Learning rate: 0.00004063, Avg batch loss: 0.8046, Avg batch acc: 0.3006
Train, Epoch: 1, Batch: 1164, Step num: 1164, Learning rate: 0.00004067, Avg batch loss: 0.8670, Avg batch acc: 0.3024
Train, Epoch: 1, Batch: 1165, Step num: 1165, Learning rate: 0.00004070, Avg batch loss: 0.7844, Avg batch acc: 0.2933
Train, Epoch: 1, Batch: 1166, Step num: 1166, Learning rate: 0.00004074, Avg batch loss: 0.7815, Avg batch acc: 0.3075
Train, Epoch: 1, Batch: 1167, Step num: 1167, Learning rate: 0.00004077, Avg batch loss: 0.8478, Avg batch acc: 0.3133
Train, Epoch: 1, Batch: 1168, Step num: 1168, Learning rate: 0.00004081, Avg batch loss: 0.8275, Avg batch acc: 0.2878
Train, Epoch: 1, Batch: 1169, Step num: 1169, Learning rate: 0.00004084, Avg batch loss: 0.8128, Avg batch acc: 0.2830
Train, Epoch: 1, Batch: 1170, Step num: 1170, Learning rate: 0.00004088, Avg batch loss: 0.7644, Avg batch acc: 0.3133
Train, Epoch: 1, Batch: 1171, Step num: 1171, Learning rate: 0.00004091, Avg batch loss: 0.8304, Avg batch acc: 0.2968
Train, Epoch: 1, Batch: 1172, Step num: 1172, Learning rate: 0.00004095, Avg batch loss: 0.7852, Avg batch acc: 0.2851
Train, Epoch: 1, Batch: 1173, Step num: 1173, Learning rate: 0.00004098, Avg batch loss: 0.7673, Avg batch acc: 0.3022
Train, Epoch: 1, Batch: 1174, Step num: 1174, Learning rate: 0.00004102, Avg batch loss: 0.7234, Avg batch acc: 0.3070
Train, Epoch: 1, Batch: 1175, Step num: 1175, Learning rate: 0.00004105, Avg batch loss: 0.8147, Avg batch acc: 0.3007
Train, Epoch: 1, Batch: 1176, Step num: 1176, Learning rate: 0.00004109, Avg batch loss: 0.7838, Avg batch acc: 0.3091
Train, Epoch: 1, Batch: 1177, Step num: 1177, Learning rate: 0.00004112, Avg batch loss: 0.8068, Avg batch acc: 0.2997
Train, Epoch: 1, Batch: 1178, Step num: 1178, Learning rate: 0.00004116, Avg batch loss: 0.8066, Avg batch acc: 0.3050
Train, Epoch: 1, Batch: 1179, Step num: 1179, Learning rate: 0.00004119, Avg batch loss: 0.8334, Avg batch acc: 0.2790
Train, Epoch: 1, Batch: 1180, Step num: 1180, Learning rate: 0.00004123, Avg batch loss: 0.7140, Avg batch acc: 0.3038
Train, Epoch: 1, Batch: 1181, Step num: 1181, Learning rate: 0.00004126, Avg batch loss: 0.8198, Avg batch acc: 0.2999
Train, Epoch: 1, Batch: 1182, Step num: 1182, Learning rate: 0.00004130, Avg batch loss: 0.6830, Avg batch acc: 0.3059
Train, Epoch: 1, Batch: 1183, Step num: 1183, Learning rate: 0.00004133, Avg batch loss: 0.7613, Avg batch acc: 0.3119
Train, Epoch: 1, Batch: 1184, Step num: 1184, Learning rate: 0.00004137, Avg batch loss: 0.8212, Avg batch acc: 0.3132
Train, Epoch: 1, Batch: 1185, Step num: 1185, Learning rate: 0.00004140, Avg batch loss: 0.6694, Avg batch acc: 0.3375
Train, Epoch: 1, Batch: 1186, Step num: 1186, Learning rate: 0.00004144, Avg batch loss: 0.7960, Avg batch acc: 0.2847
Train, Epoch: 1, Batch: 1187, Step num: 1187, Learning rate: 0.00004147, Avg batch loss: 0.7533, Avg batch acc: 0.2971
Train, Epoch: 1, Batch: 1188, Step num: 1188, Learning rate: 0.00004151, Avg batch loss: 0.7862, Avg batch acc: 0.2985
Train, Epoch: 1, Batch: 1189, Step num: 1189, Learning rate: 0.00004154, Avg batch loss: 0.8675, Avg batch acc: 0.3019
Train, Epoch: 1, Batch: 1190, Step num: 1190, Learning rate: 0.00004158, Avg batch loss: 0.7522, Avg batch acc: 0.3069
Train, Epoch: 1, Batch: 1191, Step num: 1191, Learning rate: 0.00004161, Avg batch loss: 0.7921, Avg batch acc: 0.2839
Train, Epoch: 1, Batch: 1192, Step num: 1192, Learning rate: 0.00004165, Avg batch loss: 0.8005, Avg batch acc: 0.2993
Train, Epoch: 1, Batch: 1193, Step num: 1193, Learning rate: 0.00004168, Avg batch loss: 0.6726, Avg batch acc: 0.3105
Train, Epoch: 1, Batch: 1194, Step num: 1194, Learning rate: 0.00004172, Avg batch loss: 0.7167, Avg batch acc: 0.2965
Train, Epoch: 1, Batch: 1195, Step num: 1195, Learning rate: 0.00004175, Avg batch loss: 0.7611, Avg batch acc: 0.3045
Train, Epoch: 1, Batch: 1196, Step num: 1196, Learning rate: 0.00004179, Avg batch loss: 0.7683, Avg batch acc: 0.3116
Train, Epoch: 1, Batch: 1197, Step num: 1197, Learning rate: 0.00004182, Avg batch loss: 0.7265, Avg batch acc: 0.2952
Train, Epoch: 1, Batch: 1198, Step num: 1198, Learning rate: 0.00004186, Avg batch loss: 0.7768, Avg batch acc: 0.2943
Train, Epoch: 1, Batch: 1199, Step num: 1199, Learning rate: 0.00004189, Avg batch loss: 0.7865, Avg batch acc: 0.2835
Train, Epoch: 1, Batch: 1200, Step num: 1200, Learning rate: 0.00004193, Avg batch loss: 0.8004, Avg batch acc: 0.2914
Train, Epoch: 1, Batch: 1201, Step num: 1201, Learning rate: 0.00004196, Avg batch loss: 0.7391, Avg batch acc: 0.2979
Train, Epoch: 1, Batch: 1202, Step num: 1202, Learning rate: 0.00004200, Avg batch loss: 0.7339, Avg batch acc: 0.3037
Train, Epoch: 1, Batch: 1203, Step num: 1203, Learning rate: 0.00004203, Avg batch loss: 0.7425, Avg batch acc: 0.2959
Train, Epoch: 1, Batch: 1204, Step num: 1204, Learning rate: 0.00004207, Avg batch loss: 0.7554, Avg batch acc: 0.3156
Train, Epoch: 1, Batch: 1205, Step num: 1205, Learning rate: 0.00004210, Avg batch loss: 0.8200, Avg batch acc: 0.3164
Train, Epoch: 1, Batch: 1206, Step num: 1206, Learning rate: 0.00004214, Avg batch loss: 0.7659, Avg batch acc: 0.3102
Train, Epoch: 1, Batch: 1207, Step num: 1207, Learning rate: 0.00004217, Avg batch loss: 0.7389, Avg batch acc: 0.3177
Train, Epoch: 1, Batch: 1208, Step num: 1208, Learning rate: 0.00004221, Avg batch loss: 0.6868, Avg batch acc: 0.3163
Train, Epoch: 1, Batch: 1209, Step num: 1209, Learning rate: 0.00004224, Avg batch loss: 0.7549, Avg batch acc: 0.3094
Train, Epoch: 1, Batch: 1210, Step num: 1210, Learning rate: 0.00004228, Avg batch loss: 0.8012, Avg batch acc: 0.3114
Train, Epoch: 1, Batch: 1211, Step num: 1211, Learning rate: 0.00004231, Avg batch loss: 0.7585, Avg batch acc: 0.3025
Train, Epoch: 1, Batch: 1212, Step num: 1212, Learning rate: 0.00004235, Avg batch loss: 0.7729, Avg batch acc: 0.2942
Train, Epoch: 1, Batch: 1213, Step num: 1213, Learning rate: 0.00004238, Avg batch loss: 0.8145, Avg batch acc: 0.2982
Train, Epoch: 1, Batch: 1214, Step num: 1214, Learning rate: 0.00004242, Avg batch loss: 0.7460, Avg batch acc: 0.2987
Train, Epoch: 1, Batch: 1215, Step num: 1215, Learning rate: 0.00004245, Avg batch loss: 0.7674, Avg batch acc: 0.3249
Train, Epoch: 1, Batch: 1216, Step num: 1216, Learning rate: 0.00004249, Avg batch loss: 0.7402, Avg batch acc: 0.3084
Train, Epoch: 1, Batch: 1217, Step num: 1217, Learning rate: 0.00004252, Avg batch loss: 0.8066, Avg batch acc: 0.2909
Train, Epoch: 1, Batch: 1218, Step num: 1218, Learning rate: 0.00004256, Avg batch loss: 0.7572, Avg batch acc: 0.2993
Train, Epoch: 1, Batch: 1219, Step num: 1219, Learning rate: 0.00004259, Avg batch loss: 0.7831, Avg batch acc: 0.3077
Train, Epoch: 1, Batch: 1220, Step num: 1220, Learning rate: 0.00004263, Avg batch loss: 0.7504, Avg batch acc: 0.3048
Train, Epoch: 1, Batch: 1221, Step num: 1221, Learning rate: 0.00004266, Avg batch loss: 0.7282, Avg batch acc: 0.2929
Train, Epoch: 1, Batch: 1222, Step num: 1222, Learning rate: 0.00004269, Avg batch loss: 0.7615, Avg batch acc: 0.3160
Train, Epoch: 1, Batch: 1223, Step num: 1223, Learning rate: 0.00004273, Avg batch loss: 0.7355, Avg batch acc: 0.3035
Train, Epoch: 1, Batch: 1224, Step num: 1224, Learning rate: 0.00004276, Avg batch loss: 0.8159, Avg batch acc: 0.3109
Train, Epoch: 1, Batch: 1225, Step num: 1225, Learning rate: 0.00004280, Avg batch loss: 0.7099, Avg batch acc: 0.2852
Train, Epoch: 1, Batch: 1226, Step num: 1226, Learning rate: 0.00004283, Avg batch loss: 0.7532, Avg batch acc: 0.3171
Train, Epoch: 1, Batch: 1227, Step num: 1227, Learning rate: 0.00004287, Avg batch loss: 0.7672, Avg batch acc: 0.3086
Train, Epoch: 1, Batch: 1228, Step num: 1228, Learning rate: 0.00004290, Avg batch loss: 0.7992, Avg batch acc: 0.3066
Train, Epoch: 1, Batch: 1229, Step num: 1229, Learning rate: 0.00004294, Avg batch loss: 0.7724, Avg batch acc: 0.3089
Train, Epoch: 1, Batch: 1230, Step num: 1230, Learning rate: 0.00004297, Avg batch loss: 0.7339, Avg batch acc: 0.2933
Train, Epoch: 1, Batch: 1231, Step num: 1231, Learning rate: 0.00004301, Avg batch loss: 0.7732, Avg batch acc: 0.2997
Train, Epoch: 1, Batch: 1232, Step num: 1232, Learning rate: 0.00004304, Avg batch loss: 0.7692, Avg batch acc: 0.3096
Train, Epoch: 1, Batch: 1233, Step num: 1233, Learning rate: 0.00004308, Avg batch loss: 0.7552, Avg batch acc: 0.3072
Train, Epoch: 1, Batch: 1234, Step num: 1234, Learning rate: 0.00004311, Avg batch loss: 0.7826, Avg batch acc: 0.3064
Train, Epoch: 1, Batch: 1235, Step num: 1235, Learning rate: 0.00004315, Avg batch loss: 0.7974, Avg batch acc: 0.3065
Train, Epoch: 1, Batch: 1236, Step num: 1236, Learning rate: 0.00004318, Avg batch loss: 0.7397, Avg batch acc: 0.3248
Train, Epoch: 1, Batch: 1237, Step num: 1237, Learning rate: 0.00004322, Avg batch loss: 0.7222, Avg batch acc: 0.3360
Train, Epoch: 1, Batch: 1238, Step num: 1238, Learning rate: 0.00004325, Avg batch loss: 0.8189, Avg batch acc: 0.2976
Train, Epoch: 1, Batch: 1239, Step num: 1239, Learning rate: 0.00004329, Avg batch loss: 0.7717, Avg batch acc: 0.3113
Train, Epoch: 1, Batch: 1240, Step num: 1240, Learning rate: 0.00004332, Avg batch loss: 0.7601, Avg batch acc: 0.3245
Train, Epoch: 1, Batch: 1241, Step num: 1241, Learning rate: 0.00004336, Avg batch loss: 0.7840, Avg batch acc: 0.3013
Train, Epoch: 1, Batch: 1242, Step num: 1242, Learning rate: 0.00004339, Avg batch loss: 0.7101, Avg batch acc: 0.3123
Train, Epoch: 1, Batch: 1243, Step num: 1243, Learning rate: 0.00004343, Avg batch loss: 0.7696, Avg batch acc: 0.3153
Train, Epoch: 1, Batch: 1244, Step num: 1244, Learning rate: 0.00004346, Avg batch loss: 0.7373, Avg batch acc: 0.3326
Train, Epoch: 1, Batch: 1245, Step num: 1245, Learning rate: 0.00004350, Avg batch loss: 0.7515, Avg batch acc: 0.3230
Train, Epoch: 1, Batch: 1246, Step num: 1246, Learning rate: 0.00004353, Avg batch loss: 0.6931, Avg batch acc: 0.3446
Train, Epoch: 1, Batch: 1247, Step num: 1247, Learning rate: 0.00004357, Avg batch loss: 0.7988, Avg batch acc: 0.3190
Train, Epoch: 1, Batch: 1248, Step num: 1248, Learning rate: 0.00004360, Avg batch loss: 0.7089, Avg batch acc: 0.3245
Train, Epoch: 1, Batch: 1249, Step num: 1249, Learning rate: 0.00004364, Avg batch loss: 0.7581, Avg batch acc: 0.2902
Train, Epoch: 1, Batch: 1250, Step num: 1250, Learning rate: 0.00004367, Avg batch loss: 0.8092, Avg batch acc: 0.3075
Train, Epoch: 1, Batch: 1251, Step num: 1251, Learning rate: 0.00004371, Avg batch loss: 0.6858, Avg batch acc: 0.3260
Train, Epoch: 1, Batch: 1252, Step num: 1252, Learning rate: 0.00004374, Avg batch loss: 0.7609, Avg batch acc: 0.3209
Train, Epoch: 1, Batch: 1253, Step num: 1253, Learning rate: 0.00004378, Avg batch loss: 0.7632, Avg batch acc: 0.3128
Train, Epoch: 1, Batch: 1254, Step num: 1254, Learning rate: 0.00004381, Avg batch loss: 0.7742, Avg batch acc: 0.2985
Train, Epoch: 1, Batch: 1255, Step num: 1255, Learning rate: 0.00004385, Avg batch loss: 0.7853, Avg batch acc: 0.3193
Train, Epoch: 1, Batch: 1256, Step num: 1256, Learning rate: 0.00004388, Avg batch loss: 0.7015, Avg batch acc: 0.3187
Train, Epoch: 1, Batch: 1257, Step num: 1257, Learning rate: 0.00004392, Avg batch loss: 0.8278, Avg batch acc: 0.2964
Train, Epoch: 1, Batch: 1258, Step num: 1258, Learning rate: 0.00004395, Avg batch loss: 0.7883, Avg batch acc: 0.3288
Train, Epoch: 1, Batch: 1259, Step num: 1259, Learning rate: 0.00004399, Avg batch loss: 0.8386, Avg batch acc: 0.2956
Train, Epoch: 1, Batch: 1260, Step num: 1260, Learning rate: 0.00004402, Avg batch loss: 0.7788, Avg batch acc: 0.3014
Train, Epoch: 1, Batch: 1261, Step num: 1261, Learning rate: 0.00004406, Avg batch loss: 0.7394, Avg batch acc: 0.2985
Train, Epoch: 1, Batch: 1262, Step num: 1262, Learning rate: 0.00004409, Avg batch loss: 0.7540, Avg batch acc: 0.3094
Train, Epoch: 1, Batch: 1263, Step num: 1263, Learning rate: 0.00004413, Avg batch loss: 0.7430, Avg batch acc: 0.3086
Train, Epoch: 1, Batch: 1264, Step num: 1264, Learning rate: 0.00004416, Avg batch loss: 0.7635, Avg batch acc: 0.2969
Train, Epoch: 1, Batch: 1265, Step num: 1265, Learning rate: 0.00004420, Avg batch loss: 0.7546, Avg batch acc: 0.3054
Train, Epoch: 1, Batch: 1266, Step num: 1266, Learning rate: 0.00004423, Avg batch loss: 0.7667, Avg batch acc: 0.3150
Train, Epoch: 1, Batch: 1267, Step num: 1267, Learning rate: 0.00004427, Avg batch loss: 0.8059, Avg batch acc: 0.2977
Train, Epoch: 1, Batch: 1268, Step num: 1268, Learning rate: 0.00004430, Avg batch loss: 0.7298, Avg batch acc: 0.2905
Train, Epoch: 1, Batch: 1269, Step num: 1269, Learning rate: 0.00004434, Avg batch loss: 0.7684, Avg batch acc: 0.3119
Train, Epoch: 1, Batch: 1270, Step num: 1270, Learning rate: 0.00004437, Avg batch loss: 0.7184, Avg batch acc: 0.2940
Train, Epoch: 1, Batch: 1271, Step num: 1271, Learning rate: 0.00004441, Avg batch loss: 0.7303, Avg batch acc: 0.3053
Train, Epoch: 1, Batch: 1272, Step num: 1272, Learning rate: 0.00004444, Avg batch loss: 0.7453, Avg batch acc: 0.3072
Train, Epoch: 1, Batch: 1273, Step num: 1273, Learning rate: 0.00004448, Avg batch loss: 0.7250, Avg batch acc: 0.3082
Train, Epoch: 1, Batch: 1274, Step num: 1274, Learning rate: 0.00004451, Avg batch loss: 0.6962, Avg batch acc: 0.3012
Train, Epoch: 1, Batch: 1275, Step num: 1275, Learning rate: 0.00004455, Avg batch loss: 0.7497, Avg batch acc: 0.2849
Train, Epoch: 1, Batch: 1276, Step num: 1276, Learning rate: 0.00004458, Avg batch loss: 0.7998, Avg batch acc: 0.3167
Train, Epoch: 1, Batch: 1277, Step num: 1277, Learning rate: 0.00004462, Avg batch loss: 0.8430, Avg batch acc: 0.3003
Train, Epoch: 1, Batch: 1278, Step num: 1278, Learning rate: 0.00004465, Avg batch loss: 0.7599, Avg batch acc: 0.3120
Train, Epoch: 1, Batch: 1279, Step num: 1279, Learning rate: 0.00004469, Avg batch loss: 0.7781, Avg batch acc: 0.3152
Train, Epoch: 1, Batch: 1280, Step num: 1280, Learning rate: 0.00004472, Avg batch loss: 0.7284, Avg batch acc: 0.3034
Train, Epoch: 1, Batch: 1281, Step num: 1281, Learning rate: 0.00004476, Avg batch loss: 0.8015, Avg batch acc: 0.2937
Train, Epoch: 1, Batch: 1282, Step num: 1282, Learning rate: 0.00004479, Avg batch loss: 0.7219, Avg batch acc: 0.3081
Train, Epoch: 1, Batch: 1283, Step num: 1283, Learning rate: 0.00004483, Avg batch loss: 0.7653, Avg batch acc: 0.3005
Train, Epoch: 1, Batch: 1284, Step num: 1284, Learning rate: 0.00004486, Avg batch loss: 0.7616, Avg batch acc: 0.3040
Train, Epoch: 1, Batch: 1285, Step num: 1285, Learning rate: 0.00004490, Avg batch loss: 0.7594, Avg batch acc: 0.2956
Train, Epoch: 1, Batch: 1286, Step num: 1286, Learning rate: 0.00004493, Avg batch loss: 0.7367, Avg batch acc: 0.3197
Train, Epoch: 1, Batch: 1287, Step num: 1287, Learning rate: 0.00004497, Avg batch loss: 0.7212, Avg batch acc: 0.2994
Train, Epoch: 1, Batch: 1288, Step num: 1288, Learning rate: 0.00004500, Avg batch loss: 0.7815, Avg batch acc: 0.2990
Train, Epoch: 1, Batch: 1289, Step num: 1289, Learning rate: 0.00004504, Avg batch loss: 0.6814, Avg batch acc: 0.3274
Train, Epoch: 1, Batch: 1290, Step num: 1290, Learning rate: 0.00004507, Avg batch loss: 0.7197, Avg batch acc: 0.3033
Train, Epoch: 1, Batch: 1291, Step num: 1291, Learning rate: 0.00004511, Avg batch loss: 0.7347, Avg batch acc: 0.3179
Train, Epoch: 1, Batch: 1292, Step num: 1292, Learning rate: 0.00004514, Avg batch loss: 0.8280, Avg batch acc: 0.2981
Train, Epoch: 1, Batch: 1293, Step num: 1293, Learning rate: 0.00004518, Avg batch loss: 0.8079, Avg batch acc: 0.3123
Train, Epoch: 1, Batch: 1294, Step num: 1294, Learning rate: 0.00004521, Avg batch loss: 0.7817, Avg batch acc: 0.3140
Train, Epoch: 1, Batch: 1295, Step num: 1295, Learning rate: 0.00004525, Avg batch loss: 0.7228, Avg batch acc: 0.3207
Train, Epoch: 1, Batch: 1296, Step num: 1296, Learning rate: 0.00004528, Avg batch loss: 0.7334, Avg batch acc: 0.3039
Train, Epoch: 1, Batch: 1297, Step num: 1297, Learning rate: 0.00004532, Avg batch loss: 0.7321, Avg batch acc: 0.3328
Train, Epoch: 1, Batch: 1298, Step num: 1298, Learning rate: 0.00004535, Avg batch loss: 0.7070, Avg batch acc: 0.3325
Train, Epoch: 1, Batch: 1299, Step num: 1299, Learning rate: 0.00004539, Avg batch loss: 0.8265, Avg batch acc: 0.3131
Train, Epoch: 1, Batch: 1300, Step num: 1300, Learning rate: 0.00004542, Avg batch loss: 0.7416, Avg batch acc: 0.3174
Train, Epoch: 1, Batch: 1301, Step num: 1301, Learning rate: 0.00004546, Avg batch loss: 0.7683, Avg batch acc: 0.2941
Train, Epoch: 1, Batch: 1302, Step num: 1302, Learning rate: 0.00004549, Avg batch loss: 0.7574, Avg batch acc: 0.3157
Train, Epoch: 1, Batch: 1303, Step num: 1303, Learning rate: 0.00004552, Avg batch loss: 0.8080, Avg batch acc: 0.3068
Train, Epoch: 1, Batch: 1304, Step num: 1304, Learning rate: 0.00004556, Avg batch loss: 0.7704, Avg batch acc: 0.3198
Train, Epoch: 1, Batch: 1305, Step num: 1305, Learning rate: 0.00004559, Avg batch loss: 0.7756, Avg batch acc: 0.3025
Train, Epoch: 1, Batch: 1306, Step num: 1306, Learning rate: 0.00004563, Avg batch loss: 0.7069, Avg batch acc: 0.3183
Train, Epoch: 1, Batch: 1307, Step num: 1307, Learning rate: 0.00004566, Avg batch loss: 0.6981, Avg batch acc: 0.3406
Train, Epoch: 1, Batch: 1308, Step num: 1308, Learning rate: 0.00004570, Avg batch loss: 0.7474, Avg batch acc: 0.3139
Train, Epoch: 1, Batch: 1309, Step num: 1309, Learning rate: 0.00004573, Avg batch loss: 0.7109, Avg batch acc: 0.3123
Train, Epoch: 1, Batch: 1310, Step num: 1310, Learning rate: 0.00004577, Avg batch loss: 0.7579, Avg batch acc: 0.3100
Train, Epoch: 1, Batch: 1311, Step num: 1311, Learning rate: 0.00004580, Avg batch loss: 0.6987, Avg batch acc: 0.3347
Train, Epoch: 1, Batch: 1312, Step num: 1312, Learning rate: 0.00004584, Avg batch loss: 0.8295, Avg batch acc: 0.3197
Train, Epoch: 1, Batch: 1313, Step num: 1313, Learning rate: 0.00004587, Avg batch loss: 0.8191, Avg batch acc: 0.3218
Train, Epoch: 1, Batch: 1314, Step num: 1314, Learning rate: 0.00004591, Avg batch loss: 0.7360, Avg batch acc: 0.3348
Train, Epoch: 1, Batch: 1315, Step num: 1315, Learning rate: 0.00004594, Avg batch loss: 0.7856, Avg batch acc: 0.3115
Train, Epoch: 1, Batch: 1316, Step num: 1316, Learning rate: 0.00004598, Avg batch loss: 0.6529, Avg batch acc: 0.3195
Train, Epoch: 1, Batch: 1317, Step num: 1317, Learning rate: 0.00004601, Avg batch loss: 0.7101, Avg batch acc: 0.3014
Train, Epoch: 1, Batch: 1318, Step num: 1318, Learning rate: 0.00004605, Avg batch loss: 0.7337, Avg batch acc: 0.3113
Train, Epoch: 1, Batch: 1319, Step num: 1319, Learning rate: 0.00004608, Avg batch loss: 0.7307, Avg batch acc: 0.3239
Train, Epoch: 1, Batch: 1320, Step num: 1320, Learning rate: 0.00004612, Avg batch loss: 0.7225, Avg batch acc: 0.3066
Train, Epoch: 1, Batch: 1321, Step num: 1321, Learning rate: 0.00004615, Avg batch loss: 0.7293, Avg batch acc: 0.3128
Train, Epoch: 1, Batch: 1322, Step num: 1322, Learning rate: 0.00004619, Avg batch loss: 0.7083, Avg batch acc: 0.3195
Train, Epoch: 1, Batch: 1323, Step num: 1323, Learning rate: 0.00004622, Avg batch loss: 0.7669, Avg batch acc: 0.3157
Train, Epoch: 1, Batch: 1324, Step num: 1324, Learning rate: 0.00004626, Avg batch loss: 0.7492, Avg batch acc: 0.3232
Train, Epoch: 1, Batch: 1325, Step num: 1325, Learning rate: 0.00004629, Avg batch loss: 0.8477, Avg batch acc: 0.2931
Train, Epoch: 1, Batch: 1326, Step num: 1326, Learning rate: 0.00004633, Avg batch loss: 0.7613, Avg batch acc: 0.3168
Train, Epoch: 1, Batch: 1327, Step num: 1327, Learning rate: 0.00004636, Avg batch loss: 0.7740, Avg batch acc: 0.2947
Train, Epoch: 1, Batch: 1328, Step num: 1328, Learning rate: 0.00004640, Avg batch loss: 0.7318, Avg batch acc: 0.3196
Train, Epoch: 1, Batch: 1329, Step num: 1329, Learning rate: 0.00004643, Avg batch loss: 0.7257, Avg batch acc: 0.3160
Train, Epoch: 1, Batch: 1330, Step num: 1330, Learning rate: 0.00004647, Avg batch loss: 0.7051, Avg batch acc: 0.2940
Train, Epoch: 1, Batch: 1331, Step num: 1331, Learning rate: 0.00004650, Avg batch loss: 0.7746, Avg batch acc: 0.2997
Train, Epoch: 1, Batch: 1332, Step num: 1332, Learning rate: 0.00004654, Avg batch loss: 0.7077, Avg batch acc: 0.3084
Train, Epoch: 1, Batch: 1333, Step num: 1333, Learning rate: 0.00004657, Avg batch loss: 0.7696, Avg batch acc: 0.3082
Train, Epoch: 1, Batch: 1334, Step num: 1334, Learning rate: 0.00004661, Avg batch loss: 0.6960, Avg batch acc: 0.3293
Train, Epoch: 1, Batch: 1335, Step num: 1335, Learning rate: 0.00004664, Avg batch loss: 0.6891, Avg batch acc: 0.3241
Train, Epoch: 1, Batch: 1336, Step num: 1336, Learning rate: 0.00004668, Avg batch loss: 0.7352, Avg batch acc: 0.3172
Train, Epoch: 1, Batch: 1337, Step num: 1337, Learning rate: 0.00004671, Avg batch loss: 0.7406, Avg batch acc: 0.3222
Train, Epoch: 1, Batch: 1338, Step num: 1338, Learning rate: 0.00004675, Avg batch loss: 0.7199, Avg batch acc: 0.3044
Train, Epoch: 1, Batch: 1339, Step num: 1339, Learning rate: 0.00004678, Avg batch loss: 0.6431, Avg batch acc: 0.3154
Train, Epoch: 1, Batch: 1340, Step num: 1340, Learning rate: 0.00004682, Avg batch loss: 0.7822, Avg batch acc: 0.2970
Train, Epoch: 1, Batch: 1341, Step num: 1341, Learning rate: 0.00004685, Avg batch loss: 0.7621, Avg batch acc: 0.3140
Train, Epoch: 1, Batch: 1342, Step num: 1342, Learning rate: 0.00004689, Avg batch loss: 0.7024, Avg batch acc: 0.3031
Train, Epoch: 1, Batch: 1343, Step num: 1343, Learning rate: 0.00004692, Avg batch loss: 0.7268, Avg batch acc: 0.3202
Train, Epoch: 1, Batch: 1344, Step num: 1344, Learning rate: 0.00004696, Avg batch loss: 0.7607, Avg batch acc: 0.3259
Train, Epoch: 1, Batch: 1345, Step num: 1345, Learning rate: 0.00004699, Avg batch loss: 0.8048, Avg batch acc: 0.2920
Train, Epoch: 1, Batch: 1346, Step num: 1346, Learning rate: 0.00004703, Avg batch loss: 0.7084, Avg batch acc: 0.3263
Train, Epoch: 1, Batch: 1347, Step num: 1347, Learning rate: 0.00004706, Avg batch loss: 0.7352, Avg batch acc: 0.3070
Train, Epoch: 1, Batch: 1348, Step num: 1348, Learning rate: 0.00004710, Avg batch loss: 0.7529, Avg batch acc: 0.3128
Train, Epoch: 1, Batch: 1349, Step num: 1349, Learning rate: 0.00004713, Avg batch loss: 0.7183, Avg batch acc: 0.2885
Train, Epoch: 1, Batch: 1350, Step num: 1350, Learning rate: 0.00004717, Avg batch loss: 0.7285, Avg batch acc: 0.3056
Train, Epoch: 1, Batch: 1351, Step num: 1351, Learning rate: 0.00004720, Avg batch loss: 0.7069, Avg batch acc: 0.3297
Train, Epoch: 1, Batch: 1352, Step num: 1352, Learning rate: 0.00004724, Avg batch loss: 0.7982, Avg batch acc: 0.3214
Train, Epoch: 1, Batch: 1353, Step num: 1353, Learning rate: 0.00004727, Avg batch loss: 0.7105, Avg batch acc: 0.3284
Train, Epoch: 1, Batch: 1354, Step num: 1354, Learning rate: 0.00004731, Avg batch loss: 0.7364, Avg batch acc: 0.3182
Train, Epoch: 1, Batch: 1355, Step num: 1355, Learning rate: 0.00004734, Avg batch loss: 0.7340, Avg batch acc: 0.2943
Train, Epoch: 1, Batch: 1356, Step num: 1356, Learning rate: 0.00004738, Avg batch loss: 0.6643, Avg batch acc: 0.3538
Train, Epoch: 1, Batch: 1357, Step num: 1357, Learning rate: 0.00004741, Avg batch loss: 0.7446, Avg batch acc: 0.2976
Train, Epoch: 1, Batch: 1358, Step num: 1358, Learning rate: 0.00004745, Avg batch loss: 0.7250, Avg batch acc: 0.3018
Train, Epoch: 1, Batch: 1359, Step num: 1359, Learning rate: 0.00004748, Avg batch loss: 0.6541, Avg batch acc: 0.3429
Train, Epoch: 1, Batch: 1360, Step num: 1360, Learning rate: 0.00004752, Avg batch loss: 0.7149, Avg batch acc: 0.3055
Train, Epoch: 1, Batch: 1361, Step num: 1361, Learning rate: 0.00004755, Avg batch loss: 0.7411, Avg batch acc: 0.3166
Train, Epoch: 1, Batch: 1362, Step num: 1362, Learning rate: 0.00004759, Avg batch loss: 0.7631, Avg batch acc: 0.3235
Train, Epoch: 1, Batch: 1363, Step num: 1363, Learning rate: 0.00004762, Avg batch loss: 0.7029, Avg batch acc: 0.3028
Train, Epoch: 1, Batch: 1364, Step num: 1364, Learning rate: 0.00004766, Avg batch loss: 0.7280, Avg batch acc: 0.3148
Train, Epoch: 1, Batch: 1365, Step num: 1365, Learning rate: 0.00004769, Avg batch loss: 0.7946, Avg batch acc: 0.3133
Train, Epoch: 1, Batch: 1366, Step num: 1366, Learning rate: 0.00004773, Avg batch loss: 0.8063, Avg batch acc: 0.2908
Train, Epoch: 1, Batch: 1367, Step num: 1367, Learning rate: 0.00004776, Avg batch loss: 0.6758, Avg batch acc: 0.3104
Train, Epoch: 1, Batch: 1368, Step num: 1368, Learning rate: 0.00004780, Avg batch loss: 0.7910, Avg batch acc: 0.3080
Train, Epoch: 1, Batch: 1369, Step num: 1369, Learning rate: 0.00004783, Avg batch loss: 0.8006, Avg batch acc: 0.2931
Train, Epoch: 1, Batch: 1370, Step num: 1370, Learning rate: 0.00004787, Avg batch loss: 0.6712, Avg batch acc: 0.3259
Train, Epoch: 1, Batch: 1371, Step num: 1371, Learning rate: 0.00004790, Avg batch loss: 0.7566, Avg batch acc: 0.3200
Train, Epoch: 1, Batch: 1372, Step num: 1372, Learning rate: 0.00004794, Avg batch loss: 0.7158, Avg batch acc: 0.3228
Train, Epoch: 1, Batch: 1373, Step num: 1373, Learning rate: 0.00004797, Avg batch loss: 0.7461, Avg batch acc: 0.3231
Train, Epoch: 1, Batch: 1374, Step num: 1374, Learning rate: 0.00004801, Avg batch loss: 0.6477, Avg batch acc: 0.3329
Train, Epoch: 1, Batch: 1375, Step num: 1375, Learning rate: 0.00004804, Avg batch loss: 0.7048, Avg batch acc: 0.3180
Train, Epoch: 1, Batch: 1376, Step num: 1376, Learning rate: 0.00004808, Avg batch loss: 0.6761, Avg batch acc: 0.3143
Train, Epoch: 1, Batch: 1377, Step num: 1377, Learning rate: 0.00004811, Avg batch loss: 0.7389, Avg batch acc: 0.3284
Train, Epoch: 1, Batch: 1378, Step num: 1378, Learning rate: 0.00004815, Avg batch loss: 0.6838, Avg batch acc: 0.3147
Train, Epoch: 1, Batch: 1379, Step num: 1379, Learning rate: 0.00004818, Avg batch loss: 0.7814, Avg batch acc: 0.3016
Train, Epoch: 1, Batch: 1380, Step num: 1380, Learning rate: 0.00004822, Avg batch loss: 0.7438, Avg batch acc: 0.3200
Train, Epoch: 1, Batch: 1381, Step num: 1381, Learning rate: 0.00004825, Avg batch loss: 0.7364, Avg batch acc: 0.3043
Train, Epoch: 1, Batch: 1382, Step num: 1382, Learning rate: 0.00004829, Avg batch loss: 0.6880, Avg batch acc: 0.3217
Train, Epoch: 1, Batch: 1383, Step num: 1383, Learning rate: 0.00004832, Avg batch loss: 0.7421, Avg batch acc: 0.3134
Train, Epoch: 1, Batch: 1384, Step num: 1384, Learning rate: 0.00004835, Avg batch loss: 0.7681, Avg batch acc: 0.3032
Train, Epoch: 1, Batch: 1385, Step num: 1385, Learning rate: 0.00004839, Avg batch loss: 0.7548, Avg batch acc: 0.3000
Train, Epoch: 1, Batch: 1386, Step num: 1386, Learning rate: 0.00004842, Avg batch loss: 0.7363, Avg batch acc: 0.3225
Train, Epoch: 1, Batch: 1387, Step num: 1387, Learning rate: 0.00004846, Avg batch loss: 0.7066, Avg batch acc: 0.3264
Train, Epoch: 1, Batch: 1388, Step num: 1388, Learning rate: 0.00004849, Avg batch loss: 0.6613, Avg batch acc: 0.3336
Train, Epoch: 1, Batch: 1389, Step num: 1389, Learning rate: 0.00004853, Avg batch loss: 0.7888, Avg batch acc: 0.3144
Train, Epoch: 1, Batch: 1390, Step num: 1390, Learning rate: 0.00004856, Avg batch loss: 0.6660, Avg batch acc: 0.3414
Train, Epoch: 1, Batch: 1391, Step num: 1391, Learning rate: 0.00004860, Avg batch loss: 0.7242, Avg batch acc: 0.3356
Train, Epoch: 1, Batch: 1392, Step num: 1392, Learning rate: 0.00004863, Avg batch loss: 0.7111, Avg batch acc: 0.3141
Train, Epoch: 1, Batch: 1393, Step num: 1393, Learning rate: 0.00004867, Avg batch loss: 0.6984, Avg batch acc: 0.3251
Train, Epoch: 1, Batch: 1394, Step num: 1394, Learning rate: 0.00004870, Avg batch loss: 0.6708, Avg batch acc: 0.3212
Train, Epoch: 1, Batch: 1395, Step num: 1395, Learning rate: 0.00004874, Avg batch loss: 0.7316, Avg batch acc: 0.3194
Train, Epoch: 1, Batch: 1396, Step num: 1396, Learning rate: 0.00004877, Avg batch loss: 0.7800, Avg batch acc: 0.3134
Train, Epoch: 1, Batch: 1397, Step num: 1397, Learning rate: 0.00004881, Avg batch loss: 0.7915, Avg batch acc: 0.3113
Train, Epoch: 1, Batch: 1398, Step num: 1398, Learning rate: 0.00004884, Avg batch loss: 0.7654, Avg batch acc: 0.3120
Train, Epoch: 1, Batch: 1399, Step num: 1399, Learning rate: 0.00004888, Avg batch loss: 0.6902, Avg batch acc: 0.3296
Train, Epoch: 1, Batch: 1400, Step num: 1400, Learning rate: 0.00004891, Avg batch loss: 0.7152, Avg batch acc: 0.3184
Train, Epoch: 1, Batch: 1401, Step num: 1401, Learning rate: 0.00004895, Avg batch loss: 0.6971, Avg batch acc: 0.3329
Train, Epoch: 1, Batch: 1402, Step num: 1402, Learning rate: 0.00004898, Avg batch loss: 0.7485, Avg batch acc: 0.3030
Train, Epoch: 1, Batch: 1403, Step num: 1403, Learning rate: 0.00004902, Avg batch loss: 0.7328, Avg batch acc: 0.3154
Train, Epoch: 1, Batch: 1404, Step num: 1404, Learning rate: 0.00004905, Avg batch loss: 0.7008, Avg batch acc: 0.2981
Train, Epoch: 1, Batch: 1405, Step num: 1405, Learning rate: 0.00004909, Avg batch loss: 0.6871, Avg batch acc: 0.3085
Train, Epoch: 1, Batch: 1406, Step num: 1406, Learning rate: 0.00004912, Avg batch loss: 0.7861, Avg batch acc: 0.3158
Train, Epoch: 1, Batch: 1407, Step num: 1407, Learning rate: 0.00004916, Avg batch loss: 0.7046, Avg batch acc: 0.3202
Train, Epoch: 1, Batch: 1408, Step num: 1408, Learning rate: 0.00004919, Avg batch loss: 0.7243, Avg batch acc: 0.3132
Train, Epoch: 1, Batch: 1409, Step num: 1409, Learning rate: 0.00004923, Avg batch loss: 0.7382, Avg batch acc: 0.3275
Train, Epoch: 1, Batch: 1410, Step num: 1410, Learning rate: 0.00004926, Avg batch loss: 0.7263, Avg batch acc: 0.3216
Train, Epoch: 1, Batch: 1411, Step num: 1411, Learning rate: 0.00004930, Avg batch loss: 0.6560, Avg batch acc: 0.3220
Train, Epoch: 1, Batch: 1412, Step num: 1412, Learning rate: 0.00004933, Avg batch loss: 0.7525, Avg batch acc: 0.3107
Train, Epoch: 1, Batch: 1413, Step num: 1413, Learning rate: 0.00004937, Avg batch loss: 0.7675, Avg batch acc: 0.3172
Train, Epoch: 1, Batch: 1414, Step num: 1414, Learning rate: 0.00004940, Avg batch loss: 0.7659, Avg batch acc: 0.3182
Train, Epoch: 1, Batch: 1415, Step num: 1415, Learning rate: 0.00004944, Avg batch loss: 0.7156, Avg batch acc: 0.3143
Train, Epoch: 1, Batch: 1416, Step num: 1416, Learning rate: 0.00004947, Avg batch loss: 0.6962, Avg batch acc: 0.3267
Train, Epoch: 1, Batch: 1417, Step num: 1417, Learning rate: 0.00004951, Avg batch loss: 0.6716, Avg batch acc: 0.2998
Train, Epoch: 1, Batch: 1418, Step num: 1418, Learning rate: 0.00004954, Avg batch loss: 0.7389, Avg batch acc: 0.3257
Train, Epoch: 1, Batch: 1419, Step num: 1419, Learning rate: 0.00004958, Avg batch loss: 0.7390, Avg batch acc: 0.3057
Train, Epoch: 1, Batch: 1420, Step num: 1420, Learning rate: 0.00004961, Avg batch loss: 0.7460, Avg batch acc: 0.3213
Train, Epoch: 1, Batch: 1421, Step num: 1421, Learning rate: 0.00004965, Avg batch loss: 0.7399, Avg batch acc: 0.3302
Train, Epoch: 1, Batch: 1422, Step num: 1422, Learning rate: 0.00004968, Avg batch loss: 0.7433, Avg batch acc: 0.3174
Train, Epoch: 1, Batch: 1423, Step num: 1423, Learning rate: 0.00004972, Avg batch loss: 0.6782, Avg batch acc: 0.3385
Train, Epoch: 1, Batch: 1424, Step num: 1424, Learning rate: 0.00004975, Avg batch loss: 0.7480, Avg batch acc: 0.3285
Train, Epoch: 1, Batch: 1425, Step num: 1425, Learning rate: 0.00004979, Avg batch loss: 0.7431, Avg batch acc: 0.3000
Train, Epoch: 1, Batch: 1426, Step num: 1426, Learning rate: 0.00004982, Avg batch loss: 0.7146, Avg batch acc: 0.3181
Train, Epoch: 1, Batch: 1427, Step num: 1427, Learning rate: 0.00004986, Avg batch loss: 0.7266, Avg batch acc: 0.3189
Train, Epoch: 1, Batch: 1428, Step num: 1428, Learning rate: 0.00004989, Avg batch loss: 0.6868, Avg batch acc: 0.3444
Train, Epoch: 1, Batch: 1429, Step num: 1429, Learning rate: 0.00004993, Avg batch loss: 0.6961, Avg batch acc: 0.3517
Train, Epoch: 1, Batch: 1430, Step num: 1430, Learning rate: 0.00004996, Avg batch loss: 0.7593, Avg batch acc: 0.3312
Train, Epoch: 1, Batch: 1431, Step num: 1431, Learning rate: 0.00005000, Avg batch loss: 0.7126, Avg batch acc: 0.2840
Train, Epoch: 1, Batch: 1432, Step num: 1432, Learning rate: 0.00005003, Avg batch loss: 0.7970, Avg batch acc: 0.3131
Train, Epoch: 1, Batch: 1433, Step num: 1433, Learning rate: 0.00005007, Avg batch loss: 0.7270, Avg batch acc: 0.3211
Train, Epoch: 1, Batch: 1434, Step num: 1434, Learning rate: 0.00005010, Avg batch loss: 0.7580, Avg batch acc: 0.3309
Train, Epoch: 1, Batch: 1435, Step num: 1435, Learning rate: 0.00005014, Avg batch loss: 0.6878, Avg batch acc: 0.2985
Train, Epoch: 1, Batch: 1436, Step num: 1436, Learning rate: 0.00005017, Avg batch loss: 0.7528, Avg batch acc: 0.3143
Train, Epoch: 1, Batch: 1437, Step num: 1437, Learning rate: 0.00005021, Avg batch loss: 0.7237, Avg batch acc: 0.3231
Train, Epoch: 1, Batch: 1438, Step num: 1438, Learning rate: 0.00005024, Avg batch loss: 0.7311, Avg batch acc: 0.3355
Train, Epoch: 1, Batch: 1439, Step num: 1439, Learning rate: 0.00005028, Avg batch loss: 0.7153, Avg batch acc: 0.3281
Train, Epoch: 1, Batch: 1440, Step num: 1440, Learning rate: 0.00005031, Avg batch loss: 0.7415, Avg batch acc: 0.3149
Train, Epoch: 1, Batch: 1441, Step num: 1441, Learning rate: 0.00005035, Avg batch loss: 0.7410, Avg batch acc: 0.3357
Train, Epoch: 1, Batch: 1442, Step num: 1442, Learning rate: 0.00005038, Avg batch loss: 0.7054, Avg batch acc: 0.3458
Train, Epoch: 1, Batch: 1443, Step num: 1443, Learning rate: 0.00005042, Avg batch loss: 0.6610, Avg batch acc: 0.3376
Train, Epoch: 1, Batch: 1444, Step num: 1444, Learning rate: 0.00005045, Avg batch loss: 0.7763, Avg batch acc: 0.3142
Train, Epoch: 1, Batch: 1445, Step num: 1445, Learning rate: 0.00005049, Avg batch loss: 0.7591, Avg batch acc: 0.3222
Train, Epoch: 1, Batch: 1446, Step num: 1446, Learning rate: 0.00005052, Avg batch loss: 0.7119, Avg batch acc: 0.3146
Train, Epoch: 1, Batch: 1447, Step num: 1447, Learning rate: 0.00005056, Avg batch loss: 0.6947, Avg batch acc: 0.3235
Train, Epoch: 1, Batch: 1448, Step num: 1448, Learning rate: 0.00005059, Avg batch loss: 0.7574, Avg batch acc: 0.3139
Train, Epoch: 1, Batch: 1449, Step num: 1449, Learning rate: 0.00005063, Avg batch loss: 0.7794, Avg batch acc: 0.3077
Train, Epoch: 1, Batch: 1450, Step num: 1450, Learning rate: 0.00005066, Avg batch loss: 0.6891, Avg batch acc: 0.3254
Train, Epoch: 1, Batch: 1451, Step num: 1451, Learning rate: 0.00005070, Avg batch loss: 0.6845, Avg batch acc: 0.3367
Train, Epoch: 1, Batch: 1452, Step num: 1452, Learning rate: 0.00005073, Avg batch loss: 0.6868, Avg batch acc: 0.3067
Train, Epoch: 1, Batch: 1453, Step num: 1453, Learning rate: 0.00005077, Avg batch loss: 0.7618, Avg batch acc: 0.3190
Train, Epoch: 1, Batch: 1454, Step num: 1454, Learning rate: 0.00005080, Avg batch loss: 0.7085, Avg batch acc: 0.3175
Train, Epoch: 1, Batch: 1455, Step num: 1455, Learning rate: 0.00005084, Avg batch loss: 0.7843, Avg batch acc: 0.3100
Train, Epoch: 1, Batch: 1456, Step num: 1456, Learning rate: 0.00005087, Avg batch loss: 0.6963, Avg batch acc: 0.3241
Train, Epoch: 1, Batch: 1457, Step num: 1457, Learning rate: 0.00005091, Avg batch loss: 0.6753, Avg batch acc: 0.3139
Train, Epoch: 1, Batch: 1458, Step num: 1458, Learning rate: 0.00005094, Avg batch loss: 0.7738, Avg batch acc: 0.3134
Train, Epoch: 1, Batch: 1459, Step num: 1459, Learning rate: 0.00005098, Avg batch loss: 0.7547, Avg batch acc: 0.3119
Train, Epoch: 1, Batch: 1460, Step num: 1460, Learning rate: 0.00005101, Avg batch loss: 0.7945, Avg batch acc: 0.3021
Train, Epoch: 1, Batch: 1461, Step num: 1461, Learning rate: 0.00005105, Avg batch loss: 0.7212, Avg batch acc: 0.3228
Train, Epoch: 1, Batch: 1462, Step num: 1462, Learning rate: 0.00005108, Avg batch loss: 0.7282, Avg batch acc: 0.3439
Train, Epoch: 1, Batch: 1463, Step num: 1463, Learning rate: 0.00005112, Avg batch loss: 0.6940, Avg batch acc: 0.3193
Train, Epoch: 1, Batch: 1464, Step num: 1464, Learning rate: 0.00005115, Avg batch loss: 0.7208, Avg batch acc: 0.2918
Train, Epoch: 1, Batch: 1465, Step num: 1465, Learning rate: 0.00005118, Avg batch loss: 0.7712, Avg batch acc: 0.3219
Train, Epoch: 1, Batch: 1466, Step num: 1466, Learning rate: 0.00005122, Avg batch loss: 0.6802, Avg batch acc: 0.3216
Train, Epoch: 1, Batch: 1467, Step num: 1467, Learning rate: 0.00005125, Avg batch loss: 0.7189, Avg batch acc: 0.3261
Train, Epoch: 1, Batch: 1468, Step num: 1468, Learning rate: 0.00005129, Avg batch loss: 0.6573, Avg batch acc: 0.3352
Train, Epoch: 1, Batch: 1469, Step num: 1469, Learning rate: 0.00005132, Avg batch loss: 0.6864, Avg batch acc: 0.3284
Train, Epoch: 1, Batch: 1470, Step num: 1470, Learning rate: 0.00005136, Avg batch loss: 0.7494, Avg batch acc: 0.3223
Train, Epoch: 1, Batch: 1471, Step num: 1471, Learning rate: 0.00005139, Avg batch loss: 0.6896, Avg batch acc: 0.3449
Train, Epoch: 1, Batch: 1472, Step num: 1472, Learning rate: 0.00005143, Avg batch loss: 0.7403, Avg batch acc: 0.3288
Train, Epoch: 1, Batch: 1473, Step num: 1473, Learning rate: 0.00005146, Avg batch loss: 0.7304, Avg batch acc: 0.3280
Train, Epoch: 1, Batch: 1474, Step num: 1474, Learning rate: 0.00005150, Avg batch loss: 0.7468, Avg batch acc: 0.2984
Train, Epoch: 1, Batch: 1475, Step num: 1475, Learning rate: 0.00005153, Avg batch loss: 0.7239, Avg batch acc: 0.3263
Train, Epoch: 1, Batch: 1476, Step num: 1476, Learning rate: 0.00005157, Avg batch loss: 0.7117, Avg batch acc: 0.3146
Train, Epoch: 1, Batch: 1477, Step num: 1477, Learning rate: 0.00005160, Avg batch loss: 0.7836, Avg batch acc: 0.3136
Train, Epoch: 1, Batch: 1478, Step num: 1478, Learning rate: 0.00005164, Avg batch loss: 0.6578, Avg batch acc: 0.3344
Train, Epoch: 1, Batch: 1479, Step num: 1479, Learning rate: 0.00005167, Avg batch loss: 0.7188, Avg batch acc: 0.3111
Train, Epoch: 1, Batch: 1480, Step num: 1480, Learning rate: 0.00005171, Avg batch loss: 0.7386, Avg batch acc: 0.3042
Train, Epoch: 1, Batch: 1481, Step num: 1481, Learning rate: 0.00005174, Avg batch loss: 0.6947, Avg batch acc: 0.3243
Train, Epoch: 1, Batch: 1482, Step num: 1482, Learning rate: 0.00005178, Avg batch loss: 0.6798, Avg batch acc: 0.3206
Train, Epoch: 1, Batch: 1483, Step num: 1483, Learning rate: 0.00005181, Avg batch loss: 0.6413, Avg batch acc: 0.3293
Train, Epoch: 1, Batch: 1484, Step num: 1484, Learning rate: 0.00005185, Avg batch loss: 0.7881, Avg batch acc: 0.3318
Train, Epoch: 1, Batch: 1485, Step num: 1485, Learning rate: 0.00005188, Avg batch loss: 0.7140, Avg batch acc: 0.3143
Train, Epoch: 1, Batch: 1486, Step num: 1486, Learning rate: 0.00005192, Avg batch loss: 0.6986, Avg batch acc: 0.3218
Train, Epoch: 1, Batch: 1487, Step num: 1487, Learning rate: 0.00005195, Avg batch loss: 0.7285, Avg batch acc: 0.3228
Train, Epoch: 1, Batch: 1488, Step num: 1488, Learning rate: 0.00005199, Avg batch loss: 0.7522, Avg batch acc: 0.3362
Train, Epoch: 1, Batch: 1489, Step num: 1489, Learning rate: 0.00005202, Avg batch loss: 0.6808, Avg batch acc: 0.3208
Train, Epoch: 1, Batch: 1490, Step num: 1490, Learning rate: 0.00005206, Avg batch loss: 0.7209, Avg batch acc: 0.3340
Train, Epoch: 1, Batch: 1491, Step num: 1491, Learning rate: 0.00005209, Avg batch loss: 0.6065, Avg batch acc: 0.3497
Train, Epoch: 1, Batch: 1492, Step num: 1492, Learning rate: 0.00005213, Avg batch loss: 0.6185, Avg batch acc: 0.3542
Train, Epoch: 1, Batch: 1493, Step num: 1493, Learning rate: 0.00005216, Avg batch loss: 0.6804, Avg batch acc: 0.3473
Train, Epoch: 1, Batch: 1494, Step num: 1494, Learning rate: 0.00005220, Avg batch loss: 0.6509, Avg batch acc: 0.3465
Train, Epoch: 1, Batch: 1495, Step num: 1495, Learning rate: 0.00005223, Avg batch loss: 0.6465, Avg batch acc: 0.3249
Train, Epoch: 1, Batch: 1496, Step num: 1496, Learning rate: 0.00005227, Avg batch loss: 0.7452, Avg batch acc: 0.3167
Train, Epoch: 1, Batch: 1497, Step num: 1497, Learning rate: 0.00005230, Avg batch loss: 0.7083, Avg batch acc: 0.3328
Train, Epoch: 1, Batch: 1498, Step num: 1498, Learning rate: 0.00005234, Avg batch loss: 0.7068, Avg batch acc: 0.3260
Train, Epoch: 1, Batch: 1499, Step num: 1499, Learning rate: 0.00005237, Avg batch loss: 0.7794, Avg batch acc: 0.3198
Train, Epoch: 1, Batch: 1500, Step num: 1500, Learning rate: 0.00005241, Avg batch loss: 0.7135, Avg batch acc: 0.3257
Train, Epoch: 1, Batch: 1501, Step num: 1501, Learning rate: 0.00005244, Avg batch loss: 0.7328, Avg batch acc: 0.3207
Train, Epoch: 1, Batch: 1502, Step num: 1502, Learning rate: 0.00005248, Avg batch loss: 0.7940, Avg batch acc: 0.3170
Train, Epoch: 1, Batch: 1503, Step num: 1503, Learning rate: 0.00005251, Avg batch loss: 0.7205, Avg batch acc: 0.3151
Train, Epoch: 1, Batch: 1504, Step num: 1504, Learning rate: 0.00005255, Avg batch loss: 0.7226, Avg batch acc: 0.2944
Train, Epoch: 1, Batch: 1505, Step num: 1505, Learning rate: 0.00005258, Avg batch loss: 0.7272, Avg batch acc: 0.3103
Train, Epoch: 1, Batch: 1506, Step num: 1506, Learning rate: 0.00005262, Avg batch loss: 0.6789, Avg batch acc: 0.3325
Train, Epoch: 1, Batch: 1507, Step num: 1507, Learning rate: 0.00005265, Avg batch loss: 0.6972, Avg batch acc: 0.3265
Train, Epoch: 1, Batch: 1508, Step num: 1508, Learning rate: 0.00005269, Avg batch loss: 0.7121, Avg batch acc: 0.3303
Train, Epoch: 1, Batch: 1509, Step num: 1509, Learning rate: 0.00005272, Avg batch loss: 0.7304, Avg batch acc: 0.3421
Train, Epoch: 1, Batch: 1510, Step num: 1510, Learning rate: 0.00005276, Avg batch loss: 0.7249, Avg batch acc: 0.3456
Train, Epoch: 1, Batch: 1511, Step num: 1511, Learning rate: 0.00005279, Avg batch loss: 0.7989, Avg batch acc: 0.3127
Train, Epoch: 1, Batch: 1512, Step num: 1512, Learning rate: 0.00005283, Avg batch loss: 0.6861, Avg batch acc: 0.3451
Train, Epoch: 1, Batch: 1513, Step num: 1513, Learning rate: 0.00005286, Avg batch loss: 0.6519, Avg batch acc: 0.3366
Train, Epoch: 1, Batch: 1514, Step num: 1514, Learning rate: 0.00005290, Avg batch loss: 0.7036, Avg batch acc: 0.3446
Train, Epoch: 1, Batch: 1515, Step num: 1515, Learning rate: 0.00005293, Avg batch loss: 0.6863, Avg batch acc: 0.3386
Train, Epoch: 1, Batch: 1516, Step num: 1516, Learning rate: 0.00005297, Avg batch loss: 0.7094, Avg batch acc: 0.3166
Train, Epoch: 1, Batch: 1517, Step num: 1517, Learning rate: 0.00005300, Avg batch loss: 0.7382, Avg batch acc: 0.3141
Train, Epoch: 1, Batch: 1518, Step num: 1518, Learning rate: 0.00005304, Avg batch loss: 0.7134, Avg batch acc: 0.3166
Train, Epoch: 1, Batch: 1519, Step num: 1519, Learning rate: 0.00005307, Avg batch loss: 0.6844, Avg batch acc: 0.3037
Train, Epoch: 1, Avg epoch loss: 1.1098, Avg epoch acc: 0.1916, Overall time: 989.8 s, Speed: 4397.5 tokens/s on cuda:1

Validate, Epoch: 1, Batch: 1, Avg batch loss: 0.7135, Avg batch acc: 0.3282
Validate, Epoch: 1, Batch: 2, Avg batch loss: 0.6658, Avg batch acc: 0.3320
Validate, Epoch: 1, Batch: 3, Avg batch loss: 0.6316, Avg batch acc: 0.3448
Validate, Epoch: 1, Batch: 4, Avg batch loss: 0.6561, Avg batch acc: 0.3431
Validate, Epoch: 1, Batch: 5, Avg batch loss: 0.6854, Avg batch acc: 0.3326
Validate, Epoch: 1, Batch: 6, Avg batch loss: 0.6918, Avg batch acc: 0.3383
Validate, Epoch: 1, Batch: 7, Avg batch loss: 0.7542, Avg batch acc: 0.3417
Validate, Epoch: 1, Batch: 8, Avg batch loss: 0.6896, Avg batch acc: 0.3184
Validate, Epoch: 1, Batch: 9, Avg batch loss: 0.7307, Avg batch acc: 0.3262
Validate, Epoch: 1, Batch: 10, Avg batch loss: 0.6988, Avg batch acc: 0.3087
Validate, Epoch: 1, Batch: 11, Avg batch loss: 0.6861, Avg batch acc: 0.3218
Validate, Epoch: 1, Batch: 12, Avg batch loss: 0.7034, Avg batch acc: 0.3291
Validate, Epoch: 1, Batch: 13, Avg batch loss: 0.6590, Avg batch acc: 0.3356
Validate, Epoch: 1, Batch: 14, Avg batch loss: 0.7089, Avg batch acc: 0.3293
Validate, Epoch: 1, Batch: 15, Avg batch loss: 0.6944, Avg batch acc: 0.3400
Validate, Epoch: 1, Batch: 16, Avg batch loss: 0.7686, Avg batch acc: 0.3123
Validate, Epoch: 1, Batch: 17, Avg batch loss: 0.6856, Avg batch acc: 0.3440
Validate, Epoch: 1, Batch: 18, Avg batch loss: 0.6963, Avg batch acc: 0.3300
Validate, Epoch: 1, Batch: 19, Avg batch loss: 0.6379, Avg batch acc: 0.3505
Validate, Epoch: 1, Batch: 20, Avg batch loss: 0.6922, Avg batch acc: 0.3378
Validate, Epoch: 1, Batch: 21, Avg batch loss: 0.7217, Avg batch acc: 0.3103
Validate, Epoch: 1, Batch: 22, Avg batch loss: 0.6711, Avg batch acc: 0.3199
Validate, Epoch: 1, Batch: 23, Avg batch loss: 0.7427, Avg batch acc: 0.3028
Validate, Epoch: 1, Batch: 24, Avg batch loss: 0.6552, Avg batch acc: 0.3358
Validate, Epoch: 1, Batch: 25, Avg batch loss: 0.6634, Avg batch acc: 0.3465
Validate, Epoch: 1, Batch: 26, Avg batch loss: 0.7959, Avg batch acc: 0.3003
Validate, Epoch: 1, Batch: 27, Avg batch loss: 0.7738, Avg batch acc: 0.3146
Validate, Epoch: 1, Batch: 28, Avg batch loss: 0.7365, Avg batch acc: 0.3163
Validate, Epoch: 1, Batch: 29, Avg batch loss: 0.7104, Avg batch acc: 0.3232
Validate, Epoch: 1, Batch: 30, Avg batch loss: 0.6322, Avg batch acc: 0.3477
Validate, Epoch: 1, Batch: 31, Avg batch loss: 0.6813, Avg batch acc: 0.3301
Validate, Epoch: 1, Batch: 32, Avg batch loss: 0.7302, Avg batch acc: 0.3428
Validate, Epoch: 1, Batch: 33, Avg batch loss: 0.6463, Avg batch acc: 0.3354
Validate, Epoch: 1, Batch: 34, Avg batch loss: 0.6580, Avg batch acc: 0.3539
Validate, Epoch: 1, Batch: 35, Avg batch loss: 0.7087, Avg batch acc: 0.3404
Validate, Epoch: 1, Batch: 36, Avg batch loss: 0.6643, Avg batch acc: 0.3243
Validate, Epoch: 1, Batch: 37, Avg batch loss: 0.7289, Avg batch acc: 0.3273
Validate, Epoch: 1, Batch: 38, Avg batch loss: 0.7571, Avg batch acc: 0.3246
Validate, Epoch: 1, Batch: 39, Avg batch loss: 0.7076, Avg batch acc: 0.3116
Validate, Epoch: 1, Batch: 40, Avg batch loss: 0.7361, Avg batch acc: 0.3576
Validate, Epoch: 1, Batch: 41, Avg batch loss: 0.7322, Avg batch acc: 0.3323
Validate, Epoch: 1, Batch: 42, Avg batch loss: 0.6672, Avg batch acc: 0.3279
Validate, Epoch: 1, Batch: 43, Avg batch loss: 0.7472, Avg batch acc: 0.3339
Validate, Epoch: 1, Batch: 44, Avg batch loss: 0.6992, Avg batch acc: 0.3231
Validate, Epoch: 1, Batch: 45, Avg batch loss: 0.7016, Avg batch acc: 0.3125
Validate, Epoch: 1, Batch: 46, Avg batch loss: 0.7821, Avg batch acc: 0.3072
Validate, Epoch: 1, Batch: 47, Avg batch loss: 0.7121, Avg batch acc: 0.3261
Validate, Epoch: 1, Batch: 48, Avg batch loss: 0.6772, Avg batch acc: 0.3422
Validate, Epoch: 1, Batch: 49, Avg batch loss: 0.6319, Avg batch acc: 0.3119
Validate, Epoch: 1, Batch: 50, Avg batch loss: 0.7793, Avg batch acc: 0.3030
Validate, Epoch: 1, Batch: 51, Avg batch loss: 0.7040, Avg batch acc: 0.3210
Validate, Epoch: 1, Batch: 52, Avg batch loss: 0.7106, Avg batch acc: 0.3123
Validate, Epoch: 1, Batch: 53, Avg batch loss: 0.7154, Avg batch acc: 0.3155
Validate, Epoch: 1, Batch: 54, Avg batch loss: 0.6738, Avg batch acc: 0.3509
Validate, Epoch: 1, Batch: 55, Avg batch loss: 0.7306, Avg batch acc: 0.3268
Validate, Epoch: 1, Batch: 56, Avg batch loss: 0.6960, Avg batch acc: 0.3268
Validate, Epoch: 1, Batch: 57, Avg batch loss: 0.6951, Avg batch acc: 0.3348
Validate, Epoch: 1, Batch: 58, Avg batch loss: 0.7296, Avg batch acc: 0.3299
Validate, Epoch: 1, Batch: 59, Avg batch loss: 0.7971, Avg batch acc: 0.3096
Validate, Epoch: 1, Batch: 60, Avg batch loss: 0.7234, Avg batch acc: 0.3286
Validate, Epoch: 1, Batch: 61, Avg batch loss: 0.6693, Avg batch acc: 0.3321
Validate, Epoch: 1, Batch: 62, Avg batch loss: 0.6227, Avg batch acc: 0.3291
Validate, Epoch: 1, Batch: 63, Avg batch loss: 0.6981, Avg batch acc: 0.3192
Validate, Epoch: 1, Batch: 64, Avg batch loss: 0.7241, Avg batch acc: 0.3261
Validate, Epoch: 1, Batch: 65, Avg batch loss: 0.7554, Avg batch acc: 0.3225
Validate, Epoch: 1, Batch: 66, Avg batch loss: 0.6941, Avg batch acc: 0.3363
Validate, Epoch: 1, Batch: 67, Avg batch loss: 0.7173, Avg batch acc: 0.3384
Validate, Epoch: 1, Batch: 68, Avg batch loss: 0.7572, Avg batch acc: 0.3250
Validate, Epoch: 1, Batch: 69, Avg batch loss: 0.7227, Avg batch acc: 0.3282
Validate, Epoch: 1, Batch: 70, Avg batch loss: 0.7750, Avg batch acc: 0.3075
Validate, Epoch: 1, Batch: 71, Avg batch loss: 0.7667, Avg batch acc: 0.3293
Validate, Epoch: 1, Batch: 72, Avg batch loss: 0.6001, Avg batch acc: 0.3643
Validate, Epoch: 1, Batch: 73, Avg batch loss: 0.6688, Avg batch acc: 0.3222
Validate, Epoch: 1, Batch: 74, Avg batch loss: 0.7470, Avg batch acc: 0.3291
Validate, Epoch: 1, Batch: 75, Avg batch loss: 0.6918, Avg batch acc: 0.3296
Validate, Epoch: 1, Batch: 76, Avg batch loss: 0.6677, Avg batch acc: 0.3440
Validate, Epoch: 1, Batch: 77, Avg batch loss: 0.7116, Avg batch acc: 0.3309
Validate, Epoch: 1, Batch: 78, Avg batch loss: 0.7012, Avg batch acc: 0.3317
Validate, Epoch: 1, Batch: 79, Avg batch loss: 0.6986, Avg batch acc: 0.2917
Validate, Epoch: 1, Batch: 80, Avg batch loss: 0.6704, Avg batch acc: 0.3268
Validate, Epoch: 1, Batch: 81, Avg batch loss: 0.6507, Avg batch acc: 0.3327
Validate, Epoch: 1, Batch: 82, Avg batch loss: 0.6873, Avg batch acc: 0.3366
Validate, Epoch: 1, Batch: 83, Avg batch loss: 0.6947, Avg batch acc: 0.3416
Validate, Epoch: 1, Batch: 84, Avg batch loss: 0.7148, Avg batch acc: 0.3196
Validate, Epoch: 1, Batch: 85, Avg batch loss: 0.6828, Avg batch acc: 0.3475
Validate, Epoch: 1, Batch: 86, Avg batch loss: 0.6992, Avg batch acc: 0.3410
Validate, Epoch: 1, Batch: 87, Avg batch loss: 0.6507, Avg batch acc: 0.3345
Validate, Epoch: 1, Batch: 88, Avg batch loss: 0.7954, Avg batch acc: 0.3202
Validate, Epoch: 1, Batch: 89, Avg batch loss: 0.7119, Avg batch acc: 0.3140
Validate, Epoch: 1, Batch: 90, Avg batch loss: 0.7271, Avg batch acc: 0.3138
Validate, Epoch: 1, Batch: 91, Avg batch loss: 0.7098, Avg batch acc: 0.3150
Validate, Epoch: 1, Batch: 92, Avg batch loss: 0.6982, Avg batch acc: 0.3264
Validate, Epoch: 1, Batch: 93, Avg batch loss: 0.6536, Avg batch acc: 0.3243
Validate, Epoch: 1, Batch: 94, Avg batch loss: 0.7560, Avg batch acc: 0.3368
Validate, Epoch: 1, Batch: 95, Avg batch loss: 0.7381, Avg batch acc: 0.3104
Validate, Epoch: 1, Batch: 96, Avg batch loss: 0.7299, Avg batch acc: 0.3090
Validate, Epoch: 1, Batch: 97, Avg batch loss: 0.6778, Avg batch acc: 0.3314
Validate, Epoch: 1, Batch: 98, Avg batch loss: 0.7076, Avg batch acc: 0.3259
Validate, Epoch: 1, Batch: 99, Avg batch loss: 0.7226, Avg batch acc: 0.3128
Validate, Epoch: 1, Batch: 100, Avg batch loss: 0.7030, Avg batch acc: 0.3190
Validate, Epoch: 1, Batch: 101, Avg batch loss: 0.7361, Avg batch acc: 0.3306
Validate, Epoch: 1, Batch: 102, Avg batch loss: 0.6884, Avg batch acc: 0.3370
Validate, Epoch: 1, Batch: 103, Avg batch loss: 0.6552, Avg batch acc: 0.3458
Validate, Epoch: 1, Batch: 104, Avg batch loss: 0.7077, Avg batch acc: 0.3149
Validate, Epoch: 1, Batch: 105, Avg batch loss: 0.7070, Avg batch acc: 0.3277
Validate, Epoch: 1, Batch: 106, Avg batch loss: 0.6676, Avg batch acc: 0.3275
Validate, Epoch: 1, Batch: 107, Avg batch loss: 0.7515, Avg batch acc: 0.3077
Validate, Epoch: 1, Batch: 108, Avg batch loss: 0.7300, Avg batch acc: 0.3058
Validate, Epoch: 1, Batch: 109, Avg batch loss: 0.6987, Avg batch acc: 0.3068
Validate, Epoch: 1, Batch: 110, Avg batch loss: 0.6674, Avg batch acc: 0.3363
Validate, Epoch: 1, Batch: 111, Avg batch loss: 0.6581, Avg batch acc: 0.3350
Validate, Epoch: 1, Batch: 112, Avg batch loss: 0.7047, Avg batch acc: 0.3214
Validate, Epoch: 1, Batch: 113, Avg batch loss: 0.6692, Avg batch acc: 0.3242
Validate, Epoch: 1, Batch: 114, Avg batch loss: 0.7201, Avg batch acc: 0.3170
Validate, Epoch: 1, Batch: 115, Avg batch loss: 0.6657, Avg batch acc: 0.3347
Validate, Epoch: 1, Batch: 116, Avg batch loss: 0.6508, Avg batch acc: 0.3231
Validate, Epoch: 1, Batch: 117, Avg batch loss: 0.6990, Avg batch acc: 0.3082
Validate, Epoch: 1, Batch: 118, Avg batch loss: 0.6910, Avg batch acc: 0.3453
Validate, Epoch: 1, Batch: 119, Avg batch loss: 0.7110, Avg batch acc: 0.3198
Validate, Epoch: 1, Batch: 120, Avg batch loss: 0.7250, Avg batch acc: 0.3235
Validate, Epoch: 1, Batch: 121, Avg batch loss: 0.7256, Avg batch acc: 0.3066
Validate, Epoch: 1, Batch: 122, Avg batch loss: 0.7137, Avg batch acc: 0.3462
Validate, Epoch: 1, Batch: 123, Avg batch loss: 0.7348, Avg batch acc: 0.3246
Validate, Epoch: 1, Batch: 124, Avg batch loss: 0.6610, Avg batch acc: 0.3446
Validate, Epoch: 1, Batch: 125, Avg batch loss: 0.7560, Avg batch acc: 0.3199
Validate, Epoch: 1, Batch: 126, Avg batch loss: 0.7496, Avg batch acc: 0.3189
Validate, Epoch: 1, Batch: 127, Avg batch loss: 0.6628, Avg batch acc: 0.3284
Validate, Epoch: 1, Batch: 128, Avg batch loss: 0.7628, Avg batch acc: 0.3239
Validate, Epoch: 1, Batch: 129, Avg batch loss: 0.7320, Avg batch acc: 0.3273
Validate, Epoch: 1, Batch: 130, Avg batch loss: 0.6815, Avg batch acc: 0.3205
Validate, Epoch: 1, Batch: 131, Avg batch loss: 0.6854, Avg batch acc: 0.3371
Validate, Epoch: 1, Batch: 132, Avg batch loss: 0.7175, Avg batch acc: 0.3244
Validate, Epoch: 1, Batch: 133, Avg batch loss: 0.7173, Avg batch acc: 0.3164
Validate, Epoch: 1, Batch: 134, Avg batch loss: 0.7531, Avg batch acc: 0.3208
Validate, Epoch: 1, Batch: 135, Avg batch loss: 0.7570, Avg batch acc: 0.3257
Validate, Epoch: 1, Batch: 136, Avg batch loss: 0.7282, Avg batch acc: 0.3057
Validate, Epoch: 1, Batch: 137, Avg batch loss: 0.6540, Avg batch acc: 0.3365
Validate, Epoch: 1, Batch: 138, Avg batch loss: 0.6996, Avg batch acc: 0.3123
Validate, Epoch: 1, Batch: 139, Avg batch loss: 0.7241, Avg batch acc: 0.3437
Validate, Epoch: 1, Batch: 140, Avg batch loss: 0.6486, Avg batch acc: 0.3381
Validate, Epoch: 1, Batch: 141, Avg batch loss: 0.6749, Avg batch acc: 0.3439
Validate, Epoch: 1, Batch: 142, Avg batch loss: 0.7244, Avg batch acc: 0.3410
Validate, Epoch: 1, Batch: 143, Avg batch loss: 0.7269, Avg batch acc: 0.3060
Validate, Epoch: 1, Batch: 144, Avg batch loss: 0.7621, Avg batch acc: 0.3005
Validate, Epoch: 1, Batch: 145, Avg batch loss: 0.6996, Avg batch acc: 0.3358
Validate, Epoch: 1, Batch: 146, Avg batch loss: 0.7360, Avg batch acc: 0.3245
Validate, Epoch: 1, Batch: 147, Avg batch loss: 0.7565, Avg batch acc: 0.3347
Validate, Epoch: 1, Batch: 148, Avg batch loss: 0.7410, Avg batch acc: 0.3159
Validate, Epoch: 1, Batch: 149, Avg batch loss: 0.8035, Avg batch acc: 0.3293
Validate, Epoch: 1, Batch: 150, Avg batch loss: 0.6860, Avg batch acc: 0.3208
Validate, Epoch: 1, Batch: 151, Avg batch loss: 0.6549, Avg batch acc: 0.3167
Validate, Epoch: 1, Batch: 152, Avg batch loss: 0.7002, Avg batch acc: 0.3279
Validate, Epoch: 1, Batch: 153, Avg batch loss: 0.7667, Avg batch acc: 0.3072
Validate, Epoch: 1, Batch: 154, Avg batch loss: 0.6758, Avg batch acc: 0.3437
Validate, Epoch: 1, Batch: 155, Avg batch loss: 0.7744, Avg batch acc: 0.3225
Validate, Epoch: 1, Batch: 156, Avg batch loss: 0.7137, Avg batch acc: 0.3339
Validate, Epoch: 1, Batch: 157, Avg batch loss: 0.7109, Avg batch acc: 0.3332
Validate, Epoch: 1, Batch: 158, Avg batch loss: 0.7075, Avg batch acc: 0.3054
Validate, Epoch: 1, Batch: 159, Avg batch loss: 0.6925, Avg batch acc: 0.3261
Validate, Epoch: 1, Batch: 160, Avg batch loss: 0.7250, Avg batch acc: 0.3356
Validate, Epoch: 1, Batch: 161, Avg batch loss: 0.6773, Avg batch acc: 0.3295
Validate, Epoch: 1, Batch: 162, Avg batch loss: 0.7336, Avg batch acc: 0.3325
Validate, Epoch: 1, Batch: 163, Avg batch loss: 0.6704, Avg batch acc: 0.3248
Validate, Epoch: 1, Batch: 164, Avg batch loss: 0.7353, Avg batch acc: 0.3242
Validate, Epoch: 1, Batch: 165, Avg batch loss: 0.6998, Avg batch acc: 0.3439
Validate, Epoch: 1, Batch: 166, Avg batch loss: 0.6785, Avg batch acc: 0.3339
Validate, Epoch: 1, Batch: 167, Avg batch loss: 0.7557, Avg batch acc: 0.3127
Validate, Epoch: 1, Batch: 168, Avg batch loss: 0.6439, Avg batch acc: 0.3561
Validate, Epoch: 1, Batch: 169, Avg batch loss: 0.6940, Avg batch acc: 0.3319
Validate, Epoch: 1, Avg epoch loss: 0.7062, Avg epoch acc: 0.3270, Overall time: 36.3 s, Speed: 13272.3 tokens/s on cuda:1

Train, Epoch: 2, Batch: 1, Step num: 1520, Learning rate: 0.00005311, Avg batch loss: 0.7201, Avg batch acc: 0.3201
Train, Epoch: 2, Batch: 2, Step num: 1521, Learning rate: 0.00005314, Avg batch loss: 0.7756, Avg batch acc: 0.3271
Train, Epoch: 2, Batch: 3, Step num: 1522, Learning rate: 0.00005318, Avg batch loss: 0.6276, Avg batch acc: 0.3343
Train, Epoch: 2, Batch: 4, Step num: 1523, Learning rate: 0.00005321, Avg batch loss: 0.6829, Avg batch acc: 0.3404
Train, Epoch: 2, Batch: 5, Step num: 1524, Learning rate: 0.00005325, Avg batch loss: 0.6861, Avg batch acc: 0.3442
Train, Epoch: 2, Batch: 6, Step num: 1525, Learning rate: 0.00005328, Avg batch loss: 0.7053, Avg batch acc: 0.3097
Train, Epoch: 2, Batch: 7, Step num: 1526, Learning rate: 0.00005332, Avg batch loss: 0.7856, Avg batch acc: 0.3214
Train, Epoch: 2, Batch: 8, Step num: 1527, Learning rate: 0.00005335, Avg batch loss: 0.6963, Avg batch acc: 0.3414
Train, Epoch: 2, Batch: 9, Step num: 1528, Learning rate: 0.00005339, Avg batch loss: 0.7705, Avg batch acc: 0.3099
Train, Epoch: 2, Batch: 10, Step num: 1529, Learning rate: 0.00005342, Avg batch loss: 0.7205, Avg batch acc: 0.3312
Train, Epoch: 2, Batch: 11, Step num: 1530, Learning rate: 0.00005346, Avg batch loss: 0.6177, Avg batch acc: 0.3545
Train, Epoch: 2, Batch: 12, Step num: 1531, Learning rate: 0.00005349, Avg batch loss: 0.6602, Avg batch acc: 0.3640
Train, Epoch: 2, Batch: 13, Step num: 1532, Learning rate: 0.00005353, Avg batch loss: 0.6806, Avg batch acc: 0.3249
Train, Epoch: 2, Batch: 14, Step num: 1533, Learning rate: 0.00005356, Avg batch loss: 0.7453, Avg batch acc: 0.3081
Train, Epoch: 2, Batch: 15, Step num: 1534, Learning rate: 0.00005360, Avg batch loss: 0.7196, Avg batch acc: 0.3010
Train, Epoch: 2, Batch: 16, Step num: 1535, Learning rate: 0.00005363, Avg batch loss: 0.7330, Avg batch acc: 0.3355
Train, Epoch: 2, Batch: 17, Step num: 1536, Learning rate: 0.00005367, Avg batch loss: 0.7012, Avg batch acc: 0.3585
Train, Epoch: 2, Batch: 18, Step num: 1537, Learning rate: 0.00005370, Avg batch loss: 0.7415, Avg batch acc: 0.3297
Train, Epoch: 2, Batch: 19, Step num: 1538, Learning rate: 0.00005374, Avg batch loss: 0.6742, Avg batch acc: 0.3575
Train, Epoch: 2, Batch: 20, Step num: 1539, Learning rate: 0.00005377, Avg batch loss: 0.6987, Avg batch acc: 0.3197
Train, Epoch: 2, Batch: 21, Step num: 1540, Learning rate: 0.00005381, Avg batch loss: 0.6645, Avg batch acc: 0.3364
Train, Epoch: 2, Batch: 22, Step num: 1541, Learning rate: 0.00005384, Avg batch loss: 0.7303, Avg batch acc: 0.3302
Train, Epoch: 2, Batch: 23, Step num: 1542, Learning rate: 0.00005388, Avg batch loss: 0.6842, Avg batch acc: 0.3228
Train, Epoch: 2, Batch: 24, Step num: 1543, Learning rate: 0.00005391, Avg batch loss: 0.7281, Avg batch acc: 0.3308
Train, Epoch: 2, Batch: 25, Step num: 1544, Learning rate: 0.00005395, Avg batch loss: 0.7382, Avg batch acc: 0.3222
Train, Epoch: 2, Batch: 26, Step num: 1545, Learning rate: 0.00005398, Avg batch loss: 0.6555, Avg batch acc: 0.3487
Train, Epoch: 2, Batch: 27, Step num: 1546, Learning rate: 0.00005402, Avg batch loss: 0.6343, Avg batch acc: 0.3420
Train, Epoch: 2, Batch: 28, Step num: 1547, Learning rate: 0.00005405, Avg batch loss: 0.7108, Avg batch acc: 0.3283
Train, Epoch: 2, Batch: 29, Step num: 1548, Learning rate: 0.00005408, Avg batch loss: 0.6671, Avg batch acc: 0.3219
Train, Epoch: 2, Batch: 30, Step num: 1549, Learning rate: 0.00005412, Avg batch loss: 0.7683, Avg batch acc: 0.3198
Train, Epoch: 2, Batch: 31, Step num: 1550, Learning rate: 0.00005415, Avg batch loss: 0.7184, Avg batch acc: 0.3116
Train, Epoch: 2, Batch: 32, Step num: 1551, Learning rate: 0.00005419, Avg batch loss: 0.7112, Avg batch acc: 0.3456
Train, Epoch: 2, Batch: 33, Step num: 1552, Learning rate: 0.00005422, Avg batch loss: 0.7342, Avg batch acc: 0.3208
Train, Epoch: 2, Batch: 34, Step num: 1553, Learning rate: 0.00005426, Avg batch loss: 0.6615, Avg batch acc: 0.3227
Train, Epoch: 2, Batch: 35, Step num: 1554, Learning rate: 0.00005429, Avg batch loss: 0.7190, Avg batch acc: 0.3335
Train, Epoch: 2, Batch: 36, Step num: 1555, Learning rate: 0.00005433, Avg batch loss: 0.6477, Avg batch acc: 0.3291
Train, Epoch: 2, Batch: 37, Step num: 1556, Learning rate: 0.00005436, Avg batch loss: 0.6977, Avg batch acc: 0.3204
Train, Epoch: 2, Batch: 38, Step num: 1557, Learning rate: 0.00005440, Avg batch loss: 0.7057, Avg batch acc: 0.3115
Train, Epoch: 2, Batch: 39, Step num: 1558, Learning rate: 0.00005443, Avg batch loss: 0.7701, Avg batch acc: 0.3186
Train, Epoch: 2, Batch: 40, Step num: 1559, Learning rate: 0.00005447, Avg batch loss: 0.7175, Avg batch acc: 0.3426
Train, Epoch: 2, Batch: 41, Step num: 1560, Learning rate: 0.00005450, Avg batch loss: 0.7428, Avg batch acc: 0.3202
Train, Epoch: 2, Batch: 42, Step num: 1561, Learning rate: 0.00005454, Avg batch loss: 0.6996, Avg batch acc: 0.3373
Train, Epoch: 2, Batch: 43, Step num: 1562, Learning rate: 0.00005457, Avg batch loss: 0.7122, Avg batch acc: 0.3286
Train, Epoch: 2, Batch: 44, Step num: 1563, Learning rate: 0.00005461, Avg batch loss: 0.7519, Avg batch acc: 0.3372
Train, Epoch: 2, Batch: 45, Step num: 1564, Learning rate: 0.00005464, Avg batch loss: 0.7128, Avg batch acc: 0.3475
Train, Epoch: 2, Batch: 46, Step num: 1565, Learning rate: 0.00005468, Avg batch loss: 0.7251, Avg batch acc: 0.3309
Train, Epoch: 2, Batch: 47, Step num: 1566, Learning rate: 0.00005471, Avg batch loss: 0.7227, Avg batch acc: 0.3260
Train, Epoch: 2, Batch: 48, Step num: 1567, Learning rate: 0.00005475, Avg batch loss: 0.6890, Avg batch acc: 0.3543
Train, Epoch: 2, Batch: 49, Step num: 1568, Learning rate: 0.00005478, Avg batch loss: 0.7397, Avg batch acc: 0.3295
Train, Epoch: 2, Batch: 50, Step num: 1569, Learning rate: 0.00005482, Avg batch loss: 0.7142, Avg batch acc: 0.3335
Train, Epoch: 2, Batch: 51, Step num: 1570, Learning rate: 0.00005485, Avg batch loss: 0.7544, Avg batch acc: 0.3156
Train, Epoch: 2, Batch: 52, Step num: 1571, Learning rate: 0.00005489, Avg batch loss: 0.6243, Avg batch acc: 0.3310
Train, Epoch: 2, Batch: 53, Step num: 1572, Learning rate: 0.00005492, Avg batch loss: 0.7245, Avg batch acc: 0.3273
Train, Epoch: 2, Batch: 54, Step num: 1573, Learning rate: 0.00005496, Avg batch loss: 0.7367, Avg batch acc: 0.3251
Train, Epoch: 2, Batch: 55, Step num: 1574, Learning rate: 0.00005499, Avg batch loss: 0.6700, Avg batch acc: 0.3504
Train, Epoch: 2, Batch: 56, Step num: 1575, Learning rate: 0.00005503, Avg batch loss: 0.7534, Avg batch acc: 0.3168
Train, Epoch: 2, Batch: 57, Step num: 1576, Learning rate: 0.00005506, Avg batch loss: 0.7393, Avg batch acc: 0.3375
Train, Epoch: 2, Batch: 58, Step num: 1577, Learning rate: 0.00005510, Avg batch loss: 0.7766, Avg batch acc: 0.3327
Train, Epoch: 2, Batch: 59, Step num: 1578, Learning rate: 0.00005513, Avg batch loss: 0.6777, Avg batch acc: 0.3435
Train, Epoch: 2, Batch: 60, Step num: 1579, Learning rate: 0.00005517, Avg batch loss: 0.7367, Avg batch acc: 0.3417
Train, Epoch: 2, Batch: 61, Step num: 1580, Learning rate: 0.00005520, Avg batch loss: 0.7306, Avg batch acc: 0.3299
Train, Epoch: 2, Batch: 62, Step num: 1581, Learning rate: 0.00005524, Avg batch loss: 0.7095, Avg batch acc: 0.3281
Train, Epoch: 2, Batch: 63, Step num: 1582, Learning rate: 0.00005527, Avg batch loss: 0.6869, Avg batch acc: 0.3383
Train, Epoch: 2, Batch: 64, Step num: 1583, Learning rate: 0.00005531, Avg batch loss: 0.7227, Avg batch acc: 0.3443
Train, Epoch: 2, Batch: 65, Step num: 1584, Learning rate: 0.00005534, Avg batch loss: 0.7778, Avg batch acc: 0.3156
Train, Epoch: 2, Batch: 66, Step num: 1585, Learning rate: 0.00005538, Avg batch loss: 0.7312, Avg batch acc: 0.3247
Train, Epoch: 2, Batch: 67, Step num: 1586, Learning rate: 0.00005541, Avg batch loss: 0.7113, Avg batch acc: 0.3198
Train, Epoch: 2, Batch: 68, Step num: 1587, Learning rate: 0.00005545, Avg batch loss: 0.6391, Avg batch acc: 0.3671
Train, Epoch: 2, Batch: 69, Step num: 1588, Learning rate: 0.00005548, Avg batch loss: 0.6979, Avg batch acc: 0.3164
Train, Epoch: 2, Batch: 70, Step num: 1589, Learning rate: 0.00005552, Avg batch loss: 0.7265, Avg batch acc: 0.3275
Train, Epoch: 2, Batch: 71, Step num: 1590, Learning rate: 0.00005555, Avg batch loss: 0.6803, Avg batch acc: 0.3490
Train, Epoch: 2, Batch: 72, Step num: 1591, Learning rate: 0.00005559, Avg batch loss: 0.7183, Avg batch acc: 0.3076
Train, Epoch: 2, Batch: 73, Step num: 1592, Learning rate: 0.00005562, Avg batch loss: 0.6230, Avg batch acc: 0.3380
Train, Epoch: 2, Batch: 74, Step num: 1593, Learning rate: 0.00005566, Avg batch loss: 0.7919, Avg batch acc: 0.3332
Train, Epoch: 2, Batch: 75, Step num: 1594, Learning rate: 0.00005569, Avg batch loss: 0.7251, Avg batch acc: 0.3432
Train, Epoch: 2, Batch: 76, Step num: 1595, Learning rate: 0.00005573, Avg batch loss: 0.6982, Avg batch acc: 0.3231
Train, Epoch: 2, Batch: 77, Step num: 1596, Learning rate: 0.00005576, Avg batch loss: 0.6919, Avg batch acc: 0.3357
Train, Epoch: 2, Batch: 78, Step num: 1597, Learning rate: 0.00005580, Avg batch loss: 0.6866, Avg batch acc: 0.3286
Train, Epoch: 2, Batch: 79, Step num: 1598, Learning rate: 0.00005583, Avg batch loss: 0.6990, Avg batch acc: 0.3391
Train, Epoch: 2, Batch: 80, Step num: 1599, Learning rate: 0.00005587, Avg batch loss: 0.7067, Avg batch acc: 0.3291
Train, Epoch: 2, Batch: 81, Step num: 1600, Learning rate: 0.00005590, Avg batch loss: 0.6886, Avg batch acc: 0.3473
Train, Epoch: 2, Batch: 82, Step num: 1601, Learning rate: 0.00005594, Avg batch loss: 0.7270, Avg batch acc: 0.3452
Train, Epoch: 2, Batch: 83, Step num: 1602, Learning rate: 0.00005597, Avg batch loss: 0.7135, Avg batch acc: 0.3313
Train, Epoch: 2, Batch: 84, Step num: 1603, Learning rate: 0.00005601, Avg batch loss: 0.6629, Avg batch acc: 0.3308
Train, Epoch: 2, Batch: 85, Step num: 1604, Learning rate: 0.00005604, Avg batch loss: 0.6705, Avg batch acc: 0.3636
Train, Epoch: 2, Batch: 86, Step num: 1605, Learning rate: 0.00005608, Avg batch loss: 0.7118, Avg batch acc: 0.3349
Train, Epoch: 2, Batch: 87, Step num: 1606, Learning rate: 0.00005611, Avg batch loss: 0.7096, Avg batch acc: 0.3373
Train, Epoch: 2, Batch: 88, Step num: 1607, Learning rate: 0.00005615, Avg batch loss: 0.6485, Avg batch acc: 0.3425
Train, Epoch: 2, Batch: 89, Step num: 1608, Learning rate: 0.00005618, Avg batch loss: 0.7435, Avg batch acc: 0.3236
Train, Epoch: 2, Batch: 90, Step num: 1609, Learning rate: 0.00005622, Avg batch loss: 0.7143, Avg batch acc: 0.3343
Train, Epoch: 2, Batch: 91, Step num: 1610, Learning rate: 0.00005625, Avg batch loss: 0.7134, Avg batch acc: 0.3459
Train, Epoch: 2, Batch: 92, Step num: 1611, Learning rate: 0.00005629, Avg batch loss: 0.6263, Avg batch acc: 0.3694
Train, Epoch: 2, Batch: 93, Step num: 1612, Learning rate: 0.00005632, Avg batch loss: 0.6935, Avg batch acc: 0.3241
Train, Epoch: 2, Batch: 94, Step num: 1613, Learning rate: 0.00005636, Avg batch loss: 0.7020, Avg batch acc: 0.3458
Train, Epoch: 2, Batch: 95, Step num: 1614, Learning rate: 0.00005639, Avg batch loss: 0.6567, Avg batch acc: 0.3341
Train, Epoch: 2, Batch: 96, Step num: 1615, Learning rate: 0.00005643, Avg batch loss: 0.7038, Avg batch acc: 0.3332
Train, Epoch: 2, Batch: 97, Step num: 1616, Learning rate: 0.00005646, Avg batch loss: 0.7139, Avg batch acc: 0.3525
Train, Epoch: 2, Batch: 98, Step num: 1617, Learning rate: 0.00005650, Avg batch loss: 0.6883, Avg batch acc: 0.3221
Train, Epoch: 2, Batch: 99, Step num: 1618, Learning rate: 0.00005653, Avg batch loss: 0.7104, Avg batch acc: 0.3403
Train, Epoch: 2, Batch: 100, Step num: 1619, Learning rate: 0.00005657, Avg batch loss: 0.6561, Avg batch acc: 0.3441
Train, Epoch: 2, Batch: 101, Step num: 1620, Learning rate: 0.00005660, Avg batch loss: 0.7583, Avg batch acc: 0.3224
Train, Epoch: 2, Batch: 102, Step num: 1621, Learning rate: 0.00005664, Avg batch loss: 0.6517, Avg batch acc: 0.3509
Train, Epoch: 2, Batch: 103, Step num: 1622, Learning rate: 0.00005667, Avg batch loss: 0.6855, Avg batch acc: 0.3500
Train, Epoch: 2, Batch: 104, Step num: 1623, Learning rate: 0.00005671, Avg batch loss: 0.6808, Avg batch acc: 0.3363
Train, Epoch: 2, Batch: 105, Step num: 1624, Learning rate: 0.00005674, Avg batch loss: 0.7469, Avg batch acc: 0.3450
Train, Epoch: 2, Batch: 106, Step num: 1625, Learning rate: 0.00005678, Avg batch loss: 0.7039, Avg batch acc: 0.3194
Train, Epoch: 2, Batch: 107, Step num: 1626, Learning rate: 0.00005681, Avg batch loss: 0.6985, Avg batch acc: 0.3392
Train, Epoch: 2, Batch: 108, Step num: 1627, Learning rate: 0.00005685, Avg batch loss: 0.7170, Avg batch acc: 0.3313
Train, Epoch: 2, Batch: 109, Step num: 1628, Learning rate: 0.00005688, Avg batch loss: 0.7226, Avg batch acc: 0.3502
Train, Epoch: 2, Batch: 110, Step num: 1629, Learning rate: 0.00005691, Avg batch loss: 0.7191, Avg batch acc: 0.3339
Train, Epoch: 2, Batch: 111, Step num: 1630, Learning rate: 0.00005695, Avg batch loss: 0.7223, Avg batch acc: 0.3423
Train, Epoch: 2, Batch: 112, Step num: 1631, Learning rate: 0.00005698, Avg batch loss: 0.7067, Avg batch acc: 0.3557
Train, Epoch: 2, Batch: 113, Step num: 1632, Learning rate: 0.00005702, Avg batch loss: 0.6571, Avg batch acc: 0.3559
Train, Epoch: 2, Batch: 114, Step num: 1633, Learning rate: 0.00005705, Avg batch loss: 0.6830, Avg batch acc: 0.3346
Train, Epoch: 2, Batch: 115, Step num: 1634, Learning rate: 0.00005709, Avg batch loss: 0.7673, Avg batch acc: 0.3397
Train, Epoch: 2, Batch: 116, Step num: 1635, Learning rate: 0.00005712, Avg batch loss: 0.6791, Avg batch acc: 0.3376
Train, Epoch: 2, Batch: 117, Step num: 1636, Learning rate: 0.00005716, Avg batch loss: 0.7530, Avg batch acc: 0.3263
Train, Epoch: 2, Batch: 118, Step num: 1637, Learning rate: 0.00005719, Avg batch loss: 0.7396, Avg batch acc: 0.3403
Train, Epoch: 2, Batch: 119, Step num: 1638, Learning rate: 0.00005723, Avg batch loss: 0.6909, Avg batch acc: 0.3385
Train, Epoch: 2, Batch: 120, Step num: 1639, Learning rate: 0.00005726, Avg batch loss: 0.7051, Avg batch acc: 0.3307
Train, Epoch: 2, Batch: 121, Step num: 1640, Learning rate: 0.00005730, Avg batch loss: 0.7245, Avg batch acc: 0.3535
Train, Epoch: 2, Batch: 122, Step num: 1641, Learning rate: 0.00005733, Avg batch loss: 0.6908, Avg batch acc: 0.3359
Train, Epoch: 2, Batch: 123, Step num: 1642, Learning rate: 0.00005737, Avg batch loss: 0.6725, Avg batch acc: 0.3594
Train, Epoch: 2, Batch: 124, Step num: 1643, Learning rate: 0.00005740, Avg batch loss: 0.7392, Avg batch acc: 0.3248
Train, Epoch: 2, Batch: 125, Step num: 1644, Learning rate: 0.00005744, Avg batch loss: 0.7306, Avg batch acc: 0.3562
Train, Epoch: 2, Batch: 126, Step num: 1645, Learning rate: 0.00005747, Avg batch loss: 0.7085, Avg batch acc: 0.3396
Train, Epoch: 2, Batch: 127, Step num: 1646, Learning rate: 0.00005751, Avg batch loss: 0.7121, Avg batch acc: 0.3346
Train, Epoch: 2, Batch: 128, Step num: 1647, Learning rate: 0.00005754, Avg batch loss: 0.7608, Avg batch acc: 0.3447
Train, Epoch: 2, Batch: 129, Step num: 1648, Learning rate: 0.00005758, Avg batch loss: 0.7157, Avg batch acc: 0.3603
Train, Epoch: 2, Batch: 130, Step num: 1649, Learning rate: 0.00005761, Avg batch loss: 0.7185, Avg batch acc: 0.3345
Train, Epoch: 2, Batch: 131, Step num: 1650, Learning rate: 0.00005765, Avg batch loss: 0.7031, Avg batch acc: 0.3362
Train, Epoch: 2, Batch: 132, Step num: 1651, Learning rate: 0.00005768, Avg batch loss: 0.6741, Avg batch acc: 0.3487
Train, Epoch: 2, Batch: 133, Step num: 1652, Learning rate: 0.00005772, Avg batch loss: 0.6428, Avg batch acc: 0.3567
Train, Epoch: 2, Batch: 134, Step num: 1653, Learning rate: 0.00005775, Avg batch loss: 0.7057, Avg batch acc: 0.3358
Train, Epoch: 2, Batch: 135, Step num: 1654, Learning rate: 0.00005779, Avg batch loss: 0.6850, Avg batch acc: 0.3503
Train, Epoch: 2, Batch: 136, Step num: 1655, Learning rate: 0.00005782, Avg batch loss: 0.6634, Avg batch acc: 0.3560
Train, Epoch: 2, Batch: 137, Step num: 1656, Learning rate: 0.00005786, Avg batch loss: 0.6809, Avg batch acc: 0.3536
Train, Epoch: 2, Batch: 138, Step num: 1657, Learning rate: 0.00005789, Avg batch loss: 0.7194, Avg batch acc: 0.3424
Train, Epoch: 2, Batch: 139, Step num: 1658, Learning rate: 0.00005793, Avg batch loss: 0.6760, Avg batch acc: 0.3397
Train, Epoch: 2, Batch: 140, Step num: 1659, Learning rate: 0.00005796, Avg batch loss: 0.6791, Avg batch acc: 0.3428
Train, Epoch: 2, Batch: 141, Step num: 1660, Learning rate: 0.00005800, Avg batch loss: 0.6428, Avg batch acc: 0.3656
Train, Epoch: 2, Batch: 142, Step num: 1661, Learning rate: 0.00005803, Avg batch loss: 0.6421, Avg batch acc: 0.3392
Train, Epoch: 2, Batch: 143, Step num: 1662, Learning rate: 0.00005807, Avg batch loss: 0.6922, Avg batch acc: 0.3427
Train, Epoch: 2, Batch: 144, Step num: 1663, Learning rate: 0.00005810, Avg batch loss: 0.6721, Avg batch acc: 0.3362
Train, Epoch: 2, Batch: 145, Step num: 1664, Learning rate: 0.00005814, Avg batch loss: 0.6703, Avg batch acc: 0.3528
Train, Epoch: 2, Batch: 146, Step num: 1665, Learning rate: 0.00005817, Avg batch loss: 0.7573, Avg batch acc: 0.3368
Train, Epoch: 2, Batch: 147, Step num: 1666, Learning rate: 0.00005821, Avg batch loss: 0.7126, Avg batch acc: 0.3436
Train, Epoch: 2, Batch: 148, Step num: 1667, Learning rate: 0.00005824, Avg batch loss: 0.6861, Avg batch acc: 0.3447
Train, Epoch: 2, Batch: 149, Step num: 1668, Learning rate: 0.00005828, Avg batch loss: 0.7149, Avg batch acc: 0.3417
Train, Epoch: 2, Batch: 150, Step num: 1669, Learning rate: 0.00005831, Avg batch loss: 0.7522, Avg batch acc: 0.3535
Train, Epoch: 2, Batch: 151, Step num: 1670, Learning rate: 0.00005835, Avg batch loss: 0.6687, Avg batch acc: 0.3417
Train, Epoch: 2, Batch: 152, Step num: 1671, Learning rate: 0.00005838, Avg batch loss: 0.7445, Avg batch acc: 0.3245
Train, Epoch: 2, Batch: 153, Step num: 1672, Learning rate: 0.00005842, Avg batch loss: 0.6460, Avg batch acc: 0.3672
Train, Epoch: 2, Batch: 154, Step num: 1673, Learning rate: 0.00005845, Avg batch loss: 0.6806, Avg batch acc: 0.3564
Train, Epoch: 2, Batch: 155, Step num: 1674, Learning rate: 0.00005849, Avg batch loss: 0.6743, Avg batch acc: 0.3509
Train, Epoch: 2, Batch: 156, Step num: 1675, Learning rate: 0.00005852, Avg batch loss: 0.6648, Avg batch acc: 0.3476
Train, Epoch: 2, Batch: 157, Step num: 1676, Learning rate: 0.00005856, Avg batch loss: 0.7526, Avg batch acc: 0.3365
Train, Epoch: 2, Batch: 158, Step num: 1677, Learning rate: 0.00005859, Avg batch loss: 0.6802, Avg batch acc: 0.3595
Train, Epoch: 2, Batch: 159, Step num: 1678, Learning rate: 0.00005863, Avg batch loss: 0.6903, Avg batch acc: 0.3357
Train, Epoch: 2, Batch: 160, Step num: 1679, Learning rate: 0.00005866, Avg batch loss: 0.7475, Avg batch acc: 0.3467
Train, Epoch: 2, Batch: 161, Step num: 1680, Learning rate: 0.00005870, Avg batch loss: 0.7651, Avg batch acc: 0.3344
Train, Epoch: 2, Batch: 162, Step num: 1681, Learning rate: 0.00005873, Avg batch loss: 0.7116, Avg batch acc: 0.3434
Train, Epoch: 2, Batch: 163, Step num: 1682, Learning rate: 0.00005877, Avg batch loss: 0.6285, Avg batch acc: 0.3592
Train, Epoch: 2, Batch: 164, Step num: 1683, Learning rate: 0.00005880, Avg batch loss: 0.6734, Avg batch acc: 0.3406
Train, Epoch: 2, Batch: 165, Step num: 1684, Learning rate: 0.00005884, Avg batch loss: 0.6569, Avg batch acc: 0.3344
Train, Epoch: 2, Batch: 166, Step num: 1685, Learning rate: 0.00005887, Avg batch loss: 0.6818, Avg batch acc: 0.3474
Train, Epoch: 2, Batch: 167, Step num: 1686, Learning rate: 0.00005891, Avg batch loss: 0.7022, Avg batch acc: 0.3272
Train, Epoch: 2, Batch: 168, Step num: 1687, Learning rate: 0.00005894, Avg batch loss: 0.6689, Avg batch acc: 0.3622
Train, Epoch: 2, Batch: 169, Step num: 1688, Learning rate: 0.00005898, Avg batch loss: 0.6329, Avg batch acc: 0.3732
Train, Epoch: 2, Batch: 170, Step num: 1689, Learning rate: 0.00005901, Avg batch loss: 0.6727, Avg batch acc: 0.3656
Train, Epoch: 2, Batch: 171, Step num: 1690, Learning rate: 0.00005905, Avg batch loss: 0.6665, Avg batch acc: 0.3480
Train, Epoch: 2, Batch: 172, Step num: 1691, Learning rate: 0.00005908, Avg batch loss: 0.6830, Avg batch acc: 0.3584
Train, Epoch: 2, Batch: 173, Step num: 1692, Learning rate: 0.00005912, Avg batch loss: 0.6974, Avg batch acc: 0.3370
Train, Epoch: 2, Batch: 174, Step num: 1693, Learning rate: 0.00005915, Avg batch loss: 0.6954, Avg batch acc: 0.3522
Train, Epoch: 2, Batch: 175, Step num: 1694, Learning rate: 0.00005919, Avg batch loss: 0.6340, Avg batch acc: 0.3406
Train, Epoch: 2, Batch: 176, Step num: 1695, Learning rate: 0.00005922, Avg batch loss: 0.6874, Avg batch acc: 0.3275
Train, Epoch: 2, Batch: 177, Step num: 1696, Learning rate: 0.00005926, Avg batch loss: 0.7077, Avg batch acc: 0.3394
Train, Epoch: 2, Batch: 178, Step num: 1697, Learning rate: 0.00005929, Avg batch loss: 0.7136, Avg batch acc: 0.3417
Train, Epoch: 2, Batch: 179, Step num: 1698, Learning rate: 0.00005933, Avg batch loss: 0.7106, Avg batch acc: 0.3429
Train, Epoch: 2, Batch: 180, Step num: 1699, Learning rate: 0.00005936, Avg batch loss: 0.6527, Avg batch acc: 0.3503
Train, Epoch: 2, Batch: 181, Step num: 1700, Learning rate: 0.00005940, Avg batch loss: 0.7450, Avg batch acc: 0.3569
Train, Epoch: 2, Batch: 182, Step num: 1701, Learning rate: 0.00005943, Avg batch loss: 0.6732, Avg batch acc: 0.3376
Train, Epoch: 2, Batch: 183, Step num: 1702, Learning rate: 0.00005947, Avg batch loss: 0.6065, Avg batch acc: 0.3780
Train, Epoch: 2, Batch: 184, Step num: 1703, Learning rate: 0.00005950, Avg batch loss: 0.7029, Avg batch acc: 0.3573
Train, Epoch: 2, Batch: 185, Step num: 1704, Learning rate: 0.00005954, Avg batch loss: 0.6937, Avg batch acc: 0.3450
Train, Epoch: 2, Batch: 186, Step num: 1705, Learning rate: 0.00005957, Avg batch loss: 0.7259, Avg batch acc: 0.3343
Train, Epoch: 2, Batch: 187, Step num: 1706, Learning rate: 0.00005961, Avg batch loss: 0.6801, Avg batch acc: 0.3661
Train, Epoch: 2, Batch: 188, Step num: 1707, Learning rate: 0.00005964, Avg batch loss: 0.6868, Avg batch acc: 0.3397
Train, Epoch: 2, Batch: 189, Step num: 1708, Learning rate: 0.00005968, Avg batch loss: 0.7021, Avg batch acc: 0.3387
Train, Epoch: 2, Batch: 190, Step num: 1709, Learning rate: 0.00005971, Avg batch loss: 0.7279, Avg batch acc: 0.3298
Train, Epoch: 2, Batch: 191, Step num: 1710, Learning rate: 0.00005974, Avg batch loss: 0.6801, Avg batch acc: 0.3486
Train, Epoch: 2, Batch: 192, Step num: 1711, Learning rate: 0.00005978, Avg batch loss: 0.6750, Avg batch acc: 0.3464
Train, Epoch: 2, Batch: 193, Step num: 1712, Learning rate: 0.00005981, Avg batch loss: 0.6617, Avg batch acc: 0.3173
Train, Epoch: 2, Batch: 194, Step num: 1713, Learning rate: 0.00005985, Avg batch loss: 0.6504, Avg batch acc: 0.3571
Train, Epoch: 2, Batch: 195, Step num: 1714, Learning rate: 0.00005988, Avg batch loss: 0.6882, Avg batch acc: 0.3380
Train, Epoch: 2, Batch: 196, Step num: 1715, Learning rate: 0.00005992, Avg batch loss: 0.7055, Avg batch acc: 0.3610
Train, Epoch: 2, Batch: 197, Step num: 1716, Learning rate: 0.00005995, Avg batch loss: 0.6645, Avg batch acc: 0.3298
Train, Epoch: 2, Batch: 198, Step num: 1717, Learning rate: 0.00005999, Avg batch loss: 0.6710, Avg batch acc: 0.3432
Train, Epoch: 2, Batch: 199, Step num: 1718, Learning rate: 0.00006002, Avg batch loss: 0.7883, Avg batch acc: 0.3452
Train, Epoch: 2, Batch: 200, Step num: 1719, Learning rate: 0.00006006, Avg batch loss: 0.7210, Avg batch acc: 0.3487
Train, Epoch: 2, Batch: 201, Step num: 1720, Learning rate: 0.00006009, Avg batch loss: 0.6918, Avg batch acc: 0.3354
Train, Epoch: 2, Batch: 202, Step num: 1721, Learning rate: 0.00006013, Avg batch loss: 0.6809, Avg batch acc: 0.3728
Train, Epoch: 2, Batch: 203, Step num: 1722, Learning rate: 0.00006016, Avg batch loss: 0.6928, Avg batch acc: 0.3527
Train, Epoch: 2, Batch: 204, Step num: 1723, Learning rate: 0.00006020, Avg batch loss: 0.6854, Avg batch acc: 0.3735
Train, Epoch: 2, Batch: 205, Step num: 1724, Learning rate: 0.00006023, Avg batch loss: 0.7032, Avg batch acc: 0.3350
Train, Epoch: 2, Batch: 206, Step num: 1725, Learning rate: 0.00006027, Avg batch loss: 0.6661, Avg batch acc: 0.3547
Train, Epoch: 2, Batch: 207, Step num: 1726, Learning rate: 0.00006030, Avg batch loss: 0.7192, Avg batch acc: 0.3435
Train, Epoch: 2, Batch: 208, Step num: 1727, Learning rate: 0.00006034, Avg batch loss: 0.6633, Avg batch acc: 0.3459
Train, Epoch: 2, Batch: 209, Step num: 1728, Learning rate: 0.00006037, Avg batch loss: 0.7013, Avg batch acc: 0.3736
Train, Epoch: 2, Batch: 210, Step num: 1729, Learning rate: 0.00006041, Avg batch loss: 0.6955, Avg batch acc: 0.3662
Train, Epoch: 2, Batch: 211, Step num: 1730, Learning rate: 0.00006044, Avg batch loss: 0.6915, Avg batch acc: 0.3541
Train, Epoch: 2, Batch: 212, Step num: 1731, Learning rate: 0.00006048, Avg batch loss: 0.6219, Avg batch acc: 0.3717
Train, Epoch: 2, Batch: 213, Step num: 1732, Learning rate: 0.00006051, Avg batch loss: 0.6341, Avg batch acc: 0.3845
Train, Epoch: 2, Batch: 214, Step num: 1733, Learning rate: 0.00006055, Avg batch loss: 0.6607, Avg batch acc: 0.3551
Train, Epoch: 2, Batch: 215, Step num: 1734, Learning rate: 0.00006058, Avg batch loss: 0.6586, Avg batch acc: 0.3483
Train, Epoch: 2, Batch: 216, Step num: 1735, Learning rate: 0.00006062, Avg batch loss: 0.6650, Avg batch acc: 0.3613
Train, Epoch: 2, Batch: 217, Step num: 1736, Learning rate: 0.00006065, Avg batch loss: 0.7244, Avg batch acc: 0.3466
Train, Epoch: 2, Batch: 218, Step num: 1737, Learning rate: 0.00006069, Avg batch loss: 0.6870, Avg batch acc: 0.3679
Train, Epoch: 2, Batch: 219, Step num: 1738, Learning rate: 0.00006072, Avg batch loss: 0.7163, Avg batch acc: 0.3548
Train, Epoch: 2, Batch: 220, Step num: 1739, Learning rate: 0.00006076, Avg batch loss: 0.6985, Avg batch acc: 0.3386
Train, Epoch: 2, Batch: 221, Step num: 1740, Learning rate: 0.00006079, Avg batch loss: 0.6353, Avg batch acc: 0.3481
Train, Epoch: 2, Batch: 222, Step num: 1741, Learning rate: 0.00006083, Avg batch loss: 0.7429, Avg batch acc: 0.3547
Train, Epoch: 2, Batch: 223, Step num: 1742, Learning rate: 0.00006086, Avg batch loss: 0.6126, Avg batch acc: 0.3516
Train, Epoch: 2, Batch: 224, Step num: 1743, Learning rate: 0.00006090, Avg batch loss: 0.6610, Avg batch acc: 0.3642
Train, Epoch: 2, Batch: 225, Step num: 1744, Learning rate: 0.00006093, Avg batch loss: 0.7552, Avg batch acc: 0.3312
Train, Epoch: 2, Batch: 226, Step num: 1745, Learning rate: 0.00006097, Avg batch loss: 0.6470, Avg batch acc: 0.3454
Train, Epoch: 2, Batch: 227, Step num: 1746, Learning rate: 0.00006100, Avg batch loss: 0.7236, Avg batch acc: 0.3178
Train, Epoch: 2, Batch: 228, Step num: 1747, Learning rate: 0.00006104, Avg batch loss: 0.6728, Avg batch acc: 0.3613
Train, Epoch: 2, Batch: 229, Step num: 1748, Learning rate: 0.00006107, Avg batch loss: 0.7158, Avg batch acc: 0.3421
Train, Epoch: 2, Batch: 230, Step num: 1749, Learning rate: 0.00006111, Avg batch loss: 0.6767, Avg batch acc: 0.3544
Train, Epoch: 2, Batch: 231, Step num: 1750, Learning rate: 0.00006114, Avg batch loss: 0.7686, Avg batch acc: 0.3479
Train, Epoch: 2, Batch: 232, Step num: 1751, Learning rate: 0.00006118, Avg batch loss: 0.6995, Avg batch acc: 0.3509
Train, Epoch: 2, Batch: 233, Step num: 1752, Learning rate: 0.00006121, Avg batch loss: 0.6403, Avg batch acc: 0.3629
Train, Epoch: 2, Batch: 234, Step num: 1753, Learning rate: 0.00006125, Avg batch loss: 0.6691, Avg batch acc: 0.3579
Train, Epoch: 2, Batch: 235, Step num: 1754, Learning rate: 0.00006128, Avg batch loss: 0.6543, Avg batch acc: 0.3497
Train, Epoch: 2, Batch: 236, Step num: 1755, Learning rate: 0.00006132, Avg batch loss: 0.6253, Avg batch acc: 0.3744
Train, Epoch: 2, Batch: 237, Step num: 1756, Learning rate: 0.00006135, Avg batch loss: 0.7525, Avg batch acc: 0.3532
Train, Epoch: 2, Batch: 238, Step num: 1757, Learning rate: 0.00006139, Avg batch loss: 0.6876, Avg batch acc: 0.3646
Train, Epoch: 2, Batch: 239, Step num: 1758, Learning rate: 0.00006142, Avg batch loss: 0.7472, Avg batch acc: 0.3480
Train, Epoch: 2, Batch: 240, Step num: 1759, Learning rate: 0.00006146, Avg batch loss: 0.6777, Avg batch acc: 0.3663
Train, Epoch: 2, Batch: 241, Step num: 1760, Learning rate: 0.00006149, Avg batch loss: 0.7310, Avg batch acc: 0.3542
Train, Epoch: 2, Batch: 242, Step num: 1761, Learning rate: 0.00006153, Avg batch loss: 0.6822, Avg batch acc: 0.3498
Train, Epoch: 2, Batch: 243, Step num: 1762, Learning rate: 0.00006156, Avg batch loss: 0.6632, Avg batch acc: 0.3771
Train, Epoch: 2, Batch: 244, Step num: 1763, Learning rate: 0.00006160, Avg batch loss: 0.6815, Avg batch acc: 0.3731
Train, Epoch: 2, Batch: 245, Step num: 1764, Learning rate: 0.00006163, Avg batch loss: 0.6521, Avg batch acc: 0.3593
Train, Epoch: 2, Batch: 246, Step num: 1765, Learning rate: 0.00006167, Avg batch loss: 0.6763, Avg batch acc: 0.3567
Train, Epoch: 2, Batch: 247, Step num: 1766, Learning rate: 0.00006170, Avg batch loss: 0.6506, Avg batch acc: 0.3468
Train, Epoch: 2, Batch: 248, Step num: 1767, Learning rate: 0.00006174, Avg batch loss: 0.6552, Avg batch acc: 0.3533
Train, Epoch: 2, Batch: 249, Step num: 1768, Learning rate: 0.00006177, Avg batch loss: 0.6842, Avg batch acc: 0.3312
Train, Epoch: 2, Batch: 250, Step num: 1769, Learning rate: 0.00006181, Avg batch loss: 0.6542, Avg batch acc: 0.3590
Train, Epoch: 2, Batch: 251, Step num: 1770, Learning rate: 0.00006184, Avg batch loss: 0.7094, Avg batch acc: 0.3638
Train, Epoch: 2, Batch: 252, Step num: 1771, Learning rate: 0.00006188, Avg batch loss: 0.6334, Avg batch acc: 0.3538
Train, Epoch: 2, Batch: 253, Step num: 1772, Learning rate: 0.00006191, Avg batch loss: 0.6952, Avg batch acc: 0.3565
Train, Epoch: 2, Batch: 254, Step num: 1773, Learning rate: 0.00006195, Avg batch loss: 0.6742, Avg batch acc: 0.3612
Train, Epoch: 2, Batch: 255, Step num: 1774, Learning rate: 0.00006198, Avg batch loss: 0.7163, Avg batch acc: 0.3400
Train, Epoch: 2, Batch: 256, Step num: 1775, Learning rate: 0.00006202, Avg batch loss: 0.7058, Avg batch acc: 0.3518
Train, Epoch: 2, Batch: 257, Step num: 1776, Learning rate: 0.00006205, Avg batch loss: 0.6376, Avg batch acc: 0.3699
Train, Epoch: 2, Batch: 258, Step num: 1777, Learning rate: 0.00006209, Avg batch loss: 0.6618, Avg batch acc: 0.3629
Train, Epoch: 2, Batch: 259, Step num: 1778, Learning rate: 0.00006212, Avg batch loss: 0.7056, Avg batch acc: 0.3626
Train, Epoch: 2, Batch: 260, Step num: 1779, Learning rate: 0.00006216, Avg batch loss: 0.6637, Avg batch acc: 0.3650
Train, Epoch: 2, Batch: 261, Step num: 1780, Learning rate: 0.00006219, Avg batch loss: 0.6451, Avg batch acc: 0.3687
Train, Epoch: 2, Batch: 262, Step num: 1781, Learning rate: 0.00006223, Avg batch loss: 0.6389, Avg batch acc: 0.3771
Train, Epoch: 2, Batch: 263, Step num: 1782, Learning rate: 0.00006226, Avg batch loss: 0.7164, Avg batch acc: 0.3573
Train, Epoch: 2, Batch: 264, Step num: 1783, Learning rate: 0.00006230, Avg batch loss: 0.6993, Avg batch acc: 0.3507
Train, Epoch: 2, Batch: 265, Step num: 1784, Learning rate: 0.00006233, Avg batch loss: 0.7050, Avg batch acc: 0.3628
Train, Epoch: 2, Batch: 266, Step num: 1785, Learning rate: 0.00006237, Avg batch loss: 0.6540, Avg batch acc: 0.3573
Train, Epoch: 2, Batch: 267, Step num: 1786, Learning rate: 0.00006240, Avg batch loss: 0.7229, Avg batch acc: 0.3532
Train, Epoch: 2, Batch: 268, Step num: 1787, Learning rate: 0.00006244, Avg batch loss: 0.5752, Avg batch acc: 0.3771
Train, Epoch: 2, Batch: 269, Step num: 1788, Learning rate: 0.00006247, Avg batch loss: 0.6588, Avg batch acc: 0.3737
Train, Epoch: 2, Batch: 270, Step num: 1789, Learning rate: 0.00006251, Avg batch loss: 0.6205, Avg batch acc: 0.3571
Train, Epoch: 2, Batch: 271, Step num: 1790, Learning rate: 0.00006254, Avg batch loss: 0.7064, Avg batch acc: 0.3494
Train, Epoch: 2, Batch: 272, Step num: 1791, Learning rate: 0.00006257, Avg batch loss: 0.6970, Avg batch acc: 0.3467
Train, Epoch: 2, Batch: 273, Step num: 1792, Learning rate: 0.00006261, Avg batch loss: 0.6355, Avg batch acc: 0.3753
Train, Epoch: 2, Batch: 274, Step num: 1793, Learning rate: 0.00006264, Avg batch loss: 0.6843, Avg batch acc: 0.3495
Train, Epoch: 2, Batch: 275, Step num: 1794, Learning rate: 0.00006268, Avg batch loss: 0.6470, Avg batch acc: 0.3465
Train, Epoch: 2, Batch: 276, Step num: 1795, Learning rate: 0.00006271, Avg batch loss: 0.6773, Avg batch acc: 0.3619
Train, Epoch: 2, Batch: 277, Step num: 1796, Learning rate: 0.00006275, Avg batch loss: 0.6182, Avg batch acc: 0.3712
Train, Epoch: 2, Batch: 278, Step num: 1797, Learning rate: 0.00006278, Avg batch loss: 0.6257, Avg batch acc: 0.3657
Train, Epoch: 2, Batch: 279, Step num: 1798, Learning rate: 0.00006282, Avg batch loss: 0.6258, Avg batch acc: 0.3555
Train, Epoch: 2, Batch: 280, Step num: 1799, Learning rate: 0.00006285, Avg batch loss: 0.7213, Avg batch acc: 0.3687
Train, Epoch: 2, Batch: 281, Step num: 1800, Learning rate: 0.00006289, Avg batch loss: 0.7085, Avg batch acc: 0.3732
Train, Epoch: 2, Batch: 282, Step num: 1801, Learning rate: 0.00006292, Avg batch loss: 0.7295, Avg batch acc: 0.3623
Train, Epoch: 2, Batch: 283, Step num: 1802, Learning rate: 0.00006296, Avg batch loss: 0.6876, Avg batch acc: 0.3586
Train, Epoch: 2, Batch: 284, Step num: 1803, Learning rate: 0.00006299, Avg batch loss: 0.7147, Avg batch acc: 0.3662
Train, Epoch: 2, Batch: 285, Step num: 1804, Learning rate: 0.00006303, Avg batch loss: 0.6834, Avg batch acc: 0.3568
Train, Epoch: 2, Batch: 286, Step num: 1805, Learning rate: 0.00006306, Avg batch loss: 0.6835, Avg batch acc: 0.3663
Train, Epoch: 2, Batch: 287, Step num: 1806, Learning rate: 0.00006310, Avg batch loss: 0.6670, Avg batch acc: 0.3567
Train, Epoch: 2, Batch: 288, Step num: 1807, Learning rate: 0.00006313, Avg batch loss: 0.6653, Avg batch acc: 0.3697
Train, Epoch: 2, Batch: 289, Step num: 1808, Learning rate: 0.00006317, Avg batch loss: 0.6860, Avg batch acc: 0.3647
Train, Epoch: 2, Batch: 290, Step num: 1809, Learning rate: 0.00006320, Avg batch loss: 0.6993, Avg batch acc: 0.3521
Train, Epoch: 2, Batch: 291, Step num: 1810, Learning rate: 0.00006324, Avg batch loss: 0.6670, Avg batch acc: 0.3502
Train, Epoch: 2, Batch: 292, Step num: 1811, Learning rate: 0.00006327, Avg batch loss: 0.7302, Avg batch acc: 0.3659
Train, Epoch: 2, Batch: 293, Step num: 1812, Learning rate: 0.00006331, Avg batch loss: 0.6820, Avg batch acc: 0.3493
Train, Epoch: 2, Batch: 294, Step num: 1813, Learning rate: 0.00006334, Avg batch loss: 0.6218, Avg batch acc: 0.3685
Train, Epoch: 2, Batch: 295, Step num: 1814, Learning rate: 0.00006338, Avg batch loss: 0.7386, Avg batch acc: 0.3464
Train, Epoch: 2, Batch: 296, Step num: 1815, Learning rate: 0.00006341, Avg batch loss: 0.7536, Avg batch acc: 0.3582
Train, Epoch: 2, Batch: 297, Step num: 1816, Learning rate: 0.00006345, Avg batch loss: 0.7025, Avg batch acc: 0.3709
Train, Epoch: 2, Batch: 298, Step num: 1817, Learning rate: 0.00006348, Avg batch loss: 0.6994, Avg batch acc: 0.3642
Train, Epoch: 2, Batch: 299, Step num: 1818, Learning rate: 0.00006352, Avg batch loss: 0.7245, Avg batch acc: 0.3570
Train, Epoch: 2, Batch: 300, Step num: 1819, Learning rate: 0.00006355, Avg batch loss: 0.6549, Avg batch acc: 0.3766
Train, Epoch: 2, Batch: 301, Step num: 1820, Learning rate: 0.00006359, Avg batch loss: 0.6815, Avg batch acc: 0.3474
Train, Epoch: 2, Batch: 302, Step num: 1821, Learning rate: 0.00006362, Avg batch loss: 0.6030, Avg batch acc: 0.3877
Train, Epoch: 2, Batch: 303, Step num: 1822, Learning rate: 0.00006366, Avg batch loss: 0.6581, Avg batch acc: 0.3896
Train, Epoch: 2, Batch: 304, Step num: 1823, Learning rate: 0.00006369, Avg batch loss: 0.6029, Avg batch acc: 0.3836
Train, Epoch: 2, Batch: 305, Step num: 1824, Learning rate: 0.00006373, Avg batch loss: 0.6912, Avg batch acc: 0.3657
Train, Epoch: 2, Batch: 306, Step num: 1825, Learning rate: 0.00006376, Avg batch loss: 0.7281, Avg batch acc: 0.3448
Train, Epoch: 2, Batch: 307, Step num: 1826, Learning rate: 0.00006380, Avg batch loss: 0.6046, Avg batch acc: 0.3724
Train, Epoch: 2, Batch: 308, Step num: 1827, Learning rate: 0.00006383, Avg batch loss: 0.6516, Avg batch acc: 0.3726
Train, Epoch: 2, Batch: 309, Step num: 1828, Learning rate: 0.00006387, Avg batch loss: 0.6840, Avg batch acc: 0.3899
Train, Epoch: 2, Batch: 310, Step num: 1829, Learning rate: 0.00006390, Avg batch loss: 0.6826, Avg batch acc: 0.3728
Train, Epoch: 2, Batch: 311, Step num: 1830, Learning rate: 0.00006394, Avg batch loss: 0.6409, Avg batch acc: 0.3676
Train, Epoch: 2, Batch: 312, Step num: 1831, Learning rate: 0.00006397, Avg batch loss: 0.6708, Avg batch acc: 0.3639
Train, Epoch: 2, Batch: 313, Step num: 1832, Learning rate: 0.00006401, Avg batch loss: 0.6803, Avg batch acc: 0.3632
Train, Epoch: 2, Batch: 314, Step num: 1833, Learning rate: 0.00006404, Avg batch loss: 0.6519, Avg batch acc: 0.3871
Train, Epoch: 2, Batch: 315, Step num: 1834, Learning rate: 0.00006408, Avg batch loss: 0.6635, Avg batch acc: 0.3532
Train, Epoch: 2, Batch: 316, Step num: 1835, Learning rate: 0.00006411, Avg batch loss: 0.7320, Avg batch acc: 0.3454
Train, Epoch: 2, Batch: 317, Step num: 1836, Learning rate: 0.00006415, Avg batch loss: 0.7097, Avg batch acc: 0.3712
Train, Epoch: 2, Batch: 318, Step num: 1837, Learning rate: 0.00006418, Avg batch loss: 0.6567, Avg batch acc: 0.3923
Train, Epoch: 2, Batch: 319, Step num: 1838, Learning rate: 0.00006422, Avg batch loss: 0.7168, Avg batch acc: 0.3533
Train, Epoch: 2, Batch: 320, Step num: 1839, Learning rate: 0.00006425, Avg batch loss: 0.6938, Avg batch acc: 0.3752
Train, Epoch: 2, Batch: 321, Step num: 1840, Learning rate: 0.00006429, Avg batch loss: 0.7040, Avg batch acc: 0.3678
Train, Epoch: 2, Batch: 322, Step num: 1841, Learning rate: 0.00006432, Avg batch loss: 0.6350, Avg batch acc: 0.3750
Train, Epoch: 2, Batch: 323, Step num: 1842, Learning rate: 0.00006436, Avg batch loss: 0.6814, Avg batch acc: 0.3687
Train, Epoch: 2, Batch: 324, Step num: 1843, Learning rate: 0.00006439, Avg batch loss: 0.6272, Avg batch acc: 0.3743
Train, Epoch: 2, Batch: 325, Step num: 1844, Learning rate: 0.00006443, Avg batch loss: 0.6841, Avg batch acc: 0.3728
Train, Epoch: 2, Batch: 326, Step num: 1845, Learning rate: 0.00006446, Avg batch loss: 0.6982, Avg batch acc: 0.3668
Train, Epoch: 2, Batch: 327, Step num: 1846, Learning rate: 0.00006450, Avg batch loss: 0.6707, Avg batch acc: 0.3491
Train, Epoch: 2, Batch: 328, Step num: 1847, Learning rate: 0.00006453, Avg batch loss: 0.6824, Avg batch acc: 0.3559
Train, Epoch: 2, Batch: 329, Step num: 1848, Learning rate: 0.00006457, Avg batch loss: 0.7187, Avg batch acc: 0.3639
Train, Epoch: 2, Batch: 330, Step num: 1849, Learning rate: 0.00006460, Avg batch loss: 0.6582, Avg batch acc: 0.3599
Train, Epoch: 2, Batch: 331, Step num: 1850, Learning rate: 0.00006464, Avg batch loss: 0.6681, Avg batch acc: 0.3667
Train, Epoch: 2, Batch: 332, Step num: 1851, Learning rate: 0.00006467, Avg batch loss: 0.6337, Avg batch acc: 0.3733
Train, Epoch: 2, Batch: 333, Step num: 1852, Learning rate: 0.00006471, Avg batch loss: 0.6718, Avg batch acc: 0.3547
Train, Epoch: 2, Batch: 334, Step num: 1853, Learning rate: 0.00006474, Avg batch loss: 0.6609, Avg batch acc: 0.3702
Train, Epoch: 2, Batch: 335, Step num: 1854, Learning rate: 0.00006478, Avg batch loss: 0.6563, Avg batch acc: 0.3941
Train, Epoch: 2, Batch: 336, Step num: 1855, Learning rate: 0.00006481, Avg batch loss: 0.7098, Avg batch acc: 0.3650
Train, Epoch: 2, Batch: 337, Step num: 1856, Learning rate: 0.00006485, Avg batch loss: 0.6833, Avg batch acc: 0.3596
Train, Epoch: 2, Batch: 338, Step num: 1857, Learning rate: 0.00006488, Avg batch loss: 0.6909, Avg batch acc: 0.3662
Train, Epoch: 2, Batch: 339, Step num: 1858, Learning rate: 0.00006492, Avg batch loss: 0.6913, Avg batch acc: 0.3868
Train, Epoch: 2, Batch: 340, Step num: 1859, Learning rate: 0.00006495, Avg batch loss: 0.6195, Avg batch acc: 0.3752
Train, Epoch: 2, Batch: 341, Step num: 1860, Learning rate: 0.00006499, Avg batch loss: 0.7710, Avg batch acc: 0.3541
Train, Epoch: 2, Batch: 342, Step num: 1861, Learning rate: 0.00006502, Avg batch loss: 0.6978, Avg batch acc: 0.3564
Train, Epoch: 2, Batch: 343, Step num: 1862, Learning rate: 0.00006506, Avg batch loss: 0.6823, Avg batch acc: 0.3626
Train, Epoch: 2, Batch: 344, Step num: 1863, Learning rate: 0.00006509, Avg batch loss: 0.6415, Avg batch acc: 0.3591
Train, Epoch: 2, Batch: 345, Step num: 1864, Learning rate: 0.00006513, Avg batch loss: 0.6800, Avg batch acc: 0.3637
Train, Epoch: 2, Batch: 346, Step num: 1865, Learning rate: 0.00006516, Avg batch loss: 0.6984, Avg batch acc: 0.3843
Train, Epoch: 2, Batch: 347, Step num: 1866, Learning rate: 0.00006520, Avg batch loss: 0.5861, Avg batch acc: 0.3843
Train, Epoch: 2, Batch: 348, Step num: 1867, Learning rate: 0.00006523, Avg batch loss: 0.6700, Avg batch acc: 0.3486
Train, Epoch: 2, Batch: 349, Step num: 1868, Learning rate: 0.00006527, Avg batch loss: 0.6441, Avg batch acc: 0.3654
Train, Epoch: 2, Batch: 350, Step num: 1869, Learning rate: 0.00006530, Avg batch loss: 0.6589, Avg batch acc: 0.3763
Train, Epoch: 2, Batch: 351, Step num: 1870, Learning rate: 0.00006534, Avg batch loss: 0.6857, Avg batch acc: 0.3631
Train, Epoch: 2, Batch: 352, Step num: 1871, Learning rate: 0.00006537, Avg batch loss: 0.6015, Avg batch acc: 0.3725
Train, Epoch: 2, Batch: 353, Step num: 1872, Learning rate: 0.00006540, Avg batch loss: 0.6929, Avg batch acc: 0.3643
Train, Epoch: 2, Batch: 354, Step num: 1873, Learning rate: 0.00006544, Avg batch loss: 0.6537, Avg batch acc: 0.3608
Train, Epoch: 2, Batch: 355, Step num: 1874, Learning rate: 0.00006547, Avg batch loss: 0.6556, Avg batch acc: 0.3662
Train, Epoch: 2, Batch: 356, Step num: 1875, Learning rate: 0.00006551, Avg batch loss: 0.6940, Avg batch acc: 0.3711
Train, Epoch: 2, Batch: 357, Step num: 1876, Learning rate: 0.00006554, Avg batch loss: 0.7080, Avg batch acc: 0.3735
Train, Epoch: 2, Batch: 358, Step num: 1877, Learning rate: 0.00006558, Avg batch loss: 0.7147, Avg batch acc: 0.3609
Train, Epoch: 2, Batch: 359, Step num: 1878, Learning rate: 0.00006561, Avg batch loss: 0.6430, Avg batch acc: 0.3771
Train, Epoch: 2, Batch: 360, Step num: 1879, Learning rate: 0.00006565, Avg batch loss: 0.6680, Avg batch acc: 0.3733
Train, Epoch: 2, Batch: 361, Step num: 1880, Learning rate: 0.00006568, Avg batch loss: 0.6737, Avg batch acc: 0.3738
Train, Epoch: 2, Batch: 362, Step num: 1881, Learning rate: 0.00006572, Avg batch loss: 0.6603, Avg batch acc: 0.3392
Train, Epoch: 2, Batch: 363, Step num: 1882, Learning rate: 0.00006575, Avg batch loss: 0.6326, Avg batch acc: 0.3831
Train, Epoch: 2, Batch: 364, Step num: 1883, Learning rate: 0.00006579, Avg batch loss: 0.6639, Avg batch acc: 0.3747
Train, Epoch: 2, Batch: 365, Step num: 1884, Learning rate: 0.00006582, Avg batch loss: 0.6434, Avg batch acc: 0.3662
Train, Epoch: 2, Batch: 366, Step num: 1885, Learning rate: 0.00006586, Avg batch loss: 0.6955, Avg batch acc: 0.3535
Train, Epoch: 2, Batch: 367, Step num: 1886, Learning rate: 0.00006589, Avg batch loss: 0.6813, Avg batch acc: 0.3580
Train, Epoch: 2, Batch: 368, Step num: 1887, Learning rate: 0.00006593, Avg batch loss: 0.6838, Avg batch acc: 0.3531
Train, Epoch: 2, Batch: 369, Step num: 1888, Learning rate: 0.00006596, Avg batch loss: 0.6825, Avg batch acc: 0.3696
Train, Epoch: 2, Batch: 370, Step num: 1889, Learning rate: 0.00006600, Avg batch loss: 0.6966, Avg batch acc: 0.3643
Train, Epoch: 2, Batch: 371, Step num: 1890, Learning rate: 0.00006603, Avg batch loss: 0.7271, Avg batch acc: 0.3651
Train, Epoch: 2, Batch: 372, Step num: 1891, Learning rate: 0.00006607, Avg batch loss: 0.7067, Avg batch acc: 0.3692
Train, Epoch: 2, Batch: 373, Step num: 1892, Learning rate: 0.00006610, Avg batch loss: 0.6857, Avg batch acc: 0.3888
Train, Epoch: 2, Batch: 374, Step num: 1893, Learning rate: 0.00006614, Avg batch loss: 0.7291, Avg batch acc: 0.3730
Train, Epoch: 2, Batch: 375, Step num: 1894, Learning rate: 0.00006617, Avg batch loss: 0.6567, Avg batch acc: 0.3609
Train, Epoch: 2, Batch: 376, Step num: 1895, Learning rate: 0.00006621, Avg batch loss: 0.6399, Avg batch acc: 0.3821
Train, Epoch: 2, Batch: 377, Step num: 1896, Learning rate: 0.00006624, Avg batch loss: 0.6891, Avg batch acc: 0.3743
Train, Epoch: 2, Batch: 378, Step num: 1897, Learning rate: 0.00006628, Avg batch loss: 0.7021, Avg batch acc: 0.3580
Train, Epoch: 2, Batch: 379, Step num: 1898, Learning rate: 0.00006631, Avg batch loss: 0.6665, Avg batch acc: 0.3552
Train, Epoch: 2, Batch: 380, Step num: 1899, Learning rate: 0.00006635, Avg batch loss: 0.6944, Avg batch acc: 0.3629
Train, Epoch: 2, Batch: 381, Step num: 1900, Learning rate: 0.00006638, Avg batch loss: 0.6533, Avg batch acc: 0.3802
Train, Epoch: 2, Batch: 382, Step num: 1901, Learning rate: 0.00006642, Avg batch loss: 0.6388, Avg batch acc: 0.3707
Train, Epoch: 2, Batch: 383, Step num: 1902, Learning rate: 0.00006645, Avg batch loss: 0.7077, Avg batch acc: 0.3662
Train, Epoch: 2, Batch: 384, Step num: 1903, Learning rate: 0.00006649, Avg batch loss: 0.6067, Avg batch acc: 0.3964
Train, Epoch: 2, Batch: 385, Step num: 1904, Learning rate: 0.00006652, Avg batch loss: 0.6908, Avg batch acc: 0.3627
Train, Epoch: 2, Batch: 386, Step num: 1905, Learning rate: 0.00006656, Avg batch loss: 0.6743, Avg batch acc: 0.3719
Train, Epoch: 2, Batch: 387, Step num: 1906, Learning rate: 0.00006659, Avg batch loss: 0.6763, Avg batch acc: 0.3742
Train, Epoch: 2, Batch: 388, Step num: 1907, Learning rate: 0.00006663, Avg batch loss: 0.6663, Avg batch acc: 0.3828
Train, Epoch: 2, Batch: 389, Step num: 1908, Learning rate: 0.00006666, Avg batch loss: 0.6447, Avg batch acc: 0.3732
Train, Epoch: 2, Batch: 390, Step num: 1909, Learning rate: 0.00006670, Avg batch loss: 0.5952, Avg batch acc: 0.3788
Train, Epoch: 2, Batch: 391, Step num: 1910, Learning rate: 0.00006673, Avg batch loss: 0.6769, Avg batch acc: 0.3662
Train, Epoch: 2, Batch: 392, Step num: 1911, Learning rate: 0.00006677, Avg batch loss: 0.7179, Avg batch acc: 0.3619
Train, Epoch: 2, Batch: 393, Step num: 1912, Learning rate: 0.00006680, Avg batch loss: 0.6862, Avg batch acc: 0.3333
Train, Epoch: 2, Batch: 394, Step num: 1913, Learning rate: 0.00006684, Avg batch loss: 0.6675, Avg batch acc: 0.3617
Train, Epoch: 2, Batch: 395, Step num: 1914, Learning rate: 0.00006687, Avg batch loss: 0.6857, Avg batch acc: 0.3782
Train, Epoch: 2, Batch: 396, Step num: 1915, Learning rate: 0.00006691, Avg batch loss: 0.6249, Avg batch acc: 0.3641
Train, Epoch: 2, Batch: 397, Step num: 1916, Learning rate: 0.00006694, Avg batch loss: 0.7043, Avg batch acc: 0.3639
Train, Epoch: 2, Batch: 398, Step num: 1917, Learning rate: 0.00006698, Avg batch loss: 0.6326, Avg batch acc: 0.3748
Train, Epoch: 2, Batch: 399, Step num: 1918, Learning rate: 0.00006701, Avg batch loss: 0.6423, Avg batch acc: 0.3637
Train, Epoch: 2, Batch: 400, Step num: 1919, Learning rate: 0.00006705, Avg batch loss: 0.6410, Avg batch acc: 0.3745
Train, Epoch: 2, Batch: 401, Step num: 1920, Learning rate: 0.00006708, Avg batch loss: 0.6397, Avg batch acc: 0.3868
Train, Epoch: 2, Batch: 402, Step num: 1921, Learning rate: 0.00006712, Avg batch loss: 0.7055, Avg batch acc: 0.3824
Train, Epoch: 2, Batch: 403, Step num: 1922, Learning rate: 0.00006715, Avg batch loss: 0.6340, Avg batch acc: 0.3797
Train, Epoch: 2, Batch: 404, Step num: 1923, Learning rate: 0.00006719, Avg batch loss: 0.6593, Avg batch acc: 0.3795
Train, Epoch: 2, Batch: 405, Step num: 1924, Learning rate: 0.00006722, Avg batch loss: 0.6835, Avg batch acc: 0.3692
Train, Epoch: 2, Batch: 406, Step num: 1925, Learning rate: 0.00006726, Avg batch loss: 0.6778, Avg batch acc: 0.3708
Train, Epoch: 2, Batch: 407, Step num: 1926, Learning rate: 0.00006729, Avg batch loss: 0.7255, Avg batch acc: 0.3720
Train, Epoch: 2, Batch: 408, Step num: 1927, Learning rate: 0.00006733, Avg batch loss: 0.7477, Avg batch acc: 0.3471
Train, Epoch: 2, Batch: 409, Step num: 1928, Learning rate: 0.00006736, Avg batch loss: 0.7079, Avg batch acc: 0.3537
Train, Epoch: 2, Batch: 410, Step num: 1929, Learning rate: 0.00006740, Avg batch loss: 0.7272, Avg batch acc: 0.3714
Train, Epoch: 2, Batch: 411, Step num: 1930, Learning rate: 0.00006743, Avg batch loss: 0.6322, Avg batch acc: 0.3792
Train, Epoch: 2, Batch: 412, Step num: 1931, Learning rate: 0.00006747, Avg batch loss: 0.6169, Avg batch acc: 0.3645
Train, Epoch: 2, Batch: 413, Step num: 1932, Learning rate: 0.00006750, Avg batch loss: 0.6898, Avg batch acc: 0.3639
Train, Epoch: 2, Batch: 414, Step num: 1933, Learning rate: 0.00006754, Avg batch loss: 0.6545, Avg batch acc: 0.3599
Train, Epoch: 2, Batch: 415, Step num: 1934, Learning rate: 0.00006757, Avg batch loss: 0.5812, Avg batch acc: 0.3565
Train, Epoch: 2, Batch: 416, Step num: 1935, Learning rate: 0.00006761, Avg batch loss: 0.6498, Avg batch acc: 0.3798
Train, Epoch: 2, Batch: 417, Step num: 1936, Learning rate: 0.00006764, Avg batch loss: 0.7409, Avg batch acc: 0.3575
Train, Epoch: 2, Batch: 418, Step num: 1937, Learning rate: 0.00006768, Avg batch loss: 0.6884, Avg batch acc: 0.3670
Train, Epoch: 2, Batch: 419, Step num: 1938, Learning rate: 0.00006771, Avg batch loss: 0.6105, Avg batch acc: 0.3790
Train, Epoch: 2, Batch: 420, Step num: 1939, Learning rate: 0.00006775, Avg batch loss: 0.6534, Avg batch acc: 0.3754
Train, Epoch: 2, Batch: 421, Step num: 1940, Learning rate: 0.00006778, Avg batch loss: 0.6105, Avg batch acc: 0.3929
Train, Epoch: 2, Batch: 422, Step num: 1941, Learning rate: 0.00006782, Avg batch loss: 0.7038, Avg batch acc: 0.3766
Train, Epoch: 2, Batch: 423, Step num: 1942, Learning rate: 0.00006785, Avg batch loss: 0.7095, Avg batch acc: 0.3761
Train, Epoch: 2, Batch: 424, Step num: 1943, Learning rate: 0.00006789, Avg batch loss: 0.6998, Avg batch acc: 0.3744
Train, Epoch: 2, Batch: 425, Step num: 1944, Learning rate: 0.00006792, Avg batch loss: 0.6344, Avg batch acc: 0.3745
Train, Epoch: 2, Batch: 426, Step num: 1945, Learning rate: 0.00006796, Avg batch loss: 0.6147, Avg batch acc: 0.3955
Train, Epoch: 2, Batch: 427, Step num: 1946, Learning rate: 0.00006799, Avg batch loss: 0.6734, Avg batch acc: 0.3773
Train, Epoch: 2, Batch: 428, Step num: 1947, Learning rate: 0.00006803, Avg batch loss: 0.7028, Avg batch acc: 0.3691
Train, Epoch: 2, Batch: 429, Step num: 1948, Learning rate: 0.00006806, Avg batch loss: 0.6950, Avg batch acc: 0.3667
Train, Epoch: 2, Batch: 430, Step num: 1949, Learning rate: 0.00006810, Avg batch loss: 0.6606, Avg batch acc: 0.3780
Train, Epoch: 2, Batch: 431, Step num: 1950, Learning rate: 0.00006813, Avg batch loss: 0.6599, Avg batch acc: 0.3891
Train, Epoch: 2, Batch: 432, Step num: 1951, Learning rate: 0.00006817, Avg batch loss: 0.6161, Avg batch acc: 0.3856
Train, Epoch: 2, Batch: 433, Step num: 1952, Learning rate: 0.00006820, Avg batch loss: 0.6544, Avg batch acc: 0.3623
Train, Epoch: 2, Batch: 434, Step num: 1953, Learning rate: 0.00006824, Avg batch loss: 0.6407, Avg batch acc: 0.3861
Train, Epoch: 2, Batch: 435, Step num: 1954, Learning rate: 0.00006827, Avg batch loss: 0.7165, Avg batch acc: 0.3390
Train, Epoch: 2, Batch: 436, Step num: 1955, Learning rate: 0.00006830, Avg batch loss: 0.6799, Avg batch acc: 0.3823
Train, Epoch: 2, Batch: 437, Step num: 1956, Learning rate: 0.00006834, Avg batch loss: 0.6937, Avg batch acc: 0.3698
Train, Epoch: 2, Batch: 438, Step num: 1957, Learning rate: 0.00006837, Avg batch loss: 0.6786, Avg batch acc: 0.3860
Train, Epoch: 2, Batch: 439, Step num: 1958, Learning rate: 0.00006841, Avg batch loss: 0.6563, Avg batch acc: 0.3843
Train, Epoch: 2, Batch: 440, Step num: 1959, Learning rate: 0.00006844, Avg batch loss: 0.6175, Avg batch acc: 0.3874
Train, Epoch: 2, Batch: 441, Step num: 1960, Learning rate: 0.00006848, Avg batch loss: 0.6544, Avg batch acc: 0.3658
Train, Epoch: 2, Batch: 442, Step num: 1961, Learning rate: 0.00006851, Avg batch loss: 0.6672, Avg batch acc: 0.3787
Train, Epoch: 2, Batch: 443, Step num: 1962, Learning rate: 0.00006855, Avg batch loss: 0.7000, Avg batch acc: 0.3838
Train, Epoch: 2, Batch: 444, Step num: 1963, Learning rate: 0.00006858, Avg batch loss: 0.6806, Avg batch acc: 0.3669
Train, Epoch: 2, Batch: 445, Step num: 1964, Learning rate: 0.00006862, Avg batch loss: 0.7177, Avg batch acc: 0.3631
Train, Epoch: 2, Batch: 446, Step num: 1965, Learning rate: 0.00006865, Avg batch loss: 0.6719, Avg batch acc: 0.3957
Train, Epoch: 2, Batch: 447, Step num: 1966, Learning rate: 0.00006869, Avg batch loss: 0.7061, Avg batch acc: 0.3567
Train, Epoch: 2, Batch: 448, Step num: 1967, Learning rate: 0.00006872, Avg batch loss: 0.6783, Avg batch acc: 0.3809
Train, Epoch: 2, Batch: 449, Step num: 1968, Learning rate: 0.00006876, Avg batch loss: 0.6758, Avg batch acc: 0.3795
Train, Epoch: 2, Batch: 450, Step num: 1969, Learning rate: 0.00006879, Avg batch loss: 0.6579, Avg batch acc: 0.3632
Train, Epoch: 2, Batch: 451, Step num: 1970, Learning rate: 0.00006883, Avg batch loss: 0.6437, Avg batch acc: 0.3977
Train, Epoch: 2, Batch: 452, Step num: 1971, Learning rate: 0.00006886, Avg batch loss: 0.7079, Avg batch acc: 0.3811
Train, Epoch: 2, Batch: 453, Step num: 1972, Learning rate: 0.00006890, Avg batch loss: 0.7242, Avg batch acc: 0.3672
Train, Epoch: 2, Batch: 454, Step num: 1973, Learning rate: 0.00006893, Avg batch loss: 0.6579, Avg batch acc: 0.3681
Train, Epoch: 2, Batch: 455, Step num: 1974, Learning rate: 0.00006897, Avg batch loss: 0.7494, Avg batch acc: 0.3582
Train, Epoch: 2, Batch: 456, Step num: 1975, Learning rate: 0.00006900, Avg batch loss: 0.6350, Avg batch acc: 0.3739
Train, Epoch: 2, Batch: 457, Step num: 1976, Learning rate: 0.00006904, Avg batch loss: 0.6768, Avg batch acc: 0.3823
Train, Epoch: 2, Batch: 458, Step num: 1977, Learning rate: 0.00006907, Avg batch loss: 0.6705, Avg batch acc: 0.3852
Train, Epoch: 2, Batch: 459, Step num: 1978, Learning rate: 0.00006911, Avg batch loss: 0.6820, Avg batch acc: 0.3773
Train, Epoch: 2, Batch: 460, Step num: 1979, Learning rate: 0.00006914, Avg batch loss: 0.7122, Avg batch acc: 0.3667
Train, Epoch: 2, Batch: 461, Step num: 1980, Learning rate: 0.00006918, Avg batch loss: 0.6822, Avg batch acc: 0.3927
Train, Epoch: 2, Batch: 462, Step num: 1981, Learning rate: 0.00006921, Avg batch loss: 0.6799, Avg batch acc: 0.3795
Train, Epoch: 2, Batch: 463, Step num: 1982, Learning rate: 0.00006925, Avg batch loss: 0.6626, Avg batch acc: 0.3839
Train, Epoch: 2, Batch: 464, Step num: 1983, Learning rate: 0.00006928, Avg batch loss: 0.6849, Avg batch acc: 0.3729
Train, Epoch: 2, Batch: 465, Step num: 1984, Learning rate: 0.00006932, Avg batch loss: 0.6841, Avg batch acc: 0.3676
Train, Epoch: 2, Batch: 466, Step num: 1985, Learning rate: 0.00006935, Avg batch loss: 0.6753, Avg batch acc: 0.3639
Train, Epoch: 2, Batch: 467, Step num: 1986, Learning rate: 0.00006939, Avg batch loss: 0.6956, Avg batch acc: 0.3630
Train, Epoch: 2, Batch: 468, Step num: 1987, Learning rate: 0.00006942, Avg batch loss: 0.6687, Avg batch acc: 0.3789
Train, Epoch: 2, Batch: 469, Step num: 1988, Learning rate: 0.00006946, Avg batch loss: 0.6256, Avg batch acc: 0.3881
Train, Epoch: 2, Batch: 470, Step num: 1989, Learning rate: 0.00006949, Avg batch loss: 0.6090, Avg batch acc: 0.4040
Train, Epoch: 2, Batch: 471, Step num: 1990, Learning rate: 0.00006953, Avg batch loss: 0.6823, Avg batch acc: 0.3620
Train, Epoch: 2, Batch: 472, Step num: 1991, Learning rate: 0.00006956, Avg batch loss: 0.6789, Avg batch acc: 0.3796
Train, Epoch: 2, Batch: 473, Step num: 1992, Learning rate: 0.00006960, Avg batch loss: 0.6592, Avg batch acc: 0.3778
Train, Epoch: 2, Batch: 474, Step num: 1993, Learning rate: 0.00006963, Avg batch loss: 0.6762, Avg batch acc: 0.3699
Train, Epoch: 2, Batch: 475, Step num: 1994, Learning rate: 0.00006967, Avg batch loss: 0.7396, Avg batch acc: 0.3723
Train, Epoch: 2, Batch: 476, Step num: 1995, Learning rate: 0.00006970, Avg batch loss: 0.6679, Avg batch acc: 0.3703
Train, Epoch: 2, Batch: 477, Step num: 1996, Learning rate: 0.00006974, Avg batch loss: 0.6601, Avg batch acc: 0.3763
Train, Epoch: 2, Batch: 478, Step num: 1997, Learning rate: 0.00006977, Avg batch loss: 0.7070, Avg batch acc: 0.3628
Train, Epoch: 2, Batch: 479, Step num: 1998, Learning rate: 0.00006981, Avg batch loss: 0.6461, Avg batch acc: 0.3608
Train, Epoch: 2, Batch: 480, Step num: 1999, Learning rate: 0.00006984, Avg batch loss: 0.6464, Avg batch acc: 0.3794
Train, Epoch: 2, Batch: 481, Step num: 2000, Learning rate: 0.00006988, Avg batch loss: 0.6820, Avg batch acc: 0.3755
Train, Epoch: 2, Batch: 482, Step num: 2001, Learning rate: 0.00006991, Avg batch loss: 0.6341, Avg batch acc: 0.3996
Train, Epoch: 2, Batch: 483, Step num: 2002, Learning rate: 0.00006995, Avg batch loss: 0.5928, Avg batch acc: 0.4004
Train, Epoch: 2, Batch: 484, Step num: 2003, Learning rate: 0.00006998, Avg batch loss: 0.6418, Avg batch acc: 0.3784
Train, Epoch: 2, Batch: 485, Step num: 2004, Learning rate: 0.00007002, Avg batch loss: 0.6628, Avg batch acc: 0.3822
Train, Epoch: 2, Batch: 486, Step num: 2005, Learning rate: 0.00007005, Avg batch loss: 0.7109, Avg batch acc: 0.3673
Train, Epoch: 2, Batch: 487, Step num: 2006, Learning rate: 0.00007009, Avg batch loss: 0.6535, Avg batch acc: 0.3780
Train, Epoch: 2, Batch: 488, Step num: 2007, Learning rate: 0.00007012, Avg batch loss: 0.6388, Avg batch acc: 0.3681
Train, Epoch: 2, Batch: 489, Step num: 2008, Learning rate: 0.00007016, Avg batch loss: 0.6445, Avg batch acc: 0.3734
Train, Epoch: 2, Batch: 490, Step num: 2009, Learning rate: 0.00007019, Avg batch loss: 0.6486, Avg batch acc: 0.3819
Train, Epoch: 2, Batch: 491, Step num: 2010, Learning rate: 0.00007023, Avg batch loss: 0.6845, Avg batch acc: 0.3725
Train, Epoch: 2, Batch: 492, Step num: 2011, Learning rate: 0.00007026, Avg batch loss: 0.6482, Avg batch acc: 0.3829
Train, Epoch: 2, Batch: 493, Step num: 2012, Learning rate: 0.00007030, Avg batch loss: 0.6645, Avg batch acc: 0.3624
Train, Epoch: 2, Batch: 494, Step num: 2013, Learning rate: 0.00007033, Avg batch loss: 0.6182, Avg batch acc: 0.3756
Train, Epoch: 2, Batch: 495, Step num: 2014, Learning rate: 0.00007037, Avg batch loss: 0.6394, Avg batch acc: 0.3889
Train, Epoch: 2, Batch: 496, Step num: 2015, Learning rate: 0.00007040, Avg batch loss: 0.6264, Avg batch acc: 0.3973
Train, Epoch: 2, Batch: 497, Step num: 2016, Learning rate: 0.00007044, Avg batch loss: 0.6512, Avg batch acc: 0.3829
Train, Epoch: 2, Batch: 498, Step num: 2017, Learning rate: 0.00007047, Avg batch loss: 0.6583, Avg batch acc: 0.3770
Train, Epoch: 2, Batch: 499, Step num: 2018, Learning rate: 0.00007051, Avg batch loss: 0.6256, Avg batch acc: 0.3730
Train, Epoch: 2, Batch: 500, Step num: 2019, Learning rate: 0.00007054, Avg batch loss: 0.6643, Avg batch acc: 0.3699
Train, Epoch: 2, Batch: 501, Step num: 2020, Learning rate: 0.00007058, Avg batch loss: 0.6579, Avg batch acc: 0.3752
Train, Epoch: 2, Batch: 502, Step num: 2021, Learning rate: 0.00007061, Avg batch loss: 0.6743, Avg batch acc: 0.3841
Train, Epoch: 2, Batch: 503, Step num: 2022, Learning rate: 0.00007065, Avg batch loss: 0.6376, Avg batch acc: 0.3675
Train, Epoch: 2, Batch: 504, Step num: 2023, Learning rate: 0.00007068, Avg batch loss: 0.7155, Avg batch acc: 0.3464
Train, Epoch: 2, Batch: 505, Step num: 2024, Learning rate: 0.00007072, Avg batch loss: 0.6510, Avg batch acc: 0.3874
Train, Epoch: 2, Batch: 506, Step num: 2025, Learning rate: 0.00007075, Avg batch loss: 0.6694, Avg batch acc: 0.3836
Train, Epoch: 2, Batch: 507, Step num: 2026, Learning rate: 0.00007079, Avg batch loss: 0.6452, Avg batch acc: 0.3758
Train, Epoch: 2, Batch: 508, Step num: 2027, Learning rate: 0.00007082, Avg batch loss: 0.6639, Avg batch acc: 0.3626
Train, Epoch: 2, Batch: 509, Step num: 2028, Learning rate: 0.00007086, Avg batch loss: 0.6330, Avg batch acc: 0.3849
Train, Epoch: 2, Batch: 510, Step num: 2029, Learning rate: 0.00007089, Avg batch loss: 0.6449, Avg batch acc: 0.3757
Train, Epoch: 2, Batch: 511, Step num: 2030, Learning rate: 0.00007093, Avg batch loss: 0.6418, Avg batch acc: 0.3823
Train, Epoch: 2, Batch: 512, Step num: 2031, Learning rate: 0.00007096, Avg batch loss: 0.7953, Avg batch acc: 0.3447
Train, Epoch: 2, Batch: 513, Step num: 2032, Learning rate: 0.00007100, Avg batch loss: 0.6036, Avg batch acc: 0.3919
Train, Epoch: 2, Batch: 514, Step num: 2033, Learning rate: 0.00007103, Avg batch loss: 0.6701, Avg batch acc: 0.3687
Train, Epoch: 2, Batch: 515, Step num: 2034, Learning rate: 0.00007107, Avg batch loss: 0.6924, Avg batch acc: 0.3570
Train, Epoch: 2, Batch: 516, Step num: 2035, Learning rate: 0.00007110, Avg batch loss: 0.6485, Avg batch acc: 0.3624
Train, Epoch: 2, Batch: 517, Step num: 2036, Learning rate: 0.00007113, Avg batch loss: 0.6632, Avg batch acc: 0.3724
Train, Epoch: 2, Batch: 518, Step num: 2037, Learning rate: 0.00007117, Avg batch loss: 0.5950, Avg batch acc: 0.3827
Train, Epoch: 2, Batch: 519, Step num: 2038, Learning rate: 0.00007120, Avg batch loss: 0.6457, Avg batch acc: 0.3985
Train, Epoch: 2, Batch: 520, Step num: 2039, Learning rate: 0.00007124, Avg batch loss: 0.6635, Avg batch acc: 0.3774
Train, Epoch: 2, Batch: 521, Step num: 2040, Learning rate: 0.00007127, Avg batch loss: 0.6308, Avg batch acc: 0.3744
Train, Epoch: 2, Batch: 522, Step num: 2041, Learning rate: 0.00007131, Avg batch loss: 0.6220, Avg batch acc: 0.4158
Train, Epoch: 2, Batch: 523, Step num: 2042, Learning rate: 0.00007134, Avg batch loss: 0.6491, Avg batch acc: 0.3898
Train, Epoch: 2, Batch: 524, Step num: 2043, Learning rate: 0.00007138, Avg batch loss: 0.6290, Avg batch acc: 0.3824
Train, Epoch: 2, Batch: 525, Step num: 2044, Learning rate: 0.00007141, Avg batch loss: 0.6144, Avg batch acc: 0.3819
Train, Epoch: 2, Batch: 526, Step num: 2045, Learning rate: 0.00007145, Avg batch loss: 0.6965, Avg batch acc: 0.3707
Train, Epoch: 2, Batch: 527, Step num: 2046, Learning rate: 0.00007148, Avg batch loss: 0.6486, Avg batch acc: 0.3799
Train, Epoch: 2, Batch: 528, Step num: 2047, Learning rate: 0.00007152, Avg batch loss: 0.6979, Avg batch acc: 0.3797
Train, Epoch: 2, Batch: 529, Step num: 2048, Learning rate: 0.00007155, Avg batch loss: 0.6366, Avg batch acc: 0.3923
Train, Epoch: 2, Batch: 530, Step num: 2049, Learning rate: 0.00007159, Avg batch loss: 0.6485, Avg batch acc: 0.4160
Train, Epoch: 2, Batch: 531, Step num: 2050, Learning rate: 0.00007162, Avg batch loss: 0.6700, Avg batch acc: 0.3806
Train, Epoch: 2, Batch: 532, Step num: 2051, Learning rate: 0.00007166, Avg batch loss: 0.6674, Avg batch acc: 0.3756
Train, Epoch: 2, Batch: 533, Step num: 2052, Learning rate: 0.00007169, Avg batch loss: 0.6553, Avg batch acc: 0.3898
Train, Epoch: 2, Batch: 534, Step num: 2053, Learning rate: 0.00007173, Avg batch loss: 0.6308, Avg batch acc: 0.3989
Train, Epoch: 2, Batch: 535, Step num: 2054, Learning rate: 0.00007176, Avg batch loss: 0.6318, Avg batch acc: 0.3774
Train, Epoch: 2, Batch: 536, Step num: 2055, Learning rate: 0.00007180, Avg batch loss: 0.6495, Avg batch acc: 0.3757
Train, Epoch: 2, Batch: 537, Step num: 2056, Learning rate: 0.00007183, Avg batch loss: 0.6803, Avg batch acc: 0.3906
Train, Epoch: 2, Batch: 538, Step num: 2057, Learning rate: 0.00007187, Avg batch loss: 0.6891, Avg batch acc: 0.3696
Train, Epoch: 2, Batch: 539, Step num: 2058, Learning rate: 0.00007190, Avg batch loss: 0.7043, Avg batch acc: 0.3717
Train, Epoch: 2, Batch: 540, Step num: 2059, Learning rate: 0.00007194, Avg batch loss: 0.6168, Avg batch acc: 0.3959
Train, Epoch: 2, Batch: 541, Step num: 2060, Learning rate: 0.00007197, Avg batch loss: 0.6766, Avg batch acc: 0.3580
Train, Epoch: 2, Batch: 542, Step num: 2061, Learning rate: 0.00007201, Avg batch loss: 0.6111, Avg batch acc: 0.3964
Train, Epoch: 2, Batch: 543, Step num: 2062, Learning rate: 0.00007204, Avg batch loss: 0.6360, Avg batch acc: 0.3834
Train, Epoch: 2, Batch: 544, Step num: 2063, Learning rate: 0.00007208, Avg batch loss: 0.6606, Avg batch acc: 0.3960
Train, Epoch: 2, Batch: 545, Step num: 2064, Learning rate: 0.00007211, Avg batch loss: 0.6662, Avg batch acc: 0.3815
Train, Epoch: 2, Batch: 546, Step num: 2065, Learning rate: 0.00007215, Avg batch loss: 0.6818, Avg batch acc: 0.3921
Train, Epoch: 2, Batch: 547, Step num: 2066, Learning rate: 0.00007218, Avg batch loss: 0.6485, Avg batch acc: 0.3777
Train, Epoch: 2, Batch: 548, Step num: 2067, Learning rate: 0.00007222, Avg batch loss: 0.7163, Avg batch acc: 0.3583
Train, Epoch: 2, Batch: 549, Step num: 2068, Learning rate: 0.00007225, Avg batch loss: 0.6945, Avg batch acc: 0.3630
Train, Epoch: 2, Batch: 550, Step num: 2069, Learning rate: 0.00007229, Avg batch loss: 0.5879, Avg batch acc: 0.4065
Train, Epoch: 2, Batch: 551, Step num: 2070, Learning rate: 0.00007232, Avg batch loss: 0.6853, Avg batch acc: 0.3863
Train, Epoch: 2, Batch: 552, Step num: 2071, Learning rate: 0.00007236, Avg batch loss: 0.6281, Avg batch acc: 0.3836
Train, Epoch: 2, Batch: 553, Step num: 2072, Learning rate: 0.00007239, Avg batch loss: 0.7851, Avg batch acc: 0.3378
Train, Epoch: 2, Batch: 554, Step num: 2073, Learning rate: 0.00007243, Avg batch loss: 0.6463, Avg batch acc: 0.3935
Train, Epoch: 2, Batch: 555, Step num: 2074, Learning rate: 0.00007246, Avg batch loss: 0.6081, Avg batch acc: 0.3994
Train, Epoch: 2, Batch: 556, Step num: 2075, Learning rate: 0.00007250, Avg batch loss: 0.6633, Avg batch acc: 0.3830
Train, Epoch: 2, Batch: 557, Step num: 2076, Learning rate: 0.00007253, Avg batch loss: 0.6417, Avg batch acc: 0.4010
Train, Epoch: 2, Batch: 558, Step num: 2077, Learning rate: 0.00007257, Avg batch loss: 0.6642, Avg batch acc: 0.3672
Train, Epoch: 2, Batch: 559, Step num: 2078, Learning rate: 0.00007260, Avg batch loss: 0.6702, Avg batch acc: 0.3810
Train, Epoch: 2, Batch: 560, Step num: 2079, Learning rate: 0.00007264, Avg batch loss: 0.6693, Avg batch acc: 0.3846
Train, Epoch: 2, Batch: 561, Step num: 2080, Learning rate: 0.00007267, Avg batch loss: 0.6874, Avg batch acc: 0.3756
Train, Epoch: 2, Batch: 562, Step num: 2081, Learning rate: 0.00007271, Avg batch loss: 0.6812, Avg batch acc: 0.3763
Train, Epoch: 2, Batch: 563, Step num: 2082, Learning rate: 0.00007274, Avg batch loss: 0.6439, Avg batch acc: 0.3697
Train, Epoch: 2, Batch: 564, Step num: 2083, Learning rate: 0.00007278, Avg batch loss: 0.6247, Avg batch acc: 0.3953
Train, Epoch: 2, Batch: 565, Step num: 2084, Learning rate: 0.00007281, Avg batch loss: 0.7436, Avg batch acc: 0.3865
Train, Epoch: 2, Batch: 566, Step num: 2085, Learning rate: 0.00007285, Avg batch loss: 0.6632, Avg batch acc: 0.3740
Train, Epoch: 2, Batch: 567, Step num: 2086, Learning rate: 0.00007288, Avg batch loss: 0.6457, Avg batch acc: 0.3801
Train, Epoch: 2, Batch: 568, Step num: 2087, Learning rate: 0.00007292, Avg batch loss: 0.7248, Avg batch acc: 0.3791
Train, Epoch: 2, Batch: 569, Step num: 2088, Learning rate: 0.00007295, Avg batch loss: 0.7101, Avg batch acc: 0.3875
Train, Epoch: 2, Batch: 570, Step num: 2089, Learning rate: 0.00007299, Avg batch loss: 0.6465, Avg batch acc: 0.3849
Train, Epoch: 2, Batch: 571, Step num: 2090, Learning rate: 0.00007302, Avg batch loss: 0.6272, Avg batch acc: 0.3984
Train, Epoch: 2, Batch: 572, Step num: 2091, Learning rate: 0.00007306, Avg batch loss: 0.6679, Avg batch acc: 0.3791
Train, Epoch: 2, Batch: 573, Step num: 2092, Learning rate: 0.00007309, Avg batch loss: 0.6317, Avg batch acc: 0.3849
Train, Epoch: 2, Batch: 574, Step num: 2093, Learning rate: 0.00007313, Avg batch loss: 0.6413, Avg batch acc: 0.3737
Train, Epoch: 2, Batch: 575, Step num: 2094, Learning rate: 0.00007316, Avg batch loss: 0.5867, Avg batch acc: 0.3836
Train, Epoch: 2, Batch: 576, Step num: 2095, Learning rate: 0.00007320, Avg batch loss: 0.6880, Avg batch acc: 0.3773
Train, Epoch: 2, Batch: 577, Step num: 2096, Learning rate: 0.00007323, Avg batch loss: 0.6321, Avg batch acc: 0.4056
Train, Epoch: 2, Batch: 578, Step num: 2097, Learning rate: 0.00007327, Avg batch loss: 0.6699, Avg batch acc: 0.3910
Train, Epoch: 2, Batch: 579, Step num: 2098, Learning rate: 0.00007330, Avg batch loss: 0.6468, Avg batch acc: 0.3818
Train, Epoch: 2, Batch: 580, Step num: 2099, Learning rate: 0.00007334, Avg batch loss: 0.5960, Avg batch acc: 0.3855
Train, Epoch: 2, Batch: 581, Step num: 2100, Learning rate: 0.00007337, Avg batch loss: 0.6951, Avg batch acc: 0.3679
Train, Epoch: 2, Batch: 582, Step num: 2101, Learning rate: 0.00007341, Avg batch loss: 0.5961, Avg batch acc: 0.3992
Train, Epoch: 2, Batch: 583, Step num: 2102, Learning rate: 0.00007344, Avg batch loss: 0.7242, Avg batch acc: 0.3796
Train, Epoch: 2, Batch: 584, Step num: 2103, Learning rate: 0.00007348, Avg batch loss: 0.6790, Avg batch acc: 0.3791
Train, Epoch: 2, Batch: 585, Step num: 2104, Learning rate: 0.00007351, Avg batch loss: 0.6586, Avg batch acc: 0.3941
Train, Epoch: 2, Batch: 586, Step num: 2105, Learning rate: 0.00007355, Avg batch loss: 0.6888, Avg batch acc: 0.3942
Train, Epoch: 2, Batch: 587, Step num: 2106, Learning rate: 0.00007358, Avg batch loss: 0.6441, Avg batch acc: 0.3822
Train, Epoch: 2, Batch: 588, Step num: 2107, Learning rate: 0.00007362, Avg batch loss: 0.6551, Avg batch acc: 0.3827
Train, Epoch: 2, Batch: 589, Step num: 2108, Learning rate: 0.00007365, Avg batch loss: 0.6390, Avg batch acc: 0.3807
Train, Epoch: 2, Batch: 590, Step num: 2109, Learning rate: 0.00007369, Avg batch loss: 0.6682, Avg batch acc: 0.3855
Train, Epoch: 2, Batch: 591, Step num: 2110, Learning rate: 0.00007372, Avg batch loss: 0.6228, Avg batch acc: 0.4046
Train, Epoch: 2, Batch: 592, Step num: 2111, Learning rate: 0.00007376, Avg batch loss: 0.6497, Avg batch acc: 0.3880
Train, Epoch: 2, Batch: 593, Step num: 2112, Learning rate: 0.00007379, Avg batch loss: 0.6156, Avg batch acc: 0.3865
Train, Epoch: 2, Batch: 594, Step num: 2113, Learning rate: 0.00007383, Avg batch loss: 0.6941, Avg batch acc: 0.3706
Train, Epoch: 2, Batch: 595, Step num: 2114, Learning rate: 0.00007386, Avg batch loss: 0.6763, Avg batch acc: 0.3779
Train, Epoch: 2, Batch: 596, Step num: 2115, Learning rate: 0.00007390, Avg batch loss: 0.7190, Avg batch acc: 0.3661
Train, Epoch: 2, Batch: 597, Step num: 2116, Learning rate: 0.00007393, Avg batch loss: 0.6706, Avg batch acc: 0.3903
Train, Epoch: 2, Batch: 598, Step num: 2117, Learning rate: 0.00007396, Avg batch loss: 0.6229, Avg batch acc: 0.3998
Train, Epoch: 2, Batch: 599, Step num: 2118, Learning rate: 0.00007400, Avg batch loss: 0.6460, Avg batch acc: 0.3927
Train, Epoch: 2, Batch: 600, Step num: 2119, Learning rate: 0.00007403, Avg batch loss: 0.5938, Avg batch acc: 0.3916
Train, Epoch: 2, Batch: 601, Step num: 2120, Learning rate: 0.00007407, Avg batch loss: 0.6687, Avg batch acc: 0.3884
Train, Epoch: 2, Batch: 602, Step num: 2121, Learning rate: 0.00007410, Avg batch loss: 0.7033, Avg batch acc: 0.3892
Train, Epoch: 2, Batch: 603, Step num: 2122, Learning rate: 0.00007414, Avg batch loss: 0.6196, Avg batch acc: 0.4055
Train, Epoch: 2, Batch: 604, Step num: 2123, Learning rate: 0.00007417, Avg batch loss: 0.5604, Avg batch acc: 0.4299
Train, Epoch: 2, Batch: 605, Step num: 2124, Learning rate: 0.00007421, Avg batch loss: 0.6607, Avg batch acc: 0.3873
Train, Epoch: 2, Batch: 606, Step num: 2125, Learning rate: 0.00007424, Avg batch loss: 0.6514, Avg batch acc: 0.3792
Train, Epoch: 2, Batch: 607, Step num: 2126, Learning rate: 0.00007428, Avg batch loss: 0.6645, Avg batch acc: 0.3822
Train, Epoch: 2, Batch: 608, Step num: 2127, Learning rate: 0.00007431, Avg batch loss: 0.6742, Avg batch acc: 0.3848
Train, Epoch: 2, Batch: 609, Step num: 2128, Learning rate: 0.00007435, Avg batch loss: 0.6368, Avg batch acc: 0.3893
Train, Epoch: 2, Batch: 610, Step num: 2129, Learning rate: 0.00007438, Avg batch loss: 0.6185, Avg batch acc: 0.3944
Train, Epoch: 2, Batch: 611, Step num: 2130, Learning rate: 0.00007442, Avg batch loss: 0.6770, Avg batch acc: 0.3731
Train, Epoch: 2, Batch: 612, Step num: 2131, Learning rate: 0.00007445, Avg batch loss: 0.6099, Avg batch acc: 0.4149
Train, Epoch: 2, Batch: 613, Step num: 2132, Learning rate: 0.00007449, Avg batch loss: 0.6894, Avg batch acc: 0.3944
Train, Epoch: 2, Batch: 614, Step num: 2133, Learning rate: 0.00007452, Avg batch loss: 0.6471, Avg batch acc: 0.4131
Train, Epoch: 2, Batch: 615, Step num: 2134, Learning rate: 0.00007456, Avg batch loss: 0.6998, Avg batch acc: 0.3724
Train, Epoch: 2, Batch: 616, Step num: 2135, Learning rate: 0.00007459, Avg batch loss: 0.6664, Avg batch acc: 0.3768
Train, Epoch: 2, Batch: 617, Step num: 2136, Learning rate: 0.00007463, Avg batch loss: 0.6544, Avg batch acc: 0.3807
Train, Epoch: 2, Batch: 618, Step num: 2137, Learning rate: 0.00007466, Avg batch loss: 0.6643, Avg batch acc: 0.3965
Train, Epoch: 2, Batch: 619, Step num: 2138, Learning rate: 0.00007470, Avg batch loss: 0.6734, Avg batch acc: 0.3908
Train, Epoch: 2, Batch: 620, Step num: 2139, Learning rate: 0.00007473, Avg batch loss: 0.5904, Avg batch acc: 0.3815
Train, Epoch: 2, Batch: 621, Step num: 2140, Learning rate: 0.00007477, Avg batch loss: 0.6491, Avg batch acc: 0.3951
Train, Epoch: 2, Batch: 622, Step num: 2141, Learning rate: 0.00007480, Avg batch loss: 0.6469, Avg batch acc: 0.3872
Train, Epoch: 2, Batch: 623, Step num: 2142, Learning rate: 0.00007484, Avg batch loss: 0.6818, Avg batch acc: 0.3829
Train, Epoch: 2, Batch: 624, Step num: 2143, Learning rate: 0.00007487, Avg batch loss: 0.6494, Avg batch acc: 0.3826
Train, Epoch: 2, Batch: 625, Step num: 2144, Learning rate: 0.00007491, Avg batch loss: 0.6369, Avg batch acc: 0.4111
Train, Epoch: 2, Batch: 626, Step num: 2145, Learning rate: 0.00007494, Avg batch loss: 0.6586, Avg batch acc: 0.3933
Train, Epoch: 2, Batch: 627, Step num: 2146, Learning rate: 0.00007498, Avg batch loss: 0.6452, Avg batch acc: 0.4011
Train, Epoch: 2, Batch: 628, Step num: 2147, Learning rate: 0.00007501, Avg batch loss: 0.6365, Avg batch acc: 0.3890
Train, Epoch: 2, Batch: 629, Step num: 2148, Learning rate: 0.00007505, Avg batch loss: 0.6590, Avg batch acc: 0.4097
Train, Epoch: 2, Batch: 630, Step num: 2149, Learning rate: 0.00007508, Avg batch loss: 0.6702, Avg batch acc: 0.3874
Train, Epoch: 2, Batch: 631, Step num: 2150, Learning rate: 0.00007512, Avg batch loss: 0.6057, Avg batch acc: 0.3830
Train, Epoch: 2, Batch: 632, Step num: 2151, Learning rate: 0.00007515, Avg batch loss: 0.6463, Avg batch acc: 0.3789
Train, Epoch: 2, Batch: 633, Step num: 2152, Learning rate: 0.00007519, Avg batch loss: 0.6550, Avg batch acc: 0.3664
Train, Epoch: 2, Batch: 634, Step num: 2153, Learning rate: 0.00007522, Avg batch loss: 0.6471, Avg batch acc: 0.4046
Train, Epoch: 2, Batch: 635, Step num: 2154, Learning rate: 0.00007526, Avg batch loss: 0.6779, Avg batch acc: 0.4011
Train, Epoch: 2, Batch: 636, Step num: 2155, Learning rate: 0.00007529, Avg batch loss: 0.6419, Avg batch acc: 0.3856
Train, Epoch: 2, Batch: 637, Step num: 2156, Learning rate: 0.00007533, Avg batch loss: 0.7571, Avg batch acc: 0.3820
Train, Epoch: 2, Batch: 638, Step num: 2157, Learning rate: 0.00007536, Avg batch loss: 0.6117, Avg batch acc: 0.4015
Train, Epoch: 2, Batch: 639, Step num: 2158, Learning rate: 0.00007540, Avg batch loss: 0.6668, Avg batch acc: 0.3710
Train, Epoch: 2, Batch: 640, Step num: 2159, Learning rate: 0.00007543, Avg batch loss: 0.6643, Avg batch acc: 0.3831
Train, Epoch: 2, Batch: 641, Step num: 2160, Learning rate: 0.00007547, Avg batch loss: 0.7056, Avg batch acc: 0.3854
Train, Epoch: 2, Batch: 642, Step num: 2161, Learning rate: 0.00007550, Avg batch loss: 0.6251, Avg batch acc: 0.3855
Train, Epoch: 2, Batch: 643, Step num: 2162, Learning rate: 0.00007554, Avg batch loss: 0.6485, Avg batch acc: 0.4091
Train, Epoch: 2, Batch: 644, Step num: 2163, Learning rate: 0.00007557, Avg batch loss: 0.6763, Avg batch acc: 0.3779
Train, Epoch: 2, Batch: 645, Step num: 2164, Learning rate: 0.00007561, Avg batch loss: 0.6220, Avg batch acc: 0.4113
Train, Epoch: 2, Batch: 646, Step num: 2165, Learning rate: 0.00007564, Avg batch loss: 0.6625, Avg batch acc: 0.3829
Train, Epoch: 2, Batch: 647, Step num: 2166, Learning rate: 0.00007568, Avg batch loss: 0.6342, Avg batch acc: 0.4072
Train, Epoch: 2, Batch: 648, Step num: 2167, Learning rate: 0.00007571, Avg batch loss: 0.6686, Avg batch acc: 0.4029
Train, Epoch: 2, Batch: 649, Step num: 2168, Learning rate: 0.00007575, Avg batch loss: 0.6271, Avg batch acc: 0.4161
Train, Epoch: 2, Batch: 650, Step num: 2169, Learning rate: 0.00007578, Avg batch loss: 0.6288, Avg batch acc: 0.4068
Train, Epoch: 2, Batch: 651, Step num: 2170, Learning rate: 0.00007582, Avg batch loss: 0.6206, Avg batch acc: 0.3969
Train, Epoch: 2, Batch: 652, Step num: 2171, Learning rate: 0.00007585, Avg batch loss: 0.6353, Avg batch acc: 0.3917
Train, Epoch: 2, Batch: 653, Step num: 2172, Learning rate: 0.00007589, Avg batch loss: 0.6455, Avg batch acc: 0.3913
Train, Epoch: 2, Batch: 654, Step num: 2173, Learning rate: 0.00007592, Avg batch loss: 0.5844, Avg batch acc: 0.3974
Train, Epoch: 2, Batch: 655, Step num: 2174, Learning rate: 0.00007596, Avg batch loss: 0.6345, Avg batch acc: 0.4063
Train, Epoch: 2, Batch: 656, Step num: 2175, Learning rate: 0.00007599, Avg batch loss: 0.6720, Avg batch acc: 0.3696
Train, Epoch: 2, Batch: 657, Step num: 2176, Learning rate: 0.00007603, Avg batch loss: 0.6047, Avg batch acc: 0.4012
Train, Epoch: 2, Batch: 658, Step num: 2177, Learning rate: 0.00007606, Avg batch loss: 0.6536, Avg batch acc: 0.4059
Train, Epoch: 2, Batch: 659, Step num: 2178, Learning rate: 0.00007610, Avg batch loss: 0.6175, Avg batch acc: 0.3952
Train, Epoch: 2, Batch: 660, Step num: 2179, Learning rate: 0.00007613, Avg batch loss: 0.5840, Avg batch acc: 0.4122
Train, Epoch: 2, Batch: 661, Step num: 2180, Learning rate: 0.00007617, Avg batch loss: 0.6430, Avg batch acc: 0.4032
Train, Epoch: 2, Batch: 662, Step num: 2181, Learning rate: 0.00007620, Avg batch loss: 0.6822, Avg batch acc: 0.3931
Train, Epoch: 2, Batch: 663, Step num: 2182, Learning rate: 0.00007624, Avg batch loss: 0.6659, Avg batch acc: 0.3877
Train, Epoch: 2, Batch: 664, Step num: 2183, Learning rate: 0.00007627, Avg batch loss: 0.6675, Avg batch acc: 0.3748
Train, Epoch: 2, Batch: 665, Step num: 2184, Learning rate: 0.00007631, Avg batch loss: 0.6573, Avg batch acc: 0.4126
Train, Epoch: 2, Batch: 666, Step num: 2185, Learning rate: 0.00007634, Avg batch loss: 0.6572, Avg batch acc: 0.3975
Train, Epoch: 2, Batch: 667, Step num: 2186, Learning rate: 0.00007638, Avg batch loss: 0.6564, Avg batch acc: 0.4000
Train, Epoch: 2, Batch: 668, Step num: 2187, Learning rate: 0.00007641, Avg batch loss: 0.6409, Avg batch acc: 0.3924
Train, Epoch: 2, Batch: 669, Step num: 2188, Learning rate: 0.00007645, Avg batch loss: 0.6109, Avg batch acc: 0.3806
Train, Epoch: 2, Batch: 670, Step num: 2189, Learning rate: 0.00007648, Avg batch loss: 0.6352, Avg batch acc: 0.3933
Train, Epoch: 2, Batch: 671, Step num: 2190, Learning rate: 0.00007652, Avg batch loss: 0.6639, Avg batch acc: 0.3817
Train, Epoch: 2, Batch: 672, Step num: 2191, Learning rate: 0.00007655, Avg batch loss: 0.6082, Avg batch acc: 0.4053
Train, Epoch: 2, Batch: 673, Step num: 2192, Learning rate: 0.00007659, Avg batch loss: 0.5912, Avg batch acc: 0.4023
Train, Epoch: 2, Batch: 674, Step num: 2193, Learning rate: 0.00007662, Avg batch loss: 0.6473, Avg batch acc: 0.3879
Train, Epoch: 2, Batch: 675, Step num: 2194, Learning rate: 0.00007666, Avg batch loss: 0.6033, Avg batch acc: 0.4196
Train, Epoch: 2, Batch: 676, Step num: 2195, Learning rate: 0.00007669, Avg batch loss: 0.6668, Avg batch acc: 0.3924
Train, Epoch: 2, Batch: 677, Step num: 2196, Learning rate: 0.00007673, Avg batch loss: 0.6970, Avg batch acc: 0.3762
Train, Epoch: 2, Batch: 678, Step num: 2197, Learning rate: 0.00007676, Avg batch loss: 0.6939, Avg batch acc: 0.3860
Train, Epoch: 2, Batch: 679, Step num: 2198, Learning rate: 0.00007679, Avg batch loss: 0.6387, Avg batch acc: 0.3875
Train, Epoch: 2, Batch: 680, Step num: 2199, Learning rate: 0.00007683, Avg batch loss: 0.6646, Avg batch acc: 0.3744
Train, Epoch: 2, Batch: 681, Step num: 2200, Learning rate: 0.00007686, Avg batch loss: 0.7044, Avg batch acc: 0.3808
Train, Epoch: 2, Batch: 682, Step num: 2201, Learning rate: 0.00007690, Avg batch loss: 0.6121, Avg batch acc: 0.3956
Train, Epoch: 2, Batch: 683, Step num: 2202, Learning rate: 0.00007693, Avg batch loss: 0.7319, Avg batch acc: 0.3588
Train, Epoch: 2, Batch: 684, Step num: 2203, Learning rate: 0.00007697, Avg batch loss: 0.6456, Avg batch acc: 0.3945
Train, Epoch: 2, Batch: 685, Step num: 2204, Learning rate: 0.00007700, Avg batch loss: 0.6247, Avg batch acc: 0.4117
Train, Epoch: 2, Batch: 686, Step num: 2205, Learning rate: 0.00007704, Avg batch loss: 0.6584, Avg batch acc: 0.3843
Train, Epoch: 2, Batch: 687, Step num: 2206, Learning rate: 0.00007707, Avg batch loss: 0.7029, Avg batch acc: 0.3884
Train, Epoch: 2, Batch: 688, Step num: 2207, Learning rate: 0.00007711, Avg batch loss: 0.5966, Avg batch acc: 0.4209
Train, Epoch: 2, Batch: 689, Step num: 2208, Learning rate: 0.00007714, Avg batch loss: 0.6455, Avg batch acc: 0.3847
Train, Epoch: 2, Batch: 690, Step num: 2209, Learning rate: 0.00007718, Avg batch loss: 0.6370, Avg batch acc: 0.3779
Train, Epoch: 2, Batch: 691, Step num: 2210, Learning rate: 0.00007721, Avg batch loss: 0.6558, Avg batch acc: 0.3987
Train, Epoch: 2, Batch: 692, Step num: 2211, Learning rate: 0.00007725, Avg batch loss: 0.6199, Avg batch acc: 0.3828
Train, Epoch: 2, Batch: 693, Step num: 2212, Learning rate: 0.00007728, Avg batch loss: 0.5879, Avg batch acc: 0.3991
Train, Epoch: 2, Batch: 694, Step num: 2213, Learning rate: 0.00007732, Avg batch loss: 0.6506, Avg batch acc: 0.3589
Train, Epoch: 2, Batch: 695, Step num: 2214, Learning rate: 0.00007735, Avg batch loss: 0.6571, Avg batch acc: 0.3948
Train, Epoch: 2, Batch: 696, Step num: 2215, Learning rate: 0.00007739, Avg batch loss: 0.6337, Avg batch acc: 0.3999
Train, Epoch: 2, Batch: 697, Step num: 2216, Learning rate: 0.00007742, Avg batch loss: 0.6225, Avg batch acc: 0.4144
Train, Epoch: 2, Batch: 698, Step num: 2217, Learning rate: 0.00007746, Avg batch loss: 0.6375, Avg batch acc: 0.3881
Train, Epoch: 2, Batch: 699, Step num: 2218, Learning rate: 0.00007749, Avg batch loss: 0.6369, Avg batch acc: 0.3948
Train, Epoch: 2, Batch: 700, Step num: 2219, Learning rate: 0.00007753, Avg batch loss: 0.6794, Avg batch acc: 0.3805
Train, Epoch: 2, Batch: 701, Step num: 2220, Learning rate: 0.00007756, Avg batch loss: 0.6663, Avg batch acc: 0.3957
Train, Epoch: 2, Batch: 702, Step num: 2221, Learning rate: 0.00007760, Avg batch loss: 0.6071, Avg batch acc: 0.3867
Train, Epoch: 2, Batch: 703, Step num: 2222, Learning rate: 0.00007763, Avg batch loss: 0.7029, Avg batch acc: 0.3822
Train, Epoch: 2, Batch: 704, Step num: 2223, Learning rate: 0.00007767, Avg batch loss: 0.6703, Avg batch acc: 0.3955
Train, Epoch: 2, Batch: 705, Step num: 2224, Learning rate: 0.00007770, Avg batch loss: 0.6872, Avg batch acc: 0.3700
Train, Epoch: 2, Batch: 706, Step num: 2225, Learning rate: 0.00007774, Avg batch loss: 0.6168, Avg batch acc: 0.3887
Train, Epoch: 2, Batch: 707, Step num: 2226, Learning rate: 0.00007777, Avg batch loss: 0.5703, Avg batch acc: 0.4054
Train, Epoch: 2, Batch: 708, Step num: 2227, Learning rate: 0.00007781, Avg batch loss: 0.6407, Avg batch acc: 0.3963
Train, Epoch: 2, Batch: 709, Step num: 2228, Learning rate: 0.00007784, Avg batch loss: 0.7025, Avg batch acc: 0.3899
Train, Epoch: 2, Batch: 710, Step num: 2229, Learning rate: 0.00007788, Avg batch loss: 0.6661, Avg batch acc: 0.3804
Train, Epoch: 2, Batch: 711, Step num: 2230, Learning rate: 0.00007791, Avg batch loss: 0.6408, Avg batch acc: 0.4025
Train, Epoch: 2, Batch: 712, Step num: 2231, Learning rate: 0.00007795, Avg batch loss: 0.6545, Avg batch acc: 0.4041
Train, Epoch: 2, Batch: 713, Step num: 2232, Learning rate: 0.00007798, Avg batch loss: 0.5871, Avg batch acc: 0.3962
Train, Epoch: 2, Batch: 714, Step num: 2233, Learning rate: 0.00007802, Avg batch loss: 0.6265, Avg batch acc: 0.3865
Train, Epoch: 2, Batch: 715, Step num: 2234, Learning rate: 0.00007805, Avg batch loss: 0.6782, Avg batch acc: 0.3652
Train, Epoch: 2, Batch: 716, Step num: 2235, Learning rate: 0.00007809, Avg batch loss: 0.6875, Avg batch acc: 0.3988
Train, Epoch: 2, Batch: 717, Step num: 2236, Learning rate: 0.00007812, Avg batch loss: 0.6045, Avg batch acc: 0.4144
Train, Epoch: 2, Batch: 718, Step num: 2237, Learning rate: 0.00007816, Avg batch loss: 0.6302, Avg batch acc: 0.4155
Train, Epoch: 2, Batch: 719, Step num: 2238, Learning rate: 0.00007819, Avg batch loss: 0.5980, Avg batch acc: 0.4142
Train, Epoch: 2, Batch: 720, Step num: 2239, Learning rate: 0.00007823, Avg batch loss: 0.6035, Avg batch acc: 0.4077
Train, Epoch: 2, Batch: 721, Step num: 2240, Learning rate: 0.00007826, Avg batch loss: 0.6288, Avg batch acc: 0.3971
Train, Epoch: 2, Batch: 722, Step num: 2241, Learning rate: 0.00007830, Avg batch loss: 0.6471, Avg batch acc: 0.3941
Train, Epoch: 2, Batch: 723, Step num: 2242, Learning rate: 0.00007833, Avg batch loss: 0.6455, Avg batch acc: 0.4151
Train, Epoch: 2, Batch: 724, Step num: 2243, Learning rate: 0.00007837, Avg batch loss: 0.6718, Avg batch acc: 0.3926
Train, Epoch: 2, Batch: 725, Step num: 2244, Learning rate: 0.00007840, Avg batch loss: 0.6554, Avg batch acc: 0.3837
Train, Epoch: 2, Batch: 726, Step num: 2245, Learning rate: 0.00007844, Avg batch loss: 0.6032, Avg batch acc: 0.4003
Train, Epoch: 2, Batch: 727, Step num: 2246, Learning rate: 0.00007847, Avg batch loss: 0.6771, Avg batch acc: 0.3962
Train, Epoch: 2, Batch: 728, Step num: 2247, Learning rate: 0.00007851, Avg batch loss: 0.6855, Avg batch acc: 0.3800
Train, Epoch: 2, Batch: 729, Step num: 2248, Learning rate: 0.00007854, Avg batch loss: 0.5935, Avg batch acc: 0.4042
Train, Epoch: 2, Batch: 730, Step num: 2249, Learning rate: 0.00007858, Avg batch loss: 0.6454, Avg batch acc: 0.3879
Train, Epoch: 2, Batch: 731, Step num: 2250, Learning rate: 0.00007861, Avg batch loss: 0.6559, Avg batch acc: 0.3872
Train, Epoch: 2, Batch: 732, Step num: 2251, Learning rate: 0.00007865, Avg batch loss: 0.6411, Avg batch acc: 0.3831
Train, Epoch: 2, Batch: 733, Step num: 2252, Learning rate: 0.00007868, Avg batch loss: 0.6542, Avg batch acc: 0.3954
Train, Epoch: 2, Batch: 734, Step num: 2253, Learning rate: 0.00007872, Avg batch loss: 0.5980, Avg batch acc: 0.4052
Train, Epoch: 2, Batch: 735, Step num: 2254, Learning rate: 0.00007875, Avg batch loss: 0.6108, Avg batch acc: 0.3954
Train, Epoch: 2, Batch: 736, Step num: 2255, Learning rate: 0.00007879, Avg batch loss: 0.7046, Avg batch acc: 0.3896
Train, Epoch: 2, Batch: 737, Step num: 2256, Learning rate: 0.00007882, Avg batch loss: 0.6243, Avg batch acc: 0.4172
Train, Epoch: 2, Batch: 738, Step num: 2257, Learning rate: 0.00007886, Avg batch loss: 0.6463, Avg batch acc: 0.4057
Train, Epoch: 2, Batch: 739, Step num: 2258, Learning rate: 0.00007889, Avg batch loss: 0.6538, Avg batch acc: 0.3758
Train, Epoch: 2, Batch: 740, Step num: 2259, Learning rate: 0.00007893, Avg batch loss: 0.6772, Avg batch acc: 0.3796
Train, Epoch: 2, Batch: 741, Step num: 2260, Learning rate: 0.00007896, Avg batch loss: 0.6561, Avg batch acc: 0.3990
Train, Epoch: 2, Batch: 742, Step num: 2261, Learning rate: 0.00007900, Avg batch loss: 0.6367, Avg batch acc: 0.3868
Train, Epoch: 2, Batch: 743, Step num: 2262, Learning rate: 0.00007903, Avg batch loss: 0.6465, Avg batch acc: 0.4023
Train, Epoch: 2, Batch: 744, Step num: 2263, Learning rate: 0.00007907, Avg batch loss: 0.6802, Avg batch acc: 0.4059
Train, Epoch: 2, Batch: 745, Step num: 2264, Learning rate: 0.00007910, Avg batch loss: 0.5924, Avg batch acc: 0.3874
Train, Epoch: 2, Batch: 746, Step num: 2265, Learning rate: 0.00007914, Avg batch loss: 0.6505, Avg batch acc: 0.4066
Train, Epoch: 2, Batch: 747, Step num: 2266, Learning rate: 0.00007917, Avg batch loss: 0.6434, Avg batch acc: 0.3771
Train, Epoch: 2, Batch: 748, Step num: 2267, Learning rate: 0.00007921, Avg batch loss: 0.6558, Avg batch acc: 0.4050
Train, Epoch: 2, Batch: 749, Step num: 2268, Learning rate: 0.00007924, Avg batch loss: 0.5873, Avg batch acc: 0.4123
Train, Epoch: 2, Batch: 750, Step num: 2269, Learning rate: 0.00007928, Avg batch loss: 0.6680, Avg batch acc: 0.4037
Train, Epoch: 2, Batch: 751, Step num: 2270, Learning rate: 0.00007931, Avg batch loss: 0.6058, Avg batch acc: 0.3895
Train, Epoch: 2, Batch: 752, Step num: 2271, Learning rate: 0.00007935, Avg batch loss: 0.6423, Avg batch acc: 0.3897
Train, Epoch: 2, Batch: 753, Step num: 2272, Learning rate: 0.00007938, Avg batch loss: 0.6356, Avg batch acc: 0.4023
Train, Epoch: 2, Batch: 754, Step num: 2273, Learning rate: 0.00007942, Avg batch loss: 0.6639, Avg batch acc: 0.3802
Train, Epoch: 2, Batch: 755, Step num: 2274, Learning rate: 0.00007945, Avg batch loss: 0.6254, Avg batch acc: 0.4051
Train, Epoch: 2, Batch: 756, Step num: 2275, Learning rate: 0.00007949, Avg batch loss: 0.6388, Avg batch acc: 0.4095
Train, Epoch: 2, Batch: 757, Step num: 2276, Learning rate: 0.00007952, Avg batch loss: 0.6350, Avg batch acc: 0.3930
Train, Epoch: 2, Batch: 758, Step num: 2277, Learning rate: 0.00007956, Avg batch loss: 0.6706, Avg batch acc: 0.3999
Train, Epoch: 2, Batch: 759, Step num: 2278, Learning rate: 0.00007959, Avg batch loss: 0.6746, Avg batch acc: 0.4020
Train, Epoch: 2, Batch: 760, Step num: 2279, Learning rate: 0.00007962, Avg batch loss: 0.6675, Avg batch acc: 0.3770
Train, Epoch: 2, Batch: 761, Step num: 2280, Learning rate: 0.00007966, Avg batch loss: 0.6229, Avg batch acc: 0.4114
Train, Epoch: 2, Batch: 762, Step num: 2281, Learning rate: 0.00007969, Avg batch loss: 0.6754, Avg batch acc: 0.4018
Train, Epoch: 2, Batch: 763, Step num: 2282, Learning rate: 0.00007973, Avg batch loss: 0.6355, Avg batch acc: 0.3887
Train, Epoch: 2, Batch: 764, Step num: 2283, Learning rate: 0.00007976, Avg batch loss: 0.6267, Avg batch acc: 0.3999
Train, Epoch: 2, Batch: 765, Step num: 2284, Learning rate: 0.00007980, Avg batch loss: 0.6263, Avg batch acc: 0.4054
Train, Epoch: 2, Batch: 766, Step num: 2285, Learning rate: 0.00007983, Avg batch loss: 0.6473, Avg batch acc: 0.3817
Train, Epoch: 2, Batch: 767, Step num: 2286, Learning rate: 0.00007987, Avg batch loss: 0.5754, Avg batch acc: 0.3993
Train, Epoch: 2, Batch: 768, Step num: 2287, Learning rate: 0.00007990, Avg batch loss: 0.6255, Avg batch acc: 0.4031
Train, Epoch: 2, Batch: 769, Step num: 2288, Learning rate: 0.00007994, Avg batch loss: 0.6180, Avg batch acc: 0.3939
Train, Epoch: 2, Batch: 770, Step num: 2289, Learning rate: 0.00007997, Avg batch loss: 0.6586, Avg batch acc: 0.4117
Train, Epoch: 2, Batch: 771, Step num: 2290, Learning rate: 0.00008001, Avg batch loss: 0.6513, Avg batch acc: 0.3953
Train, Epoch: 2, Batch: 772, Step num: 2291, Learning rate: 0.00008004, Avg batch loss: 0.6929, Avg batch acc: 0.3981
Train, Epoch: 2, Batch: 773, Step num: 2292, Learning rate: 0.00008008, Avg batch loss: 0.6675, Avg batch acc: 0.4124
Train, Epoch: 2, Batch: 774, Step num: 2293, Learning rate: 0.00008011, Avg batch loss: 0.6091, Avg batch acc: 0.3985
Train, Epoch: 2, Batch: 775, Step num: 2294, Learning rate: 0.00008015, Avg batch loss: 0.6631, Avg batch acc: 0.4017
Train, Epoch: 2, Batch: 776, Step num: 2295, Learning rate: 0.00008018, Avg batch loss: 0.6787, Avg batch acc: 0.3829
Train, Epoch: 2, Batch: 777, Step num: 2296, Learning rate: 0.00008022, Avg batch loss: 0.6401, Avg batch acc: 0.3824
Train, Epoch: 2, Batch: 778, Step num: 2297, Learning rate: 0.00008025, Avg batch loss: 0.6318, Avg batch acc: 0.4195
Train, Epoch: 2, Batch: 779, Step num: 2298, Learning rate: 0.00008029, Avg batch loss: 0.6508, Avg batch acc: 0.3992
Train, Epoch: 2, Batch: 780, Step num: 2299, Learning rate: 0.00008032, Avg batch loss: 0.6263, Avg batch acc: 0.4013
Train, Epoch: 2, Batch: 781, Step num: 2300, Learning rate: 0.00008036, Avg batch loss: 0.6680, Avg batch acc: 0.3759
Train, Epoch: 2, Batch: 782, Step num: 2301, Learning rate: 0.00008039, Avg batch loss: 0.6335, Avg batch acc: 0.4133
Train, Epoch: 2, Batch: 783, Step num: 2302, Learning rate: 0.00008043, Avg batch loss: 0.5940, Avg batch acc: 0.4118
Train, Epoch: 2, Batch: 784, Step num: 2303, Learning rate: 0.00008046, Avg batch loss: 0.6253, Avg batch acc: 0.4018
Train, Epoch: 2, Batch: 785, Step num: 2304, Learning rate: 0.00008050, Avg batch loss: 0.6416, Avg batch acc: 0.4015
Train, Epoch: 2, Batch: 786, Step num: 2305, Learning rate: 0.00008053, Avg batch loss: 0.6286, Avg batch acc: 0.3997
Train, Epoch: 2, Batch: 787, Step num: 2306, Learning rate: 0.00008057, Avg batch loss: 0.6012, Avg batch acc: 0.3909
Train, Epoch: 2, Batch: 788, Step num: 2307, Learning rate: 0.00008060, Avg batch loss: 0.7088, Avg batch acc: 0.3786
Train, Epoch: 2, Batch: 789, Step num: 2308, Learning rate: 0.00008064, Avg batch loss: 0.6510, Avg batch acc: 0.3954
Train, Epoch: 2, Batch: 790, Step num: 2309, Learning rate: 0.00008067, Avg batch loss: 0.6303, Avg batch acc: 0.4033
Train, Epoch: 2, Batch: 791, Step num: 2310, Learning rate: 0.00008071, Avg batch loss: 0.6905, Avg batch acc: 0.3664
Train, Epoch: 2, Batch: 792, Step num: 2311, Learning rate: 0.00008074, Avg batch loss: 0.6286, Avg batch acc: 0.3972
Train, Epoch: 2, Batch: 793, Step num: 2312, Learning rate: 0.00008078, Avg batch loss: 0.7155, Avg batch acc: 0.3952
Train, Epoch: 2, Batch: 794, Step num: 2313, Learning rate: 0.00008081, Avg batch loss: 0.6308, Avg batch acc: 0.4034
Train, Epoch: 2, Batch: 795, Step num: 2314, Learning rate: 0.00008085, Avg batch loss: 0.6573, Avg batch acc: 0.4068
Train, Epoch: 2, Batch: 796, Step num: 2315, Learning rate: 0.00008088, Avg batch loss: 0.6733, Avg batch acc: 0.3808
Train, Epoch: 2, Batch: 797, Step num: 2316, Learning rate: 0.00008092, Avg batch loss: 0.6014, Avg batch acc: 0.4008
Train, Epoch: 2, Batch: 798, Step num: 2317, Learning rate: 0.00008095, Avg batch loss: 0.6032, Avg batch acc: 0.4149
Train, Epoch: 2, Batch: 799, Step num: 2318, Learning rate: 0.00008099, Avg batch loss: 0.6192, Avg batch acc: 0.4105
Train, Epoch: 2, Batch: 800, Step num: 2319, Learning rate: 0.00008102, Avg batch loss: 0.7186, Avg batch acc: 0.3904
Train, Epoch: 2, Batch: 801, Step num: 2320, Learning rate: 0.00008106, Avg batch loss: 0.5906, Avg batch acc: 0.3980
Train, Epoch: 2, Batch: 802, Step num: 2321, Learning rate: 0.00008109, Avg batch loss: 0.6111, Avg batch acc: 0.4081
Train, Epoch: 2, Batch: 803, Step num: 2322, Learning rate: 0.00008113, Avg batch loss: 0.6095, Avg batch acc: 0.4189
Train, Epoch: 2, Batch: 804, Step num: 2323, Learning rate: 0.00008116, Avg batch loss: 0.6174, Avg batch acc: 0.4144
Train, Epoch: 2, Batch: 805, Step num: 2324, Learning rate: 0.00008120, Avg batch loss: 0.5971, Avg batch acc: 0.3972
Train, Epoch: 2, Batch: 806, Step num: 2325, Learning rate: 0.00008123, Avg batch loss: 0.6282, Avg batch acc: 0.3970
Train, Epoch: 2, Batch: 807, Step num: 2326, Learning rate: 0.00008127, Avg batch loss: 0.6564, Avg batch acc: 0.4055
Train, Epoch: 2, Batch: 808, Step num: 2327, Learning rate: 0.00008130, Avg batch loss: 0.6374, Avg batch acc: 0.4114
Train, Epoch: 2, Batch: 809, Step num: 2328, Learning rate: 0.00008134, Avg batch loss: 0.6521, Avg batch acc: 0.3984
Train, Epoch: 2, Batch: 810, Step num: 2329, Learning rate: 0.00008137, Avg batch loss: 0.5970, Avg batch acc: 0.4017
Train, Epoch: 2, Batch: 811, Step num: 2330, Learning rate: 0.00008141, Avg batch loss: 0.5896, Avg batch acc: 0.3768
Train, Epoch: 2, Batch: 812, Step num: 2331, Learning rate: 0.00008144, Avg batch loss: 0.6589, Avg batch acc: 0.3996
Train, Epoch: 2, Batch: 813, Step num: 2332, Learning rate: 0.00008148, Avg batch loss: 0.6322, Avg batch acc: 0.4240
Train, Epoch: 2, Batch: 814, Step num: 2333, Learning rate: 0.00008151, Avg batch loss: 0.6225, Avg batch acc: 0.4237
Train, Epoch: 2, Batch: 815, Step num: 2334, Learning rate: 0.00008155, Avg batch loss: 0.6031, Avg batch acc: 0.4100
Train, Epoch: 2, Batch: 816, Step num: 2335, Learning rate: 0.00008158, Avg batch loss: 0.5968, Avg batch acc: 0.4099
Train, Epoch: 2, Batch: 817, Step num: 2336, Learning rate: 0.00008162, Avg batch loss: 0.6071, Avg batch acc: 0.3925
Train, Epoch: 2, Batch: 818, Step num: 2337, Learning rate: 0.00008165, Avg batch loss: 0.5629, Avg batch acc: 0.4150
Train, Epoch: 2, Batch: 819, Step num: 2338, Learning rate: 0.00008169, Avg batch loss: 0.5827, Avg batch acc: 0.4292
Train, Epoch: 2, Batch: 820, Step num: 2339, Learning rate: 0.00008172, Avg batch loss: 0.6483, Avg batch acc: 0.3988
Train, Epoch: 2, Batch: 821, Step num: 2340, Learning rate: 0.00008176, Avg batch loss: 0.6080, Avg batch acc: 0.4142
Train, Epoch: 2, Batch: 822, Step num: 2341, Learning rate: 0.00008179, Avg batch loss: 0.6255, Avg batch acc: 0.3843
Train, Epoch: 2, Batch: 823, Step num: 2342, Learning rate: 0.00008183, Avg batch loss: 0.6861, Avg batch acc: 0.3889
Train, Epoch: 2, Batch: 824, Step num: 2343, Learning rate: 0.00008186, Avg batch loss: 0.6680, Avg batch acc: 0.4130
Train, Epoch: 2, Batch: 825, Step num: 2344, Learning rate: 0.00008190, Avg batch loss: 0.6443, Avg batch acc: 0.4155
Train, Epoch: 2, Batch: 826, Step num: 2345, Learning rate: 0.00008193, Avg batch loss: 0.6898, Avg batch acc: 0.3833
Train, Epoch: 2, Batch: 827, Step num: 2346, Learning rate: 0.00008197, Avg batch loss: 0.6773, Avg batch acc: 0.4098
Train, Epoch: 2, Batch: 828, Step num: 2347, Learning rate: 0.00008200, Avg batch loss: 0.6911, Avg batch acc: 0.3954
Train, Epoch: 2, Batch: 829, Step num: 2348, Learning rate: 0.00008204, Avg batch loss: 0.6676, Avg batch acc: 0.4067
Train, Epoch: 2, Batch: 830, Step num: 2349, Learning rate: 0.00008207, Avg batch loss: 0.6737, Avg batch acc: 0.3780
Train, Epoch: 2, Batch: 831, Step num: 2350, Learning rate: 0.00008211, Avg batch loss: 0.5898, Avg batch acc: 0.4239
Train, Epoch: 2, Batch: 832, Step num: 2351, Learning rate: 0.00008214, Avg batch loss: 0.7050, Avg batch acc: 0.4138
Train, Epoch: 2, Batch: 833, Step num: 2352, Learning rate: 0.00008218, Avg batch loss: 0.6314, Avg batch acc: 0.4198
Train, Epoch: 2, Batch: 834, Step num: 2353, Learning rate: 0.00008221, Avg batch loss: 0.5858, Avg batch acc: 0.4232
Train, Epoch: 2, Batch: 835, Step num: 2354, Learning rate: 0.00008225, Avg batch loss: 0.5754, Avg batch acc: 0.4190
Train, Epoch: 2, Batch: 836, Step num: 2355, Learning rate: 0.00008228, Avg batch loss: 0.6297, Avg batch acc: 0.4104
Train, Epoch: 2, Batch: 837, Step num: 2356, Learning rate: 0.00008232, Avg batch loss: 0.6234, Avg batch acc: 0.4191
Train, Epoch: 2, Batch: 838, Step num: 2357, Learning rate: 0.00008235, Avg batch loss: 0.6309, Avg batch acc: 0.4223
Train, Epoch: 2, Batch: 839, Step num: 2358, Learning rate: 0.00008239, Avg batch loss: 0.5800, Avg batch acc: 0.4257
Train, Epoch: 2, Batch: 840, Step num: 2359, Learning rate: 0.00008242, Avg batch loss: 0.6114, Avg batch acc: 0.4033
Train, Epoch: 2, Batch: 841, Step num: 2360, Learning rate: 0.00008246, Avg batch loss: 0.5615, Avg batch acc: 0.4373
Train, Epoch: 2, Batch: 842, Step num: 2361, Learning rate: 0.00008249, Avg batch loss: 0.6237, Avg batch acc: 0.4084
Train, Epoch: 2, Batch: 843, Step num: 2362, Learning rate: 0.00008252, Avg batch loss: 0.6915, Avg batch acc: 0.3976
Train, Epoch: 2, Batch: 844, Step num: 2363, Learning rate: 0.00008256, Avg batch loss: 0.6215, Avg batch acc: 0.3982
Train, Epoch: 2, Batch: 845, Step num: 2364, Learning rate: 0.00008259, Avg batch loss: 0.6864, Avg batch acc: 0.3956
Train, Epoch: 2, Batch: 846, Step num: 2365, Learning rate: 0.00008263, Avg batch loss: 0.5934, Avg batch acc: 0.4039
Train, Epoch: 2, Batch: 847, Step num: 2366, Learning rate: 0.00008266, Avg batch loss: 0.6481, Avg batch acc: 0.3962
Train, Epoch: 2, Batch: 848, Step num: 2367, Learning rate: 0.00008270, Avg batch loss: 0.6159, Avg batch acc: 0.3960
Train, Epoch: 2, Batch: 849, Step num: 2368, Learning rate: 0.00008273, Avg batch loss: 0.6563, Avg batch acc: 0.4041
Train, Epoch: 2, Batch: 850, Step num: 2369, Learning rate: 0.00008277, Avg batch loss: 0.5799, Avg batch acc: 0.3968
Train, Epoch: 2, Batch: 851, Step num: 2370, Learning rate: 0.00008280, Avg batch loss: 0.6760, Avg batch acc: 0.4049
Train, Epoch: 2, Batch: 852, Step num: 2371, Learning rate: 0.00008284, Avg batch loss: 0.6231, Avg batch acc: 0.4147
Train, Epoch: 2, Batch: 853, Step num: 2372, Learning rate: 0.00008287, Avg batch loss: 0.6130, Avg batch acc: 0.3993
Train, Epoch: 2, Batch: 854, Step num: 2373, Learning rate: 0.00008291, Avg batch loss: 0.5900, Avg batch acc: 0.3964
Train, Epoch: 2, Batch: 855, Step num: 2374, Learning rate: 0.00008294, Avg batch loss: 0.6114, Avg batch acc: 0.4280
Train, Epoch: 2, Batch: 856, Step num: 2375, Learning rate: 0.00008298, Avg batch loss: 0.6421, Avg batch acc: 0.3886
Train, Epoch: 2, Batch: 857, Step num: 2376, Learning rate: 0.00008301, Avg batch loss: 0.6320, Avg batch acc: 0.4231
Train, Epoch: 2, Batch: 858, Step num: 2377, Learning rate: 0.00008305, Avg batch loss: 0.5959, Avg batch acc: 0.4276
Train, Epoch: 2, Batch: 859, Step num: 2378, Learning rate: 0.00008308, Avg batch loss: 0.6008, Avg batch acc: 0.4333
Train, Epoch: 2, Batch: 860, Step num: 2379, Learning rate: 0.00008312, Avg batch loss: 0.6127, Avg batch acc: 0.4122
Train, Epoch: 2, Batch: 861, Step num: 2380, Learning rate: 0.00008315, Avg batch loss: 0.6656, Avg batch acc: 0.4241
Train, Epoch: 2, Batch: 862, Step num: 2381, Learning rate: 0.00008319, Avg batch loss: 0.6255, Avg batch acc: 0.4068
Train, Epoch: 2, Batch: 863, Step num: 2382, Learning rate: 0.00008322, Avg batch loss: 0.6412, Avg batch acc: 0.3906
Train, Epoch: 2, Batch: 864, Step num: 2383, Learning rate: 0.00008326, Avg batch loss: 0.5989, Avg batch acc: 0.4088
Train, Epoch: 2, Batch: 865, Step num: 2384, Learning rate: 0.00008329, Avg batch loss: 0.5607, Avg batch acc: 0.4089
Train, Epoch: 2, Batch: 866, Step num: 2385, Learning rate: 0.00008333, Avg batch loss: 0.6436, Avg batch acc: 0.4229
Train, Epoch: 2, Batch: 867, Step num: 2386, Learning rate: 0.00008336, Avg batch loss: 0.5955, Avg batch acc: 0.4488
Train, Epoch: 2, Batch: 868, Step num: 2387, Learning rate: 0.00008340, Avg batch loss: 0.6430, Avg batch acc: 0.4052
Train, Epoch: 2, Batch: 869, Step num: 2388, Learning rate: 0.00008343, Avg batch loss: 0.6353, Avg batch acc: 0.3809
Train, Epoch: 2, Batch: 870, Step num: 2389, Learning rate: 0.00008347, Avg batch loss: 0.6911, Avg batch acc: 0.3884
Train, Epoch: 2, Batch: 871, Step num: 2390, Learning rate: 0.00008350, Avg batch loss: 0.6617, Avg batch acc: 0.4112
Train, Epoch: 2, Batch: 872, Step num: 2391, Learning rate: 0.00008354, Avg batch loss: 0.6270, Avg batch acc: 0.3929
Train, Epoch: 2, Batch: 873, Step num: 2392, Learning rate: 0.00008357, Avg batch loss: 0.6319, Avg batch acc: 0.4239
Train, Epoch: 2, Batch: 874, Step num: 2393, Learning rate: 0.00008361, Avg batch loss: 0.5807, Avg batch acc: 0.4304
Train, Epoch: 2, Batch: 875, Step num: 2394, Learning rate: 0.00008364, Avg batch loss: 0.6150, Avg batch acc: 0.4138
Train, Epoch: 2, Batch: 876, Step num: 2395, Learning rate: 0.00008368, Avg batch loss: 0.6114, Avg batch acc: 0.4307
Train, Epoch: 2, Batch: 877, Step num: 2396, Learning rate: 0.00008371, Avg batch loss: 0.6836, Avg batch acc: 0.4044
Train, Epoch: 2, Batch: 878, Step num: 2397, Learning rate: 0.00008375, Avg batch loss: 0.6332, Avg batch acc: 0.4129
Train, Epoch: 2, Batch: 879, Step num: 2398, Learning rate: 0.00008378, Avg batch loss: 0.6257, Avg batch acc: 0.4139
Train, Epoch: 2, Batch: 880, Step num: 2399, Learning rate: 0.00008382, Avg batch loss: 0.6119, Avg batch acc: 0.3965
Train, Epoch: 2, Batch: 881, Step num: 2400, Learning rate: 0.00008385, Avg batch loss: 0.5882, Avg batch acc: 0.4020
Train, Epoch: 2, Batch: 882, Step num: 2401, Learning rate: 0.00008389, Avg batch loss: 0.7183, Avg batch acc: 0.3911
Train, Epoch: 2, Batch: 883, Step num: 2402, Learning rate: 0.00008392, Avg batch loss: 0.6480, Avg batch acc: 0.4232
Train, Epoch: 2, Batch: 884, Step num: 2403, Learning rate: 0.00008396, Avg batch loss: 0.5815, Avg batch acc: 0.4200
Train, Epoch: 2, Batch: 885, Step num: 2404, Learning rate: 0.00008399, Avg batch loss: 0.6430, Avg batch acc: 0.3983
Train, Epoch: 2, Batch: 886, Step num: 2405, Learning rate: 0.00008403, Avg batch loss: 0.6418, Avg batch acc: 0.4290
Train, Epoch: 2, Batch: 887, Step num: 2406, Learning rate: 0.00008406, Avg batch loss: 0.5921, Avg batch acc: 0.4089
Train, Epoch: 2, Batch: 888, Step num: 2407, Learning rate: 0.00008410, Avg batch loss: 0.6891, Avg batch acc: 0.4123
Train, Epoch: 2, Batch: 889, Step num: 2408, Learning rate: 0.00008413, Avg batch loss: 0.7191, Avg batch acc: 0.4105
Train, Epoch: 2, Batch: 890, Step num: 2409, Learning rate: 0.00008417, Avg batch loss: 0.6465, Avg batch acc: 0.4039
Train, Epoch: 2, Batch: 891, Step num: 2410, Learning rate: 0.00008420, Avg batch loss: 0.6016, Avg batch acc: 0.4243
Train, Epoch: 2, Batch: 892, Step num: 2411, Learning rate: 0.00008424, Avg batch loss: 0.6379, Avg batch acc: 0.3857
Train, Epoch: 2, Batch: 893, Step num: 2412, Learning rate: 0.00008427, Avg batch loss: 0.5949, Avg batch acc: 0.4201
Train, Epoch: 2, Batch: 894, Step num: 2413, Learning rate: 0.00008431, Avg batch loss: 0.6460, Avg batch acc: 0.4074
Train, Epoch: 2, Batch: 895, Step num: 2414, Learning rate: 0.00008434, Avg batch loss: 0.6035, Avg batch acc: 0.4277
Train, Epoch: 2, Batch: 896, Step num: 2415, Learning rate: 0.00008438, Avg batch loss: 0.6344, Avg batch acc: 0.4156
Train, Epoch: 2, Batch: 897, Step num: 2416, Learning rate: 0.00008441, Avg batch loss: 0.6186, Avg batch acc: 0.4123
Train, Epoch: 2, Batch: 898, Step num: 2417, Learning rate: 0.00008445, Avg batch loss: 0.6032, Avg batch acc: 0.4128
Train, Epoch: 2, Batch: 899, Step num: 2418, Learning rate: 0.00008448, Avg batch loss: 0.5953, Avg batch acc: 0.4062
Train, Epoch: 2, Batch: 900, Step num: 2419, Learning rate: 0.00008452, Avg batch loss: 0.5815, Avg batch acc: 0.4136
Train, Epoch: 2, Batch: 901, Step num: 2420, Learning rate: 0.00008455, Avg batch loss: 0.6691, Avg batch acc: 0.4229
Train, Epoch: 2, Batch: 902, Step num: 2421, Learning rate: 0.00008459, Avg batch loss: 0.6177, Avg batch acc: 0.3996
Train, Epoch: 2, Batch: 903, Step num: 2422, Learning rate: 0.00008462, Avg batch loss: 0.6772, Avg batch acc: 0.3805
Train, Epoch: 2, Batch: 904, Step num: 2423, Learning rate: 0.00008466, Avg batch loss: 0.5648, Avg batch acc: 0.4051
Train, Epoch: 2, Batch: 905, Step num: 2424, Learning rate: 0.00008469, Avg batch loss: 0.6565, Avg batch acc: 0.3829
Train, Epoch: 2, Batch: 906, Step num: 2425, Learning rate: 0.00008473, Avg batch loss: 0.6017, Avg batch acc: 0.4184
Train, Epoch: 2, Batch: 907, Step num: 2426, Learning rate: 0.00008476, Avg batch loss: 0.6089, Avg batch acc: 0.4211
Train, Epoch: 2, Batch: 908, Step num: 2427, Learning rate: 0.00008480, Avg batch loss: 0.5975, Avg batch acc: 0.4357
Train, Epoch: 2, Batch: 909, Step num: 2428, Learning rate: 0.00008483, Avg batch loss: 0.6473, Avg batch acc: 0.4012
Train, Epoch: 2, Batch: 910, Step num: 2429, Learning rate: 0.00008487, Avg batch loss: 0.6343, Avg batch acc: 0.4053
Train, Epoch: 2, Batch: 911, Step num: 2430, Learning rate: 0.00008490, Avg batch loss: 0.7202, Avg batch acc: 0.4083
Train, Epoch: 2, Batch: 912, Step num: 2431, Learning rate: 0.00008494, Avg batch loss: 0.6231, Avg batch acc: 0.4169
Train, Epoch: 2, Batch: 913, Step num: 2432, Learning rate: 0.00008497, Avg batch loss: 0.6446, Avg batch acc: 0.4254
Train, Epoch: 2, Batch: 914, Step num: 2433, Learning rate: 0.00008501, Avg batch loss: 0.6177, Avg batch acc: 0.4075
Train, Epoch: 2, Batch: 915, Step num: 2434, Learning rate: 0.00008504, Avg batch loss: 0.5706, Avg batch acc: 0.4240
Train, Epoch: 2, Batch: 916, Step num: 2435, Learning rate: 0.00008508, Avg batch loss: 0.5824, Avg batch acc: 0.4263
Train, Epoch: 2, Batch: 917, Step num: 2436, Learning rate: 0.00008511, Avg batch loss: 0.6042, Avg batch acc: 0.4239
Train, Epoch: 2, Batch: 918, Step num: 2437, Learning rate: 0.00008515, Avg batch loss: 0.5846, Avg batch acc: 0.4379
Train, Epoch: 2, Batch: 919, Step num: 2438, Learning rate: 0.00008518, Avg batch loss: 0.5822, Avg batch acc: 0.4216
Train, Epoch: 2, Batch: 920, Step num: 2439, Learning rate: 0.00008522, Avg batch loss: 0.6237, Avg batch acc: 0.4183
Train, Epoch: 2, Batch: 921, Step num: 2440, Learning rate: 0.00008525, Avg batch loss: 0.6367, Avg batch acc: 0.4363
Train, Epoch: 2, Batch: 922, Step num: 2441, Learning rate: 0.00008529, Avg batch loss: 0.6179, Avg batch acc: 0.4281
Train, Epoch: 2, Batch: 923, Step num: 2442, Learning rate: 0.00008532, Avg batch loss: 0.6597, Avg batch acc: 0.4243
Train, Epoch: 2, Batch: 924, Step num: 2443, Learning rate: 0.00008535, Avg batch loss: 0.6201, Avg batch acc: 0.4375
Train, Epoch: 2, Batch: 925, Step num: 2444, Learning rate: 0.00008539, Avg batch loss: 0.6232, Avg batch acc: 0.4086
Train, Epoch: 2, Batch: 926, Step num: 2445, Learning rate: 0.00008542, Avg batch loss: 0.5900, Avg batch acc: 0.4367
Train, Epoch: 2, Batch: 927, Step num: 2446, Learning rate: 0.00008546, Avg batch loss: 0.6350, Avg batch acc: 0.4339
Train, Epoch: 2, Batch: 928, Step num: 2447, Learning rate: 0.00008549, Avg batch loss: 0.6189, Avg batch acc: 0.4248
Train, Epoch: 2, Batch: 929, Step num: 2448, Learning rate: 0.00008553, Avg batch loss: 0.6828, Avg batch acc: 0.4270
Train, Epoch: 2, Batch: 930, Step num: 2449, Learning rate: 0.00008556, Avg batch loss: 0.5712, Avg batch acc: 0.4349
Train, Epoch: 2, Batch: 931, Step num: 2450, Learning rate: 0.00008560, Avg batch loss: 0.6884, Avg batch acc: 0.4186
Train, Epoch: 2, Batch: 932, Step num: 2451, Learning rate: 0.00008563, Avg batch loss: 0.6299, Avg batch acc: 0.4225
Train, Epoch: 2, Batch: 933, Step num: 2452, Learning rate: 0.00008567, Avg batch loss: 0.6067, Avg batch acc: 0.4423
Train, Epoch: 2, Batch: 934, Step num: 2453, Learning rate: 0.00008570, Avg batch loss: 0.6548, Avg batch acc: 0.4281
Train, Epoch: 2, Batch: 935, Step num: 2454, Learning rate: 0.00008574, Avg batch loss: 0.6686, Avg batch acc: 0.4016
Train, Epoch: 2, Batch: 936, Step num: 2455, Learning rate: 0.00008577, Avg batch loss: 0.6124, Avg batch acc: 0.4172
Train, Epoch: 2, Batch: 937, Step num: 2456, Learning rate: 0.00008581, Avg batch loss: 0.5974, Avg batch acc: 0.4223
Train, Epoch: 2, Batch: 938, Step num: 2457, Learning rate: 0.00008584, Avg batch loss: 0.5988, Avg batch acc: 0.3974
Train, Epoch: 2, Batch: 939, Step num: 2458, Learning rate: 0.00008588, Avg batch loss: 0.6191, Avg batch acc: 0.4092
Train, Epoch: 2, Batch: 940, Step num: 2459, Learning rate: 0.00008591, Avg batch loss: 0.6459, Avg batch acc: 0.3998
Train, Epoch: 2, Batch: 941, Step num: 2460, Learning rate: 0.00008595, Avg batch loss: 0.6689, Avg batch acc: 0.3909
Train, Epoch: 2, Batch: 942, Step num: 2461, Learning rate: 0.00008598, Avg batch loss: 0.5394, Avg batch acc: 0.4339
Train, Epoch: 2, Batch: 943, Step num: 2462, Learning rate: 0.00008602, Avg batch loss: 0.6348, Avg batch acc: 0.4069
Train, Epoch: 2, Batch: 944, Step num: 2463, Learning rate: 0.00008605, Avg batch loss: 0.5880, Avg batch acc: 0.4314
Train, Epoch: 2, Batch: 945, Step num: 2464, Learning rate: 0.00008609, Avg batch loss: 0.6692, Avg batch acc: 0.4133
Train, Epoch: 2, Batch: 946, Step num: 2465, Learning rate: 0.00008612, Avg batch loss: 0.6903, Avg batch acc: 0.4030
Train, Epoch: 2, Batch: 947, Step num: 2466, Learning rate: 0.00008616, Avg batch loss: 0.6271, Avg batch acc: 0.4208
Train, Epoch: 2, Batch: 948, Step num: 2467, Learning rate: 0.00008619, Avg batch loss: 0.6206, Avg batch acc: 0.4311
Train, Epoch: 2, Batch: 949, Step num: 2468, Learning rate: 0.00008623, Avg batch loss: 0.5768, Avg batch acc: 0.4280
Train, Epoch: 2, Batch: 950, Step num: 2469, Learning rate: 0.00008626, Avg batch loss: 0.6433, Avg batch acc: 0.4108
Train, Epoch: 2, Batch: 951, Step num: 2470, Learning rate: 0.00008630, Avg batch loss: 0.6117, Avg batch acc: 0.4293
Train, Epoch: 2, Batch: 952, Step num: 2471, Learning rate: 0.00008633, Avg batch loss: 0.6257, Avg batch acc: 0.4018
Train, Epoch: 2, Batch: 953, Step num: 2472, Learning rate: 0.00008637, Avg batch loss: 0.6690, Avg batch acc: 0.4157
Train, Epoch: 2, Batch: 954, Step num: 2473, Learning rate: 0.00008640, Avg batch loss: 0.6385, Avg batch acc: 0.4050
Train, Epoch: 2, Batch: 955, Step num: 2474, Learning rate: 0.00008644, Avg batch loss: 0.5658, Avg batch acc: 0.4313
Train, Epoch: 2, Batch: 956, Step num: 2475, Learning rate: 0.00008647, Avg batch loss: 0.5980, Avg batch acc: 0.4360
Train, Epoch: 2, Batch: 957, Step num: 2476, Learning rate: 0.00008651, Avg batch loss: 0.6787, Avg batch acc: 0.4287
Train, Epoch: 2, Batch: 958, Step num: 2477, Learning rate: 0.00008654, Avg batch loss: 0.5958, Avg batch acc: 0.4198
Train, Epoch: 2, Batch: 959, Step num: 2478, Learning rate: 0.00008658, Avg batch loss: 0.6247, Avg batch acc: 0.4240
Train, Epoch: 2, Batch: 960, Step num: 2479, Learning rate: 0.00008661, Avg batch loss: 0.6040, Avg batch acc: 0.4404
Train, Epoch: 2, Batch: 961, Step num: 2480, Learning rate: 0.00008665, Avg batch loss: 0.6449, Avg batch acc: 0.4099
Train, Epoch: 2, Batch: 962, Step num: 2481, Learning rate: 0.00008668, Avg batch loss: 0.5417, Avg batch acc: 0.4296
Train, Epoch: 2, Batch: 963, Step num: 2482, Learning rate: 0.00008672, Avg batch loss: 0.6174, Avg batch acc: 0.4358
Train, Epoch: 2, Batch: 964, Step num: 2483, Learning rate: 0.00008675, Avg batch loss: 0.6731, Avg batch acc: 0.3989
Train, Epoch: 2, Batch: 965, Step num: 2484, Learning rate: 0.00008679, Avg batch loss: 0.6277, Avg batch acc: 0.3928
Train, Epoch: 2, Batch: 966, Step num: 2485, Learning rate: 0.00008682, Avg batch loss: 0.6292, Avg batch acc: 0.4114
Train, Epoch: 2, Batch: 967, Step num: 2486, Learning rate: 0.00008686, Avg batch loss: 0.6039, Avg batch acc: 0.4218
Train, Epoch: 2, Batch: 968, Step num: 2487, Learning rate: 0.00008689, Avg batch loss: 0.5892, Avg batch acc: 0.4274
Train, Epoch: 2, Batch: 969, Step num: 2488, Learning rate: 0.00008693, Avg batch loss: 0.6206, Avg batch acc: 0.4156
Train, Epoch: 2, Batch: 970, Step num: 2489, Learning rate: 0.00008696, Avg batch loss: 0.5651, Avg batch acc: 0.4251
Train, Epoch: 2, Batch: 971, Step num: 2490, Learning rate: 0.00008700, Avg batch loss: 0.6575, Avg batch acc: 0.4075
Train, Epoch: 2, Batch: 972, Step num: 2491, Learning rate: 0.00008703, Avg batch loss: 0.6219, Avg batch acc: 0.4249
Train, Epoch: 2, Batch: 973, Step num: 2492, Learning rate: 0.00008707, Avg batch loss: 0.6459, Avg batch acc: 0.4195
Train, Epoch: 2, Batch: 974, Step num: 2493, Learning rate: 0.00008710, Avg batch loss: 0.6168, Avg batch acc: 0.4221
Train, Epoch: 2, Batch: 975, Step num: 2494, Learning rate: 0.00008714, Avg batch loss: 0.6136, Avg batch acc: 0.4017
Train, Epoch: 2, Batch: 976, Step num: 2495, Learning rate: 0.00008717, Avg batch loss: 0.6484, Avg batch acc: 0.4230
Train, Epoch: 2, Batch: 977, Step num: 2496, Learning rate: 0.00008721, Avg batch loss: 0.6141, Avg batch acc: 0.4279
Train, Epoch: 2, Batch: 978, Step num: 2497, Learning rate: 0.00008724, Avg batch loss: 0.6323, Avg batch acc: 0.4257
Train, Epoch: 2, Batch: 979, Step num: 2498, Learning rate: 0.00008728, Avg batch loss: 0.6163, Avg batch acc: 0.4261
Train, Epoch: 2, Batch: 980, Step num: 2499, Learning rate: 0.00008731, Avg batch loss: 0.5852, Avg batch acc: 0.4349
Train, Epoch: 2, Batch: 981, Step num: 2500, Learning rate: 0.00008735, Avg batch loss: 0.6180, Avg batch acc: 0.4086
Train, Epoch: 2, Batch: 982, Step num: 2501, Learning rate: 0.00008738, Avg batch loss: 0.5951, Avg batch acc: 0.4312
Train, Epoch: 2, Batch: 983, Step num: 2502, Learning rate: 0.00008742, Avg batch loss: 0.6254, Avg batch acc: 0.4375
Train, Epoch: 2, Batch: 984, Step num: 2503, Learning rate: 0.00008745, Avg batch loss: 0.5886, Avg batch acc: 0.4371
Train, Epoch: 2, Batch: 985, Step num: 2504, Learning rate: 0.00008749, Avg batch loss: 0.6156, Avg batch acc: 0.4335
Train, Epoch: 2, Batch: 986, Step num: 2505, Learning rate: 0.00008752, Avg batch loss: 0.6246, Avg batch acc: 0.4374
Train, Epoch: 2, Batch: 987, Step num: 2506, Learning rate: 0.00008756, Avg batch loss: 0.5556, Avg batch acc: 0.4527
Train, Epoch: 2, Batch: 988, Step num: 2507, Learning rate: 0.00008759, Avg batch loss: 0.5713, Avg batch acc: 0.4440
Train, Epoch: 2, Batch: 989, Step num: 2508, Learning rate: 0.00008763, Avg batch loss: 0.5901, Avg batch acc: 0.4411
Train, Epoch: 2, Batch: 990, Step num: 2509, Learning rate: 0.00008766, Avg batch loss: 0.6359, Avg batch acc: 0.4168
Train, Epoch: 2, Batch: 991, Step num: 2510, Learning rate: 0.00008770, Avg batch loss: 0.6503, Avg batch acc: 0.3948
Train, Epoch: 2, Batch: 992, Step num: 2511, Learning rate: 0.00008773, Avg batch loss: 0.6549, Avg batch acc: 0.4217
Train, Epoch: 2, Batch: 993, Step num: 2512, Learning rate: 0.00008777, Avg batch loss: 0.6251, Avg batch acc: 0.4208
Train, Epoch: 2, Batch: 994, Step num: 2513, Learning rate: 0.00008780, Avg batch loss: 0.5760, Avg batch acc: 0.4556
Train, Epoch: 2, Batch: 995, Step num: 2514, Learning rate: 0.00008784, Avg batch loss: 0.6271, Avg batch acc: 0.4179
Train, Epoch: 2, Batch: 996, Step num: 2515, Learning rate: 0.00008787, Avg batch loss: 0.6408, Avg batch acc: 0.4171
Train, Epoch: 2, Batch: 997, Step num: 2516, Learning rate: 0.00008791, Avg batch loss: 0.5902, Avg batch acc: 0.4393
Train, Epoch: 2, Batch: 998, Step num: 2517, Learning rate: 0.00008794, Avg batch loss: 0.6559, Avg batch acc: 0.4235
Train, Epoch: 2, Batch: 999, Step num: 2518, Learning rate: 0.00008798, Avg batch loss: 0.5987, Avg batch acc: 0.4321
Train, Epoch: 2, Batch: 1000, Step num: 2519, Learning rate: 0.00008801, Avg batch loss: 0.6532, Avg batch acc: 0.4358
Train, Epoch: 2, Batch: 1001, Step num: 2520, Learning rate: 0.00008805, Avg batch loss: 0.6345, Avg batch acc: 0.4458
Train, Epoch: 2, Batch: 1002, Step num: 2521, Learning rate: 0.00008808, Avg batch loss: 0.5548, Avg batch acc: 0.4350
Train, Epoch: 2, Batch: 1003, Step num: 2522, Learning rate: 0.00008812, Avg batch loss: 0.6509, Avg batch acc: 0.4269
Train, Epoch: 2, Batch: 1004, Step num: 2523, Learning rate: 0.00008815, Avg batch loss: 0.6157, Avg batch acc: 0.4308
Train, Epoch: 2, Batch: 1005, Step num: 2524, Learning rate: 0.00008818, Avg batch loss: 0.5724, Avg batch acc: 0.4320
Train, Epoch: 2, Batch: 1006, Step num: 2525, Learning rate: 0.00008822, Avg batch loss: 0.5812, Avg batch acc: 0.4347
Train, Epoch: 2, Batch: 1007, Step num: 2526, Learning rate: 0.00008825, Avg batch loss: 0.5704, Avg batch acc: 0.4556
Train, Epoch: 2, Batch: 1008, Step num: 2527, Learning rate: 0.00008829, Avg batch loss: 0.5878, Avg batch acc: 0.4355
Train, Epoch: 2, Batch: 1009, Step num: 2528, Learning rate: 0.00008832, Avg batch loss: 0.6174, Avg batch acc: 0.4222
Train, Epoch: 2, Batch: 1010, Step num: 2529, Learning rate: 0.00008836, Avg batch loss: 0.6201, Avg batch acc: 0.4283
Train, Epoch: 2, Batch: 1011, Step num: 2530, Learning rate: 0.00008839, Avg batch loss: 0.5847, Avg batch acc: 0.4264
Train, Epoch: 2, Batch: 1012, Step num: 2531, Learning rate: 0.00008843, Avg batch loss: 0.6001, Avg batch acc: 0.4123
Train, Epoch: 2, Batch: 1013, Step num: 2532, Learning rate: 0.00008846, Avg batch loss: 0.6164, Avg batch acc: 0.4010
Train, Epoch: 2, Batch: 1014, Step num: 2533, Learning rate: 0.00008850, Avg batch loss: 0.6185, Avg batch acc: 0.4140
Train, Epoch: 2, Batch: 1015, Step num: 2534, Learning rate: 0.00008853, Avg batch loss: 0.5885, Avg batch acc: 0.4210
Train, Epoch: 2, Batch: 1016, Step num: 2535, Learning rate: 0.00008857, Avg batch loss: 0.5853, Avg batch acc: 0.4488
Train, Epoch: 2, Batch: 1017, Step num: 2536, Learning rate: 0.00008860, Avg batch loss: 0.6299, Avg batch acc: 0.4292
Train, Epoch: 2, Batch: 1018, Step num: 2537, Learning rate: 0.00008864, Avg batch loss: 0.5841, Avg batch acc: 0.4506
Train, Epoch: 2, Batch: 1019, Step num: 2538, Learning rate: 0.00008867, Avg batch loss: 0.6203, Avg batch acc: 0.4358
Train, Epoch: 2, Batch: 1020, Step num: 2539, Learning rate: 0.00008871, Avg batch loss: 0.6346, Avg batch acc: 0.4188
Train, Epoch: 2, Batch: 1021, Step num: 2540, Learning rate: 0.00008874, Avg batch loss: 0.6192, Avg batch acc: 0.4294
Train, Epoch: 2, Batch: 1022, Step num: 2541, Learning rate: 0.00008878, Avg batch loss: 0.5802, Avg batch acc: 0.4341
Train, Epoch: 2, Batch: 1023, Step num: 2542, Learning rate: 0.00008881, Avg batch loss: 0.6058, Avg batch acc: 0.4395
Train, Epoch: 2, Batch: 1024, Step num: 2543, Learning rate: 0.00008885, Avg batch loss: 0.5655, Avg batch acc: 0.4453
Train, Epoch: 2, Batch: 1025, Step num: 2544, Learning rate: 0.00008888, Avg batch loss: 0.6038, Avg batch acc: 0.4326
Train, Epoch: 2, Batch: 1026, Step num: 2545, Learning rate: 0.00008892, Avg batch loss: 0.6099, Avg batch acc: 0.4420
Train, Epoch: 2, Batch: 1027, Step num: 2546, Learning rate: 0.00008895, Avg batch loss: 0.6267, Avg batch acc: 0.4420
Train, Epoch: 2, Batch: 1028, Step num: 2547, Learning rate: 0.00008899, Avg batch loss: 0.6525, Avg batch acc: 0.4250
Train, Epoch: 2, Batch: 1029, Step num: 2548, Learning rate: 0.00008902, Avg batch loss: 0.6017, Avg batch acc: 0.4319
Train, Epoch: 2, Batch: 1030, Step num: 2549, Learning rate: 0.00008906, Avg batch loss: 0.6275, Avg batch acc: 0.4317
Train, Epoch: 2, Batch: 1031, Step num: 2550, Learning rate: 0.00008909, Avg batch loss: 0.6635, Avg batch acc: 0.4291
Train, Epoch: 2, Batch: 1032, Step num: 2551, Learning rate: 0.00008913, Avg batch loss: 0.6935, Avg batch acc: 0.4380
Train, Epoch: 2, Batch: 1033, Step num: 2552, Learning rate: 0.00008916, Avg batch loss: 0.5772, Avg batch acc: 0.4285
Train, Epoch: 2, Batch: 1034, Step num: 2553, Learning rate: 0.00008920, Avg batch loss: 0.6142, Avg batch acc: 0.4498
Train, Epoch: 2, Batch: 1035, Step num: 2554, Learning rate: 0.00008923, Avg batch loss: 0.6934, Avg batch acc: 0.4258
Train, Epoch: 2, Batch: 1036, Step num: 2555, Learning rate: 0.00008927, Avg batch loss: 0.5923, Avg batch acc: 0.4262
Train, Epoch: 2, Batch: 1037, Step num: 2556, Learning rate: 0.00008930, Avg batch loss: 0.5751, Avg batch acc: 0.4457
Train, Epoch: 2, Batch: 1038, Step num: 2557, Learning rate: 0.00008934, Avg batch loss: 0.6135, Avg batch acc: 0.4289
Train, Epoch: 2, Batch: 1039, Step num: 2558, Learning rate: 0.00008937, Avg batch loss: 0.6187, Avg batch acc: 0.4293
Train, Epoch: 2, Batch: 1040, Step num: 2559, Learning rate: 0.00008941, Avg batch loss: 0.5937, Avg batch acc: 0.4428
Train, Epoch: 2, Batch: 1041, Step num: 2560, Learning rate: 0.00008944, Avg batch loss: 0.5377, Avg batch acc: 0.4466
Train, Epoch: 2, Batch: 1042, Step num: 2561, Learning rate: 0.00008948, Avg batch loss: 0.6197, Avg batch acc: 0.4221
Train, Epoch: 2, Batch: 1043, Step num: 2562, Learning rate: 0.00008951, Avg batch loss: 0.7316, Avg batch acc: 0.4208
Train, Epoch: 2, Batch: 1044, Step num: 2563, Learning rate: 0.00008955, Avg batch loss: 0.6503, Avg batch acc: 0.4268
Train, Epoch: 2, Batch: 1045, Step num: 2564, Learning rate: 0.00008958, Avg batch loss: 0.5830, Avg batch acc: 0.4331
Train, Epoch: 2, Batch: 1046, Step num: 2565, Learning rate: 0.00008962, Avg batch loss: 0.6637, Avg batch acc: 0.3980
Train, Epoch: 2, Batch: 1047, Step num: 2566, Learning rate: 0.00008965, Avg batch loss: 0.6015, Avg batch acc: 0.4168
Train, Epoch: 2, Batch: 1048, Step num: 2567, Learning rate: 0.00008969, Avg batch loss: 0.5812, Avg batch acc: 0.4469
Train, Epoch: 2, Batch: 1049, Step num: 2568, Learning rate: 0.00008972, Avg batch loss: 0.5768, Avg batch acc: 0.4237
Train, Epoch: 2, Batch: 1050, Step num: 2569, Learning rate: 0.00008976, Avg batch loss: 0.5603, Avg batch acc: 0.4341
Train, Epoch: 2, Batch: 1051, Step num: 2570, Learning rate: 0.00008979, Avg batch loss: 0.6384, Avg batch acc: 0.3976
Train, Epoch: 2, Batch: 1052, Step num: 2571, Learning rate: 0.00008983, Avg batch loss: 0.5591, Avg batch acc: 0.4392
Train, Epoch: 2, Batch: 1053, Step num: 2572, Learning rate: 0.00008986, Avg batch loss: 0.6184, Avg batch acc: 0.4292
Train, Epoch: 2, Batch: 1054, Step num: 2573, Learning rate: 0.00008990, Avg batch loss: 0.5723, Avg batch acc: 0.4408
Train, Epoch: 2, Batch: 1055, Step num: 2574, Learning rate: 0.00008993, Avg batch loss: 0.6433, Avg batch acc: 0.4280
Train, Epoch: 2, Batch: 1056, Step num: 2575, Learning rate: 0.00008997, Avg batch loss: 0.5121, Avg batch acc: 0.4619
Train, Epoch: 2, Batch: 1057, Step num: 2576, Learning rate: 0.00009000, Avg batch loss: 0.6032, Avg batch acc: 0.4455
Train, Epoch: 2, Batch: 1058, Step num: 2577, Learning rate: 0.00009004, Avg batch loss: 0.6230, Avg batch acc: 0.4552
Train, Epoch: 2, Batch: 1059, Step num: 2578, Learning rate: 0.00009007, Avg batch loss: 0.6352, Avg batch acc: 0.4196
Train, Epoch: 2, Batch: 1060, Step num: 2579, Learning rate: 0.00009011, Avg batch loss: 0.6106, Avg batch acc: 0.4398
Train, Epoch: 2, Batch: 1061, Step num: 2580, Learning rate: 0.00009014, Avg batch loss: 0.5645, Avg batch acc: 0.4464
Train, Epoch: 2, Batch: 1062, Step num: 2581, Learning rate: 0.00009018, Avg batch loss: 0.6506, Avg batch acc: 0.4264
Train, Epoch: 2, Batch: 1063, Step num: 2582, Learning rate: 0.00009021, Avg batch loss: 0.6325, Avg batch acc: 0.4251
Train, Epoch: 2, Batch: 1064, Step num: 2583, Learning rate: 0.00009025, Avg batch loss: 0.5814, Avg batch acc: 0.4403
Train, Epoch: 2, Batch: 1065, Step num: 2584, Learning rate: 0.00009028, Avg batch loss: 0.5981, Avg batch acc: 0.4324
Train, Epoch: 2, Batch: 1066, Step num: 2585, Learning rate: 0.00009032, Avg batch loss: 0.5689, Avg batch acc: 0.4218
Train, Epoch: 2, Batch: 1067, Step num: 2586, Learning rate: 0.00009035, Avg batch loss: 0.6009, Avg batch acc: 0.4249
Train, Epoch: 2, Batch: 1068, Step num: 2587, Learning rate: 0.00009039, Avg batch loss: 0.6019, Avg batch acc: 0.4533
Train, Epoch: 2, Batch: 1069, Step num: 2588, Learning rate: 0.00009042, Avg batch loss: 0.6041, Avg batch acc: 0.4454
Train, Epoch: 2, Batch: 1070, Step num: 2589, Learning rate: 0.00009046, Avg batch loss: 0.5626, Avg batch acc: 0.4537
Train, Epoch: 2, Batch: 1071, Step num: 2590, Learning rate: 0.00009049, Avg batch loss: 0.5602, Avg batch acc: 0.4563
Train, Epoch: 2, Batch: 1072, Step num: 2591, Learning rate: 0.00009053, Avg batch loss: 0.5744, Avg batch acc: 0.4257
Train, Epoch: 2, Batch: 1073, Step num: 2592, Learning rate: 0.00009056, Avg batch loss: 0.6815, Avg batch acc: 0.4297
Train, Epoch: 2, Batch: 1074, Step num: 2593, Learning rate: 0.00009060, Avg batch loss: 0.5913, Avg batch acc: 0.4584
Train, Epoch: 2, Batch: 1075, Step num: 2594, Learning rate: 0.00009063, Avg batch loss: 0.5847, Avg batch acc: 0.4564
Train, Epoch: 2, Batch: 1076, Step num: 2595, Learning rate: 0.00009067, Avg batch loss: 0.6254, Avg batch acc: 0.4311
Train, Epoch: 2, Batch: 1077, Step num: 2596, Learning rate: 0.00009070, Avg batch loss: 0.5655, Avg batch acc: 0.4375
Train, Epoch: 2, Batch: 1078, Step num: 2597, Learning rate: 0.00009074, Avg batch loss: 0.6042, Avg batch acc: 0.4509
Train, Epoch: 2, Batch: 1079, Step num: 2598, Learning rate: 0.00009077, Avg batch loss: 0.6018, Avg batch acc: 0.4381
Train, Epoch: 2, Batch: 1080, Step num: 2599, Learning rate: 0.00009081, Avg batch loss: 0.5828, Avg batch acc: 0.4612
Train, Epoch: 2, Batch: 1081, Step num: 2600, Learning rate: 0.00009084, Avg batch loss: 0.5605, Avg batch acc: 0.4732
Train, Epoch: 2, Batch: 1082, Step num: 2601, Learning rate: 0.00009088, Avg batch loss: 0.5997, Avg batch acc: 0.4554
Train, Epoch: 2, Batch: 1083, Step num: 2602, Learning rate: 0.00009091, Avg batch loss: 0.6520, Avg batch acc: 0.4333
Train, Epoch: 2, Batch: 1084, Step num: 2603, Learning rate: 0.00009095, Avg batch loss: 0.6379, Avg batch acc: 0.4439
Train, Epoch: 2, Batch: 1085, Step num: 2604, Learning rate: 0.00009098, Avg batch loss: 0.5779, Avg batch acc: 0.4539
Train, Epoch: 2, Batch: 1086, Step num: 2605, Learning rate: 0.00009101, Avg batch loss: 0.5845, Avg batch acc: 0.4402
Train, Epoch: 2, Batch: 1087, Step num: 2606, Learning rate: 0.00009105, Avg batch loss: 0.6214, Avg batch acc: 0.4273
Train, Epoch: 2, Batch: 1088, Step num: 2607, Learning rate: 0.00009108, Avg batch loss: 0.5756, Avg batch acc: 0.4593
Train, Epoch: 2, Batch: 1089, Step num: 2608, Learning rate: 0.00009112, Avg batch loss: 0.5897, Avg batch acc: 0.4474
Train, Epoch: 2, Batch: 1090, Step num: 2609, Learning rate: 0.00009115, Avg batch loss: 0.6012, Avg batch acc: 0.4385
Train, Epoch: 2, Batch: 1091, Step num: 2610, Learning rate: 0.00009119, Avg batch loss: 0.6145, Avg batch acc: 0.4288
Train, Epoch: 2, Batch: 1092, Step num: 2611, Learning rate: 0.00009122, Avg batch loss: 0.6486, Avg batch acc: 0.4357
Train, Epoch: 2, Batch: 1093, Step num: 2612, Learning rate: 0.00009126, Avg batch loss: 0.6319, Avg batch acc: 0.4216
Train, Epoch: 2, Batch: 1094, Step num: 2613, Learning rate: 0.00009129, Avg batch loss: 0.5909, Avg batch acc: 0.4497
Train, Epoch: 2, Batch: 1095, Step num: 2614, Learning rate: 0.00009133, Avg batch loss: 0.5823, Avg batch acc: 0.4545
Train, Epoch: 2, Batch: 1096, Step num: 2615, Learning rate: 0.00009136, Avg batch loss: 0.6424, Avg batch acc: 0.4103
Train, Epoch: 2, Batch: 1097, Step num: 2616, Learning rate: 0.00009140, Avg batch loss: 0.5428, Avg batch acc: 0.4592
Train, Epoch: 2, Batch: 1098, Step num: 2617, Learning rate: 0.00009143, Avg batch loss: 0.5456, Avg batch acc: 0.4466
Train, Epoch: 2, Batch: 1099, Step num: 2618, Learning rate: 0.00009147, Avg batch loss: 0.5958, Avg batch acc: 0.4685
Train, Epoch: 2, Batch: 1100, Step num: 2619, Learning rate: 0.00009150, Avg batch loss: 0.5441, Avg batch acc: 0.4765
Train, Epoch: 2, Batch: 1101, Step num: 2620, Learning rate: 0.00009154, Avg batch loss: 0.5955, Avg batch acc: 0.4472
Train, Epoch: 2, Batch: 1102, Step num: 2621, Learning rate: 0.00009157, Avg batch loss: 0.5674, Avg batch acc: 0.4441
Train, Epoch: 2, Batch: 1103, Step num: 2622, Learning rate: 0.00009161, Avg batch loss: 0.5550, Avg batch acc: 0.4485
Train, Epoch: 2, Batch: 1104, Step num: 2623, Learning rate: 0.00009164, Avg batch loss: 0.5701, Avg batch acc: 0.4738
Train, Epoch: 2, Batch: 1105, Step num: 2624, Learning rate: 0.00009168, Avg batch loss: 0.5988, Avg batch acc: 0.4572
Train, Epoch: 2, Batch: 1106, Step num: 2625, Learning rate: 0.00009171, Avg batch loss: 0.5717, Avg batch acc: 0.4546
Train, Epoch: 2, Batch: 1107, Step num: 2626, Learning rate: 0.00009175, Avg batch loss: 0.6429, Avg batch acc: 0.4157
Train, Epoch: 2, Batch: 1108, Step num: 2627, Learning rate: 0.00009178, Avg batch loss: 0.6000, Avg batch acc: 0.4345
Train, Epoch: 2, Batch: 1109, Step num: 2628, Learning rate: 0.00009182, Avg batch loss: 0.5990, Avg batch acc: 0.4420
Train, Epoch: 2, Batch: 1110, Step num: 2629, Learning rate: 0.00009185, Avg batch loss: 0.5583, Avg batch acc: 0.4612
Train, Epoch: 2, Batch: 1111, Step num: 2630, Learning rate: 0.00009189, Avg batch loss: 0.5757, Avg batch acc: 0.4315
Train, Epoch: 2, Batch: 1112, Step num: 2631, Learning rate: 0.00009192, Avg batch loss: 0.6248, Avg batch acc: 0.4326
Train, Epoch: 2, Batch: 1113, Step num: 2632, Learning rate: 0.00009196, Avg batch loss: 0.5782, Avg batch acc: 0.4701
Train, Epoch: 2, Batch: 1114, Step num: 2633, Learning rate: 0.00009199, Avg batch loss: 0.5460, Avg batch acc: 0.4481
Train, Epoch: 2, Batch: 1115, Step num: 2634, Learning rate: 0.00009203, Avg batch loss: 0.5671, Avg batch acc: 0.4576
Train, Epoch: 2, Batch: 1116, Step num: 2635, Learning rate: 0.00009206, Avg batch loss: 0.5530, Avg batch acc: 0.4638
Train, Epoch: 2, Batch: 1117, Step num: 2636, Learning rate: 0.00009210, Avg batch loss: 0.5888, Avg batch acc: 0.4360
Train, Epoch: 2, Batch: 1118, Step num: 2637, Learning rate: 0.00009213, Avg batch loss: 0.6401, Avg batch acc: 0.4431
Train, Epoch: 2, Batch: 1119, Step num: 2638, Learning rate: 0.00009217, Avg batch loss: 0.5559, Avg batch acc: 0.4504
Train, Epoch: 2, Batch: 1120, Step num: 2639, Learning rate: 0.00009220, Avg batch loss: 0.6135, Avg batch acc: 0.4546
Train, Epoch: 2, Batch: 1121, Step num: 2640, Learning rate: 0.00009224, Avg batch loss: 0.5617, Avg batch acc: 0.4636
Train, Epoch: 2, Batch: 1122, Step num: 2641, Learning rate: 0.00009227, Avg batch loss: 0.6562, Avg batch acc: 0.4492
Train, Epoch: 2, Batch: 1123, Step num: 2642, Learning rate: 0.00009231, Avg batch loss: 0.6375, Avg batch acc: 0.4476
Train, Epoch: 2, Batch: 1124, Step num: 2643, Learning rate: 0.00009234, Avg batch loss: 0.6211, Avg batch acc: 0.4399
Train, Epoch: 2, Batch: 1125, Step num: 2644, Learning rate: 0.00009238, Avg batch loss: 0.5823, Avg batch acc: 0.4393
Train, Epoch: 2, Batch: 1126, Step num: 2645, Learning rate: 0.00009241, Avg batch loss: 0.5898, Avg batch acc: 0.4344
Train, Epoch: 2, Batch: 1127, Step num: 2646, Learning rate: 0.00009245, Avg batch loss: 0.5625, Avg batch acc: 0.4635
Train, Epoch: 2, Batch: 1128, Step num: 2647, Learning rate: 0.00009248, Avg batch loss: 0.5965, Avg batch acc: 0.4466
Train, Epoch: 2, Batch: 1129, Step num: 2648, Learning rate: 0.00009252, Avg batch loss: 0.5268, Avg batch acc: 0.4877
Train, Epoch: 2, Batch: 1130, Step num: 2649, Learning rate: 0.00009255, Avg batch loss: 0.5527, Avg batch acc: 0.4797
Train, Epoch: 2, Batch: 1131, Step num: 2650, Learning rate: 0.00009259, Avg batch loss: 0.5740, Avg batch acc: 0.4406
Train, Epoch: 2, Batch: 1132, Step num: 2651, Learning rate: 0.00009262, Avg batch loss: 0.5889, Avg batch acc: 0.4625
Train, Epoch: 2, Batch: 1133, Step num: 2652, Learning rate: 0.00009266, Avg batch loss: 0.6170, Avg batch acc: 0.4612
Train, Epoch: 2, Batch: 1134, Step num: 2653, Learning rate: 0.00009269, Avg batch loss: 0.6214, Avg batch acc: 0.4542
Train, Epoch: 2, Batch: 1135, Step num: 2654, Learning rate: 0.00009273, Avg batch loss: 0.5933, Avg batch acc: 0.4386
Train, Epoch: 2, Batch: 1136, Step num: 2655, Learning rate: 0.00009276, Avg batch loss: 0.5824, Avg batch acc: 0.4544
Train, Epoch: 2, Batch: 1137, Step num: 2656, Learning rate: 0.00009280, Avg batch loss: 0.6058, Avg batch acc: 0.4619
Train, Epoch: 2, Batch: 1138, Step num: 2657, Learning rate: 0.00009283, Avg batch loss: 0.6439, Avg batch acc: 0.4420
Train, Epoch: 2, Batch: 1139, Step num: 2658, Learning rate: 0.00009287, Avg batch loss: 0.5870, Avg batch acc: 0.4634
Train, Epoch: 2, Batch: 1140, Step num: 2659, Learning rate: 0.00009290, Avg batch loss: 0.5431, Avg batch acc: 0.4841
Train, Epoch: 2, Batch: 1141, Step num: 2660, Learning rate: 0.00009294, Avg batch loss: 0.6199, Avg batch acc: 0.4744
Train, Epoch: 2, Batch: 1142, Step num: 2661, Learning rate: 0.00009297, Avg batch loss: 0.5382, Avg batch acc: 0.4433
Train, Epoch: 2, Batch: 1143, Step num: 2662, Learning rate: 0.00009301, Avg batch loss: 0.5765, Avg batch acc: 0.4451
Train, Epoch: 2, Batch: 1144, Step num: 2663, Learning rate: 0.00009304, Avg batch loss: 0.6025, Avg batch acc: 0.4452
Train, Epoch: 2, Batch: 1145, Step num: 2664, Learning rate: 0.00009308, Avg batch loss: 0.5585, Avg batch acc: 0.4538
Train, Epoch: 2, Batch: 1146, Step num: 2665, Learning rate: 0.00009311, Avg batch loss: 0.5485, Avg batch acc: 0.4516
Train, Epoch: 2, Batch: 1147, Step num: 2666, Learning rate: 0.00009315, Avg batch loss: 0.5979, Avg batch acc: 0.4190
Train, Epoch: 2, Batch: 1148, Step num: 2667, Learning rate: 0.00009318, Avg batch loss: 0.5195, Avg batch acc: 0.4536
Train, Epoch: 2, Batch: 1149, Step num: 2668, Learning rate: 0.00009322, Avg batch loss: 0.5807, Avg batch acc: 0.4458
Train, Epoch: 2, Batch: 1150, Step num: 2669, Learning rate: 0.00009325, Avg batch loss: 0.5732, Avg batch acc: 0.4590
Train, Epoch: 2, Batch: 1151, Step num: 2670, Learning rate: 0.00009329, Avg batch loss: 0.5860, Avg batch acc: 0.4465
Train, Epoch: 2, Batch: 1152, Step num: 2671, Learning rate: 0.00009332, Avg batch loss: 0.5586, Avg batch acc: 0.4492
Train, Epoch: 2, Batch: 1153, Step num: 2672, Learning rate: 0.00009336, Avg batch loss: 0.6040, Avg batch acc: 0.4573
Train, Epoch: 2, Batch: 1154, Step num: 2673, Learning rate: 0.00009339, Avg batch loss: 0.5415, Avg batch acc: 0.4559
Train, Epoch: 2, Batch: 1155, Step num: 2674, Learning rate: 0.00009343, Avg batch loss: 0.5738, Avg batch acc: 0.4403
Train, Epoch: 2, Batch: 1156, Step num: 2675, Learning rate: 0.00009346, Avg batch loss: 0.6343, Avg batch acc: 0.4535
Train, Epoch: 2, Batch: 1157, Step num: 2676, Learning rate: 0.00009350, Avg batch loss: 0.6108, Avg batch acc: 0.4521
Train, Epoch: 2, Batch: 1158, Step num: 2677, Learning rate: 0.00009353, Avg batch loss: 0.5335, Avg batch acc: 0.4711
Train, Epoch: 2, Batch: 1159, Step num: 2678, Learning rate: 0.00009357, Avg batch loss: 0.5678, Avg batch acc: 0.4566
Train, Epoch: 2, Batch: 1160, Step num: 2679, Learning rate: 0.00009360, Avg batch loss: 0.5926, Avg batch acc: 0.4603
Train, Epoch: 2, Batch: 1161, Step num: 2680, Learning rate: 0.00009364, Avg batch loss: 0.5920, Avg batch acc: 0.4612
Train, Epoch: 2, Batch: 1162, Step num: 2681, Learning rate: 0.00009367, Avg batch loss: 0.6932, Avg batch acc: 0.4489
Train, Epoch: 2, Batch: 1163, Step num: 2682, Learning rate: 0.00009371, Avg batch loss: 0.5590, Avg batch acc: 0.4763
Train, Epoch: 2, Batch: 1164, Step num: 2683, Learning rate: 0.00009374, Avg batch loss: 0.5917, Avg batch acc: 0.4412
Train, Epoch: 2, Batch: 1165, Step num: 2684, Learning rate: 0.00009378, Avg batch loss: 0.5702, Avg batch acc: 0.4654
Train, Epoch: 2, Batch: 1166, Step num: 2685, Learning rate: 0.00009381, Avg batch loss: 0.5851, Avg batch acc: 0.4579
Train, Epoch: 2, Batch: 1167, Step num: 2686, Learning rate: 0.00009384, Avg batch loss: 0.5109, Avg batch acc: 0.4895
Train, Epoch: 2, Batch: 1168, Step num: 2687, Learning rate: 0.00009388, Avg batch loss: 0.6729, Avg batch acc: 0.4448
Train, Epoch: 2, Batch: 1169, Step num: 2688, Learning rate: 0.00009391, Avg batch loss: 0.6483, Avg batch acc: 0.4451
Train, Epoch: 2, Batch: 1170, Step num: 2689, Learning rate: 0.00009395, Avg batch loss: 0.5573, Avg batch acc: 0.4383
Train, Epoch: 2, Batch: 1171, Step num: 2690, Learning rate: 0.00009398, Avg batch loss: 0.6545, Avg batch acc: 0.4452
Train, Epoch: 2, Batch: 1172, Step num: 2691, Learning rate: 0.00009402, Avg batch loss: 0.5640, Avg batch acc: 0.4793
Train, Epoch: 2, Batch: 1173, Step num: 2692, Learning rate: 0.00009405, Avg batch loss: 0.5698, Avg batch acc: 0.4616
Train, Epoch: 2, Batch: 1174, Step num: 2693, Learning rate: 0.00009409, Avg batch loss: 0.5788, Avg batch acc: 0.4561
Train, Epoch: 2, Batch: 1175, Step num: 2694, Learning rate: 0.00009412, Avg batch loss: 0.5947, Avg batch acc: 0.4484
Train, Epoch: 2, Batch: 1176, Step num: 2695, Learning rate: 0.00009416, Avg batch loss: 0.5761, Avg batch acc: 0.4796
Train, Epoch: 2, Batch: 1177, Step num: 2696, Learning rate: 0.00009419, Avg batch loss: 0.6442, Avg batch acc: 0.4524
Train, Epoch: 2, Batch: 1178, Step num: 2697, Learning rate: 0.00009423, Avg batch loss: 0.6072, Avg batch acc: 0.4602
Train, Epoch: 2, Batch: 1179, Step num: 2698, Learning rate: 0.00009426, Avg batch loss: 0.5385, Avg batch acc: 0.4754
Train, Epoch: 2, Batch: 1180, Step num: 2699, Learning rate: 0.00009430, Avg batch loss: 0.6297, Avg batch acc: 0.4569
Train, Epoch: 2, Batch: 1181, Step num: 2700, Learning rate: 0.00009433, Avg batch loss: 0.5924, Avg batch acc: 0.4617
Train, Epoch: 2, Batch: 1182, Step num: 2701, Learning rate: 0.00009437, Avg batch loss: 0.6049, Avg batch acc: 0.4622
Train, Epoch: 2, Batch: 1183, Step num: 2702, Learning rate: 0.00009440, Avg batch loss: 0.6296, Avg batch acc: 0.4482
Train, Epoch: 2, Batch: 1184, Step num: 2703, Learning rate: 0.00009444, Avg batch loss: 0.5779, Avg batch acc: 0.4702
Train, Epoch: 2, Batch: 1185, Step num: 2704, Learning rate: 0.00009447, Avg batch loss: 0.5943, Avg batch acc: 0.4530
Train, Epoch: 2, Batch: 1186, Step num: 2705, Learning rate: 0.00009451, Avg batch loss: 0.5265, Avg batch acc: 0.4941
Train, Epoch: 2, Batch: 1187, Step num: 2706, Learning rate: 0.00009454, Avg batch loss: 0.6390, Avg batch acc: 0.4581
Train, Epoch: 2, Batch: 1188, Step num: 2707, Learning rate: 0.00009458, Avg batch loss: 0.6377, Avg batch acc: 0.4384
Train, Epoch: 2, Batch: 1189, Step num: 2708, Learning rate: 0.00009461, Avg batch loss: 0.5811, Avg batch acc: 0.4767
Train, Epoch: 2, Batch: 1190, Step num: 2709, Learning rate: 0.00009465, Avg batch loss: 0.5983, Avg batch acc: 0.4614
Train, Epoch: 2, Batch: 1191, Step num: 2710, Learning rate: 0.00009468, Avg batch loss: 0.5586, Avg batch acc: 0.4557
Train, Epoch: 2, Batch: 1192, Step num: 2711, Learning rate: 0.00009472, Avg batch loss: 0.6121, Avg batch acc: 0.4607
Train, Epoch: 2, Batch: 1193, Step num: 2712, Learning rate: 0.00009475, Avg batch loss: 0.6076, Avg batch acc: 0.4669
Train, Epoch: 2, Batch: 1194, Step num: 2713, Learning rate: 0.00009479, Avg batch loss: 0.6127, Avg batch acc: 0.4474
Train, Epoch: 2, Batch: 1195, Step num: 2714, Learning rate: 0.00009482, Avg batch loss: 0.5692, Avg batch acc: 0.4864
Train, Epoch: 2, Batch: 1196, Step num: 2715, Learning rate: 0.00009486, Avg batch loss: 0.5879, Avg batch acc: 0.4629
Train, Epoch: 2, Batch: 1197, Step num: 2716, Learning rate: 0.00009489, Avg batch loss: 0.5726, Avg batch acc: 0.4707
Train, Epoch: 2, Batch: 1198, Step num: 2717, Learning rate: 0.00009493, Avg batch loss: 0.5497, Avg batch acc: 0.4677
Train, Epoch: 2, Batch: 1199, Step num: 2718, Learning rate: 0.00009496, Avg batch loss: 0.5556, Avg batch acc: 0.4828
Train, Epoch: 2, Batch: 1200, Step num: 2719, Learning rate: 0.00009500, Avg batch loss: 0.5973, Avg batch acc: 0.4484
Train, Epoch: 2, Batch: 1201, Step num: 2720, Learning rate: 0.00009503, Avg batch loss: 0.5838, Avg batch acc: 0.4625
Train, Epoch: 2, Batch: 1202, Step num: 2721, Learning rate: 0.00009507, Avg batch loss: 0.5939, Avg batch acc: 0.4736
Train, Epoch: 2, Batch: 1203, Step num: 2722, Learning rate: 0.00009510, Avg batch loss: 0.5392, Avg batch acc: 0.4798
Train, Epoch: 2, Batch: 1204, Step num: 2723, Learning rate: 0.00009514, Avg batch loss: 0.6241, Avg batch acc: 0.4553
Train, Epoch: 2, Batch: 1205, Step num: 2724, Learning rate: 0.00009517, Avg batch loss: 0.5513, Avg batch acc: 0.4909
Train, Epoch: 2, Batch: 1206, Step num: 2725, Learning rate: 0.00009521, Avg batch loss: 0.5832, Avg batch acc: 0.4555
Train, Epoch: 2, Batch: 1207, Step num: 2726, Learning rate: 0.00009524, Avg batch loss: 0.5867, Avg batch acc: 0.4721
Train, Epoch: 2, Batch: 1208, Step num: 2727, Learning rate: 0.00009528, Avg batch loss: 0.6672, Avg batch acc: 0.4300
Train, Epoch: 2, Batch: 1209, Step num: 2728, Learning rate: 0.00009531, Avg batch loss: 0.5728, Avg batch acc: 0.4658
Train, Epoch: 2, Batch: 1210, Step num: 2729, Learning rate: 0.00009535, Avg batch loss: 0.6149, Avg batch acc: 0.4648
Train, Epoch: 2, Batch: 1211, Step num: 2730, Learning rate: 0.00009538, Avg batch loss: 0.6037, Avg batch acc: 0.4696
Train, Epoch: 2, Batch: 1212, Step num: 2731, Learning rate: 0.00009542, Avg batch loss: 0.6103, Avg batch acc: 0.4530
Train, Epoch: 2, Batch: 1213, Step num: 2732, Learning rate: 0.00009545, Avg batch loss: 0.5869, Avg batch acc: 0.4655
Train, Epoch: 2, Batch: 1214, Step num: 2733, Learning rate: 0.00009549, Avg batch loss: 0.5758, Avg batch acc: 0.4504
Train, Epoch: 2, Batch: 1215, Step num: 2734, Learning rate: 0.00009552, Avg batch loss: 0.5619, Avg batch acc: 0.4740
Train, Epoch: 2, Batch: 1216, Step num: 2735, Learning rate: 0.00009556, Avg batch loss: 0.6033, Avg batch acc: 0.4793
Train, Epoch: 2, Batch: 1217, Step num: 2736, Learning rate: 0.00009559, Avg batch loss: 0.5888, Avg batch acc: 0.4815
Train, Epoch: 2, Batch: 1218, Step num: 2737, Learning rate: 0.00009563, Avg batch loss: 0.6036, Avg batch acc: 0.4731
Train, Epoch: 2, Batch: 1219, Step num: 2738, Learning rate: 0.00009566, Avg batch loss: 0.5472, Avg batch acc: 0.4701
Train, Epoch: 2, Batch: 1220, Step num: 2739, Learning rate: 0.00009570, Avg batch loss: 0.5642, Avg batch acc: 0.4871
Train, Epoch: 2, Batch: 1221, Step num: 2740, Learning rate: 0.00009573, Avg batch loss: 0.5568, Avg batch acc: 0.4769
Train, Epoch: 2, Batch: 1222, Step num: 2741, Learning rate: 0.00009577, Avg batch loss: 0.6078, Avg batch acc: 0.4411
Train, Epoch: 2, Batch: 1223, Step num: 2742, Learning rate: 0.00009580, Avg batch loss: 0.4958, Avg batch acc: 0.4749
Train, Epoch: 2, Batch: 1224, Step num: 2743, Learning rate: 0.00009584, Avg batch loss: 0.5798, Avg batch acc: 0.4750
Train, Epoch: 2, Batch: 1225, Step num: 2744, Learning rate: 0.00009587, Avg batch loss: 0.5639, Avg batch acc: 0.4773
Train, Epoch: 2, Batch: 1226, Step num: 2745, Learning rate: 0.00009591, Avg batch loss: 0.5870, Avg batch acc: 0.4390
Train, Epoch: 2, Batch: 1227, Step num: 2746, Learning rate: 0.00009594, Avg batch loss: 0.5466, Avg batch acc: 0.4795
Train, Epoch: 2, Batch: 1228, Step num: 2747, Learning rate: 0.00009598, Avg batch loss: 0.5737, Avg batch acc: 0.4773
Train, Epoch: 2, Batch: 1229, Step num: 2748, Learning rate: 0.00009601, Avg batch loss: 0.4961, Avg batch acc: 0.5221
Train, Epoch: 2, Batch: 1230, Step num: 2749, Learning rate: 0.00009605, Avg batch loss: 0.6176, Avg batch acc: 0.4535
Train, Epoch: 2, Batch: 1231, Step num: 2750, Learning rate: 0.00009608, Avg batch loss: 0.5946, Avg batch acc: 0.4669
Train, Epoch: 2, Batch: 1232, Step num: 2751, Learning rate: 0.00009612, Avg batch loss: 0.6008, Avg batch acc: 0.4567
Train, Epoch: 2, Batch: 1233, Step num: 2752, Learning rate: 0.00009615, Avg batch loss: 0.5436, Avg batch acc: 0.4788
Train, Epoch: 2, Batch: 1234, Step num: 2753, Learning rate: 0.00009619, Avg batch loss: 0.6186, Avg batch acc: 0.4516
Train, Epoch: 2, Batch: 1235, Step num: 2754, Learning rate: 0.00009622, Avg batch loss: 0.5259, Avg batch acc: 0.4626
Train, Epoch: 2, Batch: 1236, Step num: 2755, Learning rate: 0.00009626, Avg batch loss: 0.6087, Avg batch acc: 0.4537
Train, Epoch: 2, Batch: 1237, Step num: 2756, Learning rate: 0.00009629, Avg batch loss: 0.5219, Avg batch acc: 0.4810
Train, Epoch: 2, Batch: 1238, Step num: 2757, Learning rate: 0.00009633, Avg batch loss: 0.5446, Avg batch acc: 0.4782
Train, Epoch: 2, Batch: 1239, Step num: 2758, Learning rate: 0.00009636, Avg batch loss: 0.5126, Avg batch acc: 0.5027
Train, Epoch: 2, Batch: 1240, Step num: 2759, Learning rate: 0.00009640, Avg batch loss: 0.5383, Avg batch acc: 0.4870
Train, Epoch: 2, Batch: 1241, Step num: 2760, Learning rate: 0.00009643, Avg batch loss: 0.6172, Avg batch acc: 0.4597
Train, Epoch: 2, Batch: 1242, Step num: 2761, Learning rate: 0.00009647, Avg batch loss: 0.5565, Avg batch acc: 0.4505
Train, Epoch: 2, Batch: 1243, Step num: 2762, Learning rate: 0.00009650, Avg batch loss: 0.5449, Avg batch acc: 0.4791
Train, Epoch: 2, Batch: 1244, Step num: 2763, Learning rate: 0.00009654, Avg batch loss: 0.5345, Avg batch acc: 0.4998
Train, Epoch: 2, Batch: 1245, Step num: 2764, Learning rate: 0.00009657, Avg batch loss: 0.6199, Avg batch acc: 0.4578
Train, Epoch: 2, Batch: 1246, Step num: 2765, Learning rate: 0.00009661, Avg batch loss: 0.5680, Avg batch acc: 0.4554
Train, Epoch: 2, Batch: 1247, Step num: 2766, Learning rate: 0.00009664, Avg batch loss: 0.5513, Avg batch acc: 0.4715
Train, Epoch: 2, Batch: 1248, Step num: 2767, Learning rate: 0.00009668, Avg batch loss: 0.5242, Avg batch acc: 0.5040
Train, Epoch: 2, Batch: 1249, Step num: 2768, Learning rate: 0.00009671, Avg batch loss: 0.5775, Avg batch acc: 0.4655
Train, Epoch: 2, Batch: 1250, Step num: 2769, Learning rate: 0.00009674, Avg batch loss: 0.6270, Avg batch acc: 0.4717
Train, Epoch: 2, Batch: 1251, Step num: 2770, Learning rate: 0.00009678, Avg batch loss: 0.5532, Avg batch acc: 0.4815
Train, Epoch: 2, Batch: 1252, Step num: 2771, Learning rate: 0.00009681, Avg batch loss: 0.6038, Avg batch acc: 0.4764
Train, Epoch: 2, Batch: 1253, Step num: 2772, Learning rate: 0.00009685, Avg batch loss: 0.6223, Avg batch acc: 0.4689
Train, Epoch: 2, Batch: 1254, Step num: 2773, Learning rate: 0.00009688, Avg batch loss: 0.5437, Avg batch acc: 0.4722
Train, Epoch: 2, Batch: 1255, Step num: 2774, Learning rate: 0.00009692, Avg batch loss: 0.5669, Avg batch acc: 0.4875
Train, Epoch: 2, Batch: 1256, Step num: 2775, Learning rate: 0.00009695, Avg batch loss: 0.5869, Avg batch acc: 0.4859
Train, Epoch: 2, Batch: 1257, Step num: 2776, Learning rate: 0.00009699, Avg batch loss: 0.5462, Avg batch acc: 0.4615
Train, Epoch: 2, Batch: 1258, Step num: 2777, Learning rate: 0.00009702, Avg batch loss: 0.6019, Avg batch acc: 0.4495
Train, Epoch: 2, Batch: 1259, Step num: 2778, Learning rate: 0.00009706, Avg batch loss: 0.6176, Avg batch acc: 0.4672
Train, Epoch: 2, Batch: 1260, Step num: 2779, Learning rate: 0.00009709, Avg batch loss: 0.5035, Avg batch acc: 0.4771
Train, Epoch: 2, Batch: 1261, Step num: 2780, Learning rate: 0.00009713, Avg batch loss: 0.5750, Avg batch acc: 0.4842
Train, Epoch: 2, Batch: 1262, Step num: 2781, Learning rate: 0.00009716, Avg batch loss: 0.5736, Avg batch acc: 0.4675
Train, Epoch: 2, Batch: 1263, Step num: 2782, Learning rate: 0.00009720, Avg batch loss: 0.6532, Avg batch acc: 0.4592
Train, Epoch: 2, Batch: 1264, Step num: 2783, Learning rate: 0.00009723, Avg batch loss: 0.5574, Avg batch acc: 0.4946
Train, Epoch: 2, Batch: 1265, Step num: 2784, Learning rate: 0.00009727, Avg batch loss: 0.6146, Avg batch acc: 0.4726
Train, Epoch: 2, Batch: 1266, Step num: 2785, Learning rate: 0.00009730, Avg batch loss: 0.5655, Avg batch acc: 0.4934
Train, Epoch: 2, Batch: 1267, Step num: 2786, Learning rate: 0.00009734, Avg batch loss: 0.5646, Avg batch acc: 0.4857
Train, Epoch: 2, Batch: 1268, Step num: 2787, Learning rate: 0.00009737, Avg batch loss: 0.6075, Avg batch acc: 0.4691
Train, Epoch: 2, Batch: 1269, Step num: 2788, Learning rate: 0.00009741, Avg batch loss: 0.5971, Avg batch acc: 0.4564
Train, Epoch: 2, Batch: 1270, Step num: 2789, Learning rate: 0.00009744, Avg batch loss: 0.5181, Avg batch acc: 0.5066
Train, Epoch: 2, Batch: 1271, Step num: 2790, Learning rate: 0.00009748, Avg batch loss: 0.5814, Avg batch acc: 0.4787
Train, Epoch: 2, Batch: 1272, Step num: 2791, Learning rate: 0.00009751, Avg batch loss: 0.5430, Avg batch acc: 0.4987
Train, Epoch: 2, Batch: 1273, Step num: 2792, Learning rate: 0.00009755, Avg batch loss: 0.5394, Avg batch acc: 0.5209
Train, Epoch: 2, Batch: 1274, Step num: 2793, Learning rate: 0.00009758, Avg batch loss: 0.5792, Avg batch acc: 0.4829
Train, Epoch: 2, Batch: 1275, Step num: 2794, Learning rate: 0.00009762, Avg batch loss: 0.6263, Avg batch acc: 0.4715
Train, Epoch: 2, Batch: 1276, Step num: 2795, Learning rate: 0.00009765, Avg batch loss: 0.5443, Avg batch acc: 0.4799
Train, Epoch: 2, Batch: 1277, Step num: 2796, Learning rate: 0.00009769, Avg batch loss: 0.5739, Avg batch acc: 0.4641
Train, Epoch: 2, Batch: 1278, Step num: 2797, Learning rate: 0.00009772, Avg batch loss: 0.5502, Avg batch acc: 0.4630
Train, Epoch: 2, Batch: 1279, Step num: 2798, Learning rate: 0.00009776, Avg batch loss: 0.6064, Avg batch acc: 0.4791
Train, Epoch: 2, Batch: 1280, Step num: 2799, Learning rate: 0.00009779, Avg batch loss: 0.5602, Avg batch acc: 0.4703
Train, Epoch: 2, Batch: 1281, Step num: 2800, Learning rate: 0.00009783, Avg batch loss: 0.5521, Avg batch acc: 0.4960
Train, Epoch: 2, Batch: 1282, Step num: 2801, Learning rate: 0.00009786, Avg batch loss: 0.5538, Avg batch acc: 0.5179
Train, Epoch: 2, Batch: 1283, Step num: 2802, Learning rate: 0.00009790, Avg batch loss: 0.5823, Avg batch acc: 0.4883
Train, Epoch: 2, Batch: 1284, Step num: 2803, Learning rate: 0.00009793, Avg batch loss: 0.6535, Avg batch acc: 0.4642
Train, Epoch: 2, Batch: 1285, Step num: 2804, Learning rate: 0.00009797, Avg batch loss: 0.5478, Avg batch acc: 0.5154
Train, Epoch: 2, Batch: 1286, Step num: 2805, Learning rate: 0.00009800, Avg batch loss: 0.5724, Avg batch acc: 0.4843
Train, Epoch: 2, Batch: 1287, Step num: 2806, Learning rate: 0.00009804, Avg batch loss: 0.5289, Avg batch acc: 0.5011
Train, Epoch: 2, Batch: 1288, Step num: 2807, Learning rate: 0.00009807, Avg batch loss: 0.5286, Avg batch acc: 0.4716
Train, Epoch: 2, Batch: 1289, Step num: 2808, Learning rate: 0.00009811, Avg batch loss: 0.5321, Avg batch acc: 0.4914
Train, Epoch: 2, Batch: 1290, Step num: 2809, Learning rate: 0.00009814, Avg batch loss: 0.5841, Avg batch acc: 0.4805
Train, Epoch: 2, Batch: 1291, Step num: 2810, Learning rate: 0.00009818, Avg batch loss: 0.5452, Avg batch acc: 0.4562
Train, Epoch: 2, Batch: 1292, Step num: 2811, Learning rate: 0.00009821, Avg batch loss: 0.5819, Avg batch acc: 0.4780
Train, Epoch: 2, Batch: 1293, Step num: 2812, Learning rate: 0.00009825, Avg batch loss: 0.6615, Avg batch acc: 0.4511
Train, Epoch: 2, Batch: 1294, Step num: 2813, Learning rate: 0.00009828, Avg batch loss: 0.5423, Avg batch acc: 0.4871
Train, Epoch: 2, Batch: 1295, Step num: 2814, Learning rate: 0.00009832, Avg batch loss: 0.5815, Avg batch acc: 0.4877
Train, Epoch: 2, Batch: 1296, Step num: 2815, Learning rate: 0.00009835, Avg batch loss: 0.5099, Avg batch acc: 0.5148
Train, Epoch: 2, Batch: 1297, Step num: 2816, Learning rate: 0.00009839, Avg batch loss: 0.5244, Avg batch acc: 0.4832
Train, Epoch: 2, Batch: 1298, Step num: 2817, Learning rate: 0.00009842, Avg batch loss: 0.5446, Avg batch acc: 0.5059
Train, Epoch: 2, Batch: 1299, Step num: 2818, Learning rate: 0.00009846, Avg batch loss: 0.5686, Avg batch acc: 0.4997
Train, Epoch: 2, Batch: 1300, Step num: 2819, Learning rate: 0.00009849, Avg batch loss: 0.6181, Avg batch acc: 0.4764
Train, Epoch: 2, Batch: 1301, Step num: 2820, Learning rate: 0.00009853, Avg batch loss: 0.5145, Avg batch acc: 0.4964
Train, Epoch: 2, Batch: 1302, Step num: 2821, Learning rate: 0.00009856, Avg batch loss: 0.5471, Avg batch acc: 0.4986
Train, Epoch: 2, Batch: 1303, Step num: 2822, Learning rate: 0.00009860, Avg batch loss: 0.5407, Avg batch acc: 0.4890
Train, Epoch: 2, Batch: 1304, Step num: 2823, Learning rate: 0.00009863, Avg batch loss: 0.5716, Avg batch acc: 0.4905
Train, Epoch: 2, Batch: 1305, Step num: 2824, Learning rate: 0.00009867, Avg batch loss: 0.5758, Avg batch acc: 0.4885
Train, Epoch: 2, Batch: 1306, Step num: 2825, Learning rate: 0.00009870, Avg batch loss: 0.5914, Avg batch acc: 0.4905
Train, Epoch: 2, Batch: 1307, Step num: 2826, Learning rate: 0.00009874, Avg batch loss: 0.5351, Avg batch acc: 0.5037
Train, Epoch: 2, Batch: 1308, Step num: 2827, Learning rate: 0.00009877, Avg batch loss: 0.5799, Avg batch acc: 0.4792
Train, Epoch: 2, Batch: 1309, Step num: 2828, Learning rate: 0.00009881, Avg batch loss: 0.5913, Avg batch acc: 0.4608
Train, Epoch: 2, Batch: 1310, Step num: 2829, Learning rate: 0.00009884, Avg batch loss: 0.5669, Avg batch acc: 0.4903
Train, Epoch: 2, Batch: 1311, Step num: 2830, Learning rate: 0.00009888, Avg batch loss: 0.5417, Avg batch acc: 0.5064
Train, Epoch: 2, Batch: 1312, Step num: 2831, Learning rate: 0.00009891, Avg batch loss: 0.5333, Avg batch acc: 0.4908
Train, Epoch: 2, Batch: 1313, Step num: 2832, Learning rate: 0.00009895, Avg batch loss: 0.5315, Avg batch acc: 0.5075
Train, Epoch: 2, Batch: 1314, Step num: 2833, Learning rate: 0.00009898, Avg batch loss: 0.5420, Avg batch acc: 0.4878
Train, Epoch: 2, Batch: 1315, Step num: 2834, Learning rate: 0.00009902, Avg batch loss: 0.5338, Avg batch acc: 0.5253
Train, Epoch: 2, Batch: 1316, Step num: 2835, Learning rate: 0.00009905, Avg batch loss: 0.5770, Avg batch acc: 0.4803
Train, Epoch: 2, Batch: 1317, Step num: 2836, Learning rate: 0.00009909, Avg batch loss: 0.5477, Avg batch acc: 0.4896
Train, Epoch: 2, Batch: 1318, Step num: 2837, Learning rate: 0.00009912, Avg batch loss: 0.5445, Avg batch acc: 0.5167
Train, Epoch: 2, Batch: 1319, Step num: 2838, Learning rate: 0.00009916, Avg batch loss: 0.5497, Avg batch acc: 0.4833
Train, Epoch: 2, Batch: 1320, Step num: 2839, Learning rate: 0.00009919, Avg batch loss: 0.5415, Avg batch acc: 0.5022
Train, Epoch: 2, Batch: 1321, Step num: 2840, Learning rate: 0.00009923, Avg batch loss: 0.6053, Avg batch acc: 0.4926
Train, Epoch: 2, Batch: 1322, Step num: 2841, Learning rate: 0.00009926, Avg batch loss: 0.5602, Avg batch acc: 0.4706
Train, Epoch: 2, Batch: 1323, Step num: 2842, Learning rate: 0.00009930, Avg batch loss: 0.5506, Avg batch acc: 0.4995
Train, Epoch: 2, Batch: 1324, Step num: 2843, Learning rate: 0.00009933, Avg batch loss: 0.5955, Avg batch acc: 0.4829
Train, Epoch: 2, Batch: 1325, Step num: 2844, Learning rate: 0.00009937, Avg batch loss: 0.5108, Avg batch acc: 0.5062
Train, Epoch: 2, Batch: 1326, Step num: 2845, Learning rate: 0.00009940, Avg batch loss: 0.5659, Avg batch acc: 0.4839
Train, Epoch: 2, Batch: 1327, Step num: 2846, Learning rate: 0.00009944, Avg batch loss: 0.5744, Avg batch acc: 0.4929
Train, Epoch: 2, Batch: 1328, Step num: 2847, Learning rate: 0.00009947, Avg batch loss: 0.5880, Avg batch acc: 0.5103
Train, Epoch: 2, Batch: 1329, Step num: 2848, Learning rate: 0.00009951, Avg batch loss: 0.5092, Avg batch acc: 0.5014
Train, Epoch: 2, Batch: 1330, Step num: 2849, Learning rate: 0.00009954, Avg batch loss: 0.5619, Avg batch acc: 0.4945
Train, Epoch: 2, Batch: 1331, Step num: 2850, Learning rate: 0.00009957, Avg batch loss: 0.5444, Avg batch acc: 0.4828
Train, Epoch: 2, Batch: 1332, Step num: 2851, Learning rate: 0.00009961, Avg batch loss: 0.5576, Avg batch acc: 0.4831
Train, Epoch: 2, Batch: 1333, Step num: 2852, Learning rate: 0.00009964, Avg batch loss: 0.5358, Avg batch acc: 0.5167
Train, Epoch: 2, Batch: 1334, Step num: 2853, Learning rate: 0.00009968, Avg batch loss: 0.5072, Avg batch acc: 0.5033
Train, Epoch: 2, Batch: 1335, Step num: 2854, Learning rate: 0.00009971, Avg batch loss: 0.5545, Avg batch acc: 0.4925
Train, Epoch: 2, Batch: 1336, Step num: 2855, Learning rate: 0.00009975, Avg batch loss: 0.5334, Avg batch acc: 0.4980
Train, Epoch: 2, Batch: 1337, Step num: 2856, Learning rate: 0.00009978, Avg batch loss: 0.5274, Avg batch acc: 0.5042
Train, Epoch: 2, Batch: 1338, Step num: 2857, Learning rate: 0.00009982, Avg batch loss: 0.5289, Avg batch acc: 0.4764
Train, Epoch: 2, Batch: 1339, Step num: 2858, Learning rate: 0.00009985, Avg batch loss: 0.5764, Avg batch acc: 0.5049
Train, Epoch: 2, Batch: 1340, Step num: 2859, Learning rate: 0.00009989, Avg batch loss: 0.5951, Avg batch acc: 0.5018
Train, Epoch: 2, Batch: 1341, Step num: 2860, Learning rate: 0.00009992, Avg batch loss: 0.5607, Avg batch acc: 0.5009
Train, Epoch: 2, Batch: 1342, Step num: 2861, Learning rate: 0.00009996, Avg batch loss: 0.4796, Avg batch acc: 0.5104
Train, Epoch: 2, Batch: 1343, Step num: 2862, Learning rate: 0.00009999, Avg batch loss: 0.5441, Avg batch acc: 0.4860
Train, Epoch: 2, Batch: 1344, Step num: 2863, Learning rate: 0.00010003, Avg batch loss: 0.5380, Avg batch acc: 0.4930
Train, Epoch: 2, Batch: 1345, Step num: 2864, Learning rate: 0.00010006, Avg batch loss: 0.5569, Avg batch acc: 0.5131
Train, Epoch: 2, Batch: 1346, Step num: 2865, Learning rate: 0.00010010, Avg batch loss: 0.5473, Avg batch acc: 0.4858
Train, Epoch: 2, Batch: 1347, Step num: 2866, Learning rate: 0.00010013, Avg batch loss: 0.5331, Avg batch acc: 0.5086
Train, Epoch: 2, Batch: 1348, Step num: 2867, Learning rate: 0.00010017, Avg batch loss: 0.5539, Avg batch acc: 0.4853
Train, Epoch: 2, Batch: 1349, Step num: 2868, Learning rate: 0.00010020, Avg batch loss: 0.5373, Avg batch acc: 0.5050
Train, Epoch: 2, Batch: 1350, Step num: 2869, Learning rate: 0.00010024, Avg batch loss: 0.5661, Avg batch acc: 0.4969
Train, Epoch: 2, Batch: 1351, Step num: 2870, Learning rate: 0.00010027, Avg batch loss: 0.5554, Avg batch acc: 0.4821
Train, Epoch: 2, Batch: 1352, Step num: 2871, Learning rate: 0.00010031, Avg batch loss: 0.5898, Avg batch acc: 0.5011
Train, Epoch: 2, Batch: 1353, Step num: 2872, Learning rate: 0.00010034, Avg batch loss: 0.5555, Avg batch acc: 0.4977
Train, Epoch: 2, Batch: 1354, Step num: 2873, Learning rate: 0.00010038, Avg batch loss: 0.5557, Avg batch acc: 0.5004
Train, Epoch: 2, Batch: 1355, Step num: 2874, Learning rate: 0.00010041, Avg batch loss: 0.4940, Avg batch acc: 0.5228
Train, Epoch: 2, Batch: 1356, Step num: 2875, Learning rate: 0.00010045, Avg batch loss: 0.5924, Avg batch acc: 0.4883
Train, Epoch: 2, Batch: 1357, Step num: 2876, Learning rate: 0.00010048, Avg batch loss: 0.5617, Avg batch acc: 0.4964
Train, Epoch: 2, Batch: 1358, Step num: 2877, Learning rate: 0.00010052, Avg batch loss: 0.5344, Avg batch acc: 0.5101
Train, Epoch: 2, Batch: 1359, Step num: 2878, Learning rate: 0.00010055, Avg batch loss: 0.5537, Avg batch acc: 0.5182
Train, Epoch: 2, Batch: 1360, Step num: 2879, Learning rate: 0.00010059, Avg batch loss: 0.5744, Avg batch acc: 0.4951
Train, Epoch: 2, Batch: 1361, Step num: 2880, Learning rate: 0.00010062, Avg batch loss: 0.5117, Avg batch acc: 0.5043
Train, Epoch: 2, Batch: 1362, Step num: 2881, Learning rate: 0.00010066, Avg batch loss: 0.5360, Avg batch acc: 0.5022
Train, Epoch: 2, Batch: 1363, Step num: 2882, Learning rate: 0.00010069, Avg batch loss: 0.5667, Avg batch acc: 0.4809
Train, Epoch: 2, Batch: 1364, Step num: 2883, Learning rate: 0.00010073, Avg batch loss: 0.5819, Avg batch acc: 0.5036
Train, Epoch: 2, Batch: 1365, Step num: 2884, Learning rate: 0.00010076, Avg batch loss: 0.6557, Avg batch acc: 0.4991
Train, Epoch: 2, Batch: 1366, Step num: 2885, Learning rate: 0.00010080, Avg batch loss: 0.4837, Avg batch acc: 0.5283
Train, Epoch: 2, Batch: 1367, Step num: 2886, Learning rate: 0.00010083, Avg batch loss: 0.4867, Avg batch acc: 0.5061
Train, Epoch: 2, Batch: 1368, Step num: 2887, Learning rate: 0.00010087, Avg batch loss: 0.5672, Avg batch acc: 0.4980
Train, Epoch: 2, Batch: 1369, Step num: 2888, Learning rate: 0.00010090, Avg batch loss: 0.6078, Avg batch acc: 0.5076
Train, Epoch: 2, Batch: 1370, Step num: 2889, Learning rate: 0.00010094, Avg batch loss: 0.5272, Avg batch acc: 0.5026
Train, Epoch: 2, Batch: 1371, Step num: 2890, Learning rate: 0.00010097, Avg batch loss: 0.5496, Avg batch acc: 0.5277
Train, Epoch: 2, Batch: 1372, Step num: 2891, Learning rate: 0.00010101, Avg batch loss: 0.5671, Avg batch acc: 0.5030
Train, Epoch: 2, Batch: 1373, Step num: 2892, Learning rate: 0.00010104, Avg batch loss: 0.5558, Avg batch acc: 0.5035
Train, Epoch: 2, Batch: 1374, Step num: 2893, Learning rate: 0.00010108, Avg batch loss: 0.4969, Avg batch acc: 0.5151
Train, Epoch: 2, Batch: 1375, Step num: 2894, Learning rate: 0.00010111, Avg batch loss: 0.5511, Avg batch acc: 0.5158
Train, Epoch: 2, Batch: 1376, Step num: 2895, Learning rate: 0.00010115, Avg batch loss: 0.4976, Avg batch acc: 0.5417
Train, Epoch: 2, Batch: 1377, Step num: 2896, Learning rate: 0.00010118, Avg batch loss: 0.5077, Avg batch acc: 0.5353
Train, Epoch: 2, Batch: 1378, Step num: 2897, Learning rate: 0.00010122, Avg batch loss: 0.5877, Avg batch acc: 0.4918
Train, Epoch: 2, Batch: 1379, Step num: 2898, Learning rate: 0.00010125, Avg batch loss: 0.5530, Avg batch acc: 0.4883
Train, Epoch: 2, Batch: 1380, Step num: 2899, Learning rate: 0.00010129, Avg batch loss: 0.5702, Avg batch acc: 0.5171
Train, Epoch: 2, Batch: 1381, Step num: 2900, Learning rate: 0.00010132, Avg batch loss: 0.5217, Avg batch acc: 0.5299
Train, Epoch: 2, Batch: 1382, Step num: 2901, Learning rate: 0.00010136, Avg batch loss: 0.5566, Avg batch acc: 0.5034
Train, Epoch: 2, Batch: 1383, Step num: 2902, Learning rate: 0.00010139, Avg batch loss: 0.5123, Avg batch acc: 0.5135
Train, Epoch: 2, Batch: 1384, Step num: 2903, Learning rate: 0.00010143, Avg batch loss: 0.5450, Avg batch acc: 0.5069
Train, Epoch: 2, Batch: 1385, Step num: 2904, Learning rate: 0.00010146, Avg batch loss: 0.5344, Avg batch acc: 0.5065
Train, Epoch: 2, Batch: 1386, Step num: 2905, Learning rate: 0.00010150, Avg batch loss: 0.4991, Avg batch acc: 0.5188
Train, Epoch: 2, Batch: 1387, Step num: 2906, Learning rate: 0.00010153, Avg batch loss: 0.5062, Avg batch acc: 0.4950
Train, Epoch: 2, Batch: 1388, Step num: 2907, Learning rate: 0.00010157, Avg batch loss: 0.5111, Avg batch acc: 0.5392
Train, Epoch: 2, Batch: 1389, Step num: 2908, Learning rate: 0.00010160, Avg batch loss: 0.5387, Avg batch acc: 0.5136
Train, Epoch: 2, Batch: 1390, Step num: 2909, Learning rate: 0.00010164, Avg batch loss: 0.5414, Avg batch acc: 0.5139
Train, Epoch: 2, Batch: 1391, Step num: 2910, Learning rate: 0.00010167, Avg batch loss: 0.5269, Avg batch acc: 0.5107
Train, Epoch: 2, Batch: 1392, Step num: 2911, Learning rate: 0.00010171, Avg batch loss: 0.5237, Avg batch acc: 0.5111
Train, Epoch: 2, Batch: 1393, Step num: 2912, Learning rate: 0.00010174, Avg batch loss: 0.5631, Avg batch acc: 0.5083
Train, Epoch: 2, Batch: 1394, Step num: 2913, Learning rate: 0.00010178, Avg batch loss: 0.5226, Avg batch acc: 0.5266
Train, Epoch: 2, Batch: 1395, Step num: 2914, Learning rate: 0.00010181, Avg batch loss: 0.4827, Avg batch acc: 0.5178
Train, Epoch: 2, Batch: 1396, Step num: 2915, Learning rate: 0.00010185, Avg batch loss: 0.5830, Avg batch acc: 0.5250
Train, Epoch: 2, Batch: 1397, Step num: 2916, Learning rate: 0.00010188, Avg batch loss: 0.5440, Avg batch acc: 0.5347
Train, Epoch: 2, Batch: 1398, Step num: 2917, Learning rate: 0.00010192, Avg batch loss: 0.4896, Avg batch acc: 0.5521
Train, Epoch: 2, Batch: 1399, Step num: 2918, Learning rate: 0.00010195, Avg batch loss: 0.5251, Avg batch acc: 0.5081
Train, Epoch: 2, Batch: 1400, Step num: 2919, Learning rate: 0.00010199, Avg batch loss: 0.5191, Avg batch acc: 0.5292
Train, Epoch: 2, Batch: 1401, Step num: 2920, Learning rate: 0.00010202, Avg batch loss: 0.5565, Avg batch acc: 0.5248
Train, Epoch: 2, Batch: 1402, Step num: 2921, Learning rate: 0.00010206, Avg batch loss: 0.5112, Avg batch acc: 0.5153
Train, Epoch: 2, Batch: 1403, Step num: 2922, Learning rate: 0.00010209, Avg batch loss: 0.5504, Avg batch acc: 0.5230
Train, Epoch: 2, Batch: 1404, Step num: 2923, Learning rate: 0.00010213, Avg batch loss: 0.5407, Avg batch acc: 0.5055
Train, Epoch: 2, Batch: 1405, Step num: 2924, Learning rate: 0.00010216, Avg batch loss: 0.5315, Avg batch acc: 0.5363
Train, Epoch: 2, Batch: 1406, Step num: 2925, Learning rate: 0.00010220, Avg batch loss: 0.5734, Avg batch acc: 0.5144
Train, Epoch: 2, Batch: 1407, Step num: 2926, Learning rate: 0.00010223, Avg batch loss: 0.4975, Avg batch acc: 0.4978
Train, Epoch: 2, Batch: 1408, Step num: 2927, Learning rate: 0.00010227, Avg batch loss: 0.5381, Avg batch acc: 0.5125
Train, Epoch: 2, Batch: 1409, Step num: 2928, Learning rate: 0.00010230, Avg batch loss: 0.4880, Avg batch acc: 0.5215
Train, Epoch: 2, Batch: 1410, Step num: 2929, Learning rate: 0.00010234, Avg batch loss: 0.6027, Avg batch acc: 0.4994
Train, Epoch: 2, Batch: 1411, Step num: 2930, Learning rate: 0.00010237, Avg batch loss: 0.5160, Avg batch acc: 0.5455
Train, Epoch: 2, Batch: 1412, Step num: 2931, Learning rate: 0.00010240, Avg batch loss: 0.5389, Avg batch acc: 0.5344
Train, Epoch: 2, Batch: 1413, Step num: 2932, Learning rate: 0.00010244, Avg batch loss: 0.5972, Avg batch acc: 0.5014
Train, Epoch: 2, Batch: 1414, Step num: 2933, Learning rate: 0.00010247, Avg batch loss: 0.5059, Avg batch acc: 0.5292
Train, Epoch: 2, Batch: 1415, Step num: 2934, Learning rate: 0.00010251, Avg batch loss: 0.5692, Avg batch acc: 0.5053
Train, Epoch: 2, Batch: 1416, Step num: 2935, Learning rate: 0.00010254, Avg batch loss: 0.5671, Avg batch acc: 0.5004
Train, Epoch: 2, Batch: 1417, Step num: 2936, Learning rate: 0.00010258, Avg batch loss: 0.5622, Avg batch acc: 0.5129
Train, Epoch: 2, Batch: 1418, Step num: 2937, Learning rate: 0.00010261, Avg batch loss: 0.5143, Avg batch acc: 0.5331
Train, Epoch: 2, Batch: 1419, Step num: 2938, Learning rate: 0.00010265, Avg batch loss: 0.5017, Avg batch acc: 0.5450
Train, Epoch: 2, Batch: 1420, Step num: 2939, Learning rate: 0.00010268, Avg batch loss: 0.5402, Avg batch acc: 0.5284
Train, Epoch: 2, Batch: 1421, Step num: 2940, Learning rate: 0.00010272, Avg batch loss: 0.5040, Avg batch acc: 0.5295
Train, Epoch: 2, Batch: 1422, Step num: 2941, Learning rate: 0.00010275, Avg batch loss: 0.5199, Avg batch acc: 0.5259
Train, Epoch: 2, Batch: 1423, Step num: 2942, Learning rate: 0.00010279, Avg batch loss: 0.5632, Avg batch acc: 0.5108
Train, Epoch: 2, Batch: 1424, Step num: 2943, Learning rate: 0.00010282, Avg batch loss: 0.5218, Avg batch acc: 0.5300
Train, Epoch: 2, Batch: 1425, Step num: 2944, Learning rate: 0.00010286, Avg batch loss: 0.5530, Avg batch acc: 0.5085
Train, Epoch: 2, Batch: 1426, Step num: 2945, Learning rate: 0.00010289, Avg batch loss: 0.5826, Avg batch acc: 0.5134
Train, Epoch: 2, Batch: 1427, Step num: 2946, Learning rate: 0.00010293, Avg batch loss: 0.5993, Avg batch acc: 0.5192
Train, Epoch: 2, Batch: 1428, Step num: 2947, Learning rate: 0.00010296, Avg batch loss: 0.6171, Avg batch acc: 0.4876
Train, Epoch: 2, Batch: 1429, Step num: 2948, Learning rate: 0.00010300, Avg batch loss: 0.4944, Avg batch acc: 0.5315
Train, Epoch: 2, Batch: 1430, Step num: 2949, Learning rate: 0.00010303, Avg batch loss: 0.5583, Avg batch acc: 0.5128
Train, Epoch: 2, Batch: 1431, Step num: 2950, Learning rate: 0.00010307, Avg batch loss: 0.5174, Avg batch acc: 0.5255
Train, Epoch: 2, Batch: 1432, Step num: 2951, Learning rate: 0.00010310, Avg batch loss: 0.5819, Avg batch acc: 0.5124
Train, Epoch: 2, Batch: 1433, Step num: 2952, Learning rate: 0.00010314, Avg batch loss: 0.5228, Avg batch acc: 0.5202
Train, Epoch: 2, Batch: 1434, Step num: 2953, Learning rate: 0.00010317, Avg batch loss: 0.5059, Avg batch acc: 0.5518
Train, Epoch: 2, Batch: 1435, Step num: 2954, Learning rate: 0.00010321, Avg batch loss: 0.5184, Avg batch acc: 0.5385
Train, Epoch: 2, Batch: 1436, Step num: 2955, Learning rate: 0.00010324, Avg batch loss: 0.4833, Avg batch acc: 0.5460
Train, Epoch: 2, Batch: 1437, Step num: 2956, Learning rate: 0.00010328, Avg batch loss: 0.5247, Avg batch acc: 0.5301
Train, Epoch: 2, Batch: 1438, Step num: 2957, Learning rate: 0.00010331, Avg batch loss: 0.5721, Avg batch acc: 0.5073
Train, Epoch: 2, Batch: 1439, Step num: 2958, Learning rate: 0.00010335, Avg batch loss: 0.5652, Avg batch acc: 0.5228
Train, Epoch: 2, Batch: 1440, Step num: 2959, Learning rate: 0.00010338, Avg batch loss: 0.4992, Avg batch acc: 0.5438
Train, Epoch: 2, Batch: 1441, Step num: 2960, Learning rate: 0.00010342, Avg batch loss: 0.5346, Avg batch acc: 0.5381
Train, Epoch: 2, Batch: 1442, Step num: 2961, Learning rate: 0.00010345, Avg batch loss: 0.5484, Avg batch acc: 0.5193
Train, Epoch: 2, Batch: 1443, Step num: 2962, Learning rate: 0.00010349, Avg batch loss: 0.5692, Avg batch acc: 0.5215
Train, Epoch: 2, Batch: 1444, Step num: 2963, Learning rate: 0.00010352, Avg batch loss: 0.5141, Avg batch acc: 0.5427
Train, Epoch: 2, Batch: 1445, Step num: 2964, Learning rate: 0.00010356, Avg batch loss: 0.5068, Avg batch acc: 0.5229
Train, Epoch: 2, Batch: 1446, Step num: 2965, Learning rate: 0.00010359, Avg batch loss: 0.5206, Avg batch acc: 0.5495
Train, Epoch: 2, Batch: 1447, Step num: 2966, Learning rate: 0.00010363, Avg batch loss: 0.5253, Avg batch acc: 0.5123
Train, Epoch: 2, Batch: 1448, Step num: 2967, Learning rate: 0.00010366, Avg batch loss: 0.5366, Avg batch acc: 0.5101
Train, Epoch: 2, Batch: 1449, Step num: 2968, Learning rate: 0.00010370, Avg batch loss: 0.5547, Avg batch acc: 0.4995
Train, Epoch: 2, Batch: 1450, Step num: 2969, Learning rate: 0.00010373, Avg batch loss: 0.5197, Avg batch acc: 0.5187
Train, Epoch: 2, Batch: 1451, Step num: 2970, Learning rate: 0.00010377, Avg batch loss: 0.4899, Avg batch acc: 0.5479
Train, Epoch: 2, Batch: 1452, Step num: 2971, Learning rate: 0.00010380, Avg batch loss: 0.5200, Avg batch acc: 0.5328
Train, Epoch: 2, Batch: 1453, Step num: 2972, Learning rate: 0.00010384, Avg batch loss: 0.4698, Avg batch acc: 0.5538
Train, Epoch: 2, Batch: 1454, Step num: 2973, Learning rate: 0.00010387, Avg batch loss: 0.5033, Avg batch acc: 0.5219
Train, Epoch: 2, Batch: 1455, Step num: 2974, Learning rate: 0.00010391, Avg batch loss: 0.4989, Avg batch acc: 0.5418
Train, Epoch: 2, Batch: 1456, Step num: 2975, Learning rate: 0.00010394, Avg batch loss: 0.5506, Avg batch acc: 0.5209
Train, Epoch: 2, Batch: 1457, Step num: 2976, Learning rate: 0.00010398, Avg batch loss: 0.4702, Avg batch acc: 0.5557
Train, Epoch: 2, Batch: 1458, Step num: 2977, Learning rate: 0.00010401, Avg batch loss: 0.5700, Avg batch acc: 0.5070
Train, Epoch: 2, Batch: 1459, Step num: 2978, Learning rate: 0.00010405, Avg batch loss: 0.5141, Avg batch acc: 0.5044
Train, Epoch: 2, Batch: 1460, Step num: 2979, Learning rate: 0.00010408, Avg batch loss: 0.5402, Avg batch acc: 0.5201
Train, Epoch: 2, Batch: 1461, Step num: 2980, Learning rate: 0.00010412, Avg batch loss: 0.5467, Avg batch acc: 0.5282
Train, Epoch: 2, Batch: 1462, Step num: 2981, Learning rate: 0.00010415, Avg batch loss: 0.4799, Avg batch acc: 0.5518
Train, Epoch: 2, Batch: 1463, Step num: 2982, Learning rate: 0.00010419, Avg batch loss: 0.4563, Avg batch acc: 0.5503
Train, Epoch: 2, Batch: 1464, Step num: 2983, Learning rate: 0.00010422, Avg batch loss: 0.5120, Avg batch acc: 0.5483
Train, Epoch: 2, Batch: 1465, Step num: 2984, Learning rate: 0.00010426, Avg batch loss: 0.4578, Avg batch acc: 0.5639
Train, Epoch: 2, Batch: 1466, Step num: 2985, Learning rate: 0.00010429, Avg batch loss: 0.5143, Avg batch acc: 0.5303
Train, Epoch: 2, Batch: 1467, Step num: 2986, Learning rate: 0.00010433, Avg batch loss: 0.5711, Avg batch acc: 0.5271
Train, Epoch: 2, Batch: 1468, Step num: 2987, Learning rate: 0.00010436, Avg batch loss: 0.5602, Avg batch acc: 0.5115
Train, Epoch: 2, Batch: 1469, Step num: 2988, Learning rate: 0.00010440, Avg batch loss: 0.5465, Avg batch acc: 0.5264
Train, Epoch: 2, Batch: 1470, Step num: 2989, Learning rate: 0.00010443, Avg batch loss: 0.5082, Avg batch acc: 0.5223
Train, Epoch: 2, Batch: 1471, Step num: 2990, Learning rate: 0.00010447, Avg batch loss: 0.5104, Avg batch acc: 0.5450
Train, Epoch: 2, Batch: 1472, Step num: 2991, Learning rate: 0.00010450, Avg batch loss: 0.5490, Avg batch acc: 0.5334
Train, Epoch: 2, Batch: 1473, Step num: 2992, Learning rate: 0.00010454, Avg batch loss: 0.5159, Avg batch acc: 0.5428
Train, Epoch: 2, Batch: 1474, Step num: 2993, Learning rate: 0.00010457, Avg batch loss: 0.5635, Avg batch acc: 0.5176
Train, Epoch: 2, Batch: 1475, Step num: 2994, Learning rate: 0.00010461, Avg batch loss: 0.5216, Avg batch acc: 0.5574
Train, Epoch: 2, Batch: 1476, Step num: 2995, Learning rate: 0.00010464, Avg batch loss: 0.5392, Avg batch acc: 0.5402
Train, Epoch: 2, Batch: 1477, Step num: 2996, Learning rate: 0.00010468, Avg batch loss: 0.5381, Avg batch acc: 0.5257
Train, Epoch: 2, Batch: 1478, Step num: 2997, Learning rate: 0.00010471, Avg batch loss: 0.5154, Avg batch acc: 0.5313
Train, Epoch: 2, Batch: 1479, Step num: 2998, Learning rate: 0.00010475, Avg batch loss: 0.4461, Avg batch acc: 0.5748
Train, Epoch: 2, Batch: 1480, Step num: 2999, Learning rate: 0.00010478, Avg batch loss: 0.5072, Avg batch acc: 0.5336
Train, Epoch: 2, Batch: 1481, Step num: 3000, Learning rate: 0.00010482, Avg batch loss: 0.5054, Avg batch acc: 0.5353
Train, Epoch: 2, Batch: 1482, Step num: 3001, Learning rate: 0.00010485, Avg batch loss: 0.4853, Avg batch acc: 0.5589
Train, Epoch: 2, Batch: 1483, Step num: 3002, Learning rate: 0.00010489, Avg batch loss: 0.5270, Avg batch acc: 0.5331
Train, Epoch: 2, Batch: 1484, Step num: 3003, Learning rate: 0.00010492, Avg batch loss: 0.4699, Avg batch acc: 0.5407
Train, Epoch: 2, Batch: 1485, Step num: 3004, Learning rate: 0.00010496, Avg batch loss: 0.4862, Avg batch acc: 0.5309
Train, Epoch: 2, Batch: 1486, Step num: 3005, Learning rate: 0.00010499, Avg batch loss: 0.4714, Avg batch acc: 0.5384
Train, Epoch: 2, Batch: 1487, Step num: 3006, Learning rate: 0.00010503, Avg batch loss: 0.5244, Avg batch acc: 0.5378
Train, Epoch: 2, Batch: 1488, Step num: 3007, Learning rate: 0.00010506, Avg batch loss: 0.5079, Avg batch acc: 0.5602
Train, Epoch: 2, Batch: 1489, Step num: 3008, Learning rate: 0.00010510, Avg batch loss: 0.5156, Avg batch acc: 0.5322
Train, Epoch: 2, Batch: 1490, Step num: 3009, Learning rate: 0.00010513, Avg batch loss: 0.5568, Avg batch acc: 0.5292
Train, Epoch: 2, Batch: 1491, Step num: 3010, Learning rate: 0.00010517, Avg batch loss: 0.5332, Avg batch acc: 0.5104
Train, Epoch: 2, Batch: 1492, Step num: 3011, Learning rate: 0.00010520, Avg batch loss: 0.5401, Avg batch acc: 0.5351
Train, Epoch: 2, Batch: 1493, Step num: 3012, Learning rate: 0.00010523, Avg batch loss: 0.4998, Avg batch acc: 0.5469
Train, Epoch: 2, Batch: 1494, Step num: 3013, Learning rate: 0.00010527, Avg batch loss: 0.5253, Avg batch acc: 0.5342
Train, Epoch: 2, Batch: 1495, Step num: 3014, Learning rate: 0.00010530, Avg batch loss: 0.5523, Avg batch acc: 0.5145
Train, Epoch: 2, Batch: 1496, Step num: 3015, Learning rate: 0.00010534, Avg batch loss: 0.5347, Avg batch acc: 0.5334
Train, Epoch: 2, Batch: 1497, Step num: 3016, Learning rate: 0.00010537, Avg batch loss: 0.4994, Avg batch acc: 0.5296
Train, Epoch: 2, Batch: 1498, Step num: 3017, Learning rate: 0.00010541, Avg batch loss: 0.4925, Avg batch acc: 0.5522
Train, Epoch: 2, Batch: 1499, Step num: 3018, Learning rate: 0.00010544, Avg batch loss: 0.4862, Avg batch acc: 0.5542
Train, Epoch: 2, Batch: 1500, Step num: 3019, Learning rate: 0.00010548, Avg batch loss: 0.5232, Avg batch acc: 0.5374
Train, Epoch: 2, Batch: 1501, Step num: 3020, Learning rate: 0.00010551, Avg batch loss: 0.5478, Avg batch acc: 0.5233
Train, Epoch: 2, Batch: 1502, Step num: 3021, Learning rate: 0.00010555, Avg batch loss: 0.4760, Avg batch acc: 0.5511
Train, Epoch: 2, Batch: 1503, Step num: 3022, Learning rate: 0.00010558, Avg batch loss: 0.5154, Avg batch acc: 0.5477
Train, Epoch: 2, Batch: 1504, Step num: 3023, Learning rate: 0.00010562, Avg batch loss: 0.5097, Avg batch acc: 0.5455
Train, Epoch: 2, Batch: 1505, Step num: 3024, Learning rate: 0.00010565, Avg batch loss: 0.4862, Avg batch acc: 0.5604
Train, Epoch: 2, Batch: 1506, Step num: 3025, Learning rate: 0.00010569, Avg batch loss: 0.5193, Avg batch acc: 0.5364
Train, Epoch: 2, Batch: 1507, Step num: 3026, Learning rate: 0.00010572, Avg batch loss: 0.5511, Avg batch acc: 0.5450
Train, Epoch: 2, Batch: 1508, Step num: 3027, Learning rate: 0.00010576, Avg batch loss: 0.5236, Avg batch acc: 0.5565
Train, Epoch: 2, Batch: 1509, Step num: 3028, Learning rate: 0.00010579, Avg batch loss: 0.5812, Avg batch acc: 0.5052
Train, Epoch: 2, Batch: 1510, Step num: 3029, Learning rate: 0.00010583, Avg batch loss: 0.5453, Avg batch acc: 0.5476
Train, Epoch: 2, Batch: 1511, Step num: 3030, Learning rate: 0.00010586, Avg batch loss: 0.5672, Avg batch acc: 0.5247
Train, Epoch: 2, Batch: 1512, Step num: 3031, Learning rate: 0.00010590, Avg batch loss: 0.4816, Avg batch acc: 0.5561
Train, Epoch: 2, Batch: 1513, Step num: 3032, Learning rate: 0.00010593, Avg batch loss: 0.5125, Avg batch acc: 0.5386
Train, Epoch: 2, Batch: 1514, Step num: 3033, Learning rate: 0.00010597, Avg batch loss: 0.5501, Avg batch acc: 0.5457
Train, Epoch: 2, Batch: 1515, Step num: 3034, Learning rate: 0.00010600, Avg batch loss: 0.5089, Avg batch acc: 0.5573
Train, Epoch: 2, Batch: 1516, Step num: 3035, Learning rate: 0.00010604, Avg batch loss: 0.4849, Avg batch acc: 0.5640
Train, Epoch: 2, Batch: 1517, Step num: 3036, Learning rate: 0.00010607, Avg batch loss: 0.4566, Avg batch acc: 0.5723
Train, Epoch: 2, Batch: 1518, Step num: 3037, Learning rate: 0.00010611, Avg batch loss: 0.5026, Avg batch acc: 0.5576
Train, Epoch: 2, Batch: 1519, Step num: 3038, Learning rate: 0.00010614, Avg batch loss: 0.5781, Avg batch acc: 0.5078
Train, Epoch: 2, Avg epoch loss: 0.6293, Avg epoch acc: 0.4137, Overall time: 984.0 s, Speed: 4423.4 tokens/s on cuda:1

Validate, Epoch: 2, Batch: 1, Avg batch loss: 0.5000, Avg batch acc: 0.5645
Validate, Epoch: 2, Batch: 2, Avg batch loss: 0.4966, Avg batch acc: 0.5815
Validate, Epoch: 2, Batch: 3, Avg batch loss: 0.5447, Avg batch acc: 0.5603
Validate, Epoch: 2, Batch: 4, Avg batch loss: 0.5063, Avg batch acc: 0.5555
Validate, Epoch: 2, Batch: 5, Avg batch loss: 0.5235, Avg batch acc: 0.5475
Validate, Epoch: 2, Batch: 6, Avg batch loss: 0.4977, Avg batch acc: 0.5548
Validate, Epoch: 2, Batch: 7, Avg batch loss: 0.5250, Avg batch acc: 0.5312
Validate, Epoch: 2, Batch: 8, Avg batch loss: 0.5649, Avg batch acc: 0.5497
Validate, Epoch: 2, Batch: 9, Avg batch loss: 0.4785, Avg batch acc: 0.5734
Validate, Epoch: 2, Batch: 10, Avg batch loss: 0.4730, Avg batch acc: 0.5650
Validate, Epoch: 2, Batch: 11, Avg batch loss: 0.4680, Avg batch acc: 0.5640
Validate, Epoch: 2, Batch: 12, Avg batch loss: 0.5018, Avg batch acc: 0.5613
Validate, Epoch: 2, Batch: 13, Avg batch loss: 0.4861, Avg batch acc: 0.5732
Validate, Epoch: 2, Batch: 14, Avg batch loss: 0.4851, Avg batch acc: 0.5351
Validate, Epoch: 2, Batch: 15, Avg batch loss: 0.5024, Avg batch acc: 0.5741
Validate, Epoch: 2, Batch: 16, Avg batch loss: 0.5227, Avg batch acc: 0.5537
Validate, Epoch: 2, Batch: 17, Avg batch loss: 0.5036, Avg batch acc: 0.5254
Validate, Epoch: 2, Batch: 18, Avg batch loss: 0.4965, Avg batch acc: 0.5780
Validate, Epoch: 2, Batch: 19, Avg batch loss: 0.4456, Avg batch acc: 0.5531
Validate, Epoch: 2, Batch: 20, Avg batch loss: 0.4831, Avg batch acc: 0.5387
Validate, Epoch: 2, Batch: 21, Avg batch loss: 0.4632, Avg batch acc: 0.5760
Validate, Epoch: 2, Batch: 22, Avg batch loss: 0.5233, Avg batch acc: 0.5415
Validate, Epoch: 2, Batch: 23, Avg batch loss: 0.5275, Avg batch acc: 0.5343
Validate, Epoch: 2, Batch: 24, Avg batch loss: 0.5302, Avg batch acc: 0.5489
Validate, Epoch: 2, Batch: 25, Avg batch loss: 0.5045, Avg batch acc: 0.5590
Validate, Epoch: 2, Batch: 26, Avg batch loss: 0.5425, Avg batch acc: 0.5413
Validate, Epoch: 2, Batch: 27, Avg batch loss: 0.5044, Avg batch acc: 0.5583
Validate, Epoch: 2, Batch: 28, Avg batch loss: 0.4250, Avg batch acc: 0.5893
Validate, Epoch: 2, Batch: 29, Avg batch loss: 0.5112, Avg batch acc: 0.5614
Validate, Epoch: 2, Batch: 30, Avg batch loss: 0.5561, Avg batch acc: 0.5296
Validate, Epoch: 2, Batch: 31, Avg batch loss: 0.4924, Avg batch acc: 0.5549
Validate, Epoch: 2, Batch: 32, Avg batch loss: 0.5486, Avg batch acc: 0.5518
Validate, Epoch: 2, Batch: 33, Avg batch loss: 0.4841, Avg batch acc: 0.5597
Validate, Epoch: 2, Batch: 34, Avg batch loss: 0.5094, Avg batch acc: 0.5411
Validate, Epoch: 2, Batch: 35, Avg batch loss: 0.5184, Avg batch acc: 0.5504
Validate, Epoch: 2, Batch: 36, Avg batch loss: 0.5211, Avg batch acc: 0.5168
Validate, Epoch: 2, Batch: 37, Avg batch loss: 0.4475, Avg batch acc: 0.5406
Validate, Epoch: 2, Batch: 38, Avg batch loss: 0.4951, Avg batch acc: 0.5408
Validate, Epoch: 2, Batch: 39, Avg batch loss: 0.4923, Avg batch acc: 0.5537
Validate, Epoch: 2, Batch: 40, Avg batch loss: 0.4987, Avg batch acc: 0.5589
Validate, Epoch: 2, Batch: 41, Avg batch loss: 0.5179, Avg batch acc: 0.5637
Validate, Epoch: 2, Batch: 42, Avg batch loss: 0.5299, Avg batch acc: 0.5680
Validate, Epoch: 2, Batch: 43, Avg batch loss: 0.5023, Avg batch acc: 0.5564
Validate, Epoch: 2, Batch: 44, Avg batch loss: 0.5133, Avg batch acc: 0.5466
Validate, Epoch: 2, Batch: 45, Avg batch loss: 0.5451, Avg batch acc: 0.5341
Validate, Epoch: 2, Batch: 46, Avg batch loss: 0.4859, Avg batch acc: 0.5719
Validate, Epoch: 2, Batch: 47, Avg batch loss: 0.5267, Avg batch acc: 0.5585
Validate, Epoch: 2, Batch: 48, Avg batch loss: 0.5077, Avg batch acc: 0.5573
Validate, Epoch: 2, Batch: 49, Avg batch loss: 0.5368, Avg batch acc: 0.5383
Validate, Epoch: 2, Batch: 50, Avg batch loss: 0.5405, Avg batch acc: 0.5399
Validate, Epoch: 2, Batch: 51, Avg batch loss: 0.5365, Avg batch acc: 0.5434
Validate, Epoch: 2, Batch: 52, Avg batch loss: 0.4148, Avg batch acc: 0.5897
Validate, Epoch: 2, Batch: 53, Avg batch loss: 0.5313, Avg batch acc: 0.5474
Validate, Epoch: 2, Batch: 54, Avg batch loss: 0.5076, Avg batch acc: 0.5393
Validate, Epoch: 2, Batch: 55, Avg batch loss: 0.5296, Avg batch acc: 0.5346
Validate, Epoch: 2, Batch: 56, Avg batch loss: 0.5494, Avg batch acc: 0.5177
Validate, Epoch: 2, Batch: 57, Avg batch loss: 0.5348, Avg batch acc: 0.5377
Validate, Epoch: 2, Batch: 58, Avg batch loss: 0.5406, Avg batch acc: 0.5595
Validate, Epoch: 2, Batch: 59, Avg batch loss: 0.5592, Avg batch acc: 0.5396
Validate, Epoch: 2, Batch: 60, Avg batch loss: 0.5151, Avg batch acc: 0.5371
Validate, Epoch: 2, Batch: 61, Avg batch loss: 0.5012, Avg batch acc: 0.5460
Validate, Epoch: 2, Batch: 62, Avg batch loss: 0.5164, Avg batch acc: 0.5517
Validate, Epoch: 2, Batch: 63, Avg batch loss: 0.4643, Avg batch acc: 0.5547
Validate, Epoch: 2, Batch: 64, Avg batch loss: 0.4778, Avg batch acc: 0.5521
Validate, Epoch: 2, Batch: 65, Avg batch loss: 0.5149, Avg batch acc: 0.5467
Validate, Epoch: 2, Batch: 66, Avg batch loss: 0.5127, Avg batch acc: 0.5470
Validate, Epoch: 2, Batch: 67, Avg batch loss: 0.5023, Avg batch acc: 0.5726
Validate, Epoch: 2, Batch: 68, Avg batch loss: 0.5613, Avg batch acc: 0.5296
Validate, Epoch: 2, Batch: 69, Avg batch loss: 0.5497, Avg batch acc: 0.5278
Validate, Epoch: 2, Batch: 70, Avg batch loss: 0.5198, Avg batch acc: 0.5429
Validate, Epoch: 2, Batch: 71, Avg batch loss: 0.5216, Avg batch acc: 0.5342
Validate, Epoch: 2, Batch: 72, Avg batch loss: 0.5291, Avg batch acc: 0.5429
Validate, Epoch: 2, Batch: 73, Avg batch loss: 0.5130, Avg batch acc: 0.5512
Validate, Epoch: 2, Batch: 74, Avg batch loss: 0.5541, Avg batch acc: 0.5153
Validate, Epoch: 2, Batch: 75, Avg batch loss: 0.5560, Avg batch acc: 0.5498
Validate, Epoch: 2, Batch: 76, Avg batch loss: 0.4966, Avg batch acc: 0.5277
Validate, Epoch: 2, Batch: 77, Avg batch loss: 0.4821, Avg batch acc: 0.5440
Validate, Epoch: 2, Batch: 78, Avg batch loss: 0.4878, Avg batch acc: 0.5348
Validate, Epoch: 2, Batch: 79, Avg batch loss: 0.5285, Avg batch acc: 0.5412
Validate, Epoch: 2, Batch: 80, Avg batch loss: 0.5502, Avg batch acc: 0.5279
Validate, Epoch: 2, Batch: 81, Avg batch loss: 0.4548, Avg batch acc: 0.5624
Validate, Epoch: 2, Batch: 82, Avg batch loss: 0.4902, Avg batch acc: 0.5427
Validate, Epoch: 2, Batch: 83, Avg batch loss: 0.4641, Avg batch acc: 0.5587
Validate, Epoch: 2, Batch: 84, Avg batch loss: 0.5273, Avg batch acc: 0.5443
Validate, Epoch: 2, Batch: 85, Avg batch loss: 0.5489, Avg batch acc: 0.5666
Validate, Epoch: 2, Batch: 86, Avg batch loss: 0.4626, Avg batch acc: 0.5938
Validate, Epoch: 2, Batch: 87, Avg batch loss: 0.5543, Avg batch acc: 0.5187
Validate, Epoch: 2, Batch: 88, Avg batch loss: 0.4972, Avg batch acc: 0.5594
Validate, Epoch: 2, Batch: 89, Avg batch loss: 0.4785, Avg batch acc: 0.5774
Validate, Epoch: 2, Batch: 90, Avg batch loss: 0.4955, Avg batch acc: 0.5428
Validate, Epoch: 2, Batch: 91, Avg batch loss: 0.4829, Avg batch acc: 0.5668
Validate, Epoch: 2, Batch: 92, Avg batch loss: 0.5210, Avg batch acc: 0.5371
Validate, Epoch: 2, Batch: 93, Avg batch loss: 0.4920, Avg batch acc: 0.5475
Validate, Epoch: 2, Batch: 94, Avg batch loss: 0.5515, Avg batch acc: 0.5433
Validate, Epoch: 2, Batch: 95, Avg batch loss: 0.5214, Avg batch acc: 0.5350
Validate, Epoch: 2, Batch: 96, Avg batch loss: 0.4918, Avg batch acc: 0.5556
Validate, Epoch: 2, Batch: 97, Avg batch loss: 0.5161, Avg batch acc: 0.5173
Validate, Epoch: 2, Batch: 98, Avg batch loss: 0.5254, Avg batch acc: 0.5319
Validate, Epoch: 2, Batch: 99, Avg batch loss: 0.5509, Avg batch acc: 0.5395
Validate, Epoch: 2, Batch: 100, Avg batch loss: 0.5532, Avg batch acc: 0.5159
Validate, Epoch: 2, Batch: 101, Avg batch loss: 0.5227, Avg batch acc: 0.5459
Validate, Epoch: 2, Batch: 102, Avg batch loss: 0.4878, Avg batch acc: 0.5389
Validate, Epoch: 2, Batch: 103, Avg batch loss: 0.4985, Avg batch acc: 0.5340
Validate, Epoch: 2, Batch: 104, Avg batch loss: 0.5226, Avg batch acc: 0.5571
Validate, Epoch: 2, Batch: 105, Avg batch loss: 0.5002, Avg batch acc: 0.5604
Validate, Epoch: 2, Batch: 106, Avg batch loss: 0.5072, Avg batch acc: 0.5479
Validate, Epoch: 2, Batch: 107, Avg batch loss: 0.5040, Avg batch acc: 0.5375
Validate, Epoch: 2, Batch: 108, Avg batch loss: 0.4907, Avg batch acc: 0.5476
Validate, Epoch: 2, Batch: 109, Avg batch loss: 0.4826, Avg batch acc: 0.5484
Validate, Epoch: 2, Batch: 110, Avg batch loss: 0.4617, Avg batch acc: 0.5532
Validate, Epoch: 2, Batch: 111, Avg batch loss: 0.5190, Avg batch acc: 0.5327
Validate, Epoch: 2, Batch: 112, Avg batch loss: 0.4810, Avg batch acc: 0.5575
Validate, Epoch: 2, Batch: 113, Avg batch loss: 0.4936, Avg batch acc: 0.5510
Validate, Epoch: 2, Batch: 114, Avg batch loss: 0.4865, Avg batch acc: 0.5569
Validate, Epoch: 2, Batch: 115, Avg batch loss: 0.4971, Avg batch acc: 0.5556
Validate, Epoch: 2, Batch: 116, Avg batch loss: 0.4815, Avg batch acc: 0.5623
Validate, Epoch: 2, Batch: 117, Avg batch loss: 0.5102, Avg batch acc: 0.5470
Validate, Epoch: 2, Batch: 118, Avg batch loss: 0.5319, Avg batch acc: 0.5464
Validate, Epoch: 2, Batch: 119, Avg batch loss: 0.5116, Avg batch acc: 0.5318
Validate, Epoch: 2, Batch: 120, Avg batch loss: 0.4843, Avg batch acc: 0.5689
Validate, Epoch: 2, Batch: 121, Avg batch loss: 0.5031, Avg batch acc: 0.5711
Validate, Epoch: 2, Batch: 122, Avg batch loss: 0.4723, Avg batch acc: 0.5610
Validate, Epoch: 2, Batch: 123, Avg batch loss: 0.5161, Avg batch acc: 0.5424
Validate, Epoch: 2, Batch: 124, Avg batch loss: 0.5380, Avg batch acc: 0.5414
Validate, Epoch: 2, Batch: 125, Avg batch loss: 0.5630, Avg batch acc: 0.5229
Validate, Epoch: 2, Batch: 126, Avg batch loss: 0.4628, Avg batch acc: 0.5473
Validate, Epoch: 2, Batch: 127, Avg batch loss: 0.5381, Avg batch acc: 0.5359
Validate, Epoch: 2, Batch: 128, Avg batch loss: 0.5394, Avg batch acc: 0.5088
Validate, Epoch: 2, Batch: 129, Avg batch loss: 0.5096, Avg batch acc: 0.5478
Validate, Epoch: 2, Batch: 130, Avg batch loss: 0.5427, Avg batch acc: 0.5308
Validate, Epoch: 2, Batch: 131, Avg batch loss: 0.4632, Avg batch acc: 0.5499
Validate, Epoch: 2, Batch: 132, Avg batch loss: 0.5528, Avg batch acc: 0.5615
Validate, Epoch: 2, Batch: 133, Avg batch loss: 0.5120, Avg batch acc: 0.5665
Validate, Epoch: 2, Batch: 134, Avg batch loss: 0.5382, Avg batch acc: 0.5210
Validate, Epoch: 2, Batch: 135, Avg batch loss: 0.5249, Avg batch acc: 0.5479
Validate, Epoch: 2, Batch: 136, Avg batch loss: 0.5167, Avg batch acc: 0.5320
Validate, Epoch: 2, Batch: 137, Avg batch loss: 0.5399, Avg batch acc: 0.5519
Validate, Epoch: 2, Batch: 138, Avg batch loss: 0.4863, Avg batch acc: 0.5501
Validate, Epoch: 2, Batch: 139, Avg batch loss: 0.5393, Avg batch acc: 0.5448
Validate, Epoch: 2, Batch: 140, Avg batch loss: 0.4703, Avg batch acc: 0.5859
Validate, Epoch: 2, Batch: 141, Avg batch loss: 0.4906, Avg batch acc: 0.5541
Validate, Epoch: 2, Batch: 142, Avg batch loss: 0.5639, Avg batch acc: 0.5281
Validate, Epoch: 2, Batch: 143, Avg batch loss: 0.5464, Avg batch acc: 0.5245
Validate, Epoch: 2, Batch: 144, Avg batch loss: 0.5147, Avg batch acc: 0.5396
Validate, Epoch: 2, Batch: 145, Avg batch loss: 0.5464, Avg batch acc: 0.5432
Validate, Epoch: 2, Batch: 146, Avg batch loss: 0.5062, Avg batch acc: 0.5447
Validate, Epoch: 2, Batch: 147, Avg batch loss: 0.5481, Avg batch acc: 0.5513
Validate, Epoch: 2, Batch: 148, Avg batch loss: 0.5236, Avg batch acc: 0.5360
Validate, Epoch: 2, Batch: 149, Avg batch loss: 0.5005, Avg batch acc: 0.5399
Validate, Epoch: 2, Batch: 150, Avg batch loss: 0.5076, Avg batch acc: 0.5718
Validate, Epoch: 2, Batch: 151, Avg batch loss: 0.5279, Avg batch acc: 0.5672
Validate, Epoch: 2, Batch: 152, Avg batch loss: 0.5090, Avg batch acc: 0.5573
Validate, Epoch: 2, Batch: 153, Avg batch loss: 0.4616, Avg batch acc: 0.5440
Validate, Epoch: 2, Batch: 154, Avg batch loss: 0.4465, Avg batch acc: 0.5586
Validate, Epoch: 2, Batch: 155, Avg batch loss: 0.4815, Avg batch acc: 0.5559
Validate, Epoch: 2, Batch: 156, Avg batch loss: 0.5134, Avg batch acc: 0.5300
Validate, Epoch: 2, Batch: 157, Avg batch loss: 0.4977, Avg batch acc: 0.5449
Validate, Epoch: 2, Batch: 158, Avg batch loss: 0.4590, Avg batch acc: 0.5787
Validate, Epoch: 2, Batch: 159, Avg batch loss: 0.5025, Avg batch acc: 0.5457
Validate, Epoch: 2, Batch: 160, Avg batch loss: 0.4880, Avg batch acc: 0.5410
Validate, Epoch: 2, Batch: 161, Avg batch loss: 0.5061, Avg batch acc: 0.5297
Validate, Epoch: 2, Batch: 162, Avg batch loss: 0.5247, Avg batch acc: 0.5520
Validate, Epoch: 2, Batch: 163, Avg batch loss: 0.5223, Avg batch acc: 0.5443
Validate, Epoch: 2, Batch: 164, Avg batch loss: 0.4931, Avg batch acc: 0.5433
Validate, Epoch: 2, Batch: 165, Avg batch loss: 0.5044, Avg batch acc: 0.5304
Validate, Epoch: 2, Batch: 166, Avg batch loss: 0.5028, Avg batch acc: 0.5547
Validate, Epoch: 2, Batch: 167, Avg batch loss: 0.4930, Avg batch acc: 0.5544
Validate, Epoch: 2, Batch: 168, Avg batch loss: 0.4996, Avg batch acc: 0.5376
Validate, Epoch: 2, Batch: 169, Avg batch loss: 0.5643, Avg batch acc: 0.5427
Validate, Epoch: 2, Avg epoch loss: 0.5093, Avg epoch acc: 0.5484, Overall time: 36.4 s, Speed: 13233.9 tokens/s on cuda:1

Train, Epoch: 3, Batch: 1, Step num: 3039, Learning rate: 0.00010618, Avg batch loss: 0.5082, Avg batch acc: 0.5181
Train, Epoch: 3, Batch: 2, Step num: 3040, Learning rate: 0.00010621, Avg batch loss: 0.5305, Avg batch acc: 0.5502
Train, Epoch: 3, Batch: 3, Step num: 3041, Learning rate: 0.00010625, Avg batch loss: 0.5493, Avg batch acc: 0.5351
Train, Epoch: 3, Batch: 4, Step num: 3042, Learning rate: 0.00010628, Avg batch loss: 0.5290, Avg batch acc: 0.5542
Train, Epoch: 3, Batch: 5, Step num: 3043, Learning rate: 0.00010632, Avg batch loss: 0.5095, Avg batch acc: 0.5602
Train, Epoch: 3, Batch: 6, Step num: 3044, Learning rate: 0.00010635, Avg batch loss: 0.4403, Avg batch acc: 0.5507
Train, Epoch: 3, Batch: 7, Step num: 3045, Learning rate: 0.00010639, Avg batch loss: 0.5370, Avg batch acc: 0.5267
Train, Epoch: 3, Batch: 8, Step num: 3046, Learning rate: 0.00010642, Avg batch loss: 0.5602, Avg batch acc: 0.5250
Train, Epoch: 3, Batch: 9, Step num: 3047, Learning rate: 0.00010646, Avg batch loss: 0.5611, Avg batch acc: 0.5247
Train, Epoch: 3, Batch: 10, Step num: 3048, Learning rate: 0.00010649, Avg batch loss: 0.4946, Avg batch acc: 0.5788
Train, Epoch: 3, Batch: 11, Step num: 3049, Learning rate: 0.00010653, Avg batch loss: 0.4646, Avg batch acc: 0.5651
Train, Epoch: 3, Batch: 12, Step num: 3050, Learning rate: 0.00010656, Avg batch loss: 0.5061, Avg batch acc: 0.5407
Train, Epoch: 3, Batch: 13, Step num: 3051, Learning rate: 0.00010660, Avg batch loss: 0.5049, Avg batch acc: 0.5587
Train, Epoch: 3, Batch: 14, Step num: 3052, Learning rate: 0.00010663, Avg batch loss: 0.5648, Avg batch acc: 0.5570
Train, Epoch: 3, Batch: 15, Step num: 3053, Learning rate: 0.00010667, Avg batch loss: 0.5685, Avg batch acc: 0.5425
Train, Epoch: 3, Batch: 16, Step num: 3054, Learning rate: 0.00010670, Avg batch loss: 0.5094, Avg batch acc: 0.5443
Train, Epoch: 3, Batch: 17, Step num: 3055, Learning rate: 0.00010674, Avg batch loss: 0.4978, Avg batch acc: 0.5409
Train, Epoch: 3, Batch: 18, Step num: 3056, Learning rate: 0.00010677, Avg batch loss: 0.4817, Avg batch acc: 0.5445
Train, Epoch: 3, Batch: 19, Step num: 3057, Learning rate: 0.00010681, Avg batch loss: 0.5718, Avg batch acc: 0.5340
Train, Epoch: 3, Batch: 20, Step num: 3058, Learning rate: 0.00010684, Avg batch loss: 0.4579, Avg batch acc: 0.5791
Train, Epoch: 3, Batch: 21, Step num: 3059, Learning rate: 0.00010688, Avg batch loss: 0.5247, Avg batch acc: 0.5387
Train, Epoch: 3, Batch: 22, Step num: 3060, Learning rate: 0.00010691, Avg batch loss: 0.4930, Avg batch acc: 0.5543
Train, Epoch: 3, Batch: 23, Step num: 3061, Learning rate: 0.00010695, Avg batch loss: 0.5059, Avg batch acc: 0.5490
Train, Epoch: 3, Batch: 24, Step num: 3062, Learning rate: 0.00010698, Avg batch loss: 0.5627, Avg batch acc: 0.5446
Train, Epoch: 3, Batch: 25, Step num: 3063, Learning rate: 0.00010702, Avg batch loss: 0.5448, Avg batch acc: 0.5392
Train, Epoch: 3, Batch: 26, Step num: 3064, Learning rate: 0.00010705, Avg batch loss: 0.4825, Avg batch acc: 0.5709
Train, Epoch: 3, Batch: 27, Step num: 3065, Learning rate: 0.00010709, Avg batch loss: 0.5040, Avg batch acc: 0.5567
Train, Epoch: 3, Batch: 28, Step num: 3066, Learning rate: 0.00010712, Avg batch loss: 0.5062, Avg batch acc: 0.5515
Train, Epoch: 3, Batch: 29, Step num: 3067, Learning rate: 0.00010716, Avg batch loss: 0.5363, Avg batch acc: 0.5448
Train, Epoch: 3, Batch: 30, Step num: 3068, Learning rate: 0.00010719, Avg batch loss: 0.5614, Avg batch acc: 0.5401
Train, Epoch: 3, Batch: 31, Step num: 3069, Learning rate: 0.00010723, Avg batch loss: 0.5481, Avg batch acc: 0.5492
Train, Epoch: 3, Batch: 32, Step num: 3070, Learning rate: 0.00010726, Avg batch loss: 0.4509, Avg batch acc: 0.5795
Train, Epoch: 3, Batch: 33, Step num: 3071, Learning rate: 0.00010730, Avg batch loss: 0.5051, Avg batch acc: 0.5417
Train, Epoch: 3, Batch: 34, Step num: 3072, Learning rate: 0.00010733, Avg batch loss: 0.4839, Avg batch acc: 0.5649
Train, Epoch: 3, Batch: 35, Step num: 3073, Learning rate: 0.00010737, Avg batch loss: 0.5164, Avg batch acc: 0.5468
Train, Epoch: 3, Batch: 36, Step num: 3074, Learning rate: 0.00010740, Avg batch loss: 0.4516, Avg batch acc: 0.5612
Train, Epoch: 3, Batch: 37, Step num: 3075, Learning rate: 0.00010744, Avg batch loss: 0.5061, Avg batch acc: 0.5452
Train, Epoch: 3, Batch: 38, Step num: 3076, Learning rate: 0.00010747, Avg batch loss: 0.5724, Avg batch acc: 0.5415
Train, Epoch: 3, Batch: 39, Step num: 3077, Learning rate: 0.00010751, Avg batch loss: 0.4911, Avg batch acc: 0.5748
Train, Epoch: 3, Batch: 40, Step num: 3078, Learning rate: 0.00010754, Avg batch loss: 0.5032, Avg batch acc: 0.5509
Train, Epoch: 3, Batch: 41, Step num: 3079, Learning rate: 0.00010758, Avg batch loss: 0.5339, Avg batch acc: 0.5404
Train, Epoch: 3, Batch: 42, Step num: 3080, Learning rate: 0.00010761, Avg batch loss: 0.4267, Avg batch acc: 0.5864
Train, Epoch: 3, Batch: 43, Step num: 3081, Learning rate: 0.00010765, Avg batch loss: 0.5536, Avg batch acc: 0.5513
Train, Epoch: 3, Batch: 44, Step num: 3082, Learning rate: 0.00010768, Avg batch loss: 0.5158, Avg batch acc: 0.5378
Train, Epoch: 3, Batch: 45, Step num: 3083, Learning rate: 0.00010772, Avg batch loss: 0.4725, Avg batch acc: 0.5647
Train, Epoch: 3, Batch: 46, Step num: 3084, Learning rate: 0.00010775, Avg batch loss: 0.5110, Avg batch acc: 0.5584
Train, Epoch: 3, Batch: 47, Step num: 3085, Learning rate: 0.00010779, Avg batch loss: 0.5180, Avg batch acc: 0.5377
Train, Epoch: 3, Batch: 48, Step num: 3086, Learning rate: 0.00010782, Avg batch loss: 0.4597, Avg batch acc: 0.5523
Train, Epoch: 3, Batch: 49, Step num: 3087, Learning rate: 0.00010786, Avg batch loss: 0.4502, Avg batch acc: 0.5893
Train, Epoch: 3, Batch: 50, Step num: 3088, Learning rate: 0.00010789, Avg batch loss: 0.4780, Avg batch acc: 0.5627
Train, Epoch: 3, Batch: 51, Step num: 3089, Learning rate: 0.00010793, Avg batch loss: 0.5887, Avg batch acc: 0.5333
Train, Epoch: 3, Batch: 52, Step num: 3090, Learning rate: 0.00010796, Avg batch loss: 0.5043, Avg batch acc: 0.5731
Train, Epoch: 3, Batch: 53, Step num: 3091, Learning rate: 0.00010800, Avg batch loss: 0.5863, Avg batch acc: 0.5336
Train, Epoch: 3, Batch: 54, Step num: 3092, Learning rate: 0.00010803, Avg batch loss: 0.5082, Avg batch acc: 0.5590
Train, Epoch: 3, Batch: 55, Step num: 3093, Learning rate: 0.00010806, Avg batch loss: 0.4739, Avg batch acc: 0.5951
Train, Epoch: 3, Batch: 56, Step num: 3094, Learning rate: 0.00010810, Avg batch loss: 0.5366, Avg batch acc: 0.5266
Train, Epoch: 3, Batch: 57, Step num: 3095, Learning rate: 0.00010813, Avg batch loss: 0.4874, Avg batch acc: 0.5734
Train, Epoch: 3, Batch: 58, Step num: 3096, Learning rate: 0.00010817, Avg batch loss: 0.5051, Avg batch acc: 0.5411
Train, Epoch: 3, Batch: 59, Step num: 3097, Learning rate: 0.00010820, Avg batch loss: 0.5413, Avg batch acc: 0.5523
Train, Epoch: 3, Batch: 60, Step num: 3098, Learning rate: 0.00010824, Avg batch loss: 0.5123, Avg batch acc: 0.5758
Train, Epoch: 3, Batch: 61, Step num: 3099, Learning rate: 0.00010827, Avg batch loss: 0.5000, Avg batch acc: 0.5558
Train, Epoch: 3, Batch: 62, Step num: 3100, Learning rate: 0.00010831, Avg batch loss: 0.5307, Avg batch acc: 0.5435
Train, Epoch: 3, Batch: 63, Step num: 3101, Learning rate: 0.00010834, Avg batch loss: 0.5080, Avg batch acc: 0.5611
Train, Epoch: 3, Batch: 64, Step num: 3102, Learning rate: 0.00010838, Avg batch loss: 0.4824, Avg batch acc: 0.5626
Train, Epoch: 3, Batch: 65, Step num: 3103, Learning rate: 0.00010841, Avg batch loss: 0.5193, Avg batch acc: 0.5454
Train, Epoch: 3, Batch: 66, Step num: 3104, Learning rate: 0.00010845, Avg batch loss: 0.5307, Avg batch acc: 0.5522
Train, Epoch: 3, Batch: 67, Step num: 3105, Learning rate: 0.00010848, Avg batch loss: 0.4945, Avg batch acc: 0.5719
Train, Epoch: 3, Batch: 68, Step num: 3106, Learning rate: 0.00010852, Avg batch loss: 0.4786, Avg batch acc: 0.5718
Train, Epoch: 3, Batch: 69, Step num: 3107, Learning rate: 0.00010855, Avg batch loss: 0.4665, Avg batch acc: 0.5664
Train, Epoch: 3, Batch: 70, Step num: 3108, Learning rate: 0.00010859, Avg batch loss: 0.4933, Avg batch acc: 0.5524
Train, Epoch: 3, Batch: 71, Step num: 3109, Learning rate: 0.00010862, Avg batch loss: 0.4747, Avg batch acc: 0.5703
Train, Epoch: 3, Batch: 72, Step num: 3110, Learning rate: 0.00010866, Avg batch loss: 0.4793, Avg batch acc: 0.5751
Train, Epoch: 3, Batch: 73, Step num: 3111, Learning rate: 0.00010869, Avg batch loss: 0.4837, Avg batch acc: 0.5767
Train, Epoch: 3, Batch: 74, Step num: 3112, Learning rate: 0.00010873, Avg batch loss: 0.5082, Avg batch acc: 0.5439
Train, Epoch: 3, Batch: 75, Step num: 3113, Learning rate: 0.00010876, Avg batch loss: 0.4655, Avg batch acc: 0.5622
Train, Epoch: 3, Batch: 76, Step num: 3114, Learning rate: 0.00010880, Avg batch loss: 0.4609, Avg batch acc: 0.5889
Train, Epoch: 3, Batch: 77, Step num: 3115, Learning rate: 0.00010883, Avg batch loss: 0.4899, Avg batch acc: 0.5516
Train, Epoch: 3, Batch: 78, Step num: 3116, Learning rate: 0.00010887, Avg batch loss: 0.5323, Avg batch acc: 0.5524
Train, Epoch: 3, Batch: 79, Step num: 3117, Learning rate: 0.00010890, Avg batch loss: 0.5085, Avg batch acc: 0.5380
Train, Epoch: 3, Batch: 80, Step num: 3118, Learning rate: 0.00010894, Avg batch loss: 0.4364, Avg batch acc: 0.5819
Train, Epoch: 3, Batch: 81, Step num: 3119, Learning rate: 0.00010897, Avg batch loss: 0.4716, Avg batch acc: 0.5539
Train, Epoch: 3, Batch: 82, Step num: 3120, Learning rate: 0.00010901, Avg batch loss: 0.4774, Avg batch acc: 0.5994
Train, Epoch: 3, Batch: 83, Step num: 3121, Learning rate: 0.00010904, Avg batch loss: 0.5233, Avg batch acc: 0.5558
Train, Epoch: 3, Batch: 84, Step num: 3122, Learning rate: 0.00010908, Avg batch loss: 0.5277, Avg batch acc: 0.5391
Train, Epoch: 3, Batch: 85, Step num: 3123, Learning rate: 0.00010911, Avg batch loss: 0.4948, Avg batch acc: 0.5608
Train, Epoch: 3, Batch: 86, Step num: 3124, Learning rate: 0.00010915, Avg batch loss: 0.3965, Avg batch acc: 0.5816
Train, Epoch: 3, Batch: 87, Step num: 3125, Learning rate: 0.00010918, Avg batch loss: 0.5183, Avg batch acc: 0.5489
Train, Epoch: 3, Batch: 88, Step num: 3126, Learning rate: 0.00010922, Avg batch loss: 0.5627, Avg batch acc: 0.5360
Train, Epoch: 3, Batch: 89, Step num: 3127, Learning rate: 0.00010925, Avg batch loss: 0.4805, Avg batch acc: 0.5870
Train, Epoch: 3, Batch: 90, Step num: 3128, Learning rate: 0.00010929, Avg batch loss: 0.4583, Avg batch acc: 0.5880
Train, Epoch: 3, Batch: 91, Step num: 3129, Learning rate: 0.00010932, Avg batch loss: 0.5153, Avg batch acc: 0.5635
Train, Epoch: 3, Batch: 92, Step num: 3130, Learning rate: 0.00010936, Avg batch loss: 0.5149, Avg batch acc: 0.5529
Train, Epoch: 3, Batch: 93, Step num: 3131, Learning rate: 0.00010939, Avg batch loss: 0.4838, Avg batch acc: 0.5906
Train, Epoch: 3, Batch: 94, Step num: 3132, Learning rate: 0.00010943, Avg batch loss: 0.4637, Avg batch acc: 0.5966
Train, Epoch: 3, Batch: 95, Step num: 3133, Learning rate: 0.00010946, Avg batch loss: 0.4879, Avg batch acc: 0.5694
Train, Epoch: 3, Batch: 96, Step num: 3134, Learning rate: 0.00010950, Avg batch loss: 0.5269, Avg batch acc: 0.5622
Train, Epoch: 3, Batch: 97, Step num: 3135, Learning rate: 0.00010953, Avg batch loss: 0.4620, Avg batch acc: 0.5726
Train, Epoch: 3, Batch: 98, Step num: 3136, Learning rate: 0.00010957, Avg batch loss: 0.4594, Avg batch acc: 0.5862
Train, Epoch: 3, Batch: 99, Step num: 3137, Learning rate: 0.00010960, Avg batch loss: 0.4454, Avg batch acc: 0.5691
Train, Epoch: 3, Batch: 100, Step num: 3138, Learning rate: 0.00010964, Avg batch loss: 0.4971, Avg batch acc: 0.5662
Train, Epoch: 3, Batch: 101, Step num: 3139, Learning rate: 0.00010967, Avg batch loss: 0.4891, Avg batch acc: 0.5553
Train, Epoch: 3, Batch: 102, Step num: 3140, Learning rate: 0.00010971, Avg batch loss: 0.5325, Avg batch acc: 0.5539
Train, Epoch: 3, Batch: 103, Step num: 3141, Learning rate: 0.00010974, Avg batch loss: 0.5034, Avg batch acc: 0.5351
Train, Epoch: 3, Batch: 104, Step num: 3142, Learning rate: 0.00010978, Avg batch loss: 0.4958, Avg batch acc: 0.5599
Train, Epoch: 3, Batch: 105, Step num: 3143, Learning rate: 0.00010981, Avg batch loss: 0.5100, Avg batch acc: 0.5466
Train, Epoch: 3, Batch: 106, Step num: 3144, Learning rate: 0.00010985, Avg batch loss: 0.4812, Avg batch acc: 0.5656
Train, Epoch: 3, Batch: 107, Step num: 3145, Learning rate: 0.00010988, Avg batch loss: 0.4733, Avg batch acc: 0.5622
Train, Epoch: 3, Batch: 108, Step num: 3146, Learning rate: 0.00010992, Avg batch loss: 0.4648, Avg batch acc: 0.5696
Train, Epoch: 3, Batch: 109, Step num: 3147, Learning rate: 0.00010995, Avg batch loss: 0.4997, Avg batch acc: 0.5751
Train, Epoch: 3, Batch: 110, Step num: 3148, Learning rate: 0.00010999, Avg batch loss: 0.5177, Avg batch acc: 0.5562
Train, Epoch: 3, Batch: 111, Step num: 3149, Learning rate: 0.00011002, Avg batch loss: 0.5073, Avg batch acc: 0.5585
Train, Epoch: 3, Batch: 112, Step num: 3150, Learning rate: 0.00011006, Avg batch loss: 0.4996, Avg batch acc: 0.5797
Train, Epoch: 3, Batch: 113, Step num: 3151, Learning rate: 0.00011009, Avg batch loss: 0.5080, Avg batch acc: 0.5882
Train, Epoch: 3, Batch: 114, Step num: 3152, Learning rate: 0.00011013, Avg batch loss: 0.4849, Avg batch acc: 0.5557
Train, Epoch: 3, Batch: 115, Step num: 3153, Learning rate: 0.00011016, Avg batch loss: 0.4796, Avg batch acc: 0.5674
Train, Epoch: 3, Batch: 116, Step num: 3154, Learning rate: 0.00011020, Avg batch loss: 0.4402, Avg batch acc: 0.5833
Train, Epoch: 3, Batch: 117, Step num: 3155, Learning rate: 0.00011023, Avg batch loss: 0.4026, Avg batch acc: 0.5957
Train, Epoch: 3, Batch: 118, Step num: 3156, Learning rate: 0.00011027, Avg batch loss: 0.4710, Avg batch acc: 0.5649
Train, Epoch: 3, Batch: 119, Step num: 3157, Learning rate: 0.00011030, Avg batch loss: 0.5119, Avg batch acc: 0.5562
Train, Epoch: 3, Batch: 120, Step num: 3158, Learning rate: 0.00011034, Avg batch loss: 0.5076, Avg batch acc: 0.5627
Train, Epoch: 3, Batch: 121, Step num: 3159, Learning rate: 0.00011037, Avg batch loss: 0.4232, Avg batch acc: 0.5889
Train, Epoch: 3, Batch: 122, Step num: 3160, Learning rate: 0.00011041, Avg batch loss: 0.5284, Avg batch acc: 0.5645
Train, Epoch: 3, Batch: 123, Step num: 3161, Learning rate: 0.00011044, Avg batch loss: 0.5142, Avg batch acc: 0.5496
Train, Epoch: 3, Batch: 124, Step num: 3162, Learning rate: 0.00011048, Avg batch loss: 0.5266, Avg batch acc: 0.5534
Train, Epoch: 3, Batch: 125, Step num: 3163, Learning rate: 0.00011051, Avg batch loss: 0.4450, Avg batch acc: 0.5799
Train, Epoch: 3, Batch: 126, Step num: 3164, Learning rate: 0.00011055, Avg batch loss: 0.5166, Avg batch acc: 0.5679
Train, Epoch: 3, Batch: 127, Step num: 3165, Learning rate: 0.00011058, Avg batch loss: 0.4731, Avg batch acc: 0.5774
Train, Epoch: 3, Batch: 128, Step num: 3166, Learning rate: 0.00011062, Avg batch loss: 0.4498, Avg batch acc: 0.5667
Train, Epoch: 3, Batch: 129, Step num: 3167, Learning rate: 0.00011065, Avg batch loss: 0.4517, Avg batch acc: 0.5745
Train, Epoch: 3, Batch: 130, Step num: 3168, Learning rate: 0.00011069, Avg batch loss: 0.5133, Avg batch acc: 0.5600
Train, Epoch: 3, Batch: 131, Step num: 3169, Learning rate: 0.00011072, Avg batch loss: 0.4903, Avg batch acc: 0.5823
Train, Epoch: 3, Batch: 132, Step num: 3170, Learning rate: 0.00011076, Avg batch loss: 0.4930, Avg batch acc: 0.5519
Train, Epoch: 3, Batch: 133, Step num: 3171, Learning rate: 0.00011079, Avg batch loss: 0.5385, Avg batch acc: 0.5474
Train, Epoch: 3, Batch: 134, Step num: 3172, Learning rate: 0.00011083, Avg batch loss: 0.4382, Avg batch acc: 0.5711
Train, Epoch: 3, Batch: 135, Step num: 3173, Learning rate: 0.00011086, Avg batch loss: 0.4923, Avg batch acc: 0.5716
Train, Epoch: 3, Batch: 136, Step num: 3174, Learning rate: 0.00011089, Avg batch loss: 0.4655, Avg batch acc: 0.5369
Train, Epoch: 3, Batch: 137, Step num: 3175, Learning rate: 0.00011093, Avg batch loss: 0.5067, Avg batch acc: 0.5656
Train, Epoch: 3, Batch: 138, Step num: 3176, Learning rate: 0.00011096, Avg batch loss: 0.4676, Avg batch acc: 0.5816
Train, Epoch: 3, Batch: 139, Step num: 3177, Learning rate: 0.00011100, Avg batch loss: 0.4855, Avg batch acc: 0.5736
Train, Epoch: 3, Batch: 140, Step num: 3178, Learning rate: 0.00011103, Avg batch loss: 0.4540, Avg batch acc: 0.5798
Train, Epoch: 3, Batch: 141, Step num: 3179, Learning rate: 0.00011107, Avg batch loss: 0.4949, Avg batch acc: 0.5792
Train, Epoch: 3, Batch: 142, Step num: 3180, Learning rate: 0.00011110, Avg batch loss: 0.4550, Avg batch acc: 0.5747
Train, Epoch: 3, Batch: 143, Step num: 3181, Learning rate: 0.00011114, Avg batch loss: 0.5317, Avg batch acc: 0.5644
Train, Epoch: 3, Batch: 144, Step num: 3182, Learning rate: 0.00011117, Avg batch loss: 0.4611, Avg batch acc: 0.5957
Train, Epoch: 3, Batch: 145, Step num: 3183, Learning rate: 0.00011121, Avg batch loss: 0.4890, Avg batch acc: 0.5768
Train, Epoch: 3, Batch: 146, Step num: 3184, Learning rate: 0.00011124, Avg batch loss: 0.4334, Avg batch acc: 0.5828
Train, Epoch: 3, Batch: 147, Step num: 3185, Learning rate: 0.00011128, Avg batch loss: 0.4755, Avg batch acc: 0.5677
Train, Epoch: 3, Batch: 148, Step num: 3186, Learning rate: 0.00011131, Avg batch loss: 0.5085, Avg batch acc: 0.5823
Train, Epoch: 3, Batch: 149, Step num: 3187, Learning rate: 0.00011135, Avg batch loss: 0.4625, Avg batch acc: 0.5784
Train, Epoch: 3, Batch: 150, Step num: 3188, Learning rate: 0.00011138, Avg batch loss: 0.5263, Avg batch acc: 0.5551
Train, Epoch: 3, Batch: 151, Step num: 3189, Learning rate: 0.00011142, Avg batch loss: 0.4772, Avg batch acc: 0.5777
Train, Epoch: 3, Batch: 152, Step num: 3190, Learning rate: 0.00011145, Avg batch loss: 0.5093, Avg batch acc: 0.5554
Train, Epoch: 3, Batch: 153, Step num: 3191, Learning rate: 0.00011149, Avg batch loss: 0.4932, Avg batch acc: 0.5625
Train, Epoch: 3, Batch: 154, Step num: 3192, Learning rate: 0.00011152, Avg batch loss: 0.4565, Avg batch acc: 0.5940
Train, Epoch: 3, Batch: 155, Step num: 3193, Learning rate: 0.00011156, Avg batch loss: 0.4893, Avg batch acc: 0.5742
Train, Epoch: 3, Batch: 156, Step num: 3194, Learning rate: 0.00011159, Avg batch loss: 0.4539, Avg batch acc: 0.5689
Train, Epoch: 3, Batch: 157, Step num: 3195, Learning rate: 0.00011163, Avg batch loss: 0.4896, Avg batch acc: 0.5665
Train, Epoch: 3, Batch: 158, Step num: 3196, Learning rate: 0.00011166, Avg batch loss: 0.4712, Avg batch acc: 0.5927
Train, Epoch: 3, Batch: 159, Step num: 3197, Learning rate: 0.00011170, Avg batch loss: 0.4749, Avg batch acc: 0.5726
Train, Epoch: 3, Batch: 160, Step num: 3198, Learning rate: 0.00011173, Avg batch loss: 0.4769, Avg batch acc: 0.5647
Train, Epoch: 3, Batch: 161, Step num: 3199, Learning rate: 0.00011177, Avg batch loss: 0.4757, Avg batch acc: 0.5752
Train, Epoch: 3, Batch: 162, Step num: 3200, Learning rate: 0.00011180, Avg batch loss: 0.5211, Avg batch acc: 0.5654
Train, Epoch: 3, Batch: 163, Step num: 3201, Learning rate: 0.00011184, Avg batch loss: 0.5310, Avg batch acc: 0.5638
Train, Epoch: 3, Batch: 164, Step num: 3202, Learning rate: 0.00011187, Avg batch loss: 0.4682, Avg batch acc: 0.5709
Train, Epoch: 3, Batch: 165, Step num: 3203, Learning rate: 0.00011191, Avg batch loss: 0.4859, Avg batch acc: 0.5865
Train, Epoch: 3, Batch: 166, Step num: 3204, Learning rate: 0.00011194, Avg batch loss: 0.4798, Avg batch acc: 0.5909
Train, Epoch: 3, Batch: 167, Step num: 3205, Learning rate: 0.00011198, Avg batch loss: 0.4526, Avg batch acc: 0.5995
Train, Epoch: 3, Batch: 168, Step num: 3206, Learning rate: 0.00011201, Avg batch loss: 0.4710, Avg batch acc: 0.5720
Train, Epoch: 3, Batch: 169, Step num: 3207, Learning rate: 0.00011205, Avg batch loss: 0.4591, Avg batch acc: 0.5739
Train, Epoch: 3, Batch: 170, Step num: 3208, Learning rate: 0.00011208, Avg batch loss: 0.4572, Avg batch acc: 0.5978
Train, Epoch: 3, Batch: 171, Step num: 3209, Learning rate: 0.00011212, Avg batch loss: 0.5440, Avg batch acc: 0.5183
Train, Epoch: 3, Batch: 172, Step num: 3210, Learning rate: 0.00011215, Avg batch loss: 0.4601, Avg batch acc: 0.5726
Train, Epoch: 3, Batch: 173, Step num: 3211, Learning rate: 0.00011219, Avg batch loss: 0.4347, Avg batch acc: 0.5799
Train, Epoch: 3, Batch: 174, Step num: 3212, Learning rate: 0.00011222, Avg batch loss: 0.4479, Avg batch acc: 0.5859
Train, Epoch: 3, Batch: 175, Step num: 3213, Learning rate: 0.00011226, Avg batch loss: 0.4508, Avg batch acc: 0.5790
Train, Epoch: 3, Batch: 176, Step num: 3214, Learning rate: 0.00011229, Avg batch loss: 0.5339, Avg batch acc: 0.5612
Train, Epoch: 3, Batch: 177, Step num: 3215, Learning rate: 0.00011233, Avg batch loss: 0.4965, Avg batch acc: 0.5641
Train, Epoch: 3, Batch: 178, Step num: 3216, Learning rate: 0.00011236, Avg batch loss: 0.5146, Avg batch acc: 0.5777
Train, Epoch: 3, Batch: 179, Step num: 3217, Learning rate: 0.00011240, Avg batch loss: 0.4429, Avg batch acc: 0.5954
Train, Epoch: 3, Batch: 180, Step num: 3218, Learning rate: 0.00011243, Avg batch loss: 0.4590, Avg batch acc: 0.5850
Train, Epoch: 3, Batch: 181, Step num: 3219, Learning rate: 0.00011247, Avg batch loss: 0.4579, Avg batch acc: 0.5988
Train, Epoch: 3, Batch: 182, Step num: 3220, Learning rate: 0.00011250, Avg batch loss: 0.4330, Avg batch acc: 0.6210
Train, Epoch: 3, Batch: 183, Step num: 3221, Learning rate: 0.00011254, Avg batch loss: 0.4615, Avg batch acc: 0.5659
Train, Epoch: 3, Batch: 184, Step num: 3222, Learning rate: 0.00011257, Avg batch loss: 0.4727, Avg batch acc: 0.5702
Train, Epoch: 3, Batch: 185, Step num: 3223, Learning rate: 0.00011261, Avg batch loss: 0.4105, Avg batch acc: 0.5945
Train, Epoch: 3, Batch: 186, Step num: 3224, Learning rate: 0.00011264, Avg batch loss: 0.4674, Avg batch acc: 0.5928
Train, Epoch: 3, Batch: 187, Step num: 3225, Learning rate: 0.00011268, Avg batch loss: 0.4549, Avg batch acc: 0.5847
Train, Epoch: 3, Batch: 188, Step num: 3226, Learning rate: 0.00011271, Avg batch loss: 0.5005, Avg batch acc: 0.5715
Train, Epoch: 3, Batch: 189, Step num: 3227, Learning rate: 0.00011275, Avg batch loss: 0.4471, Avg batch acc: 0.5796
Train, Epoch: 3, Batch: 190, Step num: 3228, Learning rate: 0.00011278, Avg batch loss: 0.4733, Avg batch acc: 0.5994
Train, Epoch: 3, Batch: 191, Step num: 3229, Learning rate: 0.00011282, Avg batch loss: 0.5154, Avg batch acc: 0.5624
Train, Epoch: 3, Batch: 192, Step num: 3230, Learning rate: 0.00011285, Avg batch loss: 0.4478, Avg batch acc: 0.6044
Train, Epoch: 3, Batch: 193, Step num: 3231, Learning rate: 0.00011289, Avg batch loss: 0.4623, Avg batch acc: 0.5954
Train, Epoch: 3, Batch: 194, Step num: 3232, Learning rate: 0.00011292, Avg batch loss: 0.5173, Avg batch acc: 0.5668
Train, Epoch: 3, Batch: 195, Step num: 3233, Learning rate: 0.00011296, Avg batch loss: 0.4759, Avg batch acc: 0.5959
Train, Epoch: 3, Batch: 196, Step num: 3234, Learning rate: 0.00011299, Avg batch loss: 0.4420, Avg batch acc: 0.5818
Train, Epoch: 3, Batch: 197, Step num: 3235, Learning rate: 0.00011303, Avg batch loss: 0.4836, Avg batch acc: 0.5826
Train, Epoch: 3, Batch: 198, Step num: 3236, Learning rate: 0.00011306, Avg batch loss: 0.4610, Avg batch acc: 0.5894
Train, Epoch: 3, Batch: 199, Step num: 3237, Learning rate: 0.00011310, Avg batch loss: 0.4547, Avg batch acc: 0.5888
Train, Epoch: 3, Batch: 200, Step num: 3238, Learning rate: 0.00011313, Avg batch loss: 0.4421, Avg batch acc: 0.5937
Train, Epoch: 3, Batch: 201, Step num: 3239, Learning rate: 0.00011317, Avg batch loss: 0.4608, Avg batch acc: 0.5896
Train, Epoch: 3, Batch: 202, Step num: 3240, Learning rate: 0.00011320, Avg batch loss: 0.4412, Avg batch acc: 0.5911
Train, Epoch: 3, Batch: 203, Step num: 3241, Learning rate: 0.00011324, Avg batch loss: 0.4586, Avg batch acc: 0.5917
Train, Epoch: 3, Batch: 204, Step num: 3242, Learning rate: 0.00011327, Avg batch loss: 0.4743, Avg batch acc: 0.5714
Train, Epoch: 3, Batch: 205, Step num: 3243, Learning rate: 0.00011331, Avg batch loss: 0.4646, Avg batch acc: 0.5734
Train, Epoch: 3, Batch: 206, Step num: 3244, Learning rate: 0.00011334, Avg batch loss: 0.4457, Avg batch acc: 0.6037
Train, Epoch: 3, Batch: 207, Step num: 3245, Learning rate: 0.00011338, Avg batch loss: 0.4906, Avg batch acc: 0.5934
Train, Epoch: 3, Batch: 208, Step num: 3246, Learning rate: 0.00011341, Avg batch loss: 0.4734, Avg batch acc: 0.5635
Train, Epoch: 3, Batch: 209, Step num: 3247, Learning rate: 0.00011345, Avg batch loss: 0.4636, Avg batch acc: 0.5903
Train, Epoch: 3, Batch: 210, Step num: 3248, Learning rate: 0.00011348, Avg batch loss: 0.4849, Avg batch acc: 0.5665
Train, Epoch: 3, Batch: 211, Step num: 3249, Learning rate: 0.00011352, Avg batch loss: 0.4345, Avg batch acc: 0.5851
Train, Epoch: 3, Batch: 212, Step num: 3250, Learning rate: 0.00011355, Avg batch loss: 0.5045, Avg batch acc: 0.5873
Train, Epoch: 3, Batch: 213, Step num: 3251, Learning rate: 0.00011359, Avg batch loss: 0.5106, Avg batch acc: 0.5684
Train, Epoch: 3, Batch: 214, Step num: 3252, Learning rate: 0.00011362, Avg batch loss: 0.5266, Avg batch acc: 0.5565
Train, Epoch: 3, Batch: 215, Step num: 3253, Learning rate: 0.00011366, Avg batch loss: 0.4846, Avg batch acc: 0.5771
Train, Epoch: 3, Batch: 216, Step num: 3254, Learning rate: 0.00011369, Avg batch loss: 0.4670, Avg batch acc: 0.5774
Train, Epoch: 3, Batch: 217, Step num: 3255, Learning rate: 0.00011373, Avg batch loss: 0.4897, Avg batch acc: 0.5690
Train, Epoch: 3, Batch: 218, Step num: 3256, Learning rate: 0.00011376, Avg batch loss: 0.4542, Avg batch acc: 0.5905
Train, Epoch: 3, Batch: 219, Step num: 3257, Learning rate: 0.00011379, Avg batch loss: 0.4522, Avg batch acc: 0.5771
Train, Epoch: 3, Batch: 220, Step num: 3258, Learning rate: 0.00011383, Avg batch loss: 0.4780, Avg batch acc: 0.5701
Train, Epoch: 3, Batch: 221, Step num: 3259, Learning rate: 0.00011386, Avg batch loss: 0.4709, Avg batch acc: 0.5865
Train, Epoch: 3, Batch: 222, Step num: 3260, Learning rate: 0.00011390, Avg batch loss: 0.4495, Avg batch acc: 0.5985
Train, Epoch: 3, Batch: 223, Step num: 3261, Learning rate: 0.00011393, Avg batch loss: 0.4556, Avg batch acc: 0.5932
Train, Epoch: 3, Batch: 224, Step num: 3262, Learning rate: 0.00011397, Avg batch loss: 0.4774, Avg batch acc: 0.5783
Train, Epoch: 3, Batch: 225, Step num: 3263, Learning rate: 0.00011400, Avg batch loss: 0.5045, Avg batch acc: 0.5840
Train, Epoch: 3, Batch: 226, Step num: 3264, Learning rate: 0.00011404, Avg batch loss: 0.4068, Avg batch acc: 0.6083
Train, Epoch: 3, Batch: 227, Step num: 3265, Learning rate: 0.00011407, Avg batch loss: 0.4851, Avg batch acc: 0.5614
Train, Epoch: 3, Batch: 228, Step num: 3266, Learning rate: 0.00011411, Avg batch loss: 0.4235, Avg batch acc: 0.6167
Train, Epoch: 3, Batch: 229, Step num: 3267, Learning rate: 0.00011414, Avg batch loss: 0.4688, Avg batch acc: 0.5801
Train, Epoch: 3, Batch: 230, Step num: 3268, Learning rate: 0.00011418, Avg batch loss: 0.4688, Avg batch acc: 0.5936
Train, Epoch: 3, Batch: 231, Step num: 3269, Learning rate: 0.00011421, Avg batch loss: 0.4877, Avg batch acc: 0.5903
Train, Epoch: 3, Batch: 232, Step num: 3270, Learning rate: 0.00011425, Avg batch loss: 0.4905, Avg batch acc: 0.5635
Train, Epoch: 3, Batch: 233, Step num: 3271, Learning rate: 0.00011428, Avg batch loss: 0.4921, Avg batch acc: 0.5821
Train, Epoch: 3, Batch: 234, Step num: 3272, Learning rate: 0.00011432, Avg batch loss: 0.5014, Avg batch acc: 0.5727
Train, Epoch: 3, Batch: 235, Step num: 3273, Learning rate: 0.00011435, Avg batch loss: 0.4475, Avg batch acc: 0.5839
Train, Epoch: 3, Batch: 236, Step num: 3274, Learning rate: 0.00011439, Avg batch loss: 0.4590, Avg batch acc: 0.5665
Train, Epoch: 3, Batch: 237, Step num: 3275, Learning rate: 0.00011442, Avg batch loss: 0.4587, Avg batch acc: 0.5906
Train, Epoch: 3, Batch: 238, Step num: 3276, Learning rate: 0.00011446, Avg batch loss: 0.4671, Avg batch acc: 0.5884
Train, Epoch: 3, Batch: 239, Step num: 3277, Learning rate: 0.00011449, Avg batch loss: 0.4620, Avg batch acc: 0.5916
Train, Epoch: 3, Batch: 240, Step num: 3278, Learning rate: 0.00011453, Avg batch loss: 0.4093, Avg batch acc: 0.6191
Train, Epoch: 3, Batch: 241, Step num: 3279, Learning rate: 0.00011456, Avg batch loss: 0.4665, Avg batch acc: 0.5764
Train, Epoch: 3, Batch: 242, Step num: 3280, Learning rate: 0.00011460, Avg batch loss: 0.4203, Avg batch acc: 0.5810
Train, Epoch: 3, Batch: 243, Step num: 3281, Learning rate: 0.00011463, Avg batch loss: 0.4511, Avg batch acc: 0.5862
Train, Epoch: 3, Batch: 244, Step num: 3282, Learning rate: 0.00011467, Avg batch loss: 0.4367, Avg batch acc: 0.5745
Train, Epoch: 3, Batch: 245, Step num: 3283, Learning rate: 0.00011470, Avg batch loss: 0.4140, Avg batch acc: 0.5976
Train, Epoch: 3, Batch: 246, Step num: 3284, Learning rate: 0.00011474, Avg batch loss: 0.5023, Avg batch acc: 0.5879
Train, Epoch: 3, Batch: 247, Step num: 3285, Learning rate: 0.00011477, Avg batch loss: 0.4638, Avg batch acc: 0.5822
Train, Epoch: 3, Batch: 248, Step num: 3286, Learning rate: 0.00011481, Avg batch loss: 0.4256, Avg batch acc: 0.5942
Train, Epoch: 3, Batch: 249, Step num: 3287, Learning rate: 0.00011484, Avg batch loss: 0.4737, Avg batch acc: 0.5741
Train, Epoch: 3, Batch: 250, Step num: 3288, Learning rate: 0.00011488, Avg batch loss: 0.5132, Avg batch acc: 0.5847
Train, Epoch: 3, Batch: 251, Step num: 3289, Learning rate: 0.00011491, Avg batch loss: 0.4394, Avg batch acc: 0.6016
Train, Epoch: 3, Batch: 252, Step num: 3290, Learning rate: 0.00011495, Avg batch loss: 0.4286, Avg batch acc: 0.5983
Train, Epoch: 3, Batch: 253, Step num: 3291, Learning rate: 0.00011498, Avg batch loss: 0.4368, Avg batch acc: 0.6005
Train, Epoch: 3, Batch: 254, Step num: 3292, Learning rate: 0.00011502, Avg batch loss: 0.5068, Avg batch acc: 0.5817
Train, Epoch: 3, Batch: 255, Step num: 3293, Learning rate: 0.00011505, Avg batch loss: 0.5102, Avg batch acc: 0.5724
Train, Epoch: 3, Batch: 256, Step num: 3294, Learning rate: 0.00011509, Avg batch loss: 0.4517, Avg batch acc: 0.5878
Train, Epoch: 3, Batch: 257, Step num: 3295, Learning rate: 0.00011512, Avg batch loss: 0.4658, Avg batch acc: 0.5752
Train, Epoch: 3, Batch: 258, Step num: 3296, Learning rate: 0.00011516, Avg batch loss: 0.4472, Avg batch acc: 0.6008
Train, Epoch: 3, Batch: 259, Step num: 3297, Learning rate: 0.00011519, Avg batch loss: 0.4926, Avg batch acc: 0.5669
Train, Epoch: 3, Batch: 260, Step num: 3298, Learning rate: 0.00011523, Avg batch loss: 0.4773, Avg batch acc: 0.5767
Train, Epoch: 3, Batch: 261, Step num: 3299, Learning rate: 0.00011526, Avg batch loss: 0.4162, Avg batch acc: 0.6063
Train, Epoch: 3, Batch: 262, Step num: 3300, Learning rate: 0.00011530, Avg batch loss: 0.4427, Avg batch acc: 0.5738
Train, Epoch: 3, Batch: 263, Step num: 3301, Learning rate: 0.00011533, Avg batch loss: 0.4453, Avg batch acc: 0.6053
Train, Epoch: 3, Batch: 264, Step num: 3302, Learning rate: 0.00011537, Avg batch loss: 0.4210, Avg batch acc: 0.5833
Train, Epoch: 3, Batch: 265, Step num: 3303, Learning rate: 0.00011540, Avg batch loss: 0.4640, Avg batch acc: 0.6005
Train, Epoch: 3, Batch: 266, Step num: 3304, Learning rate: 0.00011544, Avg batch loss: 0.4905, Avg batch acc: 0.5904
Train, Epoch: 3, Batch: 267, Step num: 3305, Learning rate: 0.00011547, Avg batch loss: 0.4626, Avg batch acc: 0.5952
Train, Epoch: 3, Batch: 268, Step num: 3306, Learning rate: 0.00011551, Avg batch loss: 0.4573, Avg batch acc: 0.5948
Train, Epoch: 3, Batch: 269, Step num: 3307, Learning rate: 0.00011554, Avg batch loss: 0.4903, Avg batch acc: 0.5984
Train, Epoch: 3, Batch: 270, Step num: 3308, Learning rate: 0.00011558, Avg batch loss: 0.4585, Avg batch acc: 0.6041
Train, Epoch: 3, Batch: 271, Step num: 3309, Learning rate: 0.00011561, Avg batch loss: 0.4448, Avg batch acc: 0.5957
Train, Epoch: 3, Batch: 272, Step num: 3310, Learning rate: 0.00011565, Avg batch loss: 0.4578, Avg batch acc: 0.5968
Train, Epoch: 3, Batch: 273, Step num: 3311, Learning rate: 0.00011568, Avg batch loss: 0.5296, Avg batch acc: 0.5719
Train, Epoch: 3, Batch: 274, Step num: 3312, Learning rate: 0.00011572, Avg batch loss: 0.4860, Avg batch acc: 0.5933
Train, Epoch: 3, Batch: 275, Step num: 3313, Learning rate: 0.00011575, Avg batch loss: 0.4204, Avg batch acc: 0.6164
Train, Epoch: 3, Batch: 276, Step num: 3314, Learning rate: 0.00011579, Avg batch loss: 0.4873, Avg batch acc: 0.5885
Train, Epoch: 3, Batch: 277, Step num: 3315, Learning rate: 0.00011582, Avg batch loss: 0.4849, Avg batch acc: 0.5851
Train, Epoch: 3, Batch: 278, Step num: 3316, Learning rate: 0.00011586, Avg batch loss: 0.4302, Avg batch acc: 0.6210
Train, Epoch: 3, Batch: 279, Step num: 3317, Learning rate: 0.00011589, Avg batch loss: 0.4653, Avg batch acc: 0.6079
Train, Epoch: 3, Batch: 280, Step num: 3318, Learning rate: 0.00011593, Avg batch loss: 0.4377, Avg batch acc: 0.6064
Train, Epoch: 3, Batch: 281, Step num: 3319, Learning rate: 0.00011596, Avg batch loss: 0.4459, Avg batch acc: 0.5962
Train, Epoch: 3, Batch: 282, Step num: 3320, Learning rate: 0.00011600, Avg batch loss: 0.4902, Avg batch acc: 0.5910
Train, Epoch: 3, Batch: 283, Step num: 3321, Learning rate: 0.00011603, Avg batch loss: 0.4592, Avg batch acc: 0.5986
Train, Epoch: 3, Batch: 284, Step num: 3322, Learning rate: 0.00011607, Avg batch loss: 0.4088, Avg batch acc: 0.6230
Train, Epoch: 3, Batch: 285, Step num: 3323, Learning rate: 0.00011610, Avg batch loss: 0.4228, Avg batch acc: 0.5975
Train, Epoch: 3, Batch: 286, Step num: 3324, Learning rate: 0.00011614, Avg batch loss: 0.3960, Avg batch acc: 0.6021
Train, Epoch: 3, Batch: 287, Step num: 3325, Learning rate: 0.00011617, Avg batch loss: 0.4634, Avg batch acc: 0.5981
Train, Epoch: 3, Batch: 288, Step num: 3326, Learning rate: 0.00011621, Avg batch loss: 0.4989, Avg batch acc: 0.5764
Train, Epoch: 3, Batch: 289, Step num: 3327, Learning rate: 0.00011624, Avg batch loss: 0.4831, Avg batch acc: 0.5815
Train, Epoch: 3, Batch: 290, Step num: 3328, Learning rate: 0.00011628, Avg batch loss: 0.4468, Avg batch acc: 0.5917
Train, Epoch: 3, Batch: 291, Step num: 3329, Learning rate: 0.00011631, Avg batch loss: 0.4647, Avg batch acc: 0.6280
Train, Epoch: 3, Batch: 292, Step num: 3330, Learning rate: 0.00011635, Avg batch loss: 0.4528, Avg batch acc: 0.5918
Train, Epoch: 3, Batch: 293, Step num: 3331, Learning rate: 0.00011638, Avg batch loss: 0.4688, Avg batch acc: 0.6068
Train, Epoch: 3, Batch: 294, Step num: 3332, Learning rate: 0.00011642, Avg batch loss: 0.4507, Avg batch acc: 0.6066
Train, Epoch: 3, Batch: 295, Step num: 3333, Learning rate: 0.00011645, Avg batch loss: 0.4508, Avg batch acc: 0.5893
Train, Epoch: 3, Batch: 296, Step num: 3334, Learning rate: 0.00011649, Avg batch loss: 0.4340, Avg batch acc: 0.6099
Train, Epoch: 3, Batch: 297, Step num: 3335, Learning rate: 0.00011652, Avg batch loss: 0.4749, Avg batch acc: 0.6080
Train, Epoch: 3, Batch: 298, Step num: 3336, Learning rate: 0.00011656, Avg batch loss: 0.4616, Avg batch acc: 0.5934
Train, Epoch: 3, Batch: 299, Step num: 3337, Learning rate: 0.00011659, Avg batch loss: 0.4518, Avg batch acc: 0.6058
Train, Epoch: 3, Batch: 300, Step num: 3338, Learning rate: 0.00011662, Avg batch loss: 0.4204, Avg batch acc: 0.5929
Train, Epoch: 3, Batch: 301, Step num: 3339, Learning rate: 0.00011666, Avg batch loss: 0.4026, Avg batch acc: 0.6130
Train, Epoch: 3, Batch: 302, Step num: 3340, Learning rate: 0.00011669, Avg batch loss: 0.4411, Avg batch acc: 0.5974
Train, Epoch: 3, Batch: 303, Step num: 3341, Learning rate: 0.00011673, Avg batch loss: 0.4927, Avg batch acc: 0.5925
Train, Epoch: 3, Batch: 304, Step num: 3342, Learning rate: 0.00011676, Avg batch loss: 0.4565, Avg batch acc: 0.6035
Train, Epoch: 3, Batch: 305, Step num: 3343, Learning rate: 0.00011680, Avg batch loss: 0.4612, Avg batch acc: 0.5716
Train, Epoch: 3, Batch: 306, Step num: 3344, Learning rate: 0.00011683, Avg batch loss: 0.4462, Avg batch acc: 0.6084
Train, Epoch: 3, Batch: 307, Step num: 3345, Learning rate: 0.00011687, Avg batch loss: 0.4359, Avg batch acc: 0.5944
Train, Epoch: 3, Batch: 308, Step num: 3346, Learning rate: 0.00011690, Avg batch loss: 0.4584, Avg batch acc: 0.5840
Train, Epoch: 3, Batch: 309, Step num: 3347, Learning rate: 0.00011694, Avg batch loss: 0.3995, Avg batch acc: 0.6263
Train, Epoch: 3, Batch: 310, Step num: 3348, Learning rate: 0.00011697, Avg batch loss: 0.4084, Avg batch acc: 0.6034
Train, Epoch: 3, Batch: 311, Step num: 3349, Learning rate: 0.00011701, Avg batch loss: 0.4150, Avg batch acc: 0.6077
Train, Epoch: 3, Batch: 312, Step num: 3350, Learning rate: 0.00011704, Avg batch loss: 0.4639, Avg batch acc: 0.5859
Train, Epoch: 3, Batch: 313, Step num: 3351, Learning rate: 0.00011708, Avg batch loss: 0.4814, Avg batch acc: 0.5728
Train, Epoch: 3, Batch: 314, Step num: 3352, Learning rate: 0.00011711, Avg batch loss: 0.4497, Avg batch acc: 0.5894
Train, Epoch: 3, Batch: 315, Step num: 3353, Learning rate: 0.00011715, Avg batch loss: 0.4331, Avg batch acc: 0.6097
Train, Epoch: 3, Batch: 316, Step num: 3354, Learning rate: 0.00011718, Avg batch loss: 0.5124, Avg batch acc: 0.5955
Train, Epoch: 3, Batch: 317, Step num: 3355, Learning rate: 0.00011722, Avg batch loss: 0.4561, Avg batch acc: 0.6137
Train, Epoch: 3, Batch: 318, Step num: 3356, Learning rate: 0.00011725, Avg batch loss: 0.5201, Avg batch acc: 0.5811
Train, Epoch: 3, Batch: 319, Step num: 3357, Learning rate: 0.00011729, Avg batch loss: 0.3635, Avg batch acc: 0.6284
Train, Epoch: 3, Batch: 320, Step num: 3358, Learning rate: 0.00011732, Avg batch loss: 0.4555, Avg batch acc: 0.5808
Train, Epoch: 3, Batch: 321, Step num: 3359, Learning rate: 0.00011736, Avg batch loss: 0.4130, Avg batch acc: 0.6059
Train, Epoch: 3, Batch: 322, Step num: 3360, Learning rate: 0.00011739, Avg batch loss: 0.4220, Avg batch acc: 0.6127
Train, Epoch: 3, Batch: 323, Step num: 3361, Learning rate: 0.00011743, Avg batch loss: 0.4154, Avg batch acc: 0.6287
Train, Epoch: 3, Batch: 324, Step num: 3362, Learning rate: 0.00011746, Avg batch loss: 0.4599, Avg batch acc: 0.5689
Train, Epoch: 3, Batch: 325, Step num: 3363, Learning rate: 0.00011750, Avg batch loss: 0.4444, Avg batch acc: 0.5993
Train, Epoch: 3, Batch: 326, Step num: 3364, Learning rate: 0.00011753, Avg batch loss: 0.4610, Avg batch acc: 0.5992
Train, Epoch: 3, Batch: 327, Step num: 3365, Learning rate: 0.00011757, Avg batch loss: 0.4153, Avg batch acc: 0.5957
Train, Epoch: 3, Batch: 328, Step num: 3366, Learning rate: 0.00011760, Avg batch loss: 0.4651, Avg batch acc: 0.5724
Train, Epoch: 3, Batch: 329, Step num: 3367, Learning rate: 0.00011764, Avg batch loss: 0.4423, Avg batch acc: 0.6232
Train, Epoch: 3, Batch: 330, Step num: 3368, Learning rate: 0.00011767, Avg batch loss: 0.4214, Avg batch acc: 0.6190
Train, Epoch: 3, Batch: 331, Step num: 3369, Learning rate: 0.00011771, Avg batch loss: 0.4094, Avg batch acc: 0.6231
Train, Epoch: 3, Batch: 332, Step num: 3370, Learning rate: 0.00011774, Avg batch loss: 0.4317, Avg batch acc: 0.6228
Train, Epoch: 3, Batch: 333, Step num: 3371, Learning rate: 0.00011778, Avg batch loss: 0.4861, Avg batch acc: 0.5916
Train, Epoch: 3, Batch: 334, Step num: 3372, Learning rate: 0.00011781, Avg batch loss: 0.4371, Avg batch acc: 0.6045
Train, Epoch: 3, Batch: 335, Step num: 3373, Learning rate: 0.00011785, Avg batch loss: 0.4291, Avg batch acc: 0.5949
Train, Epoch: 3, Batch: 336, Step num: 3374, Learning rate: 0.00011788, Avg batch loss: 0.4054, Avg batch acc: 0.6227
Train, Epoch: 3, Batch: 337, Step num: 3375, Learning rate: 0.00011792, Avg batch loss: 0.4537, Avg batch acc: 0.5859
Train, Epoch: 3, Batch: 338, Step num: 3376, Learning rate: 0.00011795, Avg batch loss: 0.4709, Avg batch acc: 0.6004
Train, Epoch: 3, Batch: 339, Step num: 3377, Learning rate: 0.00011799, Avg batch loss: 0.4582, Avg batch acc: 0.5932
Train, Epoch: 3, Batch: 340, Step num: 3378, Learning rate: 0.00011802, Avg batch loss: 0.5093, Avg batch acc: 0.5980
Train, Epoch: 3, Batch: 341, Step num: 3379, Learning rate: 0.00011806, Avg batch loss: 0.4746, Avg batch acc: 0.5973
Train, Epoch: 3, Batch: 342, Step num: 3380, Learning rate: 0.00011809, Avg batch loss: 0.4471, Avg batch acc: 0.6187
Train, Epoch: 3, Batch: 343, Step num: 3381, Learning rate: 0.00011813, Avg batch loss: 0.4442, Avg batch acc: 0.6013
Train, Epoch: 3, Batch: 344, Step num: 3382, Learning rate: 0.00011816, Avg batch loss: 0.4140, Avg batch acc: 0.5946
Train, Epoch: 3, Batch: 345, Step num: 3383, Learning rate: 0.00011820, Avg batch loss: 0.4325, Avg batch acc: 0.5951
Train, Epoch: 3, Batch: 346, Step num: 3384, Learning rate: 0.00011823, Avg batch loss: 0.4265, Avg batch acc: 0.6149
Train, Epoch: 3, Batch: 347, Step num: 3385, Learning rate: 0.00011827, Avg batch loss: 0.4682, Avg batch acc: 0.6130
Train, Epoch: 3, Batch: 348, Step num: 3386, Learning rate: 0.00011830, Avg batch loss: 0.4659, Avg batch acc: 0.6213
Train, Epoch: 3, Batch: 349, Step num: 3387, Learning rate: 0.00011834, Avg batch loss: 0.4587, Avg batch acc: 0.6084
Train, Epoch: 3, Batch: 350, Step num: 3388, Learning rate: 0.00011837, Avg batch loss: 0.4400, Avg batch acc: 0.6006
Train, Epoch: 3, Batch: 351, Step num: 3389, Learning rate: 0.00011841, Avg batch loss: 0.5040, Avg batch acc: 0.5978
Train, Epoch: 3, Batch: 352, Step num: 3390, Learning rate: 0.00011844, Avg batch loss: 0.3948, Avg batch acc: 0.6214
Train, Epoch: 3, Batch: 353, Step num: 3391, Learning rate: 0.00011848, Avg batch loss: 0.4267, Avg batch acc: 0.6143
Train, Epoch: 3, Batch: 354, Step num: 3392, Learning rate: 0.00011851, Avg batch loss: 0.4265, Avg batch acc: 0.6286
Train, Epoch: 3, Batch: 355, Step num: 3393, Learning rate: 0.00011855, Avg batch loss: 0.4381, Avg batch acc: 0.6153
Train, Epoch: 3, Batch: 356, Step num: 3394, Learning rate: 0.00011858, Avg batch loss: 0.4268, Avg batch acc: 0.6365
Train, Epoch: 3, Batch: 357, Step num: 3395, Learning rate: 0.00011862, Avg batch loss: 0.4623, Avg batch acc: 0.6137
Train, Epoch: 3, Batch: 358, Step num: 3396, Learning rate: 0.00011865, Avg batch loss: 0.4537, Avg batch acc: 0.5923
Train, Epoch: 3, Batch: 359, Step num: 3397, Learning rate: 0.00011869, Avg batch loss: 0.4426, Avg batch acc: 0.6185
Train, Epoch: 3, Batch: 360, Step num: 3398, Learning rate: 0.00011872, Avg batch loss: 0.4754, Avg batch acc: 0.6007
Train, Epoch: 3, Batch: 361, Step num: 3399, Learning rate: 0.00011876, Avg batch loss: 0.4983, Avg batch acc: 0.5939
Train, Epoch: 3, Batch: 362, Step num: 3400, Learning rate: 0.00011879, Avg batch loss: 0.4464, Avg batch acc: 0.5951
Train, Epoch: 3, Batch: 363, Step num: 3401, Learning rate: 0.00011883, Avg batch loss: 0.4036, Avg batch acc: 0.6138
Train, Epoch: 3, Batch: 364, Step num: 3402, Learning rate: 0.00011886, Avg batch loss: 0.4526, Avg batch acc: 0.5982
Train, Epoch: 3, Batch: 365, Step num: 3403, Learning rate: 0.00011890, Avg batch loss: 0.4474, Avg batch acc: 0.6013
Train, Epoch: 3, Batch: 366, Step num: 3404, Learning rate: 0.00011893, Avg batch loss: 0.4832, Avg batch acc: 0.5978
Train, Epoch: 3, Batch: 367, Step num: 3405, Learning rate: 0.00011897, Avg batch loss: 0.4182, Avg batch acc: 0.6316
Train, Epoch: 3, Batch: 368, Step num: 3406, Learning rate: 0.00011900, Avg batch loss: 0.4320, Avg batch acc: 0.6196
Train, Epoch: 3, Batch: 369, Step num: 3407, Learning rate: 0.00011904, Avg batch loss: 0.4389, Avg batch acc: 0.6208
Train, Epoch: 3, Batch: 370, Step num: 3408, Learning rate: 0.00011907, Avg batch loss: 0.4547, Avg batch acc: 0.6052
Train, Epoch: 3, Batch: 371, Step num: 3409, Learning rate: 0.00011911, Avg batch loss: 0.4152, Avg batch acc: 0.5970
Train, Epoch: 3, Batch: 372, Step num: 3410, Learning rate: 0.00011914, Avg batch loss: 0.4833, Avg batch acc: 0.5873
Train, Epoch: 3, Batch: 373, Step num: 3411, Learning rate: 0.00011918, Avg batch loss: 0.4652, Avg batch acc: 0.5885
Train, Epoch: 3, Batch: 374, Step num: 3412, Learning rate: 0.00011921, Avg batch loss: 0.3733, Avg batch acc: 0.6220
Train, Epoch: 3, Batch: 375, Step num: 3413, Learning rate: 0.00011925, Avg batch loss: 0.4150, Avg batch acc: 0.6097
Train, Epoch: 3, Batch: 376, Step num: 3414, Learning rate: 0.00011928, Avg batch loss: 0.4267, Avg batch acc: 0.6043
Train, Epoch: 3, Batch: 377, Step num: 3415, Learning rate: 0.00011932, Avg batch loss: 0.4410, Avg batch acc: 0.6046
Train, Epoch: 3, Batch: 378, Step num: 3416, Learning rate: 0.00011935, Avg batch loss: 0.3755, Avg batch acc: 0.6229
Train, Epoch: 3, Batch: 379, Step num: 3417, Learning rate: 0.00011939, Avg batch loss: 0.4074, Avg batch acc: 0.6208
Train, Epoch: 3, Batch: 380, Step num: 3418, Learning rate: 0.00011942, Avg batch loss: 0.4172, Avg batch acc: 0.6181
Train, Epoch: 3, Batch: 381, Step num: 3419, Learning rate: 0.00011945, Avg batch loss: 0.4239, Avg batch acc: 0.6304
Train, Epoch: 3, Batch: 382, Step num: 3420, Learning rate: 0.00011949, Avg batch loss: 0.4212, Avg batch acc: 0.6097
Train, Epoch: 3, Batch: 383, Step num: 3421, Learning rate: 0.00011952, Avg batch loss: 0.4363, Avg batch acc: 0.6108
Train, Epoch: 3, Batch: 384, Step num: 3422, Learning rate: 0.00011956, Avg batch loss: 0.4212, Avg batch acc: 0.6287
Train, Epoch: 3, Batch: 385, Step num: 3423, Learning rate: 0.00011959, Avg batch loss: 0.4187, Avg batch acc: 0.5990
Train, Epoch: 3, Batch: 386, Step num: 3424, Learning rate: 0.00011963, Avg batch loss: 0.3857, Avg batch acc: 0.6385
Train, Epoch: 3, Batch: 387, Step num: 3425, Learning rate: 0.00011966, Avg batch loss: 0.4668, Avg batch acc: 0.5884
Train, Epoch: 3, Batch: 388, Step num: 3426, Learning rate: 0.00011970, Avg batch loss: 0.3930, Avg batch acc: 0.6188
Train, Epoch: 3, Batch: 389, Step num: 3427, Learning rate: 0.00011973, Avg batch loss: 0.4216, Avg batch acc: 0.6156
Train, Epoch: 3, Batch: 390, Step num: 3428, Learning rate: 0.00011977, Avg batch loss: 0.4266, Avg batch acc: 0.6250
Train, Epoch: 3, Batch: 391, Step num: 3429, Learning rate: 0.00011980, Avg batch loss: 0.4218, Avg batch acc: 0.6014
Train, Epoch: 3, Batch: 392, Step num: 3430, Learning rate: 0.00011984, Avg batch loss: 0.4765, Avg batch acc: 0.6007
Train, Epoch: 3, Batch: 393, Step num: 3431, Learning rate: 0.00011987, Avg batch loss: 0.4497, Avg batch acc: 0.5942
Train, Epoch: 3, Batch: 394, Step num: 3432, Learning rate: 0.00011991, Avg batch loss: 0.3943, Avg batch acc: 0.6305
Train, Epoch: 3, Batch: 395, Step num: 3433, Learning rate: 0.00011994, Avg batch loss: 0.4687, Avg batch acc: 0.5778
Train, Epoch: 3, Batch: 396, Step num: 3434, Learning rate: 0.00011998, Avg batch loss: 0.4192, Avg batch acc: 0.6167
Train, Epoch: 3, Batch: 397, Step num: 3435, Learning rate: 0.00012001, Avg batch loss: 0.4542, Avg batch acc: 0.6171
Train, Epoch: 3, Batch: 398, Step num: 3436, Learning rate: 0.00012005, Avg batch loss: 0.4297, Avg batch acc: 0.6088
Train, Epoch: 3, Batch: 399, Step num: 3437, Learning rate: 0.00012008, Avg batch loss: 0.4478, Avg batch acc: 0.6039
Train, Epoch: 3, Batch: 400, Step num: 3438, Learning rate: 0.00012012, Avg batch loss: 0.4236, Avg batch acc: 0.6378
Train, Epoch: 3, Batch: 401, Step num: 3439, Learning rate: 0.00012015, Avg batch loss: 0.4636, Avg batch acc: 0.5994
Train, Epoch: 3, Batch: 402, Step num: 3440, Learning rate: 0.00012019, Avg batch loss: 0.4751, Avg batch acc: 0.5936
Train, Epoch: 3, Batch: 403, Step num: 3441, Learning rate: 0.00012022, Avg batch loss: 0.4024, Avg batch acc: 0.6091
Train, Epoch: 3, Batch: 404, Step num: 3442, Learning rate: 0.00012026, Avg batch loss: 0.4470, Avg batch acc: 0.6296
Train, Epoch: 3, Batch: 405, Step num: 3443, Learning rate: 0.00012029, Avg batch loss: 0.4498, Avg batch acc: 0.6130
Train, Epoch: 3, Batch: 406, Step num: 3444, Learning rate: 0.00012033, Avg batch loss: 0.4322, Avg batch acc: 0.6174
Train, Epoch: 3, Batch: 407, Step num: 3445, Learning rate: 0.00012036, Avg batch loss: 0.4530, Avg batch acc: 0.6017
Train, Epoch: 3, Batch: 408, Step num: 3446, Learning rate: 0.00012040, Avg batch loss: 0.4685, Avg batch acc: 0.6073
Train, Epoch: 3, Batch: 409, Step num: 3447, Learning rate: 0.00012043, Avg batch loss: 0.4308, Avg batch acc: 0.6255
Train, Epoch: 3, Batch: 410, Step num: 3448, Learning rate: 0.00012047, Avg batch loss: 0.4190, Avg batch acc: 0.6035
Train, Epoch: 3, Batch: 411, Step num: 3449, Learning rate: 0.00012050, Avg batch loss: 0.4517, Avg batch acc: 0.6141
Train, Epoch: 3, Batch: 412, Step num: 3450, Learning rate: 0.00012054, Avg batch loss: 0.4295, Avg batch acc: 0.6180
Train, Epoch: 3, Batch: 413, Step num: 3451, Learning rate: 0.00012057, Avg batch loss: 0.4022, Avg batch acc: 0.6140
Train, Epoch: 3, Batch: 414, Step num: 3452, Learning rate: 0.00012061, Avg batch loss: 0.4535, Avg batch acc: 0.6227
Train, Epoch: 3, Batch: 415, Step num: 3453, Learning rate: 0.00012064, Avg batch loss: 0.4416, Avg batch acc: 0.5944
Train, Epoch: 3, Batch: 416, Step num: 3454, Learning rate: 0.00012068, Avg batch loss: 0.3345, Avg batch acc: 0.6385
Train, Epoch: 3, Batch: 417, Step num: 3455, Learning rate: 0.00012071, Avg batch loss: 0.3977, Avg batch acc: 0.6462
Train, Epoch: 3, Batch: 418, Step num: 3456, Learning rate: 0.00012075, Avg batch loss: 0.4109, Avg batch acc: 0.6237
Train, Epoch: 3, Batch: 419, Step num: 3457, Learning rate: 0.00012078, Avg batch loss: 0.3661, Avg batch acc: 0.6291
Train, Epoch: 3, Batch: 420, Step num: 3458, Learning rate: 0.00012082, Avg batch loss: 0.4119, Avg batch acc: 0.6238
Train, Epoch: 3, Batch: 421, Step num: 3459, Learning rate: 0.00012085, Avg batch loss: 0.3872, Avg batch acc: 0.6232
Train, Epoch: 3, Batch: 422, Step num: 3460, Learning rate: 0.00012089, Avg batch loss: 0.4030, Avg batch acc: 0.6419
Train, Epoch: 3, Batch: 423, Step num: 3461, Learning rate: 0.00012092, Avg batch loss: 0.4372, Avg batch acc: 0.6269
Train, Epoch: 3, Batch: 424, Step num: 3462, Learning rate: 0.00012096, Avg batch loss: 0.4052, Avg batch acc: 0.6270
Train, Epoch: 3, Batch: 425, Step num: 3463, Learning rate: 0.00012099, Avg batch loss: 0.4222, Avg batch acc: 0.6067
Train, Epoch: 3, Batch: 426, Step num: 3464, Learning rate: 0.00012103, Avg batch loss: 0.4383, Avg batch acc: 0.6196
Train, Epoch: 3, Batch: 427, Step num: 3465, Learning rate: 0.00012106, Avg batch loss: 0.3905, Avg batch acc: 0.6300
Train, Epoch: 3, Batch: 428, Step num: 3466, Learning rate: 0.00012110, Avg batch loss: 0.4133, Avg batch acc: 0.6352
Train, Epoch: 3, Batch: 429, Step num: 3467, Learning rate: 0.00012113, Avg batch loss: 0.4434, Avg batch acc: 0.6159
Train, Epoch: 3, Batch: 430, Step num: 3468, Learning rate: 0.00012117, Avg batch loss: 0.4560, Avg batch acc: 0.5956
Train, Epoch: 3, Batch: 431, Step num: 3469, Learning rate: 0.00012120, Avg batch loss: 0.4188, Avg batch acc: 0.6522
Train, Epoch: 3, Batch: 432, Step num: 3470, Learning rate: 0.00012124, Avg batch loss: 0.4627, Avg batch acc: 0.6183
Train, Epoch: 3, Batch: 433, Step num: 3471, Learning rate: 0.00012127, Avg batch loss: 0.4543, Avg batch acc: 0.6041
Train, Epoch: 3, Batch: 434, Step num: 3472, Learning rate: 0.00012131, Avg batch loss: 0.4134, Avg batch acc: 0.6224
Train, Epoch: 3, Batch: 435, Step num: 3473, Learning rate: 0.00012134, Avg batch loss: 0.4207, Avg batch acc: 0.6119
Train, Epoch: 3, Batch: 436, Step num: 3474, Learning rate: 0.00012138, Avg batch loss: 0.4342, Avg batch acc: 0.6154
Train, Epoch: 3, Batch: 437, Step num: 3475, Learning rate: 0.00012141, Avg batch loss: 0.4504, Avg batch acc: 0.5969
Train, Epoch: 3, Batch: 438, Step num: 3476, Learning rate: 0.00012145, Avg batch loss: 0.4126, Avg batch acc: 0.6261
Train, Epoch: 3, Batch: 439, Step num: 3477, Learning rate: 0.00012148, Avg batch loss: 0.4392, Avg batch acc: 0.5977
Train, Epoch: 3, Batch: 440, Step num: 3478, Learning rate: 0.00012152, Avg batch loss: 0.4302, Avg batch acc: 0.6082
Train, Epoch: 3, Batch: 441, Step num: 3479, Learning rate: 0.00012155, Avg batch loss: 0.4454, Avg batch acc: 0.6065
Train, Epoch: 3, Batch: 442, Step num: 3480, Learning rate: 0.00012159, Avg batch loss: 0.4323, Avg batch acc: 0.6077
Train, Epoch: 3, Batch: 443, Step num: 3481, Learning rate: 0.00012162, Avg batch loss: 0.4116, Avg batch acc: 0.6332
Train, Epoch: 3, Batch: 444, Step num: 3482, Learning rate: 0.00012166, Avg batch loss: 0.4074, Avg batch acc: 0.6173
Train, Epoch: 3, Batch: 445, Step num: 3483, Learning rate: 0.00012169, Avg batch loss: 0.4253, Avg batch acc: 0.6117
Train, Epoch: 3, Batch: 446, Step num: 3484, Learning rate: 0.00012173, Avg batch loss: 0.3744, Avg batch acc: 0.6358
Train, Epoch: 3, Batch: 447, Step num: 3485, Learning rate: 0.00012176, Avg batch loss: 0.4451, Avg batch acc: 0.5963
Train, Epoch: 3, Batch: 448, Step num: 3486, Learning rate: 0.00012180, Avg batch loss: 0.4571, Avg batch acc: 0.6213
Train, Epoch: 3, Batch: 449, Step num: 3487, Learning rate: 0.00012183, Avg batch loss: 0.4189, Avg batch acc: 0.6086
Train, Epoch: 3, Batch: 450, Step num: 3488, Learning rate: 0.00012187, Avg batch loss: 0.4158, Avg batch acc: 0.6242
Train, Epoch: 3, Batch: 451, Step num: 3489, Learning rate: 0.00012190, Avg batch loss: 0.4283, Avg batch acc: 0.6358
Train, Epoch: 3, Batch: 452, Step num: 3490, Learning rate: 0.00012194, Avg batch loss: 0.4330, Avg batch acc: 0.6113
Train, Epoch: 3, Batch: 453, Step num: 3491, Learning rate: 0.00012197, Avg batch loss: 0.3683, Avg batch acc: 0.6223
Train, Epoch: 3, Batch: 454, Step num: 3492, Learning rate: 0.00012201, Avg batch loss: 0.4241, Avg batch acc: 0.6269
Train, Epoch: 3, Batch: 455, Step num: 3493, Learning rate: 0.00012204, Avg batch loss: 0.4091, Avg batch acc: 0.6261
Train, Epoch: 3, Batch: 456, Step num: 3494, Learning rate: 0.00012208, Avg batch loss: 0.4245, Avg batch acc: 0.6150
Train, Epoch: 3, Batch: 457, Step num: 3495, Learning rate: 0.00012211, Avg batch loss: 0.4024, Avg batch acc: 0.6189
Train, Epoch: 3, Batch: 458, Step num: 3496, Learning rate: 0.00012215, Avg batch loss: 0.3860, Avg batch acc: 0.6178
Train, Epoch: 3, Batch: 459, Step num: 3497, Learning rate: 0.00012218, Avg batch loss: 0.3992, Avg batch acc: 0.6291
Train, Epoch: 3, Batch: 460, Step num: 3498, Learning rate: 0.00012222, Avg batch loss: 0.3815, Avg batch acc: 0.6305
Train, Epoch: 3, Batch: 461, Step num: 3499, Learning rate: 0.00012225, Avg batch loss: 0.3936, Avg batch acc: 0.6348
Train, Epoch: 3, Batch: 462, Step num: 3500, Learning rate: 0.00012228, Avg batch loss: 0.4170, Avg batch acc: 0.6370
Train, Epoch: 3, Batch: 463, Step num: 3501, Learning rate: 0.00012232, Avg batch loss: 0.4159, Avg batch acc: 0.6183
Train, Epoch: 3, Batch: 464, Step num: 3502, Learning rate: 0.00012235, Avg batch loss: 0.4222, Avg batch acc: 0.6072
Train, Epoch: 3, Batch: 465, Step num: 3503, Learning rate: 0.00012239, Avg batch loss: 0.4214, Avg batch acc: 0.6046
Train, Epoch: 3, Batch: 466, Step num: 3504, Learning rate: 0.00012242, Avg batch loss: 0.4655, Avg batch acc: 0.6243
Train, Epoch: 3, Batch: 467, Step num: 3505, Learning rate: 0.00012246, Avg batch loss: 0.4466, Avg batch acc: 0.6054
Train, Epoch: 3, Batch: 468, Step num: 3506, Learning rate: 0.00012249, Avg batch loss: 0.4195, Avg batch acc: 0.6183
Train, Epoch: 3, Batch: 469, Step num: 3507, Learning rate: 0.00012253, Avg batch loss: 0.4325, Avg batch acc: 0.6120
Train, Epoch: 3, Batch: 470, Step num: 3508, Learning rate: 0.00012256, Avg batch loss: 0.4580, Avg batch acc: 0.6118
Train, Epoch: 3, Batch: 471, Step num: 3509, Learning rate: 0.00012260, Avg batch loss: 0.4030, Avg batch acc: 0.6330
Train, Epoch: 3, Batch: 472, Step num: 3510, Learning rate: 0.00012263, Avg batch loss: 0.3560, Avg batch acc: 0.6613
Train, Epoch: 3, Batch: 473, Step num: 3511, Learning rate: 0.00012267, Avg batch loss: 0.4158, Avg batch acc: 0.6377
Train, Epoch: 3, Batch: 474, Step num: 3512, Learning rate: 0.00012270, Avg batch loss: 0.4152, Avg batch acc: 0.6447
Train, Epoch: 3, Batch: 475, Step num: 3513, Learning rate: 0.00012274, Avg batch loss: 0.4475, Avg batch acc: 0.6132
Train, Epoch: 3, Batch: 476, Step num: 3514, Learning rate: 0.00012277, Avg batch loss: 0.4036, Avg batch acc: 0.6201
Train, Epoch: 3, Batch: 477, Step num: 3515, Learning rate: 0.00012281, Avg batch loss: 0.4015, Avg batch acc: 0.6531
Train, Epoch: 3, Batch: 478, Step num: 3516, Learning rate: 0.00012284, Avg batch loss: 0.4236, Avg batch acc: 0.5979
Train, Epoch: 3, Batch: 479, Step num: 3517, Learning rate: 0.00012288, Avg batch loss: 0.3310, Avg batch acc: 0.6607
Train, Epoch: 3, Batch: 480, Step num: 3518, Learning rate: 0.00012291, Avg batch loss: 0.3869, Avg batch acc: 0.6446
Train, Epoch: 3, Batch: 481, Step num: 3519, Learning rate: 0.00012295, Avg batch loss: 0.3585, Avg batch acc: 0.6292
Train, Epoch: 3, Batch: 482, Step num: 3520, Learning rate: 0.00012298, Avg batch loss: 0.3966, Avg batch acc: 0.6218
Train, Epoch: 3, Batch: 483, Step num: 3521, Learning rate: 0.00012302, Avg batch loss: 0.4129, Avg batch acc: 0.6084
Train, Epoch: 3, Batch: 484, Step num: 3522, Learning rate: 0.00012305, Avg batch loss: 0.4110, Avg batch acc: 0.6312
Train, Epoch: 3, Batch: 485, Step num: 3523, Learning rate: 0.00012309, Avg batch loss: 0.3849, Avg batch acc: 0.6364
Train, Epoch: 3, Batch: 486, Step num: 3524, Learning rate: 0.00012312, Avg batch loss: 0.4278, Avg batch acc: 0.6299
Train, Epoch: 3, Batch: 487, Step num: 3525, Learning rate: 0.00012316, Avg batch loss: 0.4009, Avg batch acc: 0.6491
Train, Epoch: 3, Batch: 488, Step num: 3526, Learning rate: 0.00012319, Avg batch loss: 0.4069, Avg batch acc: 0.6137
Train, Epoch: 3, Batch: 489, Step num: 3527, Learning rate: 0.00012323, Avg batch loss: 0.4507, Avg batch acc: 0.6141
Train, Epoch: 3, Batch: 490, Step num: 3528, Learning rate: 0.00012326, Avg batch loss: 0.4084, Avg batch acc: 0.6396
Train, Epoch: 3, Batch: 491, Step num: 3529, Learning rate: 0.00012330, Avg batch loss: 0.4233, Avg batch acc: 0.6276
Train, Epoch: 3, Batch: 492, Step num: 3530, Learning rate: 0.00012333, Avg batch loss: 0.3654, Avg batch acc: 0.6562
Train, Epoch: 3, Batch: 493, Step num: 3531, Learning rate: 0.00012337, Avg batch loss: 0.3869, Avg batch acc: 0.6305
Train, Epoch: 3, Batch: 494, Step num: 3532, Learning rate: 0.00012340, Avg batch loss: 0.4181, Avg batch acc: 0.6269
Train, Epoch: 3, Batch: 495, Step num: 3533, Learning rate: 0.00012344, Avg batch loss: 0.3950, Avg batch acc: 0.6452
Train, Epoch: 3, Batch: 496, Step num: 3534, Learning rate: 0.00012347, Avg batch loss: 0.4171, Avg batch acc: 0.6288
Train, Epoch: 3, Batch: 497, Step num: 3535, Learning rate: 0.00012351, Avg batch loss: 0.4146, Avg batch acc: 0.6265
Train, Epoch: 3, Batch: 498, Step num: 3536, Learning rate: 0.00012354, Avg batch loss: 0.4149, Avg batch acc: 0.6252
Train, Epoch: 3, Batch: 499, Step num: 3537, Learning rate: 0.00012358, Avg batch loss: 0.4094, Avg batch acc: 0.6218
Train, Epoch: 3, Batch: 500, Step num: 3538, Learning rate: 0.00012361, Avg batch loss: 0.4306, Avg batch acc: 0.6160
Train, Epoch: 3, Batch: 501, Step num: 3539, Learning rate: 0.00012365, Avg batch loss: 0.4163, Avg batch acc: 0.6090
Train, Epoch: 3, Batch: 502, Step num: 3540, Learning rate: 0.00012368, Avg batch loss: 0.3959, Avg batch acc: 0.6427
Train, Epoch: 3, Batch: 503, Step num: 3541, Learning rate: 0.00012372, Avg batch loss: 0.3919, Avg batch acc: 0.6417
Train, Epoch: 3, Batch: 504, Step num: 3542, Learning rate: 0.00012375, Avg batch loss: 0.4133, Avg batch acc: 0.6193
Train, Epoch: 3, Batch: 505, Step num: 3543, Learning rate: 0.00012379, Avg batch loss: 0.3915, Avg batch acc: 0.6345
Train, Epoch: 3, Batch: 506, Step num: 3544, Learning rate: 0.00012382, Avg batch loss: 0.4050, Avg batch acc: 0.6377
Train, Epoch: 3, Batch: 507, Step num: 3545, Learning rate: 0.00012386, Avg batch loss: 0.3956, Avg batch acc: 0.6368
Train, Epoch: 3, Batch: 508, Step num: 3546, Learning rate: 0.00012389, Avg batch loss: 0.3505, Avg batch acc: 0.6450
Train, Epoch: 3, Batch: 509, Step num: 3547, Learning rate: 0.00012393, Avg batch loss: 0.4144, Avg batch acc: 0.6221
Train, Epoch: 3, Batch: 510, Step num: 3548, Learning rate: 0.00012396, Avg batch loss: 0.3656, Avg batch acc: 0.6578
Train, Epoch: 3, Batch: 511, Step num: 3549, Learning rate: 0.00012400, Avg batch loss: 0.3903, Avg batch acc: 0.6420
Train, Epoch: 3, Batch: 512, Step num: 3550, Learning rate: 0.00012403, Avg batch loss: 0.3977, Avg batch acc: 0.6270
Train, Epoch: 3, Batch: 513, Step num: 3551, Learning rate: 0.00012407, Avg batch loss: 0.3827, Avg batch acc: 0.6245
Train, Epoch: 3, Batch: 514, Step num: 3552, Learning rate: 0.00012410, Avg batch loss: 0.4082, Avg batch acc: 0.6340
Train, Epoch: 3, Batch: 515, Step num: 3553, Learning rate: 0.00012414, Avg batch loss: 0.3839, Avg batch acc: 0.6461
Train, Epoch: 3, Batch: 516, Step num: 3554, Learning rate: 0.00012417, Avg batch loss: 0.4289, Avg batch acc: 0.6255
Train, Epoch: 3, Batch: 517, Step num: 3555, Learning rate: 0.00012421, Avg batch loss: 0.4031, Avg batch acc: 0.6309
Train, Epoch: 3, Batch: 518, Step num: 3556, Learning rate: 0.00012424, Avg batch loss: 0.4199, Avg batch acc: 0.6061
Train, Epoch: 3, Batch: 519, Step num: 3557, Learning rate: 0.00012428, Avg batch loss: 0.4622, Avg batch acc: 0.6158
Train, Epoch: 3, Batch: 520, Step num: 3558, Learning rate: 0.00012431, Avg batch loss: 0.4647, Avg batch acc: 0.6046
Train, Epoch: 3, Batch: 521, Step num: 3559, Learning rate: 0.00012435, Avg batch loss: 0.4216, Avg batch acc: 0.6284
Train, Epoch: 3, Batch: 522, Step num: 3560, Learning rate: 0.00012438, Avg batch loss: 0.3694, Avg batch acc: 0.6403
Train, Epoch: 3, Batch: 523, Step num: 3561, Learning rate: 0.00012442, Avg batch loss: 0.3841, Avg batch acc: 0.6403
Train, Epoch: 3, Batch: 524, Step num: 3562, Learning rate: 0.00012445, Avg batch loss: 0.4137, Avg batch acc: 0.6383
Train, Epoch: 3, Batch: 525, Step num: 3563, Learning rate: 0.00012449, Avg batch loss: 0.3808, Avg batch acc: 0.6446
Train, Epoch: 3, Batch: 526, Step num: 3564, Learning rate: 0.00012452, Avg batch loss: 0.4162, Avg batch acc: 0.6365
Train, Epoch: 3, Batch: 527, Step num: 3565, Learning rate: 0.00012456, Avg batch loss: 0.4445, Avg batch acc: 0.6257
Train, Epoch: 3, Batch: 528, Step num: 3566, Learning rate: 0.00012459, Avg batch loss: 0.3741, Avg batch acc: 0.6355
Train, Epoch: 3, Batch: 529, Step num: 3567, Learning rate: 0.00012463, Avg batch loss: 0.4214, Avg batch acc: 0.6264
Train, Epoch: 3, Batch: 530, Step num: 3568, Learning rate: 0.00012466, Avg batch loss: 0.3983, Avg batch acc: 0.6394
Train, Epoch: 3, Batch: 531, Step num: 3569, Learning rate: 0.00012470, Avg batch loss: 0.3844, Avg batch acc: 0.6362
Train, Epoch: 3, Batch: 532, Step num: 3570, Learning rate: 0.00012473, Avg batch loss: 0.3904, Avg batch acc: 0.6463
Train, Epoch: 3, Batch: 533, Step num: 3571, Learning rate: 0.00012477, Avg batch loss: 0.3901, Avg batch acc: 0.6628
Train, Epoch: 3, Batch: 534, Step num: 3572, Learning rate: 0.00012480, Avg batch loss: 0.3682, Avg batch acc: 0.6480
Train, Epoch: 3, Batch: 535, Step num: 3573, Learning rate: 0.00012484, Avg batch loss: 0.4202, Avg batch acc: 0.6354
Train, Epoch: 3, Batch: 536, Step num: 3574, Learning rate: 0.00012487, Avg batch loss: 0.4564, Avg batch acc: 0.5949
Train, Epoch: 3, Batch: 537, Step num: 3575, Learning rate: 0.00012491, Avg batch loss: 0.4100, Avg batch acc: 0.6382
Train, Epoch: 3, Batch: 538, Step num: 3576, Learning rate: 0.00012494, Avg batch loss: 0.4128, Avg batch acc: 0.6321
Train, Epoch: 3, Batch: 539, Step num: 3577, Learning rate: 0.00012498, Avg batch loss: 0.4479, Avg batch acc: 0.6061
Train, Epoch: 3, Batch: 540, Step num: 3578, Learning rate: 0.00012501, Avg batch loss: 0.4022, Avg batch acc: 0.6392
Train, Epoch: 3, Batch: 541, Step num: 3579, Learning rate: 0.00012505, Avg batch loss: 0.4010, Avg batch acc: 0.6434
Train, Epoch: 3, Batch: 542, Step num: 3580, Learning rate: 0.00012508, Avg batch loss: 0.3653, Avg batch acc: 0.6651
Train, Epoch: 3, Batch: 543, Step num: 3581, Learning rate: 0.00012511, Avg batch loss: 0.3441, Avg batch acc: 0.6549
Train, Epoch: 3, Batch: 544, Step num: 3582, Learning rate: 0.00012515, Avg batch loss: 0.4224, Avg batch acc: 0.6279
Train, Epoch: 3, Batch: 545, Step num: 3583, Learning rate: 0.00012518, Avg batch loss: 0.4125, Avg batch acc: 0.6276
Train, Epoch: 3, Batch: 546, Step num: 3584, Learning rate: 0.00012522, Avg batch loss: 0.4160, Avg batch acc: 0.6265
Train, Epoch: 3, Batch: 547, Step num: 3585, Learning rate: 0.00012525, Avg batch loss: 0.4182, Avg batch acc: 0.6216
Train, Epoch: 3, Batch: 548, Step num: 3586, Learning rate: 0.00012529, Avg batch loss: 0.3774, Avg batch acc: 0.6566
Train, Epoch: 3, Batch: 549, Step num: 3587, Learning rate: 0.00012532, Avg batch loss: 0.3863, Avg batch acc: 0.6157
Train, Epoch: 3, Batch: 550, Step num: 3588, Learning rate: 0.00012536, Avg batch loss: 0.3794, Avg batch acc: 0.6430
Train, Epoch: 3, Batch: 551, Step num: 3589, Learning rate: 0.00012539, Avg batch loss: 0.4407, Avg batch acc: 0.6279
Train, Epoch: 3, Batch: 552, Step num: 3590, Learning rate: 0.00012543, Avg batch loss: 0.3523, Avg batch acc: 0.6413
Train, Epoch: 3, Batch: 553, Step num: 3591, Learning rate: 0.00012546, Avg batch loss: 0.3664, Avg batch acc: 0.6661
Train, Epoch: 3, Batch: 554, Step num: 3592, Learning rate: 0.00012550, Avg batch loss: 0.4104, Avg batch acc: 0.6455
Train, Epoch: 3, Batch: 555, Step num: 3593, Learning rate: 0.00012553, Avg batch loss: 0.4636, Avg batch acc: 0.6276
Train, Epoch: 3, Batch: 556, Step num: 3594, Learning rate: 0.00012557, Avg batch loss: 0.3807, Avg batch acc: 0.6515
Train, Epoch: 3, Batch: 557, Step num: 3595, Learning rate: 0.00012560, Avg batch loss: 0.3766, Avg batch acc: 0.6746
Train, Epoch: 3, Batch: 558, Step num: 3596, Learning rate: 0.00012564, Avg batch loss: 0.4059, Avg batch acc: 0.6346
Train, Epoch: 3, Batch: 559, Step num: 3597, Learning rate: 0.00012567, Avg batch loss: 0.3793, Avg batch acc: 0.6545
Train, Epoch: 3, Batch: 560, Step num: 3598, Learning rate: 0.00012571, Avg batch loss: 0.3795, Avg batch acc: 0.6371
Train, Epoch: 3, Batch: 561, Step num: 3599, Learning rate: 0.00012574, Avg batch loss: 0.3871, Avg batch acc: 0.6637
Train, Epoch: 3, Batch: 562, Step num: 3600, Learning rate: 0.00012578, Avg batch loss: 0.3757, Avg batch acc: 0.6218
Train, Epoch: 3, Batch: 563, Step num: 3601, Learning rate: 0.00012581, Avg batch loss: 0.4066, Avg batch acc: 0.6365
Train, Epoch: 3, Batch: 564, Step num: 3602, Learning rate: 0.00012585, Avg batch loss: 0.3769, Avg batch acc: 0.6485
Train, Epoch: 3, Batch: 565, Step num: 3603, Learning rate: 0.00012588, Avg batch loss: 0.4064, Avg batch acc: 0.6409
Train, Epoch: 3, Batch: 566, Step num: 3604, Learning rate: 0.00012592, Avg batch loss: 0.3938, Avg batch acc: 0.6306
Train, Epoch: 3, Batch: 567, Step num: 3605, Learning rate: 0.00012595, Avg batch loss: 0.3926, Avg batch acc: 0.6293
Train, Epoch: 3, Batch: 568, Step num: 3606, Learning rate: 0.00012599, Avg batch loss: 0.4351, Avg batch acc: 0.6315
Train, Epoch: 3, Batch: 569, Step num: 3607, Learning rate: 0.00012602, Avg batch loss: 0.3839, Avg batch acc: 0.6366
Train, Epoch: 3, Batch: 570, Step num: 3608, Learning rate: 0.00012606, Avg batch loss: 0.3426, Avg batch acc: 0.6609
Train, Epoch: 3, Batch: 571, Step num: 3609, Learning rate: 0.00012609, Avg batch loss: 0.3911, Avg batch acc: 0.6455
Train, Epoch: 3, Batch: 572, Step num: 3610, Learning rate: 0.00012613, Avg batch loss: 0.4298, Avg batch acc: 0.6402
Train, Epoch: 3, Batch: 573, Step num: 3611, Learning rate: 0.00012616, Avg batch loss: 0.4094, Avg batch acc: 0.6379
Train, Epoch: 3, Batch: 574, Step num: 3612, Learning rate: 0.00012620, Avg batch loss: 0.3797, Avg batch acc: 0.6464
Train, Epoch: 3, Batch: 575, Step num: 3613, Learning rate: 0.00012623, Avg batch loss: 0.4536, Avg batch acc: 0.6250
Train, Epoch: 3, Batch: 576, Step num: 3614, Learning rate: 0.00012627, Avg batch loss: 0.3507, Avg batch acc: 0.6490
Train, Epoch: 3, Batch: 577, Step num: 3615, Learning rate: 0.00012630, Avg batch loss: 0.3840, Avg batch acc: 0.6414
Train, Epoch: 3, Batch: 578, Step num: 3616, Learning rate: 0.00012634, Avg batch loss: 0.3702, Avg batch acc: 0.6705
Train, Epoch: 3, Batch: 579, Step num: 3617, Learning rate: 0.00012637, Avg batch loss: 0.3567, Avg batch acc: 0.6460
Train, Epoch: 3, Batch: 580, Step num: 3618, Learning rate: 0.00012641, Avg batch loss: 0.3883, Avg batch acc: 0.6433
Train, Epoch: 3, Batch: 581, Step num: 3619, Learning rate: 0.00012644, Avg batch loss: 0.3474, Avg batch acc: 0.6628
Train, Epoch: 3, Batch: 582, Step num: 3620, Learning rate: 0.00012648, Avg batch loss: 0.3782, Avg batch acc: 0.6594
Train, Epoch: 3, Batch: 583, Step num: 3621, Learning rate: 0.00012651, Avg batch loss: 0.4030, Avg batch acc: 0.6463
Train, Epoch: 3, Batch: 584, Step num: 3622, Learning rate: 0.00012655, Avg batch loss: 0.4089, Avg batch acc: 0.6402
Train, Epoch: 3, Batch: 585, Step num: 3623, Learning rate: 0.00012658, Avg batch loss: 0.4173, Avg batch acc: 0.6266
Train, Epoch: 3, Batch: 586, Step num: 3624, Learning rate: 0.00012662, Avg batch loss: 0.4160, Avg batch acc: 0.6320
Train, Epoch: 3, Batch: 587, Step num: 3625, Learning rate: 0.00012665, Avg batch loss: 0.4306, Avg batch acc: 0.6322
Train, Epoch: 3, Batch: 588, Step num: 3626, Learning rate: 0.00012669, Avg batch loss: 0.4039, Avg batch acc: 0.6374
Train, Epoch: 3, Batch: 589, Step num: 3627, Learning rate: 0.00012672, Avg batch loss: 0.3340, Avg batch acc: 0.6811
Train, Epoch: 3, Batch: 590, Step num: 3628, Learning rate: 0.00012676, Avg batch loss: 0.4079, Avg batch acc: 0.6365
Train, Epoch: 3, Batch: 591, Step num: 3629, Learning rate: 0.00012679, Avg batch loss: 0.3740, Avg batch acc: 0.6572
Train, Epoch: 3, Batch: 592, Step num: 3630, Learning rate: 0.00012683, Avg batch loss: 0.3724, Avg batch acc: 0.6453
Train, Epoch: 3, Batch: 593, Step num: 3631, Learning rate: 0.00012686, Avg batch loss: 0.3895, Avg batch acc: 0.6177
Train, Epoch: 3, Batch: 594, Step num: 3632, Learning rate: 0.00012690, Avg batch loss: 0.4105, Avg batch acc: 0.6518
Train, Epoch: 3, Batch: 595, Step num: 3633, Learning rate: 0.00012693, Avg batch loss: 0.4076, Avg batch acc: 0.6349
Train, Epoch: 3, Batch: 596, Step num: 3634, Learning rate: 0.00012697, Avg batch loss: 0.4343, Avg batch acc: 0.6298
Train, Epoch: 3, Batch: 597, Step num: 3635, Learning rate: 0.00012700, Avg batch loss: 0.3765, Avg batch acc: 0.6423
Train, Epoch: 3, Batch: 598, Step num: 3636, Learning rate: 0.00012704, Avg batch loss: 0.4187, Avg batch acc: 0.6452
Train, Epoch: 3, Batch: 599, Step num: 3637, Learning rate: 0.00012707, Avg batch loss: 0.3648, Avg batch acc: 0.6650
Train, Epoch: 3, Batch: 600, Step num: 3638, Learning rate: 0.00012711, Avg batch loss: 0.3682, Avg batch acc: 0.6359
Train, Epoch: 3, Batch: 601, Step num: 3639, Learning rate: 0.00012714, Avg batch loss: 0.3995, Avg batch acc: 0.6500
Train, Epoch: 3, Batch: 602, Step num: 3640, Learning rate: 0.00012718, Avg batch loss: 0.4098, Avg batch acc: 0.6303
Train, Epoch: 3, Batch: 603, Step num: 3641, Learning rate: 0.00012721, Avg batch loss: 0.4172, Avg batch acc: 0.6346
Train, Epoch: 3, Batch: 604, Step num: 3642, Learning rate: 0.00012725, Avg batch loss: 0.4407, Avg batch acc: 0.6220
Train, Epoch: 3, Batch: 605, Step num: 3643, Learning rate: 0.00012728, Avg batch loss: 0.4036, Avg batch acc: 0.6544
Train, Epoch: 3, Batch: 606, Step num: 3644, Learning rate: 0.00012732, Avg batch loss: 0.4463, Avg batch acc: 0.6545
Train, Epoch: 3, Batch: 607, Step num: 3645, Learning rate: 0.00012735, Avg batch loss: 0.3527, Avg batch acc: 0.6501
Train, Epoch: 3, Batch: 608, Step num: 3646, Learning rate: 0.00012739, Avg batch loss: 0.4193, Avg batch acc: 0.6438
Train, Epoch: 3, Batch: 609, Step num: 3647, Learning rate: 0.00012742, Avg batch loss: 0.3544, Avg batch acc: 0.6674
Train, Epoch: 3, Batch: 610, Step num: 3648, Learning rate: 0.00012746, Avg batch loss: 0.3838, Avg batch acc: 0.6421
Train, Epoch: 3, Batch: 611, Step num: 3649, Learning rate: 0.00012749, Avg batch loss: 0.4004, Avg batch acc: 0.6472
Train, Epoch: 3, Batch: 612, Step num: 3650, Learning rate: 0.00012753, Avg batch loss: 0.3721, Avg batch acc: 0.6780
Train, Epoch: 3, Batch: 613, Step num: 3651, Learning rate: 0.00012756, Avg batch loss: 0.3869, Avg batch acc: 0.6445
Train, Epoch: 3, Batch: 614, Step num: 3652, Learning rate: 0.00012760, Avg batch loss: 0.3529, Avg batch acc: 0.6341
Train, Epoch: 3, Batch: 615, Step num: 3653, Learning rate: 0.00012763, Avg batch loss: 0.3618, Avg batch acc: 0.6579
Train, Epoch: 3, Batch: 616, Step num: 3654, Learning rate: 0.00012767, Avg batch loss: 0.3476, Avg batch acc: 0.6638
Train, Epoch: 3, Batch: 617, Step num: 3655, Learning rate: 0.00012770, Avg batch loss: 0.3817, Avg batch acc: 0.6507
Train, Epoch: 3, Batch: 618, Step num: 3656, Learning rate: 0.00012774, Avg batch loss: 0.4064, Avg batch acc: 0.6426
Train, Epoch: 3, Batch: 619, Step num: 3657, Learning rate: 0.00012777, Avg batch loss: 0.3701, Avg batch acc: 0.6329
Train, Epoch: 3, Batch: 620, Step num: 3658, Learning rate: 0.00012781, Avg batch loss: 0.3772, Avg batch acc: 0.6449
Train, Epoch: 3, Batch: 621, Step num: 3659, Learning rate: 0.00012784, Avg batch loss: 0.3605, Avg batch acc: 0.6613
Train, Epoch: 3, Batch: 622, Step num: 3660, Learning rate: 0.00012788, Avg batch loss: 0.3716, Avg batch acc: 0.6518
Train, Epoch: 3, Batch: 623, Step num: 3661, Learning rate: 0.00012791, Avg batch loss: 0.3803, Avg batch acc: 0.6596
Train, Epoch: 3, Batch: 624, Step num: 3662, Learning rate: 0.00012795, Avg batch loss: 0.4009, Avg batch acc: 0.6393
Train, Epoch: 3, Batch: 625, Step num: 3663, Learning rate: 0.00012798, Avg batch loss: 0.3833, Avg batch acc: 0.6709
Train, Epoch: 3, Batch: 626, Step num: 3664, Learning rate: 0.00012801, Avg batch loss: 0.3769, Avg batch acc: 0.6436
Train, Epoch: 3, Batch: 627, Step num: 3665, Learning rate: 0.00012805, Avg batch loss: 0.3783, Avg batch acc: 0.6385
Train, Epoch: 3, Batch: 628, Step num: 3666, Learning rate: 0.00012808, Avg batch loss: 0.4043, Avg batch acc: 0.6560
Train, Epoch: 3, Batch: 629, Step num: 3667, Learning rate: 0.00012812, Avg batch loss: 0.3625, Avg batch acc: 0.6841
Train, Epoch: 3, Batch: 630, Step num: 3668, Learning rate: 0.00012815, Avg batch loss: 0.3799, Avg batch acc: 0.6668
Train, Epoch: 3, Batch: 631, Step num: 3669, Learning rate: 0.00012819, Avg batch loss: 0.3961, Avg batch acc: 0.6694
Train, Epoch: 3, Batch: 632, Step num: 3670, Learning rate: 0.00012822, Avg batch loss: 0.3782, Avg batch acc: 0.6480
Train, Epoch: 3, Batch: 633, Step num: 3671, Learning rate: 0.00012826, Avg batch loss: 0.3409, Avg batch acc: 0.6585
Train, Epoch: 3, Batch: 634, Step num: 3672, Learning rate: 0.00012829, Avg batch loss: 0.3929, Avg batch acc: 0.6394
Train, Epoch: 3, Batch: 635, Step num: 3673, Learning rate: 0.00012833, Avg batch loss: 0.3826, Avg batch acc: 0.6583
Train, Epoch: 3, Batch: 636, Step num: 3674, Learning rate: 0.00012836, Avg batch loss: 0.3150, Avg batch acc: 0.6807
Train, Epoch: 3, Batch: 637, Step num: 3675, Learning rate: 0.00012840, Avg batch loss: 0.4056, Avg batch acc: 0.6530
Train, Epoch: 3, Batch: 638, Step num: 3676, Learning rate: 0.00012843, Avg batch loss: 0.3027, Avg batch acc: 0.6532
Train, Epoch: 3, Batch: 639, Step num: 3677, Learning rate: 0.00012847, Avg batch loss: 0.3678, Avg batch acc: 0.6720
Train, Epoch: 3, Batch: 640, Step num: 3678, Learning rate: 0.00012850, Avg batch loss: 0.3897, Avg batch acc: 0.6458
Train, Epoch: 3, Batch: 641, Step num: 3679, Learning rate: 0.00012854, Avg batch loss: 0.3797, Avg batch acc: 0.6661
Train, Epoch: 3, Batch: 642, Step num: 3680, Learning rate: 0.00012857, Avg batch loss: 0.4119, Avg batch acc: 0.6346
Train, Epoch: 3, Batch: 643, Step num: 3681, Learning rate: 0.00012861, Avg batch loss: 0.3744, Avg batch acc: 0.6690
Train, Epoch: 3, Batch: 644, Step num: 3682, Learning rate: 0.00012864, Avg batch loss: 0.3841, Avg batch acc: 0.6560
Train, Epoch: 3, Batch: 645, Step num: 3683, Learning rate: 0.00012868, Avg batch loss: 0.3495, Avg batch acc: 0.6489
Train, Epoch: 3, Batch: 646, Step num: 3684, Learning rate: 0.00012871, Avg batch loss: 0.3962, Avg batch acc: 0.6468
Train, Epoch: 3, Batch: 647, Step num: 3685, Learning rate: 0.00012875, Avg batch loss: 0.3541, Avg batch acc: 0.6654
Train, Epoch: 3, Batch: 648, Step num: 3686, Learning rate: 0.00012878, Avg batch loss: 0.3268, Avg batch acc: 0.6819
Train, Epoch: 3, Batch: 649, Step num: 3687, Learning rate: 0.00012882, Avg batch loss: 0.3425, Avg batch acc: 0.6641
Train, Epoch: 3, Batch: 650, Step num: 3688, Learning rate: 0.00012885, Avg batch loss: 0.4349, Avg batch acc: 0.6382
Train, Epoch: 3, Batch: 651, Step num: 3689, Learning rate: 0.00012889, Avg batch loss: 0.3725, Avg batch acc: 0.6523
Train, Epoch: 3, Batch: 652, Step num: 3690, Learning rate: 0.00012892, Avg batch loss: 0.3498, Avg batch acc: 0.6545
Train, Epoch: 3, Batch: 653, Step num: 3691, Learning rate: 0.00012896, Avg batch loss: 0.3591, Avg batch acc: 0.6590
Train, Epoch: 3, Batch: 654, Step num: 3692, Learning rate: 0.00012899, Avg batch loss: 0.3962, Avg batch acc: 0.6453
Train, Epoch: 3, Batch: 655, Step num: 3693, Learning rate: 0.00012903, Avg batch loss: 0.3549, Avg batch acc: 0.6870
Train, Epoch: 3, Batch: 656, Step num: 3694, Learning rate: 0.00012906, Avg batch loss: 0.4043, Avg batch acc: 0.6579
Train, Epoch: 3, Batch: 657, Step num: 3695, Learning rate: 0.00012910, Avg batch loss: 0.3616, Avg batch acc: 0.6692
Train, Epoch: 3, Batch: 658, Step num: 3696, Learning rate: 0.00012913, Avg batch loss: 0.3709, Avg batch acc: 0.6583
Train, Epoch: 3, Batch: 659, Step num: 3697, Learning rate: 0.00012917, Avg batch loss: 0.4101, Avg batch acc: 0.6502
Train, Epoch: 3, Batch: 660, Step num: 3698, Learning rate: 0.00012920, Avg batch loss: 0.3705, Avg batch acc: 0.6505
Train, Epoch: 3, Batch: 661, Step num: 3699, Learning rate: 0.00012924, Avg batch loss: 0.3526, Avg batch acc: 0.6605
Train, Epoch: 3, Batch: 662, Step num: 3700, Learning rate: 0.00012927, Avg batch loss: 0.4091, Avg batch acc: 0.6582
Train, Epoch: 3, Batch: 663, Step num: 3701, Learning rate: 0.00012931, Avg batch loss: 0.3444, Avg batch acc: 0.6780
Train, Epoch: 3, Batch: 664, Step num: 3702, Learning rate: 0.00012934, Avg batch loss: 0.3698, Avg batch acc: 0.6571
Train, Epoch: 3, Batch: 665, Step num: 3703, Learning rate: 0.00012938, Avg batch loss: 0.3541, Avg batch acc: 0.6708
Train, Epoch: 3, Batch: 666, Step num: 3704, Learning rate: 0.00012941, Avg batch loss: 0.3615, Avg batch acc: 0.6685
Train, Epoch: 3, Batch: 667, Step num: 3705, Learning rate: 0.00012945, Avg batch loss: 0.3609, Avg batch acc: 0.6814
Train, Epoch: 3, Batch: 668, Step num: 3706, Learning rate: 0.00012948, Avg batch loss: 0.4188, Avg batch acc: 0.6519
Train, Epoch: 3, Batch: 669, Step num: 3707, Learning rate: 0.00012952, Avg batch loss: 0.3791, Avg batch acc: 0.6611
Train, Epoch: 3, Batch: 670, Step num: 3708, Learning rate: 0.00012955, Avg batch loss: 0.3555, Avg batch acc: 0.6766
Train, Epoch: 3, Batch: 671, Step num: 3709, Learning rate: 0.00012959, Avg batch loss: 0.4181, Avg batch acc: 0.6345
Train, Epoch: 3, Batch: 672, Step num: 3710, Learning rate: 0.00012962, Avg batch loss: 0.3600, Avg batch acc: 0.6846
Train, Epoch: 3, Batch: 673, Step num: 3711, Learning rate: 0.00012966, Avg batch loss: 0.4141, Avg batch acc: 0.6536
Train, Epoch: 3, Batch: 674, Step num: 3712, Learning rate: 0.00012969, Avg batch loss: 0.3380, Avg batch acc: 0.6720
Train, Epoch: 3, Batch: 675, Step num: 3713, Learning rate: 0.00012973, Avg batch loss: 0.3676, Avg batch acc: 0.6706
Train, Epoch: 3, Batch: 676, Step num: 3714, Learning rate: 0.00012976, Avg batch loss: 0.3277, Avg batch acc: 0.6755
Train, Epoch: 3, Batch: 677, Step num: 3715, Learning rate: 0.00012980, Avg batch loss: 0.3695, Avg batch acc: 0.6729
Train, Epoch: 3, Batch: 678, Step num: 3716, Learning rate: 0.00012983, Avg batch loss: 0.4155, Avg batch acc: 0.6370
Train, Epoch: 3, Batch: 679, Step num: 3717, Learning rate: 0.00012987, Avg batch loss: 0.3548, Avg batch acc: 0.6602
Train, Epoch: 3, Batch: 680, Step num: 3718, Learning rate: 0.00012990, Avg batch loss: 0.3846, Avg batch acc: 0.6668
Train, Epoch: 3, Batch: 681, Step num: 3719, Learning rate: 0.00012994, Avg batch loss: 0.3191, Avg batch acc: 0.6777
Train, Epoch: 3, Batch: 682, Step num: 3720, Learning rate: 0.00012997, Avg batch loss: 0.3727, Avg batch acc: 0.6470
Train, Epoch: 3, Batch: 683, Step num: 3721, Learning rate: 0.00013001, Avg batch loss: 0.3840, Avg batch acc: 0.6615
Train, Epoch: 3, Batch: 684, Step num: 3722, Learning rate: 0.00013004, Avg batch loss: 0.3509, Avg batch acc: 0.6840
Train, Epoch: 3, Batch: 685, Step num: 3723, Learning rate: 0.00013008, Avg batch loss: 0.3553, Avg batch acc: 0.6783
Train, Epoch: 3, Batch: 686, Step num: 3724, Learning rate: 0.00013011, Avg batch loss: 0.3476, Avg batch acc: 0.6736
Train, Epoch: 3, Batch: 687, Step num: 3725, Learning rate: 0.00013015, Avg batch loss: 0.3770, Avg batch acc: 0.6748
Train, Epoch: 3, Batch: 688, Step num: 3726, Learning rate: 0.00013018, Avg batch loss: 0.3679, Avg batch acc: 0.6704
Train, Epoch: 3, Batch: 689, Step num: 3727, Learning rate: 0.00013022, Avg batch loss: 0.3569, Avg batch acc: 0.6617
Train, Epoch: 3, Batch: 690, Step num: 3728, Learning rate: 0.00013025, Avg batch loss: 0.3326, Avg batch acc: 0.6858
Train, Epoch: 3, Batch: 691, Step num: 3729, Learning rate: 0.00013029, Avg batch loss: 0.3825, Avg batch acc: 0.6483
Train, Epoch: 3, Batch: 692, Step num: 3730, Learning rate: 0.00013032, Avg batch loss: 0.3548, Avg batch acc: 0.6797
Train, Epoch: 3, Batch: 693, Step num: 3731, Learning rate: 0.00013036, Avg batch loss: 0.3648, Avg batch acc: 0.6640
Train, Epoch: 3, Batch: 694, Step num: 3732, Learning rate: 0.00013039, Avg batch loss: 0.3604, Avg batch acc: 0.6679
Train, Epoch: 3, Batch: 695, Step num: 3733, Learning rate: 0.00013043, Avg batch loss: 0.3104, Avg batch acc: 0.6888
Train, Epoch: 3, Batch: 696, Step num: 3734, Learning rate: 0.00013046, Avg batch loss: 0.3873, Avg batch acc: 0.6725
Train, Epoch: 3, Batch: 697, Step num: 3735, Learning rate: 0.00013050, Avg batch loss: 0.3760, Avg batch acc: 0.6792
Train, Epoch: 3, Batch: 698, Step num: 3736, Learning rate: 0.00013053, Avg batch loss: 0.3168, Avg batch acc: 0.6951
Train, Epoch: 3, Batch: 699, Step num: 3737, Learning rate: 0.00013057, Avg batch loss: 0.3416, Avg batch acc: 0.6706
Train, Epoch: 3, Batch: 700, Step num: 3738, Learning rate: 0.00013060, Avg batch loss: 0.3493, Avg batch acc: 0.6762
Train, Epoch: 3, Batch: 701, Step num: 3739, Learning rate: 0.00013064, Avg batch loss: 0.3490, Avg batch acc: 0.6725
Train, Epoch: 3, Batch: 702, Step num: 3740, Learning rate: 0.00013067, Avg batch loss: 0.3469, Avg batch acc: 0.6590
Train, Epoch: 3, Batch: 703, Step num: 3741, Learning rate: 0.00013071, Avg batch loss: 0.3772, Avg batch acc: 0.6710
Train, Epoch: 3, Batch: 704, Step num: 3742, Learning rate: 0.00013074, Avg batch loss: 0.3726, Avg batch acc: 0.6798
Train, Epoch: 3, Batch: 705, Step num: 3743, Learning rate: 0.00013078, Avg batch loss: 0.3597, Avg batch acc: 0.6740
Train, Epoch: 3, Batch: 706, Step num: 3744, Learning rate: 0.00013081, Avg batch loss: 0.3529, Avg batch acc: 0.6792
Train, Epoch: 3, Batch: 707, Step num: 3745, Learning rate: 0.00013084, Avg batch loss: 0.3121, Avg batch acc: 0.6849
Train, Epoch: 3, Batch: 708, Step num: 3746, Learning rate: 0.00013088, Avg batch loss: 0.3176, Avg batch acc: 0.6824
Train, Epoch: 3, Batch: 709, Step num: 3747, Learning rate: 0.00013091, Avg batch loss: 0.3089, Avg batch acc: 0.7061
Train, Epoch: 3, Batch: 710, Step num: 3748, Learning rate: 0.00013095, Avg batch loss: 0.3395, Avg batch acc: 0.6767
Train, Epoch: 3, Batch: 711, Step num: 3749, Learning rate: 0.00013098, Avg batch loss: 0.3228, Avg batch acc: 0.6845
Train, Epoch: 3, Batch: 712, Step num: 3750, Learning rate: 0.00013102, Avg batch loss: 0.3678, Avg batch acc: 0.6681
Train, Epoch: 3, Batch: 713, Step num: 3751, Learning rate: 0.00013105, Avg batch loss: 0.3550, Avg batch acc: 0.6755
Train, Epoch: 3, Batch: 714, Step num: 3752, Learning rate: 0.00013109, Avg batch loss: 0.3391, Avg batch acc: 0.6830
Train, Epoch: 3, Batch: 715, Step num: 3753, Learning rate: 0.00013112, Avg batch loss: 0.4054, Avg batch acc: 0.6418
Train, Epoch: 3, Batch: 716, Step num: 3754, Learning rate: 0.00013116, Avg batch loss: 0.3886, Avg batch acc: 0.6773
Train, Epoch: 3, Batch: 717, Step num: 3755, Learning rate: 0.00013119, Avg batch loss: 0.3354, Avg batch acc: 0.6748
Train, Epoch: 3, Batch: 718, Step num: 3756, Learning rate: 0.00013123, Avg batch loss: 0.3420, Avg batch acc: 0.6894
Train, Epoch: 3, Batch: 719, Step num: 3757, Learning rate: 0.00013126, Avg batch loss: 0.3777, Avg batch acc: 0.6715
Train, Epoch: 3, Batch: 720, Step num: 3758, Learning rate: 0.00013130, Avg batch loss: 0.3872, Avg batch acc: 0.6614
Train, Epoch: 3, Batch: 721, Step num: 3759, Learning rate: 0.00013133, Avg batch loss: 0.3444, Avg batch acc: 0.6644
Train, Epoch: 3, Batch: 722, Step num: 3760, Learning rate: 0.00013137, Avg batch loss: 0.3819, Avg batch acc: 0.6780
Train, Epoch: 3, Batch: 723, Step num: 3761, Learning rate: 0.00013140, Avg batch loss: 0.3495, Avg batch acc: 0.6875
Train, Epoch: 3, Batch: 724, Step num: 3762, Learning rate: 0.00013144, Avg batch loss: 0.2968, Avg batch acc: 0.6790
Train, Epoch: 3, Batch: 725, Step num: 3763, Learning rate: 0.00013147, Avg batch loss: 0.3603, Avg batch acc: 0.6768
Train, Epoch: 3, Batch: 726, Step num: 3764, Learning rate: 0.00013151, Avg batch loss: 0.3720, Avg batch acc: 0.6723
Train, Epoch: 3, Batch: 727, Step num: 3765, Learning rate: 0.00013154, Avg batch loss: 0.3555, Avg batch acc: 0.6942
Train, Epoch: 3, Batch: 728, Step num: 3766, Learning rate: 0.00013158, Avg batch loss: 0.3750, Avg batch acc: 0.6799
Train, Epoch: 3, Batch: 729, Step num: 3767, Learning rate: 0.00013161, Avg batch loss: 0.3388, Avg batch acc: 0.6917
Train, Epoch: 3, Batch: 730, Step num: 3768, Learning rate: 0.00013165, Avg batch loss: 0.3732, Avg batch acc: 0.6753
Train, Epoch: 3, Batch: 731, Step num: 3769, Learning rate: 0.00013168, Avg batch loss: 0.3352, Avg batch acc: 0.6833
Train, Epoch: 3, Batch: 732, Step num: 3770, Learning rate: 0.00013172, Avg batch loss: 0.3260, Avg batch acc: 0.7015
Train, Epoch: 3, Batch: 733, Step num: 3771, Learning rate: 0.00013175, Avg batch loss: 0.3099, Avg batch acc: 0.7086
Train, Epoch: 3, Batch: 734, Step num: 3772, Learning rate: 0.00013179, Avg batch loss: 0.3886, Avg batch acc: 0.6517
Train, Epoch: 3, Batch: 735, Step num: 3773, Learning rate: 0.00013182, Avg batch loss: 0.3377, Avg batch acc: 0.6978
Train, Epoch: 3, Batch: 736, Step num: 3774, Learning rate: 0.00013186, Avg batch loss: 0.3510, Avg batch acc: 0.6581
Train, Epoch: 3, Batch: 737, Step num: 3775, Learning rate: 0.00013189, Avg batch loss: 0.3676, Avg batch acc: 0.6705
Train, Epoch: 3, Batch: 738, Step num: 3776, Learning rate: 0.00013193, Avg batch loss: 0.3500, Avg batch acc: 0.6819
Train, Epoch: 3, Batch: 739, Step num: 3777, Learning rate: 0.00013196, Avg batch loss: 0.3620, Avg batch acc: 0.6860
Train, Epoch: 3, Batch: 740, Step num: 3778, Learning rate: 0.00013200, Avg batch loss: 0.3514, Avg batch acc: 0.6614
Train, Epoch: 3, Batch: 741, Step num: 3779, Learning rate: 0.00013203, Avg batch loss: 0.3432, Avg batch acc: 0.6855
Train, Epoch: 3, Batch: 742, Step num: 3780, Learning rate: 0.00013207, Avg batch loss: 0.3459, Avg batch acc: 0.6926
Train, Epoch: 3, Batch: 743, Step num: 3781, Learning rate: 0.00013210, Avg batch loss: 0.3179, Avg batch acc: 0.7009
Train, Epoch: 3, Batch: 744, Step num: 3782, Learning rate: 0.00013214, Avg batch loss: 0.3636, Avg batch acc: 0.6760
Train, Epoch: 3, Batch: 745, Step num: 3783, Learning rate: 0.00013217, Avg batch loss: 0.3587, Avg batch acc: 0.6814
Train, Epoch: 3, Batch: 746, Step num: 3784, Learning rate: 0.00013221, Avg batch loss: 0.3226, Avg batch acc: 0.6700
Train, Epoch: 3, Batch: 747, Step num: 3785, Learning rate: 0.00013224, Avg batch loss: 0.3538, Avg batch acc: 0.6728
Train, Epoch: 3, Batch: 748, Step num: 3786, Learning rate: 0.00013228, Avg batch loss: 0.3058, Avg batch acc: 0.7028
Train, Epoch: 3, Batch: 749, Step num: 3787, Learning rate: 0.00013231, Avg batch loss: 0.3420, Avg batch acc: 0.6629
Train, Epoch: 3, Batch: 750, Step num: 3788, Learning rate: 0.00013235, Avg batch loss: 0.3588, Avg batch acc: 0.6972
Train, Epoch: 3, Batch: 751, Step num: 3789, Learning rate: 0.00013238, Avg batch loss: 0.2949, Avg batch acc: 0.7158
Train, Epoch: 3, Batch: 752, Step num: 3790, Learning rate: 0.00013242, Avg batch loss: 0.3868, Avg batch acc: 0.6722
Train, Epoch: 3, Batch: 753, Step num: 3791, Learning rate: 0.00013245, Avg batch loss: 0.3500, Avg batch acc: 0.7073
Train, Epoch: 3, Batch: 754, Step num: 3792, Learning rate: 0.00013249, Avg batch loss: 0.3454, Avg batch acc: 0.7035
Train, Epoch: 3, Batch: 755, Step num: 3793, Learning rate: 0.00013252, Avg batch loss: 0.3594, Avg batch acc: 0.7041
Train, Epoch: 3, Batch: 756, Step num: 3794, Learning rate: 0.00013256, Avg batch loss: 0.3309, Avg batch acc: 0.6831
Train, Epoch: 3, Batch: 757, Step num: 3795, Learning rate: 0.00013259, Avg batch loss: 0.2979, Avg batch acc: 0.7086
Train, Epoch: 3, Batch: 758, Step num: 3796, Learning rate: 0.00013263, Avg batch loss: 0.3628, Avg batch acc: 0.6787
Train, Epoch: 3, Batch: 759, Step num: 3797, Learning rate: 0.00013266, Avg batch loss: 0.3279, Avg batch acc: 0.6962
Train, Epoch: 3, Batch: 760, Step num: 3798, Learning rate: 0.00013270, Avg batch loss: 0.3749, Avg batch acc: 0.6778
Train, Epoch: 3, Batch: 761, Step num: 3799, Learning rate: 0.00013273, Avg batch loss: 0.3187, Avg batch acc: 0.7078
Train, Epoch: 3, Batch: 762, Step num: 3800, Learning rate: 0.00013277, Avg batch loss: 0.2963, Avg batch acc: 0.7023
Train, Epoch: 3, Batch: 763, Step num: 3801, Learning rate: 0.00013280, Avg batch loss: 0.3726, Avg batch acc: 0.6843
Train, Epoch: 3, Batch: 764, Step num: 3802, Learning rate: 0.00013284, Avg batch loss: 0.3312, Avg batch acc: 0.6872
Train, Epoch: 3, Batch: 765, Step num: 3803, Learning rate: 0.00013287, Avg batch loss: 0.3615, Avg batch acc: 0.6973
Train, Epoch: 3, Batch: 766, Step num: 3804, Learning rate: 0.00013291, Avg batch loss: 0.3628, Avg batch acc: 0.6843
Train, Epoch: 3, Batch: 767, Step num: 3805, Learning rate: 0.00013294, Avg batch loss: 0.3170, Avg batch acc: 0.6868
Train, Epoch: 3, Batch: 768, Step num: 3806, Learning rate: 0.00013298, Avg batch loss: 0.3793, Avg batch acc: 0.6612
Train, Epoch: 3, Batch: 769, Step num: 3807, Learning rate: 0.00013301, Avg batch loss: 0.3183, Avg batch acc: 0.7062
Train, Epoch: 3, Batch: 770, Step num: 3808, Learning rate: 0.00013305, Avg batch loss: 0.2934, Avg batch acc: 0.7033
Train, Epoch: 3, Batch: 771, Step num: 3809, Learning rate: 0.00013308, Avg batch loss: 0.3597, Avg batch acc: 0.6813
Train, Epoch: 3, Batch: 772, Step num: 3810, Learning rate: 0.00013312, Avg batch loss: 0.3307, Avg batch acc: 0.6792
Train, Epoch: 3, Batch: 773, Step num: 3811, Learning rate: 0.00013315, Avg batch loss: 0.2778, Avg batch acc: 0.7164
Train, Epoch: 3, Batch: 774, Step num: 3812, Learning rate: 0.00013319, Avg batch loss: 0.3263, Avg batch acc: 0.6872
Train, Epoch: 3, Batch: 775, Step num: 3813, Learning rate: 0.00013322, Avg batch loss: 0.3134, Avg batch acc: 0.6864
Train, Epoch: 3, Batch: 776, Step num: 3814, Learning rate: 0.00013326, Avg batch loss: 0.3737, Avg batch acc: 0.6836
Train, Epoch: 3, Batch: 777, Step num: 3815, Learning rate: 0.00013329, Avg batch loss: 0.3740, Avg batch acc: 0.6925
Train, Epoch: 3, Batch: 778, Step num: 3816, Learning rate: 0.00013333, Avg batch loss: 0.3670, Avg batch acc: 0.6528
Train, Epoch: 3, Batch: 779, Step num: 3817, Learning rate: 0.00013336, Avg batch loss: 0.2927, Avg batch acc: 0.7236
Train, Epoch: 3, Batch: 780, Step num: 3818, Learning rate: 0.00013340, Avg batch loss: 0.3364, Avg batch acc: 0.6758
Train, Epoch: 3, Batch: 781, Step num: 3819, Learning rate: 0.00013343, Avg batch loss: 0.3370, Avg batch acc: 0.6820
Train, Epoch: 3, Batch: 782, Step num: 3820, Learning rate: 0.00013347, Avg batch loss: 0.3364, Avg batch acc: 0.6996
Train, Epoch: 3, Batch: 783, Step num: 3821, Learning rate: 0.00013350, Avg batch loss: 0.3258, Avg batch acc: 0.6905
Train, Epoch: 3, Batch: 784, Step num: 3822, Learning rate: 0.00013354, Avg batch loss: 0.3474, Avg batch acc: 0.7052
Train, Epoch: 3, Batch: 785, Step num: 3823, Learning rate: 0.00013357, Avg batch loss: 0.3456, Avg batch acc: 0.6997
Train, Epoch: 3, Batch: 786, Step num: 3824, Learning rate: 0.00013361, Avg batch loss: 0.3372, Avg batch acc: 0.7024
Train, Epoch: 3, Batch: 787, Step num: 3825, Learning rate: 0.00013364, Avg batch loss: 0.3189, Avg batch acc: 0.7084
Train, Epoch: 3, Batch: 788, Step num: 3826, Learning rate: 0.00013367, Avg batch loss: 0.3275, Avg batch acc: 0.6990
Train, Epoch: 3, Batch: 789, Step num: 3827, Learning rate: 0.00013371, Avg batch loss: 0.3257, Avg batch acc: 0.7019
Train, Epoch: 3, Batch: 790, Step num: 3828, Learning rate: 0.00013374, Avg batch loss: 0.3128, Avg batch acc: 0.6933
Train, Epoch: 3, Batch: 791, Step num: 3829, Learning rate: 0.00013378, Avg batch loss: 0.3517, Avg batch acc: 0.7037
Train, Epoch: 3, Batch: 792, Step num: 3830, Learning rate: 0.00013381, Avg batch loss: 0.3263, Avg batch acc: 0.7032
Train, Epoch: 3, Batch: 793, Step num: 3831, Learning rate: 0.00013385, Avg batch loss: 0.3139, Avg batch acc: 0.6993
Train, Epoch: 3, Batch: 794, Step num: 3832, Learning rate: 0.00013388, Avg batch loss: 0.2791, Avg batch acc: 0.7127
Train, Epoch: 3, Batch: 795, Step num: 3833, Learning rate: 0.00013392, Avg batch loss: 0.3456, Avg batch acc: 0.7073
Train, Epoch: 3, Batch: 796, Step num: 3834, Learning rate: 0.00013395, Avg batch loss: 0.3035, Avg batch acc: 0.7119
Train, Epoch: 3, Batch: 797, Step num: 3835, Learning rate: 0.00013399, Avg batch loss: 0.3017, Avg batch acc: 0.7060
Train, Epoch: 3, Batch: 798, Step num: 3836, Learning rate: 0.00013402, Avg batch loss: 0.2902, Avg batch acc: 0.7152
Train, Epoch: 3, Batch: 799, Step num: 3837, Learning rate: 0.00013406, Avg batch loss: 0.2908, Avg batch acc: 0.7241
Train, Epoch: 3, Batch: 800, Step num: 3838, Learning rate: 0.00013409, Avg batch loss: 0.3382, Avg batch acc: 0.7000
Train, Epoch: 3, Batch: 801, Step num: 3839, Learning rate: 0.00013413, Avg batch loss: 0.3361, Avg batch acc: 0.7086
Train, Epoch: 3, Batch: 802, Step num: 3840, Learning rate: 0.00013416, Avg batch loss: 0.3151, Avg batch acc: 0.7037
Train, Epoch: 3, Batch: 803, Step num: 3841, Learning rate: 0.00013420, Avg batch loss: 0.3417, Avg batch acc: 0.7103
Train, Epoch: 3, Batch: 804, Step num: 3842, Learning rate: 0.00013423, Avg batch loss: 0.3063, Avg batch acc: 0.7007
Train, Epoch: 3, Batch: 805, Step num: 3843, Learning rate: 0.00013427, Avg batch loss: 0.3350, Avg batch acc: 0.7020
Train, Epoch: 3, Batch: 806, Step num: 3844, Learning rate: 0.00013430, Avg batch loss: 0.2680, Avg batch acc: 0.7440
Train, Epoch: 3, Batch: 807, Step num: 3845, Learning rate: 0.00013434, Avg batch loss: 0.2750, Avg batch acc: 0.7211
Train, Epoch: 3, Batch: 808, Step num: 3846, Learning rate: 0.00013437, Avg batch loss: 0.3326, Avg batch acc: 0.6946
Train, Epoch: 3, Batch: 809, Step num: 3847, Learning rate: 0.00013441, Avg batch loss: 0.3484, Avg batch acc: 0.6747
Train, Epoch: 3, Batch: 810, Step num: 3848, Learning rate: 0.00013444, Avg batch loss: 0.3090, Avg batch acc: 0.7201
Train, Epoch: 3, Batch: 811, Step num: 3849, Learning rate: 0.00013448, Avg batch loss: 0.3442, Avg batch acc: 0.6984
Train, Epoch: 3, Batch: 812, Step num: 3850, Learning rate: 0.00013451, Avg batch loss: 0.3111, Avg batch acc: 0.7167
Train, Epoch: 3, Batch: 813, Step num: 3851, Learning rate: 0.00013455, Avg batch loss: 0.2725, Avg batch acc: 0.7390
Train, Epoch: 3, Batch: 814, Step num: 3852, Learning rate: 0.00013458, Avg batch loss: 0.2898, Avg batch acc: 0.7060
Train, Epoch: 3, Batch: 815, Step num: 3853, Learning rate: 0.00013462, Avg batch loss: 0.3443, Avg batch acc: 0.6869
Train, Epoch: 3, Batch: 816, Step num: 3854, Learning rate: 0.00013465, Avg batch loss: 0.3344, Avg batch acc: 0.7034
Train, Epoch: 3, Batch: 817, Step num: 3855, Learning rate: 0.00013469, Avg batch loss: 0.2827, Avg batch acc: 0.7304
Train, Epoch: 3, Batch: 818, Step num: 3856, Learning rate: 0.00013472, Avg batch loss: 0.3170, Avg batch acc: 0.7267
Train, Epoch: 3, Batch: 819, Step num: 3857, Learning rate: 0.00013476, Avg batch loss: 0.2945, Avg batch acc: 0.7031
Train, Epoch: 3, Batch: 820, Step num: 3858, Learning rate: 0.00013479, Avg batch loss: 0.3464, Avg batch acc: 0.7109
Train, Epoch: 3, Batch: 821, Step num: 3859, Learning rate: 0.00013483, Avg batch loss: 0.3887, Avg batch acc: 0.6889
Train, Epoch: 3, Batch: 822, Step num: 3860, Learning rate: 0.00013486, Avg batch loss: 0.3283, Avg batch acc: 0.7080
Train, Epoch: 3, Batch: 823, Step num: 3861, Learning rate: 0.00013490, Avg batch loss: 0.3351, Avg batch acc: 0.6951
Train, Epoch: 3, Batch: 824, Step num: 3862, Learning rate: 0.00013493, Avg batch loss: 0.3060, Avg batch acc: 0.7142
Train, Epoch: 3, Batch: 825, Step num: 3863, Learning rate: 0.00013497, Avg batch loss: 0.3254, Avg batch acc: 0.7168
Train, Epoch: 3, Batch: 826, Step num: 3864, Learning rate: 0.00013500, Avg batch loss: 0.3266, Avg batch acc: 0.7098
Train, Epoch: 3, Batch: 827, Step num: 3865, Learning rate: 0.00013504, Avg batch loss: 0.3277, Avg batch acc: 0.7072
Train, Epoch: 3, Batch: 828, Step num: 3866, Learning rate: 0.00013507, Avg batch loss: 0.3022, Avg batch acc: 0.6871
Train, Epoch: 3, Batch: 829, Step num: 3867, Learning rate: 0.00013511, Avg batch loss: 0.3186, Avg batch acc: 0.7148
Train, Epoch: 3, Batch: 830, Step num: 3868, Learning rate: 0.00013514, Avg batch loss: 0.3114, Avg batch acc: 0.7171
Train, Epoch: 3, Batch: 831, Step num: 3869, Learning rate: 0.00013518, Avg batch loss: 0.3421, Avg batch acc: 0.7099
Train, Epoch: 3, Batch: 832, Step num: 3870, Learning rate: 0.00013521, Avg batch loss: 0.3213, Avg batch acc: 0.7011
Train, Epoch: 3, Batch: 833, Step num: 3871, Learning rate: 0.00013525, Avg batch loss: 0.3378, Avg batch acc: 0.6916
Train, Epoch: 3, Batch: 834, Step num: 3872, Learning rate: 0.00013528, Avg batch loss: 0.3156, Avg batch acc: 0.7156
Train, Epoch: 3, Batch: 835, Step num: 3873, Learning rate: 0.00013532, Avg batch loss: 0.3077, Avg batch acc: 0.7129
Train, Epoch: 3, Batch: 836, Step num: 3874, Learning rate: 0.00013535, Avg batch loss: 0.3458, Avg batch acc: 0.6986
Train, Epoch: 3, Batch: 837, Step num: 3875, Learning rate: 0.00013539, Avg batch loss: 0.2735, Avg batch acc: 0.7478
Train, Epoch: 3, Batch: 838, Step num: 3876, Learning rate: 0.00013542, Avg batch loss: 0.2977, Avg batch acc: 0.7229
Train, Epoch: 3, Batch: 839, Step num: 3877, Learning rate: 0.00013546, Avg batch loss: 0.3187, Avg batch acc: 0.7111
Train, Epoch: 3, Batch: 840, Step num: 3878, Learning rate: 0.00013549, Avg batch loss: 0.3181, Avg batch acc: 0.7178
Train, Epoch: 3, Batch: 841, Step num: 3879, Learning rate: 0.00013553, Avg batch loss: 0.3146, Avg batch acc: 0.7160
Train, Epoch: 3, Batch: 842, Step num: 3880, Learning rate: 0.00013556, Avg batch loss: 0.3309, Avg batch acc: 0.6929
Train, Epoch: 3, Batch: 843, Step num: 3881, Learning rate: 0.00013560, Avg batch loss: 0.3348, Avg batch acc: 0.7149
Train, Epoch: 3, Batch: 844, Step num: 3882, Learning rate: 0.00013563, Avg batch loss: 0.2881, Avg batch acc: 0.7139
Train, Epoch: 3, Batch: 845, Step num: 3883, Learning rate: 0.00013567, Avg batch loss: 0.3428, Avg batch acc: 0.6982
Train, Epoch: 3, Batch: 846, Step num: 3884, Learning rate: 0.00013570, Avg batch loss: 0.3403, Avg batch acc: 0.6990
Train, Epoch: 3, Batch: 847, Step num: 3885, Learning rate: 0.00013574, Avg batch loss: 0.3656, Avg batch acc: 0.6982
Train, Epoch: 3, Batch: 848, Step num: 3886, Learning rate: 0.00013577, Avg batch loss: 0.2825, Avg batch acc: 0.7300
Train, Epoch: 3, Batch: 849, Step num: 3887, Learning rate: 0.00013581, Avg batch loss: 0.3054, Avg batch acc: 0.7117
Train, Epoch: 3, Batch: 850, Step num: 3888, Learning rate: 0.00013584, Avg batch loss: 0.2734, Avg batch acc: 0.7196
Train, Epoch: 3, Batch: 851, Step num: 3889, Learning rate: 0.00013588, Avg batch loss: 0.3350, Avg batch acc: 0.7240
Train, Epoch: 3, Batch: 852, Step num: 3890, Learning rate: 0.00013591, Avg batch loss: 0.2767, Avg batch acc: 0.7215
Train, Epoch: 3, Batch: 853, Step num: 3891, Learning rate: 0.00013595, Avg batch loss: 0.3141, Avg batch acc: 0.7174
Train, Epoch: 3, Batch: 854, Step num: 3892, Learning rate: 0.00013598, Avg batch loss: 0.3014, Avg batch acc: 0.7298
Train, Epoch: 3, Batch: 855, Step num: 3893, Learning rate: 0.00013602, Avg batch loss: 0.3588, Avg batch acc: 0.7287
Train, Epoch: 3, Batch: 856, Step num: 3894, Learning rate: 0.00013605, Avg batch loss: 0.2890, Avg batch acc: 0.7403
Train, Epoch: 3, Batch: 857, Step num: 3895, Learning rate: 0.00013609, Avg batch loss: 0.2803, Avg batch acc: 0.7398
Train, Epoch: 3, Batch: 858, Step num: 3896, Learning rate: 0.00013612, Avg batch loss: 0.2765, Avg batch acc: 0.7518
Train, Epoch: 3, Batch: 859, Step num: 3897, Learning rate: 0.00013616, Avg batch loss: 0.3043, Avg batch acc: 0.7365
Train, Epoch: 3, Batch: 860, Step num: 3898, Learning rate: 0.00013619, Avg batch loss: 0.2803, Avg batch acc: 0.7414
Train, Epoch: 3, Batch: 861, Step num: 3899, Learning rate: 0.00013623, Avg batch loss: 0.3058, Avg batch acc: 0.7099
Train, Epoch: 3, Batch: 862, Step num: 3900, Learning rate: 0.00013626, Avg batch loss: 0.2430, Avg batch acc: 0.7317
Train, Epoch: 3, Batch: 863, Step num: 3901, Learning rate: 0.00013630, Avg batch loss: 0.2856, Avg batch acc: 0.7272
Train, Epoch: 3, Batch: 864, Step num: 3902, Learning rate: 0.00013633, Avg batch loss: 0.2868, Avg batch acc: 0.7503
Train, Epoch: 3, Batch: 865, Step num: 3903, Learning rate: 0.00013637, Avg batch loss: 0.3317, Avg batch acc: 0.7230
Train, Epoch: 3, Batch: 866, Step num: 3904, Learning rate: 0.00013640, Avg batch loss: 0.2906, Avg batch acc: 0.7302
Train, Epoch: 3, Batch: 867, Step num: 3905, Learning rate: 0.00013644, Avg batch loss: 0.2967, Avg batch acc: 0.7160
Train, Epoch: 3, Batch: 868, Step num: 3906, Learning rate: 0.00013647, Avg batch loss: 0.3260, Avg batch acc: 0.7246
Train, Epoch: 3, Batch: 869, Step num: 3907, Learning rate: 0.00013650, Avg batch loss: 0.2903, Avg batch acc: 0.7399
Train, Epoch: 3, Batch: 870, Step num: 3908, Learning rate: 0.00013654, Avg batch loss: 0.2865, Avg batch acc: 0.7386
Train, Epoch: 3, Batch: 871, Step num: 3909, Learning rate: 0.00013657, Avg batch loss: 0.3169, Avg batch acc: 0.7322
Train, Epoch: 3, Batch: 872, Step num: 3910, Learning rate: 0.00013661, Avg batch loss: 0.3288, Avg batch acc: 0.7099
Train, Epoch: 3, Batch: 873, Step num: 3911, Learning rate: 0.00013664, Avg batch loss: 0.2932, Avg batch acc: 0.7408
Train, Epoch: 3, Batch: 874, Step num: 3912, Learning rate: 0.00013668, Avg batch loss: 0.3011, Avg batch acc: 0.7304
Train, Epoch: 3, Batch: 875, Step num: 3913, Learning rate: 0.00013671, Avg batch loss: 0.3232, Avg batch acc: 0.7192
Train, Epoch: 3, Batch: 876, Step num: 3914, Learning rate: 0.00013675, Avg batch loss: 0.2975, Avg batch acc: 0.7208
Train, Epoch: 3, Batch: 877, Step num: 3915, Learning rate: 0.00013678, Avg batch loss: 0.3013, Avg batch acc: 0.7408
Train, Epoch: 3, Batch: 878, Step num: 3916, Learning rate: 0.00013682, Avg batch loss: 0.2698, Avg batch acc: 0.7483
Train, Epoch: 3, Batch: 879, Step num: 3917, Learning rate: 0.00013685, Avg batch loss: 0.2809, Avg batch acc: 0.7328
Train, Epoch: 3, Batch: 880, Step num: 3918, Learning rate: 0.00013689, Avg batch loss: 0.3459, Avg batch acc: 0.6967
Train, Epoch: 3, Batch: 881, Step num: 3919, Learning rate: 0.00013692, Avg batch loss: 0.2972, Avg batch acc: 0.7289
Train, Epoch: 3, Batch: 882, Step num: 3920, Learning rate: 0.00013696, Avg batch loss: 0.2591, Avg batch acc: 0.7589
Train, Epoch: 3, Batch: 883, Step num: 3921, Learning rate: 0.00013699, Avg batch loss: 0.3252, Avg batch acc: 0.7085
Train, Epoch: 3, Batch: 884, Step num: 3922, Learning rate: 0.00013703, Avg batch loss: 0.3138, Avg batch acc: 0.7226
Train, Epoch: 3, Batch: 885, Step num: 3923, Learning rate: 0.00013706, Avg batch loss: 0.2789, Avg batch acc: 0.7700
Train, Epoch: 3, Batch: 886, Step num: 3924, Learning rate: 0.00013710, Avg batch loss: 0.2930, Avg batch acc: 0.7396
Train, Epoch: 3, Batch: 887, Step num: 3925, Learning rate: 0.00013713, Avg batch loss: 0.3265, Avg batch acc: 0.7298
Train, Epoch: 3, Batch: 888, Step num: 3926, Learning rate: 0.00013717, Avg batch loss: 0.3550, Avg batch acc: 0.7313
Train, Epoch: 3, Batch: 889, Step num: 3927, Learning rate: 0.00013720, Avg batch loss: 0.2948, Avg batch acc: 0.7406
Train, Epoch: 3, Batch: 890, Step num: 3928, Learning rate: 0.00013724, Avg batch loss: 0.2606, Avg batch acc: 0.7472
Train, Epoch: 3, Batch: 891, Step num: 3929, Learning rate: 0.00013727, Avg batch loss: 0.3029, Avg batch acc: 0.7324
Train, Epoch: 3, Batch: 892, Step num: 3930, Learning rate: 0.00013731, Avg batch loss: 0.3107, Avg batch acc: 0.7435
Train, Epoch: 3, Batch: 893, Step num: 3931, Learning rate: 0.00013734, Avg batch loss: 0.2534, Avg batch acc: 0.7560
Train, Epoch: 3, Batch: 894, Step num: 3932, Learning rate: 0.00013738, Avg batch loss: 0.3030, Avg batch acc: 0.7527
Train, Epoch: 3, Batch: 895, Step num: 3933, Learning rate: 0.00013741, Avg batch loss: 0.2800, Avg batch acc: 0.7379
Train, Epoch: 3, Batch: 896, Step num: 3934, Learning rate: 0.00013745, Avg batch loss: 0.2833, Avg batch acc: 0.7449
Train, Epoch: 3, Batch: 897, Step num: 3935, Learning rate: 0.00013748, Avg batch loss: 0.3145, Avg batch acc: 0.7460
Train, Epoch: 3, Batch: 898, Step num: 3936, Learning rate: 0.00013752, Avg batch loss: 0.2402, Avg batch acc: 0.7610
Train, Epoch: 3, Batch: 899, Step num: 3937, Learning rate: 0.00013755, Avg batch loss: 0.3016, Avg batch acc: 0.7460
Train, Epoch: 3, Batch: 900, Step num: 3938, Learning rate: 0.00013759, Avg batch loss: 0.3124, Avg batch acc: 0.7239
Train, Epoch: 3, Batch: 901, Step num: 3939, Learning rate: 0.00013762, Avg batch loss: 0.2715, Avg batch acc: 0.7493
Train, Epoch: 3, Batch: 902, Step num: 3940, Learning rate: 0.00013766, Avg batch loss: 0.3195, Avg batch acc: 0.7230
Train, Epoch: 3, Batch: 903, Step num: 3941, Learning rate: 0.00013769, Avg batch loss: 0.2748, Avg batch acc: 0.7442
Train, Epoch: 3, Batch: 904, Step num: 3942, Learning rate: 0.00013773, Avg batch loss: 0.2516, Avg batch acc: 0.7559
Train, Epoch: 3, Batch: 905, Step num: 3943, Learning rate: 0.00013776, Avg batch loss: 0.2758, Avg batch acc: 0.7517
Train, Epoch: 3, Batch: 906, Step num: 3944, Learning rate: 0.00013780, Avg batch loss: 0.2782, Avg batch acc: 0.7422
Train, Epoch: 3, Batch: 907, Step num: 3945, Learning rate: 0.00013783, Avg batch loss: 0.2581, Avg batch acc: 0.7537
Train, Epoch: 3, Batch: 908, Step num: 3946, Learning rate: 0.00013787, Avg batch loss: 0.2719, Avg batch acc: 0.7525
Train, Epoch: 3, Batch: 909, Step num: 3947, Learning rate: 0.00013790, Avg batch loss: 0.2854, Avg batch acc: 0.7362
Train, Epoch: 3, Batch: 910, Step num: 3948, Learning rate: 0.00013794, Avg batch loss: 0.2938, Avg batch acc: 0.7357
Train, Epoch: 3, Batch: 911, Step num: 3949, Learning rate: 0.00013797, Avg batch loss: 0.2636, Avg batch acc: 0.7658
Train, Epoch: 3, Batch: 912, Step num: 3950, Learning rate: 0.00013801, Avg batch loss: 0.2675, Avg batch acc: 0.7521
Train, Epoch: 3, Batch: 913, Step num: 3951, Learning rate: 0.00013804, Avg batch loss: 0.2666, Avg batch acc: 0.7679
Train, Epoch: 3, Batch: 914, Step num: 3952, Learning rate: 0.00013808, Avg batch loss: 0.2875, Avg batch acc: 0.7574
Train, Epoch: 3, Batch: 915, Step num: 3953, Learning rate: 0.00013811, Avg batch loss: 0.2680, Avg batch acc: 0.7480
Train, Epoch: 3, Batch: 916, Step num: 3954, Learning rate: 0.00013815, Avg batch loss: 0.2563, Avg batch acc: 0.7622
Train, Epoch: 3, Batch: 917, Step num: 3955, Learning rate: 0.00013818, Avg batch loss: 0.2465, Avg batch acc: 0.7746
Train, Epoch: 3, Batch: 918, Step num: 3956, Learning rate: 0.00013822, Avg batch loss: 0.2549, Avg batch acc: 0.7533
Train, Epoch: 3, Batch: 919, Step num: 3957, Learning rate: 0.00013825, Avg batch loss: 0.2946, Avg batch acc: 0.7394
Train, Epoch: 3, Batch: 920, Step num: 3958, Learning rate: 0.00013829, Avg batch loss: 0.2773, Avg batch acc: 0.7545
Train, Epoch: 3, Batch: 921, Step num: 3959, Learning rate: 0.00013832, Avg batch loss: 0.2546, Avg batch acc: 0.7620
Train, Epoch: 3, Batch: 922, Step num: 3960, Learning rate: 0.00013836, Avg batch loss: 0.2757, Avg batch acc: 0.7560
Train, Epoch: 3, Batch: 923, Step num: 3961, Learning rate: 0.00013839, Avg batch loss: 0.3183, Avg batch acc: 0.7434
Train, Epoch: 3, Batch: 924, Step num: 3962, Learning rate: 0.00013843, Avg batch loss: 0.3215, Avg batch acc: 0.7311
Train, Epoch: 3, Batch: 925, Step num: 3963, Learning rate: 0.00013846, Avg batch loss: 0.3104, Avg batch acc: 0.7354
Train, Epoch: 3, Batch: 926, Step num: 3964, Learning rate: 0.00013850, Avg batch loss: 0.2720, Avg batch acc: 0.7589
Train, Epoch: 3, Batch: 927, Step num: 3965, Learning rate: 0.00013853, Avg batch loss: 0.2783, Avg batch acc: 0.7665
Train, Epoch: 3, Batch: 928, Step num: 3966, Learning rate: 0.00013857, Avg batch loss: 0.3276, Avg batch acc: 0.7429
Train, Epoch: 3, Batch: 929, Step num: 3967, Learning rate: 0.00013860, Avg batch loss: 0.2581, Avg batch acc: 0.7790
Train, Epoch: 3, Batch: 930, Step num: 3968, Learning rate: 0.00013864, Avg batch loss: 0.2938, Avg batch acc: 0.7537
Train, Epoch: 3, Batch: 931, Step num: 3969, Learning rate: 0.00013867, Avg batch loss: 0.2982, Avg batch acc: 0.7446
Train, Epoch: 3, Batch: 932, Step num: 3970, Learning rate: 0.00013871, Avg batch loss: 0.3134, Avg batch acc: 0.7534
Train, Epoch: 3, Batch: 933, Step num: 3971, Learning rate: 0.00013874, Avg batch loss: 0.2853, Avg batch acc: 0.7648
Train, Epoch: 3, Batch: 934, Step num: 3972, Learning rate: 0.00013878, Avg batch loss: 0.3035, Avg batch acc: 0.7493
Train, Epoch: 3, Batch: 935, Step num: 3973, Learning rate: 0.00013881, Avg batch loss: 0.2852, Avg batch acc: 0.7511
Train, Epoch: 3, Batch: 936, Step num: 3974, Learning rate: 0.00013885, Avg batch loss: 0.2819, Avg batch acc: 0.7404
Train, Epoch: 3, Batch: 937, Step num: 3975, Learning rate: 0.00013888, Avg batch loss: 0.2722, Avg batch acc: 0.7570
Train, Epoch: 3, Batch: 938, Step num: 3976, Learning rate: 0.00013892, Avg batch loss: 0.3092, Avg batch acc: 0.7349
Train, Epoch: 3, Batch: 939, Step num: 3977, Learning rate: 0.00013895, Avg batch loss: 0.3120, Avg batch acc: 0.7423
Train, Epoch: 3, Batch: 940, Step num: 3978, Learning rate: 0.00013899, Avg batch loss: 0.2492, Avg batch acc: 0.7450
Train, Epoch: 3, Batch: 941, Step num: 3979, Learning rate: 0.00013902, Avg batch loss: 0.2661, Avg batch acc: 0.7579
Train, Epoch: 3, Batch: 942, Step num: 3980, Learning rate: 0.00013906, Avg batch loss: 0.2848, Avg batch acc: 0.7504
Train, Epoch: 3, Batch: 943, Step num: 3981, Learning rate: 0.00013909, Avg batch loss: 0.2673, Avg batch acc: 0.7673
Train, Epoch: 3, Batch: 944, Step num: 3982, Learning rate: 0.00013913, Avg batch loss: 0.2718, Avg batch acc: 0.7708
Train, Epoch: 3, Batch: 945, Step num: 3983, Learning rate: 0.00013916, Avg batch loss: 0.3094, Avg batch acc: 0.7421
Train, Epoch: 3, Batch: 946, Step num: 3984, Learning rate: 0.00013920, Avg batch loss: 0.2926, Avg batch acc: 0.7670
Train, Epoch: 3, Batch: 947, Step num: 3985, Learning rate: 0.00013923, Avg batch loss: 0.2705, Avg batch acc: 0.7537
Train, Epoch: 3, Batch: 948, Step num: 3986, Learning rate: 0.00013927, Avg batch loss: 0.2642, Avg batch acc: 0.7798
Train, Epoch: 3, Batch: 949, Step num: 3987, Learning rate: 0.00013930, Avg batch loss: 0.2605, Avg batch acc: 0.7773
Train, Epoch: 3, Batch: 950, Step num: 3988, Learning rate: 0.00013933, Avg batch loss: 0.2677, Avg batch acc: 0.7627
Train, Epoch: 3, Batch: 951, Step num: 3989, Learning rate: 0.00013937, Avg batch loss: 0.2513, Avg batch acc: 0.7689
Train, Epoch: 3, Batch: 952, Step num: 3990, Learning rate: 0.00013940, Avg batch loss: 0.2819, Avg batch acc: 0.7587
Train, Epoch: 3, Batch: 953, Step num: 3991, Learning rate: 0.00013944, Avg batch loss: 0.2461, Avg batch acc: 0.7627
Train, Epoch: 3, Batch: 954, Step num: 3992, Learning rate: 0.00013947, Avg batch loss: 0.2972, Avg batch acc: 0.7649
Train, Epoch: 3, Batch: 955, Step num: 3993, Learning rate: 0.00013951, Avg batch loss: 0.2983, Avg batch acc: 0.7390
Train, Epoch: 3, Batch: 956, Step num: 3994, Learning rate: 0.00013954, Avg batch loss: 0.2816, Avg batch acc: 0.7421
Train, Epoch: 3, Batch: 957, Step num: 3995, Learning rate: 0.00013958, Avg batch loss: 0.2373, Avg batch acc: 0.7688
Train, Epoch: 3, Batch: 958, Step num: 3996, Learning rate: 0.00013961, Avg batch loss: 0.2855, Avg batch acc: 0.7781
Train, Epoch: 3, Batch: 959, Step num: 3997, Learning rate: 0.00013965, Avg batch loss: 0.2349, Avg batch acc: 0.7766
Train, Epoch: 3, Batch: 960, Step num: 3998, Learning rate: 0.00013968, Avg batch loss: 0.2361, Avg batch acc: 0.7909
Train, Epoch: 3, Batch: 961, Step num: 3999, Learning rate: 0.00013972, Avg batch loss: 0.2662, Avg batch acc: 0.7736
Train, Epoch: 3, Batch: 962, Step num: 4000, Learning rate: 0.00013975, Avg batch loss: 0.2537, Avg batch acc: 0.7655
Train, Epoch: 3, Batch: 963, Step num: 4001, Learning rate: 0.00013974, Avg batch loss: 0.2438, Avg batch acc: 0.7843
Train, Epoch: 3, Batch: 964, Step num: 4002, Learning rate: 0.00013972, Avg batch loss: 0.2445, Avg batch acc: 0.7752
Train, Epoch: 3, Batch: 965, Step num: 4003, Learning rate: 0.00013970, Avg batch loss: 0.2598, Avg batch acc: 0.7656
Train, Epoch: 3, Batch: 966, Step num: 4004, Learning rate: 0.00013968, Avg batch loss: 0.2540, Avg batch acc: 0.7813
Train, Epoch: 3, Batch: 967, Step num: 4005, Learning rate: 0.00013967, Avg batch loss: 0.2499, Avg batch acc: 0.7679
Train, Epoch: 3, Batch: 968, Step num: 4006, Learning rate: 0.00013965, Avg batch loss: 0.2607, Avg batch acc: 0.7686
Train, Epoch: 3, Batch: 969, Step num: 4007, Learning rate: 0.00013963, Avg batch loss: 0.2863, Avg batch acc: 0.7561
Train, Epoch: 3, Batch: 970, Step num: 4008, Learning rate: 0.00013961, Avg batch loss: 0.2705, Avg batch acc: 0.7823
Train, Epoch: 3, Batch: 971, Step num: 4009, Learning rate: 0.00013960, Avg batch loss: 0.2481, Avg batch acc: 0.7582
Train, Epoch: 3, Batch: 972, Step num: 4010, Learning rate: 0.00013958, Avg batch loss: 0.2535, Avg batch acc: 0.7716
Train, Epoch: 3, Batch: 973, Step num: 4011, Learning rate: 0.00013956, Avg batch loss: 0.2611, Avg batch acc: 0.7623
Train, Epoch: 3, Batch: 974, Step num: 4012, Learning rate: 0.00013955, Avg batch loss: 0.2585, Avg batch acc: 0.7712
Train, Epoch: 3, Batch: 975, Step num: 4013, Learning rate: 0.00013953, Avg batch loss: 0.2287, Avg batch acc: 0.7980
Train, Epoch: 3, Batch: 976, Step num: 4014, Learning rate: 0.00013951, Avg batch loss: 0.2346, Avg batch acc: 0.7892
Train, Epoch: 3, Batch: 977, Step num: 4015, Learning rate: 0.00013949, Avg batch loss: 0.2583, Avg batch acc: 0.7702
Train, Epoch: 3, Batch: 978, Step num: 4016, Learning rate: 0.00013948, Avg batch loss: 0.2523, Avg batch acc: 0.7720
Train, Epoch: 3, Batch: 979, Step num: 4017, Learning rate: 0.00013946, Avg batch loss: 0.2653, Avg batch acc: 0.7907
Train, Epoch: 3, Batch: 980, Step num: 4018, Learning rate: 0.00013944, Avg batch loss: 0.2647, Avg batch acc: 0.7756
Train, Epoch: 3, Batch: 981, Step num: 4019, Learning rate: 0.00013942, Avg batch loss: 0.2665, Avg batch acc: 0.7786
Train, Epoch: 3, Batch: 982, Step num: 4020, Learning rate: 0.00013941, Avg batch loss: 0.3040, Avg batch acc: 0.7793
Train, Epoch: 3, Batch: 983, Step num: 4021, Learning rate: 0.00013939, Avg batch loss: 0.2598, Avg batch acc: 0.7724
Train, Epoch: 3, Batch: 984, Step num: 4022, Learning rate: 0.00013937, Avg batch loss: 0.2692, Avg batch acc: 0.7648
Train, Epoch: 3, Batch: 985, Step num: 4023, Learning rate: 0.00013935, Avg batch loss: 0.2395, Avg batch acc: 0.7817
Train, Epoch: 3, Batch: 986, Step num: 4024, Learning rate: 0.00013934, Avg batch loss: 0.2727, Avg batch acc: 0.7907
Train, Epoch: 3, Batch: 987, Step num: 4025, Learning rate: 0.00013932, Avg batch loss: 0.2571, Avg batch acc: 0.7811
Train, Epoch: 3, Batch: 988, Step num: 4026, Learning rate: 0.00013930, Avg batch loss: 0.2228, Avg batch acc: 0.8099
Train, Epoch: 3, Batch: 989, Step num: 4027, Learning rate: 0.00013928, Avg batch loss: 0.2267, Avg batch acc: 0.7980
Train, Epoch: 3, Batch: 990, Step num: 4028, Learning rate: 0.00013927, Avg batch loss: 0.2659, Avg batch acc: 0.7836
Train, Epoch: 3, Batch: 991, Step num: 4029, Learning rate: 0.00013925, Avg batch loss: 0.2587, Avg batch acc: 0.7861
Train, Epoch: 3, Batch: 992, Step num: 4030, Learning rate: 0.00013923, Avg batch loss: 0.2414, Avg batch acc: 0.7856
Train, Epoch: 3, Batch: 993, Step num: 4031, Learning rate: 0.00013922, Avg batch loss: 0.2625, Avg batch acc: 0.7814
Train, Epoch: 3, Batch: 994, Step num: 4032, Learning rate: 0.00013920, Avg batch loss: 0.2384, Avg batch acc: 0.7806
Train, Epoch: 3, Batch: 995, Step num: 4033, Learning rate: 0.00013918, Avg batch loss: 0.2664, Avg batch acc: 0.7947
Train, Epoch: 3, Batch: 996, Step num: 4034, Learning rate: 0.00013916, Avg batch loss: 0.2299, Avg batch acc: 0.7993
Train, Epoch: 3, Batch: 997, Step num: 4035, Learning rate: 0.00013915, Avg batch loss: 0.2597, Avg batch acc: 0.7712
Train, Epoch: 3, Batch: 998, Step num: 4036, Learning rate: 0.00013913, Avg batch loss: 0.2504, Avg batch acc: 0.7763
Train, Epoch: 3, Batch: 999, Step num: 4037, Learning rate: 0.00013911, Avg batch loss: 0.2532, Avg batch acc: 0.7824
Train, Epoch: 3, Batch: 1000, Step num: 4038, Learning rate: 0.00013910, Avg batch loss: 0.2691, Avg batch acc: 0.7656
Train, Epoch: 3, Batch: 1001, Step num: 4039, Learning rate: 0.00013908, Avg batch loss: 0.2127, Avg batch acc: 0.8084
Train, Epoch: 3, Batch: 1002, Step num: 4040, Learning rate: 0.00013906, Avg batch loss: 0.2549, Avg batch acc: 0.7794
Train, Epoch: 3, Batch: 1003, Step num: 4041, Learning rate: 0.00013904, Avg batch loss: 0.2240, Avg batch acc: 0.8145
Train, Epoch: 3, Batch: 1004, Step num: 4042, Learning rate: 0.00013903, Avg batch loss: 0.2576, Avg batch acc: 0.7737
Train, Epoch: 3, Batch: 1005, Step num: 4043, Learning rate: 0.00013901, Avg batch loss: 0.2396, Avg batch acc: 0.7840
Train, Epoch: 3, Batch: 1006, Step num: 4044, Learning rate: 0.00013899, Avg batch loss: 0.2481, Avg batch acc: 0.7946
Train, Epoch: 3, Batch: 1007, Step num: 4045, Learning rate: 0.00013897, Avg batch loss: 0.2063, Avg batch acc: 0.8134
Train, Epoch: 3, Batch: 1008, Step num: 4046, Learning rate: 0.00013896, Avg batch loss: 0.2258, Avg batch acc: 0.7946
Train, Epoch: 3, Batch: 1009, Step num: 4047, Learning rate: 0.00013894, Avg batch loss: 0.2227, Avg batch acc: 0.8113
Train, Epoch: 3, Batch: 1010, Step num: 4048, Learning rate: 0.00013892, Avg batch loss: 0.2336, Avg batch acc: 0.7855
Train, Epoch: 3, Batch: 1011, Step num: 4049, Learning rate: 0.00013891, Avg batch loss: 0.2320, Avg batch acc: 0.7930
Train, Epoch: 3, Batch: 1012, Step num: 4050, Learning rate: 0.00013889, Avg batch loss: 0.2480, Avg batch acc: 0.8002
Train, Epoch: 3, Batch: 1013, Step num: 4051, Learning rate: 0.00013887, Avg batch loss: 0.2435, Avg batch acc: 0.7913
Train, Epoch: 3, Batch: 1014, Step num: 4052, Learning rate: 0.00013885, Avg batch loss: 0.2384, Avg batch acc: 0.8005
Train, Epoch: 3, Batch: 1015, Step num: 4053, Learning rate: 0.00013884, Avg batch loss: 0.2731, Avg batch acc: 0.7878
Train, Epoch: 3, Batch: 1016, Step num: 4054, Learning rate: 0.00013882, Avg batch loss: 0.2253, Avg batch acc: 0.7930
Train, Epoch: 3, Batch: 1017, Step num: 4055, Learning rate: 0.00013880, Avg batch loss: 0.2580, Avg batch acc: 0.7945
Train, Epoch: 3, Batch: 1018, Step num: 4056, Learning rate: 0.00013879, Avg batch loss: 0.2339, Avg batch acc: 0.8010
Train, Epoch: 3, Batch: 1019, Step num: 4057, Learning rate: 0.00013877, Avg batch loss: 0.2539, Avg batch acc: 0.7832
Train, Epoch: 3, Batch: 1020, Step num: 4058, Learning rate: 0.00013875, Avg batch loss: 0.2657, Avg batch acc: 0.7751
Train, Epoch: 3, Batch: 1021, Step num: 4059, Learning rate: 0.00013873, Avg batch loss: 0.2795, Avg batch acc: 0.7825
Train, Epoch: 3, Batch: 1022, Step num: 4060, Learning rate: 0.00013872, Avg batch loss: 0.2399, Avg batch acc: 0.7880
Train, Epoch: 3, Batch: 1023, Step num: 4061, Learning rate: 0.00013870, Avg batch loss: 0.2644, Avg batch acc: 0.7868
Train, Epoch: 3, Batch: 1024, Step num: 4062, Learning rate: 0.00013868, Avg batch loss: 0.2259, Avg batch acc: 0.8002
Train, Epoch: 3, Batch: 1025, Step num: 4063, Learning rate: 0.00013867, Avg batch loss: 0.2639, Avg batch acc: 0.7832
Train, Epoch: 3, Batch: 1026, Step num: 4064, Learning rate: 0.00013865, Avg batch loss: 0.2277, Avg batch acc: 0.7772
Train, Epoch: 3, Batch: 1027, Step num: 4065, Learning rate: 0.00013863, Avg batch loss: 0.2354, Avg batch acc: 0.8033
Train, Epoch: 3, Batch: 1028, Step num: 4066, Learning rate: 0.00013862, Avg batch loss: 0.2605, Avg batch acc: 0.8130
Train, Epoch: 3, Batch: 1029, Step num: 4067, Learning rate: 0.00013860, Avg batch loss: 0.2263, Avg batch acc: 0.8032
Train, Epoch: 3, Batch: 1030, Step num: 4068, Learning rate: 0.00013858, Avg batch loss: 0.2154, Avg batch acc: 0.8079
Train, Epoch: 3, Batch: 1031, Step num: 4069, Learning rate: 0.00013856, Avg batch loss: 0.2313, Avg batch acc: 0.8112
Train, Epoch: 3, Batch: 1032, Step num: 4070, Learning rate: 0.00013855, Avg batch loss: 0.2097, Avg batch acc: 0.8217
Train, Epoch: 3, Batch: 1033, Step num: 4071, Learning rate: 0.00013853, Avg batch loss: 0.2415, Avg batch acc: 0.8131
Train, Epoch: 3, Batch: 1034, Step num: 4072, Learning rate: 0.00013851, Avg batch loss: 0.3043, Avg batch acc: 0.7833
Train, Epoch: 3, Batch: 1035, Step num: 4073, Learning rate: 0.00013850, Avg batch loss: 0.2368, Avg batch acc: 0.7880
Train, Epoch: 3, Batch: 1036, Step num: 4074, Learning rate: 0.00013848, Avg batch loss: 0.2343, Avg batch acc: 0.7890
Train, Epoch: 3, Batch: 1037, Step num: 4075, Learning rate: 0.00013846, Avg batch loss: 0.2303, Avg batch acc: 0.8139
Train, Epoch: 3, Batch: 1038, Step num: 4076, Learning rate: 0.00013845, Avg batch loss: 0.2678, Avg batch acc: 0.7843
Train, Epoch: 3, Batch: 1039, Step num: 4077, Learning rate: 0.00013843, Avg batch loss: 0.2395, Avg batch acc: 0.8032
Train, Epoch: 3, Batch: 1040, Step num: 4078, Learning rate: 0.00013841, Avg batch loss: 0.2185, Avg batch acc: 0.8121
Train, Epoch: 3, Batch: 1041, Step num: 4079, Learning rate: 0.00013839, Avg batch loss: 0.2441, Avg batch acc: 0.8028
Train, Epoch: 3, Batch: 1042, Step num: 4080, Learning rate: 0.00013838, Avg batch loss: 0.2395, Avg batch acc: 0.8224
Train, Epoch: 3, Batch: 1043, Step num: 4081, Learning rate: 0.00013836, Avg batch loss: 0.2569, Avg batch acc: 0.7956
Train, Epoch: 3, Batch: 1044, Step num: 4082, Learning rate: 0.00013834, Avg batch loss: 0.2153, Avg batch acc: 0.8157
Train, Epoch: 3, Batch: 1045, Step num: 4083, Learning rate: 0.00013833, Avg batch loss: 0.2249, Avg batch acc: 0.8052
Train, Epoch: 3, Batch: 1046, Step num: 4084, Learning rate: 0.00013831, Avg batch loss: 0.2400, Avg batch acc: 0.7847
Train, Epoch: 3, Batch: 1047, Step num: 4085, Learning rate: 0.00013829, Avg batch loss: 0.2069, Avg batch acc: 0.8159
Train, Epoch: 3, Batch: 1048, Step num: 4086, Learning rate: 0.00013828, Avg batch loss: 0.2320, Avg batch acc: 0.8100
Train, Epoch: 3, Batch: 1049, Step num: 4087, Learning rate: 0.00013826, Avg batch loss: 0.2067, Avg batch acc: 0.8338
Train, Epoch: 3, Batch: 1050, Step num: 4088, Learning rate: 0.00013824, Avg batch loss: 0.2131, Avg batch acc: 0.8169
Train, Epoch: 3, Batch: 1051, Step num: 4089, Learning rate: 0.00013822, Avg batch loss: 0.2618, Avg batch acc: 0.7876
Train, Epoch: 3, Batch: 1052, Step num: 4090, Learning rate: 0.00013821, Avg batch loss: 0.2203, Avg batch acc: 0.8144
Train, Epoch: 3, Batch: 1053, Step num: 4091, Learning rate: 0.00013819, Avg batch loss: 0.2177, Avg batch acc: 0.8236
Train, Epoch: 3, Batch: 1054, Step num: 4092, Learning rate: 0.00013817, Avg batch loss: 0.2114, Avg batch acc: 0.8182
Train, Epoch: 3, Batch: 1055, Step num: 4093, Learning rate: 0.00013816, Avg batch loss: 0.2376, Avg batch acc: 0.8064
Train, Epoch: 3, Batch: 1056, Step num: 4094, Learning rate: 0.00013814, Avg batch loss: 0.2096, Avg batch acc: 0.8131
Train, Epoch: 3, Batch: 1057, Step num: 4095, Learning rate: 0.00013812, Avg batch loss: 0.2229, Avg batch acc: 0.7948
Train, Epoch: 3, Batch: 1058, Step num: 4096, Learning rate: 0.00013811, Avg batch loss: 0.2182, Avg batch acc: 0.7938
Train, Epoch: 3, Batch: 1059, Step num: 4097, Learning rate: 0.00013809, Avg batch loss: 0.2039, Avg batch acc: 0.8232
Train, Epoch: 3, Batch: 1060, Step num: 4098, Learning rate: 0.00013807, Avg batch loss: 0.2304, Avg batch acc: 0.7883
Train, Epoch: 3, Batch: 1061, Step num: 4099, Learning rate: 0.00013806, Avg batch loss: 0.2168, Avg batch acc: 0.8238
Train, Epoch: 3, Batch: 1062, Step num: 4100, Learning rate: 0.00013804, Avg batch loss: 0.2605, Avg batch acc: 0.8048
Train, Epoch: 3, Batch: 1063, Step num: 4101, Learning rate: 0.00013802, Avg batch loss: 0.2159, Avg batch acc: 0.8039
Train, Epoch: 3, Batch: 1064, Step num: 4102, Learning rate: 0.00013801, Avg batch loss: 0.2503, Avg batch acc: 0.7993
Train, Epoch: 3, Batch: 1065, Step num: 4103, Learning rate: 0.00013799, Avg batch loss: 0.2375, Avg batch acc: 0.8186
Train, Epoch: 3, Batch: 1066, Step num: 4104, Learning rate: 0.00013797, Avg batch loss: 0.2262, Avg batch acc: 0.8090
Train, Epoch: 3, Batch: 1067, Step num: 4105, Learning rate: 0.00013796, Avg batch loss: 0.2364, Avg batch acc: 0.7949
Train, Epoch: 3, Batch: 1068, Step num: 4106, Learning rate: 0.00013794, Avg batch loss: 0.2045, Avg batch acc: 0.8302
Train, Epoch: 3, Batch: 1069, Step num: 4107, Learning rate: 0.00013792, Avg batch loss: 0.1896, Avg batch acc: 0.8292
Train, Epoch: 3, Batch: 1070, Step num: 4108, Learning rate: 0.00013790, Avg batch loss: 0.2521, Avg batch acc: 0.7988
Train, Epoch: 3, Batch: 1071, Step num: 4109, Learning rate: 0.00013789, Avg batch loss: 0.2351, Avg batch acc: 0.8133
Train, Epoch: 3, Batch: 1072, Step num: 4110, Learning rate: 0.00013787, Avg batch loss: 0.2718, Avg batch acc: 0.7920
Train, Epoch: 3, Batch: 1073, Step num: 4111, Learning rate: 0.00013785, Avg batch loss: 0.2035, Avg batch acc: 0.8191
Train, Epoch: 3, Batch: 1074, Step num: 4112, Learning rate: 0.00013784, Avg batch loss: 0.2084, Avg batch acc: 0.8151
Train, Epoch: 3, Batch: 1075, Step num: 4113, Learning rate: 0.00013782, Avg batch loss: 0.2215, Avg batch acc: 0.8064
Train, Epoch: 3, Batch: 1076, Step num: 4114, Learning rate: 0.00013780, Avg batch loss: 0.2349, Avg batch acc: 0.8058
Train, Epoch: 3, Batch: 1077, Step num: 4115, Learning rate: 0.00013779, Avg batch loss: 0.2245, Avg batch acc: 0.8142
Train, Epoch: 3, Batch: 1078, Step num: 4116, Learning rate: 0.00013777, Avg batch loss: 0.2194, Avg batch acc: 0.8015
Train, Epoch: 3, Batch: 1079, Step num: 4117, Learning rate: 0.00013775, Avg batch loss: 0.2259, Avg batch acc: 0.8194
Train, Epoch: 3, Batch: 1080, Step num: 4118, Learning rate: 0.00013774, Avg batch loss: 0.2451, Avg batch acc: 0.8043
Train, Epoch: 3, Batch: 1081, Step num: 4119, Learning rate: 0.00013772, Avg batch loss: 0.2255, Avg batch acc: 0.8106
Train, Epoch: 3, Batch: 1082, Step num: 4120, Learning rate: 0.00013770, Avg batch loss: 0.2216, Avg batch acc: 0.8258
Train, Epoch: 3, Batch: 1083, Step num: 4121, Learning rate: 0.00013769, Avg batch loss: 0.1967, Avg batch acc: 0.8268
Train, Epoch: 3, Batch: 1084, Step num: 4122, Learning rate: 0.00013767, Avg batch loss: 0.2012, Avg batch acc: 0.8304
Train, Epoch: 3, Batch: 1085, Step num: 4123, Learning rate: 0.00013765, Avg batch loss: 0.2242, Avg batch acc: 0.8116
Train, Epoch: 3, Batch: 1086, Step num: 4124, Learning rate: 0.00013764, Avg batch loss: 0.1944, Avg batch acc: 0.8231
Train, Epoch: 3, Batch: 1087, Step num: 4125, Learning rate: 0.00013762, Avg batch loss: 0.2408, Avg batch acc: 0.8110
Train, Epoch: 3, Batch: 1088, Step num: 4126, Learning rate: 0.00013760, Avg batch loss: 0.2807, Avg batch acc: 0.7908
Train, Epoch: 3, Batch: 1089, Step num: 4127, Learning rate: 0.00013759, Avg batch loss: 0.2119, Avg batch acc: 0.8300
Train, Epoch: 3, Batch: 1090, Step num: 4128, Learning rate: 0.00013757, Avg batch loss: 0.2368, Avg batch acc: 0.8185
Train, Epoch: 3, Batch: 1091, Step num: 4129, Learning rate: 0.00013755, Avg batch loss: 0.2584, Avg batch acc: 0.8054
Train, Epoch: 3, Batch: 1092, Step num: 4130, Learning rate: 0.00013754, Avg batch loss: 0.2202, Avg batch acc: 0.8103
Train, Epoch: 3, Batch: 1093, Step num: 4131, Learning rate: 0.00013752, Avg batch loss: 0.2197, Avg batch acc: 0.8258
Train, Epoch: 3, Batch: 1094, Step num: 4132, Learning rate: 0.00013750, Avg batch loss: 0.2285, Avg batch acc: 0.8156
Train, Epoch: 3, Batch: 1095, Step num: 4133, Learning rate: 0.00013749, Avg batch loss: 0.2097, Avg batch acc: 0.8119
Train, Epoch: 3, Batch: 1096, Step num: 4134, Learning rate: 0.00013747, Avg batch loss: 0.2243, Avg batch acc: 0.8232
Train, Epoch: 3, Batch: 1097, Step num: 4135, Learning rate: 0.00013745, Avg batch loss: 0.2331, Avg batch acc: 0.8109
Train, Epoch: 3, Batch: 1098, Step num: 4136, Learning rate: 0.00013744, Avg batch loss: 0.2446, Avg batch acc: 0.8137
Train, Epoch: 3, Batch: 1099, Step num: 4137, Learning rate: 0.00013742, Avg batch loss: 0.1957, Avg batch acc: 0.8487
Train, Epoch: 3, Batch: 1100, Step num: 4138, Learning rate: 0.00013740, Avg batch loss: 0.2261, Avg batch acc: 0.8222
Train, Epoch: 3, Batch: 1101, Step num: 4139, Learning rate: 0.00013739, Avg batch loss: 0.2224, Avg batch acc: 0.8312
Train, Epoch: 3, Batch: 1102, Step num: 4140, Learning rate: 0.00013737, Avg batch loss: 0.2351, Avg batch acc: 0.8157
Train, Epoch: 3, Batch: 1103, Step num: 4141, Learning rate: 0.00013735, Avg batch loss: 0.2468, Avg batch acc: 0.7900
Train, Epoch: 3, Batch: 1104, Step num: 4142, Learning rate: 0.00013734, Avg batch loss: 0.1914, Avg batch acc: 0.8277
Train, Epoch: 3, Batch: 1105, Step num: 4143, Learning rate: 0.00013732, Avg batch loss: 0.2192, Avg batch acc: 0.8296
Train, Epoch: 3, Batch: 1106, Step num: 4144, Learning rate: 0.00013730, Avg batch loss: 0.2135, Avg batch acc: 0.8223
Train, Epoch: 3, Batch: 1107, Step num: 4145, Learning rate: 0.00013729, Avg batch loss: 0.2425, Avg batch acc: 0.8187
Train, Epoch: 3, Batch: 1108, Step num: 4146, Learning rate: 0.00013727, Avg batch loss: 0.2350, Avg batch acc: 0.8154
Train, Epoch: 3, Batch: 1109, Step num: 4147, Learning rate: 0.00013725, Avg batch loss: 0.2116, Avg batch acc: 0.8289
Train, Epoch: 3, Batch: 1110, Step num: 4148, Learning rate: 0.00013724, Avg batch loss: 0.2081, Avg batch acc: 0.8286
Train, Epoch: 3, Batch: 1111, Step num: 4149, Learning rate: 0.00013722, Avg batch loss: 0.2446, Avg batch acc: 0.8019
Train, Epoch: 3, Batch: 1112, Step num: 4150, Learning rate: 0.00013721, Avg batch loss: 0.2234, Avg batch acc: 0.8125
Train, Epoch: 3, Batch: 1113, Step num: 4151, Learning rate: 0.00013719, Avg batch loss: 0.1922, Avg batch acc: 0.8245
Train, Epoch: 3, Batch: 1114, Step num: 4152, Learning rate: 0.00013717, Avg batch loss: 0.2121, Avg batch acc: 0.8224
Train, Epoch: 3, Batch: 1115, Step num: 4153, Learning rate: 0.00013716, Avg batch loss: 0.2132, Avg batch acc: 0.8100
Train, Epoch: 3, Batch: 1116, Step num: 4154, Learning rate: 0.00013714, Avg batch loss: 0.2176, Avg batch acc: 0.8141
Train, Epoch: 3, Batch: 1117, Step num: 4155, Learning rate: 0.00013712, Avg batch loss: 0.2373, Avg batch acc: 0.8188
Train, Epoch: 3, Batch: 1118, Step num: 4156, Learning rate: 0.00013711, Avg batch loss: 0.2068, Avg batch acc: 0.8227
Train, Epoch: 3, Batch: 1119, Step num: 4157, Learning rate: 0.00013709, Avg batch loss: 0.1888, Avg batch acc: 0.8353
Train, Epoch: 3, Batch: 1120, Step num: 4158, Learning rate: 0.00013707, Avg batch loss: 0.2378, Avg batch acc: 0.8030
Train, Epoch: 3, Batch: 1121, Step num: 4159, Learning rate: 0.00013706, Avg batch loss: 0.2427, Avg batch acc: 0.8190
Train, Epoch: 3, Batch: 1122, Step num: 4160, Learning rate: 0.00013704, Avg batch loss: 0.2101, Avg batch acc: 0.8152
Train, Epoch: 3, Batch: 1123, Step num: 4161, Learning rate: 0.00013702, Avg batch loss: 0.2092, Avg batch acc: 0.8414
Train, Epoch: 3, Batch: 1124, Step num: 4162, Learning rate: 0.00013701, Avg batch loss: 0.2127, Avg batch acc: 0.8356
Train, Epoch: 3, Batch: 1125, Step num: 4163, Learning rate: 0.00013699, Avg batch loss: 0.1924, Avg batch acc: 0.8484
Train, Epoch: 3, Batch: 1126, Step num: 4164, Learning rate: 0.00013697, Avg batch loss: 0.1831, Avg batch acc: 0.8473
Train, Epoch: 3, Batch: 1127, Step num: 4165, Learning rate: 0.00013696, Avg batch loss: 0.2382, Avg batch acc: 0.8068
Train, Epoch: 3, Batch: 1128, Step num: 4166, Learning rate: 0.00013694, Avg batch loss: 0.2456, Avg batch acc: 0.8124
Train, Epoch: 3, Batch: 1129, Step num: 4167, Learning rate: 0.00013693, Avg batch loss: 0.2167, Avg batch acc: 0.8232
Train, Epoch: 3, Batch: 1130, Step num: 4168, Learning rate: 0.00013691, Avg batch loss: 0.2625, Avg batch acc: 0.8019
Train, Epoch: 3, Batch: 1131, Step num: 4169, Learning rate: 0.00013689, Avg batch loss: 0.1902, Avg batch acc: 0.8460
Train, Epoch: 3, Batch: 1132, Step num: 4170, Learning rate: 0.00013688, Avg batch loss: 0.2086, Avg batch acc: 0.8190
Train, Epoch: 3, Batch: 1133, Step num: 4171, Learning rate: 0.00013686, Avg batch loss: 0.2002, Avg batch acc: 0.8396
Train, Epoch: 3, Batch: 1134, Step num: 4172, Learning rate: 0.00013684, Avg batch loss: 0.2013, Avg batch acc: 0.8370
Train, Epoch: 3, Batch: 1135, Step num: 4173, Learning rate: 0.00013683, Avg batch loss: 0.2543, Avg batch acc: 0.8201
Train, Epoch: 3, Batch: 1136, Step num: 4174, Learning rate: 0.00013681, Avg batch loss: 0.2321, Avg batch acc: 0.8198
Train, Epoch: 3, Batch: 1137, Step num: 4175, Learning rate: 0.00013679, Avg batch loss: 0.1968, Avg batch acc: 0.8393
Train, Epoch: 3, Batch: 1138, Step num: 4176, Learning rate: 0.00013678, Avg batch loss: 0.1939, Avg batch acc: 0.8390
Train, Epoch: 3, Batch: 1139, Step num: 4177, Learning rate: 0.00013676, Avg batch loss: 0.1952, Avg batch acc: 0.8476
Train, Epoch: 3, Batch: 1140, Step num: 4178, Learning rate: 0.00013674, Avg batch loss: 0.1868, Avg batch acc: 0.8353
Train, Epoch: 3, Batch: 1141, Step num: 4179, Learning rate: 0.00013673, Avg batch loss: 0.2249, Avg batch acc: 0.8195
Train, Epoch: 3, Batch: 1142, Step num: 4180, Learning rate: 0.00013671, Avg batch loss: 0.2223, Avg batch acc: 0.8274
Train, Epoch: 3, Batch: 1143, Step num: 4181, Learning rate: 0.00013670, Avg batch loss: 0.1899, Avg batch acc: 0.8485
Train, Epoch: 3, Batch: 1144, Step num: 4182, Learning rate: 0.00013668, Avg batch loss: 0.1825, Avg batch acc: 0.8385
Train, Epoch: 3, Batch: 1145, Step num: 4183, Learning rate: 0.00013666, Avg batch loss: 0.2045, Avg batch acc: 0.8255
Train, Epoch: 3, Batch: 1146, Step num: 4184, Learning rate: 0.00013665, Avg batch loss: 0.2123, Avg batch acc: 0.8183
Train, Epoch: 3, Batch: 1147, Step num: 4185, Learning rate: 0.00013663, Avg batch loss: 0.2051, Avg batch acc: 0.8158
Train, Epoch: 3, Batch: 1148, Step num: 4186, Learning rate: 0.00013661, Avg batch loss: 0.2428, Avg batch acc: 0.8202
Train, Epoch: 3, Batch: 1149, Step num: 4187, Learning rate: 0.00013660, Avg batch loss: 0.2048, Avg batch acc: 0.8349
Train, Epoch: 3, Batch: 1150, Step num: 4188, Learning rate: 0.00013658, Avg batch loss: 0.1869, Avg batch acc: 0.8489
Train, Epoch: 3, Batch: 1151, Step num: 4189, Learning rate: 0.00013657, Avg batch loss: 0.1997, Avg batch acc: 0.8356
Train, Epoch: 3, Batch: 1152, Step num: 4190, Learning rate: 0.00013655, Avg batch loss: 0.1800, Avg batch acc: 0.8468
Train, Epoch: 3, Batch: 1153, Step num: 4191, Learning rate: 0.00013653, Avg batch loss: 0.1779, Avg batch acc: 0.8529
Train, Epoch: 3, Batch: 1154, Step num: 4192, Learning rate: 0.00013652, Avg batch loss: 0.1783, Avg batch acc: 0.8485
Train, Epoch: 3, Batch: 1155, Step num: 4193, Learning rate: 0.00013650, Avg batch loss: 0.2555, Avg batch acc: 0.8063
Train, Epoch: 3, Batch: 1156, Step num: 4194, Learning rate: 0.00013648, Avg batch loss: 0.2099, Avg batch acc: 0.8225
Train, Epoch: 3, Batch: 1157, Step num: 4195, Learning rate: 0.00013647, Avg batch loss: 0.2151, Avg batch acc: 0.8326
Train, Epoch: 3, Batch: 1158, Step num: 4196, Learning rate: 0.00013645, Avg batch loss: 0.2043, Avg batch acc: 0.8448
Train, Epoch: 3, Batch: 1159, Step num: 4197, Learning rate: 0.00013643, Avg batch loss: 0.1907, Avg batch acc: 0.8375
Train, Epoch: 3, Batch: 1160, Step num: 4198, Learning rate: 0.00013642, Avg batch loss: 0.2506, Avg batch acc: 0.8109
Train, Epoch: 3, Batch: 1161, Step num: 4199, Learning rate: 0.00013640, Avg batch loss: 0.2129, Avg batch acc: 0.8164
Train, Epoch: 3, Batch: 1162, Step num: 4200, Learning rate: 0.00013639, Avg batch loss: 0.1998, Avg batch acc: 0.8453
Train, Epoch: 3, Batch: 1163, Step num: 4201, Learning rate: 0.00013637, Avg batch loss: 0.1875, Avg batch acc: 0.8342
Train, Epoch: 3, Batch: 1164, Step num: 4202, Learning rate: 0.00013635, Avg batch loss: 0.1782, Avg batch acc: 0.8639
Train, Epoch: 3, Batch: 1165, Step num: 4203, Learning rate: 0.00013634, Avg batch loss: 0.2098, Avg batch acc: 0.8407
Train, Epoch: 3, Batch: 1166, Step num: 4204, Learning rate: 0.00013632, Avg batch loss: 0.1918, Avg batch acc: 0.8419
Train, Epoch: 3, Batch: 1167, Step num: 4205, Learning rate: 0.00013631, Avg batch loss: 0.1722, Avg batch acc: 0.8566
Train, Epoch: 3, Batch: 1168, Step num: 4206, Learning rate: 0.00013629, Avg batch loss: 0.1823, Avg batch acc: 0.8321
Train, Epoch: 3, Batch: 1169, Step num: 4207, Learning rate: 0.00013627, Avg batch loss: 0.2103, Avg batch acc: 0.8367
Train, Epoch: 3, Batch: 1170, Step num: 4208, Learning rate: 0.00013626, Avg batch loss: 0.1872, Avg batch acc: 0.8568
Train, Epoch: 3, Batch: 1171, Step num: 4209, Learning rate: 0.00013624, Avg batch loss: 0.1924, Avg batch acc: 0.8397
Train, Epoch: 3, Batch: 1172, Step num: 4210, Learning rate: 0.00013622, Avg batch loss: 0.2000, Avg batch acc: 0.8305
Train, Epoch: 3, Batch: 1173, Step num: 4211, Learning rate: 0.00013621, Avg batch loss: 0.2187, Avg batch acc: 0.8267
Train, Epoch: 3, Batch: 1174, Step num: 4212, Learning rate: 0.00013619, Avg batch loss: 0.2011, Avg batch acc: 0.8418
Train, Epoch: 3, Batch: 1175, Step num: 4213, Learning rate: 0.00013618, Avg batch loss: 0.2382, Avg batch acc: 0.8227
Train, Epoch: 3, Batch: 1176, Step num: 4214, Learning rate: 0.00013616, Avg batch loss: 0.1938, Avg batch acc: 0.8499
Train, Epoch: 3, Batch: 1177, Step num: 4215, Learning rate: 0.00013614, Avg batch loss: 0.1919, Avg batch acc: 0.8322
Train, Epoch: 3, Batch: 1178, Step num: 4216, Learning rate: 0.00013613, Avg batch loss: 0.2169, Avg batch acc: 0.8255
Train, Epoch: 3, Batch: 1179, Step num: 4217, Learning rate: 0.00013611, Avg batch loss: 0.2316, Avg batch acc: 0.8310
Train, Epoch: 3, Batch: 1180, Step num: 4218, Learning rate: 0.00013609, Avg batch loss: 0.1850, Avg batch acc: 0.8445
Train, Epoch: 3, Batch: 1181, Step num: 4219, Learning rate: 0.00013608, Avg batch loss: 0.1947, Avg batch acc: 0.8424
Train, Epoch: 3, Batch: 1182, Step num: 4220, Learning rate: 0.00013606, Avg batch loss: 0.1743, Avg batch acc: 0.8369
Train, Epoch: 3, Batch: 1183, Step num: 4221, Learning rate: 0.00013605, Avg batch loss: 0.1671, Avg batch acc: 0.8603
Train, Epoch: 3, Batch: 1184, Step num: 4222, Learning rate: 0.00013603, Avg batch loss: 0.1970, Avg batch acc: 0.8454
Train, Epoch: 3, Batch: 1185, Step num: 4223, Learning rate: 0.00013601, Avg batch loss: 0.2058, Avg batch acc: 0.8359
Train, Epoch: 3, Batch: 1186, Step num: 4224, Learning rate: 0.00013600, Avg batch loss: 0.1785, Avg batch acc: 0.8565
Train, Epoch: 3, Batch: 1187, Step num: 4225, Learning rate: 0.00013598, Avg batch loss: 0.2146, Avg batch acc: 0.8411
Train, Epoch: 3, Batch: 1188, Step num: 4226, Learning rate: 0.00013597, Avg batch loss: 0.2038, Avg batch acc: 0.8383
Train, Epoch: 3, Batch: 1189, Step num: 4227, Learning rate: 0.00013595, Avg batch loss: 0.2045, Avg batch acc: 0.8333
Train, Epoch: 3, Batch: 1190, Step num: 4228, Learning rate: 0.00013593, Avg batch loss: 0.2056, Avg batch acc: 0.8227
Train, Epoch: 3, Batch: 1191, Step num: 4229, Learning rate: 0.00013592, Avg batch loss: 0.1922, Avg batch acc: 0.8398
Train, Epoch: 3, Batch: 1192, Step num: 4230, Learning rate: 0.00013590, Avg batch loss: 0.1960, Avg batch acc: 0.8447
Train, Epoch: 3, Batch: 1193, Step num: 4231, Learning rate: 0.00013589, Avg batch loss: 0.1888, Avg batch acc: 0.8495
Train, Epoch: 3, Batch: 1194, Step num: 4232, Learning rate: 0.00013587, Avg batch loss: 0.1834, Avg batch acc: 0.8551
Train, Epoch: 3, Batch: 1195, Step num: 4233, Learning rate: 0.00013585, Avg batch loss: 0.1897, Avg batch acc: 0.8458
Train, Epoch: 3, Batch: 1196, Step num: 4234, Learning rate: 0.00013584, Avg batch loss: 0.2146, Avg batch acc: 0.8409
Train, Epoch: 3, Batch: 1197, Step num: 4235, Learning rate: 0.00013582, Avg batch loss: 0.1984, Avg batch acc: 0.8437
Train, Epoch: 3, Batch: 1198, Step num: 4236, Learning rate: 0.00013581, Avg batch loss: 0.2107, Avg batch acc: 0.8443
Train, Epoch: 3, Batch: 1199, Step num: 4237, Learning rate: 0.00013579, Avg batch loss: 0.2097, Avg batch acc: 0.8329
Train, Epoch: 3, Batch: 1200, Step num: 4238, Learning rate: 0.00013577, Avg batch loss: 0.1820, Avg batch acc: 0.8395
Train, Epoch: 3, Batch: 1201, Step num: 4239, Learning rate: 0.00013576, Avg batch loss: 0.2025, Avg batch acc: 0.8426
Train, Epoch: 3, Batch: 1202, Step num: 4240, Learning rate: 0.00013574, Avg batch loss: 0.1847, Avg batch acc: 0.8491
Train, Epoch: 3, Batch: 1203, Step num: 4241, Learning rate: 0.00013573, Avg batch loss: 0.1916, Avg batch acc: 0.8458
Train, Epoch: 3, Batch: 1204, Step num: 4242, Learning rate: 0.00013571, Avg batch loss: 0.1666, Avg batch acc: 0.8671
Train, Epoch: 3, Batch: 1205, Step num: 4243, Learning rate: 0.00013569, Avg batch loss: 0.1667, Avg batch acc: 0.8540
Train, Epoch: 3, Batch: 1206, Step num: 4244, Learning rate: 0.00013568, Avg batch loss: 0.1704, Avg batch acc: 0.8546
Train, Epoch: 3, Batch: 1207, Step num: 4245, Learning rate: 0.00013566, Avg batch loss: 0.1646, Avg batch acc: 0.8444
Train, Epoch: 3, Batch: 1208, Step num: 4246, Learning rate: 0.00013565, Avg batch loss: 0.1971, Avg batch acc: 0.8420
Train, Epoch: 3, Batch: 1209, Step num: 4247, Learning rate: 0.00013563, Avg batch loss: 0.1739, Avg batch acc: 0.8553
Train, Epoch: 3, Batch: 1210, Step num: 4248, Learning rate: 0.00013561, Avg batch loss: 0.1914, Avg batch acc: 0.8498
Train, Epoch: 3, Batch: 1211, Step num: 4249, Learning rate: 0.00013560, Avg batch loss: 0.1762, Avg batch acc: 0.8432
Train, Epoch: 3, Batch: 1212, Step num: 4250, Learning rate: 0.00013558, Avg batch loss: 0.1801, Avg batch acc: 0.8561
Train, Epoch: 3, Batch: 1213, Step num: 4251, Learning rate: 0.00013557, Avg batch loss: 0.1600, Avg batch acc: 0.8706
Train, Epoch: 3, Batch: 1214, Step num: 4252, Learning rate: 0.00013555, Avg batch loss: 0.1824, Avg batch acc: 0.8487
Train, Epoch: 3, Batch: 1215, Step num: 4253, Learning rate: 0.00013553, Avg batch loss: 0.1961, Avg batch acc: 0.8358
Train, Epoch: 3, Batch: 1216, Step num: 4254, Learning rate: 0.00013552, Avg batch loss: 0.2028, Avg batch acc: 0.8298
Train, Epoch: 3, Batch: 1217, Step num: 4255, Learning rate: 0.00013550, Avg batch loss: 0.2155, Avg batch acc: 0.8332
Train, Epoch: 3, Batch: 1218, Step num: 4256, Learning rate: 0.00013549, Avg batch loss: 0.1844, Avg batch acc: 0.8475
Train, Epoch: 3, Batch: 1219, Step num: 4257, Learning rate: 0.00013547, Avg batch loss: 0.1598, Avg batch acc: 0.8625
Train, Epoch: 3, Batch: 1220, Step num: 4258, Learning rate: 0.00013545, Avg batch loss: 0.1549, Avg batch acc: 0.8663
Train, Epoch: 3, Batch: 1221, Step num: 4259, Learning rate: 0.00013544, Avg batch loss: 0.1916, Avg batch acc: 0.8507
Train, Epoch: 3, Batch: 1222, Step num: 4260, Learning rate: 0.00013542, Avg batch loss: 0.1569, Avg batch acc: 0.8667
Train, Epoch: 3, Batch: 1223, Step num: 4261, Learning rate: 0.00013541, Avg batch loss: 0.1826, Avg batch acc: 0.8299
Train, Epoch: 3, Batch: 1224, Step num: 4262, Learning rate: 0.00013539, Avg batch loss: 0.1718, Avg batch acc: 0.8529
Train, Epoch: 3, Batch: 1225, Step num: 4263, Learning rate: 0.00013537, Avg batch loss: 0.2080, Avg batch acc: 0.8398
Train, Epoch: 3, Batch: 1226, Step num: 4264, Learning rate: 0.00013536, Avg batch loss: 0.1640, Avg batch acc: 0.8581
Train, Epoch: 3, Batch: 1227, Step num: 4265, Learning rate: 0.00013534, Avg batch loss: 0.1762, Avg batch acc: 0.8607
Train, Epoch: 3, Batch: 1228, Step num: 4266, Learning rate: 0.00013533, Avg batch loss: 0.1852, Avg batch acc: 0.8631
Train, Epoch: 3, Batch: 1229, Step num: 4267, Learning rate: 0.00013531, Avg batch loss: 0.1538, Avg batch acc: 0.8609
Train, Epoch: 3, Batch: 1230, Step num: 4268, Learning rate: 0.00013530, Avg batch loss: 0.1691, Avg batch acc: 0.8672
Train, Epoch: 3, Batch: 1231, Step num: 4269, Learning rate: 0.00013528, Avg batch loss: 0.1635, Avg batch acc: 0.8600
Train, Epoch: 3, Batch: 1232, Step num: 4270, Learning rate: 0.00013526, Avg batch loss: 0.1805, Avg batch acc: 0.8332
Train, Epoch: 3, Batch: 1233, Step num: 4271, Learning rate: 0.00013525, Avg batch loss: 0.1709, Avg batch acc: 0.8533
Train, Epoch: 3, Batch: 1234, Step num: 4272, Learning rate: 0.00013523, Avg batch loss: 0.1817, Avg batch acc: 0.8530
Train, Epoch: 3, Batch: 1235, Step num: 4273, Learning rate: 0.00013522, Avg batch loss: 0.1756, Avg batch acc: 0.8554
Train, Epoch: 3, Batch: 1236, Step num: 4274, Learning rate: 0.00013520, Avg batch loss: 0.1886, Avg batch acc: 0.8528
Train, Epoch: 3, Batch: 1237, Step num: 4275, Learning rate: 0.00013518, Avg batch loss: 0.2053, Avg batch acc: 0.8425
Train, Epoch: 3, Batch: 1238, Step num: 4276, Learning rate: 0.00013517, Avg batch loss: 0.1815, Avg batch acc: 0.8701
Train, Epoch: 3, Batch: 1239, Step num: 4277, Learning rate: 0.00013515, Avg batch loss: 0.1648, Avg batch acc: 0.8644
Train, Epoch: 3, Batch: 1240, Step num: 4278, Learning rate: 0.00013514, Avg batch loss: 0.1560, Avg batch acc: 0.8585
Train, Epoch: 3, Batch: 1241, Step num: 4279, Learning rate: 0.00013512, Avg batch loss: 0.1830, Avg batch acc: 0.8427
Train, Epoch: 3, Batch: 1242, Step num: 4280, Learning rate: 0.00013511, Avg batch loss: 0.1494, Avg batch acc: 0.8730
Train, Epoch: 3, Batch: 1243, Step num: 4281, Learning rate: 0.00013509, Avg batch loss: 0.1734, Avg batch acc: 0.8540
Train, Epoch: 3, Batch: 1244, Step num: 4282, Learning rate: 0.00013507, Avg batch loss: 0.1777, Avg batch acc: 0.8645
Train, Epoch: 3, Batch: 1245, Step num: 4283, Learning rate: 0.00013506, Avg batch loss: 0.1821, Avg batch acc: 0.8618
Train, Epoch: 3, Batch: 1246, Step num: 4284, Learning rate: 0.00013504, Avg batch loss: 0.1826, Avg batch acc: 0.8446
Train, Epoch: 3, Batch: 1247, Step num: 4285, Learning rate: 0.00013503, Avg batch loss: 0.1774, Avg batch acc: 0.8517
Train, Epoch: 3, Batch: 1248, Step num: 4286, Learning rate: 0.00013501, Avg batch loss: 0.1572, Avg batch acc: 0.8678
Train, Epoch: 3, Batch: 1249, Step num: 4287, Learning rate: 0.00013500, Avg batch loss: 0.1494, Avg batch acc: 0.8568
Train, Epoch: 3, Batch: 1250, Step num: 4288, Learning rate: 0.00013498, Avg batch loss: 0.1626, Avg batch acc: 0.8601
Train, Epoch: 3, Batch: 1251, Step num: 4289, Learning rate: 0.00013496, Avg batch loss: 0.1556, Avg batch acc: 0.8722
Train, Epoch: 3, Batch: 1252, Step num: 4290, Learning rate: 0.00013495, Avg batch loss: 0.1870, Avg batch acc: 0.8422
Train, Epoch: 3, Batch: 1253, Step num: 4291, Learning rate: 0.00013493, Avg batch loss: 0.1630, Avg batch acc: 0.8725
Train, Epoch: 3, Batch: 1254, Step num: 4292, Learning rate: 0.00013492, Avg batch loss: 0.1541, Avg batch acc: 0.8669
Train, Epoch: 3, Batch: 1255, Step num: 4293, Learning rate: 0.00013490, Avg batch loss: 0.1738, Avg batch acc: 0.8609
Train, Epoch: 3, Batch: 1256, Step num: 4294, Learning rate: 0.00013489, Avg batch loss: 0.1938, Avg batch acc: 0.8460
Train, Epoch: 3, Batch: 1257, Step num: 4295, Learning rate: 0.00013487, Avg batch loss: 0.1664, Avg batch acc: 0.8589
Train, Epoch: 3, Batch: 1258, Step num: 4296, Learning rate: 0.00013485, Avg batch loss: 0.1549, Avg batch acc: 0.8723
Train, Epoch: 3, Batch: 1259, Step num: 4297, Learning rate: 0.00013484, Avg batch loss: 0.1544, Avg batch acc: 0.8669
Train, Epoch: 3, Batch: 1260, Step num: 4298, Learning rate: 0.00013482, Avg batch loss: 0.1602, Avg batch acc: 0.8640
Train, Epoch: 3, Batch: 1261, Step num: 4299, Learning rate: 0.00013481, Avg batch loss: 0.2023, Avg batch acc: 0.8555
Train, Epoch: 3, Batch: 1262, Step num: 4300, Learning rate: 0.00013479, Avg batch loss: 0.1785, Avg batch acc: 0.8736
Train, Epoch: 3, Batch: 1263, Step num: 4301, Learning rate: 0.00013478, Avg batch loss: 0.1905, Avg batch acc: 0.8608
Train, Epoch: 3, Batch: 1264, Step num: 4302, Learning rate: 0.00013476, Avg batch loss: 0.1691, Avg batch acc: 0.8752
Train, Epoch: 3, Batch: 1265, Step num: 4303, Learning rate: 0.00013474, Avg batch loss: 0.1673, Avg batch acc: 0.8596
Train, Epoch: 3, Batch: 1266, Step num: 4304, Learning rate: 0.00013473, Avg batch loss: 0.1856, Avg batch acc: 0.8521
Train, Epoch: 3, Batch: 1267, Step num: 4305, Learning rate: 0.00013471, Avg batch loss: 0.1725, Avg batch acc: 0.8638
Train, Epoch: 3, Batch: 1268, Step num: 4306, Learning rate: 0.00013470, Avg batch loss: 0.1914, Avg batch acc: 0.8527
Train, Epoch: 3, Batch: 1269, Step num: 4307, Learning rate: 0.00013468, Avg batch loss: 0.1934, Avg batch acc: 0.8496
Train, Epoch: 3, Batch: 1270, Step num: 4308, Learning rate: 0.00013467, Avg batch loss: 0.1730, Avg batch acc: 0.8561
Train, Epoch: 3, Batch: 1271, Step num: 4309, Learning rate: 0.00013465, Avg batch loss: 0.1628, Avg batch acc: 0.8578
Train, Epoch: 3, Batch: 1272, Step num: 4310, Learning rate: 0.00013463, Avg batch loss: 0.1981, Avg batch acc: 0.8410
Train, Epoch: 3, Batch: 1273, Step num: 4311, Learning rate: 0.00013462, Avg batch loss: 0.1564, Avg batch acc: 0.8582
Train, Epoch: 3, Batch: 1274, Step num: 4312, Learning rate: 0.00013460, Avg batch loss: 0.1792, Avg batch acc: 0.8448
Train, Epoch: 3, Batch: 1275, Step num: 4313, Learning rate: 0.00013459, Avg batch loss: 0.1569, Avg batch acc: 0.8646
Train, Epoch: 3, Batch: 1276, Step num: 4314, Learning rate: 0.00013457, Avg batch loss: 0.1618, Avg batch acc: 0.8726
Train, Epoch: 3, Batch: 1277, Step num: 4315, Learning rate: 0.00013456, Avg batch loss: 0.1612, Avg batch acc: 0.8601
Train, Epoch: 3, Batch: 1278, Step num: 4316, Learning rate: 0.00013454, Avg batch loss: 0.1710, Avg batch acc: 0.8578
Train, Epoch: 3, Batch: 1279, Step num: 4317, Learning rate: 0.00013453, Avg batch loss: 0.1628, Avg batch acc: 0.8713
Train, Epoch: 3, Batch: 1280, Step num: 4318, Learning rate: 0.00013451, Avg batch loss: 0.2060, Avg batch acc: 0.8552
Train, Epoch: 3, Batch: 1281, Step num: 4319, Learning rate: 0.00013449, Avg batch loss: 0.1494, Avg batch acc: 0.8601
Train, Epoch: 3, Batch: 1282, Step num: 4320, Learning rate: 0.00013448, Avg batch loss: 0.1746, Avg batch acc: 0.8601
Train, Epoch: 3, Batch: 1283, Step num: 4321, Learning rate: 0.00013446, Avg batch loss: 0.1771, Avg batch acc: 0.8670
Train, Epoch: 3, Batch: 1284, Step num: 4322, Learning rate: 0.00013445, Avg batch loss: 0.2074, Avg batch acc: 0.8429
Train, Epoch: 3, Batch: 1285, Step num: 4323, Learning rate: 0.00013443, Avg batch loss: 0.1498, Avg batch acc: 0.8668
Train, Epoch: 3, Batch: 1286, Step num: 4324, Learning rate: 0.00013442, Avg batch loss: 0.1800, Avg batch acc: 0.8652
Train, Epoch: 3, Batch: 1287, Step num: 4325, Learning rate: 0.00013440, Avg batch loss: 0.1419, Avg batch acc: 0.8699
Train, Epoch: 3, Batch: 1288, Step num: 4326, Learning rate: 0.00013439, Avg batch loss: 0.1536, Avg batch acc: 0.8661
Train, Epoch: 3, Batch: 1289, Step num: 4327, Learning rate: 0.00013437, Avg batch loss: 0.1897, Avg batch acc: 0.8443
Train, Epoch: 3, Batch: 1290, Step num: 4328, Learning rate: 0.00013435, Avg batch loss: 0.1571, Avg batch acc: 0.8673
Train, Epoch: 3, Batch: 1291, Step num: 4329, Learning rate: 0.00013434, Avg batch loss: 0.1458, Avg batch acc: 0.8756
Train, Epoch: 3, Batch: 1292, Step num: 4330, Learning rate: 0.00013432, Avg batch loss: 0.1477, Avg batch acc: 0.8779
Train, Epoch: 3, Batch: 1293, Step num: 4331, Learning rate: 0.00013431, Avg batch loss: 0.1698, Avg batch acc: 0.8625
Train, Epoch: 3, Batch: 1294, Step num: 4332, Learning rate: 0.00013429, Avg batch loss: 0.1546, Avg batch acc: 0.8656
Train, Epoch: 3, Batch: 1295, Step num: 4333, Learning rate: 0.00013428, Avg batch loss: 0.1853, Avg batch acc: 0.8577
Train, Epoch: 3, Batch: 1296, Step num: 4334, Learning rate: 0.00013426, Avg batch loss: 0.1351, Avg batch acc: 0.8879
Train, Epoch: 3, Batch: 1297, Step num: 4335, Learning rate: 0.00013425, Avg batch loss: 0.1584, Avg batch acc: 0.8639
Train, Epoch: 3, Batch: 1298, Step num: 4336, Learning rate: 0.00013423, Avg batch loss: 0.1379, Avg batch acc: 0.8801
Train, Epoch: 3, Batch: 1299, Step num: 4337, Learning rate: 0.00013421, Avg batch loss: 0.1331, Avg batch acc: 0.8822
Train, Epoch: 3, Batch: 1300, Step num: 4338, Learning rate: 0.00013420, Avg batch loss: 0.1920, Avg batch acc: 0.8579
Train, Epoch: 3, Batch: 1301, Step num: 4339, Learning rate: 0.00013418, Avg batch loss: 0.1652, Avg batch acc: 0.8693
Train, Epoch: 3, Batch: 1302, Step num: 4340, Learning rate: 0.00013417, Avg batch loss: 0.1553, Avg batch acc: 0.8744
Train, Epoch: 3, Batch: 1303, Step num: 4341, Learning rate: 0.00013415, Avg batch loss: 0.1631, Avg batch acc: 0.8713
Train, Epoch: 3, Batch: 1304, Step num: 4342, Learning rate: 0.00013414, Avg batch loss: 0.1560, Avg batch acc: 0.8683
Train, Epoch: 3, Batch: 1305, Step num: 4343, Learning rate: 0.00013412, Avg batch loss: 0.1766, Avg batch acc: 0.8558
Train, Epoch: 3, Batch: 1306, Step num: 4344, Learning rate: 0.00013411, Avg batch loss: 0.1416, Avg batch acc: 0.8916
Train, Epoch: 3, Batch: 1307, Step num: 4345, Learning rate: 0.00013409, Avg batch loss: 0.1706, Avg batch acc: 0.8655
Train, Epoch: 3, Batch: 1308, Step num: 4346, Learning rate: 0.00013408, Avg batch loss: 0.1604, Avg batch acc: 0.8662
Train, Epoch: 3, Batch: 1309, Step num: 4347, Learning rate: 0.00013406, Avg batch loss: 0.1567, Avg batch acc: 0.8716
Train, Epoch: 3, Batch: 1310, Step num: 4348, Learning rate: 0.00013404, Avg batch loss: 0.1445, Avg batch acc: 0.8814
Train, Epoch: 3, Batch: 1311, Step num: 4349, Learning rate: 0.00013403, Avg batch loss: 0.1598, Avg batch acc: 0.8699
Train, Epoch: 3, Batch: 1312, Step num: 4350, Learning rate: 0.00013401, Avg batch loss: 0.1734, Avg batch acc: 0.8640
Train, Epoch: 3, Batch: 1313, Step num: 4351, Learning rate: 0.00013400, Avg batch loss: 0.1714, Avg batch acc: 0.8687
Train, Epoch: 3, Batch: 1314, Step num: 4352, Learning rate: 0.00013398, Avg batch loss: 0.1619, Avg batch acc: 0.8681
Train, Epoch: 3, Batch: 1315, Step num: 4353, Learning rate: 0.00013397, Avg batch loss: 0.1718, Avg batch acc: 0.8628
Train, Epoch: 3, Batch: 1316, Step num: 4354, Learning rate: 0.00013395, Avg batch loss: 0.1278, Avg batch acc: 0.8971
Train, Epoch: 3, Batch: 1317, Step num: 4355, Learning rate: 0.00013394, Avg batch loss: 0.1672, Avg batch acc: 0.8674
Train, Epoch: 3, Batch: 1318, Step num: 4356, Learning rate: 0.00013392, Avg batch loss: 0.1581, Avg batch acc: 0.8632
Train, Epoch: 3, Batch: 1319, Step num: 4357, Learning rate: 0.00013391, Avg batch loss: 0.1632, Avg batch acc: 0.8679
Train, Epoch: 3, Batch: 1320, Step num: 4358, Learning rate: 0.00013389, Avg batch loss: 0.1948, Avg batch acc: 0.8538
Train, Epoch: 3, Batch: 1321, Step num: 4359, Learning rate: 0.00013388, Avg batch loss: 0.1543, Avg batch acc: 0.8668
Train, Epoch: 3, Batch: 1322, Step num: 4360, Learning rate: 0.00013386, Avg batch loss: 0.1228, Avg batch acc: 0.8834
Train, Epoch: 3, Batch: 1323, Step num: 4361, Learning rate: 0.00013384, Avg batch loss: 0.1495, Avg batch acc: 0.8672
Train, Epoch: 3, Batch: 1324, Step num: 4362, Learning rate: 0.00013383, Avg batch loss: 0.1702, Avg batch acc: 0.8608
Train, Epoch: 3, Batch: 1325, Step num: 4363, Learning rate: 0.00013381, Avg batch loss: 0.1587, Avg batch acc: 0.8701
Train, Epoch: 3, Batch: 1326, Step num: 4364, Learning rate: 0.00013380, Avg batch loss: 0.1571, Avg batch acc: 0.8662
Train, Epoch: 3, Batch: 1327, Step num: 4365, Learning rate: 0.00013378, Avg batch loss: 0.1331, Avg batch acc: 0.8773
Train, Epoch: 3, Batch: 1328, Step num: 4366, Learning rate: 0.00013377, Avg batch loss: 0.1933, Avg batch acc: 0.8509
Train, Epoch: 3, Batch: 1329, Step num: 4367, Learning rate: 0.00013375, Avg batch loss: 0.1708, Avg batch acc: 0.8627
Train, Epoch: 3, Batch: 1330, Step num: 4368, Learning rate: 0.00013374, Avg batch loss: 0.1736, Avg batch acc: 0.8651
Train, Epoch: 3, Batch: 1331, Step num: 4369, Learning rate: 0.00013372, Avg batch loss: 0.1794, Avg batch acc: 0.8660
Train, Epoch: 3, Batch: 1332, Step num: 4370, Learning rate: 0.00013371, Avg batch loss: 0.1713, Avg batch acc: 0.8650
Train, Epoch: 3, Batch: 1333, Step num: 4371, Learning rate: 0.00013369, Avg batch loss: 0.1422, Avg batch acc: 0.8811
Train, Epoch: 3, Batch: 1334, Step num: 4372, Learning rate: 0.00013368, Avg batch loss: 0.1775, Avg batch acc: 0.8577
Train, Epoch: 3, Batch: 1335, Step num: 4373, Learning rate: 0.00013366, Avg batch loss: 0.1925, Avg batch acc: 0.8358
Train, Epoch: 3, Batch: 1336, Step num: 4374, Learning rate: 0.00013365, Avg batch loss: 0.1565, Avg batch acc: 0.8718
Train, Epoch: 3, Batch: 1337, Step num: 4375, Learning rate: 0.00013363, Avg batch loss: 0.1541, Avg batch acc: 0.8790
Train, Epoch: 3, Batch: 1338, Step num: 4376, Learning rate: 0.00013362, Avg batch loss: 0.1395, Avg batch acc: 0.8730
Train, Epoch: 3, Batch: 1339, Step num: 4377, Learning rate: 0.00013360, Avg batch loss: 0.1459, Avg batch acc: 0.8691
Train, Epoch: 3, Batch: 1340, Step num: 4378, Learning rate: 0.00013358, Avg batch loss: 0.1387, Avg batch acc: 0.8806
Train, Epoch: 3, Batch: 1341, Step num: 4379, Learning rate: 0.00013357, Avg batch loss: 0.1939, Avg batch acc: 0.8628
Train, Epoch: 3, Batch: 1342, Step num: 4380, Learning rate: 0.00013355, Avg batch loss: 0.1360, Avg batch acc: 0.8824
Train, Epoch: 3, Batch: 1343, Step num: 4381, Learning rate: 0.00013354, Avg batch loss: 0.1655, Avg batch acc: 0.8700
Train, Epoch: 3, Batch: 1344, Step num: 4382, Learning rate: 0.00013352, Avg batch loss: 0.1364, Avg batch acc: 0.8882
Train, Epoch: 3, Batch: 1345, Step num: 4383, Learning rate: 0.00013351, Avg batch loss: 0.1567, Avg batch acc: 0.8772
Train, Epoch: 3, Batch: 1346, Step num: 4384, Learning rate: 0.00013349, Avg batch loss: 0.1637, Avg batch acc: 0.8777
Train, Epoch: 3, Batch: 1347, Step num: 4385, Learning rate: 0.00013348, Avg batch loss: 0.1484, Avg batch acc: 0.8833
Train, Epoch: 3, Batch: 1348, Step num: 4386, Learning rate: 0.00013346, Avg batch loss: 0.1431, Avg batch acc: 0.8605
Train, Epoch: 3, Batch: 1349, Step num: 4387, Learning rate: 0.00013345, Avg batch loss: 0.1945, Avg batch acc: 0.8482
Train, Epoch: 3, Batch: 1350, Step num: 4388, Learning rate: 0.00013343, Avg batch loss: 0.1394, Avg batch acc: 0.8830
Train, Epoch: 3, Batch: 1351, Step num: 4389, Learning rate: 0.00013342, Avg batch loss: 0.1445, Avg batch acc: 0.8754
Train, Epoch: 3, Batch: 1352, Step num: 4390, Learning rate: 0.00013340, Avg batch loss: 0.1446, Avg batch acc: 0.8767
Train, Epoch: 3, Batch: 1353, Step num: 4391, Learning rate: 0.00013339, Avg batch loss: 0.1652, Avg batch acc: 0.8713
Train, Epoch: 3, Batch: 1354, Step num: 4392, Learning rate: 0.00013337, Avg batch loss: 0.1524, Avg batch acc: 0.8705
Train, Epoch: 3, Batch: 1355, Step num: 4393, Learning rate: 0.00013336, Avg batch loss: 0.1498, Avg batch acc: 0.8758
Train, Epoch: 3, Batch: 1356, Step num: 4394, Learning rate: 0.00013334, Avg batch loss: 0.1500, Avg batch acc: 0.8805
Train, Epoch: 3, Batch: 1357, Step num: 4395, Learning rate: 0.00013333, Avg batch loss: 0.1436, Avg batch acc: 0.8807
Train, Epoch: 3, Batch: 1358, Step num: 4396, Learning rate: 0.00013331, Avg batch loss: 0.1265, Avg batch acc: 0.8954
Train, Epoch: 3, Batch: 1359, Step num: 4397, Learning rate: 0.00013330, Avg batch loss: 0.1306, Avg batch acc: 0.8836
Train, Epoch: 3, Batch: 1360, Step num: 4398, Learning rate: 0.00013328, Avg batch loss: 0.1609, Avg batch acc: 0.8782
Train, Epoch: 3, Batch: 1361, Step num: 4399, Learning rate: 0.00013327, Avg batch loss: 0.1323, Avg batch acc: 0.8889
Train, Epoch: 3, Batch: 1362, Step num: 4400, Learning rate: 0.00013325, Avg batch loss: 0.1532, Avg batch acc: 0.8731
Train, Epoch: 3, Batch: 1363, Step num: 4401, Learning rate: 0.00013324, Avg batch loss: 0.1392, Avg batch acc: 0.8754
Train, Epoch: 3, Batch: 1364, Step num: 4402, Learning rate: 0.00013322, Avg batch loss: 0.1226, Avg batch acc: 0.8987
Train, Epoch: 3, Batch: 1365, Step num: 4403, Learning rate: 0.00013321, Avg batch loss: 0.1409, Avg batch acc: 0.8775
Train, Epoch: 3, Batch: 1366, Step num: 4404, Learning rate: 0.00013319, Avg batch loss: 0.1425, Avg batch acc: 0.8771
Train, Epoch: 3, Batch: 1367, Step num: 4405, Learning rate: 0.00013317, Avg batch loss: 0.1358, Avg batch acc: 0.8886
Train, Epoch: 3, Batch: 1368, Step num: 4406, Learning rate: 0.00013316, Avg batch loss: 0.1347, Avg batch acc: 0.8809
Train, Epoch: 3, Batch: 1369, Step num: 4407, Learning rate: 0.00013314, Avg batch loss: 0.1857, Avg batch acc: 0.8510
Train, Epoch: 3, Batch: 1370, Step num: 4408, Learning rate: 0.00013313, Avg batch loss: 0.1457, Avg batch acc: 0.8761
Train, Epoch: 3, Batch: 1371, Step num: 4409, Learning rate: 0.00013311, Avg batch loss: 0.1494, Avg batch acc: 0.8810
Train, Epoch: 3, Batch: 1372, Step num: 4410, Learning rate: 0.00013310, Avg batch loss: 0.1309, Avg batch acc: 0.8845
Train, Epoch: 3, Batch: 1373, Step num: 4411, Learning rate: 0.00013308, Avg batch loss: 0.1422, Avg batch acc: 0.8889
Train, Epoch: 3, Batch: 1374, Step num: 4412, Learning rate: 0.00013307, Avg batch loss: 0.1417, Avg batch acc: 0.8876
Train, Epoch: 3, Batch: 1375, Step num: 4413, Learning rate: 0.00013305, Avg batch loss: 0.1506, Avg batch acc: 0.8874
Train, Epoch: 3, Batch: 1376, Step num: 4414, Learning rate: 0.00013304, Avg batch loss: 0.1436, Avg batch acc: 0.8983
Train, Epoch: 3, Batch: 1377, Step num: 4415, Learning rate: 0.00013302, Avg batch loss: 0.1496, Avg batch acc: 0.8721
Train, Epoch: 3, Batch: 1378, Step num: 4416, Learning rate: 0.00013301, Avg batch loss: 0.1571, Avg batch acc: 0.8818
Train, Epoch: 3, Batch: 1379, Step num: 4417, Learning rate: 0.00013299, Avg batch loss: 0.1415, Avg batch acc: 0.8803
Train, Epoch: 3, Batch: 1380, Step num: 4418, Learning rate: 0.00013298, Avg batch loss: 0.1708, Avg batch acc: 0.8745
Train, Epoch: 3, Batch: 1381, Step num: 4419, Learning rate: 0.00013296, Avg batch loss: 0.1484, Avg batch acc: 0.8633
Train, Epoch: 3, Batch: 1382, Step num: 4420, Learning rate: 0.00013295, Avg batch loss: 0.1235, Avg batch acc: 0.8918
Train, Epoch: 3, Batch: 1383, Step num: 4421, Learning rate: 0.00013293, Avg batch loss: 0.1289, Avg batch acc: 0.8888
Train, Epoch: 3, Batch: 1384, Step num: 4422, Learning rate: 0.00013292, Avg batch loss: 0.1587, Avg batch acc: 0.8603
Train, Epoch: 3, Batch: 1385, Step num: 4423, Learning rate: 0.00013290, Avg batch loss: 0.1328, Avg batch acc: 0.8912
Train, Epoch: 3, Batch: 1386, Step num: 4424, Learning rate: 0.00013289, Avg batch loss: 0.1388, Avg batch acc: 0.8866
Train, Epoch: 3, Batch: 1387, Step num: 4425, Learning rate: 0.00013287, Avg batch loss: 0.1405, Avg batch acc: 0.8735
Train, Epoch: 3, Batch: 1388, Step num: 4426, Learning rate: 0.00013286, Avg batch loss: 0.1513, Avg batch acc: 0.8754
Train, Epoch: 3, Batch: 1389, Step num: 4427, Learning rate: 0.00013284, Avg batch loss: 0.1522, Avg batch acc: 0.8777
Train, Epoch: 3, Batch: 1390, Step num: 4428, Learning rate: 0.00013283, Avg batch loss: 0.1156, Avg batch acc: 0.9000
Train, Epoch: 3, Batch: 1391, Step num: 4429, Learning rate: 0.00013281, Avg batch loss: 0.1591, Avg batch acc: 0.8772
Train, Epoch: 3, Batch: 1392, Step num: 4430, Learning rate: 0.00013280, Avg batch loss: 0.1509, Avg batch acc: 0.8864
Train, Epoch: 3, Batch: 1393, Step num: 4431, Learning rate: 0.00013278, Avg batch loss: 0.1486, Avg batch acc: 0.8865
Train, Epoch: 3, Batch: 1394, Step num: 4432, Learning rate: 0.00013277, Avg batch loss: 0.1308, Avg batch acc: 0.8831
Train, Epoch: 3, Batch: 1395, Step num: 4433, Learning rate: 0.00013275, Avg batch loss: 0.1451, Avg batch acc: 0.8921
Train, Epoch: 3, Batch: 1396, Step num: 4434, Learning rate: 0.00013274, Avg batch loss: 0.1390, Avg batch acc: 0.8918
Train, Epoch: 3, Batch: 1397, Step num: 4435, Learning rate: 0.00013272, Avg batch loss: 0.1623, Avg batch acc: 0.8733
Train, Epoch: 3, Batch: 1398, Step num: 4436, Learning rate: 0.00013271, Avg batch loss: 0.1346, Avg batch acc: 0.8907
Train, Epoch: 3, Batch: 1399, Step num: 4437, Learning rate: 0.00013269, Avg batch loss: 0.1261, Avg batch acc: 0.8962
Train, Epoch: 3, Batch: 1400, Step num: 4438, Learning rate: 0.00013268, Avg batch loss: 0.1426, Avg batch acc: 0.8814
Train, Epoch: 3, Batch: 1401, Step num: 4439, Learning rate: 0.00013266, Avg batch loss: 0.1311, Avg batch acc: 0.8902
Train, Epoch: 3, Batch: 1402, Step num: 4440, Learning rate: 0.00013265, Avg batch loss: 0.1407, Avg batch acc: 0.8885
Train, Epoch: 3, Batch: 1403, Step num: 4441, Learning rate: 0.00013263, Avg batch loss: 0.1385, Avg batch acc: 0.8832
Train, Epoch: 3, Batch: 1404, Step num: 4442, Learning rate: 0.00013262, Avg batch loss: 0.1494, Avg batch acc: 0.8672
Train, Epoch: 3, Batch: 1405, Step num: 4443, Learning rate: 0.00013260, Avg batch loss: 0.1359, Avg batch acc: 0.8771
Train, Epoch: 3, Batch: 1406, Step num: 4444, Learning rate: 0.00013259, Avg batch loss: 0.1335, Avg batch acc: 0.8799
Train, Epoch: 3, Batch: 1407, Step num: 4445, Learning rate: 0.00013257, Avg batch loss: 0.1330, Avg batch acc: 0.8881
Train, Epoch: 3, Batch: 1408, Step num: 4446, Learning rate: 0.00013256, Avg batch loss: 0.1457, Avg batch acc: 0.8807
Train, Epoch: 3, Batch: 1409, Step num: 4447, Learning rate: 0.00013254, Avg batch loss: 0.1251, Avg batch acc: 0.8919
Train, Epoch: 3, Batch: 1410, Step num: 4448, Learning rate: 0.00013253, Avg batch loss: 0.1312, Avg batch acc: 0.8988
Train, Epoch: 3, Batch: 1411, Step num: 4449, Learning rate: 0.00013251, Avg batch loss: 0.1455, Avg batch acc: 0.8703
Train, Epoch: 3, Batch: 1412, Step num: 4450, Learning rate: 0.00013250, Avg batch loss: 0.1423, Avg batch acc: 0.8879
Train, Epoch: 3, Batch: 1413, Step num: 4451, Learning rate: 0.00013248, Avg batch loss: 0.1393, Avg batch acc: 0.8830
Train, Epoch: 3, Batch: 1414, Step num: 4452, Learning rate: 0.00013247, Avg batch loss: 0.1213, Avg batch acc: 0.8909
Train, Epoch: 3, Batch: 1415, Step num: 4453, Learning rate: 0.00013246, Avg batch loss: 0.1407, Avg batch acc: 0.8901
Train, Epoch: 3, Batch: 1416, Step num: 4454, Learning rate: 0.00013244, Avg batch loss: 0.1543, Avg batch acc: 0.8800
Train, Epoch: 3, Batch: 1417, Step num: 4455, Learning rate: 0.00013243, Avg batch loss: 0.1308, Avg batch acc: 0.8896
Train, Epoch: 3, Batch: 1418, Step num: 4456, Learning rate: 0.00013241, Avg batch loss: 0.1185, Avg batch acc: 0.8938
Train, Epoch: 3, Batch: 1419, Step num: 4457, Learning rate: 0.00013240, Avg batch loss: 0.1482, Avg batch acc: 0.8858
Train, Epoch: 3, Batch: 1420, Step num: 4458, Learning rate: 0.00013238, Avg batch loss: 0.1249, Avg batch acc: 0.8886
Train, Epoch: 3, Batch: 1421, Step num: 4459, Learning rate: 0.00013237, Avg batch loss: 0.1594, Avg batch acc: 0.8762
Train, Epoch: 3, Batch: 1422, Step num: 4460, Learning rate: 0.00013235, Avg batch loss: 0.1659, Avg batch acc: 0.8733
Train, Epoch: 3, Batch: 1423, Step num: 4461, Learning rate: 0.00013234, Avg batch loss: 0.1383, Avg batch acc: 0.8815
Train, Epoch: 3, Batch: 1424, Step num: 4462, Learning rate: 0.00013232, Avg batch loss: 0.1653, Avg batch acc: 0.8865
Train, Epoch: 3, Batch: 1425, Step num: 4463, Learning rate: 0.00013231, Avg batch loss: 0.1533, Avg batch acc: 0.8766
Train, Epoch: 3, Batch: 1426, Step num: 4464, Learning rate: 0.00013229, Avg batch loss: 0.1508, Avg batch acc: 0.8686
Train, Epoch: 3, Batch: 1427, Step num: 4465, Learning rate: 0.00013228, Avg batch loss: 0.1481, Avg batch acc: 0.8898
Train, Epoch: 3, Batch: 1428, Step num: 4466, Learning rate: 0.00013226, Avg batch loss: 0.1459, Avg batch acc: 0.8784
Train, Epoch: 3, Batch: 1429, Step num: 4467, Learning rate: 0.00013225, Avg batch loss: 0.1343, Avg batch acc: 0.8911
Train, Epoch: 3, Batch: 1430, Step num: 4468, Learning rate: 0.00013223, Avg batch loss: 0.1339, Avg batch acc: 0.8822
Train, Epoch: 3, Batch: 1431, Step num: 4469, Learning rate: 0.00013222, Avg batch loss: 0.1559, Avg batch acc: 0.8782
Train, Epoch: 3, Batch: 1432, Step num: 4470, Learning rate: 0.00013220, Avg batch loss: 0.1245, Avg batch acc: 0.9028
Train, Epoch: 3, Batch: 1433, Step num: 4471, Learning rate: 0.00013219, Avg batch loss: 0.1574, Avg batch acc: 0.8738
Train, Epoch: 3, Batch: 1434, Step num: 4472, Learning rate: 0.00013217, Avg batch loss: 0.1532, Avg batch acc: 0.8793
Train, Epoch: 3, Batch: 1435, Step num: 4473, Learning rate: 0.00013216, Avg batch loss: 0.1357, Avg batch acc: 0.8829
Train, Epoch: 3, Batch: 1436, Step num: 4474, Learning rate: 0.00013214, Avg batch loss: 0.1667, Avg batch acc: 0.8730
Train, Epoch: 3, Batch: 1437, Step num: 4475, Learning rate: 0.00013213, Avg batch loss: 0.1146, Avg batch acc: 0.9017
Train, Epoch: 3, Batch: 1438, Step num: 4476, Learning rate: 0.00013211, Avg batch loss: 0.1245, Avg batch acc: 0.8970
Train, Epoch: 3, Batch: 1439, Step num: 4477, Learning rate: 0.00013210, Avg batch loss: 0.1378, Avg batch acc: 0.8780
Train, Epoch: 3, Batch: 1440, Step num: 4478, Learning rate: 0.00013208, Avg batch loss: 0.1403, Avg batch acc: 0.8784
Train, Epoch: 3, Batch: 1441, Step num: 4479, Learning rate: 0.00013207, Avg batch loss: 0.1288, Avg batch acc: 0.8881
Train, Epoch: 3, Batch: 1442, Step num: 4480, Learning rate: 0.00013206, Avg batch loss: 0.1317, Avg batch acc: 0.8937
Train, Epoch: 3, Batch: 1443, Step num: 4481, Learning rate: 0.00013204, Avg batch loss: 0.1335, Avg batch acc: 0.8884
Train, Epoch: 3, Batch: 1444, Step num: 4482, Learning rate: 0.00013203, Avg batch loss: 0.0951, Avg batch acc: 0.9160
Train, Epoch: 3, Batch: 1445, Step num: 4483, Learning rate: 0.00013201, Avg batch loss: 0.1660, Avg batch acc: 0.8797
Train, Epoch: 3, Batch: 1446, Step num: 4484, Learning rate: 0.00013200, Avg batch loss: 0.1495, Avg batch acc: 0.8847
Train, Epoch: 3, Batch: 1447, Step num: 4485, Learning rate: 0.00013198, Avg batch loss: 0.1226, Avg batch acc: 0.8939
Train, Epoch: 3, Batch: 1448, Step num: 4486, Learning rate: 0.00013197, Avg batch loss: 0.1290, Avg batch acc: 0.8876
Train, Epoch: 3, Batch: 1449, Step num: 4487, Learning rate: 0.00013195, Avg batch loss: 0.1536, Avg batch acc: 0.8828
Train, Epoch: 3, Batch: 1450, Step num: 4488, Learning rate: 0.00013194, Avg batch loss: 0.1389, Avg batch acc: 0.8855
Train, Epoch: 3, Batch: 1451, Step num: 4489, Learning rate: 0.00013192, Avg batch loss: 0.1118, Avg batch acc: 0.9071
Train, Epoch: 3, Batch: 1452, Step num: 4490, Learning rate: 0.00013191, Avg batch loss: 0.1275, Avg batch acc: 0.8994
Train, Epoch: 3, Batch: 1453, Step num: 4491, Learning rate: 0.00013189, Avg batch loss: 0.1085, Avg batch acc: 0.8931
Train, Epoch: 3, Batch: 1454, Step num: 4492, Learning rate: 0.00013188, Avg batch loss: 0.1379, Avg batch acc: 0.8929
Train, Epoch: 3, Batch: 1455, Step num: 4493, Learning rate: 0.00013186, Avg batch loss: 0.1216, Avg batch acc: 0.8912
Train, Epoch: 3, Batch: 1456, Step num: 4494, Learning rate: 0.00013185, Avg batch loss: 0.1346, Avg batch acc: 0.8847
Train, Epoch: 3, Batch: 1457, Step num: 4495, Learning rate: 0.00013183, Avg batch loss: 0.1321, Avg batch acc: 0.8943
Train, Epoch: 3, Batch: 1458, Step num: 4496, Learning rate: 0.00013182, Avg batch loss: 0.1400, Avg batch acc: 0.8771
Train, Epoch: 3, Batch: 1459, Step num: 4497, Learning rate: 0.00013181, Avg batch loss: 0.1275, Avg batch acc: 0.8886
Train, Epoch: 3, Batch: 1460, Step num: 4498, Learning rate: 0.00013179, Avg batch loss: 0.1384, Avg batch acc: 0.8725
Train, Epoch: 3, Batch: 1461, Step num: 4499, Learning rate: 0.00013178, Avg batch loss: 0.1444, Avg batch acc: 0.8834
Train, Epoch: 3, Batch: 1462, Step num: 4500, Learning rate: 0.00013176, Avg batch loss: 0.1273, Avg batch acc: 0.8933
Train, Epoch: 3, Batch: 1463, Step num: 4501, Learning rate: 0.00013175, Avg batch loss: 0.1133, Avg batch acc: 0.9064
Train, Epoch: 3, Batch: 1464, Step num: 4502, Learning rate: 0.00013173, Avg batch loss: 0.1291, Avg batch acc: 0.8852
Train, Epoch: 3, Batch: 1465, Step num: 4503, Learning rate: 0.00013172, Avg batch loss: 0.1386, Avg batch acc: 0.8964
Train, Epoch: 3, Batch: 1466, Step num: 4504, Learning rate: 0.00013170, Avg batch loss: 0.1360, Avg batch acc: 0.8928
Train, Epoch: 3, Batch: 1467, Step num: 4505, Learning rate: 0.00013169, Avg batch loss: 0.1415, Avg batch acc: 0.8912
Train, Epoch: 3, Batch: 1468, Step num: 4506, Learning rate: 0.00013167, Avg batch loss: 0.1484, Avg batch acc: 0.8815
Train, Epoch: 3, Batch: 1469, Step num: 4507, Learning rate: 0.00013166, Avg batch loss: 0.1392, Avg batch acc: 0.8759
Train, Epoch: 3, Batch: 1470, Step num: 4508, Learning rate: 0.00013164, Avg batch loss: 0.1178, Avg batch acc: 0.8937
Train, Epoch: 3, Batch: 1471, Step num: 4509, Learning rate: 0.00013163, Avg batch loss: 0.1249, Avg batch acc: 0.9039
Train, Epoch: 3, Batch: 1472, Step num: 4510, Learning rate: 0.00013162, Avg batch loss: 0.1278, Avg batch acc: 0.8922
Train, Epoch: 3, Batch: 1473, Step num: 4511, Learning rate: 0.00013160, Avg batch loss: 0.1248, Avg batch acc: 0.8916
Train, Epoch: 3, Batch: 1474, Step num: 4512, Learning rate: 0.00013159, Avg batch loss: 0.1206, Avg batch acc: 0.8926
Train, Epoch: 3, Batch: 1475, Step num: 4513, Learning rate: 0.00013157, Avg batch loss: 0.1267, Avg batch acc: 0.8933
Train, Epoch: 3, Batch: 1476, Step num: 4514, Learning rate: 0.00013156, Avg batch loss: 0.1282, Avg batch acc: 0.8972
Train, Epoch: 3, Batch: 1477, Step num: 4515, Learning rate: 0.00013154, Avg batch loss: 0.1392, Avg batch acc: 0.8818
Train, Epoch: 3, Batch: 1478, Step num: 4516, Learning rate: 0.00013153, Avg batch loss: 0.1343, Avg batch acc: 0.8888
Train, Epoch: 3, Batch: 1479, Step num: 4517, Learning rate: 0.00013151, Avg batch loss: 0.1195, Avg batch acc: 0.8926
Train, Epoch: 3, Batch: 1480, Step num: 4518, Learning rate: 0.00013150, Avg batch loss: 0.1156, Avg batch acc: 0.9049
Train, Epoch: 3, Batch: 1481, Step num: 4519, Learning rate: 0.00013148, Avg batch loss: 0.1245, Avg batch acc: 0.8901
Train, Epoch: 3, Batch: 1482, Step num: 4520, Learning rate: 0.00013147, Avg batch loss: 0.1310, Avg batch acc: 0.8840
Train, Epoch: 3, Batch: 1483, Step num: 4521, Learning rate: 0.00013146, Avg batch loss: 0.1274, Avg batch acc: 0.8952
Train, Epoch: 3, Batch: 1484, Step num: 4522, Learning rate: 0.00013144, Avg batch loss: 0.1177, Avg batch acc: 0.9033
Train, Epoch: 3, Batch: 1485, Step num: 4523, Learning rate: 0.00013143, Avg batch loss: 0.1007, Avg batch acc: 0.9118
Train, Epoch: 3, Batch: 1486, Step num: 4524, Learning rate: 0.00013141, Avg batch loss: 0.1395, Avg batch acc: 0.8730
Train, Epoch: 3, Batch: 1487, Step num: 4525, Learning rate: 0.00013140, Avg batch loss: 0.1206, Avg batch acc: 0.8986
Train, Epoch: 3, Batch: 1488, Step num: 4526, Learning rate: 0.00013138, Avg batch loss: 0.1175, Avg batch acc: 0.9010
Train, Epoch: 3, Batch: 1489, Step num: 4527, Learning rate: 0.00013137, Avg batch loss: 0.1261, Avg batch acc: 0.8891
Train, Epoch: 3, Batch: 1490, Step num: 4528, Learning rate: 0.00013135, Avg batch loss: 0.1226, Avg batch acc: 0.8918
Train, Epoch: 3, Batch: 1491, Step num: 4529, Learning rate: 0.00013134, Avg batch loss: 0.1039, Avg batch acc: 0.9073
Train, Epoch: 3, Batch: 1492, Step num: 4530, Learning rate: 0.00013132, Avg batch loss: 0.1231, Avg batch acc: 0.8999
Train, Epoch: 3, Batch: 1493, Step num: 4531, Learning rate: 0.00013131, Avg batch loss: 0.1495, Avg batch acc: 0.8914
Train, Epoch: 3, Batch: 1494, Step num: 4532, Learning rate: 0.00013130, Avg batch loss: 0.1364, Avg batch acc: 0.8994
Train, Epoch: 3, Batch: 1495, Step num: 4533, Learning rate: 0.00013128, Avg batch loss: 0.1344, Avg batch acc: 0.8962
Train, Epoch: 3, Batch: 1496, Step num: 4534, Learning rate: 0.00013127, Avg batch loss: 0.1272, Avg batch acc: 0.8937
Train, Epoch: 3, Batch: 1497, Step num: 4535, Learning rate: 0.00013125, Avg batch loss: 0.1389, Avg batch acc: 0.8947
Train, Epoch: 3, Batch: 1498, Step num: 4536, Learning rate: 0.00013124, Avg batch loss: 0.1303, Avg batch acc: 0.8831
Train, Epoch: 3, Batch: 1499, Step num: 4537, Learning rate: 0.00013122, Avg batch loss: 0.1344, Avg batch acc: 0.8870
Train, Epoch: 3, Batch: 1500, Step num: 4538, Learning rate: 0.00013121, Avg batch loss: 0.1402, Avg batch acc: 0.8793
Train, Epoch: 3, Batch: 1501, Step num: 4539, Learning rate: 0.00013119, Avg batch loss: 0.1162, Avg batch acc: 0.9106
Train, Epoch: 3, Batch: 1502, Step num: 4540, Learning rate: 0.00013118, Avg batch loss: 0.1506, Avg batch acc: 0.8820
Train, Epoch: 3, Batch: 1503, Step num: 4541, Learning rate: 0.00013117, Avg batch loss: 0.1456, Avg batch acc: 0.8960
Train, Epoch: 3, Batch: 1504, Step num: 4542, Learning rate: 0.00013115, Avg batch loss: 0.1161, Avg batch acc: 0.9043
Train, Epoch: 3, Batch: 1505, Step num: 4543, Learning rate: 0.00013114, Avg batch loss: 0.1170, Avg batch acc: 0.8996
Train, Epoch: 3, Batch: 1506, Step num: 4544, Learning rate: 0.00013112, Avg batch loss: 0.1113, Avg batch acc: 0.9113
Train, Epoch: 3, Batch: 1507, Step num: 4545, Learning rate: 0.00013111, Avg batch loss: 0.1135, Avg batch acc: 0.9052
Train, Epoch: 3, Batch: 1508, Step num: 4546, Learning rate: 0.00013109, Avg batch loss: 0.1645, Avg batch acc: 0.8768
Train, Epoch: 3, Batch: 1509, Step num: 4547, Learning rate: 0.00013108, Avg batch loss: 0.1094, Avg batch acc: 0.9034
Train, Epoch: 3, Batch: 1510, Step num: 4548, Learning rate: 0.00013106, Avg batch loss: 0.1262, Avg batch acc: 0.8955
Train, Epoch: 3, Batch: 1511, Step num: 4549, Learning rate: 0.00013105, Avg batch loss: 0.0971, Avg batch acc: 0.9064
Train, Epoch: 3, Batch: 1512, Step num: 4550, Learning rate: 0.00013104, Avg batch loss: 0.1154, Avg batch acc: 0.9063
Train, Epoch: 3, Batch: 1513, Step num: 4551, Learning rate: 0.00013102, Avg batch loss: 0.1407, Avg batch acc: 0.8818
Train, Epoch: 3, Batch: 1514, Step num: 4552, Learning rate: 0.00013101, Avg batch loss: 0.1147, Avg batch acc: 0.8952
Train, Epoch: 3, Batch: 1515, Step num: 4553, Learning rate: 0.00013099, Avg batch loss: 0.1138, Avg batch acc: 0.9001
Train, Epoch: 3, Batch: 1516, Step num: 4554, Learning rate: 0.00013098, Avg batch loss: 0.1120, Avg batch acc: 0.9049
Train, Epoch: 3, Batch: 1517, Step num: 4555, Learning rate: 0.00013096, Avg batch loss: 0.1190, Avg batch acc: 0.8930
Train, Epoch: 3, Batch: 1518, Step num: 4556, Learning rate: 0.00013095, Avg batch loss: 0.1321, Avg batch acc: 0.9038
Train, Epoch: 3, Batch: 1519, Step num: 4557, Learning rate: 0.00013093, Avg batch loss: 0.1357, Avg batch acc: 0.8988
Train, Epoch: 3, Avg epoch loss: 0.3236, Avg epoch acc: 0.7145, Overall time: 995.8 s, Speed: 4371.2 tokens/s on cuda:1

Validate, Epoch: 3, Batch: 1, Avg batch loss: 0.1379, Avg batch acc: 0.8847
Validate, Epoch: 3, Batch: 2, Avg batch loss: 0.1344, Avg batch acc: 0.8918
Validate, Epoch: 3, Batch: 3, Avg batch loss: 0.1283, Avg batch acc: 0.9061
Validate, Epoch: 3, Batch: 4, Avg batch loss: 0.1053, Avg batch acc: 0.9023
Validate, Epoch: 3, Batch: 5, Avg batch loss: 0.1108, Avg batch acc: 0.9037
Validate, Epoch: 3, Batch: 6, Avg batch loss: 0.1274, Avg batch acc: 0.9037
Validate, Epoch: 3, Batch: 7, Avg batch loss: 0.1394, Avg batch acc: 0.8836
Validate, Epoch: 3, Batch: 8, Avg batch loss: 0.1379, Avg batch acc: 0.8867
Validate, Epoch: 3, Batch: 9, Avg batch loss: 0.1093, Avg batch acc: 0.9145
Validate, Epoch: 3, Batch: 10, Avg batch loss: 0.1726, Avg batch acc: 0.8887
Validate, Epoch: 3, Batch: 11, Avg batch loss: 0.1322, Avg batch acc: 0.8763
Validate, Epoch: 3, Batch: 12, Avg batch loss: 0.1328, Avg batch acc: 0.8880
Validate, Epoch: 3, Batch: 13, Avg batch loss: 0.1209, Avg batch acc: 0.8986
Validate, Epoch: 3, Batch: 14, Avg batch loss: 0.1399, Avg batch acc: 0.8891
Validate, Epoch: 3, Batch: 15, Avg batch loss: 0.1276, Avg batch acc: 0.8973
Validate, Epoch: 3, Batch: 16, Avg batch loss: 0.1255, Avg batch acc: 0.8994
Validate, Epoch: 3, Batch: 17, Avg batch loss: 0.1164, Avg batch acc: 0.8882
Validate, Epoch: 3, Batch: 18, Avg batch loss: 0.1049, Avg batch acc: 0.9025
Validate, Epoch: 3, Batch: 19, Avg batch loss: 0.1434, Avg batch acc: 0.8899
Validate, Epoch: 3, Batch: 20, Avg batch loss: 0.1057, Avg batch acc: 0.9012
Validate, Epoch: 3, Batch: 21, Avg batch loss: 0.1745, Avg batch acc: 0.8779
Validate, Epoch: 3, Batch: 22, Avg batch loss: 0.1308, Avg batch acc: 0.8994
Validate, Epoch: 3, Batch: 23, Avg batch loss: 0.1195, Avg batch acc: 0.8882
Validate, Epoch: 3, Batch: 24, Avg batch loss: 0.1094, Avg batch acc: 0.8967
Validate, Epoch: 3, Batch: 25, Avg batch loss: 0.1301, Avg batch acc: 0.8963
Validate, Epoch: 3, Batch: 26, Avg batch loss: 0.1584, Avg batch acc: 0.8824
Validate, Epoch: 3, Batch: 27, Avg batch loss: 0.1038, Avg batch acc: 0.9069
Validate, Epoch: 3, Batch: 28, Avg batch loss: 0.1089, Avg batch acc: 0.9023
Validate, Epoch: 3, Batch: 29, Avg batch loss: 0.1247, Avg batch acc: 0.8968
Validate, Epoch: 3, Batch: 30, Avg batch loss: 0.1179, Avg batch acc: 0.9049
Validate, Epoch: 3, Batch: 31, Avg batch loss: 0.1273, Avg batch acc: 0.8986
Validate, Epoch: 3, Batch: 32, Avg batch loss: 0.1133, Avg batch acc: 0.9058
Validate, Epoch: 3, Batch: 33, Avg batch loss: 0.1320, Avg batch acc: 0.8937
Validate, Epoch: 3, Batch: 34, Avg batch loss: 0.1395, Avg batch acc: 0.8887
Validate, Epoch: 3, Batch: 35, Avg batch loss: 0.1206, Avg batch acc: 0.8937
Validate, Epoch: 3, Batch: 36, Avg batch loss: 0.1230, Avg batch acc: 0.9039
Validate, Epoch: 3, Batch: 37, Avg batch loss: 0.1192, Avg batch acc: 0.9084
Validate, Epoch: 3, Batch: 38, Avg batch loss: 0.1226, Avg batch acc: 0.8909
Validate, Epoch: 3, Batch: 39, Avg batch loss: 0.1308, Avg batch acc: 0.8985
Validate, Epoch: 3, Batch: 40, Avg batch loss: 0.1329, Avg batch acc: 0.9044
Validate, Epoch: 3, Batch: 41, Avg batch loss: 0.1262, Avg batch acc: 0.9026
Validate, Epoch: 3, Batch: 42, Avg batch loss: 0.1122, Avg batch acc: 0.8966
Validate, Epoch: 3, Batch: 43, Avg batch loss: 0.1225, Avg batch acc: 0.8922
Validate, Epoch: 3, Batch: 44, Avg batch loss: 0.1067, Avg batch acc: 0.9055
Validate, Epoch: 3, Batch: 45, Avg batch loss: 0.1306, Avg batch acc: 0.8917
Validate, Epoch: 3, Batch: 46, Avg batch loss: 0.1156, Avg batch acc: 0.9009
Validate, Epoch: 3, Batch: 47, Avg batch loss: 0.1331, Avg batch acc: 0.9002
Validate, Epoch: 3, Batch: 48, Avg batch loss: 0.1175, Avg batch acc: 0.8957
Validate, Epoch: 3, Batch: 49, Avg batch loss: 0.1293, Avg batch acc: 0.8876
Validate, Epoch: 3, Batch: 50, Avg batch loss: 0.1150, Avg batch acc: 0.8939
Validate, Epoch: 3, Batch: 51, Avg batch loss: 0.1164, Avg batch acc: 0.9036
Validate, Epoch: 3, Batch: 52, Avg batch loss: 0.1308, Avg batch acc: 0.8952
Validate, Epoch: 3, Batch: 53, Avg batch loss: 0.0999, Avg batch acc: 0.9091
Validate, Epoch: 3, Batch: 54, Avg batch loss: 0.1354, Avg batch acc: 0.8863
Validate, Epoch: 3, Batch: 55, Avg batch loss: 0.1251, Avg batch acc: 0.9007
Validate, Epoch: 3, Batch: 56, Avg batch loss: 0.1325, Avg batch acc: 0.9020
Validate, Epoch: 3, Batch: 57, Avg batch loss: 0.1162, Avg batch acc: 0.9021
Validate, Epoch: 3, Batch: 58, Avg batch loss: 0.1285, Avg batch acc: 0.8890
Validate, Epoch: 3, Batch: 59, Avg batch loss: 0.1289, Avg batch acc: 0.8888
Validate, Epoch: 3, Batch: 60, Avg batch loss: 0.1100, Avg batch acc: 0.9026
Validate, Epoch: 3, Batch: 61, Avg batch loss: 0.1269, Avg batch acc: 0.8883
Validate, Epoch: 3, Batch: 62, Avg batch loss: 0.1487, Avg batch acc: 0.8906
Validate, Epoch: 3, Batch: 63, Avg batch loss: 0.1145, Avg batch acc: 0.9004
Validate, Epoch: 3, Batch: 64, Avg batch loss: 0.1218, Avg batch acc: 0.8990
Validate, Epoch: 3, Batch: 65, Avg batch loss: 0.1346, Avg batch acc: 0.8903
Validate, Epoch: 3, Batch: 66, Avg batch loss: 0.1147, Avg batch acc: 0.9018
Validate, Epoch: 3, Batch: 67, Avg batch loss: 0.1108, Avg batch acc: 0.9114
Validate, Epoch: 3, Batch: 68, Avg batch loss: 0.1139, Avg batch acc: 0.9035
Validate, Epoch: 3, Batch: 69, Avg batch loss: 0.1269, Avg batch acc: 0.8947
Validate, Epoch: 3, Batch: 70, Avg batch loss: 0.1451, Avg batch acc: 0.8868
Validate, Epoch: 3, Batch: 71, Avg batch loss: 0.1277, Avg batch acc: 0.9019
Validate, Epoch: 3, Batch: 72, Avg batch loss: 0.1193, Avg batch acc: 0.8915
Validate, Epoch: 3, Batch: 73, Avg batch loss: 0.1037, Avg batch acc: 0.8990
Validate, Epoch: 3, Batch: 74, Avg batch loss: 0.1361, Avg batch acc: 0.8911
Validate, Epoch: 3, Batch: 75, Avg batch loss: 0.1031, Avg batch acc: 0.9199
Validate, Epoch: 3, Batch: 76, Avg batch loss: 0.1170, Avg batch acc: 0.9034
Validate, Epoch: 3, Batch: 77, Avg batch loss: 0.1048, Avg batch acc: 0.9103
Validate, Epoch: 3, Batch: 78, Avg batch loss: 0.1198, Avg batch acc: 0.8998
Validate, Epoch: 3, Batch: 79, Avg batch loss: 0.1309, Avg batch acc: 0.8930
Validate, Epoch: 3, Batch: 80, Avg batch loss: 0.1589, Avg batch acc: 0.8823
Validate, Epoch: 3, Batch: 81, Avg batch loss: 0.1001, Avg batch acc: 0.9159
Validate, Epoch: 3, Batch: 82, Avg batch loss: 0.1228, Avg batch acc: 0.9066
Validate, Epoch: 3, Batch: 83, Avg batch loss: 0.1195, Avg batch acc: 0.8948
Validate, Epoch: 3, Batch: 84, Avg batch loss: 0.1053, Avg batch acc: 0.9104
Validate, Epoch: 3, Batch: 85, Avg batch loss: 0.1138, Avg batch acc: 0.8970
Validate, Epoch: 3, Batch: 86, Avg batch loss: 0.1123, Avg batch acc: 0.8954
Validate, Epoch: 3, Batch: 87, Avg batch loss: 0.1249, Avg batch acc: 0.9039
Validate, Epoch: 3, Batch: 88, Avg batch loss: 0.1147, Avg batch acc: 0.9006
Validate, Epoch: 3, Batch: 89, Avg batch loss: 0.1332, Avg batch acc: 0.8986
Validate, Epoch: 3, Batch: 90, Avg batch loss: 0.1229, Avg batch acc: 0.8943
Validate, Epoch: 3, Batch: 91, Avg batch loss: 0.1234, Avg batch acc: 0.8978
Validate, Epoch: 3, Batch: 92, Avg batch loss: 0.1235, Avg batch acc: 0.8970
Validate, Epoch: 3, Batch: 93, Avg batch loss: 0.1259, Avg batch acc: 0.8880
Validate, Epoch: 3, Batch: 94, Avg batch loss: 0.1551, Avg batch acc: 0.8866
Validate, Epoch: 3, Batch: 95, Avg batch loss: 0.1171, Avg batch acc: 0.9070
Validate, Epoch: 3, Batch: 96, Avg batch loss: 0.1276, Avg batch acc: 0.8813
Validate, Epoch: 3, Batch: 97, Avg batch loss: 0.1252, Avg batch acc: 0.9023
Validate, Epoch: 3, Batch: 98, Avg batch loss: 0.1091, Avg batch acc: 0.9091
Validate, Epoch: 3, Batch: 99, Avg batch loss: 0.1021, Avg batch acc: 0.9108
Validate, Epoch: 3, Batch: 100, Avg batch loss: 0.1190, Avg batch acc: 0.9015
Validate, Epoch: 3, Batch: 101, Avg batch loss: 0.1321, Avg batch acc: 0.8833
Validate, Epoch: 3, Batch: 102, Avg batch loss: 0.1121, Avg batch acc: 0.8982
Validate, Epoch: 3, Batch: 103, Avg batch loss: 0.1260, Avg batch acc: 0.8960
Validate, Epoch: 3, Batch: 104, Avg batch loss: 0.1158, Avg batch acc: 0.8961
Validate, Epoch: 3, Batch: 105, Avg batch loss: 0.1059, Avg batch acc: 0.9060
Validate, Epoch: 3, Batch: 106, Avg batch loss: 0.0995, Avg batch acc: 0.9093
Validate, Epoch: 3, Batch: 107, Avg batch loss: 0.1324, Avg batch acc: 0.8980
Validate, Epoch: 3, Batch: 108, Avg batch loss: 0.1282, Avg batch acc: 0.9046
Validate, Epoch: 3, Batch: 109, Avg batch loss: 0.1335, Avg batch acc: 0.8918
Validate, Epoch: 3, Batch: 110, Avg batch loss: 0.1383, Avg batch acc: 0.9003
Validate, Epoch: 3, Batch: 111, Avg batch loss: 0.1281, Avg batch acc: 0.8869
Validate, Epoch: 3, Batch: 112, Avg batch loss: 0.1094, Avg batch acc: 0.9022
Validate, Epoch: 3, Batch: 113, Avg batch loss: 0.1164, Avg batch acc: 0.8957
Validate, Epoch: 3, Batch: 114, Avg batch loss: 0.1234, Avg batch acc: 0.8889
Validate, Epoch: 3, Batch: 115, Avg batch loss: 0.1258, Avg batch acc: 0.8811
Validate, Epoch: 3, Batch: 116, Avg batch loss: 0.1039, Avg batch acc: 0.9011
Validate, Epoch: 3, Batch: 117, Avg batch loss: 0.1495, Avg batch acc: 0.8858
Validate, Epoch: 3, Batch: 118, Avg batch loss: 0.1141, Avg batch acc: 0.9000
Validate, Epoch: 3, Batch: 119, Avg batch loss: 0.1250, Avg batch acc: 0.8946
Validate, Epoch: 3, Batch: 120, Avg batch loss: 0.1044, Avg batch acc: 0.8971
Validate, Epoch: 3, Batch: 121, Avg batch loss: 0.1403, Avg batch acc: 0.8901
Validate, Epoch: 3, Batch: 122, Avg batch loss: 0.1239, Avg batch acc: 0.8961
Validate, Epoch: 3, Batch: 123, Avg batch loss: 0.1051, Avg batch acc: 0.9082
Validate, Epoch: 3, Batch: 124, Avg batch loss: 0.1173, Avg batch acc: 0.9044
Validate, Epoch: 3, Batch: 125, Avg batch loss: 0.1176, Avg batch acc: 0.9039
Validate, Epoch: 3, Batch: 126, Avg batch loss: 0.1272, Avg batch acc: 0.8909
Validate, Epoch: 3, Batch: 127, Avg batch loss: 0.1142, Avg batch acc: 0.8981
Validate, Epoch: 3, Batch: 128, Avg batch loss: 0.1202, Avg batch acc: 0.8995
Validate, Epoch: 3, Batch: 129, Avg batch loss: 0.1115, Avg batch acc: 0.8936
Validate, Epoch: 3, Batch: 130, Avg batch loss: 0.1060, Avg batch acc: 0.9021
Validate, Epoch: 3, Batch: 131, Avg batch loss: 0.1063, Avg batch acc: 0.9000
Validate, Epoch: 3, Batch: 132, Avg batch loss: 0.1253, Avg batch acc: 0.8972
Validate, Epoch: 3, Batch: 133, Avg batch loss: 0.1101, Avg batch acc: 0.8985
Validate, Epoch: 3, Batch: 134, Avg batch loss: 0.1118, Avg batch acc: 0.9000
Validate, Epoch: 3, Batch: 135, Avg batch loss: 0.1099, Avg batch acc: 0.8950
Validate, Epoch: 3, Batch: 136, Avg batch loss: 0.1238, Avg batch acc: 0.8943
Validate, Epoch: 3, Batch: 137, Avg batch loss: 0.1114, Avg batch acc: 0.8965
Validate, Epoch: 3, Batch: 138, Avg batch loss: 0.1283, Avg batch acc: 0.9070
Validate, Epoch: 3, Batch: 139, Avg batch loss: 0.1291, Avg batch acc: 0.8833
Validate, Epoch: 3, Batch: 140, Avg batch loss: 0.1130, Avg batch acc: 0.9049
Validate, Epoch: 3, Batch: 141, Avg batch loss: 0.1201, Avg batch acc: 0.8889
Validate, Epoch: 3, Batch: 142, Avg batch loss: 0.1065, Avg batch acc: 0.9164
Validate, Epoch: 3, Batch: 143, Avg batch loss: 0.1102, Avg batch acc: 0.8919
Validate, Epoch: 3, Batch: 144, Avg batch loss: 0.1149, Avg batch acc: 0.9069
Validate, Epoch: 3, Batch: 145, Avg batch loss: 0.1120, Avg batch acc: 0.8991
Validate, Epoch: 3, Batch: 146, Avg batch loss: 0.1047, Avg batch acc: 0.9156
Validate, Epoch: 3, Batch: 147, Avg batch loss: 0.1115, Avg batch acc: 0.9138
Validate, Epoch: 3, Batch: 148, Avg batch loss: 0.1295, Avg batch acc: 0.9017
Validate, Epoch: 3, Batch: 149, Avg batch loss: 0.1111, Avg batch acc: 0.8983
Validate, Epoch: 3, Batch: 150, Avg batch loss: 0.1360, Avg batch acc: 0.8841
Validate, Epoch: 3, Batch: 151, Avg batch loss: 0.1255, Avg batch acc: 0.8978
Validate, Epoch: 3, Batch: 152, Avg batch loss: 0.1227, Avg batch acc: 0.8977
Validate, Epoch: 3, Batch: 153, Avg batch loss: 0.1315, Avg batch acc: 0.8906
Validate, Epoch: 3, Batch: 154, Avg batch loss: 0.1463, Avg batch acc: 0.8781
Validate, Epoch: 3, Batch: 155, Avg batch loss: 0.1264, Avg batch acc: 0.8959
Validate, Epoch: 3, Batch: 156, Avg batch loss: 0.0992, Avg batch acc: 0.9141
Validate, Epoch: 3, Batch: 157, Avg batch loss: 0.1307, Avg batch acc: 0.8984
Validate, Epoch: 3, Batch: 158, Avg batch loss: 0.1281, Avg batch acc: 0.8904
Validate, Epoch: 3, Batch: 159, Avg batch loss: 0.1379, Avg batch acc: 0.8943
Validate, Epoch: 3, Batch: 160, Avg batch loss: 0.1175, Avg batch acc: 0.9007
Validate, Epoch: 3, Batch: 161, Avg batch loss: 0.1089, Avg batch acc: 0.8946
Validate, Epoch: 3, Batch: 162, Avg batch loss: 0.1249, Avg batch acc: 0.8922
Validate, Epoch: 3, Batch: 163, Avg batch loss: 0.0976, Avg batch acc: 0.9062
Validate, Epoch: 3, Batch: 164, Avg batch loss: 0.1452, Avg batch acc: 0.8749
Validate, Epoch: 3, Batch: 165, Avg batch loss: 0.1352, Avg batch acc: 0.8904
Validate, Epoch: 3, Batch: 166, Avg batch loss: 0.1269, Avg batch acc: 0.9016
Validate, Epoch: 3, Batch: 167, Avg batch loss: 0.1098, Avg batch acc: 0.9039
Validate, Epoch: 3, Batch: 168, Avg batch loss: 0.1330, Avg batch acc: 0.8933
Validate, Epoch: 3, Batch: 169, Avg batch loss: 0.1118, Avg batch acc: 0.9107
Validate, Epoch: 3, Avg epoch loss: 0.1225, Avg epoch acc: 0.8974, Overall time: 36.3 s, Speed: 13302.7 tokens/s on cuda:1

Train, Epoch: 4, Batch: 1, Step num: 4558, Learning rate: 0.00013092, Avg batch loss: 0.1183, Avg batch acc: 0.9035
Train, Epoch: 4, Batch: 2, Step num: 4559, Learning rate: 0.00013091, Avg batch loss: 0.1283, Avg batch acc: 0.8890
Train, Epoch: 4, Batch: 3, Step num: 4560, Learning rate: 0.00013089, Avg batch loss: 0.1142, Avg batch acc: 0.9047
Train, Epoch: 4, Batch: 4, Step num: 4561, Learning rate: 0.00013088, Avg batch loss: 0.1257, Avg batch acc: 0.9026
Train, Epoch: 4, Batch: 5, Step num: 4562, Learning rate: 0.00013086, Avg batch loss: 0.1276, Avg batch acc: 0.8934
Train, Epoch: 4, Batch: 6, Step num: 4563, Learning rate: 0.00013085, Avg batch loss: 0.1094, Avg batch acc: 0.8999
Train, Epoch: 4, Batch: 7, Step num: 4564, Learning rate: 0.00013083, Avg batch loss: 0.1333, Avg batch acc: 0.8921
Train, Epoch: 4, Batch: 8, Step num: 4565, Learning rate: 0.00013082, Avg batch loss: 0.1180, Avg batch acc: 0.8933
Train, Epoch: 4, Batch: 9, Step num: 4566, Learning rate: 0.00013081, Avg batch loss: 0.1531, Avg batch acc: 0.8853
Train, Epoch: 4, Batch: 10, Step num: 4567, Learning rate: 0.00013079, Avg batch loss: 0.1177, Avg batch acc: 0.9008
Train, Epoch: 4, Batch: 11, Step num: 4568, Learning rate: 0.00013078, Avg batch loss: 0.1142, Avg batch acc: 0.9008
Train, Epoch: 4, Batch: 12, Step num: 4569, Learning rate: 0.00013076, Avg batch loss: 0.1031, Avg batch acc: 0.9017
Train, Epoch: 4, Batch: 13, Step num: 4570, Learning rate: 0.00013075, Avg batch loss: 0.1173, Avg batch acc: 0.9059
Train, Epoch: 4, Batch: 14, Step num: 4571, Learning rate: 0.00013073, Avg batch loss: 0.1532, Avg batch acc: 0.8841
Train, Epoch: 4, Batch: 15, Step num: 4572, Learning rate: 0.00013072, Avg batch loss: 0.1354, Avg batch acc: 0.8801
Train, Epoch: 4, Batch: 16, Step num: 4573, Learning rate: 0.00013071, Avg batch loss: 0.1054, Avg batch acc: 0.9041
Train, Epoch: 4, Batch: 17, Step num: 4574, Learning rate: 0.00013069, Avg batch loss: 0.1337, Avg batch acc: 0.8973
Train, Epoch: 4, Batch: 18, Step num: 4575, Learning rate: 0.00013068, Avg batch loss: 0.0826, Avg batch acc: 0.9226
Train, Epoch: 4, Batch: 19, Step num: 4576, Learning rate: 0.00013066, Avg batch loss: 0.1418, Avg batch acc: 0.8985
Train, Epoch: 4, Batch: 20, Step num: 4577, Learning rate: 0.00013065, Avg batch loss: 0.1289, Avg batch acc: 0.8857
Train, Epoch: 4, Batch: 21, Step num: 4578, Learning rate: 0.00013063, Avg batch loss: 0.1061, Avg batch acc: 0.9069
Train, Epoch: 4, Batch: 22, Step num: 4579, Learning rate: 0.00013062, Avg batch loss: 0.1192, Avg batch acc: 0.9031
Train, Epoch: 4, Batch: 23, Step num: 4580, Learning rate: 0.00013061, Avg batch loss: 0.0978, Avg batch acc: 0.9114
Train, Epoch: 4, Batch: 24, Step num: 4581, Learning rate: 0.00013059, Avg batch loss: 0.1224, Avg batch acc: 0.9045
Train, Epoch: 4, Batch: 25, Step num: 4582, Learning rate: 0.00013058, Avg batch loss: 0.1097, Avg batch acc: 0.9111
Train, Epoch: 4, Batch: 26, Step num: 4583, Learning rate: 0.00013056, Avg batch loss: 0.1200, Avg batch acc: 0.9043
Train, Epoch: 4, Batch: 27, Step num: 4584, Learning rate: 0.00013055, Avg batch loss: 0.1253, Avg batch acc: 0.9077
Train, Epoch: 4, Batch: 28, Step num: 4585, Learning rate: 0.00013053, Avg batch loss: 0.1132, Avg batch acc: 0.9004
Train, Epoch: 4, Batch: 29, Step num: 4586, Learning rate: 0.00013052, Avg batch loss: 0.1108, Avg batch acc: 0.9033
Train, Epoch: 4, Batch: 30, Step num: 4587, Learning rate: 0.00013051, Avg batch loss: 0.1185, Avg batch acc: 0.9015
Train, Epoch: 4, Batch: 31, Step num: 4588, Learning rate: 0.00013049, Avg batch loss: 0.0944, Avg batch acc: 0.9026
Train, Epoch: 4, Batch: 32, Step num: 4589, Learning rate: 0.00013048, Avg batch loss: 0.1060, Avg batch acc: 0.8996
Train, Epoch: 4, Batch: 33, Step num: 4590, Learning rate: 0.00013046, Avg batch loss: 0.1109, Avg batch acc: 0.9140
Train, Epoch: 4, Batch: 34, Step num: 4591, Learning rate: 0.00013045, Avg batch loss: 0.1147, Avg batch acc: 0.9006
Train, Epoch: 4, Batch: 35, Step num: 4592, Learning rate: 0.00013043, Avg batch loss: 0.1268, Avg batch acc: 0.8938
Train, Epoch: 4, Batch: 36, Step num: 4593, Learning rate: 0.00013042, Avg batch loss: 0.1229, Avg batch acc: 0.8993
Train, Epoch: 4, Batch: 37, Step num: 4594, Learning rate: 0.00013041, Avg batch loss: 0.1176, Avg batch acc: 0.8980
Train, Epoch: 4, Batch: 38, Step num: 4595, Learning rate: 0.00013039, Avg batch loss: 0.1426, Avg batch acc: 0.8891
Train, Epoch: 4, Batch: 39, Step num: 4596, Learning rate: 0.00013038, Avg batch loss: 0.1271, Avg batch acc: 0.8985
Train, Epoch: 4, Batch: 40, Step num: 4597, Learning rate: 0.00013036, Avg batch loss: 0.1191, Avg batch acc: 0.9003
Train, Epoch: 4, Batch: 41, Step num: 4598, Learning rate: 0.00013035, Avg batch loss: 0.1107, Avg batch acc: 0.8992
Train, Epoch: 4, Batch: 42, Step num: 4599, Learning rate: 0.00013034, Avg batch loss: 0.1025, Avg batch acc: 0.9151
Train, Epoch: 4, Batch: 43, Step num: 4600, Learning rate: 0.00013032, Avg batch loss: 0.0881, Avg batch acc: 0.9222
Train, Epoch: 4, Batch: 44, Step num: 4601, Learning rate: 0.00013031, Avg batch loss: 0.1213, Avg batch acc: 0.8962
Train, Epoch: 4, Batch: 45, Step num: 4602, Learning rate: 0.00013029, Avg batch loss: 0.1362, Avg batch acc: 0.8877
Train, Epoch: 4, Batch: 46, Step num: 4603, Learning rate: 0.00013028, Avg batch loss: 0.1205, Avg batch acc: 0.8870
Train, Epoch: 4, Batch: 47, Step num: 4604, Learning rate: 0.00013026, Avg batch loss: 0.1119, Avg batch acc: 0.9006
Train, Epoch: 4, Batch: 48, Step num: 4605, Learning rate: 0.00013025, Avg batch loss: 0.1031, Avg batch acc: 0.9146
Train, Epoch: 4, Batch: 49, Step num: 4606, Learning rate: 0.00013024, Avg batch loss: 0.1009, Avg batch acc: 0.9132
Train, Epoch: 4, Batch: 50, Step num: 4607, Learning rate: 0.00013022, Avg batch loss: 0.1061, Avg batch acc: 0.9068
Train, Epoch: 4, Batch: 51, Step num: 4608, Learning rate: 0.00013021, Avg batch loss: 0.1227, Avg batch acc: 0.8945
Train, Epoch: 4, Batch: 52, Step num: 4609, Learning rate: 0.00013019, Avg batch loss: 0.1092, Avg batch acc: 0.8969
Train, Epoch: 4, Batch: 53, Step num: 4610, Learning rate: 0.00013018, Avg batch loss: 0.0894, Avg batch acc: 0.9146
Train, Epoch: 4, Batch: 54, Step num: 4611, Learning rate: 0.00013017, Avg batch loss: 0.1186, Avg batch acc: 0.9007
Train, Epoch: 4, Batch: 55, Step num: 4612, Learning rate: 0.00013015, Avg batch loss: 0.0974, Avg batch acc: 0.9075
Train, Epoch: 4, Batch: 56, Step num: 4613, Learning rate: 0.00013014, Avg batch loss: 0.1372, Avg batch acc: 0.8983
Train, Epoch: 4, Batch: 57, Step num: 4614, Learning rate: 0.00013012, Avg batch loss: 0.1167, Avg batch acc: 0.9052
Train, Epoch: 4, Batch: 58, Step num: 4615, Learning rate: 0.00013011, Avg batch loss: 0.1143, Avg batch acc: 0.9025
Train, Epoch: 4, Batch: 59, Step num: 4616, Learning rate: 0.00013010, Avg batch loss: 0.1312, Avg batch acc: 0.8993
Train, Epoch: 4, Batch: 60, Step num: 4617, Learning rate: 0.00013008, Avg batch loss: 0.1100, Avg batch acc: 0.8946
Train, Epoch: 4, Batch: 61, Step num: 4618, Learning rate: 0.00013007, Avg batch loss: 0.1087, Avg batch acc: 0.8970
Train, Epoch: 4, Batch: 62, Step num: 4619, Learning rate: 0.00013005, Avg batch loss: 0.1175, Avg batch acc: 0.8965
Train, Epoch: 4, Batch: 63, Step num: 4620, Learning rate: 0.00013004, Avg batch loss: 0.1353, Avg batch acc: 0.8898
Train, Epoch: 4, Batch: 64, Step num: 4621, Learning rate: 0.00013003, Avg batch loss: 0.1086, Avg batch acc: 0.9060
Train, Epoch: 4, Batch: 65, Step num: 4622, Learning rate: 0.00013001, Avg batch loss: 0.1291, Avg batch acc: 0.8941
Train, Epoch: 4, Batch: 66, Step num: 4623, Learning rate: 0.00013000, Avg batch loss: 0.1321, Avg batch acc: 0.8896
Train, Epoch: 4, Batch: 67, Step num: 4624, Learning rate: 0.00012998, Avg batch loss: 0.1124, Avg batch acc: 0.9031
Train, Epoch: 4, Batch: 68, Step num: 4625, Learning rate: 0.00012997, Avg batch loss: 0.1258, Avg batch acc: 0.9015
Train, Epoch: 4, Batch: 69, Step num: 4626, Learning rate: 0.00012995, Avg batch loss: 0.1197, Avg batch acc: 0.9056
Train, Epoch: 4, Batch: 70, Step num: 4627, Learning rate: 0.00012994, Avg batch loss: 0.1058, Avg batch acc: 0.9062
Train, Epoch: 4, Batch: 71, Step num: 4628, Learning rate: 0.00012993, Avg batch loss: 0.1107, Avg batch acc: 0.8965
Train, Epoch: 4, Batch: 72, Step num: 4629, Learning rate: 0.00012991, Avg batch loss: 0.1019, Avg batch acc: 0.9083
Train, Epoch: 4, Batch: 73, Step num: 4630, Learning rate: 0.00012990, Avg batch loss: 0.1360, Avg batch acc: 0.9051
Train, Epoch: 4, Batch: 74, Step num: 4631, Learning rate: 0.00012988, Avg batch loss: 0.1116, Avg batch acc: 0.9144
Train, Epoch: 4, Batch: 75, Step num: 4632, Learning rate: 0.00012987, Avg batch loss: 0.0899, Avg batch acc: 0.9130
Train, Epoch: 4, Batch: 76, Step num: 4633, Learning rate: 0.00012986, Avg batch loss: 0.1140, Avg batch acc: 0.9040
Train, Epoch: 4, Batch: 77, Step num: 4634, Learning rate: 0.00012984, Avg batch loss: 0.1075, Avg batch acc: 0.9104
Train, Epoch: 4, Batch: 78, Step num: 4635, Learning rate: 0.00012983, Avg batch loss: 0.1244, Avg batch acc: 0.8930
Train, Epoch: 4, Batch: 79, Step num: 4636, Learning rate: 0.00012981, Avg batch loss: 0.1182, Avg batch acc: 0.8951
Train, Epoch: 4, Batch: 80, Step num: 4637, Learning rate: 0.00012980, Avg batch loss: 0.1466, Avg batch acc: 0.8957
Train, Epoch: 4, Batch: 81, Step num: 4638, Learning rate: 0.00012979, Avg batch loss: 0.1026, Avg batch acc: 0.9181
Train, Epoch: 4, Batch: 82, Step num: 4639, Learning rate: 0.00012977, Avg batch loss: 0.1123, Avg batch acc: 0.9100
Train, Epoch: 4, Batch: 83, Step num: 4640, Learning rate: 0.00012976, Avg batch loss: 0.1071, Avg batch acc: 0.9111
Train, Epoch: 4, Batch: 84, Step num: 4641, Learning rate: 0.00012974, Avg batch loss: 0.1099, Avg batch acc: 0.9127
Train, Epoch: 4, Batch: 85, Step num: 4642, Learning rate: 0.00012973, Avg batch loss: 0.0993, Avg batch acc: 0.9150
Train, Epoch: 4, Batch: 86, Step num: 4643, Learning rate: 0.00012972, Avg batch loss: 0.1023, Avg batch acc: 0.9102
Train, Epoch: 4, Batch: 87, Step num: 4644, Learning rate: 0.00012970, Avg batch loss: 0.1146, Avg batch acc: 0.9003
Train, Epoch: 4, Batch: 88, Step num: 4645, Learning rate: 0.00012969, Avg batch loss: 0.1142, Avg batch acc: 0.9052
Train, Epoch: 4, Batch: 89, Step num: 4646, Learning rate: 0.00012967, Avg batch loss: 0.1108, Avg batch acc: 0.9067
Train, Epoch: 4, Batch: 90, Step num: 4647, Learning rate: 0.00012966, Avg batch loss: 0.1095, Avg batch acc: 0.9049
Train, Epoch: 4, Batch: 91, Step num: 4648, Learning rate: 0.00012965, Avg batch loss: 0.1107, Avg batch acc: 0.9064
Train, Epoch: 4, Batch: 92, Step num: 4649, Learning rate: 0.00012963, Avg batch loss: 0.1098, Avg batch acc: 0.9006
Train, Epoch: 4, Batch: 93, Step num: 4650, Learning rate: 0.00012962, Avg batch loss: 0.1030, Avg batch acc: 0.9204
Train, Epoch: 4, Batch: 94, Step num: 4651, Learning rate: 0.00012961, Avg batch loss: 0.1109, Avg batch acc: 0.8984
Train, Epoch: 4, Batch: 95, Step num: 4652, Learning rate: 0.00012959, Avg batch loss: 0.1222, Avg batch acc: 0.8971
Train, Epoch: 4, Batch: 96, Step num: 4653, Learning rate: 0.00012958, Avg batch loss: 0.1178, Avg batch acc: 0.9137
Train, Epoch: 4, Batch: 97, Step num: 4654, Learning rate: 0.00012956, Avg batch loss: 0.1310, Avg batch acc: 0.9026
Train, Epoch: 4, Batch: 98, Step num: 4655, Learning rate: 0.00012955, Avg batch loss: 0.1076, Avg batch acc: 0.9131
Train, Epoch: 4, Batch: 99, Step num: 4656, Learning rate: 0.00012954, Avg batch loss: 0.1079, Avg batch acc: 0.9094
Train, Epoch: 4, Batch: 100, Step num: 4657, Learning rate: 0.00012952, Avg batch loss: 0.1119, Avg batch acc: 0.9002
Train, Epoch: 4, Batch: 101, Step num: 4658, Learning rate: 0.00012951, Avg batch loss: 0.1034, Avg batch acc: 0.9004
Train, Epoch: 4, Batch: 102, Step num: 4659, Learning rate: 0.00012949, Avg batch loss: 0.0901, Avg batch acc: 0.9031
Train, Epoch: 4, Batch: 103, Step num: 4660, Learning rate: 0.00012948, Avg batch loss: 0.1002, Avg batch acc: 0.9083
Train, Epoch: 4, Batch: 104, Step num: 4661, Learning rate: 0.00012947, Avg batch loss: 0.1031, Avg batch acc: 0.9150
Train, Epoch: 4, Batch: 105, Step num: 4662, Learning rate: 0.00012945, Avg batch loss: 0.1033, Avg batch acc: 0.9104
Train, Epoch: 4, Batch: 106, Step num: 4663, Learning rate: 0.00012944, Avg batch loss: 0.1158, Avg batch acc: 0.8978
Train, Epoch: 4, Batch: 107, Step num: 4664, Learning rate: 0.00012942, Avg batch loss: 0.1052, Avg batch acc: 0.9190
Train, Epoch: 4, Batch: 108, Step num: 4665, Learning rate: 0.00012941, Avg batch loss: 0.1029, Avg batch acc: 0.9128
Train, Epoch: 4, Batch: 109, Step num: 4666, Learning rate: 0.00012940, Avg batch loss: 0.1005, Avg batch acc: 0.9088
Train, Epoch: 4, Batch: 110, Step num: 4667, Learning rate: 0.00012938, Avg batch loss: 0.0963, Avg batch acc: 0.9159
Train, Epoch: 4, Batch: 111, Step num: 4668, Learning rate: 0.00012937, Avg batch loss: 0.0929, Avg batch acc: 0.9191
Train, Epoch: 4, Batch: 112, Step num: 4669, Learning rate: 0.00012935, Avg batch loss: 0.1092, Avg batch acc: 0.9087
Train, Epoch: 4, Batch: 113, Step num: 4670, Learning rate: 0.00012934, Avg batch loss: 0.1322, Avg batch acc: 0.9039
Train, Epoch: 4, Batch: 114, Step num: 4671, Learning rate: 0.00012933, Avg batch loss: 0.1072, Avg batch acc: 0.9051
Train, Epoch: 4, Batch: 115, Step num: 4672, Learning rate: 0.00012931, Avg batch loss: 0.1080, Avg batch acc: 0.9067
Train, Epoch: 4, Batch: 116, Step num: 4673, Learning rate: 0.00012930, Avg batch loss: 0.1272, Avg batch acc: 0.8965
Train, Epoch: 4, Batch: 117, Step num: 4674, Learning rate: 0.00012929, Avg batch loss: 0.0966, Avg batch acc: 0.9082
Train, Epoch: 4, Batch: 118, Step num: 4675, Learning rate: 0.00012927, Avg batch loss: 0.1033, Avg batch acc: 0.9157
Train, Epoch: 4, Batch: 119, Step num: 4676, Learning rate: 0.00012926, Avg batch loss: 0.1141, Avg batch acc: 0.8981
Train, Epoch: 4, Batch: 120, Step num: 4677, Learning rate: 0.00012924, Avg batch loss: 0.1347, Avg batch acc: 0.8955
Train, Epoch: 4, Batch: 121, Step num: 4678, Learning rate: 0.00012923, Avg batch loss: 0.0992, Avg batch acc: 0.9154
Train, Epoch: 4, Batch: 122, Step num: 4679, Learning rate: 0.00012922, Avg batch loss: 0.1386, Avg batch acc: 0.8999
Train, Epoch: 4, Batch: 123, Step num: 4680, Learning rate: 0.00012920, Avg batch loss: 0.1264, Avg batch acc: 0.8958
Train, Epoch: 4, Batch: 124, Step num: 4681, Learning rate: 0.00012919, Avg batch loss: 0.1252, Avg batch acc: 0.9015
Train, Epoch: 4, Batch: 125, Step num: 4682, Learning rate: 0.00012918, Avg batch loss: 0.1051, Avg batch acc: 0.8975
Train, Epoch: 4, Batch: 126, Step num: 4683, Learning rate: 0.00012916, Avg batch loss: 0.1147, Avg batch acc: 0.9074
Train, Epoch: 4, Batch: 127, Step num: 4684, Learning rate: 0.00012915, Avg batch loss: 0.1499, Avg batch acc: 0.8847
Train, Epoch: 4, Batch: 128, Step num: 4685, Learning rate: 0.00012913, Avg batch loss: 0.1085, Avg batch acc: 0.9010
Train, Epoch: 4, Batch: 129, Step num: 4686, Learning rate: 0.00012912, Avg batch loss: 0.0955, Avg batch acc: 0.9066
Train, Epoch: 4, Batch: 130, Step num: 4687, Learning rate: 0.00012911, Avg batch loss: 0.1023, Avg batch acc: 0.9188
Train, Epoch: 4, Batch: 131, Step num: 4688, Learning rate: 0.00012909, Avg batch loss: 0.1107, Avg batch acc: 0.9052
Train, Epoch: 4, Batch: 132, Step num: 4689, Learning rate: 0.00012908, Avg batch loss: 0.1047, Avg batch acc: 0.9123
Train, Epoch: 4, Batch: 133, Step num: 4690, Learning rate: 0.00012907, Avg batch loss: 0.1093, Avg batch acc: 0.9012
Train, Epoch: 4, Batch: 134, Step num: 4691, Learning rate: 0.00012905, Avg batch loss: 0.1272, Avg batch acc: 0.9066
Train, Epoch: 4, Batch: 135, Step num: 4692, Learning rate: 0.00012904, Avg batch loss: 0.0947, Avg batch acc: 0.9098
Train, Epoch: 4, Batch: 136, Step num: 4693, Learning rate: 0.00012902, Avg batch loss: 0.1234, Avg batch acc: 0.9143
Train, Epoch: 4, Batch: 137, Step num: 4694, Learning rate: 0.00012901, Avg batch loss: 0.1154, Avg batch acc: 0.9093
Train, Epoch: 4, Batch: 138, Step num: 4695, Learning rate: 0.00012900, Avg batch loss: 0.0929, Avg batch acc: 0.9156
Train, Epoch: 4, Batch: 139, Step num: 4696, Learning rate: 0.00012898, Avg batch loss: 0.1321, Avg batch acc: 0.8873
Train, Epoch: 4, Batch: 140, Step num: 4697, Learning rate: 0.00012897, Avg batch loss: 0.1390, Avg batch acc: 0.8991
Train, Epoch: 4, Batch: 141, Step num: 4698, Learning rate: 0.00012896, Avg batch loss: 0.1216, Avg batch acc: 0.9086
Train, Epoch: 4, Batch: 142, Step num: 4699, Learning rate: 0.00012894, Avg batch loss: 0.0997, Avg batch acc: 0.9136
Train, Epoch: 4, Batch: 143, Step num: 4700, Learning rate: 0.00012893, Avg batch loss: 0.1209, Avg batch acc: 0.9018
Train, Epoch: 4, Batch: 144, Step num: 4701, Learning rate: 0.00012891, Avg batch loss: 0.1210, Avg batch acc: 0.8956
Train, Epoch: 4, Batch: 145, Step num: 4702, Learning rate: 0.00012890, Avg batch loss: 0.1181, Avg batch acc: 0.8956
Train, Epoch: 4, Batch: 146, Step num: 4703, Learning rate: 0.00012889, Avg batch loss: 0.0998, Avg batch acc: 0.9045
Train, Epoch: 4, Batch: 147, Step num: 4704, Learning rate: 0.00012887, Avg batch loss: 0.1388, Avg batch acc: 0.8825
Train, Epoch: 4, Batch: 148, Step num: 4705, Learning rate: 0.00012886, Avg batch loss: 0.1107, Avg batch acc: 0.9097
Train, Epoch: 4, Batch: 149, Step num: 4706, Learning rate: 0.00012885, Avg batch loss: 0.1009, Avg batch acc: 0.9167
Train, Epoch: 4, Batch: 150, Step num: 4707, Learning rate: 0.00012883, Avg batch loss: 0.1110, Avg batch acc: 0.9101
Train, Epoch: 4, Batch: 151, Step num: 4708, Learning rate: 0.00012882, Avg batch loss: 0.1024, Avg batch acc: 0.9004
Train, Epoch: 4, Batch: 152, Step num: 4709, Learning rate: 0.00012880, Avg batch loss: 0.1175, Avg batch acc: 0.8980
Train, Epoch: 4, Batch: 153, Step num: 4710, Learning rate: 0.00012879, Avg batch loss: 0.1101, Avg batch acc: 0.9134
Train, Epoch: 4, Batch: 154, Step num: 4711, Learning rate: 0.00012878, Avg batch loss: 0.1158, Avg batch acc: 0.8973
Train, Epoch: 4, Batch: 155, Step num: 4712, Learning rate: 0.00012876, Avg batch loss: 0.1148, Avg batch acc: 0.9114
Train, Epoch: 4, Batch: 156, Step num: 4713, Learning rate: 0.00012875, Avg batch loss: 0.1370, Avg batch acc: 0.9043
Train, Epoch: 4, Batch: 157, Step num: 4714, Learning rate: 0.00012874, Avg batch loss: 0.1039, Avg batch acc: 0.9002
Train, Epoch: 4, Batch: 158, Step num: 4715, Learning rate: 0.00012872, Avg batch loss: 0.1132, Avg batch acc: 0.9055
Train, Epoch: 4, Batch: 159, Step num: 4716, Learning rate: 0.00012871, Avg batch loss: 0.1017, Avg batch acc: 0.9105
Train, Epoch: 4, Batch: 160, Step num: 4717, Learning rate: 0.00012870, Avg batch loss: 0.1049, Avg batch acc: 0.9125
Train, Epoch: 4, Batch: 161, Step num: 4718, Learning rate: 0.00012868, Avg batch loss: 0.1193, Avg batch acc: 0.9023
Train, Epoch: 4, Batch: 162, Step num: 4719, Learning rate: 0.00012867, Avg batch loss: 0.1303, Avg batch acc: 0.9069
Train, Epoch: 4, Batch: 163, Step num: 4720, Learning rate: 0.00012865, Avg batch loss: 0.1172, Avg batch acc: 0.9121
Train, Epoch: 4, Batch: 164, Step num: 4721, Learning rate: 0.00012864, Avg batch loss: 0.0941, Avg batch acc: 0.9183
Train, Epoch: 4, Batch: 165, Step num: 4722, Learning rate: 0.00012863, Avg batch loss: 0.1234, Avg batch acc: 0.9033
Train, Epoch: 4, Batch: 166, Step num: 4723, Learning rate: 0.00012861, Avg batch loss: 0.1055, Avg batch acc: 0.9160
Train, Epoch: 4, Batch: 167, Step num: 4724, Learning rate: 0.00012860, Avg batch loss: 0.1059, Avg batch acc: 0.9078
Train, Epoch: 4, Batch: 168, Step num: 4725, Learning rate: 0.00012859, Avg batch loss: 0.1246, Avg batch acc: 0.9064
Train, Epoch: 4, Batch: 169, Step num: 4726, Learning rate: 0.00012857, Avg batch loss: 0.0991, Avg batch acc: 0.9152
Train, Epoch: 4, Batch: 170, Step num: 4727, Learning rate: 0.00012856, Avg batch loss: 0.1222, Avg batch acc: 0.9039
Train, Epoch: 4, Batch: 171, Step num: 4728, Learning rate: 0.00012855, Avg batch loss: 0.1002, Avg batch acc: 0.9230
Train, Epoch: 4, Batch: 172, Step num: 4729, Learning rate: 0.00012853, Avg batch loss: 0.1236, Avg batch acc: 0.8969
Train, Epoch: 4, Batch: 173, Step num: 4730, Learning rate: 0.00012852, Avg batch loss: 0.1133, Avg batch acc: 0.8982
Train, Epoch: 4, Batch: 174, Step num: 4731, Learning rate: 0.00012850, Avg batch loss: 0.0931, Avg batch acc: 0.9167
Train, Epoch: 4, Batch: 175, Step num: 4732, Learning rate: 0.00012849, Avg batch loss: 0.1041, Avg batch acc: 0.9110
Train, Epoch: 4, Batch: 176, Step num: 4733, Learning rate: 0.00012848, Avg batch loss: 0.1006, Avg batch acc: 0.9188
Train, Epoch: 4, Batch: 177, Step num: 4734, Learning rate: 0.00012846, Avg batch loss: 0.1021, Avg batch acc: 0.9077
Train, Epoch: 4, Batch: 178, Step num: 4735, Learning rate: 0.00012845, Avg batch loss: 0.1110, Avg batch acc: 0.9129
Train, Epoch: 4, Batch: 179, Step num: 4736, Learning rate: 0.00012844, Avg batch loss: 0.1106, Avg batch acc: 0.8994
Train, Epoch: 4, Batch: 180, Step num: 4737, Learning rate: 0.00012842, Avg batch loss: 0.0999, Avg batch acc: 0.9136
Train, Epoch: 4, Batch: 181, Step num: 4738, Learning rate: 0.00012841, Avg batch loss: 0.1217, Avg batch acc: 0.9052
Train, Epoch: 4, Batch: 182, Step num: 4739, Learning rate: 0.00012840, Avg batch loss: 0.0960, Avg batch acc: 0.9177
Train, Epoch: 4, Batch: 183, Step num: 4740, Learning rate: 0.00012838, Avg batch loss: 0.1064, Avg batch acc: 0.9029
Train, Epoch: 4, Batch: 184, Step num: 4741, Learning rate: 0.00012837, Avg batch loss: 0.0806, Avg batch acc: 0.9292
Train, Epoch: 4, Batch: 185, Step num: 4742, Learning rate: 0.00012836, Avg batch loss: 0.1010, Avg batch acc: 0.9176
Train, Epoch: 4, Batch: 186, Step num: 4743, Learning rate: 0.00012834, Avg batch loss: 0.0975, Avg batch acc: 0.9100
Train, Epoch: 4, Batch: 187, Step num: 4744, Learning rate: 0.00012833, Avg batch loss: 0.1276, Avg batch acc: 0.8988
Train, Epoch: 4, Batch: 188, Step num: 4745, Learning rate: 0.00012831, Avg batch loss: 0.0893, Avg batch acc: 0.9110
Train, Epoch: 4, Batch: 189, Step num: 4746, Learning rate: 0.00012830, Avg batch loss: 0.0905, Avg batch acc: 0.9208
Train, Epoch: 4, Batch: 190, Step num: 4747, Learning rate: 0.00012829, Avg batch loss: 0.0985, Avg batch acc: 0.9101
Train, Epoch: 4, Batch: 191, Step num: 4748, Learning rate: 0.00012827, Avg batch loss: 0.1180, Avg batch acc: 0.9112
Train, Epoch: 4, Batch: 192, Step num: 4749, Learning rate: 0.00012826, Avg batch loss: 0.0860, Avg batch acc: 0.9164
Train, Epoch: 4, Batch: 193, Step num: 4750, Learning rate: 0.00012825, Avg batch loss: 0.0969, Avg batch acc: 0.9172
Train, Epoch: 4, Batch: 194, Step num: 4751, Learning rate: 0.00012823, Avg batch loss: 0.0941, Avg batch acc: 0.9100
Train, Epoch: 4, Batch: 195, Step num: 4752, Learning rate: 0.00012822, Avg batch loss: 0.1017, Avg batch acc: 0.9097
Train, Epoch: 4, Batch: 196, Step num: 4753, Learning rate: 0.00012821, Avg batch loss: 0.1268, Avg batch acc: 0.9047
Train, Epoch: 4, Batch: 197, Step num: 4754, Learning rate: 0.00012819, Avg batch loss: 0.1026, Avg batch acc: 0.9048
Train, Epoch: 4, Batch: 198, Step num: 4755, Learning rate: 0.00012818, Avg batch loss: 0.0997, Avg batch acc: 0.9114
Train, Epoch: 4, Batch: 199, Step num: 4756, Learning rate: 0.00012817, Avg batch loss: 0.1082, Avg batch acc: 0.9042
Train, Epoch: 4, Batch: 200, Step num: 4757, Learning rate: 0.00012815, Avg batch loss: 0.1075, Avg batch acc: 0.9012
Train, Epoch: 4, Batch: 201, Step num: 4758, Learning rate: 0.00012814, Avg batch loss: 0.1152, Avg batch acc: 0.9041
Train, Epoch: 4, Batch: 202, Step num: 4759, Learning rate: 0.00012813, Avg batch loss: 0.1010, Avg batch acc: 0.9145
Train, Epoch: 4, Batch: 203, Step num: 4760, Learning rate: 0.00012811, Avg batch loss: 0.1124, Avg batch acc: 0.9059
Train, Epoch: 4, Batch: 204, Step num: 4761, Learning rate: 0.00012810, Avg batch loss: 0.0998, Avg batch acc: 0.9164
Train, Epoch: 4, Batch: 205, Step num: 4762, Learning rate: 0.00012809, Avg batch loss: 0.0955, Avg batch acc: 0.9132
Train, Epoch: 4, Batch: 206, Step num: 4763, Learning rate: 0.00012807, Avg batch loss: 0.1034, Avg batch acc: 0.9085
Train, Epoch: 4, Batch: 207, Step num: 4764, Learning rate: 0.00012806, Avg batch loss: 0.0951, Avg batch acc: 0.9077
Train, Epoch: 4, Batch: 208, Step num: 4765, Learning rate: 0.00012805, Avg batch loss: 0.0936, Avg batch acc: 0.9149
Train, Epoch: 4, Batch: 209, Step num: 4766, Learning rate: 0.00012803, Avg batch loss: 0.1189, Avg batch acc: 0.8944
Train, Epoch: 4, Batch: 210, Step num: 4767, Learning rate: 0.00012802, Avg batch loss: 0.0906, Avg batch acc: 0.9176
Train, Epoch: 4, Batch: 211, Step num: 4768, Learning rate: 0.00012800, Avg batch loss: 0.0944, Avg batch acc: 0.9150
Train, Epoch: 4, Batch: 212, Step num: 4769, Learning rate: 0.00012799, Avg batch loss: 0.0920, Avg batch acc: 0.9143
Train, Epoch: 4, Batch: 213, Step num: 4770, Learning rate: 0.00012798, Avg batch loss: 0.0964, Avg batch acc: 0.9054
Train, Epoch: 4, Batch: 214, Step num: 4771, Learning rate: 0.00012796, Avg batch loss: 0.0875, Avg batch acc: 0.9179
Train, Epoch: 4, Batch: 215, Step num: 4772, Learning rate: 0.00012795, Avg batch loss: 0.0954, Avg batch acc: 0.9203
Train, Epoch: 4, Batch: 216, Step num: 4773, Learning rate: 0.00012794, Avg batch loss: 0.1026, Avg batch acc: 0.9116
Train, Epoch: 4, Batch: 217, Step num: 4774, Learning rate: 0.00012792, Avg batch loss: 0.1085, Avg batch acc: 0.9146
Train, Epoch: 4, Batch: 218, Step num: 4775, Learning rate: 0.00012791, Avg batch loss: 0.0946, Avg batch acc: 0.9173
Train, Epoch: 4, Batch: 219, Step num: 4776, Learning rate: 0.00012790, Avg batch loss: 0.0935, Avg batch acc: 0.9209
Train, Epoch: 4, Batch: 220, Step num: 4777, Learning rate: 0.00012788, Avg batch loss: 0.1210, Avg batch acc: 0.9061
Train, Epoch: 4, Batch: 221, Step num: 4778, Learning rate: 0.00012787, Avg batch loss: 0.0997, Avg batch acc: 0.9015
Train, Epoch: 4, Batch: 222, Step num: 4779, Learning rate: 0.00012786, Avg batch loss: 0.0986, Avg batch acc: 0.9210
Train, Epoch: 4, Batch: 223, Step num: 4780, Learning rate: 0.00012784, Avg batch loss: 0.1041, Avg batch acc: 0.9123
Train, Epoch: 4, Batch: 224, Step num: 4781, Learning rate: 0.00012783, Avg batch loss: 0.0801, Avg batch acc: 0.9196
Train, Epoch: 4, Batch: 225, Step num: 4782, Learning rate: 0.00012782, Avg batch loss: 0.0795, Avg batch acc: 0.9227
Train, Epoch: 4, Batch: 226, Step num: 4783, Learning rate: 0.00012780, Avg batch loss: 0.1237, Avg batch acc: 0.9015
Train, Epoch: 4, Batch: 227, Step num: 4784, Learning rate: 0.00012779, Avg batch loss: 0.1016, Avg batch acc: 0.9135
Train, Epoch: 4, Batch: 228, Step num: 4785, Learning rate: 0.00012778, Avg batch loss: 0.0919, Avg batch acc: 0.9100
Train, Epoch: 4, Batch: 229, Step num: 4786, Learning rate: 0.00012776, Avg batch loss: 0.1024, Avg batch acc: 0.9097
Train, Epoch: 4, Batch: 230, Step num: 4787, Learning rate: 0.00012775, Avg batch loss: 0.0984, Avg batch acc: 0.9024
Train, Epoch: 4, Batch: 231, Step num: 4788, Learning rate: 0.00012774, Avg batch loss: 0.0933, Avg batch acc: 0.9193
Train, Epoch: 4, Batch: 232, Step num: 4789, Learning rate: 0.00012772, Avg batch loss: 0.0847, Avg batch acc: 0.9129
Train, Epoch: 4, Batch: 233, Step num: 4790, Learning rate: 0.00012771, Avg batch loss: 0.0803, Avg batch acc: 0.9157
Train, Epoch: 4, Batch: 234, Step num: 4791, Learning rate: 0.00012770, Avg batch loss: 0.0895, Avg batch acc: 0.9211
Train, Epoch: 4, Batch: 235, Step num: 4792, Learning rate: 0.00012768, Avg batch loss: 0.0830, Avg batch acc: 0.9161
Train, Epoch: 4, Batch: 236, Step num: 4793, Learning rate: 0.00012767, Avg batch loss: 0.1118, Avg batch acc: 0.9088
Train, Epoch: 4, Batch: 237, Step num: 4794, Learning rate: 0.00012766, Avg batch loss: 0.0953, Avg batch acc: 0.9204
Train, Epoch: 4, Batch: 238, Step num: 4795, Learning rate: 0.00012764, Avg batch loss: 0.1066, Avg batch acc: 0.9060
Train, Epoch: 4, Batch: 239, Step num: 4796, Learning rate: 0.00012763, Avg batch loss: 0.0944, Avg batch acc: 0.9237
Train, Epoch: 4, Batch: 240, Step num: 4797, Learning rate: 0.00012762, Avg batch loss: 0.1125, Avg batch acc: 0.9151
Train, Epoch: 4, Batch: 241, Step num: 4798, Learning rate: 0.00012760, Avg batch loss: 0.0779, Avg batch acc: 0.9232
Train, Epoch: 4, Batch: 242, Step num: 4799, Learning rate: 0.00012759, Avg batch loss: 0.1033, Avg batch acc: 0.9068
Train, Epoch: 4, Batch: 243, Step num: 4800, Learning rate: 0.00012758, Avg batch loss: 0.0982, Avg batch acc: 0.9205
Train, Epoch: 4, Batch: 244, Step num: 4801, Learning rate: 0.00012756, Avg batch loss: 0.0847, Avg batch acc: 0.9174
Train, Epoch: 4, Batch: 245, Step num: 4802, Learning rate: 0.00012755, Avg batch loss: 0.0999, Avg batch acc: 0.9143
Train, Epoch: 4, Batch: 246, Step num: 4803, Learning rate: 0.00012754, Avg batch loss: 0.1041, Avg batch acc: 0.9097
Train, Epoch: 4, Batch: 247, Step num: 4804, Learning rate: 0.00012752, Avg batch loss: 0.0900, Avg batch acc: 0.9126
Train, Epoch: 4, Batch: 248, Step num: 4805, Learning rate: 0.00012751, Avg batch loss: 0.0996, Avg batch acc: 0.9097
Train, Epoch: 4, Batch: 249, Step num: 4806, Learning rate: 0.00012750, Avg batch loss: 0.1025, Avg batch acc: 0.9206
Train, Epoch: 4, Batch: 250, Step num: 4807, Learning rate: 0.00012748, Avg batch loss: 0.0874, Avg batch acc: 0.9158
Train, Epoch: 4, Batch: 251, Step num: 4808, Learning rate: 0.00012747, Avg batch loss: 0.0942, Avg batch acc: 0.9058
Train, Epoch: 4, Batch: 252, Step num: 4809, Learning rate: 0.00012746, Avg batch loss: 0.1217, Avg batch acc: 0.8975
Train, Epoch: 4, Batch: 253, Step num: 4810, Learning rate: 0.00012744, Avg batch loss: 0.1077, Avg batch acc: 0.9048
Train, Epoch: 4, Batch: 254, Step num: 4811, Learning rate: 0.00012743, Avg batch loss: 0.1036, Avg batch acc: 0.9083
Train, Epoch: 4, Batch: 255, Step num: 4812, Learning rate: 0.00012742, Avg batch loss: 0.0843, Avg batch acc: 0.9249
Train, Epoch: 4, Batch: 256, Step num: 4813, Learning rate: 0.00012741, Avg batch loss: 0.0955, Avg batch acc: 0.9097
Train, Epoch: 4, Batch: 257, Step num: 4814, Learning rate: 0.00012739, Avg batch loss: 0.0977, Avg batch acc: 0.9128
Train, Epoch: 4, Batch: 258, Step num: 4815, Learning rate: 0.00012738, Avg batch loss: 0.0887, Avg batch acc: 0.9215
Train, Epoch: 4, Batch: 259, Step num: 4816, Learning rate: 0.00012737, Avg batch loss: 0.0932, Avg batch acc: 0.9069
Train, Epoch: 4, Batch: 260, Step num: 4817, Learning rate: 0.00012735, Avg batch loss: 0.0945, Avg batch acc: 0.9164
Train, Epoch: 4, Batch: 261, Step num: 4818, Learning rate: 0.00012734, Avg batch loss: 0.0869, Avg batch acc: 0.9084
Train, Epoch: 4, Batch: 262, Step num: 4819, Learning rate: 0.00012733, Avg batch loss: 0.1056, Avg batch acc: 0.9158
Train, Epoch: 4, Batch: 263, Step num: 4820, Learning rate: 0.00012731, Avg batch loss: 0.1266, Avg batch acc: 0.9018
Train, Epoch: 4, Batch: 264, Step num: 4821, Learning rate: 0.00012730, Avg batch loss: 0.0933, Avg batch acc: 0.9237
Train, Epoch: 4, Batch: 265, Step num: 4822, Learning rate: 0.00012729, Avg batch loss: 0.1081, Avg batch acc: 0.9063
Train, Epoch: 4, Batch: 266, Step num: 4823, Learning rate: 0.00012727, Avg batch loss: 0.0859, Avg batch acc: 0.9169
Train, Epoch: 4, Batch: 267, Step num: 4824, Learning rate: 0.00012726, Avg batch loss: 0.0901, Avg batch acc: 0.9201
Train, Epoch: 4, Batch: 268, Step num: 4825, Learning rate: 0.00012725, Avg batch loss: 0.1022, Avg batch acc: 0.9104
Train, Epoch: 4, Batch: 269, Step num: 4826, Learning rate: 0.00012723, Avg batch loss: 0.0978, Avg batch acc: 0.9059
Train, Epoch: 4, Batch: 270, Step num: 4827, Learning rate: 0.00012722, Avg batch loss: 0.1046, Avg batch acc: 0.9182
Train, Epoch: 4, Batch: 271, Step num: 4828, Learning rate: 0.00012721, Avg batch loss: 0.0979, Avg batch acc: 0.9192
Train, Epoch: 4, Batch: 272, Step num: 4829, Learning rate: 0.00012719, Avg batch loss: 0.0886, Avg batch acc: 0.9112
Train, Epoch: 4, Batch: 273, Step num: 4830, Learning rate: 0.00012718, Avg batch loss: 0.1058, Avg batch acc: 0.9000
Train, Epoch: 4, Batch: 274, Step num: 4831, Learning rate: 0.00012717, Avg batch loss: 0.1031, Avg batch acc: 0.9072
Train, Epoch: 4, Batch: 275, Step num: 4832, Learning rate: 0.00012715, Avg batch loss: 0.0807, Avg batch acc: 0.9223
Train, Epoch: 4, Batch: 276, Step num: 4833, Learning rate: 0.00012714, Avg batch loss: 0.1120, Avg batch acc: 0.9065
Train, Epoch: 4, Batch: 277, Step num: 4834, Learning rate: 0.00012713, Avg batch loss: 0.1103, Avg batch acc: 0.9059
Train, Epoch: 4, Batch: 278, Step num: 4835, Learning rate: 0.00012711, Avg batch loss: 0.0968, Avg batch acc: 0.9176
Train, Epoch: 4, Batch: 279, Step num: 4836, Learning rate: 0.00012710, Avg batch loss: 0.1149, Avg batch acc: 0.9087
Train, Epoch: 4, Batch: 280, Step num: 4837, Learning rate: 0.00012709, Avg batch loss: 0.1039, Avg batch acc: 0.9191
Train, Epoch: 4, Batch: 281, Step num: 4838, Learning rate: 0.00012708, Avg batch loss: 0.0926, Avg batch acc: 0.9124
Train, Epoch: 4, Batch: 282, Step num: 4839, Learning rate: 0.00012706, Avg batch loss: 0.1089, Avg batch acc: 0.9073
Train, Epoch: 4, Batch: 283, Step num: 4840, Learning rate: 0.00012705, Avg batch loss: 0.1111, Avg batch acc: 0.9016
Train, Epoch: 4, Batch: 284, Step num: 4841, Learning rate: 0.00012704, Avg batch loss: 0.1127, Avg batch acc: 0.9124
Train, Epoch: 4, Batch: 285, Step num: 4842, Learning rate: 0.00012702, Avg batch loss: 0.0837, Avg batch acc: 0.9292
Train, Epoch: 4, Batch: 286, Step num: 4843, Learning rate: 0.00012701, Avg batch loss: 0.0999, Avg batch acc: 0.9064
Train, Epoch: 4, Batch: 287, Step num: 4844, Learning rate: 0.00012700, Avg batch loss: 0.0902, Avg batch acc: 0.9157
Train, Epoch: 4, Batch: 288, Step num: 4845, Learning rate: 0.00012698, Avg batch loss: 0.0976, Avg batch acc: 0.9085
Train, Epoch: 4, Batch: 289, Step num: 4846, Learning rate: 0.00012697, Avg batch loss: 0.1119, Avg batch acc: 0.9097
Train, Epoch: 4, Batch: 290, Step num: 4847, Learning rate: 0.00012696, Avg batch loss: 0.1244, Avg batch acc: 0.9093
Train, Epoch: 4, Batch: 291, Step num: 4848, Learning rate: 0.00012694, Avg batch loss: 0.1047, Avg batch acc: 0.9161
Train, Epoch: 4, Batch: 292, Step num: 4849, Learning rate: 0.00012693, Avg batch loss: 0.0906, Avg batch acc: 0.9136
Train, Epoch: 4, Batch: 293, Step num: 4850, Learning rate: 0.00012692, Avg batch loss: 0.0907, Avg batch acc: 0.9268
Train, Epoch: 4, Batch: 294, Step num: 4851, Learning rate: 0.00012691, Avg batch loss: 0.0859, Avg batch acc: 0.9225
Train, Epoch: 4, Batch: 295, Step num: 4852, Learning rate: 0.00012689, Avg batch loss: 0.1031, Avg batch acc: 0.9163
Train, Epoch: 4, Batch: 296, Step num: 4853, Learning rate: 0.00012688, Avg batch loss: 0.1232, Avg batch acc: 0.9083
Train, Epoch: 4, Batch: 297, Step num: 4854, Learning rate: 0.00012687, Avg batch loss: 0.0738, Avg batch acc: 0.9227
Train, Epoch: 4, Batch: 298, Step num: 4855, Learning rate: 0.00012685, Avg batch loss: 0.1252, Avg batch acc: 0.8985
Train, Epoch: 4, Batch: 299, Step num: 4856, Learning rate: 0.00012684, Avg batch loss: 0.0917, Avg batch acc: 0.9165
Train, Epoch: 4, Batch: 300, Step num: 4857, Learning rate: 0.00012683, Avg batch loss: 0.0912, Avg batch acc: 0.9109
Train, Epoch: 4, Batch: 301, Step num: 4858, Learning rate: 0.00012681, Avg batch loss: 0.1041, Avg batch acc: 0.9162
Train, Epoch: 4, Batch: 302, Step num: 4859, Learning rate: 0.00012680, Avg batch loss: 0.1150, Avg batch acc: 0.9067
Train, Epoch: 4, Batch: 303, Step num: 4860, Learning rate: 0.00012679, Avg batch loss: 0.0975, Avg batch acc: 0.9174
Train, Epoch: 4, Batch: 304, Step num: 4861, Learning rate: 0.00012677, Avg batch loss: 0.0833, Avg batch acc: 0.9206
Train, Epoch: 4, Batch: 305, Step num: 4862, Learning rate: 0.00012676, Avg batch loss: 0.0950, Avg batch acc: 0.9178
Train, Epoch: 4, Batch: 306, Step num: 4863, Learning rate: 0.00012675, Avg batch loss: 0.1339, Avg batch acc: 0.8983
Train, Epoch: 4, Batch: 307, Step num: 4864, Learning rate: 0.00012674, Avg batch loss: 0.0885, Avg batch acc: 0.9192
Train, Epoch: 4, Batch: 308, Step num: 4865, Learning rate: 0.00012672, Avg batch loss: 0.1003, Avg batch acc: 0.9104
Train, Epoch: 4, Batch: 309, Step num: 4866, Learning rate: 0.00012671, Avg batch loss: 0.0861, Avg batch acc: 0.9195
Train, Epoch: 4, Batch: 310, Step num: 4867, Learning rate: 0.00012670, Avg batch loss: 0.0862, Avg batch acc: 0.9201
Train, Epoch: 4, Batch: 311, Step num: 4868, Learning rate: 0.00012668, Avg batch loss: 0.0938, Avg batch acc: 0.9165
Train, Epoch: 4, Batch: 312, Step num: 4869, Learning rate: 0.00012667, Avg batch loss: 0.0925, Avg batch acc: 0.9118
Train, Epoch: 4, Batch: 313, Step num: 4870, Learning rate: 0.00012666, Avg batch loss: 0.1131, Avg batch acc: 0.9097
Train, Epoch: 4, Batch: 314, Step num: 4871, Learning rate: 0.00012664, Avg batch loss: 0.1000, Avg batch acc: 0.9048
Train, Epoch: 4, Batch: 315, Step num: 4872, Learning rate: 0.00012663, Avg batch loss: 0.0879, Avg batch acc: 0.9095
Train, Epoch: 4, Batch: 316, Step num: 4873, Learning rate: 0.00012662, Avg batch loss: 0.1011, Avg batch acc: 0.9114
Train, Epoch: 4, Batch: 317, Step num: 4874, Learning rate: 0.00012661, Avg batch loss: 0.1168, Avg batch acc: 0.9054
Train, Epoch: 4, Batch: 318, Step num: 4875, Learning rate: 0.00012659, Avg batch loss: 0.0811, Avg batch acc: 0.9265
Train, Epoch: 4, Batch: 319, Step num: 4876, Learning rate: 0.00012658, Avg batch loss: 0.0935, Avg batch acc: 0.9161
Train, Epoch: 4, Batch: 320, Step num: 4877, Learning rate: 0.00012657, Avg batch loss: 0.1076, Avg batch acc: 0.9134
Train, Epoch: 4, Batch: 321, Step num: 4878, Learning rate: 0.00012655, Avg batch loss: 0.0940, Avg batch acc: 0.9133
Train, Epoch: 4, Batch: 322, Step num: 4879, Learning rate: 0.00012654, Avg batch loss: 0.1129, Avg batch acc: 0.9148
Train, Epoch: 4, Batch: 323, Step num: 4880, Learning rate: 0.00012653, Avg batch loss: 0.0978, Avg batch acc: 0.9116
Train, Epoch: 4, Batch: 324, Step num: 4881, Learning rate: 0.00012651, Avg batch loss: 0.0807, Avg batch acc: 0.9242
Train, Epoch: 4, Batch: 325, Step num: 4882, Learning rate: 0.00012650, Avg batch loss: 0.0832, Avg batch acc: 0.9221
Train, Epoch: 4, Batch: 326, Step num: 4883, Learning rate: 0.00012649, Avg batch loss: 0.0967, Avg batch acc: 0.9165
Train, Epoch: 4, Batch: 327, Step num: 4884, Learning rate: 0.00012648, Avg batch loss: 0.1000, Avg batch acc: 0.9010
Train, Epoch: 4, Batch: 328, Step num: 4885, Learning rate: 0.00012646, Avg batch loss: 0.0971, Avg batch acc: 0.9200
Train, Epoch: 4, Batch: 329, Step num: 4886, Learning rate: 0.00012645, Avg batch loss: 0.0877, Avg batch acc: 0.9138
Train, Epoch: 4, Batch: 330, Step num: 4887, Learning rate: 0.00012644, Avg batch loss: 0.0874, Avg batch acc: 0.9176
Train, Epoch: 4, Batch: 331, Step num: 4888, Learning rate: 0.00012642, Avg batch loss: 0.1143, Avg batch acc: 0.9218
Train, Epoch: 4, Batch: 332, Step num: 4889, Learning rate: 0.00012641, Avg batch loss: 0.0821, Avg batch acc: 0.9276
Train, Epoch: 4, Batch: 333, Step num: 4890, Learning rate: 0.00012640, Avg batch loss: 0.0805, Avg batch acc: 0.9140
Train, Epoch: 4, Batch: 334, Step num: 4891, Learning rate: 0.00012639, Avg batch loss: 0.0818, Avg batch acc: 0.9231
Train, Epoch: 4, Batch: 335, Step num: 4892, Learning rate: 0.00012637, Avg batch loss: 0.0996, Avg batch acc: 0.9213
Train, Epoch: 4, Batch: 336, Step num: 4893, Learning rate: 0.00012636, Avg batch loss: 0.0959, Avg batch acc: 0.9174
Train, Epoch: 4, Batch: 337, Step num: 4894, Learning rate: 0.00012635, Avg batch loss: 0.0964, Avg batch acc: 0.9149
Train, Epoch: 4, Batch: 338, Step num: 4895, Learning rate: 0.00012633, Avg batch loss: 0.0881, Avg batch acc: 0.9120
Train, Epoch: 4, Batch: 339, Step num: 4896, Learning rate: 0.00012632, Avg batch loss: 0.0990, Avg batch acc: 0.9134
Train, Epoch: 4, Batch: 340, Step num: 4897, Learning rate: 0.00012631, Avg batch loss: 0.0913, Avg batch acc: 0.9193
Train, Epoch: 4, Batch: 341, Step num: 4898, Learning rate: 0.00012629, Avg batch loss: 0.1113, Avg batch acc: 0.8965
Train, Epoch: 4, Batch: 342, Step num: 4899, Learning rate: 0.00012628, Avg batch loss: 0.0857, Avg batch acc: 0.9203
Train, Epoch: 4, Batch: 343, Step num: 4900, Learning rate: 0.00012627, Avg batch loss: 0.0792, Avg batch acc: 0.9277
Train, Epoch: 4, Batch: 344, Step num: 4901, Learning rate: 0.00012626, Avg batch loss: 0.1174, Avg batch acc: 0.9100
Train, Epoch: 4, Batch: 345, Step num: 4902, Learning rate: 0.00012624, Avg batch loss: 0.0838, Avg batch acc: 0.9282
Train, Epoch: 4, Batch: 346, Step num: 4903, Learning rate: 0.00012623, Avg batch loss: 0.1166, Avg batch acc: 0.9053
Train, Epoch: 4, Batch: 347, Step num: 4904, Learning rate: 0.00012622, Avg batch loss: 0.0996, Avg batch acc: 0.9113
Train, Epoch: 4, Batch: 348, Step num: 4905, Learning rate: 0.00012620, Avg batch loss: 0.1140, Avg batch acc: 0.9138
Train, Epoch: 4, Batch: 349, Step num: 4906, Learning rate: 0.00012619, Avg batch loss: 0.0920, Avg batch acc: 0.9174
Train, Epoch: 4, Batch: 350, Step num: 4907, Learning rate: 0.00012618, Avg batch loss: 0.0860, Avg batch acc: 0.9223
Train, Epoch: 4, Batch: 351, Step num: 4908, Learning rate: 0.00012617, Avg batch loss: 0.0846, Avg batch acc: 0.9126
Train, Epoch: 4, Batch: 352, Step num: 4909, Learning rate: 0.00012615, Avg batch loss: 0.0867, Avg batch acc: 0.9213
Train, Epoch: 4, Batch: 353, Step num: 4910, Learning rate: 0.00012614, Avg batch loss: 0.0792, Avg batch acc: 0.9203
Train, Epoch: 4, Batch: 354, Step num: 4911, Learning rate: 0.00012613, Avg batch loss: 0.0930, Avg batch acc: 0.9192
Train, Epoch: 4, Batch: 355, Step num: 4912, Learning rate: 0.00012611, Avg batch loss: 0.0718, Avg batch acc: 0.9309
Train, Epoch: 4, Batch: 356, Step num: 4913, Learning rate: 0.00012610, Avg batch loss: 0.1058, Avg batch acc: 0.9103
Train, Epoch: 4, Batch: 357, Step num: 4914, Learning rate: 0.00012609, Avg batch loss: 0.0905, Avg batch acc: 0.9155
Train, Epoch: 4, Batch: 358, Step num: 4915, Learning rate: 0.00012608, Avg batch loss: 0.0821, Avg batch acc: 0.9246
Train, Epoch: 4, Batch: 359, Step num: 4916, Learning rate: 0.00012606, Avg batch loss: 0.0892, Avg batch acc: 0.9161
Train, Epoch: 4, Batch: 360, Step num: 4917, Learning rate: 0.00012605, Avg batch loss: 0.0842, Avg batch acc: 0.9221
Train, Epoch: 4, Batch: 361, Step num: 4918, Learning rate: 0.00012604, Avg batch loss: 0.0863, Avg batch acc: 0.9226
Train, Epoch: 4, Batch: 362, Step num: 4919, Learning rate: 0.00012602, Avg batch loss: 0.0959, Avg batch acc: 0.9201
Train, Epoch: 4, Batch: 363, Step num: 4920, Learning rate: 0.00012601, Avg batch loss: 0.1006, Avg batch acc: 0.9161
Train, Epoch: 4, Batch: 364, Step num: 4921, Learning rate: 0.00012600, Avg batch loss: 0.0961, Avg batch acc: 0.9108
Train, Epoch: 4, Batch: 365, Step num: 4922, Learning rate: 0.00012599, Avg batch loss: 0.1081, Avg batch acc: 0.9131
Train, Epoch: 4, Batch: 366, Step num: 4923, Learning rate: 0.00012597, Avg batch loss: 0.0924, Avg batch acc: 0.9207
Train, Epoch: 4, Batch: 367, Step num: 4924, Learning rate: 0.00012596, Avg batch loss: 0.0998, Avg batch acc: 0.9205
Train, Epoch: 4, Batch: 368, Step num: 4925, Learning rate: 0.00012595, Avg batch loss: 0.0966, Avg batch acc: 0.9223
Train, Epoch: 4, Batch: 369, Step num: 4926, Learning rate: 0.00012594, Avg batch loss: 0.1002, Avg batch acc: 0.9102
Train, Epoch: 4, Batch: 370, Step num: 4927, Learning rate: 0.00012592, Avg batch loss: 0.0826, Avg batch acc: 0.9225
Train, Epoch: 4, Batch: 371, Step num: 4928, Learning rate: 0.00012591, Avg batch loss: 0.0994, Avg batch acc: 0.9139
Train, Epoch: 4, Batch: 372, Step num: 4929, Learning rate: 0.00012590, Avg batch loss: 0.1026, Avg batch acc: 0.9142
Train, Epoch: 4, Batch: 373, Step num: 4930, Learning rate: 0.00012588, Avg batch loss: 0.0928, Avg batch acc: 0.9234
Train, Epoch: 4, Batch: 374, Step num: 4931, Learning rate: 0.00012587, Avg batch loss: 0.0999, Avg batch acc: 0.9142
Train, Epoch: 4, Batch: 375, Step num: 4932, Learning rate: 0.00012586, Avg batch loss: 0.0742, Avg batch acc: 0.9274
Train, Epoch: 4, Batch: 376, Step num: 4933, Learning rate: 0.00012585, Avg batch loss: 0.0833, Avg batch acc: 0.9151
Train, Epoch: 4, Batch: 377, Step num: 4934, Learning rate: 0.00012583, Avg batch loss: 0.1090, Avg batch acc: 0.9076
Train, Epoch: 4, Batch: 378, Step num: 4935, Learning rate: 0.00012582, Avg batch loss: 0.0786, Avg batch acc: 0.9258
Train, Epoch: 4, Batch: 379, Step num: 4936, Learning rate: 0.00012581, Avg batch loss: 0.0823, Avg batch acc: 0.9235
Train, Epoch: 4, Batch: 380, Step num: 4937, Learning rate: 0.00012580, Avg batch loss: 0.0845, Avg batch acc: 0.9178
Train, Epoch: 4, Batch: 381, Step num: 4938, Learning rate: 0.00012578, Avg batch loss: 0.0847, Avg batch acc: 0.9289
Train, Epoch: 4, Batch: 382, Step num: 4939, Learning rate: 0.00012577, Avg batch loss: 0.1001, Avg batch acc: 0.9190
Train, Epoch: 4, Batch: 383, Step num: 4940, Learning rate: 0.00012576, Avg batch loss: 0.0939, Avg batch acc: 0.9206
Train, Epoch: 4, Batch: 384, Step num: 4941, Learning rate: 0.00012574, Avg batch loss: 0.0948, Avg batch acc: 0.9097
Train, Epoch: 4, Batch: 385, Step num: 4942, Learning rate: 0.00012573, Avg batch loss: 0.0801, Avg batch acc: 0.9227
Train, Epoch: 4, Batch: 386, Step num: 4943, Learning rate: 0.00012572, Avg batch loss: 0.0771, Avg batch acc: 0.9290
Train, Epoch: 4, Batch: 387, Step num: 4944, Learning rate: 0.00012571, Avg batch loss: 0.0885, Avg batch acc: 0.9296
Train, Epoch: 4, Batch: 388, Step num: 4945, Learning rate: 0.00012569, Avg batch loss: 0.0876, Avg batch acc: 0.9112
Train, Epoch: 4, Batch: 389, Step num: 4946, Learning rate: 0.00012568, Avg batch loss: 0.0830, Avg batch acc: 0.9223
Train, Epoch: 4, Batch: 390, Step num: 4947, Learning rate: 0.00012567, Avg batch loss: 0.1014, Avg batch acc: 0.9218
Train, Epoch: 4, Batch: 391, Step num: 4948, Learning rate: 0.00012566, Avg batch loss: 0.0750, Avg batch acc: 0.9242
Train, Epoch: 4, Batch: 392, Step num: 4949, Learning rate: 0.00012564, Avg batch loss: 0.0953, Avg batch acc: 0.9243
Train, Epoch: 4, Batch: 393, Step num: 4950, Learning rate: 0.00012563, Avg batch loss: 0.0931, Avg batch acc: 0.9203
Train, Epoch: 4, Batch: 394, Step num: 4951, Learning rate: 0.00012562, Avg batch loss: 0.0886, Avg batch acc: 0.9150
Train, Epoch: 4, Batch: 395, Step num: 4952, Learning rate: 0.00012560, Avg batch loss: 0.0843, Avg batch acc: 0.9225
Train, Epoch: 4, Batch: 396, Step num: 4953, Learning rate: 0.00012559, Avg batch loss: 0.0954, Avg batch acc: 0.9200
Train, Epoch: 4, Batch: 397, Step num: 4954, Learning rate: 0.00012558, Avg batch loss: 0.0978, Avg batch acc: 0.9130
Train, Epoch: 4, Batch: 398, Step num: 4955, Learning rate: 0.00012557, Avg batch loss: 0.0825, Avg batch acc: 0.9237
Train, Epoch: 4, Batch: 399, Step num: 4956, Learning rate: 0.00012555, Avg batch loss: 0.0992, Avg batch acc: 0.9033
Train, Epoch: 4, Batch: 400, Step num: 4957, Learning rate: 0.00012554, Avg batch loss: 0.0813, Avg batch acc: 0.9168
Train, Epoch: 4, Batch: 401, Step num: 4958, Learning rate: 0.00012553, Avg batch loss: 0.0755, Avg batch acc: 0.9274
Train, Epoch: 4, Batch: 402, Step num: 4959, Learning rate: 0.00012552, Avg batch loss: 0.1101, Avg batch acc: 0.9122
Train, Epoch: 4, Batch: 403, Step num: 4960, Learning rate: 0.00012550, Avg batch loss: 0.0989, Avg batch acc: 0.9129
Train, Epoch: 4, Batch: 404, Step num: 4961, Learning rate: 0.00012549, Avg batch loss: 0.0813, Avg batch acc: 0.9297
Train, Epoch: 4, Batch: 405, Step num: 4962, Learning rate: 0.00012548, Avg batch loss: 0.1049, Avg batch acc: 0.9128
Train, Epoch: 4, Batch: 406, Step num: 4963, Learning rate: 0.00012547, Avg batch loss: 0.0949, Avg batch acc: 0.9228
Train, Epoch: 4, Batch: 407, Step num: 4964, Learning rate: 0.00012545, Avg batch loss: 0.0774, Avg batch acc: 0.9204
Train, Epoch: 4, Batch: 408, Step num: 4965, Learning rate: 0.00012544, Avg batch loss: 0.0986, Avg batch acc: 0.9204
Train, Epoch: 4, Batch: 409, Step num: 4966, Learning rate: 0.00012543, Avg batch loss: 0.0846, Avg batch acc: 0.9313
Train, Epoch: 4, Batch: 410, Step num: 4967, Learning rate: 0.00012541, Avg batch loss: 0.0840, Avg batch acc: 0.9288
Train, Epoch: 4, Batch: 411, Step num: 4968, Learning rate: 0.00012540, Avg batch loss: 0.0893, Avg batch acc: 0.9159
Train, Epoch: 4, Batch: 412, Step num: 4969, Learning rate: 0.00012539, Avg batch loss: 0.0872, Avg batch acc: 0.9260
Train, Epoch: 4, Batch: 413, Step num: 4970, Learning rate: 0.00012538, Avg batch loss: 0.0706, Avg batch acc: 0.9296
Train, Epoch: 4, Batch: 414, Step num: 4971, Learning rate: 0.00012536, Avg batch loss: 0.0799, Avg batch acc: 0.9127
Train, Epoch: 4, Batch: 415, Step num: 4972, Learning rate: 0.00012535, Avg batch loss: 0.0844, Avg batch acc: 0.9178
Train, Epoch: 4, Batch: 416, Step num: 4973, Learning rate: 0.00012534, Avg batch loss: 0.0834, Avg batch acc: 0.9282
Train, Epoch: 4, Batch: 417, Step num: 4974, Learning rate: 0.00012533, Avg batch loss: 0.0850, Avg batch acc: 0.9216
Train, Epoch: 4, Batch: 418, Step num: 4975, Learning rate: 0.00012531, Avg batch loss: 0.0783, Avg batch acc: 0.9307
Train, Epoch: 4, Batch: 419, Step num: 4976, Learning rate: 0.00012530, Avg batch loss: 0.0859, Avg batch acc: 0.9281
Train, Epoch: 4, Batch: 420, Step num: 4977, Learning rate: 0.00012529, Avg batch loss: 0.0682, Avg batch acc: 0.9249
Train, Epoch: 4, Batch: 421, Step num: 4978, Learning rate: 0.00012528, Avg batch loss: 0.1071, Avg batch acc: 0.9188
Train, Epoch: 4, Batch: 422, Step num: 4979, Learning rate: 0.00012526, Avg batch loss: 0.0943, Avg batch acc: 0.9231
Train, Epoch: 4, Batch: 423, Step num: 4980, Learning rate: 0.00012525, Avg batch loss: 0.1092, Avg batch acc: 0.9118
Train, Epoch: 4, Batch: 424, Step num: 4981, Learning rate: 0.00012524, Avg batch loss: 0.0753, Avg batch acc: 0.9359
Train, Epoch: 4, Batch: 425, Step num: 4982, Learning rate: 0.00012523, Avg batch loss: 0.0918, Avg batch acc: 0.9152
Train, Epoch: 4, Batch: 426, Step num: 4983, Learning rate: 0.00012521, Avg batch loss: 0.1036, Avg batch acc: 0.9147
Train, Epoch: 4, Batch: 427, Step num: 4984, Learning rate: 0.00012520, Avg batch loss: 0.0962, Avg batch acc: 0.9226
Train, Epoch: 4, Batch: 428, Step num: 4985, Learning rate: 0.00012519, Avg batch loss: 0.0856, Avg batch acc: 0.9176
Train, Epoch: 4, Batch: 429, Step num: 4986, Learning rate: 0.00012518, Avg batch loss: 0.0895, Avg batch acc: 0.9295
Train, Epoch: 4, Batch: 430, Step num: 4987, Learning rate: 0.00012516, Avg batch loss: 0.0845, Avg batch acc: 0.9254
Train, Epoch: 4, Batch: 431, Step num: 4988, Learning rate: 0.00012515, Avg batch loss: 0.0980, Avg batch acc: 0.9208
Train, Epoch: 4, Batch: 432, Step num: 4989, Learning rate: 0.00012514, Avg batch loss: 0.0901, Avg batch acc: 0.9222
Train, Epoch: 4, Batch: 433, Step num: 4990, Learning rate: 0.00012513, Avg batch loss: 0.0773, Avg batch acc: 0.9300
Train, Epoch: 4, Batch: 434, Step num: 4991, Learning rate: 0.00012511, Avg batch loss: 0.0761, Avg batch acc: 0.9267
Train, Epoch: 4, Batch: 435, Step num: 4992, Learning rate: 0.00012510, Avg batch loss: 0.0759, Avg batch acc: 0.9302
Train, Epoch: 4, Batch: 436, Step num: 4993, Learning rate: 0.00012509, Avg batch loss: 0.1018, Avg batch acc: 0.9186
Train, Epoch: 4, Batch: 437, Step num: 4994, Learning rate: 0.00012508, Avg batch loss: 0.0670, Avg batch acc: 0.9281
Train, Epoch: 4, Batch: 438, Step num: 4995, Learning rate: 0.00012506, Avg batch loss: 0.0787, Avg batch acc: 0.9220
Train, Epoch: 4, Batch: 439, Step num: 4996, Learning rate: 0.00012505, Avg batch loss: 0.0676, Avg batch acc: 0.9335
Train, Epoch: 4, Batch: 440, Step num: 4997, Learning rate: 0.00012504, Avg batch loss: 0.0680, Avg batch acc: 0.9341
Train, Epoch: 4, Batch: 441, Step num: 4998, Learning rate: 0.00012503, Avg batch loss: 0.0810, Avg batch acc: 0.9173
Train, Epoch: 4, Batch: 442, Step num: 4999, Learning rate: 0.00012501, Avg batch loss: 0.0689, Avg batch acc: 0.9270
Train, Epoch: 4, Batch: 443, Step num: 5000, Learning rate: 0.00012500, Avg batch loss: 0.0969, Avg batch acc: 0.9242
Train, Epoch: 4, Batch: 444, Step num: 5001, Learning rate: 0.00012499, Avg batch loss: 0.0750, Avg batch acc: 0.9267
Train, Epoch: 4, Batch: 445, Step num: 5002, Learning rate: 0.00012498, Avg batch loss: 0.1011, Avg batch acc: 0.9219
Train, Epoch: 4, Batch: 446, Step num: 5003, Learning rate: 0.00012496, Avg batch loss: 0.0816, Avg batch acc: 0.9244
Train, Epoch: 4, Batch: 447, Step num: 5004, Learning rate: 0.00012495, Avg batch loss: 0.0987, Avg batch acc: 0.9200
Train, Epoch: 4, Batch: 448, Step num: 5005, Learning rate: 0.00012494, Avg batch loss: 0.0855, Avg batch acc: 0.9219
Train, Epoch: 4, Batch: 449, Step num: 5006, Learning rate: 0.00012493, Avg batch loss: 0.0908, Avg batch acc: 0.9214
Train, Epoch: 4, Batch: 450, Step num: 5007, Learning rate: 0.00012491, Avg batch loss: 0.0821, Avg batch acc: 0.9238
Train, Epoch: 4, Batch: 451, Step num: 5008, Learning rate: 0.00012490, Avg batch loss: 0.0728, Avg batch acc: 0.9288
Train, Epoch: 4, Batch: 452, Step num: 5009, Learning rate: 0.00012489, Avg batch loss: 0.0706, Avg batch acc: 0.9252
Train, Epoch: 4, Batch: 453, Step num: 5010, Learning rate: 0.00012488, Avg batch loss: 0.0696, Avg batch acc: 0.9412
Train, Epoch: 4, Batch: 454, Step num: 5011, Learning rate: 0.00012486, Avg batch loss: 0.1005, Avg batch acc: 0.9190
Train, Epoch: 4, Batch: 455, Step num: 5012, Learning rate: 0.00012485, Avg batch loss: 0.0797, Avg batch acc: 0.9331
Train, Epoch: 4, Batch: 456, Step num: 5013, Learning rate: 0.00012484, Avg batch loss: 0.0752, Avg batch acc: 0.9296
Train, Epoch: 4, Batch: 457, Step num: 5014, Learning rate: 0.00012483, Avg batch loss: 0.0836, Avg batch acc: 0.9258
Train, Epoch: 4, Batch: 458, Step num: 5015, Learning rate: 0.00012481, Avg batch loss: 0.0791, Avg batch acc: 0.9290
Train, Epoch: 4, Batch: 459, Step num: 5016, Learning rate: 0.00012480, Avg batch loss: 0.0616, Avg batch acc: 0.9411
Train, Epoch: 4, Batch: 460, Step num: 5017, Learning rate: 0.00012479, Avg batch loss: 0.0846, Avg batch acc: 0.9196
Train, Epoch: 4, Batch: 461, Step num: 5018, Learning rate: 0.00012478, Avg batch loss: 0.0855, Avg batch acc: 0.9201
Train, Epoch: 4, Batch: 462, Step num: 5019, Learning rate: 0.00012476, Avg batch loss: 0.0877, Avg batch acc: 0.9125
Train, Epoch: 4, Batch: 463, Step num: 5020, Learning rate: 0.00012475, Avg batch loss: 0.1001, Avg batch acc: 0.9193
Train, Epoch: 4, Batch: 464, Step num: 5021, Learning rate: 0.00012474, Avg batch loss: 0.0934, Avg batch acc: 0.9120
Train, Epoch: 4, Batch: 465, Step num: 5022, Learning rate: 0.00012473, Avg batch loss: 0.0720, Avg batch acc: 0.9307
Train, Epoch: 4, Batch: 466, Step num: 5023, Learning rate: 0.00012471, Avg batch loss: 0.0831, Avg batch acc: 0.9224
Train, Epoch: 4, Batch: 467, Step num: 5024, Learning rate: 0.00012470, Avg batch loss: 0.0875, Avg batch acc: 0.9252
Train, Epoch: 4, Batch: 468, Step num: 5025, Learning rate: 0.00012469, Avg batch loss: 0.0797, Avg batch acc: 0.9297
Train, Epoch: 4, Batch: 469, Step num: 5026, Learning rate: 0.00012468, Avg batch loss: 0.1033, Avg batch acc: 0.9233
Train, Epoch: 4, Batch: 470, Step num: 5027, Learning rate: 0.00012466, Avg batch loss: 0.0826, Avg batch acc: 0.9241
Train, Epoch: 4, Batch: 471, Step num: 5028, Learning rate: 0.00012465, Avg batch loss: 0.0927, Avg batch acc: 0.9214
Train, Epoch: 4, Batch: 472, Step num: 5029, Learning rate: 0.00012464, Avg batch loss: 0.0719, Avg batch acc: 0.9285
Train, Epoch: 4, Batch: 473, Step num: 5030, Learning rate: 0.00012463, Avg batch loss: 0.0855, Avg batch acc: 0.9212
Train, Epoch: 4, Batch: 474, Step num: 5031, Learning rate: 0.00012461, Avg batch loss: 0.0825, Avg batch acc: 0.9196
Train, Epoch: 4, Batch: 475, Step num: 5032, Learning rate: 0.00012460, Avg batch loss: 0.0751, Avg batch acc: 0.9262
Train, Epoch: 4, Batch: 476, Step num: 5033, Learning rate: 0.00012459, Avg batch loss: 0.0936, Avg batch acc: 0.9203
Train, Epoch: 4, Batch: 477, Step num: 5034, Learning rate: 0.00012458, Avg batch loss: 0.0728, Avg batch acc: 0.9313
Train, Epoch: 4, Batch: 478, Step num: 5035, Learning rate: 0.00012456, Avg batch loss: 0.0802, Avg batch acc: 0.9269
Train, Epoch: 4, Batch: 479, Step num: 5036, Learning rate: 0.00012455, Avg batch loss: 0.0826, Avg batch acc: 0.9269
Train, Epoch: 4, Batch: 480, Step num: 5037, Learning rate: 0.00012454, Avg batch loss: 0.0770, Avg batch acc: 0.9229
Train, Epoch: 4, Batch: 481, Step num: 5038, Learning rate: 0.00012453, Avg batch loss: 0.0742, Avg batch acc: 0.9252
Train, Epoch: 4, Batch: 482, Step num: 5039, Learning rate: 0.00012452, Avg batch loss: 0.0828, Avg batch acc: 0.9273
Train, Epoch: 4, Batch: 483, Step num: 5040, Learning rate: 0.00012450, Avg batch loss: 0.0783, Avg batch acc: 0.9244
Train, Epoch: 4, Batch: 484, Step num: 5041, Learning rate: 0.00012449, Avg batch loss: 0.1211, Avg batch acc: 0.9214
Train, Epoch: 4, Batch: 485, Step num: 5042, Learning rate: 0.00012448, Avg batch loss: 0.0727, Avg batch acc: 0.9331
Train, Epoch: 4, Batch: 486, Step num: 5043, Learning rate: 0.00012447, Avg batch loss: 0.0832, Avg batch acc: 0.9256
Train, Epoch: 4, Batch: 487, Step num: 5044, Learning rate: 0.00012445, Avg batch loss: 0.0950, Avg batch acc: 0.9214
Train, Epoch: 4, Batch: 488, Step num: 5045, Learning rate: 0.00012444, Avg batch loss: 0.0971, Avg batch acc: 0.9083
Train, Epoch: 4, Batch: 489, Step num: 5046, Learning rate: 0.00012443, Avg batch loss: 0.0638, Avg batch acc: 0.9394
Train, Epoch: 4, Batch: 490, Step num: 5047, Learning rate: 0.00012442, Avg batch loss: 0.0742, Avg batch acc: 0.9287
Train, Epoch: 4, Batch: 491, Step num: 5048, Learning rate: 0.00012440, Avg batch loss: 0.0943, Avg batch acc: 0.9189
Train, Epoch: 4, Batch: 492, Step num: 5049, Learning rate: 0.00012439, Avg batch loss: 0.1011, Avg batch acc: 0.9096
Train, Epoch: 4, Batch: 493, Step num: 5050, Learning rate: 0.00012438, Avg batch loss: 0.0934, Avg batch acc: 0.9238
Train, Epoch: 4, Batch: 494, Step num: 5051, Learning rate: 0.00012437, Avg batch loss: 0.0818, Avg batch acc: 0.9275
Train, Epoch: 4, Batch: 495, Step num: 5052, Learning rate: 0.00012436, Avg batch loss: 0.0862, Avg batch acc: 0.9203
Train, Epoch: 4, Batch: 496, Step num: 5053, Learning rate: 0.00012434, Avg batch loss: 0.0907, Avg batch acc: 0.9246
Train, Epoch: 4, Batch: 497, Step num: 5054, Learning rate: 0.00012433, Avg batch loss: 0.0895, Avg batch acc: 0.9281
Train, Epoch: 4, Batch: 498, Step num: 5055, Learning rate: 0.00012432, Avg batch loss: 0.1020, Avg batch acc: 0.9181
Train, Epoch: 4, Batch: 499, Step num: 5056, Learning rate: 0.00012431, Avg batch loss: 0.0736, Avg batch acc: 0.9340
Train, Epoch: 4, Batch: 500, Step num: 5057, Learning rate: 0.00012429, Avg batch loss: 0.0823, Avg batch acc: 0.9244
Train, Epoch: 4, Batch: 501, Step num: 5058, Learning rate: 0.00012428, Avg batch loss: 0.1012, Avg batch acc: 0.9204
Train, Epoch: 4, Batch: 502, Step num: 5059, Learning rate: 0.00012427, Avg batch loss: 0.0877, Avg batch acc: 0.9224
Train, Epoch: 4, Batch: 503, Step num: 5060, Learning rate: 0.00012426, Avg batch loss: 0.0759, Avg batch acc: 0.9228
Train, Epoch: 4, Batch: 504, Step num: 5061, Learning rate: 0.00012424, Avg batch loss: 0.0631, Avg batch acc: 0.9309
Train, Epoch: 4, Batch: 505, Step num: 5062, Learning rate: 0.00012423, Avg batch loss: 0.0787, Avg batch acc: 0.9293
Train, Epoch: 4, Batch: 506, Step num: 5063, Learning rate: 0.00012422, Avg batch loss: 0.0824, Avg batch acc: 0.9212
Train, Epoch: 4, Batch: 507, Step num: 5064, Learning rate: 0.00012421, Avg batch loss: 0.0809, Avg batch acc: 0.9196
Train, Epoch: 4, Batch: 508, Step num: 5065, Learning rate: 0.00012420, Avg batch loss: 0.0677, Avg batch acc: 0.9306
Train, Epoch: 4, Batch: 509, Step num: 5066, Learning rate: 0.00012418, Avg batch loss: 0.0695, Avg batch acc: 0.9293
Train, Epoch: 4, Batch: 510, Step num: 5067, Learning rate: 0.00012417, Avg batch loss: 0.0797, Avg batch acc: 0.9327
Train, Epoch: 4, Batch: 511, Step num: 5068, Learning rate: 0.00012416, Avg batch loss: 0.0796, Avg batch acc: 0.9256
Train, Epoch: 4, Batch: 512, Step num: 5069, Learning rate: 0.00012415, Avg batch loss: 0.0903, Avg batch acc: 0.9232
Train, Epoch: 4, Batch: 513, Step num: 5070, Learning rate: 0.00012413, Avg batch loss: 0.0848, Avg batch acc: 0.9218
Train, Epoch: 4, Batch: 514, Step num: 5071, Learning rate: 0.00012412, Avg batch loss: 0.0736, Avg batch acc: 0.9278
Train, Epoch: 4, Batch: 515, Step num: 5072, Learning rate: 0.00012411, Avg batch loss: 0.0711, Avg batch acc: 0.9291
Train, Epoch: 4, Batch: 516, Step num: 5073, Learning rate: 0.00012410, Avg batch loss: 0.0739, Avg batch acc: 0.9348
Train, Epoch: 4, Batch: 517, Step num: 5074, Learning rate: 0.00012409, Avg batch loss: 0.0942, Avg batch acc: 0.9265
Train, Epoch: 4, Batch: 518, Step num: 5075, Learning rate: 0.00012407, Avg batch loss: 0.0859, Avg batch acc: 0.9250
Train, Epoch: 4, Batch: 519, Step num: 5076, Learning rate: 0.00012406, Avg batch loss: 0.0723, Avg batch acc: 0.9299
Train, Epoch: 4, Batch: 520, Step num: 5077, Learning rate: 0.00012405, Avg batch loss: 0.0721, Avg batch acc: 0.9277
Train, Epoch: 4, Batch: 521, Step num: 5078, Learning rate: 0.00012404, Avg batch loss: 0.0923, Avg batch acc: 0.9143
Train, Epoch: 4, Batch: 522, Step num: 5079, Learning rate: 0.00012402, Avg batch loss: 0.0794, Avg batch acc: 0.9286
Train, Epoch: 4, Batch: 523, Step num: 5080, Learning rate: 0.00012401, Avg batch loss: 0.0845, Avg batch acc: 0.9234
Train, Epoch: 4, Batch: 524, Step num: 5081, Learning rate: 0.00012400, Avg batch loss: 0.0796, Avg batch acc: 0.9235
Train, Epoch: 4, Batch: 525, Step num: 5082, Learning rate: 0.00012399, Avg batch loss: 0.0717, Avg batch acc: 0.9337
Train, Epoch: 4, Batch: 526, Step num: 5083, Learning rate: 0.00012398, Avg batch loss: 0.0909, Avg batch acc: 0.9257
Train, Epoch: 4, Batch: 527, Step num: 5084, Learning rate: 0.00012396, Avg batch loss: 0.0758, Avg batch acc: 0.9313
Train, Epoch: 4, Batch: 528, Step num: 5085, Learning rate: 0.00012395, Avg batch loss: 0.0837, Avg batch acc: 0.9246
Train, Epoch: 4, Batch: 529, Step num: 5086, Learning rate: 0.00012394, Avg batch loss: 0.0739, Avg batch acc: 0.9290
Train, Epoch: 4, Batch: 530, Step num: 5087, Learning rate: 0.00012393, Avg batch loss: 0.0794, Avg batch acc: 0.9324
Train, Epoch: 4, Batch: 531, Step num: 5088, Learning rate: 0.00012391, Avg batch loss: 0.0779, Avg batch acc: 0.9334
Train, Epoch: 4, Batch: 532, Step num: 5089, Learning rate: 0.00012390, Avg batch loss: 0.0757, Avg batch acc: 0.9336
Train, Epoch: 4, Batch: 533, Step num: 5090, Learning rate: 0.00012389, Avg batch loss: 0.0772, Avg batch acc: 0.9278
Train, Epoch: 4, Batch: 534, Step num: 5091, Learning rate: 0.00012388, Avg batch loss: 0.0806, Avg batch acc: 0.9179
Train, Epoch: 4, Batch: 535, Step num: 5092, Learning rate: 0.00012387, Avg batch loss: 0.0809, Avg batch acc: 0.9304
Train, Epoch: 4, Batch: 536, Step num: 5093, Learning rate: 0.00012385, Avg batch loss: 0.0735, Avg batch acc: 0.9407
Train, Epoch: 4, Batch: 537, Step num: 5094, Learning rate: 0.00012384, Avg batch loss: 0.0714, Avg batch acc: 0.9248
Train, Epoch: 4, Batch: 538, Step num: 5095, Learning rate: 0.00012383, Avg batch loss: 0.0777, Avg batch acc: 0.9360
Train, Epoch: 4, Batch: 539, Step num: 5096, Learning rate: 0.00012382, Avg batch loss: 0.0920, Avg batch acc: 0.9293
Train, Epoch: 4, Batch: 540, Step num: 5097, Learning rate: 0.00012380, Avg batch loss: 0.0841, Avg batch acc: 0.9321
Train, Epoch: 4, Batch: 541, Step num: 5098, Learning rate: 0.00012379, Avg batch loss: 0.0768, Avg batch acc: 0.9303
Train, Epoch: 4, Batch: 542, Step num: 5099, Learning rate: 0.00012378, Avg batch loss: 0.0819, Avg batch acc: 0.9255
Train, Epoch: 4, Batch: 543, Step num: 5100, Learning rate: 0.00012377, Avg batch loss: 0.0741, Avg batch acc: 0.9216
Train, Epoch: 4, Batch: 544, Step num: 5101, Learning rate: 0.00012376, Avg batch loss: 0.0780, Avg batch acc: 0.9357
Train, Epoch: 4, Batch: 545, Step num: 5102, Learning rate: 0.00012374, Avg batch loss: 0.0823, Avg batch acc: 0.9255
Train, Epoch: 4, Batch: 546, Step num: 5103, Learning rate: 0.00012373, Avg batch loss: 0.0959, Avg batch acc: 0.9188
Train, Epoch: 4, Batch: 547, Step num: 5104, Learning rate: 0.00012372, Avg batch loss: 0.0879, Avg batch acc: 0.9184
Train, Epoch: 4, Batch: 548, Step num: 5105, Learning rate: 0.00012371, Avg batch loss: 0.0623, Avg batch acc: 0.9388
Train, Epoch: 4, Batch: 549, Step num: 5106, Learning rate: 0.00012370, Avg batch loss: 0.0734, Avg batch acc: 0.9269
Train, Epoch: 4, Batch: 550, Step num: 5107, Learning rate: 0.00012368, Avg batch loss: 0.0785, Avg batch acc: 0.9264
Train, Epoch: 4, Batch: 551, Step num: 5108, Learning rate: 0.00012367, Avg batch loss: 0.0917, Avg batch acc: 0.9147
Train, Epoch: 4, Batch: 552, Step num: 5109, Learning rate: 0.00012366, Avg batch loss: 0.0727, Avg batch acc: 0.9347
Train, Epoch: 4, Batch: 553, Step num: 5110, Learning rate: 0.00012365, Avg batch loss: 0.0871, Avg batch acc: 0.9118
Train, Epoch: 4, Batch: 554, Step num: 5111, Learning rate: 0.00012364, Avg batch loss: 0.0810, Avg batch acc: 0.9301
Train, Epoch: 4, Batch: 555, Step num: 5112, Learning rate: 0.00012362, Avg batch loss: 0.0903, Avg batch acc: 0.9191
Train, Epoch: 4, Batch: 556, Step num: 5113, Learning rate: 0.00012361, Avg batch loss: 0.0757, Avg batch acc: 0.9356
Train, Epoch: 4, Batch: 557, Step num: 5114, Learning rate: 0.00012360, Avg batch loss: 0.0847, Avg batch acc: 0.9274
Train, Epoch: 4, Batch: 558, Step num: 5115, Learning rate: 0.00012359, Avg batch loss: 0.0701, Avg batch acc: 0.9304
Train, Epoch: 4, Batch: 559, Step num: 5116, Learning rate: 0.00012357, Avg batch loss: 0.0894, Avg batch acc: 0.9219
Train, Epoch: 4, Batch: 560, Step num: 5117, Learning rate: 0.00012356, Avg batch loss: 0.0816, Avg batch acc: 0.9276
Train, Epoch: 4, Batch: 561, Step num: 5118, Learning rate: 0.00012355, Avg batch loss: 0.0938, Avg batch acc: 0.9230
Train, Epoch: 4, Batch: 562, Step num: 5119, Learning rate: 0.00012354, Avg batch loss: 0.0746, Avg batch acc: 0.9291
Train, Epoch: 4, Batch: 563, Step num: 5120, Learning rate: 0.00012353, Avg batch loss: 0.0887, Avg batch acc: 0.9252
Train, Epoch: 4, Batch: 564, Step num: 5121, Learning rate: 0.00012351, Avg batch loss: 0.0978, Avg batch acc: 0.9258
Train, Epoch: 4, Batch: 565, Step num: 5122, Learning rate: 0.00012350, Avg batch loss: 0.0817, Avg batch acc: 0.9292
Train, Epoch: 4, Batch: 566, Step num: 5123, Learning rate: 0.00012349, Avg batch loss: 0.0971, Avg batch acc: 0.9231
Train, Epoch: 4, Batch: 567, Step num: 5124, Learning rate: 0.00012348, Avg batch loss: 0.0895, Avg batch acc: 0.9232
Train, Epoch: 4, Batch: 568, Step num: 5125, Learning rate: 0.00012347, Avg batch loss: 0.0800, Avg batch acc: 0.9241
Train, Epoch: 4, Batch: 569, Step num: 5126, Learning rate: 0.00012345, Avg batch loss: 0.0734, Avg batch acc: 0.9228
Train, Epoch: 4, Batch: 570, Step num: 5127, Learning rate: 0.00012344, Avg batch loss: 0.0816, Avg batch acc: 0.9347
Train, Epoch: 4, Batch: 571, Step num: 5128, Learning rate: 0.00012343, Avg batch loss: 0.0977, Avg batch acc: 0.9161
Train, Epoch: 4, Batch: 572, Step num: 5129, Learning rate: 0.00012342, Avg batch loss: 0.0809, Avg batch acc: 0.9193
Train, Epoch: 4, Batch: 573, Step num: 5130, Learning rate: 0.00012341, Avg batch loss: 0.0806, Avg batch acc: 0.9138
Train, Epoch: 4, Batch: 574, Step num: 5131, Learning rate: 0.00012339, Avg batch loss: 0.0849, Avg batch acc: 0.9289
Train, Epoch: 4, Batch: 575, Step num: 5132, Learning rate: 0.00012338, Avg batch loss: 0.0718, Avg batch acc: 0.9386
Train, Epoch: 4, Batch: 576, Step num: 5133, Learning rate: 0.00012337, Avg batch loss: 0.0773, Avg batch acc: 0.9358
Train, Epoch: 4, Batch: 577, Step num: 5134, Learning rate: 0.00012336, Avg batch loss: 0.0843, Avg batch acc: 0.9265
Train, Epoch: 4, Batch: 578, Step num: 5135, Learning rate: 0.00012335, Avg batch loss: 0.0974, Avg batch acc: 0.9214
Train, Epoch: 4, Batch: 579, Step num: 5136, Learning rate: 0.00012333, Avg batch loss: 0.0902, Avg batch acc: 0.9201
Train, Epoch: 4, Batch: 580, Step num: 5137, Learning rate: 0.00012332, Avg batch loss: 0.0660, Avg batch acc: 0.9324
Train, Epoch: 4, Batch: 581, Step num: 5138, Learning rate: 0.00012331, Avg batch loss: 0.0731, Avg batch acc: 0.9334
Train, Epoch: 4, Batch: 582, Step num: 5139, Learning rate: 0.00012330, Avg batch loss: 0.0987, Avg batch acc: 0.9179
Train, Epoch: 4, Batch: 583, Step num: 5140, Learning rate: 0.00012329, Avg batch loss: 0.0672, Avg batch acc: 0.9331
Train, Epoch: 4, Batch: 584, Step num: 5141, Learning rate: 0.00012327, Avg batch loss: 0.0819, Avg batch acc: 0.9209
Train, Epoch: 4, Batch: 585, Step num: 5142, Learning rate: 0.00012326, Avg batch loss: 0.0924, Avg batch acc: 0.9205
Train, Epoch: 4, Batch: 586, Step num: 5143, Learning rate: 0.00012325, Avg batch loss: 0.0727, Avg batch acc: 0.9271
Train, Epoch: 4, Batch: 587, Step num: 5144, Learning rate: 0.00012324, Avg batch loss: 0.0725, Avg batch acc: 0.9308
Train, Epoch: 4, Batch: 588, Step num: 5145, Learning rate: 0.00012323, Avg batch loss: 0.0790, Avg batch acc: 0.9270
Train, Epoch: 4, Batch: 589, Step num: 5146, Learning rate: 0.00012321, Avg batch loss: 0.0871, Avg batch acc: 0.9257
Train, Epoch: 4, Batch: 590, Step num: 5147, Learning rate: 0.00012320, Avg batch loss: 0.0728, Avg batch acc: 0.9242
Train, Epoch: 4, Batch: 591, Step num: 5148, Learning rate: 0.00012319, Avg batch loss: 0.0959, Avg batch acc: 0.9228
Train, Epoch: 4, Batch: 592, Step num: 5149, Learning rate: 0.00012318, Avg batch loss: 0.0850, Avg batch acc: 0.9232
Train, Epoch: 4, Batch: 593, Step num: 5150, Learning rate: 0.00012317, Avg batch loss: 0.0832, Avg batch acc: 0.9306
Train, Epoch: 4, Batch: 594, Step num: 5151, Learning rate: 0.00012315, Avg batch loss: 0.0639, Avg batch acc: 0.9344
Train, Epoch: 4, Batch: 595, Step num: 5152, Learning rate: 0.00012314, Avg batch loss: 0.0810, Avg batch acc: 0.9230
Train, Epoch: 4, Batch: 596, Step num: 5153, Learning rate: 0.00012313, Avg batch loss: 0.0768, Avg batch acc: 0.9300
Train, Epoch: 4, Batch: 597, Step num: 5154, Learning rate: 0.00012312, Avg batch loss: 0.0729, Avg batch acc: 0.9292
Train, Epoch: 4, Batch: 598, Step num: 5155, Learning rate: 0.00012311, Avg batch loss: 0.1089, Avg batch acc: 0.9207
Train, Epoch: 4, Batch: 599, Step num: 5156, Learning rate: 0.00012309, Avg batch loss: 0.0723, Avg batch acc: 0.9359
Train, Epoch: 4, Batch: 600, Step num: 5157, Learning rate: 0.00012308, Avg batch loss: 0.0784, Avg batch acc: 0.9284
Train, Epoch: 4, Batch: 601, Step num: 5158, Learning rate: 0.00012307, Avg batch loss: 0.0783, Avg batch acc: 0.9269
Train, Epoch: 4, Batch: 602, Step num: 5159, Learning rate: 0.00012306, Avg batch loss: 0.0783, Avg batch acc: 0.9260
Train, Epoch: 4, Batch: 603, Step num: 5160, Learning rate: 0.00012305, Avg batch loss: 0.0826, Avg batch acc: 0.9244
Train, Epoch: 4, Batch: 604, Step num: 5161, Learning rate: 0.00012303, Avg batch loss: 0.0719, Avg batch acc: 0.9360
Train, Epoch: 4, Batch: 605, Step num: 5162, Learning rate: 0.00012302, Avg batch loss: 0.0788, Avg batch acc: 0.9340
Train, Epoch: 4, Batch: 606, Step num: 5163, Learning rate: 0.00012301, Avg batch loss: 0.0709, Avg batch acc: 0.9323
Train, Epoch: 4, Batch: 607, Step num: 5164, Learning rate: 0.00012300, Avg batch loss: 0.0639, Avg batch acc: 0.9425
Train, Epoch: 4, Batch: 608, Step num: 5165, Learning rate: 0.00012299, Avg batch loss: 0.0797, Avg batch acc: 0.9287
Train, Epoch: 4, Batch: 609, Step num: 5166, Learning rate: 0.00012298, Avg batch loss: 0.0663, Avg batch acc: 0.9293
Train, Epoch: 4, Batch: 610, Step num: 5167, Learning rate: 0.00012296, Avg batch loss: 0.0834, Avg batch acc: 0.9362
Train, Epoch: 4, Batch: 611, Step num: 5168, Learning rate: 0.00012295, Avg batch loss: 0.0851, Avg batch acc: 0.9240
Train, Epoch: 4, Batch: 612, Step num: 5169, Learning rate: 0.00012294, Avg batch loss: 0.0685, Avg batch acc: 0.9351
Train, Epoch: 4, Batch: 613, Step num: 5170, Learning rate: 0.00012293, Avg batch loss: 0.0900, Avg batch acc: 0.9189
Train, Epoch: 4, Batch: 614, Step num: 5171, Learning rate: 0.00012292, Avg batch loss: 0.0906, Avg batch acc: 0.9232
Train, Epoch: 4, Batch: 615, Step num: 5172, Learning rate: 0.00012290, Avg batch loss: 0.0797, Avg batch acc: 0.9285
Train, Epoch: 4, Batch: 616, Step num: 5173, Learning rate: 0.00012289, Avg batch loss: 0.1000, Avg batch acc: 0.9126
Train, Epoch: 4, Batch: 617, Step num: 5174, Learning rate: 0.00012288, Avg batch loss: 0.0703, Avg batch acc: 0.9326
Train, Epoch: 4, Batch: 618, Step num: 5175, Learning rate: 0.00012287, Avg batch loss: 0.0805, Avg batch acc: 0.9233
Train, Epoch: 4, Batch: 619, Step num: 5176, Learning rate: 0.00012286, Avg batch loss: 0.0847, Avg batch acc: 0.9300
Train, Epoch: 4, Batch: 620, Step num: 5177, Learning rate: 0.00012284, Avg batch loss: 0.0738, Avg batch acc: 0.9328
Train, Epoch: 4, Batch: 621, Step num: 5178, Learning rate: 0.00012283, Avg batch loss: 0.0706, Avg batch acc: 0.9357
Train, Epoch: 4, Batch: 622, Step num: 5179, Learning rate: 0.00012282, Avg batch loss: 0.0819, Avg batch acc: 0.9316
Train, Epoch: 4, Batch: 623, Step num: 5180, Learning rate: 0.00012281, Avg batch loss: 0.0759, Avg batch acc: 0.9327
Train, Epoch: 4, Batch: 624, Step num: 5181, Learning rate: 0.00012280, Avg batch loss: 0.0755, Avg batch acc: 0.9303
Train, Epoch: 4, Batch: 625, Step num: 5182, Learning rate: 0.00012279, Avg batch loss: 0.0703, Avg batch acc: 0.9351
Train, Epoch: 4, Batch: 626, Step num: 5183, Learning rate: 0.00012277, Avg batch loss: 0.0957, Avg batch acc: 0.9226
Train, Epoch: 4, Batch: 627, Step num: 5184, Learning rate: 0.00012276, Avg batch loss: 0.0843, Avg batch acc: 0.9272
Train, Epoch: 4, Batch: 628, Step num: 5185, Learning rate: 0.00012275, Avg batch loss: 0.0672, Avg batch acc: 0.9291
Train, Epoch: 4, Batch: 629, Step num: 5186, Learning rate: 0.00012274, Avg batch loss: 0.0772, Avg batch acc: 0.9343
Train, Epoch: 4, Batch: 630, Step num: 5187, Learning rate: 0.00012273, Avg batch loss: 0.0948, Avg batch acc: 0.9174
Train, Epoch: 4, Batch: 631, Step num: 5188, Learning rate: 0.00012271, Avg batch loss: 0.0935, Avg batch acc: 0.9174
Train, Epoch: 4, Batch: 632, Step num: 5189, Learning rate: 0.00012270, Avg batch loss: 0.0775, Avg batch acc: 0.9229
Train, Epoch: 4, Batch: 633, Step num: 5190, Learning rate: 0.00012269, Avg batch loss: 0.0645, Avg batch acc: 0.9247
Train, Epoch: 4, Batch: 634, Step num: 5191, Learning rate: 0.00012268, Avg batch loss: 0.0855, Avg batch acc: 0.9295
Train, Epoch: 4, Batch: 635, Step num: 5192, Learning rate: 0.00012267, Avg batch loss: 0.0727, Avg batch acc: 0.9387
Train, Epoch: 4, Batch: 636, Step num: 5193, Learning rate: 0.00012266, Avg batch loss: 0.0808, Avg batch acc: 0.9225
Train, Epoch: 4, Batch: 637, Step num: 5194, Learning rate: 0.00012264, Avg batch loss: 0.0691, Avg batch acc: 0.9332
Train, Epoch: 4, Batch: 638, Step num: 5195, Learning rate: 0.00012263, Avg batch loss: 0.0904, Avg batch acc: 0.9234
Train, Epoch: 4, Batch: 639, Step num: 5196, Learning rate: 0.00012262, Avg batch loss: 0.0920, Avg batch acc: 0.9193
Train, Epoch: 4, Batch: 640, Step num: 5197, Learning rate: 0.00012261, Avg batch loss: 0.0671, Avg batch acc: 0.9338
Train, Epoch: 4, Batch: 641, Step num: 5198, Learning rate: 0.00012260, Avg batch loss: 0.0698, Avg batch acc: 0.9384
Train, Epoch: 4, Batch: 642, Step num: 5199, Learning rate: 0.00012258, Avg batch loss: 0.0835, Avg batch acc: 0.9300
Train, Epoch: 4, Batch: 643, Step num: 5200, Learning rate: 0.00012257, Avg batch loss: 0.0759, Avg batch acc: 0.9289
Train, Epoch: 4, Batch: 644, Step num: 5201, Learning rate: 0.00012256, Avg batch loss: 0.0719, Avg batch acc: 0.9295
Train, Epoch: 4, Batch: 645, Step num: 5202, Learning rate: 0.00012255, Avg batch loss: 0.0789, Avg batch acc: 0.9287
Train, Epoch: 4, Batch: 646, Step num: 5203, Learning rate: 0.00012254, Avg batch loss: 0.0910, Avg batch acc: 0.9225
Train, Epoch: 4, Batch: 647, Step num: 5204, Learning rate: 0.00012253, Avg batch loss: 0.0706, Avg batch acc: 0.9371
Train, Epoch: 4, Batch: 648, Step num: 5205, Learning rate: 0.00012251, Avg batch loss: 0.0666, Avg batch acc: 0.9406
Train, Epoch: 4, Batch: 649, Step num: 5206, Learning rate: 0.00012250, Avg batch loss: 0.0759, Avg batch acc: 0.9298
Train, Epoch: 4, Batch: 650, Step num: 5207, Learning rate: 0.00012249, Avg batch loss: 0.0750, Avg batch acc: 0.9363
Train, Epoch: 4, Batch: 651, Step num: 5208, Learning rate: 0.00012248, Avg batch loss: 0.0707, Avg batch acc: 0.9279
Train, Epoch: 4, Batch: 652, Step num: 5209, Learning rate: 0.00012247, Avg batch loss: 0.0631, Avg batch acc: 0.9425
Train, Epoch: 4, Batch: 653, Step num: 5210, Learning rate: 0.00012245, Avg batch loss: 0.0935, Avg batch acc: 0.9134
Train, Epoch: 4, Batch: 654, Step num: 5211, Learning rate: 0.00012244, Avg batch loss: 0.0679, Avg batch acc: 0.9359
Train, Epoch: 4, Batch: 655, Step num: 5212, Learning rate: 0.00012243, Avg batch loss: 0.0666, Avg batch acc: 0.9337
Train, Epoch: 4, Batch: 656, Step num: 5213, Learning rate: 0.00012242, Avg batch loss: 0.0835, Avg batch acc: 0.9268
Train, Epoch: 4, Batch: 657, Step num: 5214, Learning rate: 0.00012241, Avg batch loss: 0.0653, Avg batch acc: 0.9373
Train, Epoch: 4, Batch: 658, Step num: 5215, Learning rate: 0.00012240, Avg batch loss: 0.0782, Avg batch acc: 0.9367
Train, Epoch: 4, Batch: 659, Step num: 5216, Learning rate: 0.00012238, Avg batch loss: 0.0670, Avg batch acc: 0.9349
Train, Epoch: 4, Batch: 660, Step num: 5217, Learning rate: 0.00012237, Avg batch loss: 0.0781, Avg batch acc: 0.9232
Train, Epoch: 4, Batch: 661, Step num: 5218, Learning rate: 0.00012236, Avg batch loss: 0.1102, Avg batch acc: 0.9006
Train, Epoch: 4, Batch: 662, Step num: 5219, Learning rate: 0.00012235, Avg batch loss: 0.0833, Avg batch acc: 0.9325
Train, Epoch: 4, Batch: 663, Step num: 5220, Learning rate: 0.00012234, Avg batch loss: 0.0843, Avg batch acc: 0.9222
Train, Epoch: 4, Batch: 664, Step num: 5221, Learning rate: 0.00012233, Avg batch loss: 0.0694, Avg batch acc: 0.9361
Train, Epoch: 4, Batch: 665, Step num: 5222, Learning rate: 0.00012231, Avg batch loss: 0.0797, Avg batch acc: 0.9270
Train, Epoch: 4, Batch: 666, Step num: 5223, Learning rate: 0.00012230, Avg batch loss: 0.0708, Avg batch acc: 0.9363
Train, Epoch: 4, Batch: 667, Step num: 5224, Learning rate: 0.00012229, Avg batch loss: 0.0610, Avg batch acc: 0.9365
Train, Epoch: 4, Batch: 668, Step num: 5225, Learning rate: 0.00012228, Avg batch loss: 0.0877, Avg batch acc: 0.9312
Train, Epoch: 4, Batch: 669, Step num: 5226, Learning rate: 0.00012227, Avg batch loss: 0.0756, Avg batch acc: 0.9307
Train, Epoch: 4, Batch: 670, Step num: 5227, Learning rate: 0.00012226, Avg batch loss: 0.0779, Avg batch acc: 0.9363
Train, Epoch: 4, Batch: 671, Step num: 5228, Learning rate: 0.00012224, Avg batch loss: 0.0726, Avg batch acc: 0.9281
Train, Epoch: 4, Batch: 672, Step num: 5229, Learning rate: 0.00012223, Avg batch loss: 0.0689, Avg batch acc: 0.9315
Train, Epoch: 4, Batch: 673, Step num: 5230, Learning rate: 0.00012222, Avg batch loss: 0.0693, Avg batch acc: 0.9231
Train, Epoch: 4, Batch: 674, Step num: 5231, Learning rate: 0.00012221, Avg batch loss: 0.0712, Avg batch acc: 0.9303
Train, Epoch: 4, Batch: 675, Step num: 5232, Learning rate: 0.00012220, Avg batch loss: 0.0882, Avg batch acc: 0.9192
Train, Epoch: 4, Batch: 676, Step num: 5233, Learning rate: 0.00012219, Avg batch loss: 0.0713, Avg batch acc: 0.9234
Train, Epoch: 4, Batch: 677, Step num: 5234, Learning rate: 0.00012217, Avg batch loss: 0.0691, Avg batch acc: 0.9319
Train, Epoch: 4, Batch: 678, Step num: 5235, Learning rate: 0.00012216, Avg batch loss: 0.0833, Avg batch acc: 0.9167
Train, Epoch: 4, Batch: 679, Step num: 5236, Learning rate: 0.00012215, Avg batch loss: 0.0668, Avg batch acc: 0.9288
Train, Epoch: 4, Batch: 680, Step num: 5237, Learning rate: 0.00012214, Avg batch loss: 0.0652, Avg batch acc: 0.9385
Train, Epoch: 4, Batch: 681, Step num: 5238, Learning rate: 0.00012213, Avg batch loss: 0.0773, Avg batch acc: 0.9287
Train, Epoch: 4, Batch: 682, Step num: 5239, Learning rate: 0.00012212, Avg batch loss: 0.0779, Avg batch acc: 0.9343
Train, Epoch: 4, Batch: 683, Step num: 5240, Learning rate: 0.00012210, Avg batch loss: 0.0887, Avg batch acc: 0.9349
Train, Epoch: 4, Batch: 684, Step num: 5241, Learning rate: 0.00012209, Avg batch loss: 0.1141, Avg batch acc: 0.9284
Train, Epoch: 4, Batch: 685, Step num: 5242, Learning rate: 0.00012208, Avg batch loss: 0.0964, Avg batch acc: 0.9213
Train, Epoch: 4, Batch: 686, Step num: 5243, Learning rate: 0.00012207, Avg batch loss: 0.0653, Avg batch acc: 0.9351
Train, Epoch: 4, Batch: 687, Step num: 5244, Learning rate: 0.00012206, Avg batch loss: 0.0738, Avg batch acc: 0.9381
Train, Epoch: 4, Batch: 688, Step num: 5245, Learning rate: 0.00012205, Avg batch loss: 0.1041, Avg batch acc: 0.9156
Train, Epoch: 4, Batch: 689, Step num: 5246, Learning rate: 0.00012203, Avg batch loss: 0.0745, Avg batch acc: 0.9288
Train, Epoch: 4, Batch: 690, Step num: 5247, Learning rate: 0.00012202, Avg batch loss: 0.0759, Avg batch acc: 0.9378
Train, Epoch: 4, Batch: 691, Step num: 5248, Learning rate: 0.00012201, Avg batch loss: 0.0780, Avg batch acc: 0.9229
Train, Epoch: 4, Batch: 692, Step num: 5249, Learning rate: 0.00012200, Avg batch loss: 0.0931, Avg batch acc: 0.9214
Train, Epoch: 4, Batch: 693, Step num: 5250, Learning rate: 0.00012199, Avg batch loss: 0.0758, Avg batch acc: 0.9321
Train, Epoch: 4, Batch: 694, Step num: 5251, Learning rate: 0.00012198, Avg batch loss: 0.0755, Avg batch acc: 0.9287
Train, Epoch: 4, Batch: 695, Step num: 5252, Learning rate: 0.00012196, Avg batch loss: 0.0738, Avg batch acc: 0.9252
Train, Epoch: 4, Batch: 696, Step num: 5253, Learning rate: 0.00012195, Avg batch loss: 0.0788, Avg batch acc: 0.9245
Train, Epoch: 4, Batch: 697, Step num: 5254, Learning rate: 0.00012194, Avg batch loss: 0.0783, Avg batch acc: 0.9361
Train, Epoch: 4, Batch: 698, Step num: 5255, Learning rate: 0.00012193, Avg batch loss: 0.0751, Avg batch acc: 0.9262
Train, Epoch: 4, Batch: 699, Step num: 5256, Learning rate: 0.00012192, Avg batch loss: 0.0773, Avg batch acc: 0.9296
Train, Epoch: 4, Batch: 700, Step num: 5257, Learning rate: 0.00012191, Avg batch loss: 0.0803, Avg batch acc: 0.9352
Train, Epoch: 4, Batch: 701, Step num: 5258, Learning rate: 0.00012189, Avg batch loss: 0.0667, Avg batch acc: 0.9402
Train, Epoch: 4, Batch: 702, Step num: 5259, Learning rate: 0.00012188, Avg batch loss: 0.0786, Avg batch acc: 0.9279
Train, Epoch: 4, Batch: 703, Step num: 5260, Learning rate: 0.00012187, Avg batch loss: 0.0777, Avg batch acc: 0.9318
Train, Epoch: 4, Batch: 704, Step num: 5261, Learning rate: 0.00012186, Avg batch loss: 0.0731, Avg batch acc: 0.9309
Train, Epoch: 4, Batch: 705, Step num: 5262, Learning rate: 0.00012185, Avg batch loss: 0.0716, Avg batch acc: 0.9302
Train, Epoch: 4, Batch: 706, Step num: 5263, Learning rate: 0.00012184, Avg batch loss: 0.0784, Avg batch acc: 0.9293
Train, Epoch: 4, Batch: 707, Step num: 5264, Learning rate: 0.00012183, Avg batch loss: 0.0662, Avg batch acc: 0.9306
Train, Epoch: 4, Batch: 708, Step num: 5265, Learning rate: 0.00012181, Avg batch loss: 0.0893, Avg batch acc: 0.9246
Train, Epoch: 4, Batch: 709, Step num: 5266, Learning rate: 0.00012180, Avg batch loss: 0.0865, Avg batch acc: 0.9138
Train, Epoch: 4, Batch: 710, Step num: 5267, Learning rate: 0.00012179, Avg batch loss: 0.0832, Avg batch acc: 0.9282
Train, Epoch: 4, Batch: 711, Step num: 5268, Learning rate: 0.00012178, Avg batch loss: 0.0898, Avg batch acc: 0.9251
Train, Epoch: 4, Batch: 712, Step num: 5269, Learning rate: 0.00012177, Avg batch loss: 0.1136, Avg batch acc: 0.9124
Train, Epoch: 4, Batch: 713, Step num: 5270, Learning rate: 0.00012176, Avg batch loss: 0.0675, Avg batch acc: 0.9376
Train, Epoch: 4, Batch: 714, Step num: 5271, Learning rate: 0.00012174, Avg batch loss: 0.0722, Avg batch acc: 0.9329
Train, Epoch: 4, Batch: 715, Step num: 5272, Learning rate: 0.00012173, Avg batch loss: 0.0734, Avg batch acc: 0.9317
Train, Epoch: 4, Batch: 716, Step num: 5273, Learning rate: 0.00012172, Avg batch loss: 0.0757, Avg batch acc: 0.9326
Train, Epoch: 4, Batch: 717, Step num: 5274, Learning rate: 0.00012171, Avg batch loss: 0.0728, Avg batch acc: 0.9343
Train, Epoch: 4, Batch: 718, Step num: 5275, Learning rate: 0.00012170, Avg batch loss: 0.0602, Avg batch acc: 0.9388
Train, Epoch: 4, Batch: 719, Step num: 5276, Learning rate: 0.00012169, Avg batch loss: 0.0667, Avg batch acc: 0.9375
Train, Epoch: 4, Batch: 720, Step num: 5277, Learning rate: 0.00012168, Avg batch loss: 0.0833, Avg batch acc: 0.9224
Train, Epoch: 4, Batch: 721, Step num: 5278, Learning rate: 0.00012166, Avg batch loss: 0.0700, Avg batch acc: 0.9299
Train, Epoch: 4, Batch: 722, Step num: 5279, Learning rate: 0.00012165, Avg batch loss: 0.0877, Avg batch acc: 0.9262
Train, Epoch: 4, Batch: 723, Step num: 5280, Learning rate: 0.00012164, Avg batch loss: 0.0804, Avg batch acc: 0.9356
Train, Epoch: 4, Batch: 724, Step num: 5281, Learning rate: 0.00012163, Avg batch loss: 0.0681, Avg batch acc: 0.9301
Train, Epoch: 4, Batch: 725, Step num: 5282, Learning rate: 0.00012162, Avg batch loss: 0.1082, Avg batch acc: 0.9132
Train, Epoch: 4, Batch: 726, Step num: 5283, Learning rate: 0.00012161, Avg batch loss: 0.0700, Avg batch acc: 0.9347
Train, Epoch: 4, Batch: 727, Step num: 5284, Learning rate: 0.00012159, Avg batch loss: 0.0613, Avg batch acc: 0.9358
Train, Epoch: 4, Batch: 728, Step num: 5285, Learning rate: 0.00012158, Avg batch loss: 0.0783, Avg batch acc: 0.9274
Train, Epoch: 4, Batch: 729, Step num: 5286, Learning rate: 0.00012157, Avg batch loss: 0.0652, Avg batch acc: 0.9382
Train, Epoch: 4, Batch: 730, Step num: 5287, Learning rate: 0.00012156, Avg batch loss: 0.0791, Avg batch acc: 0.9351
Train, Epoch: 4, Batch: 731, Step num: 5288, Learning rate: 0.00012155, Avg batch loss: 0.0677, Avg batch acc: 0.9292
Train, Epoch: 4, Batch: 732, Step num: 5289, Learning rate: 0.00012154, Avg batch loss: 0.0769, Avg batch acc: 0.9308
Train, Epoch: 4, Batch: 733, Step num: 5290, Learning rate: 0.00012153, Avg batch loss: 0.0771, Avg batch acc: 0.9295
Train, Epoch: 4, Batch: 734, Step num: 5291, Learning rate: 0.00012151, Avg batch loss: 0.0685, Avg batch acc: 0.9339
Train, Epoch: 4, Batch: 735, Step num: 5292, Learning rate: 0.00012150, Avg batch loss: 0.0712, Avg batch acc: 0.9366
Train, Epoch: 4, Batch: 736, Step num: 5293, Learning rate: 0.00012149, Avg batch loss: 0.0742, Avg batch acc: 0.9338
Train, Epoch: 4, Batch: 737, Step num: 5294, Learning rate: 0.00012148, Avg batch loss: 0.0681, Avg batch acc: 0.9274
Train, Epoch: 4, Batch: 738, Step num: 5295, Learning rate: 0.00012147, Avg batch loss: 0.0729, Avg batch acc: 0.9324
Train, Epoch: 4, Batch: 739, Step num: 5296, Learning rate: 0.00012146, Avg batch loss: 0.0680, Avg batch acc: 0.9326
Train, Epoch: 4, Batch: 740, Step num: 5297, Learning rate: 0.00012145, Avg batch loss: 0.0685, Avg batch acc: 0.9255
Train, Epoch: 4, Batch: 741, Step num: 5298, Learning rate: 0.00012143, Avg batch loss: 0.0812, Avg batch acc: 0.9239
Train, Epoch: 4, Batch: 742, Step num: 5299, Learning rate: 0.00012142, Avg batch loss: 0.0672, Avg batch acc: 0.9443
Train, Epoch: 4, Batch: 743, Step num: 5300, Learning rate: 0.00012141, Avg batch loss: 0.0702, Avg batch acc: 0.9394
Train, Epoch: 4, Batch: 744, Step num: 5301, Learning rate: 0.00012140, Avg batch loss: 0.0824, Avg batch acc: 0.9265
Train, Epoch: 4, Batch: 745, Step num: 5302, Learning rate: 0.00012139, Avg batch loss: 0.0704, Avg batch acc: 0.9320
Train, Epoch: 4, Batch: 746, Step num: 5303, Learning rate: 0.00012138, Avg batch loss: 0.0670, Avg batch acc: 0.9358
Train, Epoch: 4, Batch: 747, Step num: 5304, Learning rate: 0.00012136, Avg batch loss: 0.0654, Avg batch acc: 0.9287
Train, Epoch: 4, Batch: 748, Step num: 5305, Learning rate: 0.00012135, Avg batch loss: 0.0804, Avg batch acc: 0.9317
Train, Epoch: 4, Batch: 749, Step num: 5306, Learning rate: 0.00012134, Avg batch loss: 0.0830, Avg batch acc: 0.9224
Train, Epoch: 4, Batch: 750, Step num: 5307, Learning rate: 0.00012133, Avg batch loss: 0.0788, Avg batch acc: 0.9364
Train, Epoch: 4, Batch: 751, Step num: 5308, Learning rate: 0.00012132, Avg batch loss: 0.0603, Avg batch acc: 0.9431
Train, Epoch: 4, Batch: 752, Step num: 5309, Learning rate: 0.00012131, Avg batch loss: 0.0713, Avg batch acc: 0.9308
Train, Epoch: 4, Batch: 753, Step num: 5310, Learning rate: 0.00012130, Avg batch loss: 0.0733, Avg batch acc: 0.9250
Train, Epoch: 4, Batch: 754, Step num: 5311, Learning rate: 0.00012128, Avg batch loss: 0.0608, Avg batch acc: 0.9400
Train, Epoch: 4, Batch: 755, Step num: 5312, Learning rate: 0.00012127, Avg batch loss: 0.0675, Avg batch acc: 0.9407
Train, Epoch: 4, Batch: 756, Step num: 5313, Learning rate: 0.00012126, Avg batch loss: 0.0726, Avg batch acc: 0.9322
Train, Epoch: 4, Batch: 757, Step num: 5314, Learning rate: 0.00012125, Avg batch loss: 0.0567, Avg batch acc: 0.9447
Train, Epoch: 4, Batch: 758, Step num: 5315, Learning rate: 0.00012124, Avg batch loss: 0.0873, Avg batch acc: 0.9237
Train, Epoch: 4, Batch: 759, Step num: 5316, Learning rate: 0.00012123, Avg batch loss: 0.0558, Avg batch acc: 0.9443
Train, Epoch: 4, Batch: 760, Step num: 5317, Learning rate: 0.00012122, Avg batch loss: 0.0910, Avg batch acc: 0.9187
Train, Epoch: 4, Batch: 761, Step num: 5318, Learning rate: 0.00012121, Avg batch loss: 0.0628, Avg batch acc: 0.9396
Train, Epoch: 4, Batch: 762, Step num: 5319, Learning rate: 0.00012119, Avg batch loss: 0.0714, Avg batch acc: 0.9387
Train, Epoch: 4, Batch: 763, Step num: 5320, Learning rate: 0.00012118, Avg batch loss: 0.0681, Avg batch acc: 0.9359
Train, Epoch: 4, Batch: 764, Step num: 5321, Learning rate: 0.00012117, Avg batch loss: 0.0737, Avg batch acc: 0.9302
Train, Epoch: 4, Batch: 765, Step num: 5322, Learning rate: 0.00012116, Avg batch loss: 0.0736, Avg batch acc: 0.9309
Train, Epoch: 4, Batch: 766, Step num: 5323, Learning rate: 0.00012115, Avg batch loss: 0.0675, Avg batch acc: 0.9405
Train, Epoch: 4, Batch: 767, Step num: 5324, Learning rate: 0.00012114, Avg batch loss: 0.0643, Avg batch acc: 0.9426
Train, Epoch: 4, Batch: 768, Step num: 5325, Learning rate: 0.00012113, Avg batch loss: 0.0674, Avg batch acc: 0.9364
Train, Epoch: 4, Batch: 769, Step num: 5326, Learning rate: 0.00012111, Avg batch loss: 0.0599, Avg batch acc: 0.9400
Train, Epoch: 4, Batch: 770, Step num: 5327, Learning rate: 0.00012110, Avg batch loss: 0.0842, Avg batch acc: 0.9285
Train, Epoch: 4, Batch: 771, Step num: 5328, Learning rate: 0.00012109, Avg batch loss: 0.0580, Avg batch acc: 0.9468
Train, Epoch: 4, Batch: 772, Step num: 5329, Learning rate: 0.00012108, Avg batch loss: 0.0600, Avg batch acc: 0.9366
Train, Epoch: 4, Batch: 773, Step num: 5330, Learning rate: 0.00012107, Avg batch loss: 0.0648, Avg batch acc: 0.9347
Train, Epoch: 4, Batch: 774, Step num: 5331, Learning rate: 0.00012106, Avg batch loss: 0.0626, Avg batch acc: 0.9407
Train, Epoch: 4, Batch: 775, Step num: 5332, Learning rate: 0.00012105, Avg batch loss: 0.0497, Avg batch acc: 0.9470
Train, Epoch: 4, Batch: 776, Step num: 5333, Learning rate: 0.00012103, Avg batch loss: 0.0580, Avg batch acc: 0.9412
Train, Epoch: 4, Batch: 777, Step num: 5334, Learning rate: 0.00012102, Avg batch loss: 0.0802, Avg batch acc: 0.9365
Train, Epoch: 4, Batch: 778, Step num: 5335, Learning rate: 0.00012101, Avg batch loss: 0.0689, Avg batch acc: 0.9329
Train, Epoch: 4, Batch: 779, Step num: 5336, Learning rate: 0.00012100, Avg batch loss: 0.0571, Avg batch acc: 0.9419
Train, Epoch: 4, Batch: 780, Step num: 5337, Learning rate: 0.00012099, Avg batch loss: 0.0682, Avg batch acc: 0.9322
Train, Epoch: 4, Batch: 781, Step num: 5338, Learning rate: 0.00012098, Avg batch loss: 0.0699, Avg batch acc: 0.9418
Train, Epoch: 4, Batch: 782, Step num: 5339, Learning rate: 0.00012097, Avg batch loss: 0.0651, Avg batch acc: 0.9365
Train, Epoch: 4, Batch: 783, Step num: 5340, Learning rate: 0.00012096, Avg batch loss: 0.0626, Avg batch acc: 0.9417
Train, Epoch: 4, Batch: 784, Step num: 5341, Learning rate: 0.00012094, Avg batch loss: 0.0637, Avg batch acc: 0.9322
Train, Epoch: 4, Batch: 785, Step num: 5342, Learning rate: 0.00012093, Avg batch loss: 0.0788, Avg batch acc: 0.9319
Train, Epoch: 4, Batch: 786, Step num: 5343, Learning rate: 0.00012092, Avg batch loss: 0.0712, Avg batch acc: 0.9371
Train, Epoch: 4, Batch: 787, Step num: 5344, Learning rate: 0.00012091, Avg batch loss: 0.0812, Avg batch acc: 0.9319
Train, Epoch: 4, Batch: 788, Step num: 5345, Learning rate: 0.00012090, Avg batch loss: 0.0598, Avg batch acc: 0.9450
Train, Epoch: 4, Batch: 789, Step num: 5346, Learning rate: 0.00012089, Avg batch loss: 0.0556, Avg batch acc: 0.9391
Train, Epoch: 4, Batch: 790, Step num: 5347, Learning rate: 0.00012088, Avg batch loss: 0.0617, Avg batch acc: 0.9438
Train, Epoch: 4, Batch: 791, Step num: 5348, Learning rate: 0.00012086, Avg batch loss: 0.0688, Avg batch acc: 0.9371
Train, Epoch: 4, Batch: 792, Step num: 5349, Learning rate: 0.00012085, Avg batch loss: 0.0723, Avg batch acc: 0.9307
Train, Epoch: 4, Batch: 793, Step num: 5350, Learning rate: 0.00012084, Avg batch loss: 0.0783, Avg batch acc: 0.9317
Train, Epoch: 4, Batch: 794, Step num: 5351, Learning rate: 0.00012083, Avg batch loss: 0.0604, Avg batch acc: 0.9404
Train, Epoch: 4, Batch: 795, Step num: 5352, Learning rate: 0.00012082, Avg batch loss: 0.0617, Avg batch acc: 0.9439
Train, Epoch: 4, Batch: 796, Step num: 5353, Learning rate: 0.00012081, Avg batch loss: 0.0648, Avg batch acc: 0.9379
Train, Epoch: 4, Batch: 797, Step num: 5354, Learning rate: 0.00012080, Avg batch loss: 0.0739, Avg batch acc: 0.9286
Train, Epoch: 4, Batch: 798, Step num: 5355, Learning rate: 0.00012079, Avg batch loss: 0.0668, Avg batch acc: 0.9331
Train, Epoch: 4, Batch: 799, Step num: 5356, Learning rate: 0.00012077, Avg batch loss: 0.0686, Avg batch acc: 0.9269
Train, Epoch: 4, Batch: 800, Step num: 5357, Learning rate: 0.00012076, Avg batch loss: 0.0626, Avg batch acc: 0.9382
Train, Epoch: 4, Batch: 801, Step num: 5358, Learning rate: 0.00012075, Avg batch loss: 0.0699, Avg batch acc: 0.9364
Train, Epoch: 4, Batch: 802, Step num: 5359, Learning rate: 0.00012074, Avg batch loss: 0.0578, Avg batch acc: 0.9362
Train, Epoch: 4, Batch: 803, Step num: 5360, Learning rate: 0.00012073, Avg batch loss: 0.0681, Avg batch acc: 0.9322
Train, Epoch: 4, Batch: 804, Step num: 5361, Learning rate: 0.00012072, Avg batch loss: 0.0542, Avg batch acc: 0.9467
Train, Epoch: 4, Batch: 805, Step num: 5362, Learning rate: 0.00012071, Avg batch loss: 0.0603, Avg batch acc: 0.9451
Train, Epoch: 4, Batch: 806, Step num: 5363, Learning rate: 0.00012070, Avg batch loss: 0.0798, Avg batch acc: 0.9287
Train, Epoch: 4, Batch: 807, Step num: 5364, Learning rate: 0.00012068, Avg batch loss: 0.0737, Avg batch acc: 0.9308
Train, Epoch: 4, Batch: 808, Step num: 5365, Learning rate: 0.00012067, Avg batch loss: 0.0749, Avg batch acc: 0.9296
Train, Epoch: 4, Batch: 809, Step num: 5366, Learning rate: 0.00012066, Avg batch loss: 0.0778, Avg batch acc: 0.9301
Train, Epoch: 4, Batch: 810, Step num: 5367, Learning rate: 0.00012065, Avg batch loss: 0.0585, Avg batch acc: 0.9454
Train, Epoch: 4, Batch: 811, Step num: 5368, Learning rate: 0.00012064, Avg batch loss: 0.0621, Avg batch acc: 0.9381
Train, Epoch: 4, Batch: 812, Step num: 5369, Learning rate: 0.00012063, Avg batch loss: 0.0606, Avg batch acc: 0.9496
Train, Epoch: 4, Batch: 813, Step num: 5370, Learning rate: 0.00012062, Avg batch loss: 0.0812, Avg batch acc: 0.9267
Train, Epoch: 4, Batch: 814, Step num: 5371, Learning rate: 0.00012061, Avg batch loss: 0.0693, Avg batch acc: 0.9361
Train, Epoch: 4, Batch: 815, Step num: 5372, Learning rate: 0.00012059, Avg batch loss: 0.0571, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 816, Step num: 5373, Learning rate: 0.00012058, Avg batch loss: 0.0673, Avg batch acc: 0.9442
Train, Epoch: 4, Batch: 817, Step num: 5374, Learning rate: 0.00012057, Avg batch loss: 0.0669, Avg batch acc: 0.9375
Train, Epoch: 4, Batch: 818, Step num: 5375, Learning rate: 0.00012056, Avg batch loss: 0.0665, Avg batch acc: 0.9362
Train, Epoch: 4, Batch: 819, Step num: 5376, Learning rate: 0.00012055, Avg batch loss: 0.0577, Avg batch acc: 0.9423
Train, Epoch: 4, Batch: 820, Step num: 5377, Learning rate: 0.00012054, Avg batch loss: 0.0611, Avg batch acc: 0.9349
Train, Epoch: 4, Batch: 821, Step num: 5378, Learning rate: 0.00012053, Avg batch loss: 0.0679, Avg batch acc: 0.9346
Train, Epoch: 4, Batch: 822, Step num: 5379, Learning rate: 0.00012052, Avg batch loss: 0.0608, Avg batch acc: 0.9412
Train, Epoch: 4, Batch: 823, Step num: 5380, Learning rate: 0.00012050, Avg batch loss: 0.0704, Avg batch acc: 0.9343
Train, Epoch: 4, Batch: 824, Step num: 5381, Learning rate: 0.00012049, Avg batch loss: 0.0591, Avg batch acc: 0.9430
Train, Epoch: 4, Batch: 825, Step num: 5382, Learning rate: 0.00012048, Avg batch loss: 0.0654, Avg batch acc: 0.9386
Train, Epoch: 4, Batch: 826, Step num: 5383, Learning rate: 0.00012047, Avg batch loss: 0.0557, Avg batch acc: 0.9467
Train, Epoch: 4, Batch: 827, Step num: 5384, Learning rate: 0.00012046, Avg batch loss: 0.0649, Avg batch acc: 0.9404
Train, Epoch: 4, Batch: 828, Step num: 5385, Learning rate: 0.00012045, Avg batch loss: 0.0657, Avg batch acc: 0.9343
Train, Epoch: 4, Batch: 829, Step num: 5386, Learning rate: 0.00012044, Avg batch loss: 0.0618, Avg batch acc: 0.9422
Train, Epoch: 4, Batch: 830, Step num: 5387, Learning rate: 0.00012043, Avg batch loss: 0.0680, Avg batch acc: 0.9421
Train, Epoch: 4, Batch: 831, Step num: 5388, Learning rate: 0.00012042, Avg batch loss: 0.0583, Avg batch acc: 0.9439
Train, Epoch: 4, Batch: 832, Step num: 5389, Learning rate: 0.00012040, Avg batch loss: 0.0609, Avg batch acc: 0.9463
Train, Epoch: 4, Batch: 833, Step num: 5390, Learning rate: 0.00012039, Avg batch loss: 0.0677, Avg batch acc: 0.9400
Train, Epoch: 4, Batch: 834, Step num: 5391, Learning rate: 0.00012038, Avg batch loss: 0.0643, Avg batch acc: 0.9404
Train, Epoch: 4, Batch: 835, Step num: 5392, Learning rate: 0.00012037, Avg batch loss: 0.0728, Avg batch acc: 0.9334
Train, Epoch: 4, Batch: 836, Step num: 5393, Learning rate: 0.00012036, Avg batch loss: 0.0731, Avg batch acc: 0.9276
Train, Epoch: 4, Batch: 837, Step num: 5394, Learning rate: 0.00012035, Avg batch loss: 0.0673, Avg batch acc: 0.9352
Train, Epoch: 4, Batch: 838, Step num: 5395, Learning rate: 0.00012034, Avg batch loss: 0.0603, Avg batch acc: 0.9489
Train, Epoch: 4, Batch: 839, Step num: 5396, Learning rate: 0.00012033, Avg batch loss: 0.0891, Avg batch acc: 0.9289
Train, Epoch: 4, Batch: 840, Step num: 5397, Learning rate: 0.00012031, Avg batch loss: 0.0585, Avg batch acc: 0.9465
Train, Epoch: 4, Batch: 841, Step num: 5398, Learning rate: 0.00012030, Avg batch loss: 0.0638, Avg batch acc: 0.9358
Train, Epoch: 4, Batch: 842, Step num: 5399, Learning rate: 0.00012029, Avg batch loss: 0.0822, Avg batch acc: 0.9285
Train, Epoch: 4, Batch: 843, Step num: 5400, Learning rate: 0.00012028, Avg batch loss: 0.0689, Avg batch acc: 0.9372
Train, Epoch: 4, Batch: 844, Step num: 5401, Learning rate: 0.00012027, Avg batch loss: 0.0727, Avg batch acc: 0.9358
Train, Epoch: 4, Batch: 845, Step num: 5402, Learning rate: 0.00012026, Avg batch loss: 0.0701, Avg batch acc: 0.9302
Train, Epoch: 4, Batch: 846, Step num: 5403, Learning rate: 0.00012025, Avg batch loss: 0.0741, Avg batch acc: 0.9431
Train, Epoch: 4, Batch: 847, Step num: 5404, Learning rate: 0.00012024, Avg batch loss: 0.0576, Avg batch acc: 0.9413
Train, Epoch: 4, Batch: 848, Step num: 5405, Learning rate: 0.00012023, Avg batch loss: 0.0655, Avg batch acc: 0.9355
Train, Epoch: 4, Batch: 849, Step num: 5406, Learning rate: 0.00012021, Avg batch loss: 0.0730, Avg batch acc: 0.9349
Train, Epoch: 4, Batch: 850, Step num: 5407, Learning rate: 0.00012020, Avg batch loss: 0.0591, Avg batch acc: 0.9414
Train, Epoch: 4, Batch: 851, Step num: 5408, Learning rate: 0.00012019, Avg batch loss: 0.0694, Avg batch acc: 0.9391
Train, Epoch: 4, Batch: 852, Step num: 5409, Learning rate: 0.00012018, Avg batch loss: 0.0720, Avg batch acc: 0.9286
Train, Epoch: 4, Batch: 853, Step num: 5410, Learning rate: 0.00012017, Avg batch loss: 0.0620, Avg batch acc: 0.9440
Train, Epoch: 4, Batch: 854, Step num: 5411, Learning rate: 0.00012016, Avg batch loss: 0.0882, Avg batch acc: 0.9269
Train, Epoch: 4, Batch: 855, Step num: 5412, Learning rate: 0.00012015, Avg batch loss: 0.0585, Avg batch acc: 0.9356
Train, Epoch: 4, Batch: 856, Step num: 5413, Learning rate: 0.00012014, Avg batch loss: 0.0668, Avg batch acc: 0.9427
Train, Epoch: 4, Batch: 857, Step num: 5414, Learning rate: 0.00012013, Avg batch loss: 0.0821, Avg batch acc: 0.9336
Train, Epoch: 4, Batch: 858, Step num: 5415, Learning rate: 0.00012011, Avg batch loss: 0.0547, Avg batch acc: 0.9424
Train, Epoch: 4, Batch: 859, Step num: 5416, Learning rate: 0.00012010, Avg batch loss: 0.0668, Avg batch acc: 0.9338
Train, Epoch: 4, Batch: 860, Step num: 5417, Learning rate: 0.00012009, Avg batch loss: 0.0735, Avg batch acc: 0.9355
Train, Epoch: 4, Batch: 861, Step num: 5418, Learning rate: 0.00012008, Avg batch loss: 0.0618, Avg batch acc: 0.9424
Train, Epoch: 4, Batch: 862, Step num: 5419, Learning rate: 0.00012007, Avg batch loss: 0.0929, Avg batch acc: 0.9219
Train, Epoch: 4, Batch: 863, Step num: 5420, Learning rate: 0.00012006, Avg batch loss: 0.0655, Avg batch acc: 0.9414
Train, Epoch: 4, Batch: 864, Step num: 5421, Learning rate: 0.00012005, Avg batch loss: 0.0585, Avg batch acc: 0.9446
Train, Epoch: 4, Batch: 865, Step num: 5422, Learning rate: 0.00012004, Avg batch loss: 0.0621, Avg batch acc: 0.9399
Train, Epoch: 4, Batch: 866, Step num: 5423, Learning rate: 0.00012003, Avg batch loss: 0.0638, Avg batch acc: 0.9429
Train, Epoch: 4, Batch: 867, Step num: 5424, Learning rate: 0.00012001, Avg batch loss: 0.0599, Avg batch acc: 0.9433
Train, Epoch: 4, Batch: 868, Step num: 5425, Learning rate: 0.00012000, Avg batch loss: 0.0630, Avg batch acc: 0.9391
Train, Epoch: 4, Batch: 869, Step num: 5426, Learning rate: 0.00011999, Avg batch loss: 0.0678, Avg batch acc: 0.9350
Train, Epoch: 4, Batch: 870, Step num: 5427, Learning rate: 0.00011998, Avg batch loss: 0.0729, Avg batch acc: 0.9378
Train, Epoch: 4, Batch: 871, Step num: 5428, Learning rate: 0.00011997, Avg batch loss: 0.0653, Avg batch acc: 0.9370
Train, Epoch: 4, Batch: 872, Step num: 5429, Learning rate: 0.00011996, Avg batch loss: 0.0520, Avg batch acc: 0.9382
Train, Epoch: 4, Batch: 873, Step num: 5430, Learning rate: 0.00011995, Avg batch loss: 0.0719, Avg batch acc: 0.9420
Train, Epoch: 4, Batch: 874, Step num: 5431, Learning rate: 0.00011994, Avg batch loss: 0.0699, Avg batch acc: 0.9341
Train, Epoch: 4, Batch: 875, Step num: 5432, Learning rate: 0.00011993, Avg batch loss: 0.0540, Avg batch acc: 0.9404
Train, Epoch: 4, Batch: 876, Step num: 5433, Learning rate: 0.00011992, Avg batch loss: 0.0590, Avg batch acc: 0.9419
Train, Epoch: 4, Batch: 877, Step num: 5434, Learning rate: 0.00011990, Avg batch loss: 0.0601, Avg batch acc: 0.9424
Train, Epoch: 4, Batch: 878, Step num: 5435, Learning rate: 0.00011989, Avg batch loss: 0.0639, Avg batch acc: 0.9389
Train, Epoch: 4, Batch: 879, Step num: 5436, Learning rate: 0.00011988, Avg batch loss: 0.0715, Avg batch acc: 0.9382
Train, Epoch: 4, Batch: 880, Step num: 5437, Learning rate: 0.00011987, Avg batch loss: 0.0710, Avg batch acc: 0.9298
Train, Epoch: 4, Batch: 881, Step num: 5438, Learning rate: 0.00011986, Avg batch loss: 0.0881, Avg batch acc: 0.9374
Train, Epoch: 4, Batch: 882, Step num: 5439, Learning rate: 0.00011985, Avg batch loss: 0.0689, Avg batch acc: 0.9389
Train, Epoch: 4, Batch: 883, Step num: 5440, Learning rate: 0.00011984, Avg batch loss: 0.0634, Avg batch acc: 0.9441
Train, Epoch: 4, Batch: 884, Step num: 5441, Learning rate: 0.00011983, Avg batch loss: 0.0665, Avg batch acc: 0.9368
Train, Epoch: 4, Batch: 885, Step num: 5442, Learning rate: 0.00011982, Avg batch loss: 0.0668, Avg batch acc: 0.9400
Train, Epoch: 4, Batch: 886, Step num: 5443, Learning rate: 0.00011981, Avg batch loss: 0.0804, Avg batch acc: 0.9334
Train, Epoch: 4, Batch: 887, Step num: 5444, Learning rate: 0.00011979, Avg batch loss: 0.0633, Avg batch acc: 0.9424
Train, Epoch: 4, Batch: 888, Step num: 5445, Learning rate: 0.00011978, Avg batch loss: 0.0777, Avg batch acc: 0.9367
Train, Epoch: 4, Batch: 889, Step num: 5446, Learning rate: 0.00011977, Avg batch loss: 0.0775, Avg batch acc: 0.9369
Train, Epoch: 4, Batch: 890, Step num: 5447, Learning rate: 0.00011976, Avg batch loss: 0.0595, Avg batch acc: 0.9363
Train, Epoch: 4, Batch: 891, Step num: 5448, Learning rate: 0.00011975, Avg batch loss: 0.0771, Avg batch acc: 0.9302
Train, Epoch: 4, Batch: 892, Step num: 5449, Learning rate: 0.00011974, Avg batch loss: 0.0620, Avg batch acc: 0.9418
Train, Epoch: 4, Batch: 893, Step num: 5450, Learning rate: 0.00011973, Avg batch loss: 0.0646, Avg batch acc: 0.9349
Train, Epoch: 4, Batch: 894, Step num: 5451, Learning rate: 0.00011972, Avg batch loss: 0.0694, Avg batch acc: 0.9376
Train, Epoch: 4, Batch: 895, Step num: 5452, Learning rate: 0.00011971, Avg batch loss: 0.0584, Avg batch acc: 0.9455
Train, Epoch: 4, Batch: 896, Step num: 5453, Learning rate: 0.00011970, Avg batch loss: 0.0649, Avg batch acc: 0.9333
Train, Epoch: 4, Batch: 897, Step num: 5454, Learning rate: 0.00011968, Avg batch loss: 0.0696, Avg batch acc: 0.9309
Train, Epoch: 4, Batch: 898, Step num: 5455, Learning rate: 0.00011967, Avg batch loss: 0.0628, Avg batch acc: 0.9335
Train, Epoch: 4, Batch: 899, Step num: 5456, Learning rate: 0.00011966, Avg batch loss: 0.0691, Avg batch acc: 0.9354
Train, Epoch: 4, Batch: 900, Step num: 5457, Learning rate: 0.00011965, Avg batch loss: 0.0679, Avg batch acc: 0.9290
Train, Epoch: 4, Batch: 901, Step num: 5458, Learning rate: 0.00011964, Avg batch loss: 0.0611, Avg batch acc: 0.9449
Train, Epoch: 4, Batch: 902, Step num: 5459, Learning rate: 0.00011963, Avg batch loss: 0.0577, Avg batch acc: 0.9425
Train, Epoch: 4, Batch: 903, Step num: 5460, Learning rate: 0.00011962, Avg batch loss: 0.0594, Avg batch acc: 0.9423
Train, Epoch: 4, Batch: 904, Step num: 5461, Learning rate: 0.00011961, Avg batch loss: 0.0659, Avg batch acc: 0.9373
Train, Epoch: 4, Batch: 905, Step num: 5462, Learning rate: 0.00011960, Avg batch loss: 0.0674, Avg batch acc: 0.9386
Train, Epoch: 4, Batch: 906, Step num: 5463, Learning rate: 0.00011959, Avg batch loss: 0.0587, Avg batch acc: 0.9433
Train, Epoch: 4, Batch: 907, Step num: 5464, Learning rate: 0.00011957, Avg batch loss: 0.0579, Avg batch acc: 0.9526
Train, Epoch: 4, Batch: 908, Step num: 5465, Learning rate: 0.00011956, Avg batch loss: 0.0780, Avg batch acc: 0.9335
Train, Epoch: 4, Batch: 909, Step num: 5466, Learning rate: 0.00011955, Avg batch loss: 0.0630, Avg batch acc: 0.9448
Train, Epoch: 4, Batch: 910, Step num: 5467, Learning rate: 0.00011954, Avg batch loss: 0.0758, Avg batch acc: 0.9410
Train, Epoch: 4, Batch: 911, Step num: 5468, Learning rate: 0.00011953, Avg batch loss: 0.0625, Avg batch acc: 0.9409
Train, Epoch: 4, Batch: 912, Step num: 5469, Learning rate: 0.00011952, Avg batch loss: 0.0610, Avg batch acc: 0.9369
Train, Epoch: 4, Batch: 913, Step num: 5470, Learning rate: 0.00011951, Avg batch loss: 0.0635, Avg batch acc: 0.9472
Train, Epoch: 4, Batch: 914, Step num: 5471, Learning rate: 0.00011950, Avg batch loss: 0.0618, Avg batch acc: 0.9391
Train, Epoch: 4, Batch: 915, Step num: 5472, Learning rate: 0.00011949, Avg batch loss: 0.0761, Avg batch acc: 0.9327
Train, Epoch: 4, Batch: 916, Step num: 5473, Learning rate: 0.00011948, Avg batch loss: 0.0694, Avg batch acc: 0.9351
Train, Epoch: 4, Batch: 917, Step num: 5474, Learning rate: 0.00011947, Avg batch loss: 0.0634, Avg batch acc: 0.9445
Train, Epoch: 4, Batch: 918, Step num: 5475, Learning rate: 0.00011945, Avg batch loss: 0.0635, Avg batch acc: 0.9417
Train, Epoch: 4, Batch: 919, Step num: 5476, Learning rate: 0.00011944, Avg batch loss: 0.0650, Avg batch acc: 0.9370
Train, Epoch: 4, Batch: 920, Step num: 5477, Learning rate: 0.00011943, Avg batch loss: 0.0766, Avg batch acc: 0.9271
Train, Epoch: 4, Batch: 921, Step num: 5478, Learning rate: 0.00011942, Avg batch loss: 0.0707, Avg batch acc: 0.9367
Train, Epoch: 4, Batch: 922, Step num: 5479, Learning rate: 0.00011941, Avg batch loss: 0.0721, Avg batch acc: 0.9334
Train, Epoch: 4, Batch: 923, Step num: 5480, Learning rate: 0.00011940, Avg batch loss: 0.0659, Avg batch acc: 0.9437
Train, Epoch: 4, Batch: 924, Step num: 5481, Learning rate: 0.00011939, Avg batch loss: 0.0683, Avg batch acc: 0.9377
Train, Epoch: 4, Batch: 925, Step num: 5482, Learning rate: 0.00011938, Avg batch loss: 0.0662, Avg batch acc: 0.9405
Train, Epoch: 4, Batch: 926, Step num: 5483, Learning rate: 0.00011937, Avg batch loss: 0.0779, Avg batch acc: 0.9305
Train, Epoch: 4, Batch: 927, Step num: 5484, Learning rate: 0.00011936, Avg batch loss: 0.0745, Avg batch acc: 0.9293
Train, Epoch: 4, Batch: 928, Step num: 5485, Learning rate: 0.00011935, Avg batch loss: 0.0687, Avg batch acc: 0.9360
Train, Epoch: 4, Batch: 929, Step num: 5486, Learning rate: 0.00011933, Avg batch loss: 0.0580, Avg batch acc: 0.9409
Train, Epoch: 4, Batch: 930, Step num: 5487, Learning rate: 0.00011932, Avg batch loss: 0.0672, Avg batch acc: 0.9388
Train, Epoch: 4, Batch: 931, Step num: 5488, Learning rate: 0.00011931, Avg batch loss: 0.0656, Avg batch acc: 0.9345
Train, Epoch: 4, Batch: 932, Step num: 5489, Learning rate: 0.00011930, Avg batch loss: 0.0566, Avg batch acc: 0.9423
Train, Epoch: 4, Batch: 933, Step num: 5490, Learning rate: 0.00011929, Avg batch loss: 0.0735, Avg batch acc: 0.9316
Train, Epoch: 4, Batch: 934, Step num: 5491, Learning rate: 0.00011928, Avg batch loss: 0.0710, Avg batch acc: 0.9387
Train, Epoch: 4, Batch: 935, Step num: 5492, Learning rate: 0.00011927, Avg batch loss: 0.0657, Avg batch acc: 0.9349
Train, Epoch: 4, Batch: 936, Step num: 5493, Learning rate: 0.00011926, Avg batch loss: 0.0644, Avg batch acc: 0.9320
Train, Epoch: 4, Batch: 937, Step num: 5494, Learning rate: 0.00011925, Avg batch loss: 0.0511, Avg batch acc: 0.9487
Train, Epoch: 4, Batch: 938, Step num: 5495, Learning rate: 0.00011924, Avg batch loss: 0.0645, Avg batch acc: 0.9408
Train, Epoch: 4, Batch: 939, Step num: 5496, Learning rate: 0.00011923, Avg batch loss: 0.0571, Avg batch acc: 0.9365
Train, Epoch: 4, Batch: 940, Step num: 5497, Learning rate: 0.00011922, Avg batch loss: 0.0821, Avg batch acc: 0.9261
Train, Epoch: 4, Batch: 941, Step num: 5498, Learning rate: 0.00011920, Avg batch loss: 0.0716, Avg batch acc: 0.9383
Train, Epoch: 4, Batch: 942, Step num: 5499, Learning rate: 0.00011919, Avg batch loss: 0.0728, Avg batch acc: 0.9295
Train, Epoch: 4, Batch: 943, Step num: 5500, Learning rate: 0.00011918, Avg batch loss: 0.0626, Avg batch acc: 0.9335
Train, Epoch: 4, Batch: 944, Step num: 5501, Learning rate: 0.00011917, Avg batch loss: 0.0682, Avg batch acc: 0.9348
Train, Epoch: 4, Batch: 945, Step num: 5502, Learning rate: 0.00011916, Avg batch loss: 0.0541, Avg batch acc: 0.9473
Train, Epoch: 4, Batch: 946, Step num: 5503, Learning rate: 0.00011915, Avg batch loss: 0.0608, Avg batch acc: 0.9488
Train, Epoch: 4, Batch: 947, Step num: 5504, Learning rate: 0.00011914, Avg batch loss: 0.0600, Avg batch acc: 0.9300
Train, Epoch: 4, Batch: 948, Step num: 5505, Learning rate: 0.00011913, Avg batch loss: 0.0658, Avg batch acc: 0.9388
Train, Epoch: 4, Batch: 949, Step num: 5506, Learning rate: 0.00011912, Avg batch loss: 0.0659, Avg batch acc: 0.9381
Train, Epoch: 4, Batch: 950, Step num: 5507, Learning rate: 0.00011911, Avg batch loss: 0.0632, Avg batch acc: 0.9380
Train, Epoch: 4, Batch: 951, Step num: 5508, Learning rate: 0.00011910, Avg batch loss: 0.0642, Avg batch acc: 0.9374
Train, Epoch: 4, Batch: 952, Step num: 5509, Learning rate: 0.00011909, Avg batch loss: 0.0685, Avg batch acc: 0.9343
Train, Epoch: 4, Batch: 953, Step num: 5510, Learning rate: 0.00011907, Avg batch loss: 0.0641, Avg batch acc: 0.9446
Train, Epoch: 4, Batch: 954, Step num: 5511, Learning rate: 0.00011906, Avg batch loss: 0.0646, Avg batch acc: 0.9421
Train, Epoch: 4, Batch: 955, Step num: 5512, Learning rate: 0.00011905, Avg batch loss: 0.0660, Avg batch acc: 0.9407
Train, Epoch: 4, Batch: 956, Step num: 5513, Learning rate: 0.00011904, Avg batch loss: 0.0610, Avg batch acc: 0.9347
Train, Epoch: 4, Batch: 957, Step num: 5514, Learning rate: 0.00011903, Avg batch loss: 0.0662, Avg batch acc: 0.9409
Train, Epoch: 4, Batch: 958, Step num: 5515, Learning rate: 0.00011902, Avg batch loss: 0.0783, Avg batch acc: 0.9318
Train, Epoch: 4, Batch: 959, Step num: 5516, Learning rate: 0.00011901, Avg batch loss: 0.0725, Avg batch acc: 0.9297
Train, Epoch: 4, Batch: 960, Step num: 5517, Learning rate: 0.00011900, Avg batch loss: 0.0659, Avg batch acc: 0.9421
Train, Epoch: 4, Batch: 961, Step num: 5518, Learning rate: 0.00011899, Avg batch loss: 0.0721, Avg batch acc: 0.9327
Train, Epoch: 4, Batch: 962, Step num: 5519, Learning rate: 0.00011898, Avg batch loss: 0.0653, Avg batch acc: 0.9423
Train, Epoch: 4, Batch: 963, Step num: 5520, Learning rate: 0.00011897, Avg batch loss: 0.0674, Avg batch acc: 0.9354
Train, Epoch: 4, Batch: 964, Step num: 5521, Learning rate: 0.00011896, Avg batch loss: 0.0644, Avg batch acc: 0.9357
Train, Epoch: 4, Batch: 965, Step num: 5522, Learning rate: 0.00011895, Avg batch loss: 0.0657, Avg batch acc: 0.9368
Train, Epoch: 4, Batch: 966, Step num: 5523, Learning rate: 0.00011893, Avg batch loss: 0.0681, Avg batch acc: 0.9308
Train, Epoch: 4, Batch: 967, Step num: 5524, Learning rate: 0.00011892, Avg batch loss: 0.1006, Avg batch acc: 0.9266
Train, Epoch: 4, Batch: 968, Step num: 5525, Learning rate: 0.00011891, Avg batch loss: 0.0637, Avg batch acc: 0.9446
Train, Epoch: 4, Batch: 969, Step num: 5526, Learning rate: 0.00011890, Avg batch loss: 0.0611, Avg batch acc: 0.9451
Train, Epoch: 4, Batch: 970, Step num: 5527, Learning rate: 0.00011889, Avg batch loss: 0.0624, Avg batch acc: 0.9406
Train, Epoch: 4, Batch: 971, Step num: 5528, Learning rate: 0.00011888, Avg batch loss: 0.0589, Avg batch acc: 0.9354
Train, Epoch: 4, Batch: 972, Step num: 5529, Learning rate: 0.00011887, Avg batch loss: 0.0684, Avg batch acc: 0.9331
Train, Epoch: 4, Batch: 973, Step num: 5530, Learning rate: 0.00011886, Avg batch loss: 0.0594, Avg batch acc: 0.9454
Train, Epoch: 4, Batch: 974, Step num: 5531, Learning rate: 0.00011885, Avg batch loss: 0.0756, Avg batch acc: 0.9376
Train, Epoch: 4, Batch: 975, Step num: 5532, Learning rate: 0.00011884, Avg batch loss: 0.0674, Avg batch acc: 0.9489
Train, Epoch: 4, Batch: 976, Step num: 5533, Learning rate: 0.00011883, Avg batch loss: 0.0687, Avg batch acc: 0.9238
Train, Epoch: 4, Batch: 977, Step num: 5534, Learning rate: 0.00011882, Avg batch loss: 0.0708, Avg batch acc: 0.9370
Train, Epoch: 4, Batch: 978, Step num: 5535, Learning rate: 0.00011881, Avg batch loss: 0.0781, Avg batch acc: 0.9281
Train, Epoch: 4, Batch: 979, Step num: 5536, Learning rate: 0.00011879, Avg batch loss: 0.0606, Avg batch acc: 0.9400
Train, Epoch: 4, Batch: 980, Step num: 5537, Learning rate: 0.00011878, Avg batch loss: 0.0609, Avg batch acc: 0.9408
Train, Epoch: 4, Batch: 981, Step num: 5538, Learning rate: 0.00011877, Avg batch loss: 0.0678, Avg batch acc: 0.9399
Train, Epoch: 4, Batch: 982, Step num: 5539, Learning rate: 0.00011876, Avg batch loss: 0.0684, Avg batch acc: 0.9303
Train, Epoch: 4, Batch: 983, Step num: 5540, Learning rate: 0.00011875, Avg batch loss: 0.0558, Avg batch acc: 0.9454
Train, Epoch: 4, Batch: 984, Step num: 5541, Learning rate: 0.00011874, Avg batch loss: 0.0619, Avg batch acc: 0.9363
Train, Epoch: 4, Batch: 985, Step num: 5542, Learning rate: 0.00011873, Avg batch loss: 0.0740, Avg batch acc: 0.9356
Train, Epoch: 4, Batch: 986, Step num: 5543, Learning rate: 0.00011872, Avg batch loss: 0.0649, Avg batch acc: 0.9344
Train, Epoch: 4, Batch: 987, Step num: 5544, Learning rate: 0.00011871, Avg batch loss: 0.0755, Avg batch acc: 0.9337
Train, Epoch: 4, Batch: 988, Step num: 5545, Learning rate: 0.00011870, Avg batch loss: 0.0680, Avg batch acc: 0.9387
Train, Epoch: 4, Batch: 989, Step num: 5546, Learning rate: 0.00011869, Avg batch loss: 0.0767, Avg batch acc: 0.9412
Train, Epoch: 4, Batch: 990, Step num: 5547, Learning rate: 0.00011868, Avg batch loss: 0.0618, Avg batch acc: 0.9414
Train, Epoch: 4, Batch: 991, Step num: 5548, Learning rate: 0.00011867, Avg batch loss: 0.0676, Avg batch acc: 0.9398
Train, Epoch: 4, Batch: 992, Step num: 5549, Learning rate: 0.00011866, Avg batch loss: 0.0553, Avg batch acc: 0.9344
Train, Epoch: 4, Batch: 993, Step num: 5550, Learning rate: 0.00011864, Avg batch loss: 0.0881, Avg batch acc: 0.9237
Train, Epoch: 4, Batch: 994, Step num: 5551, Learning rate: 0.00011863, Avg batch loss: 0.0723, Avg batch acc: 0.9385
Train, Epoch: 4, Batch: 995, Step num: 5552, Learning rate: 0.00011862, Avg batch loss: 0.0556, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 996, Step num: 5553, Learning rate: 0.00011861, Avg batch loss: 0.0614, Avg batch acc: 0.9423
Train, Epoch: 4, Batch: 997, Step num: 5554, Learning rate: 0.00011860, Avg batch loss: 0.0693, Avg batch acc: 0.9348
Train, Epoch: 4, Batch: 998, Step num: 5555, Learning rate: 0.00011859, Avg batch loss: 0.0710, Avg batch acc: 0.9355
Train, Epoch: 4, Batch: 999, Step num: 5556, Learning rate: 0.00011858, Avg batch loss: 0.0709, Avg batch acc: 0.9262
Train, Epoch: 4, Batch: 1000, Step num: 5557, Learning rate: 0.00011857, Avg batch loss: 0.0794, Avg batch acc: 0.9289
Train, Epoch: 4, Batch: 1001, Step num: 5558, Learning rate: 0.00011856, Avg batch loss: 0.0732, Avg batch acc: 0.9310
Train, Epoch: 4, Batch: 1002, Step num: 5559, Learning rate: 0.00011855, Avg batch loss: 0.0756, Avg batch acc: 0.9371
Train, Epoch: 4, Batch: 1003, Step num: 5560, Learning rate: 0.00011854, Avg batch loss: 0.0667, Avg batch acc: 0.9450
Train, Epoch: 4, Batch: 1004, Step num: 5561, Learning rate: 0.00011853, Avg batch loss: 0.0604, Avg batch acc: 0.9465
Train, Epoch: 4, Batch: 1005, Step num: 5562, Learning rate: 0.00011852, Avg batch loss: 0.0632, Avg batch acc: 0.9394
Train, Epoch: 4, Batch: 1006, Step num: 5563, Learning rate: 0.00011851, Avg batch loss: 0.0707, Avg batch acc: 0.9295
Train, Epoch: 4, Batch: 1007, Step num: 5564, Learning rate: 0.00011850, Avg batch loss: 0.0609, Avg batch acc: 0.9383
Train, Epoch: 4, Batch: 1008, Step num: 5565, Learning rate: 0.00011848, Avg batch loss: 0.0545, Avg batch acc: 0.9475
Train, Epoch: 4, Batch: 1009, Step num: 5566, Learning rate: 0.00011847, Avg batch loss: 0.0708, Avg batch acc: 0.9337
Train, Epoch: 4, Batch: 1010, Step num: 5567, Learning rate: 0.00011846, Avg batch loss: 0.0860, Avg batch acc: 0.9351
Train, Epoch: 4, Batch: 1011, Step num: 5568, Learning rate: 0.00011845, Avg batch loss: 0.0693, Avg batch acc: 0.9379
Train, Epoch: 4, Batch: 1012, Step num: 5569, Learning rate: 0.00011844, Avg batch loss: 0.0565, Avg batch acc: 0.9438
Train, Epoch: 4, Batch: 1013, Step num: 5570, Learning rate: 0.00011843, Avg batch loss: 0.0688, Avg batch acc: 0.9403
Train, Epoch: 4, Batch: 1014, Step num: 5571, Learning rate: 0.00011842, Avg batch loss: 0.0608, Avg batch acc: 0.9415
Train, Epoch: 4, Batch: 1015, Step num: 5572, Learning rate: 0.00011841, Avg batch loss: 0.0546, Avg batch acc: 0.9490
Train, Epoch: 4, Batch: 1016, Step num: 5573, Learning rate: 0.00011840, Avg batch loss: 0.0528, Avg batch acc: 0.9454
Train, Epoch: 4, Batch: 1017, Step num: 5574, Learning rate: 0.00011839, Avg batch loss: 0.0631, Avg batch acc: 0.9442
Train, Epoch: 4, Batch: 1018, Step num: 5575, Learning rate: 0.00011838, Avg batch loss: 0.0775, Avg batch acc: 0.9336
Train, Epoch: 4, Batch: 1019, Step num: 5576, Learning rate: 0.00011837, Avg batch loss: 0.0832, Avg batch acc: 0.9395
Train, Epoch: 4, Batch: 1020, Step num: 5577, Learning rate: 0.00011836, Avg batch loss: 0.0637, Avg batch acc: 0.9365
Train, Epoch: 4, Batch: 1021, Step num: 5578, Learning rate: 0.00011835, Avg batch loss: 0.0692, Avg batch acc: 0.9266
Train, Epoch: 4, Batch: 1022, Step num: 5579, Learning rate: 0.00011834, Avg batch loss: 0.0872, Avg batch acc: 0.9320
Train, Epoch: 4, Batch: 1023, Step num: 5580, Learning rate: 0.00011833, Avg batch loss: 0.0776, Avg batch acc: 0.9297
Train, Epoch: 4, Batch: 1024, Step num: 5581, Learning rate: 0.00011831, Avg batch loss: 0.0587, Avg batch acc: 0.9450
Train, Epoch: 4, Batch: 1025, Step num: 5582, Learning rate: 0.00011830, Avg batch loss: 0.0510, Avg batch acc: 0.9452
Train, Epoch: 4, Batch: 1026, Step num: 5583, Learning rate: 0.00011829, Avg batch loss: 0.0697, Avg batch acc: 0.9405
Train, Epoch: 4, Batch: 1027, Step num: 5584, Learning rate: 0.00011828, Avg batch loss: 0.0636, Avg batch acc: 0.9409
Train, Epoch: 4, Batch: 1028, Step num: 5585, Learning rate: 0.00011827, Avg batch loss: 0.0427, Avg batch acc: 0.9552
Train, Epoch: 4, Batch: 1029, Step num: 5586, Learning rate: 0.00011826, Avg batch loss: 0.0573, Avg batch acc: 0.9388
Train, Epoch: 4, Batch: 1030, Step num: 5587, Learning rate: 0.00011825, Avg batch loss: 0.0600, Avg batch acc: 0.9458
Train, Epoch: 4, Batch: 1031, Step num: 5588, Learning rate: 0.00011824, Avg batch loss: 0.0751, Avg batch acc: 0.9336
Train, Epoch: 4, Batch: 1032, Step num: 5589, Learning rate: 0.00011823, Avg batch loss: 0.0593, Avg batch acc: 0.9470
Train, Epoch: 4, Batch: 1033, Step num: 5590, Learning rate: 0.00011822, Avg batch loss: 0.0679, Avg batch acc: 0.9377
Train, Epoch: 4, Batch: 1034, Step num: 5591, Learning rate: 0.00011821, Avg batch loss: 0.0659, Avg batch acc: 0.9430
Train, Epoch: 4, Batch: 1035, Step num: 5592, Learning rate: 0.00011820, Avg batch loss: 0.0675, Avg batch acc: 0.9429
Train, Epoch: 4, Batch: 1036, Step num: 5593, Learning rate: 0.00011819, Avg batch loss: 0.0630, Avg batch acc: 0.9422
Train, Epoch: 4, Batch: 1037, Step num: 5594, Learning rate: 0.00011818, Avg batch loss: 0.0755, Avg batch acc: 0.9475
Train, Epoch: 4, Batch: 1038, Step num: 5595, Learning rate: 0.00011817, Avg batch loss: 0.0682, Avg batch acc: 0.9387
Train, Epoch: 4, Batch: 1039, Step num: 5596, Learning rate: 0.00011816, Avg batch loss: 0.0499, Avg batch acc: 0.9545
Train, Epoch: 4, Batch: 1040, Step num: 5597, Learning rate: 0.00011815, Avg batch loss: 0.0627, Avg batch acc: 0.9403
Train, Epoch: 4, Batch: 1041, Step num: 5598, Learning rate: 0.00011813, Avg batch loss: 0.0630, Avg batch acc: 0.9436
Train, Epoch: 4, Batch: 1042, Step num: 5599, Learning rate: 0.00011812, Avg batch loss: 0.0638, Avg batch acc: 0.9362
Train, Epoch: 4, Batch: 1043, Step num: 5600, Learning rate: 0.00011811, Avg batch loss: 0.0691, Avg batch acc: 0.9428
Train, Epoch: 4, Batch: 1044, Step num: 5601, Learning rate: 0.00011810, Avg batch loss: 0.0567, Avg batch acc: 0.9462
Train, Epoch: 4, Batch: 1045, Step num: 5602, Learning rate: 0.00011809, Avg batch loss: 0.0541, Avg batch acc: 0.9457
Train, Epoch: 4, Batch: 1046, Step num: 5603, Learning rate: 0.00011808, Avg batch loss: 0.0515, Avg batch acc: 0.9445
Train, Epoch: 4, Batch: 1047, Step num: 5604, Learning rate: 0.00011807, Avg batch loss: 0.0701, Avg batch acc: 0.9345
Train, Epoch: 4, Batch: 1048, Step num: 5605, Learning rate: 0.00011806, Avg batch loss: 0.0635, Avg batch acc: 0.9412
Train, Epoch: 4, Batch: 1049, Step num: 5606, Learning rate: 0.00011805, Avg batch loss: 0.0637, Avg batch acc: 0.9384
Train, Epoch: 4, Batch: 1050, Step num: 5607, Learning rate: 0.00011804, Avg batch loss: 0.0610, Avg batch acc: 0.9449
Train, Epoch: 4, Batch: 1051, Step num: 5608, Learning rate: 0.00011803, Avg batch loss: 0.0625, Avg batch acc: 0.9449
Train, Epoch: 4, Batch: 1052, Step num: 5609, Learning rate: 0.00011802, Avg batch loss: 0.0679, Avg batch acc: 0.9447
Train, Epoch: 4, Batch: 1053, Step num: 5610, Learning rate: 0.00011801, Avg batch loss: 0.0621, Avg batch acc: 0.9449
Train, Epoch: 4, Batch: 1054, Step num: 5611, Learning rate: 0.00011800, Avg batch loss: 0.0632, Avg batch acc: 0.9428
Train, Epoch: 4, Batch: 1055, Step num: 5612, Learning rate: 0.00011799, Avg batch loss: 0.0505, Avg batch acc: 0.9504
Train, Epoch: 4, Batch: 1056, Step num: 5613, Learning rate: 0.00011798, Avg batch loss: 0.0564, Avg batch acc: 0.9454
Train, Epoch: 4, Batch: 1057, Step num: 5614, Learning rate: 0.00011797, Avg batch loss: 0.0531, Avg batch acc: 0.9436
Train, Epoch: 4, Batch: 1058, Step num: 5615, Learning rate: 0.00011796, Avg batch loss: 0.0604, Avg batch acc: 0.9303
Train, Epoch: 4, Batch: 1059, Step num: 5616, Learning rate: 0.00011795, Avg batch loss: 0.0595, Avg batch acc: 0.9471
Train, Epoch: 4, Batch: 1060, Step num: 5617, Learning rate: 0.00011794, Avg batch loss: 0.0579, Avg batch acc: 0.9384
Train, Epoch: 4, Batch: 1061, Step num: 5618, Learning rate: 0.00011792, Avg batch loss: 0.0621, Avg batch acc: 0.9376
Train, Epoch: 4, Batch: 1062, Step num: 5619, Learning rate: 0.00011791, Avg batch loss: 0.0674, Avg batch acc: 0.9482
Train, Epoch: 4, Batch: 1063, Step num: 5620, Learning rate: 0.00011790, Avg batch loss: 0.0601, Avg batch acc: 0.9427
Train, Epoch: 4, Batch: 1064, Step num: 5621, Learning rate: 0.00011789, Avg batch loss: 0.0560, Avg batch acc: 0.9457
Train, Epoch: 4, Batch: 1065, Step num: 5622, Learning rate: 0.00011788, Avg batch loss: 0.0564, Avg batch acc: 0.9417
Train, Epoch: 4, Batch: 1066, Step num: 5623, Learning rate: 0.00011787, Avg batch loss: 0.0533, Avg batch acc: 0.9522
Train, Epoch: 4, Batch: 1067, Step num: 5624, Learning rate: 0.00011786, Avg batch loss: 0.0477, Avg batch acc: 0.9458
Train, Epoch: 4, Batch: 1068, Step num: 5625, Learning rate: 0.00011785, Avg batch loss: 0.0609, Avg batch acc: 0.9446
Train, Epoch: 4, Batch: 1069, Step num: 5626, Learning rate: 0.00011784, Avg batch loss: 0.0582, Avg batch acc: 0.9456
Train, Epoch: 4, Batch: 1070, Step num: 5627, Learning rate: 0.00011783, Avg batch loss: 0.0787, Avg batch acc: 0.9351
Train, Epoch: 4, Batch: 1071, Step num: 5628, Learning rate: 0.00011782, Avg batch loss: 0.0559, Avg batch acc: 0.9464
Train, Epoch: 4, Batch: 1072, Step num: 5629, Learning rate: 0.00011781, Avg batch loss: 0.0668, Avg batch acc: 0.9355
Train, Epoch: 4, Batch: 1073, Step num: 5630, Learning rate: 0.00011780, Avg batch loss: 0.0661, Avg batch acc: 0.9382
Train, Epoch: 4, Batch: 1074, Step num: 5631, Learning rate: 0.00011779, Avg batch loss: 0.0589, Avg batch acc: 0.9468
Train, Epoch: 4, Batch: 1075, Step num: 5632, Learning rate: 0.00011778, Avg batch loss: 0.0613, Avg batch acc: 0.9409
Train, Epoch: 4, Batch: 1076, Step num: 5633, Learning rate: 0.00011777, Avg batch loss: 0.0612, Avg batch acc: 0.9406
Train, Epoch: 4, Batch: 1077, Step num: 5634, Learning rate: 0.00011776, Avg batch loss: 0.0670, Avg batch acc: 0.9356
Train, Epoch: 4, Batch: 1078, Step num: 5635, Learning rate: 0.00011775, Avg batch loss: 0.0628, Avg batch acc: 0.9384
Train, Epoch: 4, Batch: 1079, Step num: 5636, Learning rate: 0.00011774, Avg batch loss: 0.0526, Avg batch acc: 0.9400
Train, Epoch: 4, Batch: 1080, Step num: 5637, Learning rate: 0.00011773, Avg batch loss: 0.0736, Avg batch acc: 0.9348
Train, Epoch: 4, Batch: 1081, Step num: 5638, Learning rate: 0.00011772, Avg batch loss: 0.0544, Avg batch acc: 0.9506
Train, Epoch: 4, Batch: 1082, Step num: 5639, Learning rate: 0.00011770, Avg batch loss: 0.0645, Avg batch acc: 0.9351
Train, Epoch: 4, Batch: 1083, Step num: 5640, Learning rate: 0.00011769, Avg batch loss: 0.0686, Avg batch acc: 0.9457
Train, Epoch: 4, Batch: 1084, Step num: 5641, Learning rate: 0.00011768, Avg batch loss: 0.0650, Avg batch acc: 0.9376
Train, Epoch: 4, Batch: 1085, Step num: 5642, Learning rate: 0.00011767, Avg batch loss: 0.0595, Avg batch acc: 0.9431
Train, Epoch: 4, Batch: 1086, Step num: 5643, Learning rate: 0.00011766, Avg batch loss: 0.0696, Avg batch acc: 0.9345
Train, Epoch: 4, Batch: 1087, Step num: 5644, Learning rate: 0.00011765, Avg batch loss: 0.0624, Avg batch acc: 0.9394
Train, Epoch: 4, Batch: 1088, Step num: 5645, Learning rate: 0.00011764, Avg batch loss: 0.0681, Avg batch acc: 0.9377
Train, Epoch: 4, Batch: 1089, Step num: 5646, Learning rate: 0.00011763, Avg batch loss: 0.0591, Avg batch acc: 0.9401
Train, Epoch: 4, Batch: 1090, Step num: 5647, Learning rate: 0.00011762, Avg batch loss: 0.0799, Avg batch acc: 0.9343
Train, Epoch: 4, Batch: 1091, Step num: 5648, Learning rate: 0.00011761, Avg batch loss: 0.0608, Avg batch acc: 0.9386
Train, Epoch: 4, Batch: 1092, Step num: 5649, Learning rate: 0.00011760, Avg batch loss: 0.0689, Avg batch acc: 0.9381
Train, Epoch: 4, Batch: 1093, Step num: 5650, Learning rate: 0.00011759, Avg batch loss: 0.0510, Avg batch acc: 0.9482
Train, Epoch: 4, Batch: 1094, Step num: 5651, Learning rate: 0.00011758, Avg batch loss: 0.0610, Avg batch acc: 0.9391
Train, Epoch: 4, Batch: 1095, Step num: 5652, Learning rate: 0.00011757, Avg batch loss: 0.0508, Avg batch acc: 0.9483
Train, Epoch: 4, Batch: 1096, Step num: 5653, Learning rate: 0.00011756, Avg batch loss: 0.0459, Avg batch acc: 0.9509
Train, Epoch: 4, Batch: 1097, Step num: 5654, Learning rate: 0.00011755, Avg batch loss: 0.0731, Avg batch acc: 0.9373
Train, Epoch: 4, Batch: 1098, Step num: 5655, Learning rate: 0.00011754, Avg batch loss: 0.0537, Avg batch acc: 0.9522
Train, Epoch: 4, Batch: 1099, Step num: 5656, Learning rate: 0.00011753, Avg batch loss: 0.0891, Avg batch acc: 0.9292
Train, Epoch: 4, Batch: 1100, Step num: 5657, Learning rate: 0.00011752, Avg batch loss: 0.0618, Avg batch acc: 0.9321
Train, Epoch: 4, Batch: 1101, Step num: 5658, Learning rate: 0.00011751, Avg batch loss: 0.0653, Avg batch acc: 0.9407
Train, Epoch: 4, Batch: 1102, Step num: 5659, Learning rate: 0.00011750, Avg batch loss: 0.0810, Avg batch acc: 0.9324
Train, Epoch: 4, Batch: 1103, Step num: 5660, Learning rate: 0.00011749, Avg batch loss: 0.0715, Avg batch acc: 0.9421
Train, Epoch: 4, Batch: 1104, Step num: 5661, Learning rate: 0.00011748, Avg batch loss: 0.0751, Avg batch acc: 0.9392
Train, Epoch: 4, Batch: 1105, Step num: 5662, Learning rate: 0.00011747, Avg batch loss: 0.0654, Avg batch acc: 0.9420
Train, Epoch: 4, Batch: 1106, Step num: 5663, Learning rate: 0.00011746, Avg batch loss: 0.0520, Avg batch acc: 0.9487
Train, Epoch: 4, Batch: 1107, Step num: 5664, Learning rate: 0.00011744, Avg batch loss: 0.0640, Avg batch acc: 0.9445
Train, Epoch: 4, Batch: 1108, Step num: 5665, Learning rate: 0.00011743, Avg batch loss: 0.0670, Avg batch acc: 0.9369
Train, Epoch: 4, Batch: 1109, Step num: 5666, Learning rate: 0.00011742, Avg batch loss: 0.0581, Avg batch acc: 0.9348
Train, Epoch: 4, Batch: 1110, Step num: 5667, Learning rate: 0.00011741, Avg batch loss: 0.0690, Avg batch acc: 0.9416
Train, Epoch: 4, Batch: 1111, Step num: 5668, Learning rate: 0.00011740, Avg batch loss: 0.0706, Avg batch acc: 0.9336
Train, Epoch: 4, Batch: 1112, Step num: 5669, Learning rate: 0.00011739, Avg batch loss: 0.0597, Avg batch acc: 0.9418
Train, Epoch: 4, Batch: 1113, Step num: 5670, Learning rate: 0.00011738, Avg batch loss: 0.0751, Avg batch acc: 0.9376
Train, Epoch: 4, Batch: 1114, Step num: 5671, Learning rate: 0.00011737, Avg batch loss: 0.0626, Avg batch acc: 0.9405
Train, Epoch: 4, Batch: 1115, Step num: 5672, Learning rate: 0.00011736, Avg batch loss: 0.0609, Avg batch acc: 0.9462
Train, Epoch: 4, Batch: 1116, Step num: 5673, Learning rate: 0.00011735, Avg batch loss: 0.0642, Avg batch acc: 0.9384
Train, Epoch: 4, Batch: 1117, Step num: 5674, Learning rate: 0.00011734, Avg batch loss: 0.0747, Avg batch acc: 0.9340
Train, Epoch: 4, Batch: 1118, Step num: 5675, Learning rate: 0.00011733, Avg batch loss: 0.0630, Avg batch acc: 0.9352
Train, Epoch: 4, Batch: 1119, Step num: 5676, Learning rate: 0.00011732, Avg batch loss: 0.0735, Avg batch acc: 0.9470
Train, Epoch: 4, Batch: 1120, Step num: 5677, Learning rate: 0.00011731, Avg batch loss: 0.0631, Avg batch acc: 0.9373
Train, Epoch: 4, Batch: 1121, Step num: 5678, Learning rate: 0.00011730, Avg batch loss: 0.0442, Avg batch acc: 0.9631
Train, Epoch: 4, Batch: 1122, Step num: 5679, Learning rate: 0.00011729, Avg batch loss: 0.0544, Avg batch acc: 0.9423
Train, Epoch: 4, Batch: 1123, Step num: 5680, Learning rate: 0.00011728, Avg batch loss: 0.0535, Avg batch acc: 0.9394
Train, Epoch: 4, Batch: 1124, Step num: 5681, Learning rate: 0.00011727, Avg batch loss: 0.0633, Avg batch acc: 0.9406
Train, Epoch: 4, Batch: 1125, Step num: 5682, Learning rate: 0.00011726, Avg batch loss: 0.0685, Avg batch acc: 0.9393
Train, Epoch: 4, Batch: 1126, Step num: 5683, Learning rate: 0.00011725, Avg batch loss: 0.0550, Avg batch acc: 0.9456
Train, Epoch: 4, Batch: 1127, Step num: 5684, Learning rate: 0.00011724, Avg batch loss: 0.0596, Avg batch acc: 0.9367
Train, Epoch: 4, Batch: 1128, Step num: 5685, Learning rate: 0.00011723, Avg batch loss: 0.0646, Avg batch acc: 0.9434
Train, Epoch: 4, Batch: 1129, Step num: 5686, Learning rate: 0.00011722, Avg batch loss: 0.0584, Avg batch acc: 0.9462
Train, Epoch: 4, Batch: 1130, Step num: 5687, Learning rate: 0.00011721, Avg batch loss: 0.0599, Avg batch acc: 0.9393
Train, Epoch: 4, Batch: 1131, Step num: 5688, Learning rate: 0.00011720, Avg batch loss: 0.0616, Avg batch acc: 0.9409
Train, Epoch: 4, Batch: 1132, Step num: 5689, Learning rate: 0.00011719, Avg batch loss: 0.1008, Avg batch acc: 0.9295
Train, Epoch: 4, Batch: 1133, Step num: 5690, Learning rate: 0.00011718, Avg batch loss: 0.0538, Avg batch acc: 0.9459
Train, Epoch: 4, Batch: 1134, Step num: 5691, Learning rate: 0.00011717, Avg batch loss: 0.0473, Avg batch acc: 0.9530
Train, Epoch: 4, Batch: 1135, Step num: 5692, Learning rate: 0.00011716, Avg batch loss: 0.0511, Avg batch acc: 0.9478
Train, Epoch: 4, Batch: 1136, Step num: 5693, Learning rate: 0.00011715, Avg batch loss: 0.0505, Avg batch acc: 0.9499
Train, Epoch: 4, Batch: 1137, Step num: 5694, Learning rate: 0.00011713, Avg batch loss: 0.0540, Avg batch acc: 0.9461
Train, Epoch: 4, Batch: 1138, Step num: 5695, Learning rate: 0.00011712, Avg batch loss: 0.0744, Avg batch acc: 0.9381
Train, Epoch: 4, Batch: 1139, Step num: 5696, Learning rate: 0.00011711, Avg batch loss: 0.0575, Avg batch acc: 0.9380
Train, Epoch: 4, Batch: 1140, Step num: 5697, Learning rate: 0.00011710, Avg batch loss: 0.0606, Avg batch acc: 0.9337
Train, Epoch: 4, Batch: 1141, Step num: 5698, Learning rate: 0.00011709, Avg batch loss: 0.0637, Avg batch acc: 0.9415
Train, Epoch: 4, Batch: 1142, Step num: 5699, Learning rate: 0.00011708, Avg batch loss: 0.0580, Avg batch acc: 0.9456
Train, Epoch: 4, Batch: 1143, Step num: 5700, Learning rate: 0.00011707, Avg batch loss: 0.0600, Avg batch acc: 0.9470
Train, Epoch: 4, Batch: 1144, Step num: 5701, Learning rate: 0.00011706, Avg batch loss: 0.0743, Avg batch acc: 0.9359
Train, Epoch: 4, Batch: 1145, Step num: 5702, Learning rate: 0.00011705, Avg batch loss: 0.0725, Avg batch acc: 0.9388
Train, Epoch: 4, Batch: 1146, Step num: 5703, Learning rate: 0.00011704, Avg batch loss: 0.0633, Avg batch acc: 0.9379
Train, Epoch: 4, Batch: 1147, Step num: 5704, Learning rate: 0.00011703, Avg batch loss: 0.0531, Avg batch acc: 0.9400
Train, Epoch: 4, Batch: 1148, Step num: 5705, Learning rate: 0.00011702, Avg batch loss: 0.0535, Avg batch acc: 0.9448
Train, Epoch: 4, Batch: 1149, Step num: 5706, Learning rate: 0.00011701, Avg batch loss: 0.0695, Avg batch acc: 0.9406
Train, Epoch: 4, Batch: 1150, Step num: 5707, Learning rate: 0.00011700, Avg batch loss: 0.0512, Avg batch acc: 0.9527
Train, Epoch: 4, Batch: 1151, Step num: 5708, Learning rate: 0.00011699, Avg batch loss: 0.0769, Avg batch acc: 0.9332
Train, Epoch: 4, Batch: 1152, Step num: 5709, Learning rate: 0.00011698, Avg batch loss: 0.0513, Avg batch acc: 0.9464
Train, Epoch: 4, Batch: 1153, Step num: 5710, Learning rate: 0.00011697, Avg batch loss: 0.0767, Avg batch acc: 0.9319
Train, Epoch: 4, Batch: 1154, Step num: 5711, Learning rate: 0.00011696, Avg batch loss: 0.0592, Avg batch acc: 0.9461
Train, Epoch: 4, Batch: 1155, Step num: 5712, Learning rate: 0.00011695, Avg batch loss: 0.0527, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 1156, Step num: 5713, Learning rate: 0.00011694, Avg batch loss: 0.0440, Avg batch acc: 0.9507
Train, Epoch: 4, Batch: 1157, Step num: 5714, Learning rate: 0.00011693, Avg batch loss: 0.0579, Avg batch acc: 0.9457
Train, Epoch: 4, Batch: 1158, Step num: 5715, Learning rate: 0.00011692, Avg batch loss: 0.0568, Avg batch acc: 0.9430
Train, Epoch: 4, Batch: 1159, Step num: 5716, Learning rate: 0.00011691, Avg batch loss: 0.0559, Avg batch acc: 0.9483
Train, Epoch: 4, Batch: 1160, Step num: 5717, Learning rate: 0.00011690, Avg batch loss: 0.0551, Avg batch acc: 0.9425
Train, Epoch: 4, Batch: 1161, Step num: 5718, Learning rate: 0.00011689, Avg batch loss: 0.0526, Avg batch acc: 0.9488
Train, Epoch: 4, Batch: 1162, Step num: 5719, Learning rate: 0.00011688, Avg batch loss: 0.0552, Avg batch acc: 0.9468
Train, Epoch: 4, Batch: 1163, Step num: 5720, Learning rate: 0.00011687, Avg batch loss: 0.0642, Avg batch acc: 0.9344
Train, Epoch: 4, Batch: 1164, Step num: 5721, Learning rate: 0.00011686, Avg batch loss: 0.0606, Avg batch acc: 0.9405
Train, Epoch: 4, Batch: 1165, Step num: 5722, Learning rate: 0.00011685, Avg batch loss: 0.0658, Avg batch acc: 0.9315
Train, Epoch: 4, Batch: 1166, Step num: 5723, Learning rate: 0.00011684, Avg batch loss: 0.0491, Avg batch acc: 0.9510
Train, Epoch: 4, Batch: 1167, Step num: 5724, Learning rate: 0.00011683, Avg batch loss: 0.0582, Avg batch acc: 0.9459
Train, Epoch: 4, Batch: 1168, Step num: 5725, Learning rate: 0.00011682, Avg batch loss: 0.0570, Avg batch acc: 0.9483
Train, Epoch: 4, Batch: 1169, Step num: 5726, Learning rate: 0.00011681, Avg batch loss: 0.0457, Avg batch acc: 0.9599
Train, Epoch: 4, Batch: 1170, Step num: 5727, Learning rate: 0.00011680, Avg batch loss: 0.0654, Avg batch acc: 0.9374
Train, Epoch: 4, Batch: 1171, Step num: 5728, Learning rate: 0.00011679, Avg batch loss: 0.0629, Avg batch acc: 0.9452
Train, Epoch: 4, Batch: 1172, Step num: 5729, Learning rate: 0.00011678, Avg batch loss: 0.0585, Avg batch acc: 0.9432
Train, Epoch: 4, Batch: 1173, Step num: 5730, Learning rate: 0.00011677, Avg batch loss: 0.0560, Avg batch acc: 0.9445
Train, Epoch: 4, Batch: 1174, Step num: 5731, Learning rate: 0.00011676, Avg batch loss: 0.0710, Avg batch acc: 0.9380
Train, Epoch: 4, Batch: 1175, Step num: 5732, Learning rate: 0.00011675, Avg batch loss: 0.0490, Avg batch acc: 0.9507
Train, Epoch: 4, Batch: 1176, Step num: 5733, Learning rate: 0.00011674, Avg batch loss: 0.0483, Avg batch acc: 0.9511
Train, Epoch: 4, Batch: 1177, Step num: 5734, Learning rate: 0.00011673, Avg batch loss: 0.0667, Avg batch acc: 0.9421
Train, Epoch: 4, Batch: 1178, Step num: 5735, Learning rate: 0.00011672, Avg batch loss: 0.0579, Avg batch acc: 0.9490
Train, Epoch: 4, Batch: 1179, Step num: 5736, Learning rate: 0.00011671, Avg batch loss: 0.0515, Avg batch acc: 0.9480
Train, Epoch: 4, Batch: 1180, Step num: 5737, Learning rate: 0.00011670, Avg batch loss: 0.0676, Avg batch acc: 0.9404
Train, Epoch: 4, Batch: 1181, Step num: 5738, Learning rate: 0.00011668, Avg batch loss: 0.0517, Avg batch acc: 0.9485
Train, Epoch: 4, Batch: 1182, Step num: 5739, Learning rate: 0.00011667, Avg batch loss: 0.0653, Avg batch acc: 0.9348
Train, Epoch: 4, Batch: 1183, Step num: 5740, Learning rate: 0.00011666, Avg batch loss: 0.0582, Avg batch acc: 0.9389
Train, Epoch: 4, Batch: 1184, Step num: 5741, Learning rate: 0.00011665, Avg batch loss: 0.0518, Avg batch acc: 0.9511
Train, Epoch: 4, Batch: 1185, Step num: 5742, Learning rate: 0.00011664, Avg batch loss: 0.0610, Avg batch acc: 0.9420
Train, Epoch: 4, Batch: 1186, Step num: 5743, Learning rate: 0.00011663, Avg batch loss: 0.0801, Avg batch acc: 0.9326
Train, Epoch: 4, Batch: 1187, Step num: 5744, Learning rate: 0.00011662, Avg batch loss: 0.0690, Avg batch acc: 0.9354
Train, Epoch: 4, Batch: 1188, Step num: 5745, Learning rate: 0.00011661, Avg batch loss: 0.0618, Avg batch acc: 0.9423
Train, Epoch: 4, Batch: 1189, Step num: 5746, Learning rate: 0.00011660, Avg batch loss: 0.0755, Avg batch acc: 0.9402
Train, Epoch: 4, Batch: 1190, Step num: 5747, Learning rate: 0.00011659, Avg batch loss: 0.0581, Avg batch acc: 0.9396
Train, Epoch: 4, Batch: 1191, Step num: 5748, Learning rate: 0.00011658, Avg batch loss: 0.0488, Avg batch acc: 0.9488
Train, Epoch: 4, Batch: 1192, Step num: 5749, Learning rate: 0.00011657, Avg batch loss: 0.0888, Avg batch acc: 0.9393
Train, Epoch: 4, Batch: 1193, Step num: 5750, Learning rate: 0.00011656, Avg batch loss: 0.0505, Avg batch acc: 0.9534
Train, Epoch: 4, Batch: 1194, Step num: 5751, Learning rate: 0.00011655, Avg batch loss: 0.0532, Avg batch acc: 0.9425
Train, Epoch: 4, Batch: 1195, Step num: 5752, Learning rate: 0.00011654, Avg batch loss: 0.0691, Avg batch acc: 0.9309
Train, Epoch: 4, Batch: 1196, Step num: 5753, Learning rate: 0.00011653, Avg batch loss: 0.0728, Avg batch acc: 0.9395
Train, Epoch: 4, Batch: 1197, Step num: 5754, Learning rate: 0.00011652, Avg batch loss: 0.0720, Avg batch acc: 0.9394
Train, Epoch: 4, Batch: 1198, Step num: 5755, Learning rate: 0.00011651, Avg batch loss: 0.0582, Avg batch acc: 0.9468
Train, Epoch: 4, Batch: 1199, Step num: 5756, Learning rate: 0.00011650, Avg batch loss: 0.0516, Avg batch acc: 0.9442
Train, Epoch: 4, Batch: 1200, Step num: 5757, Learning rate: 0.00011649, Avg batch loss: 0.0632, Avg batch acc: 0.9431
Train, Epoch: 4, Batch: 1201, Step num: 5758, Learning rate: 0.00011648, Avg batch loss: 0.0536, Avg batch acc: 0.9494
Train, Epoch: 4, Batch: 1202, Step num: 5759, Learning rate: 0.00011647, Avg batch loss: 0.0618, Avg batch acc: 0.9421
Train, Epoch: 4, Batch: 1203, Step num: 5760, Learning rate: 0.00011646, Avg batch loss: 0.0561, Avg batch acc: 0.9430
Train, Epoch: 4, Batch: 1204, Step num: 5761, Learning rate: 0.00011645, Avg batch loss: 0.0534, Avg batch acc: 0.9438
Train, Epoch: 4, Batch: 1205, Step num: 5762, Learning rate: 0.00011644, Avg batch loss: 0.0540, Avg batch acc: 0.9460
Train, Epoch: 4, Batch: 1206, Step num: 5763, Learning rate: 0.00011643, Avg batch loss: 0.0493, Avg batch acc: 0.9477
Train, Epoch: 4, Batch: 1207, Step num: 5764, Learning rate: 0.00011642, Avg batch loss: 0.0717, Avg batch acc: 0.9363
Train, Epoch: 4, Batch: 1208, Step num: 5765, Learning rate: 0.00011641, Avg batch loss: 0.0658, Avg batch acc: 0.9399
Train, Epoch: 4, Batch: 1209, Step num: 5766, Learning rate: 0.00011640, Avg batch loss: 0.0670, Avg batch acc: 0.9350
Train, Epoch: 4, Batch: 1210, Step num: 5767, Learning rate: 0.00011639, Avg batch loss: 0.0968, Avg batch acc: 0.9290
Train, Epoch: 4, Batch: 1211, Step num: 5768, Learning rate: 0.00011638, Avg batch loss: 0.0622, Avg batch acc: 0.9411
Train, Epoch: 4, Batch: 1212, Step num: 5769, Learning rate: 0.00011637, Avg batch loss: 0.0551, Avg batch acc: 0.9443
Train, Epoch: 4, Batch: 1213, Step num: 5770, Learning rate: 0.00011636, Avg batch loss: 0.0610, Avg batch acc: 0.9459
Train, Epoch: 4, Batch: 1214, Step num: 5771, Learning rate: 0.00011635, Avg batch loss: 0.0611, Avg batch acc: 0.9384
Train, Epoch: 4, Batch: 1215, Step num: 5772, Learning rate: 0.00011634, Avg batch loss: 0.0654, Avg batch acc: 0.9480
Train, Epoch: 4, Batch: 1216, Step num: 5773, Learning rate: 0.00011633, Avg batch loss: 0.0651, Avg batch acc: 0.9407
Train, Epoch: 4, Batch: 1217, Step num: 5774, Learning rate: 0.00011632, Avg batch loss: 0.0557, Avg batch acc: 0.9492
Train, Epoch: 4, Batch: 1218, Step num: 5775, Learning rate: 0.00011631, Avg batch loss: 0.0706, Avg batch acc: 0.9479
Train, Epoch: 4, Batch: 1219, Step num: 5776, Learning rate: 0.00011630, Avg batch loss: 0.0538, Avg batch acc: 0.9470
Train, Epoch: 4, Batch: 1220, Step num: 5777, Learning rate: 0.00011629, Avg batch loss: 0.0610, Avg batch acc: 0.9418
Train, Epoch: 4, Batch: 1221, Step num: 5778, Learning rate: 0.00011628, Avg batch loss: 0.0601, Avg batch acc: 0.9464
Train, Epoch: 4, Batch: 1222, Step num: 5779, Learning rate: 0.00011627, Avg batch loss: 0.0546, Avg batch acc: 0.9477
Train, Epoch: 4, Batch: 1223, Step num: 5780, Learning rate: 0.00011626, Avg batch loss: 0.0555, Avg batch acc: 0.9441
Train, Epoch: 4, Batch: 1224, Step num: 5781, Learning rate: 0.00011625, Avg batch loss: 0.0603, Avg batch acc: 0.9476
Train, Epoch: 4, Batch: 1225, Step num: 5782, Learning rate: 0.00011624, Avg batch loss: 0.0666, Avg batch acc: 0.9452
Train, Epoch: 4, Batch: 1226, Step num: 5783, Learning rate: 0.00011623, Avg batch loss: 0.0520, Avg batch acc: 0.9407
Train, Epoch: 4, Batch: 1227, Step num: 5784, Learning rate: 0.00011622, Avg batch loss: 0.0611, Avg batch acc: 0.9285
Train, Epoch: 4, Batch: 1228, Step num: 5785, Learning rate: 0.00011621, Avg batch loss: 0.0865, Avg batch acc: 0.9394
Train, Epoch: 4, Batch: 1229, Step num: 5786, Learning rate: 0.00011620, Avg batch loss: 0.0501, Avg batch acc: 0.9476
Train, Epoch: 4, Batch: 1230, Step num: 5787, Learning rate: 0.00011619, Avg batch loss: 0.0576, Avg batch acc: 0.9409
Train, Epoch: 4, Batch: 1231, Step num: 5788, Learning rate: 0.00011618, Avg batch loss: 0.0530, Avg batch acc: 0.9438
Train, Epoch: 4, Batch: 1232, Step num: 5789, Learning rate: 0.00011617, Avg batch loss: 0.0655, Avg batch acc: 0.9456
Train, Epoch: 4, Batch: 1233, Step num: 5790, Learning rate: 0.00011616, Avg batch loss: 0.0587, Avg batch acc: 0.9425
Train, Epoch: 4, Batch: 1234, Step num: 5791, Learning rate: 0.00011615, Avg batch loss: 0.0517, Avg batch acc: 0.9444
Train, Epoch: 4, Batch: 1235, Step num: 5792, Learning rate: 0.00011614, Avg batch loss: 0.0548, Avg batch acc: 0.9467
Train, Epoch: 4, Batch: 1236, Step num: 5793, Learning rate: 0.00011613, Avg batch loss: 0.0685, Avg batch acc: 0.9440
Train, Epoch: 4, Batch: 1237, Step num: 5794, Learning rate: 0.00011612, Avg batch loss: 0.0590, Avg batch acc: 0.9466
Train, Epoch: 4, Batch: 1238, Step num: 5795, Learning rate: 0.00011611, Avg batch loss: 0.0531, Avg batch acc: 0.9456
Train, Epoch: 4, Batch: 1239, Step num: 5796, Learning rate: 0.00011610, Avg batch loss: 0.0516, Avg batch acc: 0.9463
Train, Epoch: 4, Batch: 1240, Step num: 5797, Learning rate: 0.00011609, Avg batch loss: 0.0524, Avg batch acc: 0.9504
Train, Epoch: 4, Batch: 1241, Step num: 5798, Learning rate: 0.00011608, Avg batch loss: 0.0533, Avg batch acc: 0.9454
Train, Epoch: 4, Batch: 1242, Step num: 5799, Learning rate: 0.00011607, Avg batch loss: 0.0512, Avg batch acc: 0.9523
Train, Epoch: 4, Batch: 1243, Step num: 5800, Learning rate: 0.00011606, Avg batch loss: 0.0619, Avg batch acc: 0.9433
Train, Epoch: 4, Batch: 1244, Step num: 5801, Learning rate: 0.00011605, Avg batch loss: 0.0652, Avg batch acc: 0.9364
Train, Epoch: 4, Batch: 1245, Step num: 5802, Learning rate: 0.00011604, Avg batch loss: 0.0567, Avg batch acc: 0.9439
Train, Epoch: 4, Batch: 1246, Step num: 5803, Learning rate: 0.00011603, Avg batch loss: 0.0482, Avg batch acc: 0.9536
Train, Epoch: 4, Batch: 1247, Step num: 5804, Learning rate: 0.00011602, Avg batch loss: 0.0685, Avg batch acc: 0.9379
Train, Epoch: 4, Batch: 1248, Step num: 5805, Learning rate: 0.00011601, Avg batch loss: 0.0599, Avg batch acc: 0.9390
Train, Epoch: 4, Batch: 1249, Step num: 5806, Learning rate: 0.00011600, Avg batch loss: 0.0563, Avg batch acc: 0.9492
Train, Epoch: 4, Batch: 1250, Step num: 5807, Learning rate: 0.00011599, Avg batch loss: 0.0877, Avg batch acc: 0.9287
Train, Epoch: 4, Batch: 1251, Step num: 5808, Learning rate: 0.00011598, Avg batch loss: 0.0623, Avg batch acc: 0.9484
Train, Epoch: 4, Batch: 1252, Step num: 5809, Learning rate: 0.00011597, Avg batch loss: 0.0620, Avg batch acc: 0.9442
Train, Epoch: 4, Batch: 1253, Step num: 5810, Learning rate: 0.00011596, Avg batch loss: 0.0629, Avg batch acc: 0.9421
Train, Epoch: 4, Batch: 1254, Step num: 5811, Learning rate: 0.00011595, Avg batch loss: 0.0503, Avg batch acc: 0.9544
Train, Epoch: 4, Batch: 1255, Step num: 5812, Learning rate: 0.00011594, Avg batch loss: 0.0530, Avg batch acc: 0.9518
Train, Epoch: 4, Batch: 1256, Step num: 5813, Learning rate: 0.00011593, Avg batch loss: 0.0663, Avg batch acc: 0.9444
Train, Epoch: 4, Batch: 1257, Step num: 5814, Learning rate: 0.00011592, Avg batch loss: 0.0522, Avg batch acc: 0.9522
Train, Epoch: 4, Batch: 1258, Step num: 5815, Learning rate: 0.00011591, Avg batch loss: 0.0598, Avg batch acc: 0.9443
Train, Epoch: 4, Batch: 1259, Step num: 5816, Learning rate: 0.00011590, Avg batch loss: 0.0603, Avg batch acc: 0.9503
Train, Epoch: 4, Batch: 1260, Step num: 5817, Learning rate: 0.00011589, Avg batch loss: 0.0855, Avg batch acc: 0.9335
Train, Epoch: 4, Batch: 1261, Step num: 5818, Learning rate: 0.00011588, Avg batch loss: 0.0628, Avg batch acc: 0.9484
Train, Epoch: 4, Batch: 1262, Step num: 5819, Learning rate: 0.00011587, Avg batch loss: 0.0611, Avg batch acc: 0.9500
Train, Epoch: 4, Batch: 1263, Step num: 5820, Learning rate: 0.00011586, Avg batch loss: 0.0517, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 1264, Step num: 5821, Learning rate: 0.00011585, Avg batch loss: 0.0588, Avg batch acc: 0.9378
Train, Epoch: 4, Batch: 1265, Step num: 5822, Learning rate: 0.00011584, Avg batch loss: 0.0523, Avg batch acc: 0.9492
Train, Epoch: 4, Batch: 1266, Step num: 5823, Learning rate: 0.00011583, Avg batch loss: 0.0564, Avg batch acc: 0.9454
Train, Epoch: 4, Batch: 1267, Step num: 5824, Learning rate: 0.00011582, Avg batch loss: 0.0712, Avg batch acc: 0.9417
Train, Epoch: 4, Batch: 1268, Step num: 5825, Learning rate: 0.00011581, Avg batch loss: 0.0552, Avg batch acc: 0.9343
Train, Epoch: 4, Batch: 1269, Step num: 5826, Learning rate: 0.00011580, Avg batch loss: 0.0579, Avg batch acc: 0.9345
Train, Epoch: 4, Batch: 1270, Step num: 5827, Learning rate: 0.00011579, Avg batch loss: 0.0561, Avg batch acc: 0.9447
Train, Epoch: 4, Batch: 1271, Step num: 5828, Learning rate: 0.00011578, Avg batch loss: 0.0587, Avg batch acc: 0.9427
Train, Epoch: 4, Batch: 1272, Step num: 5829, Learning rate: 0.00011577, Avg batch loss: 0.0585, Avg batch acc: 0.9451
Train, Epoch: 4, Batch: 1273, Step num: 5830, Learning rate: 0.00011576, Avg batch loss: 0.0657, Avg batch acc: 0.9377
Train, Epoch: 4, Batch: 1274, Step num: 5831, Learning rate: 0.00011575, Avg batch loss: 0.0528, Avg batch acc: 0.9505
Train, Epoch: 4, Batch: 1275, Step num: 5832, Learning rate: 0.00011574, Avg batch loss: 0.0665, Avg batch acc: 0.9490
Train, Epoch: 4, Batch: 1276, Step num: 5833, Learning rate: 0.00011573, Avg batch loss: 0.0504, Avg batch acc: 0.9471
Train, Epoch: 4, Batch: 1277, Step num: 5834, Learning rate: 0.00011572, Avg batch loss: 0.0531, Avg batch acc: 0.9434
Train, Epoch: 4, Batch: 1278, Step num: 5835, Learning rate: 0.00011571, Avg batch loss: 0.0477, Avg batch acc: 0.9544
Train, Epoch: 4, Batch: 1279, Step num: 5836, Learning rate: 0.00011570, Avg batch loss: 0.0446, Avg batch acc: 0.9515
Train, Epoch: 4, Batch: 1280, Step num: 5837, Learning rate: 0.00011569, Avg batch loss: 0.0557, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 1281, Step num: 5838, Learning rate: 0.00011568, Avg batch loss: 0.0449, Avg batch acc: 0.9553
Train, Epoch: 4, Batch: 1282, Step num: 5839, Learning rate: 0.00011567, Avg batch loss: 0.0547, Avg batch acc: 0.9521
Train, Epoch: 4, Batch: 1283, Step num: 5840, Learning rate: 0.00011566, Avg batch loss: 0.0509, Avg batch acc: 0.9497
Train, Epoch: 4, Batch: 1284, Step num: 5841, Learning rate: 0.00011565, Avg batch loss: 0.0527, Avg batch acc: 0.9527
Train, Epoch: 4, Batch: 1285, Step num: 5842, Learning rate: 0.00011564, Avg batch loss: 0.0523, Avg batch acc: 0.9493
Train, Epoch: 4, Batch: 1286, Step num: 5843, Learning rate: 0.00011563, Avg batch loss: 0.0560, Avg batch acc: 0.9486
Train, Epoch: 4, Batch: 1287, Step num: 5844, Learning rate: 0.00011562, Avg batch loss: 0.0534, Avg batch acc: 0.9490
Train, Epoch: 4, Batch: 1288, Step num: 5845, Learning rate: 0.00011561, Avg batch loss: 0.0679, Avg batch acc: 0.9386
Train, Epoch: 4, Batch: 1289, Step num: 5846, Learning rate: 0.00011560, Avg batch loss: 0.0562, Avg batch acc: 0.9458
Train, Epoch: 4, Batch: 1290, Step num: 5847, Learning rate: 0.00011559, Avg batch loss: 0.0611, Avg batch acc: 0.9479
Train, Epoch: 4, Batch: 1291, Step num: 5848, Learning rate: 0.00011558, Avg batch loss: 0.0459, Avg batch acc: 0.9531
Train, Epoch: 4, Batch: 1292, Step num: 5849, Learning rate: 0.00011557, Avg batch loss: 0.0547, Avg batch acc: 0.9428
Train, Epoch: 4, Batch: 1293, Step num: 5850, Learning rate: 0.00011556, Avg batch loss: 0.0523, Avg batch acc: 0.9536
Train, Epoch: 4, Batch: 1294, Step num: 5851, Learning rate: 0.00011555, Avg batch loss: 0.0469, Avg batch acc: 0.9523
Train, Epoch: 4, Batch: 1295, Step num: 5852, Learning rate: 0.00011554, Avg batch loss: 0.0572, Avg batch acc: 0.9483
Train, Epoch: 4, Batch: 1296, Step num: 5853, Learning rate: 0.00011553, Avg batch loss: 0.0497, Avg batch acc: 0.9508
Train, Epoch: 4, Batch: 1297, Step num: 5854, Learning rate: 0.00011552, Avg batch loss: 0.0648, Avg batch acc: 0.9511
Train, Epoch: 4, Batch: 1298, Step num: 5855, Learning rate: 0.00011551, Avg batch loss: 0.0639, Avg batch acc: 0.9414
Train, Epoch: 4, Batch: 1299, Step num: 5856, Learning rate: 0.00011550, Avg batch loss: 0.0512, Avg batch acc: 0.9494
Train, Epoch: 4, Batch: 1300, Step num: 5857, Learning rate: 0.00011549, Avg batch loss: 0.0615, Avg batch acc: 0.9372
Train, Epoch: 4, Batch: 1301, Step num: 5858, Learning rate: 0.00011548, Avg batch loss: 0.0491, Avg batch acc: 0.9578
Train, Epoch: 4, Batch: 1302, Step num: 5859, Learning rate: 0.00011547, Avg batch loss: 0.0746, Avg batch acc: 0.9344
Train, Epoch: 4, Batch: 1303, Step num: 5860, Learning rate: 0.00011546, Avg batch loss: 0.0562, Avg batch acc: 0.9444
Train, Epoch: 4, Batch: 1304, Step num: 5861, Learning rate: 0.00011545, Avg batch loss: 0.0579, Avg batch acc: 0.9518
Train, Epoch: 4, Batch: 1305, Step num: 5862, Learning rate: 0.00011544, Avg batch loss: 0.0505, Avg batch acc: 0.9474
Train, Epoch: 4, Batch: 1306, Step num: 5863, Learning rate: 0.00011543, Avg batch loss: 0.0420, Avg batch acc: 0.9608
Train, Epoch: 4, Batch: 1307, Step num: 5864, Learning rate: 0.00011542, Avg batch loss: 0.0613, Avg batch acc: 0.9430
Train, Epoch: 4, Batch: 1308, Step num: 5865, Learning rate: 0.00011541, Avg batch loss: 0.0551, Avg batch acc: 0.9496
Train, Epoch: 4, Batch: 1309, Step num: 5866, Learning rate: 0.00011540, Avg batch loss: 0.0596, Avg batch acc: 0.9387
Train, Epoch: 4, Batch: 1310, Step num: 5867, Learning rate: 0.00011539, Avg batch loss: 0.0536, Avg batch acc: 0.9484
Train, Epoch: 4, Batch: 1311, Step num: 5868, Learning rate: 0.00011539, Avg batch loss: 0.0662, Avg batch acc: 0.9376
Train, Epoch: 4, Batch: 1312, Step num: 5869, Learning rate: 0.00011538, Avg batch loss: 0.0524, Avg batch acc: 0.9475
Train, Epoch: 4, Batch: 1313, Step num: 5870, Learning rate: 0.00011537, Avg batch loss: 0.0561, Avg batch acc: 0.9452
Train, Epoch: 4, Batch: 1314, Step num: 5871, Learning rate: 0.00011536, Avg batch loss: 0.0776, Avg batch acc: 0.9397
Train, Epoch: 4, Batch: 1315, Step num: 5872, Learning rate: 0.00011535, Avg batch loss: 0.0586, Avg batch acc: 0.9413
Train, Epoch: 4, Batch: 1316, Step num: 5873, Learning rate: 0.00011534, Avg batch loss: 0.0621, Avg batch acc: 0.9476
Train, Epoch: 4, Batch: 1317, Step num: 5874, Learning rate: 0.00011533, Avg batch loss: 0.0553, Avg batch acc: 0.9519
Train, Epoch: 4, Batch: 1318, Step num: 5875, Learning rate: 0.00011532, Avg batch loss: 0.0449, Avg batch acc: 0.9541
Train, Epoch: 4, Batch: 1319, Step num: 5876, Learning rate: 0.00011531, Avg batch loss: 0.0462, Avg batch acc: 0.9507
Train, Epoch: 4, Batch: 1320, Step num: 5877, Learning rate: 0.00011530, Avg batch loss: 0.0535, Avg batch acc: 0.9496
Train, Epoch: 4, Batch: 1321, Step num: 5878, Learning rate: 0.00011529, Avg batch loss: 0.0555, Avg batch acc: 0.9465
Train, Epoch: 4, Batch: 1322, Step num: 5879, Learning rate: 0.00011528, Avg batch loss: 0.0680, Avg batch acc: 0.9327
Train, Epoch: 4, Batch: 1323, Step num: 5880, Learning rate: 0.00011527, Avg batch loss: 0.0509, Avg batch acc: 0.9507
Train, Epoch: 4, Batch: 1324, Step num: 5881, Learning rate: 0.00011526, Avg batch loss: 0.0512, Avg batch acc: 0.9532
Train, Epoch: 4, Batch: 1325, Step num: 5882, Learning rate: 0.00011525, Avg batch loss: 0.0562, Avg batch acc: 0.9508
Train, Epoch: 4, Batch: 1326, Step num: 5883, Learning rate: 0.00011524, Avg batch loss: 0.0547, Avg batch acc: 0.9487
Train, Epoch: 4, Batch: 1327, Step num: 5884, Learning rate: 0.00011523, Avg batch loss: 0.0599, Avg batch acc: 0.9422
Train, Epoch: 4, Batch: 1328, Step num: 5885, Learning rate: 0.00011522, Avg batch loss: 0.0575, Avg batch acc: 0.9460
Train, Epoch: 4, Batch: 1329, Step num: 5886, Learning rate: 0.00011521, Avg batch loss: 0.0569, Avg batch acc: 0.9446
Train, Epoch: 4, Batch: 1330, Step num: 5887, Learning rate: 0.00011520, Avg batch loss: 0.0523, Avg batch acc: 0.9592
Train, Epoch: 4, Batch: 1331, Step num: 5888, Learning rate: 0.00011519, Avg batch loss: 0.0701, Avg batch acc: 0.9357
Train, Epoch: 4, Batch: 1332, Step num: 5889, Learning rate: 0.00011518, Avg batch loss: 0.0655, Avg batch acc: 0.9452
Train, Epoch: 4, Batch: 1333, Step num: 5890, Learning rate: 0.00011517, Avg batch loss: 0.0490, Avg batch acc: 0.9481
Train, Epoch: 4, Batch: 1334, Step num: 5891, Learning rate: 0.00011516, Avg batch loss: 0.0532, Avg batch acc: 0.9471
Train, Epoch: 4, Batch: 1335, Step num: 5892, Learning rate: 0.00011515, Avg batch loss: 0.0493, Avg batch acc: 0.9505
Train, Epoch: 4, Batch: 1336, Step num: 5893, Learning rate: 0.00011514, Avg batch loss: 0.0459, Avg batch acc: 0.9504
Train, Epoch: 4, Batch: 1337, Step num: 5894, Learning rate: 0.00011513, Avg batch loss: 0.0571, Avg batch acc: 0.9421
Train, Epoch: 4, Batch: 1338, Step num: 5895, Learning rate: 0.00011512, Avg batch loss: 0.0559, Avg batch acc: 0.9459
Train, Epoch: 4, Batch: 1339, Step num: 5896, Learning rate: 0.00011511, Avg batch loss: 0.0502, Avg batch acc: 0.9523
Train, Epoch: 4, Batch: 1340, Step num: 5897, Learning rate: 0.00011510, Avg batch loss: 0.0583, Avg batch acc: 0.9454
Train, Epoch: 4, Batch: 1341, Step num: 5898, Learning rate: 0.00011509, Avg batch loss: 0.0474, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 1342, Step num: 5899, Learning rate: 0.00011508, Avg batch loss: 0.0568, Avg batch acc: 0.9475
Train, Epoch: 4, Batch: 1343, Step num: 5900, Learning rate: 0.00011507, Avg batch loss: 0.0543, Avg batch acc: 0.9445
Train, Epoch: 4, Batch: 1344, Step num: 5901, Learning rate: 0.00011506, Avg batch loss: 0.0618, Avg batch acc: 0.9342
Train, Epoch: 4, Batch: 1345, Step num: 5902, Learning rate: 0.00011505, Avg batch loss: 0.0496, Avg batch acc: 0.9461
Train, Epoch: 4, Batch: 1346, Step num: 5903, Learning rate: 0.00011504, Avg batch loss: 0.0523, Avg batch acc: 0.9533
Train, Epoch: 4, Batch: 1347, Step num: 5904, Learning rate: 0.00011503, Avg batch loss: 0.0521, Avg batch acc: 0.9415
Train, Epoch: 4, Batch: 1348, Step num: 5905, Learning rate: 0.00011502, Avg batch loss: 0.0517, Avg batch acc: 0.9521
Train, Epoch: 4, Batch: 1349, Step num: 5906, Learning rate: 0.00011501, Avg batch loss: 0.0603, Avg batch acc: 0.9494
Train, Epoch: 4, Batch: 1350, Step num: 5907, Learning rate: 0.00011500, Avg batch loss: 0.0459, Avg batch acc: 0.9583
Train, Epoch: 4, Batch: 1351, Step num: 5908, Learning rate: 0.00011499, Avg batch loss: 0.0488, Avg batch acc: 0.9537
Train, Epoch: 4, Batch: 1352, Step num: 5909, Learning rate: 0.00011498, Avg batch loss: 0.0533, Avg batch acc: 0.9507
Train, Epoch: 4, Batch: 1353, Step num: 5910, Learning rate: 0.00011497, Avg batch loss: 0.0486, Avg batch acc: 0.9566
Train, Epoch: 4, Batch: 1354, Step num: 5911, Learning rate: 0.00011496, Avg batch loss: 0.0549, Avg batch acc: 0.9485
Train, Epoch: 4, Batch: 1355, Step num: 5912, Learning rate: 0.00011495, Avg batch loss: 0.0569, Avg batch acc: 0.9419
Train, Epoch: 4, Batch: 1356, Step num: 5913, Learning rate: 0.00011495, Avg batch loss: 0.0528, Avg batch acc: 0.9415
Train, Epoch: 4, Batch: 1357, Step num: 5914, Learning rate: 0.00011494, Avg batch loss: 0.0434, Avg batch acc: 0.9554
Train, Epoch: 4, Batch: 1358, Step num: 5915, Learning rate: 0.00011493, Avg batch loss: 0.0504, Avg batch acc: 0.9508
Train, Epoch: 4, Batch: 1359, Step num: 5916, Learning rate: 0.00011492, Avg batch loss: 0.0450, Avg batch acc: 0.9524
Train, Epoch: 4, Batch: 1360, Step num: 5917, Learning rate: 0.00011491, Avg batch loss: 0.0536, Avg batch acc: 0.9471
Train, Epoch: 4, Batch: 1361, Step num: 5918, Learning rate: 0.00011490, Avg batch loss: 0.0525, Avg batch acc: 0.9533
Train, Epoch: 4, Batch: 1362, Step num: 5919, Learning rate: 0.00011489, Avg batch loss: 0.0589, Avg batch acc: 0.9450
Train, Epoch: 4, Batch: 1363, Step num: 5920, Learning rate: 0.00011488, Avg batch loss: 0.0536, Avg batch acc: 0.9413
Train, Epoch: 4, Batch: 1364, Step num: 5921, Learning rate: 0.00011487, Avg batch loss: 0.0477, Avg batch acc: 0.9487
Train, Epoch: 4, Batch: 1365, Step num: 5922, Learning rate: 0.00011486, Avg batch loss: 0.0592, Avg batch acc: 0.9468
Train, Epoch: 4, Batch: 1366, Step num: 5923, Learning rate: 0.00011485, Avg batch loss: 0.0516, Avg batch acc: 0.9506
Train, Epoch: 4, Batch: 1367, Step num: 5924, Learning rate: 0.00011484, Avg batch loss: 0.0544, Avg batch acc: 0.9487
Train, Epoch: 4, Batch: 1368, Step num: 5925, Learning rate: 0.00011483, Avg batch loss: 0.0559, Avg batch acc: 0.9505
Train, Epoch: 4, Batch: 1369, Step num: 5926, Learning rate: 0.00011482, Avg batch loss: 0.0521, Avg batch acc: 0.9516
Train, Epoch: 4, Batch: 1370, Step num: 5927, Learning rate: 0.00011481, Avg batch loss: 0.0461, Avg batch acc: 0.9524
Train, Epoch: 4, Batch: 1371, Step num: 5928, Learning rate: 0.00011480, Avg batch loss: 0.0703, Avg batch acc: 0.9437
Train, Epoch: 4, Batch: 1372, Step num: 5929, Learning rate: 0.00011479, Avg batch loss: 0.0519, Avg batch acc: 0.9494
Train, Epoch: 4, Batch: 1373, Step num: 5930, Learning rate: 0.00011478, Avg batch loss: 0.0477, Avg batch acc: 0.9569
Train, Epoch: 4, Batch: 1374, Step num: 5931, Learning rate: 0.00011477, Avg batch loss: 0.0536, Avg batch acc: 0.9488
Train, Epoch: 4, Batch: 1375, Step num: 5932, Learning rate: 0.00011476, Avg batch loss: 0.0513, Avg batch acc: 0.9376
Train, Epoch: 4, Batch: 1376, Step num: 5933, Learning rate: 0.00011475, Avg batch loss: 0.0580, Avg batch acc: 0.9402
Train, Epoch: 4, Batch: 1377, Step num: 5934, Learning rate: 0.00011474, Avg batch loss: 0.0543, Avg batch acc: 0.9469
Train, Epoch: 4, Batch: 1378, Step num: 5935, Learning rate: 0.00011473, Avg batch loss: 0.0567, Avg batch acc: 0.9536
Train, Epoch: 4, Batch: 1379, Step num: 5936, Learning rate: 0.00011472, Avg batch loss: 0.0598, Avg batch acc: 0.9449
Train, Epoch: 4, Batch: 1380, Step num: 5937, Learning rate: 0.00011471, Avg batch loss: 0.0539, Avg batch acc: 0.9458
Train, Epoch: 4, Batch: 1381, Step num: 5938, Learning rate: 0.00011470, Avg batch loss: 0.0501, Avg batch acc: 0.9520
Train, Epoch: 4, Batch: 1382, Step num: 5939, Learning rate: 0.00011469, Avg batch loss: 0.0713, Avg batch acc: 0.9344
Train, Epoch: 4, Batch: 1383, Step num: 5940, Learning rate: 0.00011468, Avg batch loss: 0.0513, Avg batch acc: 0.9513
Train, Epoch: 4, Batch: 1384, Step num: 5941, Learning rate: 0.00011467, Avg batch loss: 0.0528, Avg batch acc: 0.9496
Train, Epoch: 4, Batch: 1385, Step num: 5942, Learning rate: 0.00011466, Avg batch loss: 0.0537, Avg batch acc: 0.9513
Train, Epoch: 4, Batch: 1386, Step num: 5943, Learning rate: 0.00011465, Avg batch loss: 0.0479, Avg batch acc: 0.9533
Train, Epoch: 4, Batch: 1387, Step num: 5944, Learning rate: 0.00011465, Avg batch loss: 0.0466, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 1388, Step num: 5945, Learning rate: 0.00011464, Avg batch loss: 0.0443, Avg batch acc: 0.9500
Train, Epoch: 4, Batch: 1389, Step num: 5946, Learning rate: 0.00011463, Avg batch loss: 0.0474, Avg batch acc: 0.9506
Train, Epoch: 4, Batch: 1390, Step num: 5947, Learning rate: 0.00011462, Avg batch loss: 0.0460, Avg batch acc: 0.9571
Train, Epoch: 4, Batch: 1391, Step num: 5948, Learning rate: 0.00011461, Avg batch loss: 0.0650, Avg batch acc: 0.9476
Train, Epoch: 4, Batch: 1392, Step num: 5949, Learning rate: 0.00011460, Avg batch loss: 0.0565, Avg batch acc: 0.9455
Train, Epoch: 4, Batch: 1393, Step num: 5950, Learning rate: 0.00011459, Avg batch loss: 0.0586, Avg batch acc: 0.9484
Train, Epoch: 4, Batch: 1394, Step num: 5951, Learning rate: 0.00011458, Avg batch loss: 0.0539, Avg batch acc: 0.9482
Train, Epoch: 4, Batch: 1395, Step num: 5952, Learning rate: 0.00011457, Avg batch loss: 0.0538, Avg batch acc: 0.9473
Train, Epoch: 4, Batch: 1396, Step num: 5953, Learning rate: 0.00011456, Avg batch loss: 0.0547, Avg batch acc: 0.9486
Train, Epoch: 4, Batch: 1397, Step num: 5954, Learning rate: 0.00011455, Avg batch loss: 0.0497, Avg batch acc: 0.9474
Train, Epoch: 4, Batch: 1398, Step num: 5955, Learning rate: 0.00011454, Avg batch loss: 0.0579, Avg batch acc: 0.9483
Train, Epoch: 4, Batch: 1399, Step num: 5956, Learning rate: 0.00011453, Avg batch loss: 0.0545, Avg batch acc: 0.9423
Train, Epoch: 4, Batch: 1400, Step num: 5957, Learning rate: 0.00011452, Avg batch loss: 0.0659, Avg batch acc: 0.9449
Train, Epoch: 4, Batch: 1401, Step num: 5958, Learning rate: 0.00011451, Avg batch loss: 0.0775, Avg batch acc: 0.9432
Train, Epoch: 4, Batch: 1402, Step num: 5959, Learning rate: 0.00011450, Avg batch loss: 0.0732, Avg batch acc: 0.9418
Train, Epoch: 4, Batch: 1403, Step num: 5960, Learning rate: 0.00011449, Avg batch loss: 0.0566, Avg batch acc: 0.9462
Train, Epoch: 4, Batch: 1404, Step num: 5961, Learning rate: 0.00011448, Avg batch loss: 0.0541, Avg batch acc: 0.9433
Train, Epoch: 4, Batch: 1405, Step num: 5962, Learning rate: 0.00011447, Avg batch loss: 0.0789, Avg batch acc: 0.9432
Train, Epoch: 4, Batch: 1406, Step num: 5963, Learning rate: 0.00011446, Avg batch loss: 0.0534, Avg batch acc: 0.9487
Train, Epoch: 4, Batch: 1407, Step num: 5964, Learning rate: 0.00011445, Avg batch loss: 0.0540, Avg batch acc: 0.9516
Train, Epoch: 4, Batch: 1408, Step num: 5965, Learning rate: 0.00011444, Avg batch loss: 0.0543, Avg batch acc: 0.9461
Train, Epoch: 4, Batch: 1409, Step num: 5966, Learning rate: 0.00011443, Avg batch loss: 0.0442, Avg batch acc: 0.9517
Train, Epoch: 4, Batch: 1410, Step num: 5967, Learning rate: 0.00011442, Avg batch loss: 0.0567, Avg batch acc: 0.9456
Train, Epoch: 4, Batch: 1411, Step num: 5968, Learning rate: 0.00011441, Avg batch loss: 0.0650, Avg batch acc: 0.9451
Train, Epoch: 4, Batch: 1412, Step num: 5969, Learning rate: 0.00011440, Avg batch loss: 0.0711, Avg batch acc: 0.9392
Train, Epoch: 4, Batch: 1413, Step num: 5970, Learning rate: 0.00011440, Avg batch loss: 0.0569, Avg batch acc: 0.9478
Train, Epoch: 4, Batch: 1414, Step num: 5971, Learning rate: 0.00011439, Avg batch loss: 0.0561, Avg batch acc: 0.9468
Train, Epoch: 4, Batch: 1415, Step num: 5972, Learning rate: 0.00011438, Avg batch loss: 0.0510, Avg batch acc: 0.9498
Train, Epoch: 4, Batch: 1416, Step num: 5973, Learning rate: 0.00011437, Avg batch loss: 0.0522, Avg batch acc: 0.9541
Train, Epoch: 4, Batch: 1417, Step num: 5974, Learning rate: 0.00011436, Avg batch loss: 0.0707, Avg batch acc: 0.9373
Train, Epoch: 4, Batch: 1418, Step num: 5975, Learning rate: 0.00011435, Avg batch loss: 0.0509, Avg batch acc: 0.9498
Train, Epoch: 4, Batch: 1419, Step num: 5976, Learning rate: 0.00011434, Avg batch loss: 0.0586, Avg batch acc: 0.9437
Train, Epoch: 4, Batch: 1420, Step num: 5977, Learning rate: 0.00011433, Avg batch loss: 0.0700, Avg batch acc: 0.9435
Train, Epoch: 4, Batch: 1421, Step num: 5978, Learning rate: 0.00011432, Avg batch loss: 0.0437, Avg batch acc: 0.9519
Train, Epoch: 4, Batch: 1422, Step num: 5979, Learning rate: 0.00011431, Avg batch loss: 0.0550, Avg batch acc: 0.9474
Train, Epoch: 4, Batch: 1423, Step num: 5980, Learning rate: 0.00011430, Avg batch loss: 0.0461, Avg batch acc: 0.9569
Train, Epoch: 4, Batch: 1424, Step num: 5981, Learning rate: 0.00011429, Avg batch loss: 0.0550, Avg batch acc: 0.9475
Train, Epoch: 4, Batch: 1425, Step num: 5982, Learning rate: 0.00011428, Avg batch loss: 0.0496, Avg batch acc: 0.9452
Train, Epoch: 4, Batch: 1426, Step num: 5983, Learning rate: 0.00011427, Avg batch loss: 0.0535, Avg batch acc: 0.9470
Train, Epoch: 4, Batch: 1427, Step num: 5984, Learning rate: 0.00011426, Avg batch loss: 0.0437, Avg batch acc: 0.9554
Train, Epoch: 4, Batch: 1428, Step num: 5985, Learning rate: 0.00011425, Avg batch loss: 0.0481, Avg batch acc: 0.9517
Train, Epoch: 4, Batch: 1429, Step num: 5986, Learning rate: 0.00011424, Avg batch loss: 0.0700, Avg batch acc: 0.9436
Train, Epoch: 4, Batch: 1430, Step num: 5987, Learning rate: 0.00011423, Avg batch loss: 0.0604, Avg batch acc: 0.9414
Train, Epoch: 4, Batch: 1431, Step num: 5988, Learning rate: 0.00011422, Avg batch loss: 0.0703, Avg batch acc: 0.9439
Train, Epoch: 4, Batch: 1432, Step num: 5989, Learning rate: 0.00011421, Avg batch loss: 0.0543, Avg batch acc: 0.9536
Train, Epoch: 4, Batch: 1433, Step num: 5990, Learning rate: 0.00011420, Avg batch loss: 0.0548, Avg batch acc: 0.9428
Train, Epoch: 4, Batch: 1434, Step num: 5991, Learning rate: 0.00011419, Avg batch loss: 0.0591, Avg batch acc: 0.9459
Train, Epoch: 4, Batch: 1435, Step num: 5992, Learning rate: 0.00011419, Avg batch loss: 0.0450, Avg batch acc: 0.9534
Train, Epoch: 4, Batch: 1436, Step num: 5993, Learning rate: 0.00011418, Avg batch loss: 0.0553, Avg batch acc: 0.9463
Train, Epoch: 4, Batch: 1437, Step num: 5994, Learning rate: 0.00011417, Avg batch loss: 0.0613, Avg batch acc: 0.9426
Train, Epoch: 4, Batch: 1438, Step num: 5995, Learning rate: 0.00011416, Avg batch loss: 0.0544, Avg batch acc: 0.9427
Train, Epoch: 4, Batch: 1439, Step num: 5996, Learning rate: 0.00011415, Avg batch loss: 0.0535, Avg batch acc: 0.9432
Train, Epoch: 4, Batch: 1440, Step num: 5997, Learning rate: 0.00011414, Avg batch loss: 0.0550, Avg batch acc: 0.9462
Train, Epoch: 4, Batch: 1441, Step num: 5998, Learning rate: 0.00011413, Avg batch loss: 0.0532, Avg batch acc: 0.9451
Train, Epoch: 4, Batch: 1442, Step num: 5999, Learning rate: 0.00011412, Avg batch loss: 0.0532, Avg batch acc: 0.9416
Train, Epoch: 4, Batch: 1443, Step num: 6000, Learning rate: 0.00011411, Avg batch loss: 0.0416, Avg batch acc: 0.9612
Train, Epoch: 4, Batch: 1444, Step num: 6001, Learning rate: 0.00011410, Avg batch loss: 0.0637, Avg batch acc: 0.9464
Train, Epoch: 4, Batch: 1445, Step num: 6002, Learning rate: 0.00011409, Avg batch loss: 0.0634, Avg batch acc: 0.9398
Train, Epoch: 4, Batch: 1446, Step num: 6003, Learning rate: 0.00011408, Avg batch loss: 0.0574, Avg batch acc: 0.9522
Train, Epoch: 4, Batch: 1447, Step num: 6004, Learning rate: 0.00011407, Avg batch loss: 0.0503, Avg batch acc: 0.9453
Train, Epoch: 4, Batch: 1448, Step num: 6005, Learning rate: 0.00011406, Avg batch loss: 0.0639, Avg batch acc: 0.9402
Train, Epoch: 4, Batch: 1449, Step num: 6006, Learning rate: 0.00011405, Avg batch loss: 0.0503, Avg batch acc: 0.9507
Train, Epoch: 4, Batch: 1450, Step num: 6007, Learning rate: 0.00011404, Avg batch loss: 0.0642, Avg batch acc: 0.9492
Train, Epoch: 4, Batch: 1451, Step num: 6008, Learning rate: 0.00011403, Avg batch loss: 0.0692, Avg batch acc: 0.9442
Train, Epoch: 4, Batch: 1452, Step num: 6009, Learning rate: 0.00011402, Avg batch loss: 0.0583, Avg batch acc: 0.9444
Train, Epoch: 4, Batch: 1453, Step num: 6010, Learning rate: 0.00011401, Avg batch loss: 0.0540, Avg batch acc: 0.9476
Train, Epoch: 4, Batch: 1454, Step num: 6011, Learning rate: 0.00011400, Avg batch loss: 0.0536, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 1455, Step num: 6012, Learning rate: 0.00011399, Avg batch loss: 0.0446, Avg batch acc: 0.9512
Train, Epoch: 4, Batch: 1456, Step num: 6013, Learning rate: 0.00011399, Avg batch loss: 0.0534, Avg batch acc: 0.9419
Train, Epoch: 4, Batch: 1457, Step num: 6014, Learning rate: 0.00011398, Avg batch loss: 0.0475, Avg batch acc: 0.9544
Train, Epoch: 4, Batch: 1458, Step num: 6015, Learning rate: 0.00011397, Avg batch loss: 0.0648, Avg batch acc: 0.9342
Train, Epoch: 4, Batch: 1459, Step num: 6016, Learning rate: 0.00011396, Avg batch loss: 0.0788, Avg batch acc: 0.9379
Train, Epoch: 4, Batch: 1460, Step num: 6017, Learning rate: 0.00011395, Avg batch loss: 0.0874, Avg batch acc: 0.9421
Train, Epoch: 4, Batch: 1461, Step num: 6018, Learning rate: 0.00011394, Avg batch loss: 0.0430, Avg batch acc: 0.9562
Train, Epoch: 4, Batch: 1462, Step num: 6019, Learning rate: 0.00011393, Avg batch loss: 0.0704, Avg batch acc: 0.9438
Train, Epoch: 4, Batch: 1463, Step num: 6020, Learning rate: 0.00011392, Avg batch loss: 0.0599, Avg batch acc: 0.9522
Train, Epoch: 4, Batch: 1464, Step num: 6021, Learning rate: 0.00011391, Avg batch loss: 0.0568, Avg batch acc: 0.9511
Train, Epoch: 4, Batch: 1465, Step num: 6022, Learning rate: 0.00011390, Avg batch loss: 0.0480, Avg batch acc: 0.9538
Train, Epoch: 4, Batch: 1466, Step num: 6023, Learning rate: 0.00011389, Avg batch loss: 0.0551, Avg batch acc: 0.9432
Train, Epoch: 4, Batch: 1467, Step num: 6024, Learning rate: 0.00011388, Avg batch loss: 0.0514, Avg batch acc: 0.9485
Train, Epoch: 4, Batch: 1468, Step num: 6025, Learning rate: 0.00011387, Avg batch loss: 0.0804, Avg batch acc: 0.9399
Train, Epoch: 4, Batch: 1469, Step num: 6026, Learning rate: 0.00011386, Avg batch loss: 0.0522, Avg batch acc: 0.9476
Train, Epoch: 4, Batch: 1470, Step num: 6027, Learning rate: 0.00011385, Avg batch loss: 0.0760, Avg batch acc: 0.9362
Train, Epoch: 4, Batch: 1471, Step num: 6028, Learning rate: 0.00011384, Avg batch loss: 0.0640, Avg batch acc: 0.9506
Train, Epoch: 4, Batch: 1472, Step num: 6029, Learning rate: 0.00011383, Avg batch loss: 0.0545, Avg batch acc: 0.9460
Train, Epoch: 4, Batch: 1473, Step num: 6030, Learning rate: 0.00011382, Avg batch loss: 0.0436, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 1474, Step num: 6031, Learning rate: 0.00011382, Avg batch loss: 0.0584, Avg batch acc: 0.9467
Train, Epoch: 4, Batch: 1475, Step num: 6032, Learning rate: 0.00011381, Avg batch loss: 0.0521, Avg batch acc: 0.9465
Train, Epoch: 4, Batch: 1476, Step num: 6033, Learning rate: 0.00011380, Avg batch loss: 0.0515, Avg batch acc: 0.9417
Train, Epoch: 4, Batch: 1477, Step num: 6034, Learning rate: 0.00011379, Avg batch loss: 0.0682, Avg batch acc: 0.9350
Train, Epoch: 4, Batch: 1478, Step num: 6035, Learning rate: 0.00011378, Avg batch loss: 0.0546, Avg batch acc: 0.9458
Train, Epoch: 4, Batch: 1479, Step num: 6036, Learning rate: 0.00011377, Avg batch loss: 0.0507, Avg batch acc: 0.9530
Train, Epoch: 4, Batch: 1480, Step num: 6037, Learning rate: 0.00011376, Avg batch loss: 0.0611, Avg batch acc: 0.9423
Train, Epoch: 4, Batch: 1481, Step num: 6038, Learning rate: 0.00011375, Avg batch loss: 0.0546, Avg batch acc: 0.9515
Train, Epoch: 4, Batch: 1482, Step num: 6039, Learning rate: 0.00011374, Avg batch loss: 0.0472, Avg batch acc: 0.9587
Train, Epoch: 4, Batch: 1483, Step num: 6040, Learning rate: 0.00011373, Avg batch loss: 0.0441, Avg batch acc: 0.9529
Train, Epoch: 4, Batch: 1484, Step num: 6041, Learning rate: 0.00011372, Avg batch loss: 0.0498, Avg batch acc: 0.9429
Train, Epoch: 4, Batch: 1485, Step num: 6042, Learning rate: 0.00011371, Avg batch loss: 0.0583, Avg batch acc: 0.9440
Train, Epoch: 4, Batch: 1486, Step num: 6043, Learning rate: 0.00011370, Avg batch loss: 0.0589, Avg batch acc: 0.9540
Train, Epoch: 4, Batch: 1487, Step num: 6044, Learning rate: 0.00011369, Avg batch loss: 0.0532, Avg batch acc: 0.9433
Train, Epoch: 4, Batch: 1488, Step num: 6045, Learning rate: 0.00011368, Avg batch loss: 0.0521, Avg batch acc: 0.9488
Train, Epoch: 4, Batch: 1489, Step num: 6046, Learning rate: 0.00011367, Avg batch loss: 0.0343, Avg batch acc: 0.9658
Train, Epoch: 4, Batch: 1490, Step num: 6047, Learning rate: 0.00011366, Avg batch loss: 0.0493, Avg batch acc: 0.9502
Train, Epoch: 4, Batch: 1491, Step num: 6048, Learning rate: 0.00011366, Avg batch loss: 0.0511, Avg batch acc: 0.9500
Train, Epoch: 4, Batch: 1492, Step num: 6049, Learning rate: 0.00011365, Avg batch loss: 0.0368, Avg batch acc: 0.9601
Train, Epoch: 4, Batch: 1493, Step num: 6050, Learning rate: 0.00011364, Avg batch loss: 0.0594, Avg batch acc: 0.9474
Train, Epoch: 4, Batch: 1494, Step num: 6051, Learning rate: 0.00011363, Avg batch loss: 0.0498, Avg batch acc: 0.9483
Train, Epoch: 4, Batch: 1495, Step num: 6052, Learning rate: 0.00011362, Avg batch loss: 0.0483, Avg batch acc: 0.9535
Train, Epoch: 4, Batch: 1496, Step num: 6053, Learning rate: 0.00011361, Avg batch loss: 0.0579, Avg batch acc: 0.9441
Train, Epoch: 4, Batch: 1497, Step num: 6054, Learning rate: 0.00011360, Avg batch loss: 0.0526, Avg batch acc: 0.9511
Train, Epoch: 4, Batch: 1498, Step num: 6055, Learning rate: 0.00011359, Avg batch loss: 0.0445, Avg batch acc: 0.9601
Train, Epoch: 4, Batch: 1499, Step num: 6056, Learning rate: 0.00011358, Avg batch loss: 0.0520, Avg batch acc: 0.9512
Train, Epoch: 4, Batch: 1500, Step num: 6057, Learning rate: 0.00011357, Avg batch loss: 0.0655, Avg batch acc: 0.9479
Train, Epoch: 4, Batch: 1501, Step num: 6058, Learning rate: 0.00011356, Avg batch loss: 0.0570, Avg batch acc: 0.9483
Train, Epoch: 4, Batch: 1502, Step num: 6059, Learning rate: 0.00011355, Avg batch loss: 0.0455, Avg batch acc: 0.9451
Train, Epoch: 4, Batch: 1503, Step num: 6060, Learning rate: 0.00011354, Avg batch loss: 0.0592, Avg batch acc: 0.9426
Train, Epoch: 4, Batch: 1504, Step num: 6061, Learning rate: 0.00011353, Avg batch loss: 0.0503, Avg batch acc: 0.9487
Train, Epoch: 4, Batch: 1505, Step num: 6062, Learning rate: 0.00011352, Avg batch loss: 0.0699, Avg batch acc: 0.9362
Train, Epoch: 4, Batch: 1506, Step num: 6063, Learning rate: 0.00011351, Avg batch loss: 0.0447, Avg batch acc: 0.9570
Train, Epoch: 4, Batch: 1507, Step num: 6064, Learning rate: 0.00011351, Avg batch loss: 0.0541, Avg batch acc: 0.9526
Train, Epoch: 4, Batch: 1508, Step num: 6065, Learning rate: 0.00011350, Avg batch loss: 0.0456, Avg batch acc: 0.9554
Train, Epoch: 4, Batch: 1509, Step num: 6066, Learning rate: 0.00011349, Avg batch loss: 0.0585, Avg batch acc: 0.9490
Train, Epoch: 4, Batch: 1510, Step num: 6067, Learning rate: 0.00011348, Avg batch loss: 0.0495, Avg batch acc: 0.9514
Train, Epoch: 4, Batch: 1511, Step num: 6068, Learning rate: 0.00011347, Avg batch loss: 0.0577, Avg batch acc: 0.9389
Train, Epoch: 4, Batch: 1512, Step num: 6069, Learning rate: 0.00011346, Avg batch loss: 0.0669, Avg batch acc: 0.9353
Train, Epoch: 4, Batch: 1513, Step num: 6070, Learning rate: 0.00011345, Avg batch loss: 0.0442, Avg batch acc: 0.9580
Train, Epoch: 4, Batch: 1514, Step num: 6071, Learning rate: 0.00011344, Avg batch loss: 0.0493, Avg batch acc: 0.9519
Train, Epoch: 4, Batch: 1515, Step num: 6072, Learning rate: 0.00011343, Avg batch loss: 0.0505, Avg batch acc: 0.9483
Train, Epoch: 4, Batch: 1516, Step num: 6073, Learning rate: 0.00011342, Avg batch loss: 0.0615, Avg batch acc: 0.9409
Train, Epoch: 4, Batch: 1517, Step num: 6074, Learning rate: 0.00011341, Avg batch loss: 0.0606, Avg batch acc: 0.9456
Train, Epoch: 4, Batch: 1518, Step num: 6075, Learning rate: 0.00011340, Avg batch loss: 0.0624, Avg batch acc: 0.9468
Train, Epoch: 4, Batch: 1519, Step num: 6076, Learning rate: 0.00011339, Avg batch loss: 0.0503, Avg batch acc: 0.9525
Train, Epoch: 4, Avg epoch loss: 0.0772, Avg epoch acc: 0.9304, Overall time: 962.0 s, Speed: 4524.7 tokens/s on cuda:1

Validate, Epoch: 4, Batch: 1, Avg batch loss: 0.0457, Avg batch acc: 0.9516
Validate, Epoch: 4, Batch: 2, Avg batch loss: 0.0609, Avg batch acc: 0.9437
Validate, Epoch: 4, Batch: 3, Avg batch loss: 0.0525, Avg batch acc: 0.9510
Validate, Epoch: 4, Batch: 4, Avg batch loss: 0.0407, Avg batch acc: 0.9604
Validate, Epoch: 4, Batch: 5, Avg batch loss: 0.0448, Avg batch acc: 0.9569
Validate, Epoch: 4, Batch: 6, Avg batch loss: 0.0456, Avg batch acc: 0.9515
Validate, Epoch: 4, Batch: 7, Avg batch loss: 0.0555, Avg batch acc: 0.9481
Validate, Epoch: 4, Batch: 8, Avg batch loss: 0.0495, Avg batch acc: 0.9537
Validate, Epoch: 4, Batch: 9, Avg batch loss: 0.0487, Avg batch acc: 0.9520
Validate, Epoch: 4, Batch: 10, Avg batch loss: 0.0517, Avg batch acc: 0.9476
Validate, Epoch: 4, Batch: 11, Avg batch loss: 0.0518, Avg batch acc: 0.9491
Validate, Epoch: 4, Batch: 12, Avg batch loss: 0.0649, Avg batch acc: 0.9318
Validate, Epoch: 4, Batch: 13, Avg batch loss: 0.0774, Avg batch acc: 0.9515
Validate, Epoch: 4, Batch: 14, Avg batch loss: 0.0613, Avg batch acc: 0.9405
Validate, Epoch: 4, Batch: 15, Avg batch loss: 0.0515, Avg batch acc: 0.9477
Validate, Epoch: 4, Batch: 16, Avg batch loss: 0.0560, Avg batch acc: 0.9556
Validate, Epoch: 4, Batch: 17, Avg batch loss: 0.0516, Avg batch acc: 0.9461
Validate, Epoch: 4, Batch: 18, Avg batch loss: 0.0478, Avg batch acc: 0.9577
Validate, Epoch: 4, Batch: 19, Avg batch loss: 0.0574, Avg batch acc: 0.9414
Validate, Epoch: 4, Batch: 20, Avg batch loss: 0.0479, Avg batch acc: 0.9545
Validate, Epoch: 4, Batch: 21, Avg batch loss: 0.0581, Avg batch acc: 0.9437
Validate, Epoch: 4, Batch: 22, Avg batch loss: 0.0460, Avg batch acc: 0.9536
Validate, Epoch: 4, Batch: 23, Avg batch loss: 0.0537, Avg batch acc: 0.9406
Validate, Epoch: 4, Batch: 24, Avg batch loss: 0.0465, Avg batch acc: 0.9504
Validate, Epoch: 4, Batch: 25, Avg batch loss: 0.0425, Avg batch acc: 0.9490
Validate, Epoch: 4, Batch: 26, Avg batch loss: 0.0436, Avg batch acc: 0.9576
Validate, Epoch: 4, Batch: 27, Avg batch loss: 0.0560, Avg batch acc: 0.9493
Validate, Epoch: 4, Batch: 28, Avg batch loss: 0.0514, Avg batch acc: 0.9499
Validate, Epoch: 4, Batch: 29, Avg batch loss: 0.0522, Avg batch acc: 0.9463
Validate, Epoch: 4, Batch: 30, Avg batch loss: 0.0519, Avg batch acc: 0.9524
Validate, Epoch: 4, Batch: 31, Avg batch loss: 0.0660, Avg batch acc: 0.9466
Validate, Epoch: 4, Batch: 32, Avg batch loss: 0.0598, Avg batch acc: 0.9399
Validate, Epoch: 4, Batch: 33, Avg batch loss: 0.0611, Avg batch acc: 0.9406
Validate, Epoch: 4, Batch: 34, Avg batch loss: 0.0467, Avg batch acc: 0.9549
Validate, Epoch: 4, Batch: 35, Avg batch loss: 0.0662, Avg batch acc: 0.9514
Validate, Epoch: 4, Batch: 36, Avg batch loss: 0.0493, Avg batch acc: 0.9472
Validate, Epoch: 4, Batch: 37, Avg batch loss: 0.0540, Avg batch acc: 0.9425
Validate, Epoch: 4, Batch: 38, Avg batch loss: 0.0501, Avg batch acc: 0.9542
Validate, Epoch: 4, Batch: 39, Avg batch loss: 0.0458, Avg batch acc: 0.9514
Validate, Epoch: 4, Batch: 40, Avg batch loss: 0.0683, Avg batch acc: 0.9497
Validate, Epoch: 4, Batch: 41, Avg batch loss: 0.0504, Avg batch acc: 0.9544
Validate, Epoch: 4, Batch: 42, Avg batch loss: 0.0565, Avg batch acc: 0.9510
Validate, Epoch: 4, Batch: 43, Avg batch loss: 0.0488, Avg batch acc: 0.9453
Validate, Epoch: 4, Batch: 44, Avg batch loss: 0.0502, Avg batch acc: 0.9539
Validate, Epoch: 4, Batch: 45, Avg batch loss: 0.0477, Avg batch acc: 0.9538
Validate, Epoch: 4, Batch: 46, Avg batch loss: 0.1021, Avg batch acc: 0.9418
Validate, Epoch: 4, Batch: 47, Avg batch loss: 0.0563, Avg batch acc: 0.9476
Validate, Epoch: 4, Batch: 48, Avg batch loss: 0.0526, Avg batch acc: 0.9543
Validate, Epoch: 4, Batch: 49, Avg batch loss: 0.0510, Avg batch acc: 0.9468
Validate, Epoch: 4, Batch: 50, Avg batch loss: 0.0565, Avg batch acc: 0.9456
Validate, Epoch: 4, Batch: 51, Avg batch loss: 0.0479, Avg batch acc: 0.9436
Validate, Epoch: 4, Batch: 52, Avg batch loss: 0.0558, Avg batch acc: 0.9466
Validate, Epoch: 4, Batch: 53, Avg batch loss: 0.0573, Avg batch acc: 0.9513
Validate, Epoch: 4, Batch: 54, Avg batch loss: 0.0473, Avg batch acc: 0.9489
Validate, Epoch: 4, Batch: 55, Avg batch loss: 0.0510, Avg batch acc: 0.9518
Validate, Epoch: 4, Batch: 56, Avg batch loss: 0.0452, Avg batch acc: 0.9575
Validate, Epoch: 4, Batch: 57, Avg batch loss: 0.0635, Avg batch acc: 0.9503
Validate, Epoch: 4, Batch: 58, Avg batch loss: 0.0467, Avg batch acc: 0.9480
Validate, Epoch: 4, Batch: 59, Avg batch loss: 0.0517, Avg batch acc: 0.9461
Validate, Epoch: 4, Batch: 60, Avg batch loss: 0.0523, Avg batch acc: 0.9483
Validate, Epoch: 4, Batch: 61, Avg batch loss: 0.0579, Avg batch acc: 0.9419
Validate, Epoch: 4, Batch: 62, Avg batch loss: 0.0410, Avg batch acc: 0.9574
Validate, Epoch: 4, Batch: 63, Avg batch loss: 0.0430, Avg batch acc: 0.9552
Validate, Epoch: 4, Batch: 64, Avg batch loss: 0.0452, Avg batch acc: 0.9514
Validate, Epoch: 4, Batch: 65, Avg batch loss: 0.0512, Avg batch acc: 0.9479
Validate, Epoch: 4, Batch: 66, Avg batch loss: 0.0482, Avg batch acc: 0.9547
Validate, Epoch: 4, Batch: 67, Avg batch loss: 0.0463, Avg batch acc: 0.9553
Validate, Epoch: 4, Batch: 68, Avg batch loss: 0.0578, Avg batch acc: 0.9453
Validate, Epoch: 4, Batch: 69, Avg batch loss: 0.0601, Avg batch acc: 0.9468
Validate, Epoch: 4, Batch: 70, Avg batch loss: 0.0490, Avg batch acc: 0.9508
Validate, Epoch: 4, Batch: 71, Avg batch loss: 0.0543, Avg batch acc: 0.9516
Validate, Epoch: 4, Batch: 72, Avg batch loss: 0.0650, Avg batch acc: 0.9447
Validate, Epoch: 4, Batch: 73, Avg batch loss: 0.0551, Avg batch acc: 0.9489
Validate, Epoch: 4, Batch: 74, Avg batch loss: 0.0462, Avg batch acc: 0.9546
Validate, Epoch: 4, Batch: 75, Avg batch loss: 0.0591, Avg batch acc: 0.9412
Validate, Epoch: 4, Batch: 76, Avg batch loss: 0.0393, Avg batch acc: 0.9640
Validate, Epoch: 4, Batch: 77, Avg batch loss: 0.0454, Avg batch acc: 0.9502
Validate, Epoch: 4, Batch: 78, Avg batch loss: 0.0525, Avg batch acc: 0.9463
Validate, Epoch: 4, Batch: 79, Avg batch loss: 0.0580, Avg batch acc: 0.9392
Validate, Epoch: 4, Batch: 80, Avg batch loss: 0.0480, Avg batch acc: 0.9610
Validate, Epoch: 4, Batch: 81, Avg batch loss: 0.0525, Avg batch acc: 0.9494
Validate, Epoch: 4, Batch: 82, Avg batch loss: 0.0524, Avg batch acc: 0.9440
Validate, Epoch: 4, Batch: 83, Avg batch loss: 0.0431, Avg batch acc: 0.9601
Validate, Epoch: 4, Batch: 84, Avg batch loss: 0.0477, Avg batch acc: 0.9517
Validate, Epoch: 4, Batch: 85, Avg batch loss: 0.0494, Avg batch acc: 0.9501
Validate, Epoch: 4, Batch: 86, Avg batch loss: 0.0546, Avg batch acc: 0.9427
Validate, Epoch: 4, Batch: 87, Avg batch loss: 0.0462, Avg batch acc: 0.9568
Validate, Epoch: 4, Batch: 88, Avg batch loss: 0.0496, Avg batch acc: 0.9507
Validate, Epoch: 4, Batch: 89, Avg batch loss: 0.0461, Avg batch acc: 0.9497
Validate, Epoch: 4, Batch: 90, Avg batch loss: 0.0520, Avg batch acc: 0.9516
Validate, Epoch: 4, Batch: 91, Avg batch loss: 0.0569, Avg batch acc: 0.9484
Validate, Epoch: 4, Batch: 92, Avg batch loss: 0.0606, Avg batch acc: 0.9505
Validate, Epoch: 4, Batch: 93, Avg batch loss: 0.0468, Avg batch acc: 0.9517
Validate, Epoch: 4, Batch: 94, Avg batch loss: 0.0497, Avg batch acc: 0.9477
Validate, Epoch: 4, Batch: 95, Avg batch loss: 0.0478, Avg batch acc: 0.9506
Validate, Epoch: 4, Batch: 96, Avg batch loss: 0.0615, Avg batch acc: 0.9438
Validate, Epoch: 4, Batch: 97, Avg batch loss: 0.0632, Avg batch acc: 0.9402
Validate, Epoch: 4, Batch: 98, Avg batch loss: 0.0582, Avg batch acc: 0.9477
Validate, Epoch: 4, Batch: 99, Avg batch loss: 0.0563, Avg batch acc: 0.9439
Validate, Epoch: 4, Batch: 100, Avg batch loss: 0.0478, Avg batch acc: 0.9545
Validate, Epoch: 4, Batch: 101, Avg batch loss: 0.0500, Avg batch acc: 0.9482
Validate, Epoch: 4, Batch: 102, Avg batch loss: 0.0504, Avg batch acc: 0.9527
Validate, Epoch: 4, Batch: 103, Avg batch loss: 0.0469, Avg batch acc: 0.9525
Validate, Epoch: 4, Batch: 104, Avg batch loss: 0.0639, Avg batch acc: 0.9483
Validate, Epoch: 4, Batch: 105, Avg batch loss: 0.0474, Avg batch acc: 0.9543
Validate, Epoch: 4, Batch: 106, Avg batch loss: 0.0455, Avg batch acc: 0.9573
Validate, Epoch: 4, Batch: 107, Avg batch loss: 0.0429, Avg batch acc: 0.9547
Validate, Epoch: 4, Batch: 108, Avg batch loss: 0.0521, Avg batch acc: 0.9488
Validate, Epoch: 4, Batch: 109, Avg batch loss: 0.0454, Avg batch acc: 0.9487
Validate, Epoch: 4, Batch: 110, Avg batch loss: 0.0466, Avg batch acc: 0.9584
Validate, Epoch: 4, Batch: 111, Avg batch loss: 0.0552, Avg batch acc: 0.9511
Validate, Epoch: 4, Batch: 112, Avg batch loss: 0.0387, Avg batch acc: 0.9515
Validate, Epoch: 4, Batch: 113, Avg batch loss: 0.0567, Avg batch acc: 0.9459
Validate, Epoch: 4, Batch: 114, Avg batch loss: 0.0537, Avg batch acc: 0.9457
Validate, Epoch: 4, Batch: 115, Avg batch loss: 0.0573, Avg batch acc: 0.9535
Validate, Epoch: 4, Batch: 116, Avg batch loss: 0.0641, Avg batch acc: 0.9433
Validate, Epoch: 4, Batch: 117, Avg batch loss: 0.0471, Avg batch acc: 0.9550
Validate, Epoch: 4, Batch: 118, Avg batch loss: 0.0529, Avg batch acc: 0.9478
Validate, Epoch: 4, Batch: 119, Avg batch loss: 0.0448, Avg batch acc: 0.9566
Validate, Epoch: 4, Batch: 120, Avg batch loss: 0.0728, Avg batch acc: 0.9411
Validate, Epoch: 4, Batch: 121, Avg batch loss: 0.0509, Avg batch acc: 0.9464
Validate, Epoch: 4, Batch: 122, Avg batch loss: 0.0645, Avg batch acc: 0.9520
Validate, Epoch: 4, Batch: 123, Avg batch loss: 0.0476, Avg batch acc: 0.9520
Validate, Epoch: 4, Batch: 124, Avg batch loss: 0.0507, Avg batch acc: 0.9502
Validate, Epoch: 4, Batch: 125, Avg batch loss: 0.0880, Avg batch acc: 0.9329
Validate, Epoch: 4, Batch: 126, Avg batch loss: 0.0523, Avg batch acc: 0.9460
Validate, Epoch: 4, Batch: 127, Avg batch loss: 0.0605, Avg batch acc: 0.9526
Validate, Epoch: 4, Batch: 128, Avg batch loss: 0.0778, Avg batch acc: 0.9407
Validate, Epoch: 4, Batch: 129, Avg batch loss: 0.0449, Avg batch acc: 0.9527
Validate, Epoch: 4, Batch: 130, Avg batch loss: 0.0431, Avg batch acc: 0.9531
Validate, Epoch: 4, Batch: 131, Avg batch loss: 0.0526, Avg batch acc: 0.9546
Validate, Epoch: 4, Batch: 132, Avg batch loss: 0.0501, Avg batch acc: 0.9485
Validate, Epoch: 4, Batch: 133, Avg batch loss: 0.0618, Avg batch acc: 0.9418
Validate, Epoch: 4, Batch: 134, Avg batch loss: 0.0416, Avg batch acc: 0.9583
Validate, Epoch: 4, Batch: 135, Avg batch loss: 0.0476, Avg batch acc: 0.9536
Validate, Epoch: 4, Batch: 136, Avg batch loss: 0.0560, Avg batch acc: 0.9496
Validate, Epoch: 4, Batch: 137, Avg batch loss: 0.0544, Avg batch acc: 0.9537
Validate, Epoch: 4, Batch: 138, Avg batch loss: 0.0522, Avg batch acc: 0.9507
Validate, Epoch: 4, Batch: 139, Avg batch loss: 0.0477, Avg batch acc: 0.9517
Validate, Epoch: 4, Batch: 140, Avg batch loss: 0.0471, Avg batch acc: 0.9508
Validate, Epoch: 4, Batch: 141, Avg batch loss: 0.0474, Avg batch acc: 0.9563
Validate, Epoch: 4, Batch: 142, Avg batch loss: 0.0603, Avg batch acc: 0.9502
Validate, Epoch: 4, Batch: 143, Avg batch loss: 0.0476, Avg batch acc: 0.9533
Validate, Epoch: 4, Batch: 144, Avg batch loss: 0.0541, Avg batch acc: 0.9463
Validate, Epoch: 4, Batch: 145, Avg batch loss: 0.0546, Avg batch acc: 0.9479
Validate, Epoch: 4, Batch: 146, Avg batch loss: 0.0532, Avg batch acc: 0.9489
Validate, Epoch: 4, Batch: 147, Avg batch loss: 0.0454, Avg batch acc: 0.9537
Validate, Epoch: 4, Batch: 148, Avg batch loss: 0.0588, Avg batch acc: 0.9491
Validate, Epoch: 4, Batch: 149, Avg batch loss: 0.0475, Avg batch acc: 0.9531
Validate, Epoch: 4, Batch: 150, Avg batch loss: 0.0549, Avg batch acc: 0.9508
Validate, Epoch: 4, Batch: 151, Avg batch loss: 0.0547, Avg batch acc: 0.9421
Validate, Epoch: 4, Batch: 152, Avg batch loss: 0.0435, Avg batch acc: 0.9580
Validate, Epoch: 4, Batch: 153, Avg batch loss: 0.0604, Avg batch acc: 0.9404
Validate, Epoch: 4, Batch: 154, Avg batch loss: 0.0602, Avg batch acc: 0.9443
Validate, Epoch: 4, Batch: 155, Avg batch loss: 0.0471, Avg batch acc: 0.9516
Validate, Epoch: 4, Batch: 156, Avg batch loss: 0.0692, Avg batch acc: 0.9446
Validate, Epoch: 4, Batch: 157, Avg batch loss: 0.0476, Avg batch acc: 0.9529
Validate, Epoch: 4, Batch: 158, Avg batch loss: 0.0513, Avg batch acc: 0.9536
Validate, Epoch: 4, Batch: 159, Avg batch loss: 0.0471, Avg batch acc: 0.9497
Validate, Epoch: 4, Batch: 160, Avg batch loss: 0.0394, Avg batch acc: 0.9560
Validate, Epoch: 4, Batch: 161, Avg batch loss: 0.0635, Avg batch acc: 0.9394
Validate, Epoch: 4, Batch: 162, Avg batch loss: 0.0417, Avg batch acc: 0.9579
Validate, Epoch: 4, Batch: 163, Avg batch loss: 0.0493, Avg batch acc: 0.9437
Validate, Epoch: 4, Batch: 164, Avg batch loss: 0.0535, Avg batch acc: 0.9421
Validate, Epoch: 4, Batch: 165, Avg batch loss: 0.0514, Avg batch acc: 0.9460
Validate, Epoch: 4, Batch: 166, Avg batch loss: 0.0648, Avg batch acc: 0.9449
Validate, Epoch: 4, Batch: 167, Avg batch loss: 0.0444, Avg batch acc: 0.9556
Validate, Epoch: 4, Batch: 168, Avg batch loss: 0.0532, Avg batch acc: 0.9376
Validate, Epoch: 4, Batch: 169, Avg batch loss: 0.0529, Avg batch acc: 0.9442
Validate, Epoch: 4, Avg epoch loss: 0.0529, Avg epoch acc: 0.9495, Overall time: 37.8 s, Speed: 12756.1 tokens/s on cuda:1

Train, Epoch: 5, Batch: 1, Step num: 6077, Learning rate: 0.00011338, Avg batch loss: 0.0446, Avg batch acc: 0.9548
Train, Epoch: 5, Batch: 2, Step num: 6078, Learning rate: 0.00011337, Avg batch loss: 0.0546, Avg batch acc: 0.9449
Train, Epoch: 5, Batch: 3, Step num: 6079, Learning rate: 0.00011336, Avg batch loss: 0.0490, Avg batch acc: 0.9446
Train, Epoch: 5, Batch: 4, Step num: 6080, Learning rate: 0.00011336, Avg batch loss: 0.0521, Avg batch acc: 0.9442
Train, Epoch: 5, Batch: 5, Step num: 6081, Learning rate: 0.00011335, Avg batch loss: 0.0530, Avg batch acc: 0.9484
Train, Epoch: 5, Batch: 6, Step num: 6082, Learning rate: 0.00011334, Avg batch loss: 0.0561, Avg batch acc: 0.9424
Train, Epoch: 5, Batch: 7, Step num: 6083, Learning rate: 0.00011333, Avg batch loss: 0.0497, Avg batch acc: 0.9476
Train, Epoch: 5, Batch: 8, Step num: 6084, Learning rate: 0.00011332, Avg batch loss: 0.0538, Avg batch acc: 0.9484
Train, Epoch: 5, Batch: 9, Step num: 6085, Learning rate: 0.00011331, Avg batch loss: 0.0481, Avg batch acc: 0.9498
Train, Epoch: 5, Batch: 10, Step num: 6086, Learning rate: 0.00011330, Avg batch loss: 0.0496, Avg batch acc: 0.9528
Train, Epoch: 5, Batch: 11, Step num: 6087, Learning rate: 0.00011329, Avg batch loss: 0.0467, Avg batch acc: 0.9479
Train, Epoch: 5, Batch: 12, Step num: 6088, Learning rate: 0.00011328, Avg batch loss: 0.0439, Avg batch acc: 0.9539
Train, Epoch: 5, Batch: 13, Step num: 6089, Learning rate: 0.00011327, Avg batch loss: 0.0538, Avg batch acc: 0.9421
Train, Epoch: 5, Batch: 14, Step num: 6090, Learning rate: 0.00011326, Avg batch loss: 0.0464, Avg batch acc: 0.9569
Train, Epoch: 5, Batch: 15, Step num: 6091, Learning rate: 0.00011325, Avg batch loss: 0.0599, Avg batch acc: 0.9459
Train, Epoch: 5, Batch: 16, Step num: 6092, Learning rate: 0.00011324, Avg batch loss: 0.0417, Avg batch acc: 0.9608
Train, Epoch: 5, Batch: 17, Step num: 6093, Learning rate: 0.00011323, Avg batch loss: 0.0550, Avg batch acc: 0.9501
Train, Epoch: 5, Batch: 18, Step num: 6094, Learning rate: 0.00011323, Avg batch loss: 0.0679, Avg batch acc: 0.9533
Train, Epoch: 5, Batch: 19, Step num: 6095, Learning rate: 0.00011322, Avg batch loss: 0.0506, Avg batch acc: 0.9517
Train, Epoch: 5, Batch: 20, Step num: 6096, Learning rate: 0.00011321, Avg batch loss: 0.0520, Avg batch acc: 0.9443
Train, Epoch: 5, Batch: 21, Step num: 6097, Learning rate: 0.00011320, Avg batch loss: 0.0447, Avg batch acc: 0.9571
Train, Epoch: 5, Batch: 22, Step num: 6098, Learning rate: 0.00011319, Avg batch loss: 0.0514, Avg batch acc: 0.9468
Train, Epoch: 5, Batch: 23, Step num: 6099, Learning rate: 0.00011318, Avg batch loss: 0.0483, Avg batch acc: 0.9510
Train, Epoch: 5, Batch: 24, Step num: 6100, Learning rate: 0.00011317, Avg batch loss: 0.0441, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 25, Step num: 6101, Learning rate: 0.00011316, Avg batch loss: 0.0495, Avg batch acc: 0.9533
Train, Epoch: 5, Batch: 26, Step num: 6102, Learning rate: 0.00011315, Avg batch loss: 0.0550, Avg batch acc: 0.9488
Train, Epoch: 5, Batch: 27, Step num: 6103, Learning rate: 0.00011314, Avg batch loss: 0.0541, Avg batch acc: 0.9442
Train, Epoch: 5, Batch: 28, Step num: 6104, Learning rate: 0.00011313, Avg batch loss: 0.0451, Avg batch acc: 0.9571
Train, Epoch: 5, Batch: 29, Step num: 6105, Learning rate: 0.00011312, Avg batch loss: 0.0430, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 30, Step num: 6106, Learning rate: 0.00011311, Avg batch loss: 0.0614, Avg batch acc: 0.9472
Train, Epoch: 5, Batch: 31, Step num: 6107, Learning rate: 0.00011310, Avg batch loss: 0.0483, Avg batch acc: 0.9521
Train, Epoch: 5, Batch: 32, Step num: 6108, Learning rate: 0.00011310, Avg batch loss: 0.0476, Avg batch acc: 0.9494
Train, Epoch: 5, Batch: 33, Step num: 6109, Learning rate: 0.00011309, Avg batch loss: 0.0496, Avg batch acc: 0.9439
Train, Epoch: 5, Batch: 34, Step num: 6110, Learning rate: 0.00011308, Avg batch loss: 0.0446, Avg batch acc: 0.9493
Train, Epoch: 5, Batch: 35, Step num: 6111, Learning rate: 0.00011307, Avg batch loss: 0.0431, Avg batch acc: 0.9530
Train, Epoch: 5, Batch: 36, Step num: 6112, Learning rate: 0.00011306, Avg batch loss: 0.0642, Avg batch acc: 0.9477
Train, Epoch: 5, Batch: 37, Step num: 6113, Learning rate: 0.00011305, Avg batch loss: 0.0469, Avg batch acc: 0.9552
Train, Epoch: 5, Batch: 38, Step num: 6114, Learning rate: 0.00011304, Avg batch loss: 0.0494, Avg batch acc: 0.9496
Train, Epoch: 5, Batch: 39, Step num: 6115, Learning rate: 0.00011303, Avg batch loss: 0.0450, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 40, Step num: 6116, Learning rate: 0.00011302, Avg batch loss: 0.0435, Avg batch acc: 0.9598
Train, Epoch: 5, Batch: 41, Step num: 6117, Learning rate: 0.00011301, Avg batch loss: 0.0534, Avg batch acc: 0.9468
Train, Epoch: 5, Batch: 42, Step num: 6118, Learning rate: 0.00011300, Avg batch loss: 0.0559, Avg batch acc: 0.9519
Train, Epoch: 5, Batch: 43, Step num: 6119, Learning rate: 0.00011299, Avg batch loss: 0.0476, Avg batch acc: 0.9487
Train, Epoch: 5, Batch: 44, Step num: 6120, Learning rate: 0.00011298, Avg batch loss: 0.0451, Avg batch acc: 0.9548
Train, Epoch: 5, Batch: 45, Step num: 6121, Learning rate: 0.00011298, Avg batch loss: 0.0466, Avg batch acc: 0.9508
Train, Epoch: 5, Batch: 46, Step num: 6122, Learning rate: 0.00011297, Avg batch loss: 0.0518, Avg batch acc: 0.9471
Train, Epoch: 5, Batch: 47, Step num: 6123, Learning rate: 0.00011296, Avg batch loss: 0.0634, Avg batch acc: 0.9451
Train, Epoch: 5, Batch: 48, Step num: 6124, Learning rate: 0.00011295, Avg batch loss: 0.0455, Avg batch acc: 0.9514
Train, Epoch: 5, Batch: 49, Step num: 6125, Learning rate: 0.00011294, Avg batch loss: 0.0500, Avg batch acc: 0.9517
Train, Epoch: 5, Batch: 50, Step num: 6126, Learning rate: 0.00011293, Avg batch loss: 0.0522, Avg batch acc: 0.9486
Train, Epoch: 5, Batch: 51, Step num: 6127, Learning rate: 0.00011292, Avg batch loss: 0.0578, Avg batch acc: 0.9546
Train, Epoch: 5, Batch: 52, Step num: 6128, Learning rate: 0.00011291, Avg batch loss: 0.0453, Avg batch acc: 0.9493
Train, Epoch: 5, Batch: 53, Step num: 6129, Learning rate: 0.00011290, Avg batch loss: 0.0650, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 54, Step num: 6130, Learning rate: 0.00011289, Avg batch loss: 0.0444, Avg batch acc: 0.9567
Train, Epoch: 5, Batch: 55, Step num: 6131, Learning rate: 0.00011288, Avg batch loss: 0.0415, Avg batch acc: 0.9553
Train, Epoch: 5, Batch: 56, Step num: 6132, Learning rate: 0.00011287, Avg batch loss: 0.0552, Avg batch acc: 0.9497
Train, Epoch: 5, Batch: 57, Step num: 6133, Learning rate: 0.00011286, Avg batch loss: 0.0543, Avg batch acc: 0.9472
Train, Epoch: 5, Batch: 58, Step num: 6134, Learning rate: 0.00011286, Avg batch loss: 0.0505, Avg batch acc: 0.9506
Train, Epoch: 5, Batch: 59, Step num: 6135, Learning rate: 0.00011285, Avg batch loss: 0.0427, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 60, Step num: 6136, Learning rate: 0.00011284, Avg batch loss: 0.0380, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 61, Step num: 6137, Learning rate: 0.00011283, Avg batch loss: 0.0468, Avg batch acc: 0.9516
Train, Epoch: 5, Batch: 62, Step num: 6138, Learning rate: 0.00011282, Avg batch loss: 0.0490, Avg batch acc: 0.9464
Train, Epoch: 5, Batch: 63, Step num: 6139, Learning rate: 0.00011281, Avg batch loss: 0.0523, Avg batch acc: 0.9545
Train, Epoch: 5, Batch: 64, Step num: 6140, Learning rate: 0.00011280, Avg batch loss: 0.0390, Avg batch acc: 0.9560
Train, Epoch: 5, Batch: 65, Step num: 6141, Learning rate: 0.00011279, Avg batch loss: 0.0393, Avg batch acc: 0.9622
Train, Epoch: 5, Batch: 66, Step num: 6142, Learning rate: 0.00011278, Avg batch loss: 0.0454, Avg batch acc: 0.9560
Train, Epoch: 5, Batch: 67, Step num: 6143, Learning rate: 0.00011277, Avg batch loss: 0.0580, Avg batch acc: 0.9533
Train, Epoch: 5, Batch: 68, Step num: 6144, Learning rate: 0.00011276, Avg batch loss: 0.0480, Avg batch acc: 0.9500
Train, Epoch: 5, Batch: 69, Step num: 6145, Learning rate: 0.00011275, Avg batch loss: 0.0778, Avg batch acc: 0.9375
Train, Epoch: 5, Batch: 70, Step num: 6146, Learning rate: 0.00011275, Avg batch loss: 0.0485, Avg batch acc: 0.9506
Train, Epoch: 5, Batch: 71, Step num: 6147, Learning rate: 0.00011274, Avg batch loss: 0.0472, Avg batch acc: 0.9514
Train, Epoch: 5, Batch: 72, Step num: 6148, Learning rate: 0.00011273, Avg batch loss: 0.0530, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 73, Step num: 6149, Learning rate: 0.00011272, Avg batch loss: 0.0451, Avg batch acc: 0.9556
Train, Epoch: 5, Batch: 74, Step num: 6150, Learning rate: 0.00011271, Avg batch loss: 0.0462, Avg batch acc: 0.9544
Train, Epoch: 5, Batch: 75, Step num: 6151, Learning rate: 0.00011270, Avg batch loss: 0.0413, Avg batch acc: 0.9486
Train, Epoch: 5, Batch: 76, Step num: 6152, Learning rate: 0.00011269, Avg batch loss: 0.0433, Avg batch acc: 0.9519
Train, Epoch: 5, Batch: 77, Step num: 6153, Learning rate: 0.00011268, Avg batch loss: 0.0501, Avg batch acc: 0.9546
Train, Epoch: 5, Batch: 78, Step num: 6154, Learning rate: 0.00011267, Avg batch loss: 0.0479, Avg batch acc: 0.9504
Train, Epoch: 5, Batch: 79, Step num: 6155, Learning rate: 0.00011266, Avg batch loss: 0.0489, Avg batch acc: 0.9508
Train, Epoch: 5, Batch: 80, Step num: 6156, Learning rate: 0.00011265, Avg batch loss: 0.0407, Avg batch acc: 0.9603
Train, Epoch: 5, Batch: 81, Step num: 6157, Learning rate: 0.00011264, Avg batch loss: 0.0478, Avg batch acc: 0.9551
Train, Epoch: 5, Batch: 82, Step num: 6158, Learning rate: 0.00011264, Avg batch loss: 0.0533, Avg batch acc: 0.9504
Train, Epoch: 5, Batch: 83, Step num: 6159, Learning rate: 0.00011263, Avg batch loss: 0.0546, Avg batch acc: 0.9495
Train, Epoch: 5, Batch: 84, Step num: 6160, Learning rate: 0.00011262, Avg batch loss: 0.0465, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 85, Step num: 6161, Learning rate: 0.00011261, Avg batch loss: 0.0463, Avg batch acc: 0.9535
Train, Epoch: 5, Batch: 86, Step num: 6162, Learning rate: 0.00011260, Avg batch loss: 0.0469, Avg batch acc: 0.9524
Train, Epoch: 5, Batch: 87, Step num: 6163, Learning rate: 0.00011259, Avg batch loss: 0.0492, Avg batch acc: 0.9510
Train, Epoch: 5, Batch: 88, Step num: 6164, Learning rate: 0.00011258, Avg batch loss: 0.0562, Avg batch acc: 0.9422
Train, Epoch: 5, Batch: 89, Step num: 6165, Learning rate: 0.00011257, Avg batch loss: 0.0493, Avg batch acc: 0.9491
Train, Epoch: 5, Batch: 90, Step num: 6166, Learning rate: 0.00011256, Avg batch loss: 0.0474, Avg batch acc: 0.9515
Train, Epoch: 5, Batch: 91, Step num: 6167, Learning rate: 0.00011255, Avg batch loss: 0.0396, Avg batch acc: 0.9585
Train, Epoch: 5, Batch: 92, Step num: 6168, Learning rate: 0.00011254, Avg batch loss: 0.0532, Avg batch acc: 0.9466
Train, Epoch: 5, Batch: 93, Step num: 6169, Learning rate: 0.00011254, Avg batch loss: 0.0564, Avg batch acc: 0.9551
Train, Epoch: 5, Batch: 94, Step num: 6170, Learning rate: 0.00011253, Avg batch loss: 0.0492, Avg batch acc: 0.9512
Train, Epoch: 5, Batch: 95, Step num: 6171, Learning rate: 0.00011252, Avg batch loss: 0.0596, Avg batch acc: 0.9436
Train, Epoch: 5, Batch: 96, Step num: 6172, Learning rate: 0.00011251, Avg batch loss: 0.0440, Avg batch acc: 0.9593
Train, Epoch: 5, Batch: 97, Step num: 6173, Learning rate: 0.00011250, Avg batch loss: 0.0570, Avg batch acc: 0.9526
Train, Epoch: 5, Batch: 98, Step num: 6174, Learning rate: 0.00011249, Avg batch loss: 0.0578, Avg batch acc: 0.9425
Train, Epoch: 5, Batch: 99, Step num: 6175, Learning rate: 0.00011248, Avg batch loss: 0.0742, Avg batch acc: 0.9339
Train, Epoch: 5, Batch: 100, Step num: 6176, Learning rate: 0.00011247, Avg batch loss: 0.0508, Avg batch acc: 0.9529
Train, Epoch: 5, Batch: 101, Step num: 6177, Learning rate: 0.00011246, Avg batch loss: 0.0493, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 102, Step num: 6178, Learning rate: 0.00011245, Avg batch loss: 0.0471, Avg batch acc: 0.9552
Train, Epoch: 5, Batch: 103, Step num: 6179, Learning rate: 0.00011244, Avg batch loss: 0.0441, Avg batch acc: 0.9540
Train, Epoch: 5, Batch: 104, Step num: 6180, Learning rate: 0.00011243, Avg batch loss: 0.0495, Avg batch acc: 0.9551
Train, Epoch: 5, Batch: 105, Step num: 6181, Learning rate: 0.00011243, Avg batch loss: 0.0551, Avg batch acc: 0.9484
Train, Epoch: 5, Batch: 106, Step num: 6182, Learning rate: 0.00011242, Avg batch loss: 0.0384, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 107, Step num: 6183, Learning rate: 0.00011241, Avg batch loss: 0.0725, Avg batch acc: 0.9476
Train, Epoch: 5, Batch: 108, Step num: 6184, Learning rate: 0.00011240, Avg batch loss: 0.0535, Avg batch acc: 0.9486
Train, Epoch: 5, Batch: 109, Step num: 6185, Learning rate: 0.00011239, Avg batch loss: 0.0515, Avg batch acc: 0.9503
Train, Epoch: 5, Batch: 110, Step num: 6186, Learning rate: 0.00011238, Avg batch loss: 0.0741, Avg batch acc: 0.9437
Train, Epoch: 5, Batch: 111, Step num: 6187, Learning rate: 0.00011237, Avg batch loss: 0.0467, Avg batch acc: 0.9501
Train, Epoch: 5, Batch: 112, Step num: 6188, Learning rate: 0.00011236, Avg batch loss: 0.0535, Avg batch acc: 0.9521
Train, Epoch: 5, Batch: 113, Step num: 6189, Learning rate: 0.00011235, Avg batch loss: 0.0437, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 114, Step num: 6190, Learning rate: 0.00011234, Avg batch loss: 0.0467, Avg batch acc: 0.9522
Train, Epoch: 5, Batch: 115, Step num: 6191, Learning rate: 0.00011233, Avg batch loss: 0.0493, Avg batch acc: 0.9500
Train, Epoch: 5, Batch: 116, Step num: 6192, Learning rate: 0.00011233, Avg batch loss: 0.0594, Avg batch acc: 0.9476
Train, Epoch: 5, Batch: 117, Step num: 6193, Learning rate: 0.00011232, Avg batch loss: 0.0426, Avg batch acc: 0.9569
Train, Epoch: 5, Batch: 118, Step num: 6194, Learning rate: 0.00011231, Avg batch loss: 0.0435, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 119, Step num: 6195, Learning rate: 0.00011230, Avg batch loss: 0.0658, Avg batch acc: 0.9414
Train, Epoch: 5, Batch: 120, Step num: 6196, Learning rate: 0.00011229, Avg batch loss: 0.0511, Avg batch acc: 0.9478
Train, Epoch: 5, Batch: 121, Step num: 6197, Learning rate: 0.00011228, Avg batch loss: 0.0469, Avg batch acc: 0.9502
Train, Epoch: 5, Batch: 122, Step num: 6198, Learning rate: 0.00011227, Avg batch loss: 0.0451, Avg batch acc: 0.9550
Train, Epoch: 5, Batch: 123, Step num: 6199, Learning rate: 0.00011226, Avg batch loss: 0.0460, Avg batch acc: 0.9524
Train, Epoch: 5, Batch: 124, Step num: 6200, Learning rate: 0.00011225, Avg batch loss: 0.0542, Avg batch acc: 0.9486
Train, Epoch: 5, Batch: 125, Step num: 6201, Learning rate: 0.00011224, Avg batch loss: 0.0507, Avg batch acc: 0.9559
Train, Epoch: 5, Batch: 126, Step num: 6202, Learning rate: 0.00011224, Avg batch loss: 0.0553, Avg batch acc: 0.9430
Train, Epoch: 5, Batch: 127, Step num: 6203, Learning rate: 0.00011223, Avg batch loss: 0.0411, Avg batch acc: 0.9620
Train, Epoch: 5, Batch: 128, Step num: 6204, Learning rate: 0.00011222, Avg batch loss: 0.0436, Avg batch acc: 0.9548
Train, Epoch: 5, Batch: 129, Step num: 6205, Learning rate: 0.00011221, Avg batch loss: 0.0620, Avg batch acc: 0.9474
Train, Epoch: 5, Batch: 130, Step num: 6206, Learning rate: 0.00011220, Avg batch loss: 0.0514, Avg batch acc: 0.9592
Train, Epoch: 5, Batch: 131, Step num: 6207, Learning rate: 0.00011219, Avg batch loss: 0.0496, Avg batch acc: 0.9523
Train, Epoch: 5, Batch: 132, Step num: 6208, Learning rate: 0.00011218, Avg batch loss: 0.0442, Avg batch acc: 0.9538
Train, Epoch: 5, Batch: 133, Step num: 6209, Learning rate: 0.00011217, Avg batch loss: 0.0384, Avg batch acc: 0.9618
Train, Epoch: 5, Batch: 134, Step num: 6210, Learning rate: 0.00011216, Avg batch loss: 0.0592, Avg batch acc: 0.9397
Train, Epoch: 5, Batch: 135, Step num: 6211, Learning rate: 0.00011215, Avg batch loss: 0.0477, Avg batch acc: 0.9518
Train, Epoch: 5, Batch: 136, Step num: 6212, Learning rate: 0.00011214, Avg batch loss: 0.0418, Avg batch acc: 0.9550
Train, Epoch: 5, Batch: 137, Step num: 6213, Learning rate: 0.00011214, Avg batch loss: 0.0467, Avg batch acc: 0.9531
Train, Epoch: 5, Batch: 138, Step num: 6214, Learning rate: 0.00011213, Avg batch loss: 0.0457, Avg batch acc: 0.9579
Train, Epoch: 5, Batch: 139, Step num: 6215, Learning rate: 0.00011212, Avg batch loss: 0.0515, Avg batch acc: 0.9474
Train, Epoch: 5, Batch: 140, Step num: 6216, Learning rate: 0.00011211, Avg batch loss: 0.0622, Avg batch acc: 0.9422
Train, Epoch: 5, Batch: 141, Step num: 6217, Learning rate: 0.00011210, Avg batch loss: 0.0434, Avg batch acc: 0.9478
Train, Epoch: 5, Batch: 142, Step num: 6218, Learning rate: 0.00011209, Avg batch loss: 0.0540, Avg batch acc: 0.9524
Train, Epoch: 5, Batch: 143, Step num: 6219, Learning rate: 0.00011208, Avg batch loss: 0.0460, Avg batch acc: 0.9466
Train, Epoch: 5, Batch: 144, Step num: 6220, Learning rate: 0.00011207, Avg batch loss: 0.0480, Avg batch acc: 0.9530
Train, Epoch: 5, Batch: 145, Step num: 6221, Learning rate: 0.00011206, Avg batch loss: 0.0428, Avg batch acc: 0.9508
Train, Epoch: 5, Batch: 146, Step num: 6222, Learning rate: 0.00011205, Avg batch loss: 0.0461, Avg batch acc: 0.9506
Train, Epoch: 5, Batch: 147, Step num: 6223, Learning rate: 0.00011205, Avg batch loss: 0.0538, Avg batch acc: 0.9448
Train, Epoch: 5, Batch: 148, Step num: 6224, Learning rate: 0.00011204, Avg batch loss: 0.0505, Avg batch acc: 0.9492
Train, Epoch: 5, Batch: 149, Step num: 6225, Learning rate: 0.00011203, Avg batch loss: 0.0433, Avg batch acc: 0.9642
Train, Epoch: 5, Batch: 150, Step num: 6226, Learning rate: 0.00011202, Avg batch loss: 0.0450, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 151, Step num: 6227, Learning rate: 0.00011201, Avg batch loss: 0.0415, Avg batch acc: 0.9603
Train, Epoch: 5, Batch: 152, Step num: 6228, Learning rate: 0.00011200, Avg batch loss: 0.0531, Avg batch acc: 0.9531
Train, Epoch: 5, Batch: 153, Step num: 6229, Learning rate: 0.00011199, Avg batch loss: 0.0436, Avg batch acc: 0.9501
Train, Epoch: 5, Batch: 154, Step num: 6230, Learning rate: 0.00011198, Avg batch loss: 0.0481, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 155, Step num: 6231, Learning rate: 0.00011197, Avg batch loss: 0.0392, Avg batch acc: 0.9666
Train, Epoch: 5, Batch: 156, Step num: 6232, Learning rate: 0.00011196, Avg batch loss: 0.0402, Avg batch acc: 0.9528
Train, Epoch: 5, Batch: 157, Step num: 6233, Learning rate: 0.00011196, Avg batch loss: 0.0488, Avg batch acc: 0.9546
Train, Epoch: 5, Batch: 158, Step num: 6234, Learning rate: 0.00011195, Avg batch loss: 0.0514, Avg batch acc: 0.9491
Train, Epoch: 5, Batch: 159, Step num: 6235, Learning rate: 0.00011194, Avg batch loss: 0.0409, Avg batch acc: 0.9569
Train, Epoch: 5, Batch: 160, Step num: 6236, Learning rate: 0.00011193, Avg batch loss: 0.0407, Avg batch acc: 0.9581
Train, Epoch: 5, Batch: 161, Step num: 6237, Learning rate: 0.00011192, Avg batch loss: 0.0366, Avg batch acc: 0.9609
Train, Epoch: 5, Batch: 162, Step num: 6238, Learning rate: 0.00011191, Avg batch loss: 0.0482, Avg batch acc: 0.9500
Train, Epoch: 5, Batch: 163, Step num: 6239, Learning rate: 0.00011190, Avg batch loss: 0.0549, Avg batch acc: 0.9448
Train, Epoch: 5, Batch: 164, Step num: 6240, Learning rate: 0.00011189, Avg batch loss: 0.0715, Avg batch acc: 0.9463
Train, Epoch: 5, Batch: 165, Step num: 6241, Learning rate: 0.00011188, Avg batch loss: 0.0475, Avg batch acc: 0.9500
Train, Epoch: 5, Batch: 166, Step num: 6242, Learning rate: 0.00011188, Avg batch loss: 0.0439, Avg batch acc: 0.9596
Train, Epoch: 5, Batch: 167, Step num: 6243, Learning rate: 0.00011187, Avg batch loss: 0.0472, Avg batch acc: 0.9514
Train, Epoch: 5, Batch: 168, Step num: 6244, Learning rate: 0.00011186, Avg batch loss: 0.0426, Avg batch acc: 0.9604
Train, Epoch: 5, Batch: 169, Step num: 6245, Learning rate: 0.00011185, Avg batch loss: 0.0450, Avg batch acc: 0.9543
Train, Epoch: 5, Batch: 170, Step num: 6246, Learning rate: 0.00011184, Avg batch loss: 0.0435, Avg batch acc: 0.9565
Train, Epoch: 5, Batch: 171, Step num: 6247, Learning rate: 0.00011183, Avg batch loss: 0.0480, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 172, Step num: 6248, Learning rate: 0.00011182, Avg batch loss: 0.0518, Avg batch acc: 0.9559
Train, Epoch: 5, Batch: 173, Step num: 6249, Learning rate: 0.00011181, Avg batch loss: 0.0441, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 174, Step num: 6250, Learning rate: 0.00011180, Avg batch loss: 0.0460, Avg batch acc: 0.9575
Train, Epoch: 5, Batch: 175, Step num: 6251, Learning rate: 0.00011179, Avg batch loss: 0.0582, Avg batch acc: 0.9467
Train, Epoch: 5, Batch: 176, Step num: 6252, Learning rate: 0.00011179, Avg batch loss: 0.0432, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 177, Step num: 6253, Learning rate: 0.00011178, Avg batch loss: 0.0566, Avg batch acc: 0.9531
Train, Epoch: 5, Batch: 178, Step num: 6254, Learning rate: 0.00011177, Avg batch loss: 0.0390, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 179, Step num: 6255, Learning rate: 0.00011176, Avg batch loss: 0.0429, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 180, Step num: 6256, Learning rate: 0.00011175, Avg batch loss: 0.0687, Avg batch acc: 0.9505
Train, Epoch: 5, Batch: 181, Step num: 6257, Learning rate: 0.00011174, Avg batch loss: 0.0482, Avg batch acc: 0.9507
Train, Epoch: 5, Batch: 182, Step num: 6258, Learning rate: 0.00011173, Avg batch loss: 0.0496, Avg batch acc: 0.9495
Train, Epoch: 5, Batch: 183, Step num: 6259, Learning rate: 0.00011172, Avg batch loss: 0.0467, Avg batch acc: 0.9538
Train, Epoch: 5, Batch: 184, Step num: 6260, Learning rate: 0.00011171, Avg batch loss: 0.0426, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 185, Step num: 6261, Learning rate: 0.00011171, Avg batch loss: 0.0488, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 186, Step num: 6262, Learning rate: 0.00011170, Avg batch loss: 0.0463, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 187, Step num: 6263, Learning rate: 0.00011169, Avg batch loss: 0.0999, Avg batch acc: 0.9287
Train, Epoch: 5, Batch: 188, Step num: 6264, Learning rate: 0.00011168, Avg batch loss: 0.0571, Avg batch acc: 0.9499
Train, Epoch: 5, Batch: 189, Step num: 6265, Learning rate: 0.00011167, Avg batch loss: 0.0413, Avg batch acc: 0.9561
Train, Epoch: 5, Batch: 190, Step num: 6266, Learning rate: 0.00011166, Avg batch loss: 0.0545, Avg batch acc: 0.9486
Train, Epoch: 5, Batch: 191, Step num: 6267, Learning rate: 0.00011165, Avg batch loss: 0.0529, Avg batch acc: 0.9495
Train, Epoch: 5, Batch: 192, Step num: 6268, Learning rate: 0.00011164, Avg batch loss: 0.0446, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 193, Step num: 6269, Learning rate: 0.00011163, Avg batch loss: 0.0469, Avg batch acc: 0.9537
Train, Epoch: 5, Batch: 194, Step num: 6270, Learning rate: 0.00011162, Avg batch loss: 0.0314, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 195, Step num: 6271, Learning rate: 0.00011162, Avg batch loss: 0.0403, Avg batch acc: 0.9473
Train, Epoch: 5, Batch: 196, Step num: 6272, Learning rate: 0.00011161, Avg batch loss: 0.0590, Avg batch acc: 0.9483
Train, Epoch: 5, Batch: 197, Step num: 6273, Learning rate: 0.00011160, Avg batch loss: 0.0618, Avg batch acc: 0.9470
Train, Epoch: 5, Batch: 198, Step num: 6274, Learning rate: 0.00011159, Avg batch loss: 0.0526, Avg batch acc: 0.9501
Train, Epoch: 5, Batch: 199, Step num: 6275, Learning rate: 0.00011158, Avg batch loss: 0.0543, Avg batch acc: 0.9402
Train, Epoch: 5, Batch: 200, Step num: 6276, Learning rate: 0.00011157, Avg batch loss: 0.0541, Avg batch acc: 0.9492
Train, Epoch: 5, Batch: 201, Step num: 6277, Learning rate: 0.00011156, Avg batch loss: 0.0527, Avg batch acc: 0.9516
Train, Epoch: 5, Batch: 202, Step num: 6278, Learning rate: 0.00011155, Avg batch loss: 0.0427, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 203, Step num: 6279, Learning rate: 0.00011154, Avg batch loss: 0.0452, Avg batch acc: 0.9540
Train, Epoch: 5, Batch: 204, Step num: 6280, Learning rate: 0.00011154, Avg batch loss: 0.0523, Avg batch acc: 0.9491
Train, Epoch: 5, Batch: 205, Step num: 6281, Learning rate: 0.00011153, Avg batch loss: 0.0700, Avg batch acc: 0.9479
Train, Epoch: 5, Batch: 206, Step num: 6282, Learning rate: 0.00011152, Avg batch loss: 0.0362, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 207, Step num: 6283, Learning rate: 0.00011151, Avg batch loss: 0.0458, Avg batch acc: 0.9579
Train, Epoch: 5, Batch: 208, Step num: 6284, Learning rate: 0.00011150, Avg batch loss: 0.0517, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 209, Step num: 6285, Learning rate: 0.00011149, Avg batch loss: 0.0533, Avg batch acc: 0.9563
Train, Epoch: 5, Batch: 210, Step num: 6286, Learning rate: 0.00011148, Avg batch loss: 0.0488, Avg batch acc: 0.9521
Train, Epoch: 5, Batch: 211, Step num: 6287, Learning rate: 0.00011147, Avg batch loss: 0.0413, Avg batch acc: 0.9539
Train, Epoch: 5, Batch: 212, Step num: 6288, Learning rate: 0.00011147, Avg batch loss: 0.0429, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 213, Step num: 6289, Learning rate: 0.00011146, Avg batch loss: 0.0469, Avg batch acc: 0.9530
Train, Epoch: 5, Batch: 214, Step num: 6290, Learning rate: 0.00011145, Avg batch loss: 0.0488, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 215, Step num: 6291, Learning rate: 0.00011144, Avg batch loss: 0.0455, Avg batch acc: 0.9564
Train, Epoch: 5, Batch: 216, Step num: 6292, Learning rate: 0.00011143, Avg batch loss: 0.0520, Avg batch acc: 0.9482
Train, Epoch: 5, Batch: 217, Step num: 6293, Learning rate: 0.00011142, Avg batch loss: 0.0504, Avg batch acc: 0.9473
Train, Epoch: 5, Batch: 218, Step num: 6294, Learning rate: 0.00011141, Avg batch loss: 0.0497, Avg batch acc: 0.9552
Train, Epoch: 5, Batch: 219, Step num: 6295, Learning rate: 0.00011140, Avg batch loss: 0.0484, Avg batch acc: 0.9543
Train, Epoch: 5, Batch: 220, Step num: 6296, Learning rate: 0.00011139, Avg batch loss: 0.0378, Avg batch acc: 0.9608
Train, Epoch: 5, Batch: 221, Step num: 6297, Learning rate: 0.00011139, Avg batch loss: 0.0426, Avg batch acc: 0.9535
Train, Epoch: 5, Batch: 222, Step num: 6298, Learning rate: 0.00011138, Avg batch loss: 0.0420, Avg batch acc: 0.9513
Train, Epoch: 5, Batch: 223, Step num: 6299, Learning rate: 0.00011137, Avg batch loss: 0.0459, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 224, Step num: 6300, Learning rate: 0.00011136, Avg batch loss: 0.0457, Avg batch acc: 0.9567
Train, Epoch: 5, Batch: 225, Step num: 6301, Learning rate: 0.00011135, Avg batch loss: 0.0390, Avg batch acc: 0.9618
Train, Epoch: 5, Batch: 226, Step num: 6302, Learning rate: 0.00011134, Avg batch loss: 0.0436, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 227, Step num: 6303, Learning rate: 0.00011133, Avg batch loss: 0.0541, Avg batch acc: 0.9459
Train, Epoch: 5, Batch: 228, Step num: 6304, Learning rate: 0.00011132, Avg batch loss: 0.0411, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 229, Step num: 6305, Learning rate: 0.00011131, Avg batch loss: 0.0381, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 230, Step num: 6306, Learning rate: 0.00011131, Avg batch loss: 0.0410, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 231, Step num: 6307, Learning rate: 0.00011130, Avg batch loss: 0.0475, Avg batch acc: 0.9535
Train, Epoch: 5, Batch: 232, Step num: 6308, Learning rate: 0.00011129, Avg batch loss: 0.0597, Avg batch acc: 0.9481
Train, Epoch: 5, Batch: 233, Step num: 6309, Learning rate: 0.00011128, Avg batch loss: 0.0449, Avg batch acc: 0.9528
Train, Epoch: 5, Batch: 234, Step num: 6310, Learning rate: 0.00011127, Avg batch loss: 0.0556, Avg batch acc: 0.9459
Train, Epoch: 5, Batch: 235, Step num: 6311, Learning rate: 0.00011126, Avg batch loss: 0.0467, Avg batch acc: 0.9574
Train, Epoch: 5, Batch: 236, Step num: 6312, Learning rate: 0.00011125, Avg batch loss: 0.0364, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 237, Step num: 6313, Learning rate: 0.00011124, Avg batch loss: 0.0433, Avg batch acc: 0.9515
Train, Epoch: 5, Batch: 238, Step num: 6314, Learning rate: 0.00011124, Avg batch loss: 0.0740, Avg batch acc: 0.9519
Train, Epoch: 5, Batch: 239, Step num: 6315, Learning rate: 0.00011123, Avg batch loss: 0.0368, Avg batch acc: 0.9584
Train, Epoch: 5, Batch: 240, Step num: 6316, Learning rate: 0.00011122, Avg batch loss: 0.0450, Avg batch acc: 0.9518
Train, Epoch: 5, Batch: 241, Step num: 6317, Learning rate: 0.00011121, Avg batch loss: 0.0502, Avg batch acc: 0.9519
Train, Epoch: 5, Batch: 242, Step num: 6318, Learning rate: 0.00011120, Avg batch loss: 0.0394, Avg batch acc: 0.9529
Train, Epoch: 5, Batch: 243, Step num: 6319, Learning rate: 0.00011119, Avg batch loss: 0.0442, Avg batch acc: 0.9629
Train, Epoch: 5, Batch: 244, Step num: 6320, Learning rate: 0.00011118, Avg batch loss: 0.0447, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 245, Step num: 6321, Learning rate: 0.00011117, Avg batch loss: 0.0441, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 246, Step num: 6322, Learning rate: 0.00011116, Avg batch loss: 0.0483, Avg batch acc: 0.9555
Train, Epoch: 5, Batch: 247, Step num: 6323, Learning rate: 0.00011116, Avg batch loss: 0.0452, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 248, Step num: 6324, Learning rate: 0.00011115, Avg batch loss: 0.0462, Avg batch acc: 0.9615
Train, Epoch: 5, Batch: 249, Step num: 6325, Learning rate: 0.00011114, Avg batch loss: 0.0446, Avg batch acc: 0.9569
Train, Epoch: 5, Batch: 250, Step num: 6326, Learning rate: 0.00011113, Avg batch loss: 0.0443, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 251, Step num: 6327, Learning rate: 0.00011112, Avg batch loss: 0.0468, Avg batch acc: 0.9551
Train, Epoch: 5, Batch: 252, Step num: 6328, Learning rate: 0.00011111, Avg batch loss: 0.0409, Avg batch acc: 0.9541
Train, Epoch: 5, Batch: 253, Step num: 6329, Learning rate: 0.00011110, Avg batch loss: 0.0499, Avg batch acc: 0.9534
Train, Epoch: 5, Batch: 254, Step num: 6330, Learning rate: 0.00011109, Avg batch loss: 0.0461, Avg batch acc: 0.9516
Train, Epoch: 5, Batch: 255, Step num: 6331, Learning rate: 0.00011109, Avg batch loss: 0.0409, Avg batch acc: 0.9534
Train, Epoch: 5, Batch: 256, Step num: 6332, Learning rate: 0.00011108, Avg batch loss: 0.0461, Avg batch acc: 0.9526
Train, Epoch: 5, Batch: 257, Step num: 6333, Learning rate: 0.00011107, Avg batch loss: 0.0440, Avg batch acc: 0.9551
Train, Epoch: 5, Batch: 258, Step num: 6334, Learning rate: 0.00011106, Avg batch loss: 0.0486, Avg batch acc: 0.9594
Train, Epoch: 5, Batch: 259, Step num: 6335, Learning rate: 0.00011105, Avg batch loss: 0.0416, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 260, Step num: 6336, Learning rate: 0.00011104, Avg batch loss: 0.0578, Avg batch acc: 0.9481
Train, Epoch: 5, Batch: 261, Step num: 6337, Learning rate: 0.00011103, Avg batch loss: 0.0413, Avg batch acc: 0.9607
Train, Epoch: 5, Batch: 262, Step num: 6338, Learning rate: 0.00011102, Avg batch loss: 0.0458, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 263, Step num: 6339, Learning rate: 0.00011102, Avg batch loss: 0.0506, Avg batch acc: 0.9519
Train, Epoch: 5, Batch: 264, Step num: 6340, Learning rate: 0.00011101, Avg batch loss: 0.0521, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 265, Step num: 6341, Learning rate: 0.00011100, Avg batch loss: 0.0452, Avg batch acc: 0.9539
Train, Epoch: 5, Batch: 266, Step num: 6342, Learning rate: 0.00011099, Avg batch loss: 0.0435, Avg batch acc: 0.9522
Train, Epoch: 5, Batch: 267, Step num: 6343, Learning rate: 0.00011098, Avg batch loss: 0.0476, Avg batch acc: 0.9565
Train, Epoch: 5, Batch: 268, Step num: 6344, Learning rate: 0.00011097, Avg batch loss: 0.0508, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 269, Step num: 6345, Learning rate: 0.00011096, Avg batch loss: 0.0452, Avg batch acc: 0.9537
Train, Epoch: 5, Batch: 270, Step num: 6346, Learning rate: 0.00011095, Avg batch loss: 0.0441, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 271, Step num: 6347, Learning rate: 0.00011095, Avg batch loss: 0.0406, Avg batch acc: 0.9607
Train, Epoch: 5, Batch: 272, Step num: 6348, Learning rate: 0.00011094, Avg batch loss: 0.0480, Avg batch acc: 0.9534
Train, Epoch: 5, Batch: 273, Step num: 6349, Learning rate: 0.00011093, Avg batch loss: 0.0464, Avg batch acc: 0.9547
Train, Epoch: 5, Batch: 274, Step num: 6350, Learning rate: 0.00011092, Avg batch loss: 0.0605, Avg batch acc: 0.9434
Train, Epoch: 5, Batch: 275, Step num: 6351, Learning rate: 0.00011091, Avg batch loss: 0.0440, Avg batch acc: 0.9577
Train, Epoch: 5, Batch: 276, Step num: 6352, Learning rate: 0.00011090, Avg batch loss: 0.0436, Avg batch acc: 0.9596
Train, Epoch: 5, Batch: 277, Step num: 6353, Learning rate: 0.00011089, Avg batch loss: 0.0494, Avg batch acc: 0.9529
Train, Epoch: 5, Batch: 278, Step num: 6354, Learning rate: 0.00011088, Avg batch loss: 0.0426, Avg batch acc: 0.9584
Train, Epoch: 5, Batch: 279, Step num: 6355, Learning rate: 0.00011088, Avg batch loss: 0.0483, Avg batch acc: 0.9481
Train, Epoch: 5, Batch: 280, Step num: 6356, Learning rate: 0.00011087, Avg batch loss: 0.0458, Avg batch acc: 0.9491
Train, Epoch: 5, Batch: 281, Step num: 6357, Learning rate: 0.00011086, Avg batch loss: 0.0601, Avg batch acc: 0.9478
Train, Epoch: 5, Batch: 282, Step num: 6358, Learning rate: 0.00011085, Avg batch loss: 0.0459, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 283, Step num: 6359, Learning rate: 0.00011084, Avg batch loss: 0.0476, Avg batch acc: 0.9489
Train, Epoch: 5, Batch: 284, Step num: 6360, Learning rate: 0.00011083, Avg batch loss: 0.0382, Avg batch acc: 0.9651
Train, Epoch: 5, Batch: 285, Step num: 6361, Learning rate: 0.00011082, Avg batch loss: 0.0441, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 286, Step num: 6362, Learning rate: 0.00011081, Avg batch loss: 0.0542, Avg batch acc: 0.9543
Train, Epoch: 5, Batch: 287, Step num: 6363, Learning rate: 0.00011081, Avg batch loss: 0.0512, Avg batch acc: 0.9501
Train, Epoch: 5, Batch: 288, Step num: 6364, Learning rate: 0.00011080, Avg batch loss: 0.0422, Avg batch acc: 0.9552
Train, Epoch: 5, Batch: 289, Step num: 6365, Learning rate: 0.00011079, Avg batch loss: 0.0541, Avg batch acc: 0.9604
Train, Epoch: 5, Batch: 290, Step num: 6366, Learning rate: 0.00011078, Avg batch loss: 0.0392, Avg batch acc: 0.9594
Train, Epoch: 5, Batch: 291, Step num: 6367, Learning rate: 0.00011077, Avg batch loss: 0.0431, Avg batch acc: 0.9599
Train, Epoch: 5, Batch: 292, Step num: 6368, Learning rate: 0.00011076, Avg batch loss: 0.0470, Avg batch acc: 0.9572
Train, Epoch: 5, Batch: 293, Step num: 6369, Learning rate: 0.00011075, Avg batch loss: 0.0462, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 294, Step num: 6370, Learning rate: 0.00011075, Avg batch loss: 0.0499, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 295, Step num: 6371, Learning rate: 0.00011074, Avg batch loss: 0.0486, Avg batch acc: 0.9473
Train, Epoch: 5, Batch: 296, Step num: 6372, Learning rate: 0.00011073, Avg batch loss: 0.0566, Avg batch acc: 0.9565
Train, Epoch: 5, Batch: 297, Step num: 6373, Learning rate: 0.00011072, Avg batch loss: 0.0599, Avg batch acc: 0.9651
Train, Epoch: 5, Batch: 298, Step num: 6374, Learning rate: 0.00011071, Avg batch loss: 0.0450, Avg batch acc: 0.9525
Train, Epoch: 5, Batch: 299, Step num: 6375, Learning rate: 0.00011070, Avg batch loss: 0.0381, Avg batch acc: 0.9653
Train, Epoch: 5, Batch: 300, Step num: 6376, Learning rate: 0.00011069, Avg batch loss: 0.0417, Avg batch acc: 0.9585
Train, Epoch: 5, Batch: 301, Step num: 6377, Learning rate: 0.00011068, Avg batch loss: 0.0416, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 302, Step num: 6378, Learning rate: 0.00011068, Avg batch loss: 0.0639, Avg batch acc: 0.9464
Train, Epoch: 5, Batch: 303, Step num: 6379, Learning rate: 0.00011067, Avg batch loss: 0.0454, Avg batch acc: 0.9494
Train, Epoch: 5, Batch: 304, Step num: 6380, Learning rate: 0.00011066, Avg batch loss: 0.0464, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 305, Step num: 6381, Learning rate: 0.00011065, Avg batch loss: 0.0439, Avg batch acc: 0.9504
Train, Epoch: 5, Batch: 306, Step num: 6382, Learning rate: 0.00011064, Avg batch loss: 0.0597, Avg batch acc: 0.9504
Train, Epoch: 5, Batch: 307, Step num: 6383, Learning rate: 0.00011063, Avg batch loss: 0.0540, Avg batch acc: 0.9480
Train, Epoch: 5, Batch: 308, Step num: 6384, Learning rate: 0.00011062, Avg batch loss: 0.0563, Avg batch acc: 0.9475
Train, Epoch: 5, Batch: 309, Step num: 6385, Learning rate: 0.00011062, Avg batch loss: 0.0496, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 310, Step num: 6386, Learning rate: 0.00011061, Avg batch loss: 0.0598, Avg batch acc: 0.9463
Train, Epoch: 5, Batch: 311, Step num: 6387, Learning rate: 0.00011060, Avg batch loss: 0.0513, Avg batch acc: 0.9487
Train, Epoch: 5, Batch: 312, Step num: 6388, Learning rate: 0.00011059, Avg batch loss: 0.0421, Avg batch acc: 0.9581
Train, Epoch: 5, Batch: 313, Step num: 6389, Learning rate: 0.00011058, Avg batch loss: 0.0635, Avg batch acc: 0.9443
Train, Epoch: 5, Batch: 314, Step num: 6390, Learning rate: 0.00011057, Avg batch loss: 0.0399, Avg batch acc: 0.9508
Train, Epoch: 5, Batch: 315, Step num: 6391, Learning rate: 0.00011056, Avg batch loss: 0.0388, Avg batch acc: 0.9582
Train, Epoch: 5, Batch: 316, Step num: 6392, Learning rate: 0.00011055, Avg batch loss: 0.0377, Avg batch acc: 0.9582
Train, Epoch: 5, Batch: 317, Step num: 6393, Learning rate: 0.00011055, Avg batch loss: 0.0419, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 318, Step num: 6394, Learning rate: 0.00011054, Avg batch loss: 0.0411, Avg batch acc: 0.9556
Train, Epoch: 5, Batch: 319, Step num: 6395, Learning rate: 0.00011053, Avg batch loss: 0.0479, Avg batch acc: 0.9531
Train, Epoch: 5, Batch: 320, Step num: 6396, Learning rate: 0.00011052, Avg batch loss: 0.0426, Avg batch acc: 0.9559
Train, Epoch: 5, Batch: 321, Step num: 6397, Learning rate: 0.00011051, Avg batch loss: 0.0431, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 322, Step num: 6398, Learning rate: 0.00011050, Avg batch loss: 0.0407, Avg batch acc: 0.9581
Train, Epoch: 5, Batch: 323, Step num: 6399, Learning rate: 0.00011049, Avg batch loss: 0.0407, Avg batch acc: 0.9580
Train, Epoch: 5, Batch: 324, Step num: 6400, Learning rate: 0.00011049, Avg batch loss: 0.0435, Avg batch acc: 0.9608
Train, Epoch: 5, Batch: 325, Step num: 6401, Learning rate: 0.00011048, Avg batch loss: 0.0507, Avg batch acc: 0.9574
Train, Epoch: 5, Batch: 326, Step num: 6402, Learning rate: 0.00011047, Avg batch loss: 0.0530, Avg batch acc: 0.9472
Train, Epoch: 5, Batch: 327, Step num: 6403, Learning rate: 0.00011046, Avg batch loss: 0.0422, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 328, Step num: 6404, Learning rate: 0.00011045, Avg batch loss: 0.0484, Avg batch acc: 0.9466
Train, Epoch: 5, Batch: 329, Step num: 6405, Learning rate: 0.00011044, Avg batch loss: 0.0423, Avg batch acc: 0.9603
Train, Epoch: 5, Batch: 330, Step num: 6406, Learning rate: 0.00011043, Avg batch loss: 0.0448, Avg batch acc: 0.9479
Train, Epoch: 5, Batch: 331, Step num: 6407, Learning rate: 0.00011043, Avg batch loss: 0.0354, Avg batch acc: 0.9623
Train, Epoch: 5, Batch: 332, Step num: 6408, Learning rate: 0.00011042, Avg batch loss: 0.0493, Avg batch acc: 0.9508
Train, Epoch: 5, Batch: 333, Step num: 6409, Learning rate: 0.00011041, Avg batch loss: 0.0495, Avg batch acc: 0.9539
Train, Epoch: 5, Batch: 334, Step num: 6410, Learning rate: 0.00011040, Avg batch loss: 0.0500, Avg batch acc: 0.9529
Train, Epoch: 5, Batch: 335, Step num: 6411, Learning rate: 0.00011039, Avg batch loss: 0.0634, Avg batch acc: 0.9506
Train, Epoch: 5, Batch: 336, Step num: 6412, Learning rate: 0.00011038, Avg batch loss: 0.0567, Avg batch acc: 0.9514
Train, Epoch: 5, Batch: 337, Step num: 6413, Learning rate: 0.00011037, Avg batch loss: 0.0551, Avg batch acc: 0.9458
Train, Epoch: 5, Batch: 338, Step num: 6414, Learning rate: 0.00011036, Avg batch loss: 0.0460, Avg batch acc: 0.9511
Train, Epoch: 5, Batch: 339, Step num: 6415, Learning rate: 0.00011036, Avg batch loss: 0.0526, Avg batch acc: 0.9553
Train, Epoch: 5, Batch: 340, Step num: 6416, Learning rate: 0.00011035, Avg batch loss: 0.0486, Avg batch acc: 0.9524
Train, Epoch: 5, Batch: 341, Step num: 6417, Learning rate: 0.00011034, Avg batch loss: 0.0462, Avg batch acc: 0.9508
Train, Epoch: 5, Batch: 342, Step num: 6418, Learning rate: 0.00011033, Avg batch loss: 0.0692, Avg batch acc: 0.9458
Train, Epoch: 5, Batch: 343, Step num: 6419, Learning rate: 0.00011032, Avg batch loss: 0.0408, Avg batch acc: 0.9609
Train, Epoch: 5, Batch: 344, Step num: 6420, Learning rate: 0.00011031, Avg batch loss: 0.0409, Avg batch acc: 0.9606
Train, Epoch: 5, Batch: 345, Step num: 6421, Learning rate: 0.00011030, Avg batch loss: 0.0429, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 346, Step num: 6422, Learning rate: 0.00011030, Avg batch loss: 0.0561, Avg batch acc: 0.9526
Train, Epoch: 5, Batch: 347, Step num: 6423, Learning rate: 0.00011029, Avg batch loss: 0.0435, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 348, Step num: 6424, Learning rate: 0.00011028, Avg batch loss: 0.0416, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 349, Step num: 6425, Learning rate: 0.00011027, Avg batch loss: 0.0405, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 350, Step num: 6426, Learning rate: 0.00011026, Avg batch loss: 0.0591, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 351, Step num: 6427, Learning rate: 0.00011025, Avg batch loss: 0.0418, Avg batch acc: 0.9506
Train, Epoch: 5, Batch: 352, Step num: 6428, Learning rate: 0.00011024, Avg batch loss: 0.0328, Avg batch acc: 0.9686
Train, Epoch: 5, Batch: 353, Step num: 6429, Learning rate: 0.00011024, Avg batch loss: 0.0418, Avg batch acc: 0.9584
Train, Epoch: 5, Batch: 354, Step num: 6430, Learning rate: 0.00011023, Avg batch loss: 0.0468, Avg batch acc: 0.9527
Train, Epoch: 5, Batch: 355, Step num: 6431, Learning rate: 0.00011022, Avg batch loss: 0.0414, Avg batch acc: 0.9528
Train, Epoch: 5, Batch: 356, Step num: 6432, Learning rate: 0.00011021, Avg batch loss: 0.0463, Avg batch acc: 0.9421
Train, Epoch: 5, Batch: 357, Step num: 6433, Learning rate: 0.00011020, Avg batch loss: 0.0439, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 358, Step num: 6434, Learning rate: 0.00011019, Avg batch loss: 0.0419, Avg batch acc: 0.9519
Train, Epoch: 5, Batch: 359, Step num: 6435, Learning rate: 0.00011018, Avg batch loss: 0.0379, Avg batch acc: 0.9649
Train, Epoch: 5, Batch: 360, Step num: 6436, Learning rate: 0.00011018, Avg batch loss: 0.0412, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 361, Step num: 6437, Learning rate: 0.00011017, Avg batch loss: 0.0407, Avg batch acc: 0.9571
Train, Epoch: 5, Batch: 362, Step num: 6438, Learning rate: 0.00011016, Avg batch loss: 0.0398, Avg batch acc: 0.9571
Train, Epoch: 5, Batch: 363, Step num: 6439, Learning rate: 0.00011015, Avg batch loss: 0.0464, Avg batch acc: 0.9523
Train, Epoch: 5, Batch: 364, Step num: 6440, Learning rate: 0.00011014, Avg batch loss: 0.0535, Avg batch acc: 0.9464
Train, Epoch: 5, Batch: 365, Step num: 6441, Learning rate: 0.00011013, Avg batch loss: 0.0493, Avg batch acc: 0.9481
Train, Epoch: 5, Batch: 366, Step num: 6442, Learning rate: 0.00011012, Avg batch loss: 0.0433, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 367, Step num: 6443, Learning rate: 0.00011012, Avg batch loss: 0.0428, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 368, Step num: 6444, Learning rate: 0.00011011, Avg batch loss: 0.0452, Avg batch acc: 0.9605
Train, Epoch: 5, Batch: 369, Step num: 6445, Learning rate: 0.00011010, Avg batch loss: 0.0469, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 370, Step num: 6446, Learning rate: 0.00011009, Avg batch loss: 0.0427, Avg batch acc: 0.9539
Train, Epoch: 5, Batch: 371, Step num: 6447, Learning rate: 0.00011008, Avg batch loss: 0.0580, Avg batch acc: 0.9500
Train, Epoch: 5, Batch: 372, Step num: 6448, Learning rate: 0.00011007, Avg batch loss: 0.0416, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 373, Step num: 6449, Learning rate: 0.00011006, Avg batch loss: 0.0365, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 374, Step num: 6450, Learning rate: 0.00011006, Avg batch loss: 0.0360, Avg batch acc: 0.9623
Train, Epoch: 5, Batch: 375, Step num: 6451, Learning rate: 0.00011005, Avg batch loss: 0.0460, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 376, Step num: 6452, Learning rate: 0.00011004, Avg batch loss: 0.0405, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 377, Step num: 6453, Learning rate: 0.00011003, Avg batch loss: 0.0465, Avg batch acc: 0.9545
Train, Epoch: 5, Batch: 378, Step num: 6454, Learning rate: 0.00011002, Avg batch loss: 0.0602, Avg batch acc: 0.9467
Train, Epoch: 5, Batch: 379, Step num: 6455, Learning rate: 0.00011001, Avg batch loss: 0.0403, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 380, Step num: 6456, Learning rate: 0.00011001, Avg batch loss: 0.0442, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 381, Step num: 6457, Learning rate: 0.00011000, Avg batch loss: 0.0425, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 382, Step num: 6458, Learning rate: 0.00010999, Avg batch loss: 0.0404, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 383, Step num: 6459, Learning rate: 0.00010998, Avg batch loss: 0.0425, Avg batch acc: 0.9587
Train, Epoch: 5, Batch: 384, Step num: 6460, Learning rate: 0.00010997, Avg batch loss: 0.0438, Avg batch acc: 0.9579
Train, Epoch: 5, Batch: 385, Step num: 6461, Learning rate: 0.00010996, Avg batch loss: 0.0465, Avg batch acc: 0.9517
Train, Epoch: 5, Batch: 386, Step num: 6462, Learning rate: 0.00010995, Avg batch loss: 0.0431, Avg batch acc: 0.9531
Train, Epoch: 5, Batch: 387, Step num: 6463, Learning rate: 0.00010995, Avg batch loss: 0.0408, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 388, Step num: 6464, Learning rate: 0.00010994, Avg batch loss: 0.0464, Avg batch acc: 0.9523
Train, Epoch: 5, Batch: 389, Step num: 6465, Learning rate: 0.00010993, Avg batch loss: 0.0430, Avg batch acc: 0.9530
Train, Epoch: 5, Batch: 390, Step num: 6466, Learning rate: 0.00010992, Avg batch loss: 0.0394, Avg batch acc: 0.9596
Train, Epoch: 5, Batch: 391, Step num: 6467, Learning rate: 0.00010991, Avg batch loss: 0.0534, Avg batch acc: 0.9539
Train, Epoch: 5, Batch: 392, Step num: 6468, Learning rate: 0.00010990, Avg batch loss: 0.0722, Avg batch acc: 0.9457
Train, Epoch: 5, Batch: 393, Step num: 6469, Learning rate: 0.00010989, Avg batch loss: 0.0469, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 394, Step num: 6470, Learning rate: 0.00010989, Avg batch loss: 0.0464, Avg batch acc: 0.9553
Train, Epoch: 5, Batch: 395, Step num: 6471, Learning rate: 0.00010988, Avg batch loss: 0.0369, Avg batch acc: 0.9597
Train, Epoch: 5, Batch: 396, Step num: 6472, Learning rate: 0.00010987, Avg batch loss: 0.0403, Avg batch acc: 0.9553
Train, Epoch: 5, Batch: 397, Step num: 6473, Learning rate: 0.00010986, Avg batch loss: 0.0467, Avg batch acc: 0.9547
Train, Epoch: 5, Batch: 398, Step num: 6474, Learning rate: 0.00010985, Avg batch loss: 0.0486, Avg batch acc: 0.9548
Train, Epoch: 5, Batch: 399, Step num: 6475, Learning rate: 0.00010984, Avg batch loss: 0.0482, Avg batch acc: 0.9509
Train, Epoch: 5, Batch: 400, Step num: 6476, Learning rate: 0.00010984, Avg batch loss: 0.0445, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 401, Step num: 6477, Learning rate: 0.00010983, Avg batch loss: 0.0527, Avg batch acc: 0.9522
Train, Epoch: 5, Batch: 402, Step num: 6478, Learning rate: 0.00010982, Avg batch loss: 0.0549, Avg batch acc: 0.9481
Train, Epoch: 5, Batch: 403, Step num: 6479, Learning rate: 0.00010981, Avg batch loss: 0.0530, Avg batch acc: 0.9536
Train, Epoch: 5, Batch: 404, Step num: 6480, Learning rate: 0.00010980, Avg batch loss: 0.0452, Avg batch acc: 0.9600
Train, Epoch: 5, Batch: 405, Step num: 6481, Learning rate: 0.00010979, Avg batch loss: 0.0507, Avg batch acc: 0.9456
Train, Epoch: 5, Batch: 406, Step num: 6482, Learning rate: 0.00010978, Avg batch loss: 0.0436, Avg batch acc: 0.9550
Train, Epoch: 5, Batch: 407, Step num: 6483, Learning rate: 0.00010978, Avg batch loss: 0.0304, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 408, Step num: 6484, Learning rate: 0.00010977, Avg batch loss: 0.0527, Avg batch acc: 0.9550
Train, Epoch: 5, Batch: 409, Step num: 6485, Learning rate: 0.00010976, Avg batch loss: 0.0458, Avg batch acc: 0.9553
Train, Epoch: 5, Batch: 410, Step num: 6486, Learning rate: 0.00010975, Avg batch loss: 0.0385, Avg batch acc: 0.9547
Train, Epoch: 5, Batch: 411, Step num: 6487, Learning rate: 0.00010974, Avg batch loss: 0.0650, Avg batch acc: 0.9481
Train, Epoch: 5, Batch: 412, Step num: 6488, Learning rate: 0.00010973, Avg batch loss: 0.0450, Avg batch acc: 0.9547
Train, Epoch: 5, Batch: 413, Step num: 6489, Learning rate: 0.00010973, Avg batch loss: 0.0531, Avg batch acc: 0.9547
Train, Epoch: 5, Batch: 414, Step num: 6490, Learning rate: 0.00010972, Avg batch loss: 0.0441, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 415, Step num: 6491, Learning rate: 0.00010971, Avg batch loss: 0.0344, Avg batch acc: 0.9691
Train, Epoch: 5, Batch: 416, Step num: 6492, Learning rate: 0.00010970, Avg batch loss: 0.0337, Avg batch acc: 0.9647
Train, Epoch: 5, Batch: 417, Step num: 6493, Learning rate: 0.00010969, Avg batch loss: 0.0489, Avg batch acc: 0.9537
Train, Epoch: 5, Batch: 418, Step num: 6494, Learning rate: 0.00010968, Avg batch loss: 0.0471, Avg batch acc: 0.9460
Train, Epoch: 5, Batch: 419, Step num: 6495, Learning rate: 0.00010967, Avg batch loss: 0.0504, Avg batch acc: 0.9504
Train, Epoch: 5, Batch: 420, Step num: 6496, Learning rate: 0.00010967, Avg batch loss: 0.0504, Avg batch acc: 0.9552
Train, Epoch: 5, Batch: 421, Step num: 6497, Learning rate: 0.00010966, Avg batch loss: 0.0512, Avg batch acc: 0.9528
Train, Epoch: 5, Batch: 422, Step num: 6498, Learning rate: 0.00010965, Avg batch loss: 0.0479, Avg batch acc: 0.9514
Train, Epoch: 5, Batch: 423, Step num: 6499, Learning rate: 0.00010964, Avg batch loss: 0.0446, Avg batch acc: 0.9528
Train, Epoch: 5, Batch: 424, Step num: 6500, Learning rate: 0.00010963, Avg batch loss: 0.0436, Avg batch acc: 0.9523
Train, Epoch: 5, Batch: 425, Step num: 6501, Learning rate: 0.00010962, Avg batch loss: 0.0413, Avg batch acc: 0.9580
Train, Epoch: 5, Batch: 426, Step num: 6502, Learning rate: 0.00010962, Avg batch loss: 0.0446, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 427, Step num: 6503, Learning rate: 0.00010961, Avg batch loss: 0.0408, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 428, Step num: 6504, Learning rate: 0.00010960, Avg batch loss: 0.0397, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 429, Step num: 6505, Learning rate: 0.00010959, Avg batch loss: 0.0422, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 430, Step num: 6506, Learning rate: 0.00010958, Avg batch loss: 0.0465, Avg batch acc: 0.9505
Train, Epoch: 5, Batch: 431, Step num: 6507, Learning rate: 0.00010957, Avg batch loss: 0.0440, Avg batch acc: 0.9644
Train, Epoch: 5, Batch: 432, Step num: 6508, Learning rate: 0.00010956, Avg batch loss: 0.0449, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 433, Step num: 6509, Learning rate: 0.00010956, Avg batch loss: 0.0435, Avg batch acc: 0.9567
Train, Epoch: 5, Batch: 434, Step num: 6510, Learning rate: 0.00010955, Avg batch loss: 0.0475, Avg batch acc: 0.9547
Train, Epoch: 5, Batch: 435, Step num: 6511, Learning rate: 0.00010954, Avg batch loss: 0.0536, Avg batch acc: 0.9556
Train, Epoch: 5, Batch: 436, Step num: 6512, Learning rate: 0.00010953, Avg batch loss: 0.0425, Avg batch acc: 0.9524
Train, Epoch: 5, Batch: 437, Step num: 6513, Learning rate: 0.00010952, Avg batch loss: 0.0443, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 438, Step num: 6514, Learning rate: 0.00010951, Avg batch loss: 0.0413, Avg batch acc: 0.9600
Train, Epoch: 5, Batch: 439, Step num: 6515, Learning rate: 0.00010951, Avg batch loss: 0.0523, Avg batch acc: 0.9496
Train, Epoch: 5, Batch: 440, Step num: 6516, Learning rate: 0.00010950, Avg batch loss: 0.0403, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 441, Step num: 6517, Learning rate: 0.00010949, Avg batch loss: 0.0422, Avg batch acc: 0.9551
Train, Epoch: 5, Batch: 442, Step num: 6518, Learning rate: 0.00010948, Avg batch loss: 0.0452, Avg batch acc: 0.9507
Train, Epoch: 5, Batch: 443, Step num: 6519, Learning rate: 0.00010947, Avg batch loss: 0.0430, Avg batch acc: 0.9582
Train, Epoch: 5, Batch: 444, Step num: 6520, Learning rate: 0.00010946, Avg batch loss: 0.0448, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 445, Step num: 6521, Learning rate: 0.00010946, Avg batch loss: 0.0341, Avg batch acc: 0.9660
Train, Epoch: 5, Batch: 446, Step num: 6522, Learning rate: 0.00010945, Avg batch loss: 0.0475, Avg batch acc: 0.9470
Train, Epoch: 5, Batch: 447, Step num: 6523, Learning rate: 0.00010944, Avg batch loss: 0.0558, Avg batch acc: 0.9587
Train, Epoch: 5, Batch: 448, Step num: 6524, Learning rate: 0.00010943, Avg batch loss: 0.0428, Avg batch acc: 0.9538
Train, Epoch: 5, Batch: 449, Step num: 6525, Learning rate: 0.00010942, Avg batch loss: 0.0401, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 450, Step num: 6526, Learning rate: 0.00010941, Avg batch loss: 0.0408, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 451, Step num: 6527, Learning rate: 0.00010941, Avg batch loss: 0.0453, Avg batch acc: 0.9512
Train, Epoch: 5, Batch: 452, Step num: 6528, Learning rate: 0.00010940, Avg batch loss: 0.0469, Avg batch acc: 0.9526
Train, Epoch: 5, Batch: 453, Step num: 6529, Learning rate: 0.00010939, Avg batch loss: 0.0411, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 454, Step num: 6530, Learning rate: 0.00010938, Avg batch loss: 0.0439, Avg batch acc: 0.9579
Train, Epoch: 5, Batch: 455, Step num: 6531, Learning rate: 0.00010937, Avg batch loss: 0.0463, Avg batch acc: 0.9612
Train, Epoch: 5, Batch: 456, Step num: 6532, Learning rate: 0.00010936, Avg batch loss: 0.0447, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 457, Step num: 6533, Learning rate: 0.00010936, Avg batch loss: 0.0412, Avg batch acc: 0.9565
Train, Epoch: 5, Batch: 458, Step num: 6534, Learning rate: 0.00010935, Avg batch loss: 0.0508, Avg batch acc: 0.9575
Train, Epoch: 5, Batch: 459, Step num: 6535, Learning rate: 0.00010934, Avg batch loss: 0.0426, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 460, Step num: 6536, Learning rate: 0.00010933, Avg batch loss: 0.0416, Avg batch acc: 0.9522
Train, Epoch: 5, Batch: 461, Step num: 6537, Learning rate: 0.00010932, Avg batch loss: 0.0462, Avg batch acc: 0.9534
Train, Epoch: 5, Batch: 462, Step num: 6538, Learning rate: 0.00010931, Avg batch loss: 0.0447, Avg batch acc: 0.9604
Train, Epoch: 5, Batch: 463, Step num: 6539, Learning rate: 0.00010930, Avg batch loss: 0.0472, Avg batch acc: 0.9560
Train, Epoch: 5, Batch: 464, Step num: 6540, Learning rate: 0.00010930, Avg batch loss: 0.0481, Avg batch acc: 0.9555
Train, Epoch: 5, Batch: 465, Step num: 6541, Learning rate: 0.00010929, Avg batch loss: 0.0417, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 466, Step num: 6542, Learning rate: 0.00010928, Avg batch loss: 0.0722, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 467, Step num: 6543, Learning rate: 0.00010927, Avg batch loss: 0.0444, Avg batch acc: 0.9563
Train, Epoch: 5, Batch: 468, Step num: 6544, Learning rate: 0.00010926, Avg batch loss: 0.0365, Avg batch acc: 0.9677
Train, Epoch: 5, Batch: 469, Step num: 6545, Learning rate: 0.00010925, Avg batch loss: 0.0487, Avg batch acc: 0.9522
Train, Epoch: 5, Batch: 470, Step num: 6546, Learning rate: 0.00010925, Avg batch loss: 0.0467, Avg batch acc: 0.9528
Train, Epoch: 5, Batch: 471, Step num: 6547, Learning rate: 0.00010924, Avg batch loss: 0.0474, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 472, Step num: 6548, Learning rate: 0.00010923, Avg batch loss: 0.0472, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 473, Step num: 6549, Learning rate: 0.00010922, Avg batch loss: 0.0469, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 474, Step num: 6550, Learning rate: 0.00010921, Avg batch loss: 0.0614, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 475, Step num: 6551, Learning rate: 0.00010920, Avg batch loss: 0.0389, Avg batch acc: 0.9542
Train, Epoch: 5, Batch: 476, Step num: 6552, Learning rate: 0.00010920, Avg batch loss: 0.0532, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 477, Step num: 6553, Learning rate: 0.00010919, Avg batch loss: 0.0417, Avg batch acc: 0.9572
Train, Epoch: 5, Batch: 478, Step num: 6554, Learning rate: 0.00010918, Avg batch loss: 0.0481, Avg batch acc: 0.9599
Train, Epoch: 5, Batch: 479, Step num: 6555, Learning rate: 0.00010917, Avg batch loss: 0.0494, Avg batch acc: 0.9523
Train, Epoch: 5, Batch: 480, Step num: 6556, Learning rate: 0.00010916, Avg batch loss: 0.0431, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 481, Step num: 6557, Learning rate: 0.00010915, Avg batch loss: 0.0370, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 482, Step num: 6558, Learning rate: 0.00010915, Avg batch loss: 0.0477, Avg batch acc: 0.9548
Train, Epoch: 5, Batch: 483, Step num: 6559, Learning rate: 0.00010914, Avg batch loss: 0.0439, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 484, Step num: 6560, Learning rate: 0.00010913, Avg batch loss: 0.0445, Avg batch acc: 0.9577
Train, Epoch: 5, Batch: 485, Step num: 6561, Learning rate: 0.00010912, Avg batch loss: 0.0518, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 486, Step num: 6562, Learning rate: 0.00010911, Avg batch loss: 0.0389, Avg batch acc: 0.9640
Train, Epoch: 5, Batch: 487, Step num: 6563, Learning rate: 0.00010910, Avg batch loss: 0.0390, Avg batch acc: 0.9622
Train, Epoch: 5, Batch: 488, Step num: 6564, Learning rate: 0.00010910, Avg batch loss: 0.0462, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 489, Step num: 6565, Learning rate: 0.00010909, Avg batch loss: 0.0443, Avg batch acc: 0.9569
Train, Epoch: 5, Batch: 490, Step num: 6566, Learning rate: 0.00010908, Avg batch loss: 0.0454, Avg batch acc: 0.9572
Train, Epoch: 5, Batch: 491, Step num: 6567, Learning rate: 0.00010907, Avg batch loss: 0.0524, Avg batch acc: 0.9497
Train, Epoch: 5, Batch: 492, Step num: 6568, Learning rate: 0.00010906, Avg batch loss: 0.0465, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 493, Step num: 6569, Learning rate: 0.00010905, Avg batch loss: 0.0490, Avg batch acc: 0.9488
Train, Epoch: 5, Batch: 494, Step num: 6570, Learning rate: 0.00010905, Avg batch loss: 0.0452, Avg batch acc: 0.9513
Train, Epoch: 5, Batch: 495, Step num: 6571, Learning rate: 0.00010904, Avg batch loss: 0.0441, Avg batch acc: 0.9526
Train, Epoch: 5, Batch: 496, Step num: 6572, Learning rate: 0.00010903, Avg batch loss: 0.0417, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 497, Step num: 6573, Learning rate: 0.00010902, Avg batch loss: 0.0456, Avg batch acc: 0.9606
Train, Epoch: 5, Batch: 498, Step num: 6574, Learning rate: 0.00010901, Avg batch loss: 0.0388, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 499, Step num: 6575, Learning rate: 0.00010901, Avg batch loss: 0.0451, Avg batch acc: 0.9582
Train, Epoch: 5, Batch: 500, Step num: 6576, Learning rate: 0.00010900, Avg batch loss: 0.0417, Avg batch acc: 0.9555
Train, Epoch: 5, Batch: 501, Step num: 6577, Learning rate: 0.00010899, Avg batch loss: 0.0390, Avg batch acc: 0.9633
Train, Epoch: 5, Batch: 502, Step num: 6578, Learning rate: 0.00010898, Avg batch loss: 0.0471, Avg batch acc: 0.9567
Train, Epoch: 5, Batch: 503, Step num: 6579, Learning rate: 0.00010897, Avg batch loss: 0.0341, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 504, Step num: 6580, Learning rate: 0.00010896, Avg batch loss: 0.0389, Avg batch acc: 0.9593
Train, Epoch: 5, Batch: 505, Step num: 6581, Learning rate: 0.00010896, Avg batch loss: 0.0429, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 506, Step num: 6582, Learning rate: 0.00010895, Avg batch loss: 0.0398, Avg batch acc: 0.9545
Train, Epoch: 5, Batch: 507, Step num: 6583, Learning rate: 0.00010894, Avg batch loss: 0.0454, Avg batch acc: 0.9545
Train, Epoch: 5, Batch: 508, Step num: 6584, Learning rate: 0.00010893, Avg batch loss: 0.0443, Avg batch acc: 0.9569
Train, Epoch: 5, Batch: 509, Step num: 6585, Learning rate: 0.00010892, Avg batch loss: 0.0424, Avg batch acc: 0.9617
Train, Epoch: 5, Batch: 510, Step num: 6586, Learning rate: 0.00010891, Avg batch loss: 0.0501, Avg batch acc: 0.9520
Train, Epoch: 5, Batch: 511, Step num: 6587, Learning rate: 0.00010891, Avg batch loss: 0.0493, Avg batch acc: 0.9469
Train, Epoch: 5, Batch: 512, Step num: 6588, Learning rate: 0.00010890, Avg batch loss: 0.0394, Avg batch acc: 0.9575
Train, Epoch: 5, Batch: 513, Step num: 6589, Learning rate: 0.00010889, Avg batch loss: 0.0333, Avg batch acc: 0.9640
Train, Epoch: 5, Batch: 514, Step num: 6590, Learning rate: 0.00010888, Avg batch loss: 0.0428, Avg batch acc: 0.9608
Train, Epoch: 5, Batch: 515, Step num: 6591, Learning rate: 0.00010887, Avg batch loss: 0.0405, Avg batch acc: 0.9584
Train, Epoch: 5, Batch: 516, Step num: 6592, Learning rate: 0.00010886, Avg batch loss: 0.0541, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 517, Step num: 6593, Learning rate: 0.00010886, Avg batch loss: 0.0447, Avg batch acc: 0.9575
Train, Epoch: 5, Batch: 518, Step num: 6594, Learning rate: 0.00010885, Avg batch loss: 0.0406, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 519, Step num: 6595, Learning rate: 0.00010884, Avg batch loss: 0.0404, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 520, Step num: 6596, Learning rate: 0.00010883, Avg batch loss: 0.0424, Avg batch acc: 0.9567
Train, Epoch: 5, Batch: 521, Step num: 6597, Learning rate: 0.00010882, Avg batch loss: 0.0391, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 522, Step num: 6598, Learning rate: 0.00010882, Avg batch loss: 0.0343, Avg batch acc: 0.9631
Train, Epoch: 5, Batch: 523, Step num: 6599, Learning rate: 0.00010881, Avg batch loss: 0.0435, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 524, Step num: 6600, Learning rate: 0.00010880, Avg batch loss: 0.0417, Avg batch acc: 0.9612
Train, Epoch: 5, Batch: 525, Step num: 6601, Learning rate: 0.00010879, Avg batch loss: 0.0433, Avg batch acc: 0.9621
Train, Epoch: 5, Batch: 526, Step num: 6602, Learning rate: 0.00010878, Avg batch loss: 0.0382, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 527, Step num: 6603, Learning rate: 0.00010877, Avg batch loss: 0.0471, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 528, Step num: 6604, Learning rate: 0.00010877, Avg batch loss: 0.0338, Avg batch acc: 0.9569
Train, Epoch: 5, Batch: 529, Step num: 6605, Learning rate: 0.00010876, Avg batch loss: 0.0395, Avg batch acc: 0.9584
Train, Epoch: 5, Batch: 530, Step num: 6606, Learning rate: 0.00010875, Avg batch loss: 0.0483, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 531, Step num: 6607, Learning rate: 0.00010874, Avg batch loss: 0.0474, Avg batch acc: 0.9585
Train, Epoch: 5, Batch: 532, Step num: 6608, Learning rate: 0.00010873, Avg batch loss: 0.0537, Avg batch acc: 0.9489
Train, Epoch: 5, Batch: 533, Step num: 6609, Learning rate: 0.00010872, Avg batch loss: 0.0420, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 534, Step num: 6610, Learning rate: 0.00010872, Avg batch loss: 0.0384, Avg batch acc: 0.9616
Train, Epoch: 5, Batch: 535, Step num: 6611, Learning rate: 0.00010871, Avg batch loss: 0.0415, Avg batch acc: 0.9587
Train, Epoch: 5, Batch: 536, Step num: 6612, Learning rate: 0.00010870, Avg batch loss: 0.0513, Avg batch acc: 0.9523
Train, Epoch: 5, Batch: 537, Step num: 6613, Learning rate: 0.00010869, Avg batch loss: 0.0381, Avg batch acc: 0.9631
Train, Epoch: 5, Batch: 538, Step num: 6614, Learning rate: 0.00010868, Avg batch loss: 0.0401, Avg batch acc: 0.9644
Train, Epoch: 5, Batch: 539, Step num: 6615, Learning rate: 0.00010868, Avg batch loss: 0.0467, Avg batch acc: 0.9608
Train, Epoch: 5, Batch: 540, Step num: 6616, Learning rate: 0.00010867, Avg batch loss: 0.0360, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 541, Step num: 6617, Learning rate: 0.00010866, Avg batch loss: 0.0346, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 542, Step num: 6618, Learning rate: 0.00010865, Avg batch loss: 0.0509, Avg batch acc: 0.9528
Train, Epoch: 5, Batch: 543, Step num: 6619, Learning rate: 0.00010864, Avg batch loss: 0.0583, Avg batch acc: 0.9472
Train, Epoch: 5, Batch: 544, Step num: 6620, Learning rate: 0.00010863, Avg batch loss: 0.0457, Avg batch acc: 0.9541
Train, Epoch: 5, Batch: 545, Step num: 6621, Learning rate: 0.00010863, Avg batch loss: 0.0448, Avg batch acc: 0.9598
Train, Epoch: 5, Batch: 546, Step num: 6622, Learning rate: 0.00010862, Avg batch loss: 0.0437, Avg batch acc: 0.9542
Train, Epoch: 5, Batch: 547, Step num: 6623, Learning rate: 0.00010861, Avg batch loss: 0.0506, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 548, Step num: 6624, Learning rate: 0.00010860, Avg batch loss: 0.0452, Avg batch acc: 0.9515
Train, Epoch: 5, Batch: 549, Step num: 6625, Learning rate: 0.00010859, Avg batch loss: 0.0406, Avg batch acc: 0.9658
Train, Epoch: 5, Batch: 550, Step num: 6626, Learning rate: 0.00010858, Avg batch loss: 0.0508, Avg batch acc: 0.9523
Train, Epoch: 5, Batch: 551, Step num: 6627, Learning rate: 0.00010858, Avg batch loss: 0.0489, Avg batch acc: 0.9523
Train, Epoch: 5, Batch: 552, Step num: 6628, Learning rate: 0.00010857, Avg batch loss: 0.0397, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 553, Step num: 6629, Learning rate: 0.00010856, Avg batch loss: 0.0382, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 554, Step num: 6630, Learning rate: 0.00010855, Avg batch loss: 0.0409, Avg batch acc: 0.9571
Train, Epoch: 5, Batch: 555, Step num: 6631, Learning rate: 0.00010854, Avg batch loss: 0.0538, Avg batch acc: 0.9535
Train, Epoch: 5, Batch: 556, Step num: 6632, Learning rate: 0.00010854, Avg batch loss: 0.0373, Avg batch acc: 0.9594
Train, Epoch: 5, Batch: 557, Step num: 6633, Learning rate: 0.00010853, Avg batch loss: 0.0387, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 558, Step num: 6634, Learning rate: 0.00010852, Avg batch loss: 0.0360, Avg batch acc: 0.9609
Train, Epoch: 5, Batch: 559, Step num: 6635, Learning rate: 0.00010851, Avg batch loss: 0.0349, Avg batch acc: 0.9672
Train, Epoch: 5, Batch: 560, Step num: 6636, Learning rate: 0.00010850, Avg batch loss: 0.0451, Avg batch acc: 0.9542
Train, Epoch: 5, Batch: 561, Step num: 6637, Learning rate: 0.00010849, Avg batch loss: 0.0405, Avg batch acc: 0.9602
Train, Epoch: 5, Batch: 562, Step num: 6638, Learning rate: 0.00010849, Avg batch loss: 0.0357, Avg batch acc: 0.9665
Train, Epoch: 5, Batch: 563, Step num: 6639, Learning rate: 0.00010848, Avg batch loss: 0.0413, Avg batch acc: 0.9540
Train, Epoch: 5, Batch: 564, Step num: 6640, Learning rate: 0.00010847, Avg batch loss: 0.0342, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 565, Step num: 6641, Learning rate: 0.00010846, Avg batch loss: 0.0403, Avg batch acc: 0.9516
Train, Epoch: 5, Batch: 566, Step num: 6642, Learning rate: 0.00010845, Avg batch loss: 0.0444, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 567, Step num: 6643, Learning rate: 0.00010845, Avg batch loss: 0.0404, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 568, Step num: 6644, Learning rate: 0.00010844, Avg batch loss: 0.0495, Avg batch acc: 0.9577
Train, Epoch: 5, Batch: 569, Step num: 6645, Learning rate: 0.00010843, Avg batch loss: 0.0500, Avg batch acc: 0.9529
Train, Epoch: 5, Batch: 570, Step num: 6646, Learning rate: 0.00010842, Avg batch loss: 0.0424, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 571, Step num: 6647, Learning rate: 0.00010841, Avg batch loss: 0.0398, Avg batch acc: 0.9604
Train, Epoch: 5, Batch: 572, Step num: 6648, Learning rate: 0.00010841, Avg batch loss: 0.0485, Avg batch acc: 0.9567
Train, Epoch: 5, Batch: 573, Step num: 6649, Learning rate: 0.00010840, Avg batch loss: 0.0582, Avg batch acc: 0.9513
Train, Epoch: 5, Batch: 574, Step num: 6650, Learning rate: 0.00010839, Avg batch loss: 0.0347, Avg batch acc: 0.9651
Train, Epoch: 5, Batch: 575, Step num: 6651, Learning rate: 0.00010838, Avg batch loss: 0.0354, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 576, Step num: 6652, Learning rate: 0.00010837, Avg batch loss: 0.0455, Avg batch acc: 0.9616
Train, Epoch: 5, Batch: 577, Step num: 6653, Learning rate: 0.00010836, Avg batch loss: 0.0430, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 578, Step num: 6654, Learning rate: 0.00010836, Avg batch loss: 0.0425, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 579, Step num: 6655, Learning rate: 0.00010835, Avg batch loss: 0.0347, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 580, Step num: 6656, Learning rate: 0.00010834, Avg batch loss: 0.0465, Avg batch acc: 0.9512
Train, Epoch: 5, Batch: 581, Step num: 6657, Learning rate: 0.00010833, Avg batch loss: 0.0429, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 582, Step num: 6658, Learning rate: 0.00010832, Avg batch loss: 0.0400, Avg batch acc: 0.9640
Train, Epoch: 5, Batch: 583, Step num: 6659, Learning rate: 0.00010832, Avg batch loss: 0.0371, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 584, Step num: 6660, Learning rate: 0.00010831, Avg batch loss: 0.0530, Avg batch acc: 0.9533
Train, Epoch: 5, Batch: 585, Step num: 6661, Learning rate: 0.00010830, Avg batch loss: 0.0375, Avg batch acc: 0.9593
Train, Epoch: 5, Batch: 586, Step num: 6662, Learning rate: 0.00010829, Avg batch loss: 0.0351, Avg batch acc: 0.9659
Train, Epoch: 5, Batch: 587, Step num: 6663, Learning rate: 0.00010828, Avg batch loss: 0.0437, Avg batch acc: 0.9567
Train, Epoch: 5, Batch: 588, Step num: 6664, Learning rate: 0.00010827, Avg batch loss: 0.0416, Avg batch acc: 0.9531
Train, Epoch: 5, Batch: 589, Step num: 6665, Learning rate: 0.00010827, Avg batch loss: 0.0380, Avg batch acc: 0.9630
Train, Epoch: 5, Batch: 590, Step num: 6666, Learning rate: 0.00010826, Avg batch loss: 0.0428, Avg batch acc: 0.9634
Train, Epoch: 5, Batch: 591, Step num: 6667, Learning rate: 0.00010825, Avg batch loss: 0.0379, Avg batch acc: 0.9594
Train, Epoch: 5, Batch: 592, Step num: 6668, Learning rate: 0.00010824, Avg batch loss: 0.0362, Avg batch acc: 0.9664
Train, Epoch: 5, Batch: 593, Step num: 6669, Learning rate: 0.00010823, Avg batch loss: 0.0494, Avg batch acc: 0.9530
Train, Epoch: 5, Batch: 594, Step num: 6670, Learning rate: 0.00010823, Avg batch loss: 0.0364, Avg batch acc: 0.9646
Train, Epoch: 5, Batch: 595, Step num: 6671, Learning rate: 0.00010822, Avg batch loss: 0.0376, Avg batch acc: 0.9639
Train, Epoch: 5, Batch: 596, Step num: 6672, Learning rate: 0.00010821, Avg batch loss: 0.0548, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 597, Step num: 6673, Learning rate: 0.00010820, Avg batch loss: 0.0354, Avg batch acc: 0.9675
Train, Epoch: 5, Batch: 598, Step num: 6674, Learning rate: 0.00010819, Avg batch loss: 0.0480, Avg batch acc: 0.9489
Train, Epoch: 5, Batch: 599, Step num: 6675, Learning rate: 0.00010819, Avg batch loss: 0.0466, Avg batch acc: 0.9521
Train, Epoch: 5, Batch: 600, Step num: 6676, Learning rate: 0.00010818, Avg batch loss: 0.0326, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 601, Step num: 6677, Learning rate: 0.00010817, Avg batch loss: 0.0509, Avg batch acc: 0.9592
Train, Epoch: 5, Batch: 602, Step num: 6678, Learning rate: 0.00010816, Avg batch loss: 0.0405, Avg batch acc: 0.9623
Train, Epoch: 5, Batch: 603, Step num: 6679, Learning rate: 0.00010815, Avg batch loss: 0.0361, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 604, Step num: 6680, Learning rate: 0.00010815, Avg batch loss: 0.0412, Avg batch acc: 0.9562
Train, Epoch: 5, Batch: 605, Step num: 6681, Learning rate: 0.00010814, Avg batch loss: 0.0425, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 606, Step num: 6682, Learning rate: 0.00010813, Avg batch loss: 0.0348, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 607, Step num: 6683, Learning rate: 0.00010812, Avg batch loss: 0.0576, Avg batch acc: 0.9495
Train, Epoch: 5, Batch: 608, Step num: 6684, Learning rate: 0.00010811, Avg batch loss: 0.0454, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 609, Step num: 6685, Learning rate: 0.00010810, Avg batch loss: 0.0399, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 610, Step num: 6686, Learning rate: 0.00010810, Avg batch loss: 0.0369, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 611, Step num: 6687, Learning rate: 0.00010809, Avg batch loss: 0.0501, Avg batch acc: 0.9550
Train, Epoch: 5, Batch: 612, Step num: 6688, Learning rate: 0.00010808, Avg batch loss: 0.0352, Avg batch acc: 0.9684
Train, Epoch: 5, Batch: 613, Step num: 6689, Learning rate: 0.00010807, Avg batch loss: 0.0384, Avg batch acc: 0.9598
Train, Epoch: 5, Batch: 614, Step num: 6690, Learning rate: 0.00010806, Avg batch loss: 0.0395, Avg batch acc: 0.9579
Train, Epoch: 5, Batch: 615, Step num: 6691, Learning rate: 0.00010806, Avg batch loss: 0.0303, Avg batch acc: 0.9686
Train, Epoch: 5, Batch: 616, Step num: 6692, Learning rate: 0.00010805, Avg batch loss: 0.0328, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 617, Step num: 6693, Learning rate: 0.00010804, Avg batch loss: 0.0389, Avg batch acc: 0.9609
Train, Epoch: 5, Batch: 618, Step num: 6694, Learning rate: 0.00010803, Avg batch loss: 0.0342, Avg batch acc: 0.9585
Train, Epoch: 5, Batch: 619, Step num: 6695, Learning rate: 0.00010802, Avg batch loss: 0.0427, Avg batch acc: 0.9571
Train, Epoch: 5, Batch: 620, Step num: 6696, Learning rate: 0.00010802, Avg batch loss: 0.0409, Avg batch acc: 0.9574
Train, Epoch: 5, Batch: 621, Step num: 6697, Learning rate: 0.00010801, Avg batch loss: 0.0437, Avg batch acc: 0.9547
Train, Epoch: 5, Batch: 622, Step num: 6698, Learning rate: 0.00010800, Avg batch loss: 0.0454, Avg batch acc: 0.9550
Train, Epoch: 5, Batch: 623, Step num: 6699, Learning rate: 0.00010799, Avg batch loss: 0.0430, Avg batch acc: 0.9594
Train, Epoch: 5, Batch: 624, Step num: 6700, Learning rate: 0.00010798, Avg batch loss: 0.0450, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 625, Step num: 6701, Learning rate: 0.00010798, Avg batch loss: 0.0438, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 626, Step num: 6702, Learning rate: 0.00010797, Avg batch loss: 0.0313, Avg batch acc: 0.9653
Train, Epoch: 5, Batch: 627, Step num: 6703, Learning rate: 0.00010796, Avg batch loss: 0.0413, Avg batch acc: 0.9505
Train, Epoch: 5, Batch: 628, Step num: 6704, Learning rate: 0.00010795, Avg batch loss: 0.0394, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 629, Step num: 6705, Learning rate: 0.00010794, Avg batch loss: 0.0420, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 630, Step num: 6706, Learning rate: 0.00010794, Avg batch loss: 0.0483, Avg batch acc: 0.9564
Train, Epoch: 5, Batch: 631, Step num: 6707, Learning rate: 0.00010793, Avg batch loss: 0.0355, Avg batch acc: 0.9630
Train, Epoch: 5, Batch: 632, Step num: 6708, Learning rate: 0.00010792, Avg batch loss: 0.0349, Avg batch acc: 0.9669
Train, Epoch: 5, Batch: 633, Step num: 6709, Learning rate: 0.00010791, Avg batch loss: 0.0419, Avg batch acc: 0.9548
Train, Epoch: 5, Batch: 634, Step num: 6710, Learning rate: 0.00010790, Avg batch loss: 0.0399, Avg batch acc: 0.9632
Train, Epoch: 5, Batch: 635, Step num: 6711, Learning rate: 0.00010790, Avg batch loss: 0.0353, Avg batch acc: 0.9572
Train, Epoch: 5, Batch: 636, Step num: 6712, Learning rate: 0.00010789, Avg batch loss: 0.0443, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 637, Step num: 6713, Learning rate: 0.00010788, Avg batch loss: 0.0510, Avg batch acc: 0.9489
Train, Epoch: 5, Batch: 638, Step num: 6714, Learning rate: 0.00010787, Avg batch loss: 0.0370, Avg batch acc: 0.9622
Train, Epoch: 5, Batch: 639, Step num: 6715, Learning rate: 0.00010786, Avg batch loss: 0.0471, Avg batch acc: 0.9556
Train, Epoch: 5, Batch: 640, Step num: 6716, Learning rate: 0.00010785, Avg batch loss: 0.0418, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 641, Step num: 6717, Learning rate: 0.00010785, Avg batch loss: 0.0619, Avg batch acc: 0.9540
Train, Epoch: 5, Batch: 642, Step num: 6718, Learning rate: 0.00010784, Avg batch loss: 0.0397, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 643, Step num: 6719, Learning rate: 0.00010783, Avg batch loss: 0.0434, Avg batch acc: 0.9621
Train, Epoch: 5, Batch: 644, Step num: 6720, Learning rate: 0.00010782, Avg batch loss: 0.0575, Avg batch acc: 0.9474
Train, Epoch: 5, Batch: 645, Step num: 6721, Learning rate: 0.00010781, Avg batch loss: 0.0398, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 646, Step num: 6722, Learning rate: 0.00010781, Avg batch loss: 0.0391, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 647, Step num: 6723, Learning rate: 0.00010780, Avg batch loss: 0.0419, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 648, Step num: 6724, Learning rate: 0.00010779, Avg batch loss: 0.0405, Avg batch acc: 0.9642
Train, Epoch: 5, Batch: 649, Step num: 6725, Learning rate: 0.00010778, Avg batch loss: 0.0402, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 650, Step num: 6726, Learning rate: 0.00010777, Avg batch loss: 0.0444, Avg batch acc: 0.9538
Train, Epoch: 5, Batch: 651, Step num: 6727, Learning rate: 0.00010777, Avg batch loss: 0.0457, Avg batch acc: 0.9522
Train, Epoch: 5, Batch: 652, Step num: 6728, Learning rate: 0.00010776, Avg batch loss: 0.0298, Avg batch acc: 0.9686
Train, Epoch: 5, Batch: 653, Step num: 6729, Learning rate: 0.00010775, Avg batch loss: 0.0437, Avg batch acc: 0.9565
Train, Epoch: 5, Batch: 654, Step num: 6730, Learning rate: 0.00010774, Avg batch loss: 0.0403, Avg batch acc: 0.9615
Train, Epoch: 5, Batch: 655, Step num: 6731, Learning rate: 0.00010773, Avg batch loss: 0.0445, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 656, Step num: 6732, Learning rate: 0.00010773, Avg batch loss: 0.0395, Avg batch acc: 0.9571
Train, Epoch: 5, Batch: 657, Step num: 6733, Learning rate: 0.00010772, Avg batch loss: 0.0461, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 658, Step num: 6734, Learning rate: 0.00010771, Avg batch loss: 0.0443, Avg batch acc: 0.9571
Train, Epoch: 5, Batch: 659, Step num: 6735, Learning rate: 0.00010770, Avg batch loss: 0.0444, Avg batch acc: 0.9564
Train, Epoch: 5, Batch: 660, Step num: 6736, Learning rate: 0.00010769, Avg batch loss: 0.0394, Avg batch acc: 0.9598
Train, Epoch: 5, Batch: 661, Step num: 6737, Learning rate: 0.00010769, Avg batch loss: 0.0763, Avg batch acc: 0.9484
Train, Epoch: 5, Batch: 662, Step num: 6738, Learning rate: 0.00010768, Avg batch loss: 0.0534, Avg batch acc: 0.9616
Train, Epoch: 5, Batch: 663, Step num: 6739, Learning rate: 0.00010767, Avg batch loss: 0.0431, Avg batch acc: 0.9544
Train, Epoch: 5, Batch: 664, Step num: 6740, Learning rate: 0.00010766, Avg batch loss: 0.0355, Avg batch acc: 0.9600
Train, Epoch: 5, Batch: 665, Step num: 6741, Learning rate: 0.00010765, Avg batch loss: 0.0391, Avg batch acc: 0.9599
Train, Epoch: 5, Batch: 666, Step num: 6742, Learning rate: 0.00010765, Avg batch loss: 0.0344, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 667, Step num: 6743, Learning rate: 0.00010764, Avg batch loss: 0.0465, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 668, Step num: 6744, Learning rate: 0.00010763, Avg batch loss: 0.0453, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 669, Step num: 6745, Learning rate: 0.00010762, Avg batch loss: 0.0396, Avg batch acc: 0.9632
Train, Epoch: 5, Batch: 670, Step num: 6746, Learning rate: 0.00010761, Avg batch loss: 0.0462, Avg batch acc: 0.9562
Train, Epoch: 5, Batch: 671, Step num: 6747, Learning rate: 0.00010761, Avg batch loss: 0.0397, Avg batch acc: 0.9646
Train, Epoch: 5, Batch: 672, Step num: 6748, Learning rate: 0.00010760, Avg batch loss: 0.0367, Avg batch acc: 0.9669
Train, Epoch: 5, Batch: 673, Step num: 6749, Learning rate: 0.00010759, Avg batch loss: 0.0472, Avg batch acc: 0.9541
Train, Epoch: 5, Batch: 674, Step num: 6750, Learning rate: 0.00010758, Avg batch loss: 0.0478, Avg batch acc: 0.9534
Train, Epoch: 5, Batch: 675, Step num: 6751, Learning rate: 0.00010757, Avg batch loss: 0.0357, Avg batch acc: 0.9634
Train, Epoch: 5, Batch: 676, Step num: 6752, Learning rate: 0.00010757, Avg batch loss: 0.0524, Avg batch acc: 0.9512
Train, Epoch: 5, Batch: 677, Step num: 6753, Learning rate: 0.00010756, Avg batch loss: 0.0359, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 678, Step num: 6754, Learning rate: 0.00010755, Avg batch loss: 0.0515, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 679, Step num: 6755, Learning rate: 0.00010754, Avg batch loss: 0.0437, Avg batch acc: 0.9661
Train, Epoch: 5, Batch: 680, Step num: 6756, Learning rate: 0.00010754, Avg batch loss: 0.0336, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 681, Step num: 6757, Learning rate: 0.00010753, Avg batch loss: 0.0367, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 682, Step num: 6758, Learning rate: 0.00010752, Avg batch loss: 0.0411, Avg batch acc: 0.9531
Train, Epoch: 5, Batch: 683, Step num: 6759, Learning rate: 0.00010751, Avg batch loss: 0.0470, Avg batch acc: 0.9561
Train, Epoch: 5, Batch: 684, Step num: 6760, Learning rate: 0.00010750, Avg batch loss: 0.0369, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 685, Step num: 6761, Learning rate: 0.00010750, Avg batch loss: 0.0473, Avg batch acc: 0.9579
Train, Epoch: 5, Batch: 686, Step num: 6762, Learning rate: 0.00010749, Avg batch loss: 0.0386, Avg batch acc: 0.9618
Train, Epoch: 5, Batch: 687, Step num: 6763, Learning rate: 0.00010748, Avg batch loss: 0.0364, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 688, Step num: 6764, Learning rate: 0.00010747, Avg batch loss: 0.0333, Avg batch acc: 0.9622
Train, Epoch: 5, Batch: 689, Step num: 6765, Learning rate: 0.00010746, Avg batch loss: 0.0442, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 690, Step num: 6766, Learning rate: 0.00010746, Avg batch loss: 0.0375, Avg batch acc: 0.9607
Train, Epoch: 5, Batch: 691, Step num: 6767, Learning rate: 0.00010745, Avg batch loss: 0.0654, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 692, Step num: 6768, Learning rate: 0.00010744, Avg batch loss: 0.0452, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 693, Step num: 6769, Learning rate: 0.00010743, Avg batch loss: 0.0382, Avg batch acc: 0.9605
Train, Epoch: 5, Batch: 694, Step num: 6770, Learning rate: 0.00010742, Avg batch loss: 0.0418, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 695, Step num: 6771, Learning rate: 0.00010742, Avg batch loss: 0.0396, Avg batch acc: 0.9582
Train, Epoch: 5, Batch: 696, Step num: 6772, Learning rate: 0.00010741, Avg batch loss: 0.0425, Avg batch acc: 0.9549
Train, Epoch: 5, Batch: 697, Step num: 6773, Learning rate: 0.00010740, Avg batch loss: 0.0501, Avg batch acc: 0.9526
Train, Epoch: 5, Batch: 698, Step num: 6774, Learning rate: 0.00010739, Avg batch loss: 0.0424, Avg batch acc: 0.9615
Train, Epoch: 5, Batch: 699, Step num: 6775, Learning rate: 0.00010738, Avg batch loss: 0.0415, Avg batch acc: 0.9581
Train, Epoch: 5, Batch: 700, Step num: 6776, Learning rate: 0.00010738, Avg batch loss: 0.0401, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 701, Step num: 6777, Learning rate: 0.00010737, Avg batch loss: 0.0404, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 702, Step num: 6778, Learning rate: 0.00010736, Avg batch loss: 0.0340, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 703, Step num: 6779, Learning rate: 0.00010735, Avg batch loss: 0.0475, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 704, Step num: 6780, Learning rate: 0.00010734, Avg batch loss: 0.0332, Avg batch acc: 0.9658
Train, Epoch: 5, Batch: 705, Step num: 6781, Learning rate: 0.00010734, Avg batch loss: 0.0456, Avg batch acc: 0.9609
Train, Epoch: 5, Batch: 706, Step num: 6782, Learning rate: 0.00010733, Avg batch loss: 0.0387, Avg batch acc: 0.9599
Train, Epoch: 5, Batch: 707, Step num: 6783, Learning rate: 0.00010732, Avg batch loss: 0.0362, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 708, Step num: 6784, Learning rate: 0.00010731, Avg batch loss: 0.0400, Avg batch acc: 0.9605
Train, Epoch: 5, Batch: 709, Step num: 6785, Learning rate: 0.00010731, Avg batch loss: 0.0433, Avg batch acc: 0.9480
Train, Epoch: 5, Batch: 710, Step num: 6786, Learning rate: 0.00010730, Avg batch loss: 0.0349, Avg batch acc: 0.9652
Train, Epoch: 5, Batch: 711, Step num: 6787, Learning rate: 0.00010729, Avg batch loss: 0.0371, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 712, Step num: 6788, Learning rate: 0.00010728, Avg batch loss: 0.0386, Avg batch acc: 0.9647
Train, Epoch: 5, Batch: 713, Step num: 6789, Learning rate: 0.00010727, Avg batch loss: 0.0316, Avg batch acc: 0.9656
Train, Epoch: 5, Batch: 714, Step num: 6790, Learning rate: 0.00010727, Avg batch loss: 0.0308, Avg batch acc: 0.9655
Train, Epoch: 5, Batch: 715, Step num: 6791, Learning rate: 0.00010726, Avg batch loss: 0.0389, Avg batch acc: 0.9639
Train, Epoch: 5, Batch: 716, Step num: 6792, Learning rate: 0.00010725, Avg batch loss: 0.0353, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 717, Step num: 6793, Learning rate: 0.00010724, Avg batch loss: 0.0416, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 718, Step num: 6794, Learning rate: 0.00010723, Avg batch loss: 0.0474, Avg batch acc: 0.9561
Train, Epoch: 5, Batch: 719, Step num: 6795, Learning rate: 0.00010723, Avg batch loss: 0.0397, Avg batch acc: 0.9610
Train, Epoch: 5, Batch: 720, Step num: 6796, Learning rate: 0.00010722, Avg batch loss: 0.0438, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 721, Step num: 6797, Learning rate: 0.00010721, Avg batch loss: 0.0425, Avg batch acc: 0.9627
Train, Epoch: 5, Batch: 722, Step num: 6798, Learning rate: 0.00010720, Avg batch loss: 0.0419, Avg batch acc: 0.9602
Train, Epoch: 5, Batch: 723, Step num: 6799, Learning rate: 0.00010719, Avg batch loss: 0.0565, Avg batch acc: 0.9544
Train, Epoch: 5, Batch: 724, Step num: 6800, Learning rate: 0.00010719, Avg batch loss: 0.0598, Avg batch acc: 0.9501
Train, Epoch: 5, Batch: 725, Step num: 6801, Learning rate: 0.00010718, Avg batch loss: 0.0387, Avg batch acc: 0.9593
Train, Epoch: 5, Batch: 726, Step num: 6802, Learning rate: 0.00010717, Avg batch loss: 0.0337, Avg batch acc: 0.9692
Train, Epoch: 5, Batch: 727, Step num: 6803, Learning rate: 0.00010716, Avg batch loss: 0.0387, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 728, Step num: 6804, Learning rate: 0.00010716, Avg batch loss: 0.0368, Avg batch acc: 0.9607
Train, Epoch: 5, Batch: 729, Step num: 6805, Learning rate: 0.00010715, Avg batch loss: 0.0426, Avg batch acc: 0.9565
Train, Epoch: 5, Batch: 730, Step num: 6806, Learning rate: 0.00010714, Avg batch loss: 0.0639, Avg batch acc: 0.9548
Train, Epoch: 5, Batch: 731, Step num: 6807, Learning rate: 0.00010713, Avg batch loss: 0.0467, Avg batch acc: 0.9662
Train, Epoch: 5, Batch: 732, Step num: 6808, Learning rate: 0.00010712, Avg batch loss: 0.0399, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 733, Step num: 6809, Learning rate: 0.00010712, Avg batch loss: 0.0436, Avg batch acc: 0.9542
Train, Epoch: 5, Batch: 734, Step num: 6810, Learning rate: 0.00010711, Avg batch loss: 0.0410, Avg batch acc: 0.9541
Train, Epoch: 5, Batch: 735, Step num: 6811, Learning rate: 0.00010710, Avg batch loss: 0.0328, Avg batch acc: 0.9678
Train, Epoch: 5, Batch: 736, Step num: 6812, Learning rate: 0.00010709, Avg batch loss: 0.0341, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 737, Step num: 6813, Learning rate: 0.00010708, Avg batch loss: 0.0403, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 738, Step num: 6814, Learning rate: 0.00010708, Avg batch loss: 0.0509, Avg batch acc: 0.9451
Train, Epoch: 5, Batch: 739, Step num: 6815, Learning rate: 0.00010707, Avg batch loss: 0.0574, Avg batch acc: 0.9551
Train, Epoch: 5, Batch: 740, Step num: 6816, Learning rate: 0.00010706, Avg batch loss: 0.0385, Avg batch acc: 0.9587
Train, Epoch: 5, Batch: 741, Step num: 6817, Learning rate: 0.00010705, Avg batch loss: 0.0395, Avg batch acc: 0.9606
Train, Epoch: 5, Batch: 742, Step num: 6818, Learning rate: 0.00010705, Avg batch loss: 0.0362, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 743, Step num: 6819, Learning rate: 0.00010704, Avg batch loss: 0.0395, Avg batch acc: 0.9627
Train, Epoch: 5, Batch: 744, Step num: 6820, Learning rate: 0.00010703, Avg batch loss: 0.0419, Avg batch acc: 0.9577
Train, Epoch: 5, Batch: 745, Step num: 6821, Learning rate: 0.00010702, Avg batch loss: 0.0424, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 746, Step num: 6822, Learning rate: 0.00010701, Avg batch loss: 0.0489, Avg batch acc: 0.9474
Train, Epoch: 5, Batch: 747, Step num: 6823, Learning rate: 0.00010701, Avg batch loss: 0.0407, Avg batch acc: 0.9599
Train, Epoch: 5, Batch: 748, Step num: 6824, Learning rate: 0.00010700, Avg batch loss: 0.0391, Avg batch acc: 0.9603
Train, Epoch: 5, Batch: 749, Step num: 6825, Learning rate: 0.00010699, Avg batch loss: 0.0387, Avg batch acc: 0.9577
Train, Epoch: 5, Batch: 750, Step num: 6826, Learning rate: 0.00010698, Avg batch loss: 0.0384, Avg batch acc: 0.9596
Train, Epoch: 5, Batch: 751, Step num: 6827, Learning rate: 0.00010697, Avg batch loss: 0.0460, Avg batch acc: 0.9502
Train, Epoch: 5, Batch: 752, Step num: 6828, Learning rate: 0.00010697, Avg batch loss: 0.0431, Avg batch acc: 0.9542
Train, Epoch: 5, Batch: 753, Step num: 6829, Learning rate: 0.00010696, Avg batch loss: 0.0440, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 754, Step num: 6830, Learning rate: 0.00010695, Avg batch loss: 0.0437, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 755, Step num: 6831, Learning rate: 0.00010694, Avg batch loss: 0.0393, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 756, Step num: 6832, Learning rate: 0.00010694, Avg batch loss: 0.0351, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 757, Step num: 6833, Learning rate: 0.00010693, Avg batch loss: 0.0487, Avg batch acc: 0.9598
Train, Epoch: 5, Batch: 758, Step num: 6834, Learning rate: 0.00010692, Avg batch loss: 0.0490, Avg batch acc: 0.9522
Train, Epoch: 5, Batch: 759, Step num: 6835, Learning rate: 0.00010691, Avg batch loss: 0.0411, Avg batch acc: 0.9563
Train, Epoch: 5, Batch: 760, Step num: 6836, Learning rate: 0.00010690, Avg batch loss: 0.0529, Avg batch acc: 0.9547
Train, Epoch: 5, Batch: 761, Step num: 6837, Learning rate: 0.00010690, Avg batch loss: 0.0380, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 762, Step num: 6838, Learning rate: 0.00010689, Avg batch loss: 0.0444, Avg batch acc: 0.9559
Train, Epoch: 5, Batch: 763, Step num: 6839, Learning rate: 0.00010688, Avg batch loss: 0.0351, Avg batch acc: 0.9637
Train, Epoch: 5, Batch: 764, Step num: 6840, Learning rate: 0.00010687, Avg batch loss: 0.0398, Avg batch acc: 0.9606
Train, Epoch: 5, Batch: 765, Step num: 6841, Learning rate: 0.00010686, Avg batch loss: 0.0358, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 766, Step num: 6842, Learning rate: 0.00010686, Avg batch loss: 0.0499, Avg batch acc: 0.9563
Train, Epoch: 5, Batch: 767, Step num: 6843, Learning rate: 0.00010685, Avg batch loss: 0.0371, Avg batch acc: 0.9694
Train, Epoch: 5, Batch: 768, Step num: 6844, Learning rate: 0.00010684, Avg batch loss: 0.0541, Avg batch acc: 0.9501
Train, Epoch: 5, Batch: 769, Step num: 6845, Learning rate: 0.00010683, Avg batch loss: 0.0333, Avg batch acc: 0.9680
Train, Epoch: 5, Batch: 770, Step num: 6846, Learning rate: 0.00010683, Avg batch loss: 0.0441, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 771, Step num: 6847, Learning rate: 0.00010682, Avg batch loss: 0.0355, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 772, Step num: 6848, Learning rate: 0.00010681, Avg batch loss: 0.0370, Avg batch acc: 0.9623
Train, Epoch: 5, Batch: 773, Step num: 6849, Learning rate: 0.00010680, Avg batch loss: 0.0462, Avg batch acc: 0.9631
Train, Epoch: 5, Batch: 774, Step num: 6850, Learning rate: 0.00010679, Avg batch loss: 0.0343, Avg batch acc: 0.9697
Train, Epoch: 5, Batch: 775, Step num: 6851, Learning rate: 0.00010679, Avg batch loss: 0.0345, Avg batch acc: 0.9615
Train, Epoch: 5, Batch: 776, Step num: 6852, Learning rate: 0.00010678, Avg batch loss: 0.0488, Avg batch acc: 0.9551
Train, Epoch: 5, Batch: 777, Step num: 6853, Learning rate: 0.00010677, Avg batch loss: 0.0404, Avg batch acc: 0.9608
Train, Epoch: 5, Batch: 778, Step num: 6854, Learning rate: 0.00010676, Avg batch loss: 0.0413, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 779, Step num: 6855, Learning rate: 0.00010676, Avg batch loss: 0.0446, Avg batch acc: 0.9609
Train, Epoch: 5, Batch: 780, Step num: 6856, Learning rate: 0.00010675, Avg batch loss: 0.0472, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 781, Step num: 6857, Learning rate: 0.00010674, Avg batch loss: 0.0355, Avg batch acc: 0.9675
Train, Epoch: 5, Batch: 782, Step num: 6858, Learning rate: 0.00010673, Avg batch loss: 0.0355, Avg batch acc: 0.9618
Train, Epoch: 5, Batch: 783, Step num: 6859, Learning rate: 0.00010672, Avg batch loss: 0.0294, Avg batch acc: 0.9661
Train, Epoch: 5, Batch: 784, Step num: 6860, Learning rate: 0.00010672, Avg batch loss: 0.0438, Avg batch acc: 0.9614
Train, Epoch: 5, Batch: 785, Step num: 6861, Learning rate: 0.00010671, Avg batch loss: 0.0418, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 786, Step num: 6862, Learning rate: 0.00010670, Avg batch loss: 0.0510, Avg batch acc: 0.9587
Train, Epoch: 5, Batch: 787, Step num: 6863, Learning rate: 0.00010669, Avg batch loss: 0.0440, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 788, Step num: 6864, Learning rate: 0.00010669, Avg batch loss: 0.0391, Avg batch acc: 0.9617
Train, Epoch: 5, Batch: 789, Step num: 6865, Learning rate: 0.00010668, Avg batch loss: 0.0314, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 790, Step num: 6866, Learning rate: 0.00010667, Avg batch loss: 0.0430, Avg batch acc: 0.9536
Train, Epoch: 5, Batch: 791, Step num: 6867, Learning rate: 0.00010666, Avg batch loss: 0.0537, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 792, Step num: 6868, Learning rate: 0.00010665, Avg batch loss: 0.0350, Avg batch acc: 0.9667
Train, Epoch: 5, Batch: 793, Step num: 6869, Learning rate: 0.00010665, Avg batch loss: 0.0393, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 794, Step num: 6870, Learning rate: 0.00010664, Avg batch loss: 0.0510, Avg batch acc: 0.9519
Train, Epoch: 5, Batch: 795, Step num: 6871, Learning rate: 0.00010663, Avg batch loss: 0.0354, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 796, Step num: 6872, Learning rate: 0.00010662, Avg batch loss: 0.0451, Avg batch acc: 0.9512
Train, Epoch: 5, Batch: 797, Step num: 6873, Learning rate: 0.00010662, Avg batch loss: 0.0347, Avg batch acc: 0.9703
Train, Epoch: 5, Batch: 798, Step num: 6874, Learning rate: 0.00010661, Avg batch loss: 0.0343, Avg batch acc: 0.9630
Train, Epoch: 5, Batch: 799, Step num: 6875, Learning rate: 0.00010660, Avg batch loss: 0.0341, Avg batch acc: 0.9677
Train, Epoch: 5, Batch: 800, Step num: 6876, Learning rate: 0.00010659, Avg batch loss: 0.0310, Avg batch acc: 0.9698
Train, Epoch: 5, Batch: 801, Step num: 6877, Learning rate: 0.00010658, Avg batch loss: 0.0439, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 802, Step num: 6878, Learning rate: 0.00010658, Avg batch loss: 0.0282, Avg batch acc: 0.9701
Train, Epoch: 5, Batch: 803, Step num: 6879, Learning rate: 0.00010657, Avg batch loss: 0.0397, Avg batch acc: 0.9637
Train, Epoch: 5, Batch: 804, Step num: 6880, Learning rate: 0.00010656, Avg batch loss: 0.0381, Avg batch acc: 0.9604
Train, Epoch: 5, Batch: 805, Step num: 6881, Learning rate: 0.00010655, Avg batch loss: 0.0338, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 806, Step num: 6882, Learning rate: 0.00010655, Avg batch loss: 0.0469, Avg batch acc: 0.9610
Train, Epoch: 5, Batch: 807, Step num: 6883, Learning rate: 0.00010654, Avg batch loss: 0.0445, Avg batch acc: 0.9618
Train, Epoch: 5, Batch: 808, Step num: 6884, Learning rate: 0.00010653, Avg batch loss: 0.0403, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 809, Step num: 6885, Learning rate: 0.00010652, Avg batch loss: 0.0393, Avg batch acc: 0.9543
Train, Epoch: 5, Batch: 810, Step num: 6886, Learning rate: 0.00010652, Avg batch loss: 0.0338, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 811, Step num: 6887, Learning rate: 0.00010651, Avg batch loss: 0.0394, Avg batch acc: 0.9609
Train, Epoch: 5, Batch: 812, Step num: 6888, Learning rate: 0.00010650, Avg batch loss: 0.0392, Avg batch acc: 0.9607
Train, Epoch: 5, Batch: 813, Step num: 6889, Learning rate: 0.00010649, Avg batch loss: 0.0381, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 814, Step num: 6890, Learning rate: 0.00010648, Avg batch loss: 0.0452, Avg batch acc: 0.9602
Train, Epoch: 5, Batch: 815, Step num: 6891, Learning rate: 0.00010648, Avg batch loss: 0.0330, Avg batch acc: 0.9604
Train, Epoch: 5, Batch: 816, Step num: 6892, Learning rate: 0.00010647, Avg batch loss: 0.0420, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 817, Step num: 6893, Learning rate: 0.00010646, Avg batch loss: 0.0357, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 818, Step num: 6894, Learning rate: 0.00010645, Avg batch loss: 0.0421, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 819, Step num: 6895, Learning rate: 0.00010645, Avg batch loss: 0.0410, Avg batch acc: 0.9607
Train, Epoch: 5, Batch: 820, Step num: 6896, Learning rate: 0.00010644, Avg batch loss: 0.0397, Avg batch acc: 0.9637
Train, Epoch: 5, Batch: 821, Step num: 6897, Learning rate: 0.00010643, Avg batch loss: 0.0421, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 822, Step num: 6898, Learning rate: 0.00010642, Avg batch loss: 0.0406, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 823, Step num: 6899, Learning rate: 0.00010641, Avg batch loss: 0.0427, Avg batch acc: 0.9587
Train, Epoch: 5, Batch: 824, Step num: 6900, Learning rate: 0.00010641, Avg batch loss: 0.0374, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 825, Step num: 6901, Learning rate: 0.00010640, Avg batch loss: 0.0337, Avg batch acc: 0.9687
Train, Epoch: 5, Batch: 826, Step num: 6902, Learning rate: 0.00010639, Avg batch loss: 0.0652, Avg batch acc: 0.9460
Train, Epoch: 5, Batch: 827, Step num: 6903, Learning rate: 0.00010638, Avg batch loss: 0.0384, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 828, Step num: 6904, Learning rate: 0.00010638, Avg batch loss: 0.0365, Avg batch acc: 0.9605
Train, Epoch: 5, Batch: 829, Step num: 6905, Learning rate: 0.00010637, Avg batch loss: 0.0361, Avg batch acc: 0.9594
Train, Epoch: 5, Batch: 830, Step num: 6906, Learning rate: 0.00010636, Avg batch loss: 0.0409, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 831, Step num: 6907, Learning rate: 0.00010635, Avg batch loss: 0.0374, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 832, Step num: 6908, Learning rate: 0.00010635, Avg batch loss: 0.0403, Avg batch acc: 0.9597
Train, Epoch: 5, Batch: 833, Step num: 6909, Learning rate: 0.00010634, Avg batch loss: 0.0371, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 834, Step num: 6910, Learning rate: 0.00010633, Avg batch loss: 0.0448, Avg batch acc: 0.9571
Train, Epoch: 5, Batch: 835, Step num: 6911, Learning rate: 0.00010632, Avg batch loss: 0.0440, Avg batch acc: 0.9546
Train, Epoch: 5, Batch: 836, Step num: 6912, Learning rate: 0.00010631, Avg batch loss: 0.0329, Avg batch acc: 0.9698
Train, Epoch: 5, Batch: 837, Step num: 6913, Learning rate: 0.00010631, Avg batch loss: 0.0400, Avg batch acc: 0.9633
Train, Epoch: 5, Batch: 838, Step num: 6914, Learning rate: 0.00010630, Avg batch loss: 0.0371, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 839, Step num: 6915, Learning rate: 0.00010629, Avg batch loss: 0.0475, Avg batch acc: 0.9540
Train, Epoch: 5, Batch: 840, Step num: 6916, Learning rate: 0.00010628, Avg batch loss: 0.0435, Avg batch acc: 0.9623
Train, Epoch: 5, Batch: 841, Step num: 6917, Learning rate: 0.00010628, Avg batch loss: 0.0360, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 842, Step num: 6918, Learning rate: 0.00010627, Avg batch loss: 0.0359, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 843, Step num: 6919, Learning rate: 0.00010626, Avg batch loss: 0.0342, Avg batch acc: 0.9660
Train, Epoch: 5, Batch: 844, Step num: 6920, Learning rate: 0.00010625, Avg batch loss: 0.0383, Avg batch acc: 0.9575
Train, Epoch: 5, Batch: 845, Step num: 6921, Learning rate: 0.00010625, Avg batch loss: 0.0351, Avg batch acc: 0.9647
Train, Epoch: 5, Batch: 846, Step num: 6922, Learning rate: 0.00010624, Avg batch loss: 0.0447, Avg batch acc: 0.9585
Train, Epoch: 5, Batch: 847, Step num: 6923, Learning rate: 0.00010623, Avg batch loss: 0.0409, Avg batch acc: 0.9609
Train, Epoch: 5, Batch: 848, Step num: 6924, Learning rate: 0.00010622, Avg batch loss: 0.0390, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 849, Step num: 6925, Learning rate: 0.00010621, Avg batch loss: 0.0421, Avg batch acc: 0.9517
Train, Epoch: 5, Batch: 850, Step num: 6926, Learning rate: 0.00010621, Avg batch loss: 0.0371, Avg batch acc: 0.9574
Train, Epoch: 5, Batch: 851, Step num: 6927, Learning rate: 0.00010620, Avg batch loss: 0.0591, Avg batch acc: 0.9532
Train, Epoch: 5, Batch: 852, Step num: 6928, Learning rate: 0.00010619, Avg batch loss: 0.0367, Avg batch acc: 0.9631
Train, Epoch: 5, Batch: 853, Step num: 6929, Learning rate: 0.00010618, Avg batch loss: 0.0450, Avg batch acc: 0.9557
Train, Epoch: 5, Batch: 854, Step num: 6930, Learning rate: 0.00010618, Avg batch loss: 0.0514, Avg batch acc: 0.9469
Train, Epoch: 5, Batch: 855, Step num: 6931, Learning rate: 0.00010617, Avg batch loss: 0.0369, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 856, Step num: 6932, Learning rate: 0.00010616, Avg batch loss: 0.0382, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 857, Step num: 6933, Learning rate: 0.00010615, Avg batch loss: 0.0445, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 858, Step num: 6934, Learning rate: 0.00010615, Avg batch loss: 0.0449, Avg batch acc: 0.9567
Train, Epoch: 5, Batch: 859, Step num: 6935, Learning rate: 0.00010614, Avg batch loss: 0.0359, Avg batch acc: 0.9631
Train, Epoch: 5, Batch: 860, Step num: 6936, Learning rate: 0.00010613, Avg batch loss: 0.0337, Avg batch acc: 0.9674
Train, Epoch: 5, Batch: 861, Step num: 6937, Learning rate: 0.00010612, Avg batch loss: 0.0411, Avg batch acc: 0.9567
Train, Epoch: 5, Batch: 862, Step num: 6938, Learning rate: 0.00010612, Avg batch loss: 0.0357, Avg batch acc: 0.9585
Train, Epoch: 5, Batch: 863, Step num: 6939, Learning rate: 0.00010611, Avg batch loss: 0.0404, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 864, Step num: 6940, Learning rate: 0.00010610, Avg batch loss: 0.0402, Avg batch acc: 0.9592
Train, Epoch: 5, Batch: 865, Step num: 6941, Learning rate: 0.00010609, Avg batch loss: 0.0427, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 866, Step num: 6942, Learning rate: 0.00010608, Avg batch loss: 0.0379, Avg batch acc: 0.9555
Train, Epoch: 5, Batch: 867, Step num: 6943, Learning rate: 0.00010608, Avg batch loss: 0.0380, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 868, Step num: 6944, Learning rate: 0.00010607, Avg batch loss: 0.0437, Avg batch acc: 0.9550
Train, Epoch: 5, Batch: 869, Step num: 6945, Learning rate: 0.00010606, Avg batch loss: 0.0390, Avg batch acc: 0.9542
Train, Epoch: 5, Batch: 870, Step num: 6946, Learning rate: 0.00010605, Avg batch loss: 0.0382, Avg batch acc: 0.9617
Train, Epoch: 5, Batch: 871, Step num: 6947, Learning rate: 0.00010605, Avg batch loss: 0.0399, Avg batch acc: 0.9615
Train, Epoch: 5, Batch: 872, Step num: 6948, Learning rate: 0.00010604, Avg batch loss: 0.0319, Avg batch acc: 0.9668
Train, Epoch: 5, Batch: 873, Step num: 6949, Learning rate: 0.00010603, Avg batch loss: 0.0301, Avg batch acc: 0.9679
Train, Epoch: 5, Batch: 874, Step num: 6950, Learning rate: 0.00010602, Avg batch loss: 0.0391, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 875, Step num: 6951, Learning rate: 0.00010602, Avg batch loss: 0.0349, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 876, Step num: 6952, Learning rate: 0.00010601, Avg batch loss: 0.0425, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 877, Step num: 6953, Learning rate: 0.00010600, Avg batch loss: 0.0482, Avg batch acc: 0.9544
Train, Epoch: 5, Batch: 878, Step num: 6954, Learning rate: 0.00010599, Avg batch loss: 0.0452, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 879, Step num: 6955, Learning rate: 0.00010599, Avg batch loss: 0.0326, Avg batch acc: 0.9695
Train, Epoch: 5, Batch: 880, Step num: 6956, Learning rate: 0.00010598, Avg batch loss: 0.0333, Avg batch acc: 0.9639
Train, Epoch: 5, Batch: 881, Step num: 6957, Learning rate: 0.00010597, Avg batch loss: 0.0404, Avg batch acc: 0.9596
Train, Epoch: 5, Batch: 882, Step num: 6958, Learning rate: 0.00010596, Avg batch loss: 0.0429, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 883, Step num: 6959, Learning rate: 0.00010596, Avg batch loss: 0.0383, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 884, Step num: 6960, Learning rate: 0.00010595, Avg batch loss: 0.0381, Avg batch acc: 0.9651
Train, Epoch: 5, Batch: 885, Step num: 6961, Learning rate: 0.00010594, Avg batch loss: 0.0344, Avg batch acc: 0.9660
Train, Epoch: 5, Batch: 886, Step num: 6962, Learning rate: 0.00010593, Avg batch loss: 0.0369, Avg batch acc: 0.9627
Train, Epoch: 5, Batch: 887, Step num: 6963, Learning rate: 0.00010592, Avg batch loss: 0.0389, Avg batch acc: 0.9651
Train, Epoch: 5, Batch: 888, Step num: 6964, Learning rate: 0.00010592, Avg batch loss: 0.0371, Avg batch acc: 0.9618
Train, Epoch: 5, Batch: 889, Step num: 6965, Learning rate: 0.00010591, Avg batch loss: 0.0345, Avg batch acc: 0.9673
Train, Epoch: 5, Batch: 890, Step num: 6966, Learning rate: 0.00010590, Avg batch loss: 0.0470, Avg batch acc: 0.9597
Train, Epoch: 5, Batch: 891, Step num: 6967, Learning rate: 0.00010589, Avg batch loss: 0.0310, Avg batch acc: 0.9665
Train, Epoch: 5, Batch: 892, Step num: 6968, Learning rate: 0.00010589, Avg batch loss: 0.0347, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 893, Step num: 6969, Learning rate: 0.00010588, Avg batch loss: 0.0394, Avg batch acc: 0.9572
Train, Epoch: 5, Batch: 894, Step num: 6970, Learning rate: 0.00010587, Avg batch loss: 0.0364, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 895, Step num: 6971, Learning rate: 0.00010586, Avg batch loss: 0.0324, Avg batch acc: 0.9621
Train, Epoch: 5, Batch: 896, Step num: 6972, Learning rate: 0.00010586, Avg batch loss: 0.0409, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 897, Step num: 6973, Learning rate: 0.00010585, Avg batch loss: 0.0406, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 898, Step num: 6974, Learning rate: 0.00010584, Avg batch loss: 0.0432, Avg batch acc: 0.9561
Train, Epoch: 5, Batch: 899, Step num: 6975, Learning rate: 0.00010583, Avg batch loss: 0.0358, Avg batch acc: 0.9659
Train, Epoch: 5, Batch: 900, Step num: 6976, Learning rate: 0.00010583, Avg batch loss: 0.0347, Avg batch acc: 0.9629
Train, Epoch: 5, Batch: 901, Step num: 6977, Learning rate: 0.00010582, Avg batch loss: 0.0341, Avg batch acc: 0.9648
Train, Epoch: 5, Batch: 902, Step num: 6978, Learning rate: 0.00010581, Avg batch loss: 0.0373, Avg batch acc: 0.9614
Train, Epoch: 5, Batch: 903, Step num: 6979, Learning rate: 0.00010580, Avg batch loss: 0.0312, Avg batch acc: 0.9710
Train, Epoch: 5, Batch: 904, Step num: 6980, Learning rate: 0.00010580, Avg batch loss: 0.0293, Avg batch acc: 0.9669
Train, Epoch: 5, Batch: 905, Step num: 6981, Learning rate: 0.00010579, Avg batch loss: 0.0321, Avg batch acc: 0.9672
Train, Epoch: 5, Batch: 906, Step num: 6982, Learning rate: 0.00010578, Avg batch loss: 0.0300, Avg batch acc: 0.9614
Train, Epoch: 5, Batch: 907, Step num: 6983, Learning rate: 0.00010577, Avg batch loss: 0.0533, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 908, Step num: 6984, Learning rate: 0.00010577, Avg batch loss: 0.0342, Avg batch acc: 0.9662
Train, Epoch: 5, Batch: 909, Step num: 6985, Learning rate: 0.00010576, Avg batch loss: 0.0300, Avg batch acc: 0.9724
Train, Epoch: 5, Batch: 910, Step num: 6986, Learning rate: 0.00010575, Avg batch loss: 0.0466, Avg batch acc: 0.9597
Train, Epoch: 5, Batch: 911, Step num: 6987, Learning rate: 0.00010574, Avg batch loss: 0.0598, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 912, Step num: 6988, Learning rate: 0.00010573, Avg batch loss: 0.0345, Avg batch acc: 0.9663
Train, Epoch: 5, Batch: 913, Step num: 6989, Learning rate: 0.00010573, Avg batch loss: 0.0480, Avg batch acc: 0.9607
Train, Epoch: 5, Batch: 914, Step num: 6990, Learning rate: 0.00010572, Avg batch loss: 0.0433, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 915, Step num: 6991, Learning rate: 0.00010571, Avg batch loss: 0.0403, Avg batch acc: 0.9602
Train, Epoch: 5, Batch: 916, Step num: 6992, Learning rate: 0.00010570, Avg batch loss: 0.0341, Avg batch acc: 0.9640
Train, Epoch: 5, Batch: 917, Step num: 6993, Learning rate: 0.00010570, Avg batch loss: 0.0467, Avg batch acc: 0.9526
Train, Epoch: 5, Batch: 918, Step num: 6994, Learning rate: 0.00010569, Avg batch loss: 0.0389, Avg batch acc: 0.9607
Train, Epoch: 5, Batch: 919, Step num: 6995, Learning rate: 0.00010568, Avg batch loss: 0.0320, Avg batch acc: 0.9671
Train, Epoch: 5, Batch: 920, Step num: 6996, Learning rate: 0.00010567, Avg batch loss: 0.0386, Avg batch acc: 0.9555
Train, Epoch: 5, Batch: 921, Step num: 6997, Learning rate: 0.00010567, Avg batch loss: 0.0307, Avg batch acc: 0.9642
Train, Epoch: 5, Batch: 922, Step num: 6998, Learning rate: 0.00010566, Avg batch loss: 0.0421, Avg batch acc: 0.9587
Train, Epoch: 5, Batch: 923, Step num: 6999, Learning rate: 0.00010565, Avg batch loss: 0.0751, Avg batch acc: 0.9551
Train, Epoch: 5, Batch: 924, Step num: 7000, Learning rate: 0.00010564, Avg batch loss: 0.0850, Avg batch acc: 0.9525
Train, Epoch: 5, Batch: 925, Step num: 7001, Learning rate: 0.00010564, Avg batch loss: 0.0360, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 926, Step num: 7002, Learning rate: 0.00010563, Avg batch loss: 0.0487, Avg batch acc: 0.9552
Train, Epoch: 5, Batch: 927, Step num: 7003, Learning rate: 0.00010562, Avg batch loss: 0.0523, Avg batch acc: 0.9535
Train, Epoch: 5, Batch: 928, Step num: 7004, Learning rate: 0.00010561, Avg batch loss: 0.0345, Avg batch acc: 0.9561
Train, Epoch: 5, Batch: 929, Step num: 7005, Learning rate: 0.00010561, Avg batch loss: 0.0344, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 930, Step num: 7006, Learning rate: 0.00010560, Avg batch loss: 0.0480, Avg batch acc: 0.9610
Train, Epoch: 5, Batch: 931, Step num: 7007, Learning rate: 0.00010559, Avg batch loss: 0.0310, Avg batch acc: 0.9671
Train, Epoch: 5, Batch: 932, Step num: 7008, Learning rate: 0.00010558, Avg batch loss: 0.0413, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 933, Step num: 7009, Learning rate: 0.00010558, Avg batch loss: 0.0442, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 934, Step num: 7010, Learning rate: 0.00010557, Avg batch loss: 0.0414, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 935, Step num: 7011, Learning rate: 0.00010556, Avg batch loss: 0.0347, Avg batch acc: 0.9678
Train, Epoch: 5, Batch: 936, Step num: 7012, Learning rate: 0.00010555, Avg batch loss: 0.0329, Avg batch acc: 0.9652
Train, Epoch: 5, Batch: 937, Step num: 7013, Learning rate: 0.00010555, Avg batch loss: 0.0438, Avg batch acc: 0.9542
Train, Epoch: 5, Batch: 938, Step num: 7014, Learning rate: 0.00010554, Avg batch loss: 0.0502, Avg batch acc: 0.9597
Train, Epoch: 5, Batch: 939, Step num: 7015, Learning rate: 0.00010553, Avg batch loss: 0.0405, Avg batch acc: 0.9605
Train, Epoch: 5, Batch: 940, Step num: 7016, Learning rate: 0.00010552, Avg batch loss: 0.0349, Avg batch acc: 0.9652
Train, Epoch: 5, Batch: 941, Step num: 7017, Learning rate: 0.00010552, Avg batch loss: 0.0414, Avg batch acc: 0.9616
Train, Epoch: 5, Batch: 942, Step num: 7018, Learning rate: 0.00010551, Avg batch loss: 0.0366, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 943, Step num: 7019, Learning rate: 0.00010550, Avg batch loss: 0.0411, Avg batch acc: 0.9631
Train, Epoch: 5, Batch: 944, Step num: 7020, Learning rate: 0.00010549, Avg batch loss: 0.0375, Avg batch acc: 0.9648
Train, Epoch: 5, Batch: 945, Step num: 7021, Learning rate: 0.00010549, Avg batch loss: 0.0369, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 946, Step num: 7022, Learning rate: 0.00010548, Avg batch loss: 0.0369, Avg batch acc: 0.9608
Train, Epoch: 5, Batch: 947, Step num: 7023, Learning rate: 0.00010547, Avg batch loss: 0.0433, Avg batch acc: 0.9605
Train, Epoch: 5, Batch: 948, Step num: 7024, Learning rate: 0.00010546, Avg batch loss: 0.0374, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 949, Step num: 7025, Learning rate: 0.00010546, Avg batch loss: 0.0448, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 950, Step num: 7026, Learning rate: 0.00010545, Avg batch loss: 0.0434, Avg batch acc: 0.9618
Train, Epoch: 5, Batch: 951, Step num: 7027, Learning rate: 0.00010544, Avg batch loss: 0.0363, Avg batch acc: 0.9640
Train, Epoch: 5, Batch: 952, Step num: 7028, Learning rate: 0.00010543, Avg batch loss: 0.0409, Avg batch acc: 0.9600
Train, Epoch: 5, Batch: 953, Step num: 7029, Learning rate: 0.00010543, Avg batch loss: 0.0402, Avg batch acc: 0.9634
Train, Epoch: 5, Batch: 954, Step num: 7030, Learning rate: 0.00010542, Avg batch loss: 0.0368, Avg batch acc: 0.9666
Train, Epoch: 5, Batch: 955, Step num: 7031, Learning rate: 0.00010541, Avg batch loss: 0.0357, Avg batch acc: 0.9668
Train, Epoch: 5, Batch: 956, Step num: 7032, Learning rate: 0.00010540, Avg batch loss: 0.0368, Avg batch acc: 0.9604
Train, Epoch: 5, Batch: 957, Step num: 7033, Learning rate: 0.00010540, Avg batch loss: 0.0347, Avg batch acc: 0.9681
Train, Epoch: 5, Batch: 958, Step num: 7034, Learning rate: 0.00010539, Avg batch loss: 0.0407, Avg batch acc: 0.9599
Train, Epoch: 5, Batch: 959, Step num: 7035, Learning rate: 0.00010538, Avg batch loss: 0.0296, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 960, Step num: 7036, Learning rate: 0.00010537, Avg batch loss: 0.0411, Avg batch acc: 0.9631
Train, Epoch: 5, Batch: 961, Step num: 7037, Learning rate: 0.00010537, Avg batch loss: 0.0386, Avg batch acc: 0.9652
Train, Epoch: 5, Batch: 962, Step num: 7038, Learning rate: 0.00010536, Avg batch loss: 0.0331, Avg batch acc: 0.9663
Train, Epoch: 5, Batch: 963, Step num: 7039, Learning rate: 0.00010535, Avg batch loss: 0.0400, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 964, Step num: 7040, Learning rate: 0.00010534, Avg batch loss: 0.0437, Avg batch acc: 0.9569
Train, Epoch: 5, Batch: 965, Step num: 7041, Learning rate: 0.00010534, Avg batch loss: 0.0457, Avg batch acc: 0.9559
Train, Epoch: 5, Batch: 966, Step num: 7042, Learning rate: 0.00010533, Avg batch loss: 0.0348, Avg batch acc: 0.9649
Train, Epoch: 5, Batch: 967, Step num: 7043, Learning rate: 0.00010532, Avg batch loss: 0.0361, Avg batch acc: 0.9584
Train, Epoch: 5, Batch: 968, Step num: 7044, Learning rate: 0.00010531, Avg batch loss: 0.0502, Avg batch acc: 0.9602
Train, Epoch: 5, Batch: 969, Step num: 7045, Learning rate: 0.00010531, Avg batch loss: 0.0379, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 970, Step num: 7046, Learning rate: 0.00010530, Avg batch loss: 0.0369, Avg batch acc: 0.9620
Train, Epoch: 5, Batch: 971, Step num: 7047, Learning rate: 0.00010529, Avg batch loss: 0.0404, Avg batch acc: 0.9581
Train, Epoch: 5, Batch: 972, Step num: 7048, Learning rate: 0.00010528, Avg batch loss: 0.0372, Avg batch acc: 0.9589
Train, Epoch: 5, Batch: 973, Step num: 7049, Learning rate: 0.00010528, Avg batch loss: 0.0331, Avg batch acc: 0.9705
Train, Epoch: 5, Batch: 974, Step num: 7050, Learning rate: 0.00010527, Avg batch loss: 0.0471, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 975, Step num: 7051, Learning rate: 0.00010526, Avg batch loss: 0.0370, Avg batch acc: 0.9616
Train, Epoch: 5, Batch: 976, Step num: 7052, Learning rate: 0.00010525, Avg batch loss: 0.0362, Avg batch acc: 0.9581
Train, Epoch: 5, Batch: 977, Step num: 7053, Learning rate: 0.00010525, Avg batch loss: 0.0419, Avg batch acc: 0.9623
Train, Epoch: 5, Batch: 978, Step num: 7054, Learning rate: 0.00010524, Avg batch loss: 0.0288, Avg batch acc: 0.9687
Train, Epoch: 5, Batch: 979, Step num: 7055, Learning rate: 0.00010523, Avg batch loss: 0.0491, Avg batch acc: 0.9554
Train, Epoch: 5, Batch: 980, Step num: 7056, Learning rate: 0.00010522, Avg batch loss: 0.0312, Avg batch acc: 0.9656
Train, Epoch: 5, Batch: 981, Step num: 7057, Learning rate: 0.00010522, Avg batch loss: 0.0400, Avg batch acc: 0.9620
Train, Epoch: 5, Batch: 982, Step num: 7058, Learning rate: 0.00010521, Avg batch loss: 0.0353, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 983, Step num: 7059, Learning rate: 0.00010520, Avg batch loss: 0.0422, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 984, Step num: 7060, Learning rate: 0.00010519, Avg batch loss: 0.0342, Avg batch acc: 0.9602
Train, Epoch: 5, Batch: 985, Step num: 7061, Learning rate: 0.00010519, Avg batch loss: 0.0400, Avg batch acc: 0.9614
Train, Epoch: 5, Batch: 986, Step num: 7062, Learning rate: 0.00010518, Avg batch loss: 0.0410, Avg batch acc: 0.9620
Train, Epoch: 5, Batch: 987, Step num: 7063, Learning rate: 0.00010517, Avg batch loss: 0.0437, Avg batch acc: 0.9612
Train, Epoch: 5, Batch: 988, Step num: 7064, Learning rate: 0.00010516, Avg batch loss: 0.0431, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 989, Step num: 7065, Learning rate: 0.00010516, Avg batch loss: 0.0406, Avg batch acc: 0.9620
Train, Epoch: 5, Batch: 990, Step num: 7066, Learning rate: 0.00010515, Avg batch loss: 0.0354, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 991, Step num: 7067, Learning rate: 0.00010514, Avg batch loss: 0.0292, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 992, Step num: 7068, Learning rate: 0.00010513, Avg batch loss: 0.0354, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 993, Step num: 7069, Learning rate: 0.00010513, Avg batch loss: 0.0297, Avg batch acc: 0.9652
Train, Epoch: 5, Batch: 994, Step num: 7070, Learning rate: 0.00010512, Avg batch loss: 0.0390, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 995, Step num: 7071, Learning rate: 0.00010511, Avg batch loss: 0.0439, Avg batch acc: 0.9647
Train, Epoch: 5, Batch: 996, Step num: 7072, Learning rate: 0.00010511, Avg batch loss: 0.0329, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 997, Step num: 7073, Learning rate: 0.00010510, Avg batch loss: 0.0303, Avg batch acc: 0.9725
Train, Epoch: 5, Batch: 998, Step num: 7074, Learning rate: 0.00010509, Avg batch loss: 0.0351, Avg batch acc: 0.9646
Train, Epoch: 5, Batch: 999, Step num: 7075, Learning rate: 0.00010508, Avg batch loss: 0.0595, Avg batch acc: 0.9559
Train, Epoch: 5, Batch: 1000, Step num: 7076, Learning rate: 0.00010508, Avg batch loss: 0.0477, Avg batch acc: 0.9497
Train, Epoch: 5, Batch: 1001, Step num: 7077, Learning rate: 0.00010507, Avg batch loss: 0.0408, Avg batch acc: 0.9606
Train, Epoch: 5, Batch: 1002, Step num: 7078, Learning rate: 0.00010506, Avg batch loss: 0.0329, Avg batch acc: 0.9712
Train, Epoch: 5, Batch: 1003, Step num: 7079, Learning rate: 0.00010505, Avg batch loss: 0.0374, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 1004, Step num: 7080, Learning rate: 0.00010505, Avg batch loss: 0.0353, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 1005, Step num: 7081, Learning rate: 0.00010504, Avg batch loss: 0.0396, Avg batch acc: 0.9596
Train, Epoch: 5, Batch: 1006, Step num: 7082, Learning rate: 0.00010503, Avg batch loss: 0.0363, Avg batch acc: 0.9671
Train, Epoch: 5, Batch: 1007, Step num: 7083, Learning rate: 0.00010502, Avg batch loss: 0.0308, Avg batch acc: 0.9665
Train, Epoch: 5, Batch: 1008, Step num: 7084, Learning rate: 0.00010502, Avg batch loss: 0.0386, Avg batch acc: 0.9644
Train, Epoch: 5, Batch: 1009, Step num: 7085, Learning rate: 0.00010501, Avg batch loss: 0.0403, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 1010, Step num: 7086, Learning rate: 0.00010500, Avg batch loss: 0.0383, Avg batch acc: 0.9612
Train, Epoch: 5, Batch: 1011, Step num: 7087, Learning rate: 0.00010499, Avg batch loss: 0.0285, Avg batch acc: 0.9734
Train, Epoch: 5, Batch: 1012, Step num: 7088, Learning rate: 0.00010499, Avg batch loss: 0.0383, Avg batch acc: 0.9669
Train, Epoch: 5, Batch: 1013, Step num: 7089, Learning rate: 0.00010498, Avg batch loss: 0.0362, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 1014, Step num: 7090, Learning rate: 0.00010497, Avg batch loss: 0.0382, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 1015, Step num: 7091, Learning rate: 0.00010496, Avg batch loss: 0.0373, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 1016, Step num: 7092, Learning rate: 0.00010496, Avg batch loss: 0.0276, Avg batch acc: 0.9700
Train, Epoch: 5, Batch: 1017, Step num: 7093, Learning rate: 0.00010495, Avg batch loss: 0.0378, Avg batch acc: 0.9581
Train, Epoch: 5, Batch: 1018, Step num: 7094, Learning rate: 0.00010494, Avg batch loss: 0.0357, Avg batch acc: 0.9663
Train, Epoch: 5, Batch: 1019, Step num: 7095, Learning rate: 0.00010493, Avg batch loss: 0.0343, Avg batch acc: 0.9623
Train, Epoch: 5, Batch: 1020, Step num: 7096, Learning rate: 0.00010493, Avg batch loss: 0.0371, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 1021, Step num: 7097, Learning rate: 0.00010492, Avg batch loss: 0.0341, Avg batch acc: 0.9669
Train, Epoch: 5, Batch: 1022, Step num: 7098, Learning rate: 0.00010491, Avg batch loss: 0.0311, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 1023, Step num: 7099, Learning rate: 0.00010491, Avg batch loss: 0.0459, Avg batch acc: 0.9497
Train, Epoch: 5, Batch: 1024, Step num: 7100, Learning rate: 0.00010490, Avg batch loss: 0.0362, Avg batch acc: 0.9658
Train, Epoch: 5, Batch: 1025, Step num: 7101, Learning rate: 0.00010489, Avg batch loss: 0.0432, Avg batch acc: 0.9647
Train, Epoch: 5, Batch: 1026, Step num: 7102, Learning rate: 0.00010488, Avg batch loss: 0.0386, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 1027, Step num: 7103, Learning rate: 0.00010488, Avg batch loss: 0.0315, Avg batch acc: 0.9678
Train, Epoch: 5, Batch: 1028, Step num: 7104, Learning rate: 0.00010487, Avg batch loss: 0.0317, Avg batch acc: 0.9728
Train, Epoch: 5, Batch: 1029, Step num: 7105, Learning rate: 0.00010486, Avg batch loss: 0.0367, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 1030, Step num: 7106, Learning rate: 0.00010485, Avg batch loss: 0.0363, Avg batch acc: 0.9698
Train, Epoch: 5, Batch: 1031, Step num: 7107, Learning rate: 0.00010485, Avg batch loss: 0.0351, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 1032, Step num: 7108, Learning rate: 0.00010484, Avg batch loss: 0.0303, Avg batch acc: 0.9728
Train, Epoch: 5, Batch: 1033, Step num: 7109, Learning rate: 0.00010483, Avg batch loss: 0.0436, Avg batch acc: 0.9553
Train, Epoch: 5, Batch: 1034, Step num: 7110, Learning rate: 0.00010482, Avg batch loss: 0.0332, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 1035, Step num: 7111, Learning rate: 0.00010482, Avg batch loss: 0.0426, Avg batch acc: 0.9597
Train, Epoch: 5, Batch: 1036, Step num: 7112, Learning rate: 0.00010481, Avg batch loss: 0.0325, Avg batch acc: 0.9634
Train, Epoch: 5, Batch: 1037, Step num: 7113, Learning rate: 0.00010480, Avg batch loss: 0.0392, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 1038, Step num: 7114, Learning rate: 0.00010479, Avg batch loss: 0.0384, Avg batch acc: 0.9675
Train, Epoch: 5, Batch: 1039, Step num: 7115, Learning rate: 0.00010479, Avg batch loss: 0.0584, Avg batch acc: 0.9573
Train, Epoch: 5, Batch: 1040, Step num: 7116, Learning rate: 0.00010478, Avg batch loss: 0.0377, Avg batch acc: 0.9612
Train, Epoch: 5, Batch: 1041, Step num: 7117, Learning rate: 0.00010477, Avg batch loss: 0.0397, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 1042, Step num: 7118, Learning rate: 0.00010476, Avg batch loss: 0.0331, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 1043, Step num: 7119, Learning rate: 0.00010476, Avg batch loss: 0.0368, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 1044, Step num: 7120, Learning rate: 0.00010475, Avg batch loss: 0.0382, Avg batch acc: 0.9633
Train, Epoch: 5, Batch: 1045, Step num: 7121, Learning rate: 0.00010474, Avg batch loss: 0.0348, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 1046, Step num: 7122, Learning rate: 0.00010474, Avg batch loss: 0.0292, Avg batch acc: 0.9729
Train, Epoch: 5, Batch: 1047, Step num: 7123, Learning rate: 0.00010473, Avg batch loss: 0.0346, Avg batch acc: 0.9592
Train, Epoch: 5, Batch: 1048, Step num: 7124, Learning rate: 0.00010472, Avg batch loss: 0.0383, Avg batch acc: 0.9659
Train, Epoch: 5, Batch: 1049, Step num: 7125, Learning rate: 0.00010471, Avg batch loss: 0.0414, Avg batch acc: 0.9552
Train, Epoch: 5, Batch: 1050, Step num: 7126, Learning rate: 0.00010471, Avg batch loss: 0.0445, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 1051, Step num: 7127, Learning rate: 0.00010470, Avg batch loss: 0.0324, Avg batch acc: 0.9677
Train, Epoch: 5, Batch: 1052, Step num: 7128, Learning rate: 0.00010469, Avg batch loss: 0.0343, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 1053, Step num: 7129, Learning rate: 0.00010468, Avg batch loss: 0.0363, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 1054, Step num: 7130, Learning rate: 0.00010468, Avg batch loss: 0.0326, Avg batch acc: 0.9668
Train, Epoch: 5, Batch: 1055, Step num: 7131, Learning rate: 0.00010467, Avg batch loss: 0.0375, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 1056, Step num: 7132, Learning rate: 0.00010466, Avg batch loss: 0.0330, Avg batch acc: 0.9639
Train, Epoch: 5, Batch: 1057, Step num: 7133, Learning rate: 0.00010465, Avg batch loss: 0.0324, Avg batch acc: 0.9676
Train, Epoch: 5, Batch: 1058, Step num: 7134, Learning rate: 0.00010465, Avg batch loss: 0.0411, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 1059, Step num: 7135, Learning rate: 0.00010464, Avg batch loss: 0.0413, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 1060, Step num: 7136, Learning rate: 0.00010463, Avg batch loss: 0.0370, Avg batch acc: 0.9594
Train, Epoch: 5, Batch: 1061, Step num: 7137, Learning rate: 0.00010463, Avg batch loss: 0.0422, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 1062, Step num: 7138, Learning rate: 0.00010462, Avg batch loss: 0.0293, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 1063, Step num: 7139, Learning rate: 0.00010461, Avg batch loss: 0.0371, Avg batch acc: 0.9599
Train, Epoch: 5, Batch: 1064, Step num: 7140, Learning rate: 0.00010460, Avg batch loss: 0.0443, Avg batch acc: 0.9542
Train, Epoch: 5, Batch: 1065, Step num: 7141, Learning rate: 0.00010460, Avg batch loss: 0.0322, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 1066, Step num: 7142, Learning rate: 0.00010459, Avg batch loss: 0.0352, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 1067, Step num: 7143, Learning rate: 0.00010458, Avg batch loss: 0.0392, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 1068, Step num: 7144, Learning rate: 0.00010457, Avg batch loss: 0.0334, Avg batch acc: 0.9687
Train, Epoch: 5, Batch: 1069, Step num: 7145, Learning rate: 0.00010457, Avg batch loss: 0.0341, Avg batch acc: 0.9649
Train, Epoch: 5, Batch: 1070, Step num: 7146, Learning rate: 0.00010456, Avg batch loss: 0.0331, Avg batch acc: 0.9689
Train, Epoch: 5, Batch: 1071, Step num: 7147, Learning rate: 0.00010455, Avg batch loss: 0.0348, Avg batch acc: 0.9618
Train, Epoch: 5, Batch: 1072, Step num: 7148, Learning rate: 0.00010454, Avg batch loss: 0.0296, Avg batch acc: 0.9739
Train, Epoch: 5, Batch: 1073, Step num: 7149, Learning rate: 0.00010454, Avg batch loss: 0.0283, Avg batch acc: 0.9782
Train, Epoch: 5, Batch: 1074, Step num: 7150, Learning rate: 0.00010453, Avg batch loss: 0.0339, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 1075, Step num: 7151, Learning rate: 0.00010452, Avg batch loss: 0.0309, Avg batch acc: 0.9709
Train, Epoch: 5, Batch: 1076, Step num: 7152, Learning rate: 0.00010452, Avg batch loss: 0.0431, Avg batch acc: 0.9582
Train, Epoch: 5, Batch: 1077, Step num: 7153, Learning rate: 0.00010451, Avg batch loss: 0.0370, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 1078, Step num: 7154, Learning rate: 0.00010450, Avg batch loss: 0.0318, Avg batch acc: 0.9651
Train, Epoch: 5, Batch: 1079, Step num: 7155, Learning rate: 0.00010449, Avg batch loss: 0.0555, Avg batch acc: 0.9534
Train, Epoch: 5, Batch: 1080, Step num: 7156, Learning rate: 0.00010449, Avg batch loss: 0.0390, Avg batch acc: 0.9627
Train, Epoch: 5, Batch: 1081, Step num: 7157, Learning rate: 0.00010448, Avg batch loss: 0.0501, Avg batch acc: 0.9606
Train, Epoch: 5, Batch: 1082, Step num: 7158, Learning rate: 0.00010447, Avg batch loss: 0.0327, Avg batch acc: 0.9646
Train, Epoch: 5, Batch: 1083, Step num: 7159, Learning rate: 0.00010446, Avg batch loss: 0.0481, Avg batch acc: 0.9527
Train, Epoch: 5, Batch: 1084, Step num: 7160, Learning rate: 0.00010446, Avg batch loss: 0.0340, Avg batch acc: 0.9696
Train, Epoch: 5, Batch: 1085, Step num: 7161, Learning rate: 0.00010445, Avg batch loss: 0.0472, Avg batch acc: 0.9655
Train, Epoch: 5, Batch: 1086, Step num: 7162, Learning rate: 0.00010444, Avg batch loss: 0.0367, Avg batch acc: 0.9607
Train, Epoch: 5, Batch: 1087, Step num: 7163, Learning rate: 0.00010444, Avg batch loss: 0.0353, Avg batch acc: 0.9700
Train, Epoch: 5, Batch: 1088, Step num: 7164, Learning rate: 0.00010443, Avg batch loss: 0.0355, Avg batch acc: 0.9651
Train, Epoch: 5, Batch: 1089, Step num: 7165, Learning rate: 0.00010442, Avg batch loss: 0.0390, Avg batch acc: 0.9681
Train, Epoch: 5, Batch: 1090, Step num: 7166, Learning rate: 0.00010441, Avg batch loss: 0.0447, Avg batch acc: 0.9566
Train, Epoch: 5, Batch: 1091, Step num: 7167, Learning rate: 0.00010441, Avg batch loss: 0.0287, Avg batch acc: 0.9743
Train, Epoch: 5, Batch: 1092, Step num: 7168, Learning rate: 0.00010440, Avg batch loss: 0.0418, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 1093, Step num: 7169, Learning rate: 0.00010439, Avg batch loss: 0.0330, Avg batch acc: 0.9609
Train, Epoch: 5, Batch: 1094, Step num: 7170, Learning rate: 0.00010438, Avg batch loss: 0.0388, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 1095, Step num: 7171, Learning rate: 0.00010438, Avg batch loss: 0.0566, Avg batch acc: 0.9608
Train, Epoch: 5, Batch: 1096, Step num: 7172, Learning rate: 0.00010437, Avg batch loss: 0.0304, Avg batch acc: 0.9704
Train, Epoch: 5, Batch: 1097, Step num: 7173, Learning rate: 0.00010436, Avg batch loss: 0.0318, Avg batch acc: 0.9707
Train, Epoch: 5, Batch: 1098, Step num: 7174, Learning rate: 0.00010436, Avg batch loss: 0.0285, Avg batch acc: 0.9710
Train, Epoch: 5, Batch: 1099, Step num: 7175, Learning rate: 0.00010435, Avg batch loss: 0.0403, Avg batch acc: 0.9582
Train, Epoch: 5, Batch: 1100, Step num: 7176, Learning rate: 0.00010434, Avg batch loss: 0.0304, Avg batch acc: 0.9688
Train, Epoch: 5, Batch: 1101, Step num: 7177, Learning rate: 0.00010433, Avg batch loss: 0.0269, Avg batch acc: 0.9701
Train, Epoch: 5, Batch: 1102, Step num: 7178, Learning rate: 0.00010433, Avg batch loss: 0.0296, Avg batch acc: 0.9550
Train, Epoch: 5, Batch: 1103, Step num: 7179, Learning rate: 0.00010432, Avg batch loss: 0.0303, Avg batch acc: 0.9680
Train, Epoch: 5, Batch: 1104, Step num: 7180, Learning rate: 0.00010431, Avg batch loss: 0.0377, Avg batch acc: 0.9596
Train, Epoch: 5, Batch: 1105, Step num: 7181, Learning rate: 0.00010430, Avg batch loss: 0.0369, Avg batch acc: 0.9602
Train, Epoch: 5, Batch: 1106, Step num: 7182, Learning rate: 0.00010430, Avg batch loss: 0.0338, Avg batch acc: 0.9651
Train, Epoch: 5, Batch: 1107, Step num: 7183, Learning rate: 0.00010429, Avg batch loss: 0.0315, Avg batch acc: 0.9632
Train, Epoch: 5, Batch: 1108, Step num: 7184, Learning rate: 0.00010428, Avg batch loss: 0.0354, Avg batch acc: 0.9578
Train, Epoch: 5, Batch: 1109, Step num: 7185, Learning rate: 0.00010428, Avg batch loss: 0.0386, Avg batch acc: 0.9577
Train, Epoch: 5, Batch: 1110, Step num: 7186, Learning rate: 0.00010427, Avg batch loss: 0.0366, Avg batch acc: 0.9618
Train, Epoch: 5, Batch: 1111, Step num: 7187, Learning rate: 0.00010426, Avg batch loss: 0.0339, Avg batch acc: 0.9614
Train, Epoch: 5, Batch: 1112, Step num: 7188, Learning rate: 0.00010425, Avg batch loss: 0.0333, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 1113, Step num: 7189, Learning rate: 0.00010425, Avg batch loss: 0.0353, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 1114, Step num: 7190, Learning rate: 0.00010424, Avg batch loss: 0.0304, Avg batch acc: 0.9669
Train, Epoch: 5, Batch: 1115, Step num: 7191, Learning rate: 0.00010423, Avg batch loss: 0.0290, Avg batch acc: 0.9709
Train, Epoch: 5, Batch: 1116, Step num: 7192, Learning rate: 0.00010422, Avg batch loss: 0.0344, Avg batch acc: 0.9693
Train, Epoch: 5, Batch: 1117, Step num: 7193, Learning rate: 0.00010422, Avg batch loss: 0.0302, Avg batch acc: 0.9689
Train, Epoch: 5, Batch: 1118, Step num: 7194, Learning rate: 0.00010421, Avg batch loss: 0.0304, Avg batch acc: 0.9681
Train, Epoch: 5, Batch: 1119, Step num: 7195, Learning rate: 0.00010420, Avg batch loss: 0.0347, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 1120, Step num: 7196, Learning rate: 0.00010420, Avg batch loss: 0.0335, Avg batch acc: 0.9652
Train, Epoch: 5, Batch: 1121, Step num: 7197, Learning rate: 0.00010419, Avg batch loss: 0.0333, Avg batch acc: 0.9679
Train, Epoch: 5, Batch: 1122, Step num: 7198, Learning rate: 0.00010418, Avg batch loss: 0.0364, Avg batch acc: 0.9612
Train, Epoch: 5, Batch: 1123, Step num: 7199, Learning rate: 0.00010417, Avg batch loss: 0.0394, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 1124, Step num: 7200, Learning rate: 0.00010417, Avg batch loss: 0.0307, Avg batch acc: 0.9713
Train, Epoch: 5, Batch: 1125, Step num: 7201, Learning rate: 0.00010416, Avg batch loss: 0.0374, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 1126, Step num: 7202, Learning rate: 0.00010415, Avg batch loss: 0.0287, Avg batch acc: 0.9708
Train, Epoch: 5, Batch: 1127, Step num: 7203, Learning rate: 0.00010414, Avg batch loss: 0.0314, Avg batch acc: 0.9718
Train, Epoch: 5, Batch: 1128, Step num: 7204, Learning rate: 0.00010414, Avg batch loss: 0.0321, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 1129, Step num: 7205, Learning rate: 0.00010413, Avg batch loss: 0.0331, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 1130, Step num: 7206, Learning rate: 0.00010412, Avg batch loss: 0.0356, Avg batch acc: 0.9672
Train, Epoch: 5, Batch: 1131, Step num: 7207, Learning rate: 0.00010412, Avg batch loss: 0.0304, Avg batch acc: 0.9703
Train, Epoch: 5, Batch: 1132, Step num: 7208, Learning rate: 0.00010411, Avg batch loss: 0.0370, Avg batch acc: 0.9632
Train, Epoch: 5, Batch: 1133, Step num: 7209, Learning rate: 0.00010410, Avg batch loss: 0.0418, Avg batch acc: 0.9584
Train, Epoch: 5, Batch: 1134, Step num: 7210, Learning rate: 0.00010409, Avg batch loss: 0.0386, Avg batch acc: 0.9646
Train, Epoch: 5, Batch: 1135, Step num: 7211, Learning rate: 0.00010409, Avg batch loss: 0.0344, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 1136, Step num: 7212, Learning rate: 0.00010408, Avg batch loss: 0.0347, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 1137, Step num: 7213, Learning rate: 0.00010407, Avg batch loss: 0.0357, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 1138, Step num: 7214, Learning rate: 0.00010407, Avg batch loss: 0.0334, Avg batch acc: 0.9630
Train, Epoch: 5, Batch: 1139, Step num: 7215, Learning rate: 0.00010406, Avg batch loss: 0.0366, Avg batch acc: 0.9653
Train, Epoch: 5, Batch: 1140, Step num: 7216, Learning rate: 0.00010405, Avg batch loss: 0.0348, Avg batch acc: 0.9642
Train, Epoch: 5, Batch: 1141, Step num: 7217, Learning rate: 0.00010404, Avg batch loss: 0.0362, Avg batch acc: 0.9659
Train, Epoch: 5, Batch: 1142, Step num: 7218, Learning rate: 0.00010404, Avg batch loss: 0.0433, Avg batch acc: 0.9631
Train, Epoch: 5, Batch: 1143, Step num: 7219, Learning rate: 0.00010403, Avg batch loss: 0.0403, Avg batch acc: 0.9655
Train, Epoch: 5, Batch: 1144, Step num: 7220, Learning rate: 0.00010402, Avg batch loss: 0.0300, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 1145, Step num: 7221, Learning rate: 0.00010402, Avg batch loss: 0.0386, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 1146, Step num: 7222, Learning rate: 0.00010401, Avg batch loss: 0.0368, Avg batch acc: 0.9681
Train, Epoch: 5, Batch: 1147, Step num: 7223, Learning rate: 0.00010400, Avg batch loss: 0.0360, Avg batch acc: 0.9630
Train, Epoch: 5, Batch: 1148, Step num: 7224, Learning rate: 0.00010399, Avg batch loss: 0.0360, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 1149, Step num: 7225, Learning rate: 0.00010399, Avg batch loss: 0.0369, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 1150, Step num: 7226, Learning rate: 0.00010398, Avg batch loss: 0.0331, Avg batch acc: 0.9653
Train, Epoch: 5, Batch: 1151, Step num: 7227, Learning rate: 0.00010397, Avg batch loss: 0.0328, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 1152, Step num: 7228, Learning rate: 0.00010396, Avg batch loss: 0.0584, Avg batch acc: 0.9544
Train, Epoch: 5, Batch: 1153, Step num: 7229, Learning rate: 0.00010396, Avg batch loss: 0.0308, Avg batch acc: 0.9714
Train, Epoch: 5, Batch: 1154, Step num: 7230, Learning rate: 0.00010395, Avg batch loss: 0.0351, Avg batch acc: 0.9644
Train, Epoch: 5, Batch: 1155, Step num: 7231, Learning rate: 0.00010394, Avg batch loss: 0.0383, Avg batch acc: 0.9673
Train, Epoch: 5, Batch: 1156, Step num: 7232, Learning rate: 0.00010394, Avg batch loss: 0.0323, Avg batch acc: 0.9633
Train, Epoch: 5, Batch: 1157, Step num: 7233, Learning rate: 0.00010393, Avg batch loss: 0.0391, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 1158, Step num: 7234, Learning rate: 0.00010392, Avg batch loss: 0.0304, Avg batch acc: 0.9646
Train, Epoch: 5, Batch: 1159, Step num: 7235, Learning rate: 0.00010391, Avg batch loss: 0.0381, Avg batch acc: 0.9562
Train, Epoch: 5, Batch: 1160, Step num: 7236, Learning rate: 0.00010391, Avg batch loss: 0.0391, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 1161, Step num: 7237, Learning rate: 0.00010390, Avg batch loss: 0.0795, Avg batch acc: 0.9433
Train, Epoch: 5, Batch: 1162, Step num: 7238, Learning rate: 0.00010389, Avg batch loss: 0.0500, Avg batch acc: 0.9610
Train, Epoch: 5, Batch: 1163, Step num: 7239, Learning rate: 0.00010389, Avg batch loss: 0.0334, Avg batch acc: 0.9678
Train, Epoch: 5, Batch: 1164, Step num: 7240, Learning rate: 0.00010388, Avg batch loss: 0.0338, Avg batch acc: 0.9689
Train, Epoch: 5, Batch: 1165, Step num: 7241, Learning rate: 0.00010387, Avg batch loss: 0.0293, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 1166, Step num: 7242, Learning rate: 0.00010386, Avg batch loss: 0.0406, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 1167, Step num: 7243, Learning rate: 0.00010386, Avg batch loss: 0.0337, Avg batch acc: 0.9691
Train, Epoch: 5, Batch: 1168, Step num: 7244, Learning rate: 0.00010385, Avg batch loss: 0.0300, Avg batch acc: 0.9682
Train, Epoch: 5, Batch: 1169, Step num: 7245, Learning rate: 0.00010384, Avg batch loss: 0.0387, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 1170, Step num: 7246, Learning rate: 0.00010384, Avg batch loss: 0.0277, Avg batch acc: 0.9715
Train, Epoch: 5, Batch: 1171, Step num: 7247, Learning rate: 0.00010383, Avg batch loss: 0.0304, Avg batch acc: 0.9698
Train, Epoch: 5, Batch: 1172, Step num: 7248, Learning rate: 0.00010382, Avg batch loss: 0.0381, Avg batch acc: 0.9593
Train, Epoch: 5, Batch: 1173, Step num: 7249, Learning rate: 0.00010381, Avg batch loss: 0.0320, Avg batch acc: 0.9627
Train, Epoch: 5, Batch: 1174, Step num: 7250, Learning rate: 0.00010381, Avg batch loss: 0.0401, Avg batch acc: 0.9622
Train, Epoch: 5, Batch: 1175, Step num: 7251, Learning rate: 0.00010380, Avg batch loss: 0.0344, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 1176, Step num: 7252, Learning rate: 0.00010379, Avg batch loss: 0.0330, Avg batch acc: 0.9656
Train, Epoch: 5, Batch: 1177, Step num: 7253, Learning rate: 0.00010379, Avg batch loss: 0.0306, Avg batch acc: 0.9707
Train, Epoch: 5, Batch: 1178, Step num: 7254, Learning rate: 0.00010378, Avg batch loss: 0.0538, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 1179, Step num: 7255, Learning rate: 0.00010377, Avg batch loss: 0.0372, Avg batch acc: 0.9633
Train, Epoch: 5, Batch: 1180, Step num: 7256, Learning rate: 0.00010376, Avg batch loss: 0.0405, Avg batch acc: 0.9632
Train, Epoch: 5, Batch: 1181, Step num: 7257, Learning rate: 0.00010376, Avg batch loss: 0.0294, Avg batch acc: 0.9707
Train, Epoch: 5, Batch: 1182, Step num: 7258, Learning rate: 0.00010375, Avg batch loss: 0.0366, Avg batch acc: 0.9671
Train, Epoch: 5, Batch: 1183, Step num: 7259, Learning rate: 0.00010374, Avg batch loss: 0.0431, Avg batch acc: 0.9544
Train, Epoch: 5, Batch: 1184, Step num: 7260, Learning rate: 0.00010374, Avg batch loss: 0.0384, Avg batch acc: 0.9559
Train, Epoch: 5, Batch: 1185, Step num: 7261, Learning rate: 0.00010373, Avg batch loss: 0.0372, Avg batch acc: 0.9612
Train, Epoch: 5, Batch: 1186, Step num: 7262, Learning rate: 0.00010372, Avg batch loss: 0.0329, Avg batch acc: 0.9642
Train, Epoch: 5, Batch: 1187, Step num: 7263, Learning rate: 0.00010371, Avg batch loss: 0.0299, Avg batch acc: 0.9715
Train, Epoch: 5, Batch: 1188, Step num: 7264, Learning rate: 0.00010371, Avg batch loss: 0.0357, Avg batch acc: 0.9570
Train, Epoch: 5, Batch: 1189, Step num: 7265, Learning rate: 0.00010370, Avg batch loss: 0.0348, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 1190, Step num: 7266, Learning rate: 0.00010369, Avg batch loss: 0.0344, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 1191, Step num: 7267, Learning rate: 0.00010369, Avg batch loss: 0.0326, Avg batch acc: 0.9674
Train, Epoch: 5, Batch: 1192, Step num: 7268, Learning rate: 0.00010368, Avg batch loss: 0.0352, Avg batch acc: 0.9630
Train, Epoch: 5, Batch: 1193, Step num: 7269, Learning rate: 0.00010367, Avg batch loss: 0.0343, Avg batch acc: 0.9596
Train, Epoch: 5, Batch: 1194, Step num: 7270, Learning rate: 0.00010366, Avg batch loss: 0.0368, Avg batch acc: 0.9656
Train, Epoch: 5, Batch: 1195, Step num: 7271, Learning rate: 0.00010366, Avg batch loss: 0.0325, Avg batch acc: 0.9665
Train, Epoch: 5, Batch: 1196, Step num: 7272, Learning rate: 0.00010365, Avg batch loss: 0.0311, Avg batch acc: 0.9667
Train, Epoch: 5, Batch: 1197, Step num: 7273, Learning rate: 0.00010364, Avg batch loss: 0.0356, Avg batch acc: 0.9652
Train, Epoch: 5, Batch: 1198, Step num: 7274, Learning rate: 0.00010364, Avg batch loss: 0.0403, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 1199, Step num: 7275, Learning rate: 0.00010363, Avg batch loss: 0.0305, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 1200, Step num: 7276, Learning rate: 0.00010362, Avg batch loss: 0.0324, Avg batch acc: 0.9689
Train, Epoch: 5, Batch: 1201, Step num: 7277, Learning rate: 0.00010361, Avg batch loss: 0.0454, Avg batch acc: 0.9580
Train, Epoch: 5, Batch: 1202, Step num: 7278, Learning rate: 0.00010361, Avg batch loss: 0.0316, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 1203, Step num: 7279, Learning rate: 0.00010360, Avg batch loss: 0.0329, Avg batch acc: 0.9629
Train, Epoch: 5, Batch: 1204, Step num: 7280, Learning rate: 0.00010359, Avg batch loss: 0.0334, Avg batch acc: 0.9665
Train, Epoch: 5, Batch: 1205, Step num: 7281, Learning rate: 0.00010359, Avg batch loss: 0.0323, Avg batch acc: 0.9694
Train, Epoch: 5, Batch: 1206, Step num: 7282, Learning rate: 0.00010358, Avg batch loss: 0.0350, Avg batch acc: 0.9587
Train, Epoch: 5, Batch: 1207, Step num: 7283, Learning rate: 0.00010357, Avg batch loss: 0.0350, Avg batch acc: 0.9646
Train, Epoch: 5, Batch: 1208, Step num: 7284, Learning rate: 0.00010356, Avg batch loss: 0.0336, Avg batch acc: 0.9656
Train, Epoch: 5, Batch: 1209, Step num: 7285, Learning rate: 0.00010356, Avg batch loss: 0.0378, Avg batch acc: 0.9612
Train, Epoch: 5, Batch: 1210, Step num: 7286, Learning rate: 0.00010355, Avg batch loss: 0.0387, Avg batch acc: 0.9632
Train, Epoch: 5, Batch: 1211, Step num: 7287, Learning rate: 0.00010354, Avg batch loss: 0.0330, Avg batch acc: 0.9695
Train, Epoch: 5, Batch: 1212, Step num: 7288, Learning rate: 0.00010354, Avg batch loss: 0.0335, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 1213, Step num: 7289, Learning rate: 0.00010353, Avg batch loss: 0.0365, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 1214, Step num: 7290, Learning rate: 0.00010352, Avg batch loss: 0.0311, Avg batch acc: 0.9695
Train, Epoch: 5, Batch: 1215, Step num: 7291, Learning rate: 0.00010351, Avg batch loss: 0.0301, Avg batch acc: 0.9674
Train, Epoch: 5, Batch: 1216, Step num: 7292, Learning rate: 0.00010351, Avg batch loss: 0.0311, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 1217, Step num: 7293, Learning rate: 0.00010350, Avg batch loss: 0.0377, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 1218, Step num: 7294, Learning rate: 0.00010349, Avg batch loss: 0.0337, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 1219, Step num: 7295, Learning rate: 0.00010349, Avg batch loss: 0.0415, Avg batch acc: 0.9633
Train, Epoch: 5, Batch: 1220, Step num: 7296, Learning rate: 0.00010348, Avg batch loss: 0.0348, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 1221, Step num: 7297, Learning rate: 0.00010347, Avg batch loss: 0.0490, Avg batch acc: 0.9510
Train, Epoch: 5, Batch: 1222, Step num: 7298, Learning rate: 0.00010346, Avg batch loss: 0.0454, Avg batch acc: 0.9699
Train, Epoch: 5, Batch: 1223, Step num: 7299, Learning rate: 0.00010346, Avg batch loss: 0.0274, Avg batch acc: 0.9717
Train, Epoch: 5, Batch: 1224, Step num: 7300, Learning rate: 0.00010345, Avg batch loss: 0.0387, Avg batch acc: 0.9661
Train, Epoch: 5, Batch: 1225, Step num: 7301, Learning rate: 0.00010344, Avg batch loss: 0.0316, Avg batch acc: 0.9651
Train, Epoch: 5, Batch: 1226, Step num: 7302, Learning rate: 0.00010344, Avg batch loss: 0.0314, Avg batch acc: 0.9660
Train, Epoch: 5, Batch: 1227, Step num: 7303, Learning rate: 0.00010343, Avg batch loss: 0.0411, Avg batch acc: 0.9620
Train, Epoch: 5, Batch: 1228, Step num: 7304, Learning rate: 0.00010342, Avg batch loss: 0.0405, Avg batch acc: 0.9519
Train, Epoch: 5, Batch: 1229, Step num: 7305, Learning rate: 0.00010342, Avg batch loss: 0.0312, Avg batch acc: 0.9685
Train, Epoch: 5, Batch: 1230, Step num: 7306, Learning rate: 0.00010341, Avg batch loss: 0.0339, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 1231, Step num: 7307, Learning rate: 0.00010340, Avg batch loss: 0.0602, Avg batch acc: 0.9590
Train, Epoch: 5, Batch: 1232, Step num: 7308, Learning rate: 0.00010339, Avg batch loss: 0.0327, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 1233, Step num: 7309, Learning rate: 0.00010339, Avg batch loss: 0.0293, Avg batch acc: 0.9688
Train, Epoch: 5, Batch: 1234, Step num: 7310, Learning rate: 0.00010338, Avg batch loss: 0.0375, Avg batch acc: 0.9648
Train, Epoch: 5, Batch: 1235, Step num: 7311, Learning rate: 0.00010337, Avg batch loss: 0.0285, Avg batch acc: 0.9688
Train, Epoch: 5, Batch: 1236, Step num: 7312, Learning rate: 0.00010337, Avg batch loss: 0.0401, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 1237, Step num: 7313, Learning rate: 0.00010336, Avg batch loss: 0.0422, Avg batch acc: 0.9610
Train, Epoch: 5, Batch: 1238, Step num: 7314, Learning rate: 0.00010335, Avg batch loss: 0.0347, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 1239, Step num: 7315, Learning rate: 0.00010334, Avg batch loss: 0.0534, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 1240, Step num: 7316, Learning rate: 0.00010334, Avg batch loss: 0.0226, Avg batch acc: 0.9745
Train, Epoch: 5, Batch: 1241, Step num: 7317, Learning rate: 0.00010333, Avg batch loss: 0.0362, Avg batch acc: 0.9621
Train, Epoch: 5, Batch: 1242, Step num: 7318, Learning rate: 0.00010332, Avg batch loss: 0.0594, Avg batch acc: 0.9539
Train, Epoch: 5, Batch: 1243, Step num: 7319, Learning rate: 0.00010332, Avg batch loss: 0.0395, Avg batch acc: 0.9664
Train, Epoch: 5, Batch: 1244, Step num: 7320, Learning rate: 0.00010331, Avg batch loss: 0.0497, Avg batch acc: 0.9653
Train, Epoch: 5, Batch: 1245, Step num: 7321, Learning rate: 0.00010330, Avg batch loss: 0.0510, Avg batch acc: 0.9619
Train, Epoch: 5, Batch: 1246, Step num: 7322, Learning rate: 0.00010330, Avg batch loss: 0.0375, Avg batch acc: 0.9582
Train, Epoch: 5, Batch: 1247, Step num: 7323, Learning rate: 0.00010329, Avg batch loss: 0.0396, Avg batch acc: 0.9708
Train, Epoch: 5, Batch: 1248, Step num: 7324, Learning rate: 0.00010328, Avg batch loss: 0.0344, Avg batch acc: 0.9642
Train, Epoch: 5, Batch: 1249, Step num: 7325, Learning rate: 0.00010327, Avg batch loss: 0.0316, Avg batch acc: 0.9637
Train, Epoch: 5, Batch: 1250, Step num: 7326, Learning rate: 0.00010327, Avg batch loss: 0.0400, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 1251, Step num: 7327, Learning rate: 0.00010326, Avg batch loss: 0.0734, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 1252, Step num: 7328, Learning rate: 0.00010325, Avg batch loss: 0.0375, Avg batch acc: 0.9598
Train, Epoch: 5, Batch: 1253, Step num: 7329, Learning rate: 0.00010325, Avg batch loss: 0.0386, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 1254, Step num: 7330, Learning rate: 0.00010324, Avg batch loss: 0.0362, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 1255, Step num: 7331, Learning rate: 0.00010323, Avg batch loss: 0.0384, Avg batch acc: 0.9668
Train, Epoch: 5, Batch: 1256, Step num: 7332, Learning rate: 0.00010322, Avg batch loss: 0.0316, Avg batch acc: 0.9677
Train, Epoch: 5, Batch: 1257, Step num: 7333, Learning rate: 0.00010322, Avg batch loss: 0.0372, Avg batch acc: 0.9630
Train, Epoch: 5, Batch: 1258, Step num: 7334, Learning rate: 0.00010321, Avg batch loss: 0.0372, Avg batch acc: 0.9656
Train, Epoch: 5, Batch: 1259, Step num: 7335, Learning rate: 0.00010320, Avg batch loss: 0.0317, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 1260, Step num: 7336, Learning rate: 0.00010320, Avg batch loss: 0.0357, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 1261, Step num: 7337, Learning rate: 0.00010319, Avg batch loss: 0.0404, Avg batch acc: 0.9587
Train, Epoch: 5, Batch: 1262, Step num: 7338, Learning rate: 0.00010318, Avg batch loss: 0.0426, Avg batch acc: 0.9537
Train, Epoch: 5, Batch: 1263, Step num: 7339, Learning rate: 0.00010318, Avg batch loss: 0.0468, Avg batch acc: 0.9552
Train, Epoch: 5, Batch: 1264, Step num: 7340, Learning rate: 0.00010317, Avg batch loss: 0.0374, Avg batch acc: 0.9642
Train, Epoch: 5, Batch: 1265, Step num: 7341, Learning rate: 0.00010316, Avg batch loss: 0.0329, Avg batch acc: 0.9666
Train, Epoch: 5, Batch: 1266, Step num: 7342, Learning rate: 0.00010315, Avg batch loss: 0.0466, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 1267, Step num: 7343, Learning rate: 0.00010315, Avg batch loss: 0.0365, Avg batch acc: 0.9702
Train, Epoch: 5, Batch: 1268, Step num: 7344, Learning rate: 0.00010314, Avg batch loss: 0.0616, Avg batch acc: 0.9576
Train, Epoch: 5, Batch: 1269, Step num: 7345, Learning rate: 0.00010313, Avg batch loss: 0.0520, Avg batch acc: 0.9605
Train, Epoch: 5, Batch: 1270, Step num: 7346, Learning rate: 0.00010313, Avg batch loss: 0.0444, Avg batch acc: 0.9568
Train, Epoch: 5, Batch: 1271, Step num: 7347, Learning rate: 0.00010312, Avg batch loss: 0.0372, Avg batch acc: 0.9575
Train, Epoch: 5, Batch: 1272, Step num: 7348, Learning rate: 0.00010311, Avg batch loss: 0.0379, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 1273, Step num: 7349, Learning rate: 0.00010311, Avg batch loss: 0.0325, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 1274, Step num: 7350, Learning rate: 0.00010310, Avg batch loss: 0.0317, Avg batch acc: 0.9670
Train, Epoch: 5, Batch: 1275, Step num: 7351, Learning rate: 0.00010309, Avg batch loss: 0.0307, Avg batch acc: 0.9705
Train, Epoch: 5, Batch: 1276, Step num: 7352, Learning rate: 0.00010308, Avg batch loss: 0.0377, Avg batch acc: 0.9584
Train, Epoch: 5, Batch: 1277, Step num: 7353, Learning rate: 0.00010308, Avg batch loss: 0.0353, Avg batch acc: 0.9670
Train, Epoch: 5, Batch: 1278, Step num: 7354, Learning rate: 0.00010307, Avg batch loss: 0.0410, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 1279, Step num: 7355, Learning rate: 0.00010306, Avg batch loss: 0.0287, Avg batch acc: 0.9682
Train, Epoch: 5, Batch: 1280, Step num: 7356, Learning rate: 0.00010306, Avg batch loss: 0.0342, Avg batch acc: 0.9684
Train, Epoch: 5, Batch: 1281, Step num: 7357, Learning rate: 0.00010305, Avg batch loss: 0.0300, Avg batch acc: 0.9702
Train, Epoch: 5, Batch: 1282, Step num: 7358, Learning rate: 0.00010304, Avg batch loss: 0.0361, Avg batch acc: 0.9672
Train, Epoch: 5, Batch: 1283, Step num: 7359, Learning rate: 0.00010304, Avg batch loss: 0.0329, Avg batch acc: 0.9692
Train, Epoch: 5, Batch: 1284, Step num: 7360, Learning rate: 0.00010303, Avg batch loss: 0.0368, Avg batch acc: 0.9594
Train, Epoch: 5, Batch: 1285, Step num: 7361, Learning rate: 0.00010302, Avg batch loss: 0.0382, Avg batch acc: 0.9608
Train, Epoch: 5, Batch: 1286, Step num: 7362, Learning rate: 0.00010301, Avg batch loss: 0.0318, Avg batch acc: 0.9692
Train, Epoch: 5, Batch: 1287, Step num: 7363, Learning rate: 0.00010301, Avg batch loss: 0.0253, Avg batch acc: 0.9688
Train, Epoch: 5, Batch: 1288, Step num: 7364, Learning rate: 0.00010300, Avg batch loss: 0.0341, Avg batch acc: 0.9644
Train, Epoch: 5, Batch: 1289, Step num: 7365, Learning rate: 0.00010299, Avg batch loss: 0.0351, Avg batch acc: 0.9659
Train, Epoch: 5, Batch: 1290, Step num: 7366, Learning rate: 0.00010299, Avg batch loss: 0.0381, Avg batch acc: 0.9676
Train, Epoch: 5, Batch: 1291, Step num: 7367, Learning rate: 0.00010298, Avg batch loss: 0.0386, Avg batch acc: 0.9633
Train, Epoch: 5, Batch: 1292, Step num: 7368, Learning rate: 0.00010297, Avg batch loss: 0.0337, Avg batch acc: 0.9644
Train, Epoch: 5, Batch: 1293, Step num: 7369, Learning rate: 0.00010297, Avg batch loss: 0.0351, Avg batch acc: 0.9704
Train, Epoch: 5, Batch: 1294, Step num: 7370, Learning rate: 0.00010296, Avg batch loss: 0.0382, Avg batch acc: 0.9595
Train, Epoch: 5, Batch: 1295, Step num: 7371, Learning rate: 0.00010295, Avg batch loss: 0.0347, Avg batch acc: 0.9668
Train, Epoch: 5, Batch: 1296, Step num: 7372, Learning rate: 0.00010294, Avg batch loss: 0.0285, Avg batch acc: 0.9725
Train, Epoch: 5, Batch: 1297, Step num: 7373, Learning rate: 0.00010294, Avg batch loss: 0.0370, Avg batch acc: 0.9649
Train, Epoch: 5, Batch: 1298, Step num: 7374, Learning rate: 0.00010293, Avg batch loss: 0.0341, Avg batch acc: 0.9705
Train, Epoch: 5, Batch: 1299, Step num: 7375, Learning rate: 0.00010292, Avg batch loss: 0.0374, Avg batch acc: 0.9655
Train, Epoch: 5, Batch: 1300, Step num: 7376, Learning rate: 0.00010292, Avg batch loss: 0.0505, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 1301, Step num: 7377, Learning rate: 0.00010291, Avg batch loss: 0.0296, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 1302, Step num: 7378, Learning rate: 0.00010290, Avg batch loss: 0.0472, Avg batch acc: 0.9630
Train, Epoch: 5, Batch: 1303, Step num: 7379, Learning rate: 0.00010290, Avg batch loss: 0.0332, Avg batch acc: 0.9603
Train, Epoch: 5, Batch: 1304, Step num: 7380, Learning rate: 0.00010289, Avg batch loss: 0.0396, Avg batch acc: 0.9730
Train, Epoch: 5, Batch: 1305, Step num: 7381, Learning rate: 0.00010288, Avg batch loss: 0.0295, Avg batch acc: 0.9705
Train, Epoch: 5, Batch: 1306, Step num: 7382, Learning rate: 0.00010287, Avg batch loss: 0.0333, Avg batch acc: 0.9671
Train, Epoch: 5, Batch: 1307, Step num: 7383, Learning rate: 0.00010287, Avg batch loss: 0.0345, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 1308, Step num: 7384, Learning rate: 0.00010286, Avg batch loss: 0.0288, Avg batch acc: 0.9689
Train, Epoch: 5, Batch: 1309, Step num: 7385, Learning rate: 0.00010285, Avg batch loss: 0.0431, Avg batch acc: 0.9620
Train, Epoch: 5, Batch: 1310, Step num: 7386, Learning rate: 0.00010285, Avg batch loss: 0.0333, Avg batch acc: 0.9658
Train, Epoch: 5, Batch: 1311, Step num: 7387, Learning rate: 0.00010284, Avg batch loss: 0.0289, Avg batch acc: 0.9692
Train, Epoch: 5, Batch: 1312, Step num: 7388, Learning rate: 0.00010283, Avg batch loss: 0.0315, Avg batch acc: 0.9721
Train, Epoch: 5, Batch: 1313, Step num: 7389, Learning rate: 0.00010283, Avg batch loss: 0.0303, Avg batch acc: 0.9723
Train, Epoch: 5, Batch: 1314, Step num: 7390, Learning rate: 0.00010282, Avg batch loss: 0.0289, Avg batch acc: 0.9678
Train, Epoch: 5, Batch: 1315, Step num: 7391, Learning rate: 0.00010281, Avg batch loss: 0.0345, Avg batch acc: 0.9647
Train, Epoch: 5, Batch: 1316, Step num: 7392, Learning rate: 0.00010280, Avg batch loss: 0.0271, Avg batch acc: 0.9689
Train, Epoch: 5, Batch: 1317, Step num: 7393, Learning rate: 0.00010280, Avg batch loss: 0.0360, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 1318, Step num: 7394, Learning rate: 0.00010279, Avg batch loss: 0.0350, Avg batch acc: 0.9655
Train, Epoch: 5, Batch: 1319, Step num: 7395, Learning rate: 0.00010278, Avg batch loss: 0.0273, Avg batch acc: 0.9701
Train, Epoch: 5, Batch: 1320, Step num: 7396, Learning rate: 0.00010278, Avg batch loss: 0.0334, Avg batch acc: 0.9660
Train, Epoch: 5, Batch: 1321, Step num: 7397, Learning rate: 0.00010277, Avg batch loss: 0.0300, Avg batch acc: 0.9703
Train, Epoch: 5, Batch: 1322, Step num: 7398, Learning rate: 0.00010276, Avg batch loss: 0.0386, Avg batch acc: 0.9648
Train, Epoch: 5, Batch: 1323, Step num: 7399, Learning rate: 0.00010276, Avg batch loss: 0.0293, Avg batch acc: 0.9691
Train, Epoch: 5, Batch: 1324, Step num: 7400, Learning rate: 0.00010275, Avg batch loss: 0.0371, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 1325, Step num: 7401, Learning rate: 0.00010274, Avg batch loss: 0.0323, Avg batch acc: 0.9732
Train, Epoch: 5, Batch: 1326, Step num: 7402, Learning rate: 0.00010274, Avg batch loss: 0.0326, Avg batch acc: 0.9634
Train, Epoch: 5, Batch: 1327, Step num: 7403, Learning rate: 0.00010273, Avg batch loss: 0.0342, Avg batch acc: 0.9670
Train, Epoch: 5, Batch: 1328, Step num: 7404, Learning rate: 0.00010272, Avg batch loss: 0.0310, Avg batch acc: 0.9663
Train, Epoch: 5, Batch: 1329, Step num: 7405, Learning rate: 0.00010271, Avg batch loss: 0.0329, Avg batch acc: 0.9646
Train, Epoch: 5, Batch: 1330, Step num: 7406, Learning rate: 0.00010271, Avg batch loss: 0.0276, Avg batch acc: 0.9731
Train, Epoch: 5, Batch: 1331, Step num: 7407, Learning rate: 0.00010270, Avg batch loss: 0.0306, Avg batch acc: 0.9691
Train, Epoch: 5, Batch: 1332, Step num: 7408, Learning rate: 0.00010269, Avg batch loss: 0.0295, Avg batch acc: 0.9670
Train, Epoch: 5, Batch: 1333, Step num: 7409, Learning rate: 0.00010269, Avg batch loss: 0.0339, Avg batch acc: 0.9654
Train, Epoch: 5, Batch: 1334, Step num: 7410, Learning rate: 0.00010268, Avg batch loss: 0.0430, Avg batch acc: 0.9586
Train, Epoch: 5, Batch: 1335, Step num: 7411, Learning rate: 0.00010267, Avg batch loss: 0.0345, Avg batch acc: 0.9697
Train, Epoch: 5, Batch: 1336, Step num: 7412, Learning rate: 0.00010267, Avg batch loss: 0.0322, Avg batch acc: 0.9688
Train, Epoch: 5, Batch: 1337, Step num: 7413, Learning rate: 0.00010266, Avg batch loss: 0.0338, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 1338, Step num: 7414, Learning rate: 0.00010265, Avg batch loss: 0.0482, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 1339, Step num: 7415, Learning rate: 0.00010265, Avg batch loss: 0.0455, Avg batch acc: 0.9630
Train, Epoch: 5, Batch: 1340, Step num: 7416, Learning rate: 0.00010264, Avg batch loss: 0.0280, Avg batch acc: 0.9716
Train, Epoch: 5, Batch: 1341, Step num: 7417, Learning rate: 0.00010263, Avg batch loss: 0.0317, Avg batch acc: 0.9701
Train, Epoch: 5, Batch: 1342, Step num: 7418, Learning rate: 0.00010262, Avg batch loss: 0.0295, Avg batch acc: 0.9686
Train, Epoch: 5, Batch: 1343, Step num: 7419, Learning rate: 0.00010262, Avg batch loss: 0.0321, Avg batch acc: 0.9667
Train, Epoch: 5, Batch: 1344, Step num: 7420, Learning rate: 0.00010261, Avg batch loss: 0.0289, Avg batch acc: 0.9697
Train, Epoch: 5, Batch: 1345, Step num: 7421, Learning rate: 0.00010260, Avg batch loss: 0.0326, Avg batch acc: 0.9633
Train, Epoch: 5, Batch: 1346, Step num: 7422, Learning rate: 0.00010260, Avg batch loss: 0.0301, Avg batch acc: 0.9748
Train, Epoch: 5, Batch: 1347, Step num: 7423, Learning rate: 0.00010259, Avg batch loss: 0.0302, Avg batch acc: 0.9632
Train, Epoch: 5, Batch: 1348, Step num: 7424, Learning rate: 0.00010258, Avg batch loss: 0.0337, Avg batch acc: 0.9670
Train, Epoch: 5, Batch: 1349, Step num: 7425, Learning rate: 0.00010258, Avg batch loss: 0.0311, Avg batch acc: 0.9669
Train, Epoch: 5, Batch: 1350, Step num: 7426, Learning rate: 0.00010257, Avg batch loss: 0.0379, Avg batch acc: 0.9703
Train, Epoch: 5, Batch: 1351, Step num: 7427, Learning rate: 0.00010256, Avg batch loss: 0.0354, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 1352, Step num: 7428, Learning rate: 0.00010256, Avg batch loss: 0.0357, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 1353, Step num: 7429, Learning rate: 0.00010255, Avg batch loss: 0.0362, Avg batch acc: 0.9647
Train, Epoch: 5, Batch: 1354, Step num: 7430, Learning rate: 0.00010254, Avg batch loss: 0.0339, Avg batch acc: 0.9670
Train, Epoch: 5, Batch: 1355, Step num: 7431, Learning rate: 0.00010253, Avg batch loss: 0.0328, Avg batch acc: 0.9662
Train, Epoch: 5, Batch: 1356, Step num: 7432, Learning rate: 0.00010253, Avg batch loss: 0.0298, Avg batch acc: 0.9698
Train, Epoch: 5, Batch: 1357, Step num: 7433, Learning rate: 0.00010252, Avg batch loss: 0.0253, Avg batch acc: 0.9747
Train, Epoch: 5, Batch: 1358, Step num: 7434, Learning rate: 0.00010251, Avg batch loss: 0.0328, Avg batch acc: 0.9699
Train, Epoch: 5, Batch: 1359, Step num: 7435, Learning rate: 0.00010251, Avg batch loss: 0.0425, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 1360, Step num: 7436, Learning rate: 0.00010250, Avg batch loss: 0.0424, Avg batch acc: 0.9679
Train, Epoch: 5, Batch: 1361, Step num: 7437, Learning rate: 0.00010249, Avg batch loss: 0.0359, Avg batch acc: 0.9646
Train, Epoch: 5, Batch: 1362, Step num: 7438, Learning rate: 0.00010249, Avg batch loss: 0.0367, Avg batch acc: 0.9622
Train, Epoch: 5, Batch: 1363, Step num: 7439, Learning rate: 0.00010248, Avg batch loss: 0.0312, Avg batch acc: 0.9700
Train, Epoch: 5, Batch: 1364, Step num: 7440, Learning rate: 0.00010247, Avg batch loss: 0.0381, Avg batch acc: 0.9661
Train, Epoch: 5, Batch: 1365, Step num: 7441, Learning rate: 0.00010247, Avg batch loss: 0.0324, Avg batch acc: 0.9666
Train, Epoch: 5, Batch: 1366, Step num: 7442, Learning rate: 0.00010246, Avg batch loss: 0.0351, Avg batch acc: 0.9696
Train, Epoch: 5, Batch: 1367, Step num: 7443, Learning rate: 0.00010245, Avg batch loss: 0.0417, Avg batch acc: 0.9621
Train, Epoch: 5, Batch: 1368, Step num: 7444, Learning rate: 0.00010245, Avg batch loss: 0.0285, Avg batch acc: 0.9711
Train, Epoch: 5, Batch: 1369, Step num: 7445, Learning rate: 0.00010244, Avg batch loss: 0.0383, Avg batch acc: 0.9556
Train, Epoch: 5, Batch: 1370, Step num: 7446, Learning rate: 0.00010243, Avg batch loss: 0.0320, Avg batch acc: 0.9678
Train, Epoch: 5, Batch: 1371, Step num: 7447, Learning rate: 0.00010242, Avg batch loss: 0.0349, Avg batch acc: 0.9662
Train, Epoch: 5, Batch: 1372, Step num: 7448, Learning rate: 0.00010242, Avg batch loss: 0.0400, Avg batch acc: 0.9632
Train, Epoch: 5, Batch: 1373, Step num: 7449, Learning rate: 0.00010241, Avg batch loss: 0.0461, Avg batch acc: 0.9561
Train, Epoch: 5, Batch: 1374, Step num: 7450, Learning rate: 0.00010240, Avg batch loss: 0.0334, Avg batch acc: 0.9610
Train, Epoch: 5, Batch: 1375, Step num: 7451, Learning rate: 0.00010240, Avg batch loss: 0.0406, Avg batch acc: 0.9622
Train, Epoch: 5, Batch: 1376, Step num: 7452, Learning rate: 0.00010239, Avg batch loss: 0.0328, Avg batch acc: 0.9672
Train, Epoch: 5, Batch: 1377, Step num: 7453, Learning rate: 0.00010238, Avg batch loss: 0.0346, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 1378, Step num: 7454, Learning rate: 0.00010238, Avg batch loss: 0.0308, Avg batch acc: 0.9670
Train, Epoch: 5, Batch: 1379, Step num: 7455, Learning rate: 0.00010237, Avg batch loss: 0.0385, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 1380, Step num: 7456, Learning rate: 0.00010236, Avg batch loss: 0.0415, Avg batch acc: 0.9677
Train, Epoch: 5, Batch: 1381, Step num: 7457, Learning rate: 0.00010236, Avg batch loss: 0.0461, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 1382, Step num: 7458, Learning rate: 0.00010235, Avg batch loss: 0.0379, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 1383, Step num: 7459, Learning rate: 0.00010234, Avg batch loss: 0.0375, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 1384, Step num: 7460, Learning rate: 0.00010234, Avg batch loss: 0.0274, Avg batch acc: 0.9703
Train, Epoch: 5, Batch: 1385, Step num: 7461, Learning rate: 0.00010233, Avg batch loss: 0.0306, Avg batch acc: 0.9707
Train, Epoch: 5, Batch: 1386, Step num: 7462, Learning rate: 0.00010232, Avg batch loss: 0.0357, Avg batch acc: 0.9648
Train, Epoch: 5, Batch: 1387, Step num: 7463, Learning rate: 0.00010231, Avg batch loss: 0.0366, Avg batch acc: 0.9672
Train, Epoch: 5, Batch: 1388, Step num: 7464, Learning rate: 0.00010231, Avg batch loss: 0.0384, Avg batch acc: 0.9599
Train, Epoch: 5, Batch: 1389, Step num: 7465, Learning rate: 0.00010230, Avg batch loss: 0.0303, Avg batch acc: 0.9708
Train, Epoch: 5, Batch: 1390, Step num: 7466, Learning rate: 0.00010229, Avg batch loss: 0.0350, Avg batch acc: 0.9625
Train, Epoch: 5, Batch: 1391, Step num: 7467, Learning rate: 0.00010229, Avg batch loss: 0.0343, Avg batch acc: 0.9708
Train, Epoch: 5, Batch: 1392, Step num: 7468, Learning rate: 0.00010228, Avg batch loss: 0.0334, Avg batch acc: 0.9614
Train, Epoch: 5, Batch: 1393, Step num: 7469, Learning rate: 0.00010227, Avg batch loss: 0.0295, Avg batch acc: 0.9674
Train, Epoch: 5, Batch: 1394, Step num: 7470, Learning rate: 0.00010227, Avg batch loss: 0.0366, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 1395, Step num: 7471, Learning rate: 0.00010226, Avg batch loss: 0.0310, Avg batch acc: 0.9703
Train, Epoch: 5, Batch: 1396, Step num: 7472, Learning rate: 0.00010225, Avg batch loss: 0.0278, Avg batch acc: 0.9708
Train, Epoch: 5, Batch: 1397, Step num: 7473, Learning rate: 0.00010225, Avg batch loss: 0.0311, Avg batch acc: 0.9706
Train, Epoch: 5, Batch: 1398, Step num: 7474, Learning rate: 0.00010224, Avg batch loss: 0.0319, Avg batch acc: 0.9664
Train, Epoch: 5, Batch: 1399, Step num: 7475, Learning rate: 0.00010223, Avg batch loss: 0.0330, Avg batch acc: 0.9639
Train, Epoch: 5, Batch: 1400, Step num: 7476, Learning rate: 0.00010223, Avg batch loss: 0.0278, Avg batch acc: 0.9735
Train, Epoch: 5, Batch: 1401, Step num: 7477, Learning rate: 0.00010222, Avg batch loss: 0.0301, Avg batch acc: 0.9660
Train, Epoch: 5, Batch: 1402, Step num: 7478, Learning rate: 0.00010221, Avg batch loss: 0.0499, Avg batch acc: 0.9640
Train, Epoch: 5, Batch: 1403, Step num: 7479, Learning rate: 0.00010221, Avg batch loss: 0.0366, Avg batch acc: 0.9641
Train, Epoch: 5, Batch: 1404, Step num: 7480, Learning rate: 0.00010220, Avg batch loss: 0.0338, Avg batch acc: 0.9699
Train, Epoch: 5, Batch: 1405, Step num: 7481, Learning rate: 0.00010219, Avg batch loss: 0.0222, Avg batch acc: 0.9738
Train, Epoch: 5, Batch: 1406, Step num: 7482, Learning rate: 0.00010218, Avg batch loss: 0.0318, Avg batch acc: 0.9668
Train, Epoch: 5, Batch: 1407, Step num: 7483, Learning rate: 0.00010218, Avg batch loss: 0.0305, Avg batch acc: 0.9694
Train, Epoch: 5, Batch: 1408, Step num: 7484, Learning rate: 0.00010217, Avg batch loss: 0.0272, Avg batch acc: 0.9675
Train, Epoch: 5, Batch: 1409, Step num: 7485, Learning rate: 0.00010216, Avg batch loss: 0.0318, Avg batch acc: 0.9702
Train, Epoch: 5, Batch: 1410, Step num: 7486, Learning rate: 0.00010216, Avg batch loss: 0.0278, Avg batch acc: 0.9733
Train, Epoch: 5, Batch: 1411, Step num: 7487, Learning rate: 0.00010215, Avg batch loss: 0.0354, Avg batch acc: 0.9659
Train, Epoch: 5, Batch: 1412, Step num: 7488, Learning rate: 0.00010214, Avg batch loss: 0.0340, Avg batch acc: 0.9647
Train, Epoch: 5, Batch: 1413, Step num: 7489, Learning rate: 0.00010214, Avg batch loss: 0.0263, Avg batch acc: 0.9704
Train, Epoch: 5, Batch: 1414, Step num: 7490, Learning rate: 0.00010213, Avg batch loss: 0.0378, Avg batch acc: 0.9685
Train, Epoch: 5, Batch: 1415, Step num: 7491, Learning rate: 0.00010212, Avg batch loss: 0.0435, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 1416, Step num: 7492, Learning rate: 0.00010212, Avg batch loss: 0.0373, Avg batch acc: 0.9648
Train, Epoch: 5, Batch: 1417, Step num: 7493, Learning rate: 0.00010211, Avg batch loss: 0.0322, Avg batch acc: 0.9584
Train, Epoch: 5, Batch: 1418, Step num: 7494, Learning rate: 0.00010210, Avg batch loss: 0.0346, Avg batch acc: 0.9699
Train, Epoch: 5, Batch: 1419, Step num: 7495, Learning rate: 0.00010210, Avg batch loss: 0.0377, Avg batch acc: 0.9564
Train, Epoch: 5, Batch: 1420, Step num: 7496, Learning rate: 0.00010209, Avg batch loss: 0.0281, Avg batch acc: 0.9691
Train, Epoch: 5, Batch: 1421, Step num: 7497, Learning rate: 0.00010208, Avg batch loss: 0.0274, Avg batch acc: 0.9673
Train, Epoch: 5, Batch: 1422, Step num: 7498, Learning rate: 0.00010208, Avg batch loss: 0.0369, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 1423, Step num: 7499, Learning rate: 0.00010207, Avg batch loss: 0.0318, Avg batch acc: 0.9693
Train, Epoch: 5, Batch: 1424, Step num: 7500, Learning rate: 0.00010206, Avg batch loss: 0.0354, Avg batch acc: 0.9679
Train, Epoch: 5, Batch: 1425, Step num: 7501, Learning rate: 0.00010206, Avg batch loss: 0.0366, Avg batch acc: 0.9634
Train, Epoch: 5, Batch: 1426, Step num: 7502, Learning rate: 0.00010205, Avg batch loss: 0.0402, Avg batch acc: 0.9649
Train, Epoch: 5, Batch: 1427, Step num: 7503, Learning rate: 0.00010204, Avg batch loss: 0.0404, Avg batch acc: 0.9659
Train, Epoch: 5, Batch: 1428, Step num: 7504, Learning rate: 0.00010203, Avg batch loss: 0.0309, Avg batch acc: 0.9723
Train, Epoch: 5, Batch: 1429, Step num: 7505, Learning rate: 0.00010203, Avg batch loss: 0.0301, Avg batch acc: 0.9682
Train, Epoch: 5, Batch: 1430, Step num: 7506, Learning rate: 0.00010202, Avg batch loss: 0.0341, Avg batch acc: 0.9616
Train, Epoch: 5, Batch: 1431, Step num: 7507, Learning rate: 0.00010201, Avg batch loss: 0.0292, Avg batch acc: 0.9703
Train, Epoch: 5, Batch: 1432, Step num: 7508, Learning rate: 0.00010201, Avg batch loss: 0.0361, Avg batch acc: 0.9639
Train, Epoch: 5, Batch: 1433, Step num: 7509, Learning rate: 0.00010200, Avg batch loss: 0.0372, Avg batch acc: 0.9601
Train, Epoch: 5, Batch: 1434, Step num: 7510, Learning rate: 0.00010199, Avg batch loss: 0.0267, Avg batch acc: 0.9680
Train, Epoch: 5, Batch: 1435, Step num: 7511, Learning rate: 0.00010199, Avg batch loss: 0.0320, Avg batch acc: 0.9671
Train, Epoch: 5, Batch: 1436, Step num: 7512, Learning rate: 0.00010198, Avg batch loss: 0.0541, Avg batch acc: 0.9558
Train, Epoch: 5, Batch: 1437, Step num: 7513, Learning rate: 0.00010197, Avg batch loss: 0.0294, Avg batch acc: 0.9681
Train, Epoch: 5, Batch: 1438, Step num: 7514, Learning rate: 0.00010197, Avg batch loss: 0.0256, Avg batch acc: 0.9683
Train, Epoch: 5, Batch: 1439, Step num: 7515, Learning rate: 0.00010196, Avg batch loss: 0.0326, Avg batch acc: 0.9709
Train, Epoch: 5, Batch: 1440, Step num: 7516, Learning rate: 0.00010195, Avg batch loss: 0.0457, Avg batch acc: 0.9668
Train, Epoch: 5, Batch: 1441, Step num: 7517, Learning rate: 0.00010195, Avg batch loss: 0.0345, Avg batch acc: 0.9662
Train, Epoch: 5, Batch: 1442, Step num: 7518, Learning rate: 0.00010194, Avg batch loss: 0.0409, Avg batch acc: 0.9599
Train, Epoch: 5, Batch: 1443, Step num: 7519, Learning rate: 0.00010193, Avg batch loss: 0.0314, Avg batch acc: 0.9639
Train, Epoch: 5, Batch: 1444, Step num: 7520, Learning rate: 0.00010193, Avg batch loss: 0.0302, Avg batch acc: 0.9689
Train, Epoch: 5, Batch: 1445, Step num: 7521, Learning rate: 0.00010192, Avg batch loss: 0.0391, Avg batch acc: 0.9674
Train, Epoch: 5, Batch: 1446, Step num: 7522, Learning rate: 0.00010191, Avg batch loss: 0.0211, Avg batch acc: 0.9769
Train, Epoch: 5, Batch: 1447, Step num: 7523, Learning rate: 0.00010191, Avg batch loss: 0.0312, Avg batch acc: 0.9716
Train, Epoch: 5, Batch: 1448, Step num: 7524, Learning rate: 0.00010190, Avg batch loss: 0.0348, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 1449, Step num: 7525, Learning rate: 0.00010189, Avg batch loss: 0.0391, Avg batch acc: 0.9668
Train, Epoch: 5, Batch: 1450, Step num: 7526, Learning rate: 0.00010189, Avg batch loss: 0.0250, Avg batch acc: 0.9755
Train, Epoch: 5, Batch: 1451, Step num: 7527, Learning rate: 0.00010188, Avg batch loss: 0.0303, Avg batch acc: 0.9658
Train, Epoch: 5, Batch: 1452, Step num: 7528, Learning rate: 0.00010187, Avg batch loss: 0.0453, Avg batch acc: 0.9585
Train, Epoch: 5, Batch: 1453, Step num: 7529, Learning rate: 0.00010187, Avg batch loss: 0.0283, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 1454, Step num: 7530, Learning rate: 0.00010186, Avg batch loss: 0.0314, Avg batch acc: 0.9686
Train, Epoch: 5, Batch: 1455, Step num: 7531, Learning rate: 0.00010185, Avg batch loss: 0.0353, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 1456, Step num: 7532, Learning rate: 0.00010185, Avg batch loss: 0.0347, Avg batch acc: 0.9670
Train, Epoch: 5, Batch: 1457, Step num: 7533, Learning rate: 0.00010184, Avg batch loss: 0.0314, Avg batch acc: 0.9644
Train, Epoch: 5, Batch: 1458, Step num: 7534, Learning rate: 0.00010183, Avg batch loss: 0.0419, Avg batch acc: 0.9631
Train, Epoch: 5, Batch: 1459, Step num: 7535, Learning rate: 0.00010182, Avg batch loss: 0.0332, Avg batch acc: 0.9707
Train, Epoch: 5, Batch: 1460, Step num: 7536, Learning rate: 0.00010182, Avg batch loss: 0.0316, Avg batch acc: 0.9671
Train, Epoch: 5, Batch: 1461, Step num: 7537, Learning rate: 0.00010181, Avg batch loss: 0.0302, Avg batch acc: 0.9678
Train, Epoch: 5, Batch: 1462, Step num: 7538, Learning rate: 0.00010180, Avg batch loss: 0.0274, Avg batch acc: 0.9704
Train, Epoch: 5, Batch: 1463, Step num: 7539, Learning rate: 0.00010180, Avg batch loss: 0.0305, Avg batch acc: 0.9714
Train, Epoch: 5, Batch: 1464, Step num: 7540, Learning rate: 0.00010179, Avg batch loss: 0.0309, Avg batch acc: 0.9643
Train, Epoch: 5, Batch: 1465, Step num: 7541, Learning rate: 0.00010178, Avg batch loss: 0.0264, Avg batch acc: 0.9710
Train, Epoch: 5, Batch: 1466, Step num: 7542, Learning rate: 0.00010178, Avg batch loss: 0.0361, Avg batch acc: 0.9672
Train, Epoch: 5, Batch: 1467, Step num: 7543, Learning rate: 0.00010177, Avg batch loss: 0.0327, Avg batch acc: 0.9635
Train, Epoch: 5, Batch: 1468, Step num: 7544, Learning rate: 0.00010176, Avg batch loss: 0.0275, Avg batch acc: 0.9685
Train, Epoch: 5, Batch: 1469, Step num: 7545, Learning rate: 0.00010176, Avg batch loss: 0.0631, Avg batch acc: 0.9613
Train, Epoch: 5, Batch: 1470, Step num: 7546, Learning rate: 0.00010175, Avg batch loss: 0.0499, Avg batch acc: 0.9624
Train, Epoch: 5, Batch: 1471, Step num: 7547, Learning rate: 0.00010174, Avg batch loss: 0.0380, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 1472, Step num: 7548, Learning rate: 0.00010174, Avg batch loss: 0.0373, Avg batch acc: 0.9623
Train, Epoch: 5, Batch: 1473, Step num: 7549, Learning rate: 0.00010173, Avg batch loss: 0.0303, Avg batch acc: 0.9732
Train, Epoch: 5, Batch: 1474, Step num: 7550, Learning rate: 0.00010172, Avg batch loss: 0.0298, Avg batch acc: 0.9649
Train, Epoch: 5, Batch: 1475, Step num: 7551, Learning rate: 0.00010172, Avg batch loss: 0.0515, Avg batch acc: 0.9517
Train, Epoch: 5, Batch: 1476, Step num: 7552, Learning rate: 0.00010171, Avg batch loss: 0.0274, Avg batch acc: 0.9710
Train, Epoch: 5, Batch: 1477, Step num: 7553, Learning rate: 0.00010170, Avg batch loss: 0.0332, Avg batch acc: 0.9665
Train, Epoch: 5, Batch: 1478, Step num: 7554, Learning rate: 0.00010170, Avg batch loss: 0.0277, Avg batch acc: 0.9659
Train, Epoch: 5, Batch: 1479, Step num: 7555, Learning rate: 0.00010169, Avg batch loss: 0.0220, Avg batch acc: 0.9718
Train, Epoch: 5, Batch: 1480, Step num: 7556, Learning rate: 0.00010168, Avg batch loss: 0.0321, Avg batch acc: 0.9699
Train, Epoch: 5, Batch: 1481, Step num: 7557, Learning rate: 0.00010168, Avg batch loss: 0.0250, Avg batch acc: 0.9705
Train, Epoch: 5, Batch: 1482, Step num: 7558, Learning rate: 0.00010167, Avg batch loss: 0.0387, Avg batch acc: 0.9637
Train, Epoch: 5, Batch: 1483, Step num: 7559, Learning rate: 0.00010166, Avg batch loss: 0.0339, Avg batch acc: 0.9650
Train, Epoch: 5, Batch: 1484, Step num: 7560, Learning rate: 0.00010166, Avg batch loss: 0.0270, Avg batch acc: 0.9677
Train, Epoch: 5, Batch: 1485, Step num: 7561, Learning rate: 0.00010165, Avg batch loss: 0.0337, Avg batch acc: 0.9691
Train, Epoch: 5, Batch: 1486, Step num: 7562, Learning rate: 0.00010164, Avg batch loss: 0.0338, Avg batch acc: 0.9685
Train, Epoch: 5, Batch: 1487, Step num: 7563, Learning rate: 0.00010164, Avg batch loss: 0.0546, Avg batch acc: 0.9533
Train, Epoch: 5, Batch: 1488, Step num: 7564, Learning rate: 0.00010163, Avg batch loss: 0.0290, Avg batch acc: 0.9701
Train, Epoch: 5, Batch: 1489, Step num: 7565, Learning rate: 0.00010162, Avg batch loss: 0.0333, Avg batch acc: 0.9680
Train, Epoch: 5, Batch: 1490, Step num: 7566, Learning rate: 0.00010162, Avg batch loss: 0.0239, Avg batch acc: 0.9746
Train, Epoch: 5, Batch: 1491, Step num: 7567, Learning rate: 0.00010161, Avg batch loss: 0.0333, Avg batch acc: 0.9673
Train, Epoch: 5, Batch: 1492, Step num: 7568, Learning rate: 0.00010160, Avg batch loss: 0.0251, Avg batch acc: 0.9726
Train, Epoch: 5, Batch: 1493, Step num: 7569, Learning rate: 0.00010160, Avg batch loss: 0.0304, Avg batch acc: 0.9690
Train, Epoch: 5, Batch: 1494, Step num: 7570, Learning rate: 0.00010159, Avg batch loss: 0.0351, Avg batch acc: 0.9602
Train, Epoch: 5, Batch: 1495, Step num: 7571, Learning rate: 0.00010158, Avg batch loss: 0.0386, Avg batch acc: 0.9628
Train, Epoch: 5, Batch: 1496, Step num: 7572, Learning rate: 0.00010158, Avg batch loss: 0.0260, Avg batch acc: 0.9702
Train, Epoch: 5, Batch: 1497, Step num: 7573, Learning rate: 0.00010157, Avg batch loss: 0.0617, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 1498, Step num: 7574, Learning rate: 0.00010156, Avg batch loss: 0.0310, Avg batch acc: 0.9687
Train, Epoch: 5, Batch: 1499, Step num: 7575, Learning rate: 0.00010156, Avg batch loss: 0.0378, Avg batch acc: 0.9588
Train, Epoch: 5, Batch: 1500, Step num: 7576, Learning rate: 0.00010155, Avg batch loss: 0.0368, Avg batch acc: 0.9583
Train, Epoch: 5, Batch: 1501, Step num: 7577, Learning rate: 0.00010154, Avg batch loss: 0.0342, Avg batch acc: 0.9696
Train, Epoch: 5, Batch: 1502, Step num: 7578, Learning rate: 0.00010154, Avg batch loss: 0.0298, Avg batch acc: 0.9685
Train, Epoch: 5, Batch: 1503, Step num: 7579, Learning rate: 0.00010153, Avg batch loss: 0.0326, Avg batch acc: 0.9664
Train, Epoch: 5, Batch: 1504, Step num: 7580, Learning rate: 0.00010152, Avg batch loss: 0.0294, Avg batch acc: 0.9670
Train, Epoch: 5, Batch: 1505, Step num: 7581, Learning rate: 0.00010152, Avg batch loss: 0.0314, Avg batch acc: 0.9679
Train, Epoch: 5, Batch: 1506, Step num: 7582, Learning rate: 0.00010151, Avg batch loss: 0.0426, Avg batch acc: 0.9611
Train, Epoch: 5, Batch: 1507, Step num: 7583, Learning rate: 0.00010150, Avg batch loss: 0.0485, Avg batch acc: 0.9626
Train, Epoch: 5, Batch: 1508, Step num: 7584, Learning rate: 0.00010150, Avg batch loss: 0.0303, Avg batch acc: 0.9688
Train, Epoch: 5, Batch: 1509, Step num: 7585, Learning rate: 0.00010149, Avg batch loss: 0.0350, Avg batch acc: 0.9645
Train, Epoch: 5, Batch: 1510, Step num: 7586, Learning rate: 0.00010148, Avg batch loss: 0.0489, Avg batch acc: 0.9605
Train, Epoch: 5, Batch: 1511, Step num: 7587, Learning rate: 0.00010148, Avg batch loss: 0.0699, Avg batch acc: 0.9649
Train, Epoch: 5, Batch: 1512, Step num: 7588, Learning rate: 0.00010147, Avg batch loss: 0.0437, Avg batch acc: 0.9591
Train, Epoch: 5, Batch: 1513, Step num: 7589, Learning rate: 0.00010146, Avg batch loss: 0.0299, Avg batch acc: 0.9657
Train, Epoch: 5, Batch: 1514, Step num: 7590, Learning rate: 0.00010146, Avg batch loss: 0.0268, Avg batch acc: 0.9689
Train, Epoch: 5, Batch: 1515, Step num: 7591, Learning rate: 0.00010145, Avg batch loss: 0.0343, Avg batch acc: 0.9636
Train, Epoch: 5, Batch: 1516, Step num: 7592, Learning rate: 0.00010144, Avg batch loss: 0.0309, Avg batch acc: 0.9700
Train, Epoch: 5, Batch: 1517, Step num: 7593, Learning rate: 0.00010144, Avg batch loss: 0.0272, Avg batch acc: 0.9727
Train, Epoch: 5, Batch: 1518, Step num: 7594, Learning rate: 0.00010143, Avg batch loss: 0.0352, Avg batch acc: 0.9638
Train, Epoch: 5, Batch: 1519, Step num: 7595, Learning rate: 0.00010142, Avg batch loss: 0.0268, Avg batch acc: 0.9764
Train, Epoch: 5, Avg epoch loss: 0.0414, Avg epoch acc: 0.9597, Overall time: 997.6 s, Speed: 4362.8 tokens/s on cuda:1

Validate, Epoch: 5, Batch: 1, Avg batch loss: 0.0314, Avg batch acc: 0.9710
Validate, Epoch: 5, Batch: 2, Avg batch loss: 0.0311, Avg batch acc: 0.9707
Validate, Epoch: 5, Batch: 3, Avg batch loss: 0.0285, Avg batch acc: 0.9713
Validate, Epoch: 5, Batch: 4, Avg batch loss: 0.0333, Avg batch acc: 0.9635
Validate, Epoch: 5, Batch: 5, Avg batch loss: 0.0334, Avg batch acc: 0.9675
Validate, Epoch: 5, Batch: 6, Avg batch loss: 0.0344, Avg batch acc: 0.9643
Validate, Epoch: 5, Batch: 7, Avg batch loss: 0.0277, Avg batch acc: 0.9683
Validate, Epoch: 5, Batch: 8, Avg batch loss: 0.0257, Avg batch acc: 0.9703
Validate, Epoch: 5, Batch: 9, Avg batch loss: 0.0519, Avg batch acc: 0.9581
Validate, Epoch: 5, Batch: 10, Avg batch loss: 0.0353, Avg batch acc: 0.9636
Validate, Epoch: 5, Batch: 11, Avg batch loss: 0.0317, Avg batch acc: 0.9665
Validate, Epoch: 5, Batch: 12, Avg batch loss: 0.0341, Avg batch acc: 0.9630
Validate, Epoch: 5, Batch: 13, Avg batch loss: 0.0299, Avg batch acc: 0.9668
Validate, Epoch: 5, Batch: 14, Avg batch loss: 0.0312, Avg batch acc: 0.9710
Validate, Epoch: 5, Batch: 15, Avg batch loss: 0.0331, Avg batch acc: 0.9686
Validate, Epoch: 5, Batch: 16, Avg batch loss: 0.0334, Avg batch acc: 0.9655
Validate, Epoch: 5, Batch: 17, Avg batch loss: 0.0423, Avg batch acc: 0.9569
Validate, Epoch: 5, Batch: 18, Avg batch loss: 0.0336, Avg batch acc: 0.9637
Validate, Epoch: 5, Batch: 19, Avg batch loss: 0.0319, Avg batch acc: 0.9680
Validate, Epoch: 5, Batch: 20, Avg batch loss: 0.0237, Avg batch acc: 0.9766
Validate, Epoch: 5, Batch: 21, Avg batch loss: 0.0358, Avg batch acc: 0.9593
Validate, Epoch: 5, Batch: 22, Avg batch loss: 0.0313, Avg batch acc: 0.9682
Validate, Epoch: 5, Batch: 23, Avg batch loss: 0.0423, Avg batch acc: 0.9610
Validate, Epoch: 5, Batch: 24, Avg batch loss: 0.0289, Avg batch acc: 0.9673
Validate, Epoch: 5, Batch: 25, Avg batch loss: 0.0304, Avg batch acc: 0.9676
Validate, Epoch: 5, Batch: 26, Avg batch loss: 0.0453, Avg batch acc: 0.9623
Validate, Epoch: 5, Batch: 27, Avg batch loss: 0.0335, Avg batch acc: 0.9593
Validate, Epoch: 5, Batch: 28, Avg batch loss: 0.0344, Avg batch acc: 0.9661
Validate, Epoch: 5, Batch: 29, Avg batch loss: 0.0327, Avg batch acc: 0.9558
Validate, Epoch: 5, Batch: 30, Avg batch loss: 0.0438, Avg batch acc: 0.9617
Validate, Epoch: 5, Batch: 31, Avg batch loss: 0.0348, Avg batch acc: 0.9655
Validate, Epoch: 5, Batch: 32, Avg batch loss: 0.0325, Avg batch acc: 0.9679
Validate, Epoch: 5, Batch: 33, Avg batch loss: 0.0333, Avg batch acc: 0.9683
Validate, Epoch: 5, Batch: 34, Avg batch loss: 0.0344, Avg batch acc: 0.9594
Validate, Epoch: 5, Batch: 35, Avg batch loss: 0.0312, Avg batch acc: 0.9610
Validate, Epoch: 5, Batch: 36, Avg batch loss: 0.0305, Avg batch acc: 0.9681
Validate, Epoch: 5, Batch: 37, Avg batch loss: 0.0342, Avg batch acc: 0.9650
Validate, Epoch: 5, Batch: 38, Avg batch loss: 0.0273, Avg batch acc: 0.9724
Validate, Epoch: 5, Batch: 39, Avg batch loss: 0.0341, Avg batch acc: 0.9668
Validate, Epoch: 5, Batch: 40, Avg batch loss: 0.0352, Avg batch acc: 0.9617
Validate, Epoch: 5, Batch: 41, Avg batch loss: 0.0562, Avg batch acc: 0.9598
Validate, Epoch: 5, Batch: 42, Avg batch loss: 0.0303, Avg batch acc: 0.9725
Validate, Epoch: 5, Batch: 43, Avg batch loss: 0.0351, Avg batch acc: 0.9637
Validate, Epoch: 5, Batch: 44, Avg batch loss: 0.0359, Avg batch acc: 0.9652
Validate, Epoch: 5, Batch: 45, Avg batch loss: 0.0357, Avg batch acc: 0.9623
Validate, Epoch: 5, Batch: 46, Avg batch loss: 0.0269, Avg batch acc: 0.9736
Validate, Epoch: 5, Batch: 47, Avg batch loss: 0.0343, Avg batch acc: 0.9610
Validate, Epoch: 5, Batch: 48, Avg batch loss: 0.0326, Avg batch acc: 0.9701
Validate, Epoch: 5, Batch: 49, Avg batch loss: 0.0361, Avg batch acc: 0.9640
Validate, Epoch: 5, Batch: 50, Avg batch loss: 0.0301, Avg batch acc: 0.9763
Validate, Epoch: 5, Batch: 51, Avg batch loss: 0.0289, Avg batch acc: 0.9713
Validate, Epoch: 5, Batch: 52, Avg batch loss: 0.0329, Avg batch acc: 0.9625
Validate, Epoch: 5, Batch: 53, Avg batch loss: 0.0299, Avg batch acc: 0.9698
Validate, Epoch: 5, Batch: 54, Avg batch loss: 0.0319, Avg batch acc: 0.9672
Validate, Epoch: 5, Batch: 55, Avg batch loss: 0.0311, Avg batch acc: 0.9683
Validate, Epoch: 5, Batch: 56, Avg batch loss: 0.0332, Avg batch acc: 0.9619
Validate, Epoch: 5, Batch: 57, Avg batch loss: 0.0395, Avg batch acc: 0.9520
Validate, Epoch: 5, Batch: 58, Avg batch loss: 0.0361, Avg batch acc: 0.9647
Validate, Epoch: 5, Batch: 59, Avg batch loss: 0.0265, Avg batch acc: 0.9729
Validate, Epoch: 5, Batch: 60, Avg batch loss: 0.0295, Avg batch acc: 0.9657
Validate, Epoch: 5, Batch: 61, Avg batch loss: 0.0289, Avg batch acc: 0.9693
Validate, Epoch: 5, Batch: 62, Avg batch loss: 0.0552, Avg batch acc: 0.9609
Validate, Epoch: 5, Batch: 63, Avg batch loss: 0.0381, Avg batch acc: 0.9583
Validate, Epoch: 5, Batch: 64, Avg batch loss: 0.0354, Avg batch acc: 0.9669
Validate, Epoch: 5, Batch: 65, Avg batch loss: 0.0370, Avg batch acc: 0.9630
Validate, Epoch: 5, Batch: 66, Avg batch loss: 0.0348, Avg batch acc: 0.9599
Validate, Epoch: 5, Batch: 67, Avg batch loss: 0.0383, Avg batch acc: 0.9606
Validate, Epoch: 5, Batch: 68, Avg batch loss: 0.0325, Avg batch acc: 0.9683
Validate, Epoch: 5, Batch: 69, Avg batch loss: 0.0353, Avg batch acc: 0.9674
Validate, Epoch: 5, Batch: 70, Avg batch loss: 0.0306, Avg batch acc: 0.9677
Validate, Epoch: 5, Batch: 71, Avg batch loss: 0.0362, Avg batch acc: 0.9598
Validate, Epoch: 5, Batch: 72, Avg batch loss: 0.0312, Avg batch acc: 0.9752
Validate, Epoch: 5, Batch: 73, Avg batch loss: 0.0316, Avg batch acc: 0.9664
Validate, Epoch: 5, Batch: 74, Avg batch loss: 0.0237, Avg batch acc: 0.9732
Validate, Epoch: 5, Batch: 75, Avg batch loss: 0.0310, Avg batch acc: 0.9698
Validate, Epoch: 5, Batch: 76, Avg batch loss: 0.0310, Avg batch acc: 0.9677
Validate, Epoch: 5, Batch: 77, Avg batch loss: 0.0435, Avg batch acc: 0.9603
Validate, Epoch: 5, Batch: 78, Avg batch loss: 0.0337, Avg batch acc: 0.9664
Validate, Epoch: 5, Batch: 79, Avg batch loss: 0.0274, Avg batch acc: 0.9642
Validate, Epoch: 5, Batch: 80, Avg batch loss: 0.0346, Avg batch acc: 0.9660
Validate, Epoch: 5, Batch: 81, Avg batch loss: 0.0279, Avg batch acc: 0.9737
Validate, Epoch: 5, Batch: 82, Avg batch loss: 0.0392, Avg batch acc: 0.9614
Validate, Epoch: 5, Batch: 83, Avg batch loss: 0.0430, Avg batch acc: 0.9621
Validate, Epoch: 5, Batch: 84, Avg batch loss: 0.0309, Avg batch acc: 0.9668
Validate, Epoch: 5, Batch: 85, Avg batch loss: 0.0255, Avg batch acc: 0.9709
Validate, Epoch: 5, Batch: 86, Avg batch loss: 0.0292, Avg batch acc: 0.9682
Validate, Epoch: 5, Batch: 87, Avg batch loss: 0.0301, Avg batch acc: 0.9669
Validate, Epoch: 5, Batch: 88, Avg batch loss: 0.0337, Avg batch acc: 0.9638
Validate, Epoch: 5, Batch: 89, Avg batch loss: 0.0377, Avg batch acc: 0.9638
Validate, Epoch: 5, Batch: 90, Avg batch loss: 0.0424, Avg batch acc: 0.9599
Validate, Epoch: 5, Batch: 91, Avg batch loss: 0.0297, Avg batch acc: 0.9752
Validate, Epoch: 5, Batch: 92, Avg batch loss: 0.0277, Avg batch acc: 0.9669
Validate, Epoch: 5, Batch: 93, Avg batch loss: 0.0336, Avg batch acc: 0.9684
Validate, Epoch: 5, Batch: 94, Avg batch loss: 0.0340, Avg batch acc: 0.9667
Validate, Epoch: 5, Batch: 95, Avg batch loss: 0.0408, Avg batch acc: 0.9633
Validate, Epoch: 5, Batch: 96, Avg batch loss: 0.0327, Avg batch acc: 0.9675
Validate, Epoch: 5, Batch: 97, Avg batch loss: 0.0389, Avg batch acc: 0.9565
Validate, Epoch: 5, Batch: 98, Avg batch loss: 0.0332, Avg batch acc: 0.9600
Validate, Epoch: 5, Batch: 99, Avg batch loss: 0.0262, Avg batch acc: 0.9687
Validate, Epoch: 5, Batch: 100, Avg batch loss: 0.0309, Avg batch acc: 0.9667
Validate, Epoch: 5, Batch: 101, Avg batch loss: 0.0392, Avg batch acc: 0.9643
Validate, Epoch: 5, Batch: 102, Avg batch loss: 0.0296, Avg batch acc: 0.9661
Validate, Epoch: 5, Batch: 103, Avg batch loss: 0.0288, Avg batch acc: 0.9664
Validate, Epoch: 5, Batch: 104, Avg batch loss: 0.0381, Avg batch acc: 0.9629
Validate, Epoch: 5, Batch: 105, Avg batch loss: 0.0333, Avg batch acc: 0.9672
Validate, Epoch: 5, Batch: 106, Avg batch loss: 0.0390, Avg batch acc: 0.9607
Validate, Epoch: 5, Batch: 107, Avg batch loss: 0.0287, Avg batch acc: 0.9694
Validate, Epoch: 5, Batch: 108, Avg batch loss: 0.0299, Avg batch acc: 0.9690
Validate, Epoch: 5, Batch: 109, Avg batch loss: 0.0374, Avg batch acc: 0.9639
Validate, Epoch: 5, Batch: 110, Avg batch loss: 0.0291, Avg batch acc: 0.9632
Validate, Epoch: 5, Batch: 111, Avg batch loss: 0.0282, Avg batch acc: 0.9691
Validate, Epoch: 5, Batch: 112, Avg batch loss: 0.0310, Avg batch acc: 0.9680
Validate, Epoch: 5, Batch: 113, Avg batch loss: 0.0331, Avg batch acc: 0.9667
Validate, Epoch: 5, Batch: 114, Avg batch loss: 0.0311, Avg batch acc: 0.9670
Validate, Epoch: 5, Batch: 115, Avg batch loss: 0.0359, Avg batch acc: 0.9675
Validate, Epoch: 5, Batch: 116, Avg batch loss: 0.0410, Avg batch acc: 0.9619
Validate, Epoch: 5, Batch: 117, Avg batch loss: 0.0296, Avg batch acc: 0.9667
Validate, Epoch: 5, Batch: 118, Avg batch loss: 0.0388, Avg batch acc: 0.9664
Validate, Epoch: 5, Batch: 119, Avg batch loss: 0.0370, Avg batch acc: 0.9646
Validate, Epoch: 5, Batch: 120, Avg batch loss: 0.0287, Avg batch acc: 0.9720
Validate, Epoch: 5, Batch: 121, Avg batch loss: 0.0269, Avg batch acc: 0.9756
Validate, Epoch: 5, Batch: 122, Avg batch loss: 0.0303, Avg batch acc: 0.9672
Validate, Epoch: 5, Batch: 123, Avg batch loss: 0.0267, Avg batch acc: 0.9724
Validate, Epoch: 5, Batch: 124, Avg batch loss: 0.0239, Avg batch acc: 0.9745
Validate, Epoch: 5, Batch: 125, Avg batch loss: 0.0308, Avg batch acc: 0.9703
Validate, Epoch: 5, Batch: 126, Avg batch loss: 0.0276, Avg batch acc: 0.9682
Validate, Epoch: 5, Batch: 127, Avg batch loss: 0.0325, Avg batch acc: 0.9647
Validate, Epoch: 5, Batch: 128, Avg batch loss: 0.0311, Avg batch acc: 0.9596
Validate, Epoch: 5, Batch: 129, Avg batch loss: 0.0283, Avg batch acc: 0.9687
Validate, Epoch: 5, Batch: 130, Avg batch loss: 0.0753, Avg batch acc: 0.9619
Validate, Epoch: 5, Batch: 131, Avg batch loss: 0.0291, Avg batch acc: 0.9705
Validate, Epoch: 5, Batch: 132, Avg batch loss: 0.0313, Avg batch acc: 0.9640
Validate, Epoch: 5, Batch: 133, Avg batch loss: 0.0267, Avg batch acc: 0.9703
Validate, Epoch: 5, Batch: 134, Avg batch loss: 0.0333, Avg batch acc: 0.9644
Validate, Epoch: 5, Batch: 135, Avg batch loss: 0.0543, Avg batch acc: 0.9612
Validate, Epoch: 5, Batch: 136, Avg batch loss: 0.0359, Avg batch acc: 0.9628
Validate, Epoch: 5, Batch: 137, Avg batch loss: 0.0410, Avg batch acc: 0.9567
Validate, Epoch: 5, Batch: 138, Avg batch loss: 0.0294, Avg batch acc: 0.9701
Validate, Epoch: 5, Batch: 139, Avg batch loss: 0.0307, Avg batch acc: 0.9684
Validate, Epoch: 5, Batch: 140, Avg batch loss: 0.0325, Avg batch acc: 0.9626
Validate, Epoch: 5, Batch: 141, Avg batch loss: 0.0346, Avg batch acc: 0.9640
Validate, Epoch: 5, Batch: 142, Avg batch loss: 0.0307, Avg batch acc: 0.9673
Validate, Epoch: 5, Batch: 143, Avg batch loss: 0.0302, Avg batch acc: 0.9663
Validate, Epoch: 5, Batch: 144, Avg batch loss: 0.0381, Avg batch acc: 0.9669
Validate, Epoch: 5, Batch: 145, Avg batch loss: 0.0287, Avg batch acc: 0.9688
Validate, Epoch: 5, Batch: 146, Avg batch loss: 0.0240, Avg batch acc: 0.9764
Validate, Epoch: 5, Batch: 147, Avg batch loss: 0.0282, Avg batch acc: 0.9715
Validate, Epoch: 5, Batch: 148, Avg batch loss: 0.0292, Avg batch acc: 0.9681
Validate, Epoch: 5, Batch: 149, Avg batch loss: 0.0314, Avg batch acc: 0.9703
Validate, Epoch: 5, Batch: 150, Avg batch loss: 0.0351, Avg batch acc: 0.9592
Validate, Epoch: 5, Batch: 151, Avg batch loss: 0.0254, Avg batch acc: 0.9732
Validate, Epoch: 5, Batch: 152, Avg batch loss: 0.0373, Avg batch acc: 0.9665
Validate, Epoch: 5, Batch: 153, Avg batch loss: 0.0312, Avg batch acc: 0.9662
Validate, Epoch: 5, Batch: 154, Avg batch loss: 0.0315, Avg batch acc: 0.9677
Validate, Epoch: 5, Batch: 155, Avg batch loss: 0.0344, Avg batch acc: 0.9669
Validate, Epoch: 5, Batch: 156, Avg batch loss: 0.0342, Avg batch acc: 0.9666
Validate, Epoch: 5, Batch: 157, Avg batch loss: 0.0572, Avg batch acc: 0.9535
Validate, Epoch: 5, Batch: 158, Avg batch loss: 0.0264, Avg batch acc: 0.9717
Validate, Epoch: 5, Batch: 159, Avg batch loss: 0.0312, Avg batch acc: 0.9657
Validate, Epoch: 5, Batch: 160, Avg batch loss: 0.0440, Avg batch acc: 0.9651
Validate, Epoch: 5, Batch: 161, Avg batch loss: 0.0371, Avg batch acc: 0.9645
Validate, Epoch: 5, Batch: 162, Avg batch loss: 0.0284, Avg batch acc: 0.9730
Validate, Epoch: 5, Batch: 163, Avg batch loss: 0.0341, Avg batch acc: 0.9658
Validate, Epoch: 5, Batch: 164, Avg batch loss: 0.0301, Avg batch acc: 0.9645
Validate, Epoch: 5, Batch: 165, Avg batch loss: 0.0485, Avg batch acc: 0.9619
Validate, Epoch: 5, Batch: 166, Avg batch loss: 0.0322, Avg batch acc: 0.9675
Validate, Epoch: 5, Batch: 167, Avg batch loss: 0.0352, Avg batch acc: 0.9639
Validate, Epoch: 5, Batch: 168, Avg batch loss: 0.0312, Avg batch acc: 0.9673
Validate, Epoch: 5, Batch: 169, Avg batch loss: 0.0331, Avg batch acc: 0.9669
Validate, Epoch: 5, Avg epoch loss: 0.0337, Avg epoch acc: 0.9661, Overall time: 36.9 s, Speed: 13078.8 tokens/s on cuda:1

Train, Epoch: 6, Batch: 1, Step num: 7596, Learning rate: 0.00010142, Avg batch loss: 0.0260, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 2, Step num: 7597, Learning rate: 0.00010141, Avg batch loss: 0.0344, Avg batch acc: 0.9647
Train, Epoch: 6, Batch: 3, Step num: 7598, Learning rate: 0.00010140, Avg batch loss: 0.0260, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 4, Step num: 7599, Learning rate: 0.00010140, Avg batch loss: 0.0404, Avg batch acc: 0.9631
Train, Epoch: 6, Batch: 5, Step num: 7600, Learning rate: 0.00010139, Avg batch loss: 0.0328, Avg batch acc: 0.9605
Train, Epoch: 6, Batch: 6, Step num: 7601, Learning rate: 0.00010138, Avg batch loss: 0.0349, Avg batch acc: 0.9710
Train, Epoch: 6, Batch: 7, Step num: 7602, Learning rate: 0.00010138, Avg batch loss: 0.0295, Avg batch acc: 0.9686
Train, Epoch: 6, Batch: 8, Step num: 7603, Learning rate: 0.00010137, Avg batch loss: 0.0329, Avg batch acc: 0.9664
Train, Epoch: 6, Batch: 9, Step num: 7604, Learning rate: 0.00010136, Avg batch loss: 0.0327, Avg batch acc: 0.9631
Train, Epoch: 6, Batch: 10, Step num: 7605, Learning rate: 0.00010136, Avg batch loss: 0.0267, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 11, Step num: 7606, Learning rate: 0.00010135, Avg batch loss: 0.0335, Avg batch acc: 0.9656
Train, Epoch: 6, Batch: 12, Step num: 7607, Learning rate: 0.00010134, Avg batch loss: 0.0379, Avg batch acc: 0.9633
Train, Epoch: 6, Batch: 13, Step num: 7608, Learning rate: 0.00010134, Avg batch loss: 0.0365, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 14, Step num: 7609, Learning rate: 0.00010133, Avg batch loss: 0.0326, Avg batch acc: 0.9649
Train, Epoch: 6, Batch: 15, Step num: 7610, Learning rate: 0.00010132, Avg batch loss: 0.0328, Avg batch acc: 0.9674
Train, Epoch: 6, Batch: 16, Step num: 7611, Learning rate: 0.00010132, Avg batch loss: 0.0306, Avg batch acc: 0.9690
Train, Epoch: 6, Batch: 17, Step num: 7612, Learning rate: 0.00010131, Avg batch loss: 0.0285, Avg batch acc: 0.9727
Train, Epoch: 6, Batch: 18, Step num: 7613, Learning rate: 0.00010130, Avg batch loss: 0.0398, Avg batch acc: 0.9600
Train, Epoch: 6, Batch: 19, Step num: 7614, Learning rate: 0.00010130, Avg batch loss: 0.0370, Avg batch acc: 0.9653
Train, Epoch: 6, Batch: 20, Step num: 7615, Learning rate: 0.00010129, Avg batch loss: 0.0311, Avg batch acc: 0.9656
Train, Epoch: 6, Batch: 21, Step num: 7616, Learning rate: 0.00010128, Avg batch loss: 0.0269, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 22, Step num: 7617, Learning rate: 0.00010128, Avg batch loss: 0.0433, Avg batch acc: 0.9615
Train, Epoch: 6, Batch: 23, Step num: 7618, Learning rate: 0.00010127, Avg batch loss: 0.0331, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 24, Step num: 7619, Learning rate: 0.00010126, Avg batch loss: 0.0337, Avg batch acc: 0.9610
Train, Epoch: 6, Batch: 25, Step num: 7620, Learning rate: 0.00010126, Avg batch loss: 0.0302, Avg batch acc: 0.9696
Train, Epoch: 6, Batch: 26, Step num: 7621, Learning rate: 0.00010125, Avg batch loss: 0.0347, Avg batch acc: 0.9606
Train, Epoch: 6, Batch: 27, Step num: 7622, Learning rate: 0.00010124, Avg batch loss: 0.0298, Avg batch acc: 0.9651
Train, Epoch: 6, Batch: 28, Step num: 7623, Learning rate: 0.00010124, Avg batch loss: 0.0251, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 29, Step num: 7624, Learning rate: 0.00010123, Avg batch loss: 0.0292, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 30, Step num: 7625, Learning rate: 0.00010122, Avg batch loss: 0.0312, Avg batch acc: 0.9663
Train, Epoch: 6, Batch: 31, Step num: 7626, Learning rate: 0.00010122, Avg batch loss: 0.0376, Avg batch acc: 0.9623
Train, Epoch: 6, Batch: 32, Step num: 7627, Learning rate: 0.00010121, Avg batch loss: 0.0273, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 33, Step num: 7628, Learning rate: 0.00010120, Avg batch loss: 0.0307, Avg batch acc: 0.9642
Train, Epoch: 6, Batch: 34, Step num: 7629, Learning rate: 0.00010120, Avg batch loss: 0.0331, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 35, Step num: 7630, Learning rate: 0.00010119, Avg batch loss: 0.0411, Avg batch acc: 0.9655
Train, Epoch: 6, Batch: 36, Step num: 7631, Learning rate: 0.00010118, Avg batch loss: 0.0283, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 37, Step num: 7632, Learning rate: 0.00010118, Avg batch loss: 0.0310, Avg batch acc: 0.9677
Train, Epoch: 6, Batch: 38, Step num: 7633, Learning rate: 0.00010117, Avg batch loss: 0.0278, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 39, Step num: 7634, Learning rate: 0.00010116, Avg batch loss: 0.0300, Avg batch acc: 0.9696
Train, Epoch: 6, Batch: 40, Step num: 7635, Learning rate: 0.00010116, Avg batch loss: 0.0318, Avg batch acc: 0.9623
Train, Epoch: 6, Batch: 41, Step num: 7636, Learning rate: 0.00010115, Avg batch loss: 0.0482, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 42, Step num: 7637, Learning rate: 0.00010114, Avg batch loss: 0.0303, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 43, Step num: 7638, Learning rate: 0.00010114, Avg batch loss: 0.0298, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 44, Step num: 7639, Learning rate: 0.00010113, Avg batch loss: 0.0303, Avg batch acc: 0.9639
Train, Epoch: 6, Batch: 45, Step num: 7640, Learning rate: 0.00010112, Avg batch loss: 0.0377, Avg batch acc: 0.9611
Train, Epoch: 6, Batch: 46, Step num: 7641, Learning rate: 0.00010112, Avg batch loss: 0.0284, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 47, Step num: 7642, Learning rate: 0.00010111, Avg batch loss: 0.0355, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 48, Step num: 7643, Learning rate: 0.00010110, Avg batch loss: 0.0306, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 49, Step num: 7644, Learning rate: 0.00010110, Avg batch loss: 0.0487, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 50, Step num: 7645, Learning rate: 0.00010109, Avg batch loss: 0.0257, Avg batch acc: 0.9725
Train, Epoch: 6, Batch: 51, Step num: 7646, Learning rate: 0.00010108, Avg batch loss: 0.0525, Avg batch acc: 0.9665
Train, Epoch: 6, Batch: 52, Step num: 7647, Learning rate: 0.00010108, Avg batch loss: 0.0333, Avg batch acc: 0.9642
Train, Epoch: 6, Batch: 53, Step num: 7648, Learning rate: 0.00010107, Avg batch loss: 0.0280, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 54, Step num: 7649, Learning rate: 0.00010106, Avg batch loss: 0.0307, Avg batch acc: 0.9675
Train, Epoch: 6, Batch: 55, Step num: 7650, Learning rate: 0.00010106, Avg batch loss: 0.0234, Avg batch acc: 0.9781
Train, Epoch: 6, Batch: 56, Step num: 7651, Learning rate: 0.00010105, Avg batch loss: 0.0369, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 57, Step num: 7652, Learning rate: 0.00010104, Avg batch loss: 0.0404, Avg batch acc: 0.9617
Train, Epoch: 6, Batch: 58, Step num: 7653, Learning rate: 0.00010104, Avg batch loss: 0.0307, Avg batch acc: 0.9702
Train, Epoch: 6, Batch: 59, Step num: 7654, Learning rate: 0.00010103, Avg batch loss: 0.0356, Avg batch acc: 0.9641
Train, Epoch: 6, Batch: 60, Step num: 7655, Learning rate: 0.00010102, Avg batch loss: 0.0354, Avg batch acc: 0.9636
Train, Epoch: 6, Batch: 61, Step num: 7656, Learning rate: 0.00010102, Avg batch loss: 0.0374, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 62, Step num: 7657, Learning rate: 0.00010101, Avg batch loss: 0.0407, Avg batch acc: 0.9668
Train, Epoch: 6, Batch: 63, Step num: 7658, Learning rate: 0.00010100, Avg batch loss: 0.0298, Avg batch acc: 0.9643
Train, Epoch: 6, Batch: 64, Step num: 7659, Learning rate: 0.00010100, Avg batch loss: 0.0481, Avg batch acc: 0.9529
Train, Epoch: 6, Batch: 65, Step num: 7660, Learning rate: 0.00010099, Avg batch loss: 0.0272, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 66, Step num: 7661, Learning rate: 0.00010098, Avg batch loss: 0.0257, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 67, Step num: 7662, Learning rate: 0.00010098, Avg batch loss: 0.0320, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 68, Step num: 7663, Learning rate: 0.00010097, Avg batch loss: 0.0327, Avg batch acc: 0.9669
Train, Epoch: 6, Batch: 69, Step num: 7664, Learning rate: 0.00010096, Avg batch loss: 0.0387, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 70, Step num: 7665, Learning rate: 0.00010096, Avg batch loss: 0.0288, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 71, Step num: 7666, Learning rate: 0.00010095, Avg batch loss: 0.0312, Avg batch acc: 0.9655
Train, Epoch: 6, Batch: 72, Step num: 7667, Learning rate: 0.00010094, Avg batch loss: 0.0376, Avg batch acc: 0.9590
Train, Epoch: 6, Batch: 73, Step num: 7668, Learning rate: 0.00010094, Avg batch loss: 0.0316, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 74, Step num: 7669, Learning rate: 0.00010093, Avg batch loss: 0.0377, Avg batch acc: 0.9611
Train, Epoch: 6, Batch: 75, Step num: 7670, Learning rate: 0.00010092, Avg batch loss: 0.0271, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 76, Step num: 7671, Learning rate: 0.00010092, Avg batch loss: 0.0353, Avg batch acc: 0.9660
Train, Epoch: 6, Batch: 77, Step num: 7672, Learning rate: 0.00010091, Avg batch loss: 0.0320, Avg batch acc: 0.9656
Train, Epoch: 6, Batch: 78, Step num: 7673, Learning rate: 0.00010090, Avg batch loss: 0.0260, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 79, Step num: 7674, Learning rate: 0.00010090, Avg batch loss: 0.0249, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 80, Step num: 7675, Learning rate: 0.00010089, Avg batch loss: 0.0338, Avg batch acc: 0.9634
Train, Epoch: 6, Batch: 81, Step num: 7676, Learning rate: 0.00010089, Avg batch loss: 0.0333, Avg batch acc: 0.9648
Train, Epoch: 6, Batch: 82, Step num: 7677, Learning rate: 0.00010088, Avg batch loss: 0.0290, Avg batch acc: 0.9683
Train, Epoch: 6, Batch: 83, Step num: 7678, Learning rate: 0.00010087, Avg batch loss: 0.0254, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 84, Step num: 7679, Learning rate: 0.00010087, Avg batch loss: 0.0300, Avg batch acc: 0.9643
Train, Epoch: 6, Batch: 85, Step num: 7680, Learning rate: 0.00010086, Avg batch loss: 0.0324, Avg batch acc: 0.9639
Train, Epoch: 6, Batch: 86, Step num: 7681, Learning rate: 0.00010085, Avg batch loss: 0.0301, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 87, Step num: 7682, Learning rate: 0.00010085, Avg batch loss: 0.0277, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 88, Step num: 7683, Learning rate: 0.00010084, Avg batch loss: 0.0372, Avg batch acc: 0.9622
Train, Epoch: 6, Batch: 89, Step num: 7684, Learning rate: 0.00010083, Avg batch loss: 0.0332, Avg batch acc: 0.9604
Train, Epoch: 6, Batch: 90, Step num: 7685, Learning rate: 0.00010083, Avg batch loss: 0.0252, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 91, Step num: 7686, Learning rate: 0.00010082, Avg batch loss: 0.0373, Avg batch acc: 0.9667
Train, Epoch: 6, Batch: 92, Step num: 7687, Learning rate: 0.00010081, Avg batch loss: 0.0270, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 93, Step num: 7688, Learning rate: 0.00010081, Avg batch loss: 0.0274, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 94, Step num: 7689, Learning rate: 0.00010080, Avg batch loss: 0.0274, Avg batch acc: 0.9712
Train, Epoch: 6, Batch: 95, Step num: 7690, Learning rate: 0.00010079, Avg batch loss: 0.0252, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 96, Step num: 7691, Learning rate: 0.00010079, Avg batch loss: 0.0317, Avg batch acc: 0.9672
Train, Epoch: 6, Batch: 97, Step num: 7692, Learning rate: 0.00010078, Avg batch loss: 0.0278, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 98, Step num: 7693, Learning rate: 0.00010077, Avg batch loss: 0.0305, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 99, Step num: 7694, Learning rate: 0.00010077, Avg batch loss: 0.0283, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 100, Step num: 7695, Learning rate: 0.00010076, Avg batch loss: 0.0330, Avg batch acc: 0.9630
Train, Epoch: 6, Batch: 101, Step num: 7696, Learning rate: 0.00010075, Avg batch loss: 0.0306, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 102, Step num: 7697, Learning rate: 0.00010075, Avg batch loss: 0.0272, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 103, Step num: 7698, Learning rate: 0.00010074, Avg batch loss: 0.0251, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 104, Step num: 7699, Learning rate: 0.00010073, Avg batch loss: 0.0280, Avg batch acc: 0.9696
Train, Epoch: 6, Batch: 105, Step num: 7700, Learning rate: 0.00010073, Avg batch loss: 0.0325, Avg batch acc: 0.9686
Train, Epoch: 6, Batch: 106, Step num: 7701, Learning rate: 0.00010072, Avg batch loss: 0.0289, Avg batch acc: 0.9697
Train, Epoch: 6, Batch: 107, Step num: 7702, Learning rate: 0.00010071, Avg batch loss: 0.0286, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 108, Step num: 7703, Learning rate: 0.00010071, Avg batch loss: 0.0314, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 109, Step num: 7704, Learning rate: 0.00010070, Avg batch loss: 0.0257, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 110, Step num: 7705, Learning rate: 0.00010070, Avg batch loss: 0.0259, Avg batch acc: 0.9614
Train, Epoch: 6, Batch: 111, Step num: 7706, Learning rate: 0.00010069, Avg batch loss: 0.0259, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 112, Step num: 7707, Learning rate: 0.00010068, Avg batch loss: 0.0318, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 113, Step num: 7708, Learning rate: 0.00010068, Avg batch loss: 0.0328, Avg batch acc: 0.9639
Train, Epoch: 6, Batch: 114, Step num: 7709, Learning rate: 0.00010067, Avg batch loss: 0.0252, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 115, Step num: 7710, Learning rate: 0.00010066, Avg batch loss: 0.0315, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 116, Step num: 7711, Learning rate: 0.00010066, Avg batch loss: 0.0341, Avg batch acc: 0.9669
Train, Epoch: 6, Batch: 117, Step num: 7712, Learning rate: 0.00010065, Avg batch loss: 0.0320, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 118, Step num: 7713, Learning rate: 0.00010064, Avg batch loss: 0.0325, Avg batch acc: 0.9647
Train, Epoch: 6, Batch: 119, Step num: 7714, Learning rate: 0.00010064, Avg batch loss: 0.0340, Avg batch acc: 0.9646
Train, Epoch: 6, Batch: 120, Step num: 7715, Learning rate: 0.00010063, Avg batch loss: 0.0339, Avg batch acc: 0.9644
Train, Epoch: 6, Batch: 121, Step num: 7716, Learning rate: 0.00010062, Avg batch loss: 0.0350, Avg batch acc: 0.9672
Train, Epoch: 6, Batch: 122, Step num: 7717, Learning rate: 0.00010062, Avg batch loss: 0.0297, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 123, Step num: 7718, Learning rate: 0.00010061, Avg batch loss: 0.0272, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 124, Step num: 7719, Learning rate: 0.00010060, Avg batch loss: 0.0297, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 125, Step num: 7720, Learning rate: 0.00010060, Avg batch loss: 0.0244, Avg batch acc: 0.9719
Train, Epoch: 6, Batch: 126, Step num: 7721, Learning rate: 0.00010059, Avg batch loss: 0.0255, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 127, Step num: 7722, Learning rate: 0.00010058, Avg batch loss: 0.0303, Avg batch acc: 0.9710
Train, Epoch: 6, Batch: 128, Step num: 7723, Learning rate: 0.00010058, Avg batch loss: 0.0307, Avg batch acc: 0.9681
Train, Epoch: 6, Batch: 129, Step num: 7724, Learning rate: 0.00010057, Avg batch loss: 0.0283, Avg batch acc: 0.9691
Train, Epoch: 6, Batch: 130, Step num: 7725, Learning rate: 0.00010056, Avg batch loss: 0.0286, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 131, Step num: 7726, Learning rate: 0.00010056, Avg batch loss: 0.0291, Avg batch acc: 0.9646
Train, Epoch: 6, Batch: 132, Step num: 7727, Learning rate: 0.00010055, Avg batch loss: 0.0259, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 133, Step num: 7728, Learning rate: 0.00010055, Avg batch loss: 0.0262, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 134, Step num: 7729, Learning rate: 0.00010054, Avg batch loss: 0.0307, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 135, Step num: 7730, Learning rate: 0.00010053, Avg batch loss: 0.0263, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 136, Step num: 7731, Learning rate: 0.00010053, Avg batch loss: 0.0262, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 137, Step num: 7732, Learning rate: 0.00010052, Avg batch loss: 0.0305, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 138, Step num: 7733, Learning rate: 0.00010051, Avg batch loss: 0.0311, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 139, Step num: 7734, Learning rate: 0.00010051, Avg batch loss: 0.0288, Avg batch acc: 0.9677
Train, Epoch: 6, Batch: 140, Step num: 7735, Learning rate: 0.00010050, Avg batch loss: 0.0282, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 141, Step num: 7736, Learning rate: 0.00010049, Avg batch loss: 0.0345, Avg batch acc: 0.9660
Train, Epoch: 6, Batch: 142, Step num: 7737, Learning rate: 0.00010049, Avg batch loss: 0.0324, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 143, Step num: 7738, Learning rate: 0.00010048, Avg batch loss: 0.0239, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 144, Step num: 7739, Learning rate: 0.00010047, Avg batch loss: 0.0323, Avg batch acc: 0.9633
Train, Epoch: 6, Batch: 145, Step num: 7740, Learning rate: 0.00010047, Avg batch loss: 0.0284, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 146, Step num: 7741, Learning rate: 0.00010046, Avg batch loss: 0.0304, Avg batch acc: 0.9725
Train, Epoch: 6, Batch: 147, Step num: 7742, Learning rate: 0.00010045, Avg batch loss: 0.0313, Avg batch acc: 0.9621
Train, Epoch: 6, Batch: 148, Step num: 7743, Learning rate: 0.00010045, Avg batch loss: 0.0307, Avg batch acc: 0.9674
Train, Epoch: 6, Batch: 149, Step num: 7744, Learning rate: 0.00010044, Avg batch loss: 0.0281, Avg batch acc: 0.9691
Train, Epoch: 6, Batch: 150, Step num: 7745, Learning rate: 0.00010043, Avg batch loss: 0.0349, Avg batch acc: 0.9626
Train, Epoch: 6, Batch: 151, Step num: 7746, Learning rate: 0.00010043, Avg batch loss: 0.0351, Avg batch acc: 0.9636
Train, Epoch: 6, Batch: 152, Step num: 7747, Learning rate: 0.00010042, Avg batch loss: 0.0369, Avg batch acc: 0.9644
Train, Epoch: 6, Batch: 153, Step num: 7748, Learning rate: 0.00010042, Avg batch loss: 0.0431, Avg batch acc: 0.9634
Train, Epoch: 6, Batch: 154, Step num: 7749, Learning rate: 0.00010041, Avg batch loss: 0.0310, Avg batch acc: 0.9645
Train, Epoch: 6, Batch: 155, Step num: 7750, Learning rate: 0.00010040, Avg batch loss: 0.0320, Avg batch acc: 0.9670
Train, Epoch: 6, Batch: 156, Step num: 7751, Learning rate: 0.00010040, Avg batch loss: 0.0300, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 157, Step num: 7752, Learning rate: 0.00010039, Avg batch loss: 0.0234, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 158, Step num: 7753, Learning rate: 0.00010038, Avg batch loss: 0.0283, Avg batch acc: 0.9651
Train, Epoch: 6, Batch: 159, Step num: 7754, Learning rate: 0.00010038, Avg batch loss: 0.0311, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 160, Step num: 7755, Learning rate: 0.00010037, Avg batch loss: 0.0349, Avg batch acc: 0.9667
Train, Epoch: 6, Batch: 161, Step num: 7756, Learning rate: 0.00010036, Avg batch loss: 0.0338, Avg batch acc: 0.9643
Train, Epoch: 6, Batch: 162, Step num: 7757, Learning rate: 0.00010036, Avg batch loss: 0.0316, Avg batch acc: 0.9692
Train, Epoch: 6, Batch: 163, Step num: 7758, Learning rate: 0.00010035, Avg batch loss: 0.0304, Avg batch acc: 0.9692
Train, Epoch: 6, Batch: 164, Step num: 7759, Learning rate: 0.00010034, Avg batch loss: 0.0289, Avg batch acc: 0.9682
Train, Epoch: 6, Batch: 165, Step num: 7760, Learning rate: 0.00010034, Avg batch loss: 0.0256, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 166, Step num: 7761, Learning rate: 0.00010033, Avg batch loss: 0.0274, Avg batch acc: 0.9680
Train, Epoch: 6, Batch: 167, Step num: 7762, Learning rate: 0.00010032, Avg batch loss: 0.0426, Avg batch acc: 0.9606
Train, Epoch: 6, Batch: 168, Step num: 7763, Learning rate: 0.00010032, Avg batch loss: 0.0278, Avg batch acc: 0.9670
Train, Epoch: 6, Batch: 169, Step num: 7764, Learning rate: 0.00010031, Avg batch loss: 0.0308, Avg batch acc: 0.9664
Train, Epoch: 6, Batch: 170, Step num: 7765, Learning rate: 0.00010031, Avg batch loss: 0.0237, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 171, Step num: 7766, Learning rate: 0.00010030, Avg batch loss: 0.0298, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 172, Step num: 7767, Learning rate: 0.00010029, Avg batch loss: 0.0268, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 173, Step num: 7768, Learning rate: 0.00010029, Avg batch loss: 0.0306, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 174, Step num: 7769, Learning rate: 0.00010028, Avg batch loss: 0.0337, Avg batch acc: 0.9669
Train, Epoch: 6, Batch: 175, Step num: 7770, Learning rate: 0.00010027, Avg batch loss: 0.0355, Avg batch acc: 0.9646
Train, Epoch: 6, Batch: 176, Step num: 7771, Learning rate: 0.00010027, Avg batch loss: 0.0261, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 177, Step num: 7772, Learning rate: 0.00010026, Avg batch loss: 0.0312, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 178, Step num: 7773, Learning rate: 0.00010025, Avg batch loss: 0.0236, Avg batch acc: 0.9727
Train, Epoch: 6, Batch: 179, Step num: 7774, Learning rate: 0.00010025, Avg batch loss: 0.0315, Avg batch acc: 0.9691
Train, Epoch: 6, Batch: 180, Step num: 7775, Learning rate: 0.00010024, Avg batch loss: 0.0269, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 181, Step num: 7776, Learning rate: 0.00010023, Avg batch loss: 0.0282, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 182, Step num: 7777, Learning rate: 0.00010023, Avg batch loss: 0.0248, Avg batch acc: 0.9771
Train, Epoch: 6, Batch: 183, Step num: 7778, Learning rate: 0.00010022, Avg batch loss: 0.0298, Avg batch acc: 0.9712
Train, Epoch: 6, Batch: 184, Step num: 7779, Learning rate: 0.00010022, Avg batch loss: 0.0329, Avg batch acc: 0.9664
Train, Epoch: 6, Batch: 185, Step num: 7780, Learning rate: 0.00010021, Avg batch loss: 0.0264, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 186, Step num: 7781, Learning rate: 0.00010020, Avg batch loss: 0.0277, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 187, Step num: 7782, Learning rate: 0.00010020, Avg batch loss: 0.0273, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 188, Step num: 7783, Learning rate: 0.00010019, Avg batch loss: 0.0383, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 189, Step num: 7784, Learning rate: 0.00010018, Avg batch loss: 0.0301, Avg batch acc: 0.9656
Train, Epoch: 6, Batch: 190, Step num: 7785, Learning rate: 0.00010018, Avg batch loss: 0.0330, Avg batch acc: 0.9591
Train, Epoch: 6, Batch: 191, Step num: 7786, Learning rate: 0.00010017, Avg batch loss: 0.0373, Avg batch acc: 0.9639
Train, Epoch: 6, Batch: 192, Step num: 7787, Learning rate: 0.00010016, Avg batch loss: 0.0260, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 193, Step num: 7788, Learning rate: 0.00010016, Avg batch loss: 0.0260, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 194, Step num: 7789, Learning rate: 0.00010015, Avg batch loss: 0.0515, Avg batch acc: 0.9584
Train, Epoch: 6, Batch: 195, Step num: 7790, Learning rate: 0.00010014, Avg batch loss: 0.0353, Avg batch acc: 0.9625
Train, Epoch: 6, Batch: 196, Step num: 7791, Learning rate: 0.00010014, Avg batch loss: 0.0276, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 197, Step num: 7792, Learning rate: 0.00010013, Avg batch loss: 0.0311, Avg batch acc: 0.9647
Train, Epoch: 6, Batch: 198, Step num: 7793, Learning rate: 0.00010013, Avg batch loss: 0.0378, Avg batch acc: 0.9580
Train, Epoch: 6, Batch: 199, Step num: 7794, Learning rate: 0.00010012, Avg batch loss: 0.0351, Avg batch acc: 0.9675
Train, Epoch: 6, Batch: 200, Step num: 7795, Learning rate: 0.00010011, Avg batch loss: 0.0327, Avg batch acc: 0.9672
Train, Epoch: 6, Batch: 201, Step num: 7796, Learning rate: 0.00010011, Avg batch loss: 0.0295, Avg batch acc: 0.9680
Train, Epoch: 6, Batch: 202, Step num: 7797, Learning rate: 0.00010010, Avg batch loss: 0.0316, Avg batch acc: 0.9668
Train, Epoch: 6, Batch: 203, Step num: 7798, Learning rate: 0.00010009, Avg batch loss: 0.0327, Avg batch acc: 0.9656
Train, Epoch: 6, Batch: 204, Step num: 7799, Learning rate: 0.00010009, Avg batch loss: 0.0392, Avg batch acc: 0.9611
Train, Epoch: 6, Batch: 205, Step num: 7800, Learning rate: 0.00010008, Avg batch loss: 0.0370, Avg batch acc: 0.9674
Train, Epoch: 6, Batch: 206, Step num: 7801, Learning rate: 0.00010007, Avg batch loss: 0.0319, Avg batch acc: 0.9657
Train, Epoch: 6, Batch: 207, Step num: 7802, Learning rate: 0.00010007, Avg batch loss: 0.0478, Avg batch acc: 0.9618
Train, Epoch: 6, Batch: 208, Step num: 7803, Learning rate: 0.00010006, Avg batch loss: 0.0270, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 209, Step num: 7804, Learning rate: 0.00010005, Avg batch loss: 0.0333, Avg batch acc: 0.9643
Train, Epoch: 6, Batch: 210, Step num: 7805, Learning rate: 0.00010005, Avg batch loss: 0.0301, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 211, Step num: 7806, Learning rate: 0.00010004, Avg batch loss: 0.0309, Avg batch acc: 0.9655
Train, Epoch: 6, Batch: 212, Step num: 7807, Learning rate: 0.00010004, Avg batch loss: 0.0273, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 213, Step num: 7808, Learning rate: 0.00010003, Avg batch loss: 0.0341, Avg batch acc: 0.9669
Train, Epoch: 6, Batch: 214, Step num: 7809, Learning rate: 0.00010002, Avg batch loss: 0.0487, Avg batch acc: 0.9600
Train, Epoch: 6, Batch: 215, Step num: 7810, Learning rate: 0.00010002, Avg batch loss: 0.0331, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 216, Step num: 7811, Learning rate: 0.00010001, Avg batch loss: 0.0583, Avg batch acc: 0.9635
Train, Epoch: 6, Batch: 217, Step num: 7812, Learning rate: 0.00010000, Avg batch loss: 0.0275, Avg batch acc: 0.9664
Train, Epoch: 6, Batch: 218, Step num: 7813, Learning rate: 0.00010000, Avg batch loss: 0.0256, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 219, Step num: 7814, Learning rate: 0.00009999, Avg batch loss: 0.0327, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 220, Step num: 7815, Learning rate: 0.00009998, Avg batch loss: 0.0346, Avg batch acc: 0.9691
Train, Epoch: 6, Batch: 221, Step num: 7816, Learning rate: 0.00009998, Avg batch loss: 0.0275, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 222, Step num: 7817, Learning rate: 0.00009997, Avg batch loss: 0.0314, Avg batch acc: 0.9696
Train, Epoch: 6, Batch: 223, Step num: 7818, Learning rate: 0.00009996, Avg batch loss: 0.0248, Avg batch acc: 0.9786
Train, Epoch: 6, Batch: 224, Step num: 7819, Learning rate: 0.00009996, Avg batch loss: 0.0696, Avg batch acc: 0.9542
Train, Epoch: 6, Batch: 225, Step num: 7820, Learning rate: 0.00009995, Avg batch loss: 0.0520, Avg batch acc: 0.9628
Train, Epoch: 6, Batch: 226, Step num: 7821, Learning rate: 0.00009995, Avg batch loss: 0.0319, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 227, Step num: 7822, Learning rate: 0.00009994, Avg batch loss: 0.0366, Avg batch acc: 0.9620
Train, Epoch: 6, Batch: 228, Step num: 7823, Learning rate: 0.00009993, Avg batch loss: 0.0273, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 229, Step num: 7824, Learning rate: 0.00009993, Avg batch loss: 0.0310, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 230, Step num: 7825, Learning rate: 0.00009992, Avg batch loss: 0.0278, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 231, Step num: 7826, Learning rate: 0.00009991, Avg batch loss: 0.0335, Avg batch acc: 0.9702
Train, Epoch: 6, Batch: 232, Step num: 7827, Learning rate: 0.00009991, Avg batch loss: 0.0250, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 233, Step num: 7828, Learning rate: 0.00009990, Avg batch loss: 0.0586, Avg batch acc: 0.9614
Train, Epoch: 6, Batch: 234, Step num: 7829, Learning rate: 0.00009989, Avg batch loss: 0.0384, Avg batch acc: 0.9635
Train, Epoch: 6, Batch: 235, Step num: 7830, Learning rate: 0.00009989, Avg batch loss: 0.0293, Avg batch acc: 0.9642
Train, Epoch: 6, Batch: 236, Step num: 7831, Learning rate: 0.00009988, Avg batch loss: 0.0325, Avg batch acc: 0.9673
Train, Epoch: 6, Batch: 237, Step num: 7832, Learning rate: 0.00009988, Avg batch loss: 0.0315, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 238, Step num: 7833, Learning rate: 0.00009987, Avg batch loss: 0.0351, Avg batch acc: 0.9644
Train, Epoch: 6, Batch: 239, Step num: 7834, Learning rate: 0.00009986, Avg batch loss: 0.0320, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 240, Step num: 7835, Learning rate: 0.00009986, Avg batch loss: 0.0481, Avg batch acc: 0.9651
Train, Epoch: 6, Batch: 241, Step num: 7836, Learning rate: 0.00009985, Avg batch loss: 0.0364, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 242, Step num: 7837, Learning rate: 0.00009984, Avg batch loss: 0.0231, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 243, Step num: 7838, Learning rate: 0.00009984, Avg batch loss: 0.0302, Avg batch acc: 0.9719
Train, Epoch: 6, Batch: 244, Step num: 7839, Learning rate: 0.00009983, Avg batch loss: 0.0307, Avg batch acc: 0.9658
Train, Epoch: 6, Batch: 245, Step num: 7840, Learning rate: 0.00009982, Avg batch loss: 0.0311, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 246, Step num: 7841, Learning rate: 0.00009982, Avg batch loss: 0.0371, Avg batch acc: 0.9607
Train, Epoch: 6, Batch: 247, Step num: 7842, Learning rate: 0.00009981, Avg batch loss: 0.0314, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 248, Step num: 7843, Learning rate: 0.00009981, Avg batch loss: 0.0332, Avg batch acc: 0.9648
Train, Epoch: 6, Batch: 249, Step num: 7844, Learning rate: 0.00009980, Avg batch loss: 0.0290, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 250, Step num: 7845, Learning rate: 0.00009979, Avg batch loss: 0.0534, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 251, Step num: 7846, Learning rate: 0.00009979, Avg batch loss: 0.0315, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 252, Step num: 7847, Learning rate: 0.00009978, Avg batch loss: 0.0366, Avg batch acc: 0.9627
Train, Epoch: 6, Batch: 253, Step num: 7848, Learning rate: 0.00009977, Avg batch loss: 0.0319, Avg batch acc: 0.9652
Train, Epoch: 6, Batch: 254, Step num: 7849, Learning rate: 0.00009977, Avg batch loss: 0.0267, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 255, Step num: 7850, Learning rate: 0.00009976, Avg batch loss: 0.0293, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 256, Step num: 7851, Learning rate: 0.00009975, Avg batch loss: 0.0295, Avg batch acc: 0.9671
Train, Epoch: 6, Batch: 257, Step num: 7852, Learning rate: 0.00009975, Avg batch loss: 0.0285, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 258, Step num: 7853, Learning rate: 0.00009974, Avg batch loss: 0.0328, Avg batch acc: 0.9652
Train, Epoch: 6, Batch: 259, Step num: 7854, Learning rate: 0.00009974, Avg batch loss: 0.0312, Avg batch acc: 0.9663
Train, Epoch: 6, Batch: 260, Step num: 7855, Learning rate: 0.00009973, Avg batch loss: 0.0262, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 261, Step num: 7856, Learning rate: 0.00009972, Avg batch loss: 0.0314, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 262, Step num: 7857, Learning rate: 0.00009972, Avg batch loss: 0.0307, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 263, Step num: 7858, Learning rate: 0.00009971, Avg batch loss: 0.0269, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 264, Step num: 7859, Learning rate: 0.00009970, Avg batch loss: 0.0407, Avg batch acc: 0.9612
Train, Epoch: 6, Batch: 265, Step num: 7860, Learning rate: 0.00009970, Avg batch loss: 0.0299, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 266, Step num: 7861, Learning rate: 0.00009969, Avg batch loss: 0.0219, Avg batch acc: 0.9787
Train, Epoch: 6, Batch: 267, Step num: 7862, Learning rate: 0.00009968, Avg batch loss: 0.0317, Avg batch acc: 0.9629
Train, Epoch: 6, Batch: 268, Step num: 7863, Learning rate: 0.00009968, Avg batch loss: 0.0289, Avg batch acc: 0.9656
Train, Epoch: 6, Batch: 269, Step num: 7864, Learning rate: 0.00009967, Avg batch loss: 0.0341, Avg batch acc: 0.9634
Train, Epoch: 6, Batch: 270, Step num: 7865, Learning rate: 0.00009967, Avg batch loss: 0.0494, Avg batch acc: 0.9586
Train, Epoch: 6, Batch: 271, Step num: 7866, Learning rate: 0.00009966, Avg batch loss: 0.0312, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 272, Step num: 7867, Learning rate: 0.00009965, Avg batch loss: 0.0336, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 273, Step num: 7868, Learning rate: 0.00009965, Avg batch loss: 0.0272, Avg batch acc: 0.9670
Train, Epoch: 6, Batch: 274, Step num: 7869, Learning rate: 0.00009964, Avg batch loss: 0.0296, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 275, Step num: 7870, Learning rate: 0.00009963, Avg batch loss: 0.0274, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 276, Step num: 7871, Learning rate: 0.00009963, Avg batch loss: 0.0307, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 277, Step num: 7872, Learning rate: 0.00009962, Avg batch loss: 0.0386, Avg batch acc: 0.9606
Train, Epoch: 6, Batch: 278, Step num: 7873, Learning rate: 0.00009962, Avg batch loss: 0.0293, Avg batch acc: 0.9697
Train, Epoch: 6, Batch: 279, Step num: 7874, Learning rate: 0.00009961, Avg batch loss: 0.0269, Avg batch acc: 0.9695
Train, Epoch: 6, Batch: 280, Step num: 7875, Learning rate: 0.00009960, Avg batch loss: 0.0295, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 281, Step num: 7876, Learning rate: 0.00009960, Avg batch loss: 0.0332, Avg batch acc: 0.9643
Train, Epoch: 6, Batch: 282, Step num: 7877, Learning rate: 0.00009959, Avg batch loss: 0.0326, Avg batch acc: 0.9645
Train, Epoch: 6, Batch: 283, Step num: 7878, Learning rate: 0.00009958, Avg batch loss: 0.0304, Avg batch acc: 0.9690
Train, Epoch: 6, Batch: 284, Step num: 7879, Learning rate: 0.00009958, Avg batch loss: 0.0302, Avg batch acc: 0.9681
Train, Epoch: 6, Batch: 285, Step num: 7880, Learning rate: 0.00009957, Avg batch loss: 0.0727, Avg batch acc: 0.9630
Train, Epoch: 6, Batch: 286, Step num: 7881, Learning rate: 0.00009956, Avg batch loss: 0.0263, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 287, Step num: 7882, Learning rate: 0.00009956, Avg batch loss: 0.0275, Avg batch acc: 0.9675
Train, Epoch: 6, Batch: 288, Step num: 7883, Learning rate: 0.00009955, Avg batch loss: 0.0337, Avg batch acc: 0.9673
Train, Epoch: 6, Batch: 289, Step num: 7884, Learning rate: 0.00009955, Avg batch loss: 0.0388, Avg batch acc: 0.9625
Train, Epoch: 6, Batch: 290, Step num: 7885, Learning rate: 0.00009954, Avg batch loss: 0.0336, Avg batch acc: 0.9665
Train, Epoch: 6, Batch: 291, Step num: 7886, Learning rate: 0.00009953, Avg batch loss: 0.0312, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 292, Step num: 7887, Learning rate: 0.00009953, Avg batch loss: 0.0510, Avg batch acc: 0.9683
Train, Epoch: 6, Batch: 293, Step num: 7888, Learning rate: 0.00009952, Avg batch loss: 0.0274, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 294, Step num: 7889, Learning rate: 0.00009951, Avg batch loss: 0.0285, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 295, Step num: 7890, Learning rate: 0.00009951, Avg batch loss: 0.0236, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 296, Step num: 7891, Learning rate: 0.00009950, Avg batch loss: 0.0302, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 297, Step num: 7892, Learning rate: 0.00009950, Avg batch loss: 0.0482, Avg batch acc: 0.9672
Train, Epoch: 6, Batch: 298, Step num: 7893, Learning rate: 0.00009949, Avg batch loss: 0.0318, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 299, Step num: 7894, Learning rate: 0.00009948, Avg batch loss: 0.0277, Avg batch acc: 0.9661
Train, Epoch: 6, Batch: 300, Step num: 7895, Learning rate: 0.00009948, Avg batch loss: 0.0305, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 301, Step num: 7896, Learning rate: 0.00009947, Avg batch loss: 0.0337, Avg batch acc: 0.9630
Train, Epoch: 6, Batch: 302, Step num: 7897, Learning rate: 0.00009946, Avg batch loss: 0.0312, Avg batch acc: 0.9670
Train, Epoch: 6, Batch: 303, Step num: 7898, Learning rate: 0.00009946, Avg batch loss: 0.0300, Avg batch acc: 0.9691
Train, Epoch: 6, Batch: 304, Step num: 7899, Learning rate: 0.00009945, Avg batch loss: 0.0310, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 305, Step num: 7900, Learning rate: 0.00009944, Avg batch loss: 0.0342, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 306, Step num: 7901, Learning rate: 0.00009944, Avg batch loss: 0.0310, Avg batch acc: 0.9712
Train, Epoch: 6, Batch: 307, Step num: 7902, Learning rate: 0.00009943, Avg batch loss: 0.0314, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 308, Step num: 7903, Learning rate: 0.00009943, Avg batch loss: 0.0281, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 309, Step num: 7904, Learning rate: 0.00009942, Avg batch loss: 0.0280, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 310, Step num: 7905, Learning rate: 0.00009941, Avg batch loss: 0.0281, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 311, Step num: 7906, Learning rate: 0.00009941, Avg batch loss: 0.0309, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 312, Step num: 7907, Learning rate: 0.00009940, Avg batch loss: 0.0359, Avg batch acc: 0.9670
Train, Epoch: 6, Batch: 313, Step num: 7908, Learning rate: 0.00009939, Avg batch loss: 0.0426, Avg batch acc: 0.9660
Train, Epoch: 6, Batch: 314, Step num: 7909, Learning rate: 0.00009939, Avg batch loss: 0.0368, Avg batch acc: 0.9649
Train, Epoch: 6, Batch: 315, Step num: 7910, Learning rate: 0.00009938, Avg batch loss: 0.0290, Avg batch acc: 0.9683
Train, Epoch: 6, Batch: 316, Step num: 7911, Learning rate: 0.00009938, Avg batch loss: 0.0421, Avg batch acc: 0.9594
Train, Epoch: 6, Batch: 317, Step num: 7912, Learning rate: 0.00009937, Avg batch loss: 0.0307, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 318, Step num: 7913, Learning rate: 0.00009936, Avg batch loss: 0.0264, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 319, Step num: 7914, Learning rate: 0.00009936, Avg batch loss: 0.0410, Avg batch acc: 0.9651
Train, Epoch: 6, Batch: 320, Step num: 7915, Learning rate: 0.00009935, Avg batch loss: 0.0233, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 321, Step num: 7916, Learning rate: 0.00009934, Avg batch loss: 0.0341, Avg batch acc: 0.9657
Train, Epoch: 6, Batch: 322, Step num: 7917, Learning rate: 0.00009934, Avg batch loss: 0.0257, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 323, Step num: 7918, Learning rate: 0.00009933, Avg batch loss: 0.0332, Avg batch acc: 0.9664
Train, Epoch: 6, Batch: 324, Step num: 7919, Learning rate: 0.00009933, Avg batch loss: 0.0267, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 325, Step num: 7920, Learning rate: 0.00009932, Avg batch loss: 0.0282, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 326, Step num: 7921, Learning rate: 0.00009931, Avg batch loss: 0.0298, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 327, Step num: 7922, Learning rate: 0.00009931, Avg batch loss: 0.0279, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 328, Step num: 7923, Learning rate: 0.00009930, Avg batch loss: 0.0309, Avg batch acc: 0.9655
Train, Epoch: 6, Batch: 329, Step num: 7924, Learning rate: 0.00009929, Avg batch loss: 0.0347, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 330, Step num: 7925, Learning rate: 0.00009929, Avg batch loss: 0.0404, Avg batch acc: 0.9673
Train, Epoch: 6, Batch: 331, Step num: 7926, Learning rate: 0.00009928, Avg batch loss: 0.0305, Avg batch acc: 0.9683
Train, Epoch: 6, Batch: 332, Step num: 7927, Learning rate: 0.00009928, Avg batch loss: 0.0419, Avg batch acc: 0.9668
Train, Epoch: 6, Batch: 333, Step num: 7928, Learning rate: 0.00009927, Avg batch loss: 0.0339, Avg batch acc: 0.9632
Train, Epoch: 6, Batch: 334, Step num: 7929, Learning rate: 0.00009926, Avg batch loss: 0.0306, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 335, Step num: 7930, Learning rate: 0.00009926, Avg batch loss: 0.0290, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 336, Step num: 7931, Learning rate: 0.00009925, Avg batch loss: 0.0259, Avg batch acc: 0.9665
Train, Epoch: 6, Batch: 337, Step num: 7932, Learning rate: 0.00009924, Avg batch loss: 0.0333, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 338, Step num: 7933, Learning rate: 0.00009924, Avg batch loss: 0.0291, Avg batch acc: 0.9731
Train, Epoch: 6, Batch: 339, Step num: 7934, Learning rate: 0.00009923, Avg batch loss: 0.0280, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 340, Step num: 7935, Learning rate: 0.00009923, Avg batch loss: 0.0274, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 341, Step num: 7936, Learning rate: 0.00009922, Avg batch loss: 0.0277, Avg batch acc: 0.9681
Train, Epoch: 6, Batch: 342, Step num: 7937, Learning rate: 0.00009921, Avg batch loss: 0.0330, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 343, Step num: 7938, Learning rate: 0.00009921, Avg batch loss: 0.0267, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 344, Step num: 7939, Learning rate: 0.00009920, Avg batch loss: 0.0290, Avg batch acc: 0.9686
Train, Epoch: 6, Batch: 345, Step num: 7940, Learning rate: 0.00009919, Avg batch loss: 0.0280, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 346, Step num: 7941, Learning rate: 0.00009919, Avg batch loss: 0.0222, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 347, Step num: 7942, Learning rate: 0.00009918, Avg batch loss: 0.0336, Avg batch acc: 0.9651
Train, Epoch: 6, Batch: 348, Step num: 7943, Learning rate: 0.00009918, Avg batch loss: 0.0356, Avg batch acc: 0.9621
Train, Epoch: 6, Batch: 349, Step num: 7944, Learning rate: 0.00009917, Avg batch loss: 0.0347, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 350, Step num: 7945, Learning rate: 0.00009916, Avg batch loss: 0.0333, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 351, Step num: 7946, Learning rate: 0.00009916, Avg batch loss: 0.0243, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 352, Step num: 7947, Learning rate: 0.00009915, Avg batch loss: 0.0285, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 353, Step num: 7948, Learning rate: 0.00009914, Avg batch loss: 0.0326, Avg batch acc: 0.9690
Train, Epoch: 6, Batch: 354, Step num: 7949, Learning rate: 0.00009914, Avg batch loss: 0.0251, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 355, Step num: 7950, Learning rate: 0.00009913, Avg batch loss: 0.0275, Avg batch acc: 0.9665
Train, Epoch: 6, Batch: 356, Step num: 7951, Learning rate: 0.00009913, Avg batch loss: 0.0277, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 357, Step num: 7952, Learning rate: 0.00009912, Avg batch loss: 0.0217, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 358, Step num: 7953, Learning rate: 0.00009911, Avg batch loss: 0.0275, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 359, Step num: 7954, Learning rate: 0.00009911, Avg batch loss: 0.0272, Avg batch acc: 0.9682
Train, Epoch: 6, Batch: 360, Step num: 7955, Learning rate: 0.00009910, Avg batch loss: 0.0297, Avg batch acc: 0.9680
Train, Epoch: 6, Batch: 361, Step num: 7956, Learning rate: 0.00009909, Avg batch loss: 0.0330, Avg batch acc: 0.9671
Train, Epoch: 6, Batch: 362, Step num: 7957, Learning rate: 0.00009909, Avg batch loss: 0.0264, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 363, Step num: 7958, Learning rate: 0.00009908, Avg batch loss: 0.0317, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 364, Step num: 7959, Learning rate: 0.00009908, Avg batch loss: 0.0236, Avg batch acc: 0.9796
Train, Epoch: 6, Batch: 365, Step num: 7960, Learning rate: 0.00009907, Avg batch loss: 0.0296, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 366, Step num: 7961, Learning rate: 0.00009906, Avg batch loss: 0.0253, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 367, Step num: 7962, Learning rate: 0.00009906, Avg batch loss: 0.0275, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 368, Step num: 7963, Learning rate: 0.00009905, Avg batch loss: 0.0309, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 369, Step num: 7964, Learning rate: 0.00009904, Avg batch loss: 0.0273, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 370, Step num: 7965, Learning rate: 0.00009904, Avg batch loss: 0.0308, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 371, Step num: 7966, Learning rate: 0.00009903, Avg batch loss: 0.0277, Avg batch acc: 0.9712
Train, Epoch: 6, Batch: 372, Step num: 7967, Learning rate: 0.00009903, Avg batch loss: 0.0499, Avg batch acc: 0.9638
Train, Epoch: 6, Batch: 373, Step num: 7968, Learning rate: 0.00009902, Avg batch loss: 0.0348, Avg batch acc: 0.9619
Train, Epoch: 6, Batch: 374, Step num: 7969, Learning rate: 0.00009901, Avg batch loss: 0.0387, Avg batch acc: 0.9648
Train, Epoch: 6, Batch: 375, Step num: 7970, Learning rate: 0.00009901, Avg batch loss: 0.0222, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 376, Step num: 7971, Learning rate: 0.00009900, Avg batch loss: 0.0318, Avg batch acc: 0.9673
Train, Epoch: 6, Batch: 377, Step num: 7972, Learning rate: 0.00009899, Avg batch loss: 0.0277, Avg batch acc: 0.9695
Train, Epoch: 6, Batch: 378, Step num: 7973, Learning rate: 0.00009899, Avg batch loss: 0.0282, Avg batch acc: 0.9626
Train, Epoch: 6, Batch: 379, Step num: 7974, Learning rate: 0.00009898, Avg batch loss: 0.0200, Avg batch acc: 0.9798
Train, Epoch: 6, Batch: 380, Step num: 7975, Learning rate: 0.00009898, Avg batch loss: 0.0281, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 381, Step num: 7976, Learning rate: 0.00009897, Avg batch loss: 0.0330, Avg batch acc: 0.9607
Train, Epoch: 6, Batch: 382, Step num: 7977, Learning rate: 0.00009896, Avg batch loss: 0.0268, Avg batch acc: 0.9712
Train, Epoch: 6, Batch: 383, Step num: 7978, Learning rate: 0.00009896, Avg batch loss: 0.0233, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 384, Step num: 7979, Learning rate: 0.00009895, Avg batch loss: 0.0239, Avg batch acc: 0.9771
Train, Epoch: 6, Batch: 385, Step num: 7980, Learning rate: 0.00009894, Avg batch loss: 0.0267, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 386, Step num: 7981, Learning rate: 0.00009894, Avg batch loss: 0.0291, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 387, Step num: 7982, Learning rate: 0.00009893, Avg batch loss: 0.0231, Avg batch acc: 0.9727
Train, Epoch: 6, Batch: 388, Step num: 7983, Learning rate: 0.00009893, Avg batch loss: 0.0296, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 389, Step num: 7984, Learning rate: 0.00009892, Avg batch loss: 0.0258, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 390, Step num: 7985, Learning rate: 0.00009891, Avg batch loss: 0.0241, Avg batch acc: 0.9783
Train, Epoch: 6, Batch: 391, Step num: 7986, Learning rate: 0.00009891, Avg batch loss: 0.0295, Avg batch acc: 0.9664
Train, Epoch: 6, Batch: 392, Step num: 7987, Learning rate: 0.00009890, Avg batch loss: 0.0265, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 393, Step num: 7988, Learning rate: 0.00009890, Avg batch loss: 0.0301, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 394, Step num: 7989, Learning rate: 0.00009889, Avg batch loss: 0.0294, Avg batch acc: 0.9677
Train, Epoch: 6, Batch: 395, Step num: 7990, Learning rate: 0.00009888, Avg batch loss: 0.0238, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 396, Step num: 7991, Learning rate: 0.00009888, Avg batch loss: 0.0268, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 397, Step num: 7992, Learning rate: 0.00009887, Avg batch loss: 0.0286, Avg batch acc: 0.9665
Train, Epoch: 6, Batch: 398, Step num: 7993, Learning rate: 0.00009886, Avg batch loss: 0.0296, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 399, Step num: 7994, Learning rate: 0.00009886, Avg batch loss: 0.0252, Avg batch acc: 0.9691
Train, Epoch: 6, Batch: 400, Step num: 7995, Learning rate: 0.00009885, Avg batch loss: 0.0320, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 401, Step num: 7996, Learning rate: 0.00009885, Avg batch loss: 0.0362, Avg batch acc: 0.9650
Train, Epoch: 6, Batch: 402, Step num: 7997, Learning rate: 0.00009884, Avg batch loss: 0.0282, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 403, Step num: 7998, Learning rate: 0.00009883, Avg batch loss: 0.0314, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 404, Step num: 7999, Learning rate: 0.00009883, Avg batch loss: 0.0303, Avg batch acc: 0.9670
Train, Epoch: 6, Batch: 405, Step num: 8000, Learning rate: 0.00009882, Avg batch loss: 0.0256, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 406, Step num: 8001, Learning rate: 0.00009882, Avg batch loss: 0.0249, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 407, Step num: 8002, Learning rate: 0.00009881, Avg batch loss: 0.0242, Avg batch acc: 0.9774
Train, Epoch: 6, Batch: 408, Step num: 8003, Learning rate: 0.00009880, Avg batch loss: 0.0285, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 409, Step num: 8004, Learning rate: 0.00009880, Avg batch loss: 0.0257, Avg batch acc: 0.9752
Train, Epoch: 6, Batch: 410, Step num: 8005, Learning rate: 0.00009879, Avg batch loss: 0.0237, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 411, Step num: 8006, Learning rate: 0.00009878, Avg batch loss: 0.0319, Avg batch acc: 0.9643
Train, Epoch: 6, Batch: 412, Step num: 8007, Learning rate: 0.00009878, Avg batch loss: 0.0232, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 413, Step num: 8008, Learning rate: 0.00009877, Avg batch loss: 0.0435, Avg batch acc: 0.9681
Train, Epoch: 6, Batch: 414, Step num: 8009, Learning rate: 0.00009877, Avg batch loss: 0.0229, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 415, Step num: 8010, Learning rate: 0.00009876, Avg batch loss: 0.0228, Avg batch acc: 0.9774
Train, Epoch: 6, Batch: 416, Step num: 8011, Learning rate: 0.00009875, Avg batch loss: 0.0307, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 417, Step num: 8012, Learning rate: 0.00009875, Avg batch loss: 0.0271, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 418, Step num: 8013, Learning rate: 0.00009874, Avg batch loss: 0.0280, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 419, Step num: 8014, Learning rate: 0.00009873, Avg batch loss: 0.0277, Avg batch acc: 0.9668
Train, Epoch: 6, Batch: 420, Step num: 8015, Learning rate: 0.00009873, Avg batch loss: 0.0279, Avg batch acc: 0.9682
Train, Epoch: 6, Batch: 421, Step num: 8016, Learning rate: 0.00009872, Avg batch loss: 0.0217, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 422, Step num: 8017, Learning rate: 0.00009872, Avg batch loss: 0.0282, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 423, Step num: 8018, Learning rate: 0.00009871, Avg batch loss: 0.0255, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 424, Step num: 8019, Learning rate: 0.00009870, Avg batch loss: 0.0248, Avg batch acc: 0.9750
Train, Epoch: 6, Batch: 425, Step num: 8020, Learning rate: 0.00009870, Avg batch loss: 0.0282, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 426, Step num: 8021, Learning rate: 0.00009869, Avg batch loss: 0.0278, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 427, Step num: 8022, Learning rate: 0.00009869, Avg batch loss: 0.0321, Avg batch acc: 0.9695
Train, Epoch: 6, Batch: 428, Step num: 8023, Learning rate: 0.00009868, Avg batch loss: 0.0267, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 429, Step num: 8024, Learning rate: 0.00009867, Avg batch loss: 0.0302, Avg batch acc: 0.9683
Train, Epoch: 6, Batch: 430, Step num: 8025, Learning rate: 0.00009867, Avg batch loss: 0.0307, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 431, Step num: 8026, Learning rate: 0.00009866, Avg batch loss: 0.0244, Avg batch acc: 0.9763
Train, Epoch: 6, Batch: 432, Step num: 8027, Learning rate: 0.00009865, Avg batch loss: 0.0339, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 433, Step num: 8028, Learning rate: 0.00009865, Avg batch loss: 0.0291, Avg batch acc: 0.9771
Train, Epoch: 6, Batch: 434, Step num: 8029, Learning rate: 0.00009864, Avg batch loss: 0.0312, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 435, Step num: 8030, Learning rate: 0.00009864, Avg batch loss: 0.0251, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 436, Step num: 8031, Learning rate: 0.00009863, Avg batch loss: 0.0283, Avg batch acc: 0.9691
Train, Epoch: 6, Batch: 437, Step num: 8032, Learning rate: 0.00009862, Avg batch loss: 0.0303, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 438, Step num: 8033, Learning rate: 0.00009862, Avg batch loss: 0.0217, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 439, Step num: 8034, Learning rate: 0.00009861, Avg batch loss: 0.0412, Avg batch acc: 0.9650
Train, Epoch: 6, Batch: 440, Step num: 8035, Learning rate: 0.00009861, Avg batch loss: 0.0267, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 441, Step num: 8036, Learning rate: 0.00009860, Avg batch loss: 0.0300, Avg batch acc: 0.9673
Train, Epoch: 6, Batch: 442, Step num: 8037, Learning rate: 0.00009859, Avg batch loss: 0.0270, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 443, Step num: 8038, Learning rate: 0.00009859, Avg batch loss: 0.0292, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 444, Step num: 8039, Learning rate: 0.00009858, Avg batch loss: 0.0302, Avg batch acc: 0.9680
Train, Epoch: 6, Batch: 445, Step num: 8040, Learning rate: 0.00009858, Avg batch loss: 0.0284, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 446, Step num: 8041, Learning rate: 0.00009857, Avg batch loss: 0.0371, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 447, Step num: 8042, Learning rate: 0.00009856, Avg batch loss: 0.0240, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 448, Step num: 8043, Learning rate: 0.00009856, Avg batch loss: 0.0248, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 449, Step num: 8044, Learning rate: 0.00009855, Avg batch loss: 0.0286, Avg batch acc: 0.9648
Train, Epoch: 6, Batch: 450, Step num: 8045, Learning rate: 0.00009854, Avg batch loss: 0.0329, Avg batch acc: 0.9668
Train, Epoch: 6, Batch: 451, Step num: 8046, Learning rate: 0.00009854, Avg batch loss: 0.0343, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 452, Step num: 8047, Learning rate: 0.00009853, Avg batch loss: 0.0323, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 453, Step num: 8048, Learning rate: 0.00009853, Avg batch loss: 0.0407, Avg batch acc: 0.9663
Train, Epoch: 6, Batch: 454, Step num: 8049, Learning rate: 0.00009852, Avg batch loss: 0.0275, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 455, Step num: 8050, Learning rate: 0.00009851, Avg batch loss: 0.0285, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 456, Step num: 8051, Learning rate: 0.00009851, Avg batch loss: 0.0305, Avg batch acc: 0.9750
Train, Epoch: 6, Batch: 457, Step num: 8052, Learning rate: 0.00009850, Avg batch loss: 0.0309, Avg batch acc: 0.9681
Train, Epoch: 6, Batch: 458, Step num: 8053, Learning rate: 0.00009850, Avg batch loss: 0.0278, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 459, Step num: 8054, Learning rate: 0.00009849, Avg batch loss: 0.0279, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 460, Step num: 8055, Learning rate: 0.00009848, Avg batch loss: 0.0277, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 461, Step num: 8056, Learning rate: 0.00009848, Avg batch loss: 0.0277, Avg batch acc: 0.9671
Train, Epoch: 6, Batch: 462, Step num: 8057, Learning rate: 0.00009847, Avg batch loss: 0.0264, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 463, Step num: 8058, Learning rate: 0.00009846, Avg batch loss: 0.0386, Avg batch acc: 0.9647
Train, Epoch: 6, Batch: 464, Step num: 8059, Learning rate: 0.00009846, Avg batch loss: 0.0250, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 465, Step num: 8060, Learning rate: 0.00009845, Avg batch loss: 0.0236, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 466, Step num: 8061, Learning rate: 0.00009845, Avg batch loss: 0.0223, Avg batch acc: 0.9792
Train, Epoch: 6, Batch: 467, Step num: 8062, Learning rate: 0.00009844, Avg batch loss: 0.0257, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 468, Step num: 8063, Learning rate: 0.00009843, Avg batch loss: 0.0227, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 469, Step num: 8064, Learning rate: 0.00009843, Avg batch loss: 0.0247, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 470, Step num: 8065, Learning rate: 0.00009842, Avg batch loss: 0.0274, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 471, Step num: 8066, Learning rate: 0.00009842, Avg batch loss: 0.0399, Avg batch acc: 0.9650
Train, Epoch: 6, Batch: 472, Step num: 8067, Learning rate: 0.00009841, Avg batch loss: 0.0269, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 473, Step num: 8068, Learning rate: 0.00009840, Avg batch loss: 0.0261, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 474, Step num: 8069, Learning rate: 0.00009840, Avg batch loss: 0.0212, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 475, Step num: 8070, Learning rate: 0.00009839, Avg batch loss: 0.0410, Avg batch acc: 0.9640
Train, Epoch: 6, Batch: 476, Step num: 8071, Learning rate: 0.00009839, Avg batch loss: 0.0307, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 477, Step num: 8072, Learning rate: 0.00009838, Avg batch loss: 0.0270, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 478, Step num: 8073, Learning rate: 0.00009837, Avg batch loss: 0.0317, Avg batch acc: 0.9683
Train, Epoch: 6, Batch: 479, Step num: 8074, Learning rate: 0.00009837, Avg batch loss: 0.0306, Avg batch acc: 0.9686
Train, Epoch: 6, Batch: 480, Step num: 8075, Learning rate: 0.00009836, Avg batch loss: 0.0289, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 481, Step num: 8076, Learning rate: 0.00009836, Avg batch loss: 0.0231, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 482, Step num: 8077, Learning rate: 0.00009835, Avg batch loss: 0.0267, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 483, Step num: 8078, Learning rate: 0.00009834, Avg batch loss: 0.0293, Avg batch acc: 0.9697
Train, Epoch: 6, Batch: 484, Step num: 8079, Learning rate: 0.00009834, Avg batch loss: 0.0252, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 485, Step num: 8080, Learning rate: 0.00009833, Avg batch loss: 0.0301, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 486, Step num: 8081, Learning rate: 0.00009832, Avg batch loss: 0.0283, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 487, Step num: 8082, Learning rate: 0.00009832, Avg batch loss: 0.0310, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 488, Step num: 8083, Learning rate: 0.00009831, Avg batch loss: 0.0320, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 489, Step num: 8084, Learning rate: 0.00009831, Avg batch loss: 0.0659, Avg batch acc: 0.9623
Train, Epoch: 6, Batch: 490, Step num: 8085, Learning rate: 0.00009830, Avg batch loss: 0.0246, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 491, Step num: 8086, Learning rate: 0.00009829, Avg batch loss: 0.0241, Avg batch acc: 0.9719
Train, Epoch: 6, Batch: 492, Step num: 8087, Learning rate: 0.00009829, Avg batch loss: 0.0280, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 493, Step num: 8088, Learning rate: 0.00009828, Avg batch loss: 0.0444, Avg batch acc: 0.9668
Train, Epoch: 6, Batch: 494, Step num: 8089, Learning rate: 0.00009828, Avg batch loss: 0.0270, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 495, Step num: 8090, Learning rate: 0.00009827, Avg batch loss: 0.0242, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 496, Step num: 8091, Learning rate: 0.00009826, Avg batch loss: 0.0293, Avg batch acc: 0.9663
Train, Epoch: 6, Batch: 497, Step num: 8092, Learning rate: 0.00009826, Avg batch loss: 0.0267, Avg batch acc: 0.9727
Train, Epoch: 6, Batch: 498, Step num: 8093, Learning rate: 0.00009825, Avg batch loss: 0.0314, Avg batch acc: 0.9702
Train, Epoch: 6, Batch: 499, Step num: 8094, Learning rate: 0.00009825, Avg batch loss: 0.0334, Avg batch acc: 0.9655
Train, Epoch: 6, Batch: 500, Step num: 8095, Learning rate: 0.00009824, Avg batch loss: 0.0247, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 501, Step num: 8096, Learning rate: 0.00009823, Avg batch loss: 0.0302, Avg batch acc: 0.9691
Train, Epoch: 6, Batch: 502, Step num: 8097, Learning rate: 0.00009823, Avg batch loss: 0.0273, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 503, Step num: 8098, Learning rate: 0.00009822, Avg batch loss: 0.0318, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 504, Step num: 8099, Learning rate: 0.00009822, Avg batch loss: 0.0268, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 505, Step num: 8100, Learning rate: 0.00009821, Avg batch loss: 0.0271, Avg batch acc: 0.9725
Train, Epoch: 6, Batch: 506, Step num: 8101, Learning rate: 0.00009820, Avg batch loss: 0.0217, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 507, Step num: 8102, Learning rate: 0.00009820, Avg batch loss: 0.0456, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 508, Step num: 8103, Learning rate: 0.00009819, Avg batch loss: 0.0247, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 509, Step num: 8104, Learning rate: 0.00009819, Avg batch loss: 0.0241, Avg batch acc: 0.9739
Train, Epoch: 6, Batch: 510, Step num: 8105, Learning rate: 0.00009818, Avg batch loss: 0.0286, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 511, Step num: 8106, Learning rate: 0.00009817, Avg batch loss: 0.0242, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 512, Step num: 8107, Learning rate: 0.00009817, Avg batch loss: 0.0339, Avg batch acc: 0.9639
Train, Epoch: 6, Batch: 513, Step num: 8108, Learning rate: 0.00009816, Avg batch loss: 0.0240, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 514, Step num: 8109, Learning rate: 0.00009815, Avg batch loss: 0.0302, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 515, Step num: 8110, Learning rate: 0.00009815, Avg batch loss: 0.0296, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 516, Step num: 8111, Learning rate: 0.00009814, Avg batch loss: 0.0229, Avg batch acc: 0.9764
Train, Epoch: 6, Batch: 517, Step num: 8112, Learning rate: 0.00009814, Avg batch loss: 0.0270, Avg batch acc: 0.9697
Train, Epoch: 6, Batch: 518, Step num: 8113, Learning rate: 0.00009813, Avg batch loss: 0.0443, Avg batch acc: 0.9609
Train, Epoch: 6, Batch: 519, Step num: 8114, Learning rate: 0.00009812, Avg batch loss: 0.0315, Avg batch acc: 0.9662
Train, Epoch: 6, Batch: 520, Step num: 8115, Learning rate: 0.00009812, Avg batch loss: 0.0239, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 521, Step num: 8116, Learning rate: 0.00009811, Avg batch loss: 0.0329, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 522, Step num: 8117, Learning rate: 0.00009811, Avg batch loss: 0.0275, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 523, Step num: 8118, Learning rate: 0.00009810, Avg batch loss: 0.0297, Avg batch acc: 0.9652
Train, Epoch: 6, Batch: 524, Step num: 8119, Learning rate: 0.00009809, Avg batch loss: 0.0438, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 525, Step num: 8120, Learning rate: 0.00009809, Avg batch loss: 0.0244, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 526, Step num: 8121, Learning rate: 0.00009808, Avg batch loss: 0.0269, Avg batch acc: 0.9681
Train, Epoch: 6, Batch: 527, Step num: 8122, Learning rate: 0.00009808, Avg batch loss: 0.0306, Avg batch acc: 0.9645
Train, Epoch: 6, Batch: 528, Step num: 8123, Learning rate: 0.00009807, Avg batch loss: 0.0234, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 529, Step num: 8124, Learning rate: 0.00009806, Avg batch loss: 0.0283, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 530, Step num: 8125, Learning rate: 0.00009806, Avg batch loss: 0.0386, Avg batch acc: 0.9666
Train, Epoch: 6, Batch: 531, Step num: 8126, Learning rate: 0.00009805, Avg batch loss: 0.0267, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 532, Step num: 8127, Learning rate: 0.00009805, Avg batch loss: 0.0303, Avg batch acc: 0.9682
Train, Epoch: 6, Batch: 533, Step num: 8128, Learning rate: 0.00009804, Avg batch loss: 0.0328, Avg batch acc: 0.9672
Train, Epoch: 6, Batch: 534, Step num: 8129, Learning rate: 0.00009803, Avg batch loss: 0.0257, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 535, Step num: 8130, Learning rate: 0.00009803, Avg batch loss: 0.0249, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 536, Step num: 8131, Learning rate: 0.00009802, Avg batch loss: 0.0285, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 537, Step num: 8132, Learning rate: 0.00009802, Avg batch loss: 0.0265, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 538, Step num: 8133, Learning rate: 0.00009801, Avg batch loss: 0.0300, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 539, Step num: 8134, Learning rate: 0.00009800, Avg batch loss: 0.0251, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 540, Step num: 8135, Learning rate: 0.00009800, Avg batch loss: 0.0229, Avg batch acc: 0.9790
Train, Epoch: 6, Batch: 541, Step num: 8136, Learning rate: 0.00009799, Avg batch loss: 0.0266, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 542, Step num: 8137, Learning rate: 0.00009799, Avg batch loss: 0.0264, Avg batch acc: 0.9752
Train, Epoch: 6, Batch: 543, Step num: 8138, Learning rate: 0.00009798, Avg batch loss: 0.0294, Avg batch acc: 0.9670
Train, Epoch: 6, Batch: 544, Step num: 8139, Learning rate: 0.00009797, Avg batch loss: 0.0266, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 545, Step num: 8140, Learning rate: 0.00009797, Avg batch loss: 0.0349, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 546, Step num: 8141, Learning rate: 0.00009796, Avg batch loss: 0.0271, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 547, Step num: 8142, Learning rate: 0.00009796, Avg batch loss: 0.0318, Avg batch acc: 0.9677
Train, Epoch: 6, Batch: 548, Step num: 8143, Learning rate: 0.00009795, Avg batch loss: 0.0299, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 549, Step num: 8144, Learning rate: 0.00009794, Avg batch loss: 0.0269, Avg batch acc: 0.9714
Train, Epoch: 6, Batch: 550, Step num: 8145, Learning rate: 0.00009794, Avg batch loss: 0.0271, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 551, Step num: 8146, Learning rate: 0.00009793, Avg batch loss: 0.0325, Avg batch acc: 0.9683
Train, Epoch: 6, Batch: 552, Step num: 8147, Learning rate: 0.00009793, Avg batch loss: 0.0213, Avg batch acc: 0.9799
Train, Epoch: 6, Batch: 553, Step num: 8148, Learning rate: 0.00009792, Avg batch loss: 0.0265, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 554, Step num: 8149, Learning rate: 0.00009791, Avg batch loss: 0.0481, Avg batch acc: 0.9651
Train, Epoch: 6, Batch: 555, Step num: 8150, Learning rate: 0.00009791, Avg batch loss: 0.0302, Avg batch acc: 0.9668
Train, Epoch: 6, Batch: 556, Step num: 8151, Learning rate: 0.00009790, Avg batch loss: 0.0224, Avg batch acc: 0.9785
Train, Epoch: 6, Batch: 557, Step num: 8152, Learning rate: 0.00009790, Avg batch loss: 0.0281, Avg batch acc: 0.9680
Train, Epoch: 6, Batch: 558, Step num: 8153, Learning rate: 0.00009789, Avg batch loss: 0.0247, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 559, Step num: 8154, Learning rate: 0.00009788, Avg batch loss: 0.0335, Avg batch acc: 0.9614
Train, Epoch: 6, Batch: 560, Step num: 8155, Learning rate: 0.00009788, Avg batch loss: 0.0260, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 561, Step num: 8156, Learning rate: 0.00009787, Avg batch loss: 0.0279, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 562, Step num: 8157, Learning rate: 0.00009787, Avg batch loss: 0.0314, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 563, Step num: 8158, Learning rate: 0.00009786, Avg batch loss: 0.0245, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 564, Step num: 8159, Learning rate: 0.00009785, Avg batch loss: 0.0285, Avg batch acc: 0.9690
Train, Epoch: 6, Batch: 565, Step num: 8160, Learning rate: 0.00009785, Avg batch loss: 0.0237, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 566, Step num: 8161, Learning rate: 0.00009784, Avg batch loss: 0.0249, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 567, Step num: 8162, Learning rate: 0.00009784, Avg batch loss: 0.0364, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 568, Step num: 8163, Learning rate: 0.00009783, Avg batch loss: 0.0286, Avg batch acc: 0.9714
Train, Epoch: 6, Batch: 569, Step num: 8164, Learning rate: 0.00009782, Avg batch loss: 0.0223, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 570, Step num: 8165, Learning rate: 0.00009782, Avg batch loss: 0.0326, Avg batch acc: 0.9627
Train, Epoch: 6, Batch: 571, Step num: 8166, Learning rate: 0.00009781, Avg batch loss: 0.0275, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 572, Step num: 8167, Learning rate: 0.00009781, Avg batch loss: 0.0287, Avg batch acc: 0.9651
Train, Epoch: 6, Batch: 573, Step num: 8168, Learning rate: 0.00009780, Avg batch loss: 0.0294, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 574, Step num: 8169, Learning rate: 0.00009779, Avg batch loss: 0.0265, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 575, Step num: 8170, Learning rate: 0.00009779, Avg batch loss: 0.0245, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 576, Step num: 8171, Learning rate: 0.00009778, Avg batch loss: 0.0261, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 577, Step num: 8172, Learning rate: 0.00009778, Avg batch loss: 0.0237, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 578, Step num: 8173, Learning rate: 0.00009777, Avg batch loss: 0.0301, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 579, Step num: 8174, Learning rate: 0.00009776, Avg batch loss: 0.0304, Avg batch acc: 0.9672
Train, Epoch: 6, Batch: 580, Step num: 8175, Learning rate: 0.00009776, Avg batch loss: 0.0282, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 581, Step num: 8176, Learning rate: 0.00009775, Avg batch loss: 0.0230, Avg batch acc: 0.9752
Train, Epoch: 6, Batch: 582, Step num: 8177, Learning rate: 0.00009775, Avg batch loss: 0.0325, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 583, Step num: 8178, Learning rate: 0.00009774, Avg batch loss: 0.0296, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 584, Step num: 8179, Learning rate: 0.00009773, Avg batch loss: 0.0248, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 585, Step num: 8180, Learning rate: 0.00009773, Avg batch loss: 0.0227, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 586, Step num: 8181, Learning rate: 0.00009772, Avg batch loss: 0.0225, Avg batch acc: 0.9754
Train, Epoch: 6, Batch: 587, Step num: 8182, Learning rate: 0.00009772, Avg batch loss: 0.0313, Avg batch acc: 0.9665
Train, Epoch: 6, Batch: 588, Step num: 8183, Learning rate: 0.00009771, Avg batch loss: 0.0321, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 589, Step num: 8184, Learning rate: 0.00009770, Avg batch loss: 0.0269, Avg batch acc: 0.9712
Train, Epoch: 6, Batch: 590, Step num: 8185, Learning rate: 0.00009770, Avg batch loss: 0.0261, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 591, Step num: 8186, Learning rate: 0.00009769, Avg batch loss: 0.0249, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 592, Step num: 8187, Learning rate: 0.00009769, Avg batch loss: 0.0263, Avg batch acc: 0.9773
Train, Epoch: 6, Batch: 593, Step num: 8188, Learning rate: 0.00009768, Avg batch loss: 0.0287, Avg batch acc: 0.9714
Train, Epoch: 6, Batch: 594, Step num: 8189, Learning rate: 0.00009767, Avg batch loss: 0.0257, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 595, Step num: 8190, Learning rate: 0.00009767, Avg batch loss: 0.0320, Avg batch acc: 0.9652
Train, Epoch: 6, Batch: 596, Step num: 8191, Learning rate: 0.00009766, Avg batch loss: 0.0285, Avg batch acc: 0.9727
Train, Epoch: 6, Batch: 597, Step num: 8192, Learning rate: 0.00009766, Avg batch loss: 0.0276, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 598, Step num: 8193, Learning rate: 0.00009765, Avg batch loss: 0.0354, Avg batch acc: 0.9657
Train, Epoch: 6, Batch: 599, Step num: 8194, Learning rate: 0.00009764, Avg batch loss: 0.0300, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 600, Step num: 8195, Learning rate: 0.00009764, Avg batch loss: 0.0267, Avg batch acc: 0.9697
Train, Epoch: 6, Batch: 601, Step num: 8196, Learning rate: 0.00009763, Avg batch loss: 0.0238, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 602, Step num: 8197, Learning rate: 0.00009763, Avg batch loss: 0.0287, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 603, Step num: 8198, Learning rate: 0.00009762, Avg batch loss: 0.0221, Avg batch acc: 0.9804
Train, Epoch: 6, Batch: 604, Step num: 8199, Learning rate: 0.00009761, Avg batch loss: 0.0264, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 605, Step num: 8200, Learning rate: 0.00009761, Avg batch loss: 0.0241, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 606, Step num: 8201, Learning rate: 0.00009760, Avg batch loss: 0.0299, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 607, Step num: 8202, Learning rate: 0.00009760, Avg batch loss: 0.0356, Avg batch acc: 0.9650
Train, Epoch: 6, Batch: 608, Step num: 8203, Learning rate: 0.00009759, Avg batch loss: 0.0260, Avg batch acc: 0.9727
Train, Epoch: 6, Batch: 609, Step num: 8204, Learning rate: 0.00009758, Avg batch loss: 0.0326, Avg batch acc: 0.9656
Train, Epoch: 6, Batch: 610, Step num: 8205, Learning rate: 0.00009758, Avg batch loss: 0.0268, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 611, Step num: 8206, Learning rate: 0.00009757, Avg batch loss: 0.0253, Avg batch acc: 0.9659
Train, Epoch: 6, Batch: 612, Step num: 8207, Learning rate: 0.00009757, Avg batch loss: 0.0276, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 613, Step num: 8208, Learning rate: 0.00009756, Avg batch loss: 0.0288, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 614, Step num: 8209, Learning rate: 0.00009756, Avg batch loss: 0.0322, Avg batch acc: 0.9666
Train, Epoch: 6, Batch: 615, Step num: 8210, Learning rate: 0.00009755, Avg batch loss: 0.0258, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 616, Step num: 8211, Learning rate: 0.00009754, Avg batch loss: 0.0364, Avg batch acc: 0.9623
Train, Epoch: 6, Batch: 617, Step num: 8212, Learning rate: 0.00009754, Avg batch loss: 0.0251, Avg batch acc: 0.9750
Train, Epoch: 6, Batch: 618, Step num: 8213, Learning rate: 0.00009753, Avg batch loss: 0.0235, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 619, Step num: 8214, Learning rate: 0.00009753, Avg batch loss: 0.0210, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 620, Step num: 8215, Learning rate: 0.00009752, Avg batch loss: 0.0268, Avg batch acc: 0.9683
Train, Epoch: 6, Batch: 621, Step num: 8216, Learning rate: 0.00009751, Avg batch loss: 0.0251, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 622, Step num: 8217, Learning rate: 0.00009751, Avg batch loss: 0.0233, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 623, Step num: 8218, Learning rate: 0.00009750, Avg batch loss: 0.0262, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 624, Step num: 8219, Learning rate: 0.00009750, Avg batch loss: 0.0318, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 625, Step num: 8220, Learning rate: 0.00009749, Avg batch loss: 0.0321, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 626, Step num: 8221, Learning rate: 0.00009748, Avg batch loss: 0.0302, Avg batch acc: 0.9673
Train, Epoch: 6, Batch: 627, Step num: 8222, Learning rate: 0.00009748, Avg batch loss: 0.0276, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 628, Step num: 8223, Learning rate: 0.00009747, Avg batch loss: 0.0269, Avg batch acc: 0.9680
Train, Epoch: 6, Batch: 629, Step num: 8224, Learning rate: 0.00009747, Avg batch loss: 0.0193, Avg batch acc: 0.9796
Train, Epoch: 6, Batch: 630, Step num: 8225, Learning rate: 0.00009746, Avg batch loss: 0.0289, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 631, Step num: 8226, Learning rate: 0.00009745, Avg batch loss: 0.0266, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 632, Step num: 8227, Learning rate: 0.00009745, Avg batch loss: 0.0313, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 633, Step num: 8228, Learning rate: 0.00009744, Avg batch loss: 0.0312, Avg batch acc: 0.9665
Train, Epoch: 6, Batch: 634, Step num: 8229, Learning rate: 0.00009744, Avg batch loss: 0.0272, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 635, Step num: 8230, Learning rate: 0.00009743, Avg batch loss: 0.0276, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 636, Step num: 8231, Learning rate: 0.00009742, Avg batch loss: 0.0291, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 637, Step num: 8232, Learning rate: 0.00009742, Avg batch loss: 0.0213, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 638, Step num: 8233, Learning rate: 0.00009741, Avg batch loss: 0.0256, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 639, Step num: 8234, Learning rate: 0.00009741, Avg batch loss: 0.0264, Avg batch acc: 0.9731
Train, Epoch: 6, Batch: 640, Step num: 8235, Learning rate: 0.00009740, Avg batch loss: 0.0286, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 641, Step num: 8236, Learning rate: 0.00009740, Avg batch loss: 0.0223, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 642, Step num: 8237, Learning rate: 0.00009739, Avg batch loss: 0.0212, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 643, Step num: 8238, Learning rate: 0.00009738, Avg batch loss: 0.0294, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 644, Step num: 8239, Learning rate: 0.00009738, Avg batch loss: 0.0286, Avg batch acc: 0.9727
Train, Epoch: 6, Batch: 645, Step num: 8240, Learning rate: 0.00009737, Avg batch loss: 0.0435, Avg batch acc: 0.9686
Train, Epoch: 6, Batch: 646, Step num: 8241, Learning rate: 0.00009737, Avg batch loss: 0.0283, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 647, Step num: 8242, Learning rate: 0.00009736, Avg batch loss: 0.0235, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 648, Step num: 8243, Learning rate: 0.00009735, Avg batch loss: 0.0288, Avg batch acc: 0.9750
Train, Epoch: 6, Batch: 649, Step num: 8244, Learning rate: 0.00009735, Avg batch loss: 0.0224, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 650, Step num: 8245, Learning rate: 0.00009734, Avg batch loss: 0.0298, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 651, Step num: 8246, Learning rate: 0.00009734, Avg batch loss: 0.0276, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 652, Step num: 8247, Learning rate: 0.00009733, Avg batch loss: 0.0251, Avg batch acc: 0.9724
Train, Epoch: 6, Batch: 653, Step num: 8248, Learning rate: 0.00009732, Avg batch loss: 0.0265, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 654, Step num: 8249, Learning rate: 0.00009732, Avg batch loss: 0.0268, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 655, Step num: 8250, Learning rate: 0.00009731, Avg batch loss: 0.0283, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 656, Step num: 8251, Learning rate: 0.00009731, Avg batch loss: 0.0276, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 657, Step num: 8252, Learning rate: 0.00009730, Avg batch loss: 0.0322, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 658, Step num: 8253, Learning rate: 0.00009729, Avg batch loss: 0.0224, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 659, Step num: 8254, Learning rate: 0.00009729, Avg batch loss: 0.0310, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 660, Step num: 8255, Learning rate: 0.00009728, Avg batch loss: 0.0233, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 661, Step num: 8256, Learning rate: 0.00009728, Avg batch loss: 0.0223, Avg batch acc: 0.9731
Train, Epoch: 6, Batch: 662, Step num: 8257, Learning rate: 0.00009727, Avg batch loss: 0.0259, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 663, Step num: 8258, Learning rate: 0.00009727, Avg batch loss: 0.0283, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 664, Step num: 8259, Learning rate: 0.00009726, Avg batch loss: 0.0232, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 665, Step num: 8260, Learning rate: 0.00009725, Avg batch loss: 0.0224, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 666, Step num: 8261, Learning rate: 0.00009725, Avg batch loss: 0.0242, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 667, Step num: 8262, Learning rate: 0.00009724, Avg batch loss: 0.0233, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 668, Step num: 8263, Learning rate: 0.00009724, Avg batch loss: 0.0292, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 669, Step num: 8264, Learning rate: 0.00009723, Avg batch loss: 0.0306, Avg batch acc: 0.9696
Train, Epoch: 6, Batch: 670, Step num: 8265, Learning rate: 0.00009722, Avg batch loss: 0.0279, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 671, Step num: 8266, Learning rate: 0.00009722, Avg batch loss: 0.0268, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 672, Step num: 8267, Learning rate: 0.00009721, Avg batch loss: 0.0290, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 673, Step num: 8268, Learning rate: 0.00009721, Avg batch loss: 0.0291, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 674, Step num: 8269, Learning rate: 0.00009720, Avg batch loss: 0.0283, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 675, Step num: 8270, Learning rate: 0.00009719, Avg batch loss: 0.0266, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 676, Step num: 8271, Learning rate: 0.00009719, Avg batch loss: 0.0256, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 677, Step num: 8272, Learning rate: 0.00009718, Avg batch loss: 0.0277, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 678, Step num: 8273, Learning rate: 0.00009718, Avg batch loss: 0.0263, Avg batch acc: 0.9763
Train, Epoch: 6, Batch: 679, Step num: 8274, Learning rate: 0.00009717, Avg batch loss: 0.0274, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 680, Step num: 8275, Learning rate: 0.00009717, Avg batch loss: 0.0306, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 681, Step num: 8276, Learning rate: 0.00009716, Avg batch loss: 0.0196, Avg batch acc: 0.9817
Train, Epoch: 6, Batch: 682, Step num: 8277, Learning rate: 0.00009715, Avg batch loss: 0.0326, Avg batch acc: 0.9651
Train, Epoch: 6, Batch: 683, Step num: 8278, Learning rate: 0.00009715, Avg batch loss: 0.0238, Avg batch acc: 0.9750
Train, Epoch: 6, Batch: 684, Step num: 8279, Learning rate: 0.00009714, Avg batch loss: 0.0293, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 685, Step num: 8280, Learning rate: 0.00009714, Avg batch loss: 0.0251, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 686, Step num: 8281, Learning rate: 0.00009713, Avg batch loss: 0.0292, Avg batch acc: 0.9681
Train, Epoch: 6, Batch: 687, Step num: 8282, Learning rate: 0.00009712, Avg batch loss: 0.0254, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 688, Step num: 8283, Learning rate: 0.00009712, Avg batch loss: 0.0269, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 689, Step num: 8284, Learning rate: 0.00009711, Avg batch loss: 0.0305, Avg batch acc: 0.9651
Train, Epoch: 6, Batch: 690, Step num: 8285, Learning rate: 0.00009711, Avg batch loss: 0.0313, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 691, Step num: 8286, Learning rate: 0.00009710, Avg batch loss: 0.0231, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 692, Step num: 8287, Learning rate: 0.00009709, Avg batch loss: 0.0265, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 693, Step num: 8288, Learning rate: 0.00009709, Avg batch loss: 0.0285, Avg batch acc: 0.9692
Train, Epoch: 6, Batch: 694, Step num: 8289, Learning rate: 0.00009708, Avg batch loss: 0.0239, Avg batch acc: 0.9790
Train, Epoch: 6, Batch: 695, Step num: 8290, Learning rate: 0.00009708, Avg batch loss: 0.0297, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 696, Step num: 8291, Learning rate: 0.00009707, Avg batch loss: 0.0214, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 697, Step num: 8292, Learning rate: 0.00009707, Avg batch loss: 0.0303, Avg batch acc: 0.9695
Train, Epoch: 6, Batch: 698, Step num: 8293, Learning rate: 0.00009706, Avg batch loss: 0.0306, Avg batch acc: 0.9611
Train, Epoch: 6, Batch: 699, Step num: 8294, Learning rate: 0.00009705, Avg batch loss: 0.0301, Avg batch acc: 0.9681
Train, Epoch: 6, Batch: 700, Step num: 8295, Learning rate: 0.00009705, Avg batch loss: 0.0198, Avg batch acc: 0.9806
Train, Epoch: 6, Batch: 701, Step num: 8296, Learning rate: 0.00009704, Avg batch loss: 0.0217, Avg batch acc: 0.9739
Train, Epoch: 6, Batch: 702, Step num: 8297, Learning rate: 0.00009704, Avg batch loss: 0.0304, Avg batch acc: 0.9677
Train, Epoch: 6, Batch: 703, Step num: 8298, Learning rate: 0.00009703, Avg batch loss: 0.0326, Avg batch acc: 0.9671
Train, Epoch: 6, Batch: 704, Step num: 8299, Learning rate: 0.00009702, Avg batch loss: 0.0272, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 705, Step num: 8300, Learning rate: 0.00009702, Avg batch loss: 0.0291, Avg batch acc: 0.9668
Train, Epoch: 6, Batch: 706, Step num: 8301, Learning rate: 0.00009701, Avg batch loss: 0.0265, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 707, Step num: 8302, Learning rate: 0.00009701, Avg batch loss: 0.0239, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 708, Step num: 8303, Learning rate: 0.00009700, Avg batch loss: 0.0252, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 709, Step num: 8304, Learning rate: 0.00009700, Avg batch loss: 0.0232, Avg batch acc: 0.9727
Train, Epoch: 6, Batch: 710, Step num: 8305, Learning rate: 0.00009699, Avg batch loss: 0.0265, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 711, Step num: 8306, Learning rate: 0.00009698, Avg batch loss: 0.0249, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 712, Step num: 8307, Learning rate: 0.00009698, Avg batch loss: 0.0270, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 713, Step num: 8308, Learning rate: 0.00009697, Avg batch loss: 0.0246, Avg batch acc: 0.9677
Train, Epoch: 6, Batch: 714, Step num: 8309, Learning rate: 0.00009697, Avg batch loss: 0.0324, Avg batch acc: 0.9634
Train, Epoch: 6, Batch: 715, Step num: 8310, Learning rate: 0.00009696, Avg batch loss: 0.0256, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 716, Step num: 8311, Learning rate: 0.00009695, Avg batch loss: 0.0228, Avg batch acc: 0.9750
Train, Epoch: 6, Batch: 717, Step num: 8312, Learning rate: 0.00009695, Avg batch loss: 0.0245, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 718, Step num: 8313, Learning rate: 0.00009694, Avg batch loss: 0.0278, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 719, Step num: 8314, Learning rate: 0.00009694, Avg batch loss: 0.0253, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 720, Step num: 8315, Learning rate: 0.00009693, Avg batch loss: 0.0245, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 721, Step num: 8316, Learning rate: 0.00009693, Avg batch loss: 0.0310, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 722, Step num: 8317, Learning rate: 0.00009692, Avg batch loss: 0.0279, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 723, Step num: 8318, Learning rate: 0.00009691, Avg batch loss: 0.0306, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 724, Step num: 8319, Learning rate: 0.00009691, Avg batch loss: 0.0211, Avg batch acc: 0.9791
Train, Epoch: 6, Batch: 725, Step num: 8320, Learning rate: 0.00009690, Avg batch loss: 0.0226, Avg batch acc: 0.9771
Train, Epoch: 6, Batch: 726, Step num: 8321, Learning rate: 0.00009690, Avg batch loss: 0.0214, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 727, Step num: 8322, Learning rate: 0.00009689, Avg batch loss: 0.0235, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 728, Step num: 8323, Learning rate: 0.00009688, Avg batch loss: 0.0228, Avg batch acc: 0.9786
Train, Epoch: 6, Batch: 729, Step num: 8324, Learning rate: 0.00009688, Avg batch loss: 0.0215, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 730, Step num: 8325, Learning rate: 0.00009687, Avg batch loss: 0.0496, Avg batch acc: 0.9644
Train, Epoch: 6, Batch: 731, Step num: 8326, Learning rate: 0.00009687, Avg batch loss: 0.0245, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 732, Step num: 8327, Learning rate: 0.00009686, Avg batch loss: 0.0272, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 733, Step num: 8328, Learning rate: 0.00009686, Avg batch loss: 0.0241, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 734, Step num: 8329, Learning rate: 0.00009685, Avg batch loss: 0.0242, Avg batch acc: 0.9776
Train, Epoch: 6, Batch: 735, Step num: 8330, Learning rate: 0.00009684, Avg batch loss: 0.0279, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 736, Step num: 8331, Learning rate: 0.00009684, Avg batch loss: 0.0253, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 737, Step num: 8332, Learning rate: 0.00009683, Avg batch loss: 0.0210, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 738, Step num: 8333, Learning rate: 0.00009683, Avg batch loss: 0.0201, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 739, Step num: 8334, Learning rate: 0.00009682, Avg batch loss: 0.0211, Avg batch acc: 0.9781
Train, Epoch: 6, Batch: 740, Step num: 8335, Learning rate: 0.00009681, Avg batch loss: 0.0237, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 741, Step num: 8336, Learning rate: 0.00009681, Avg batch loss: 0.0260, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 742, Step num: 8337, Learning rate: 0.00009680, Avg batch loss: 0.0232, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 743, Step num: 8338, Learning rate: 0.00009680, Avg batch loss: 0.0271, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 744, Step num: 8339, Learning rate: 0.00009679, Avg batch loss: 0.0226, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 745, Step num: 8340, Learning rate: 0.00009679, Avg batch loss: 0.0247, Avg batch acc: 0.9773
Train, Epoch: 6, Batch: 746, Step num: 8341, Learning rate: 0.00009678, Avg batch loss: 0.0303, Avg batch acc: 0.9673
Train, Epoch: 6, Batch: 747, Step num: 8342, Learning rate: 0.00009677, Avg batch loss: 0.0227, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 748, Step num: 8343, Learning rate: 0.00009677, Avg batch loss: 0.0262, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 749, Step num: 8344, Learning rate: 0.00009676, Avg batch loss: 0.0244, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 750, Step num: 8345, Learning rate: 0.00009676, Avg batch loss: 0.0217, Avg batch acc: 0.9773
Train, Epoch: 6, Batch: 751, Step num: 8346, Learning rate: 0.00009675, Avg batch loss: 0.0309, Avg batch acc: 0.9724
Train, Epoch: 6, Batch: 752, Step num: 8347, Learning rate: 0.00009675, Avg batch loss: 0.0412, Avg batch acc: 0.9663
Train, Epoch: 6, Batch: 753, Step num: 8348, Learning rate: 0.00009674, Avg batch loss: 0.0256, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 754, Step num: 8349, Learning rate: 0.00009673, Avg batch loss: 0.0242, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 755, Step num: 8350, Learning rate: 0.00009673, Avg batch loss: 0.0252, Avg batch acc: 0.9798
Train, Epoch: 6, Batch: 756, Step num: 8351, Learning rate: 0.00009672, Avg batch loss: 0.0281, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 757, Step num: 8352, Learning rate: 0.00009672, Avg batch loss: 0.0276, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 758, Step num: 8353, Learning rate: 0.00009671, Avg batch loss: 0.0272, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 759, Step num: 8354, Learning rate: 0.00009670, Avg batch loss: 0.0284, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 760, Step num: 8355, Learning rate: 0.00009670, Avg batch loss: 0.0234, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 761, Step num: 8356, Learning rate: 0.00009669, Avg batch loss: 0.0356, Avg batch acc: 0.9724
Train, Epoch: 6, Batch: 762, Step num: 8357, Learning rate: 0.00009669, Avg batch loss: 0.0310, Avg batch acc: 0.9633
Train, Epoch: 6, Batch: 763, Step num: 8358, Learning rate: 0.00009668, Avg batch loss: 0.0271, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 764, Step num: 8359, Learning rate: 0.00009668, Avg batch loss: 0.0288, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 765, Step num: 8360, Learning rate: 0.00009667, Avg batch loss: 0.0394, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 766, Step num: 8361, Learning rate: 0.00009666, Avg batch loss: 0.0241, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 767, Step num: 8362, Learning rate: 0.00009666, Avg batch loss: 0.0286, Avg batch acc: 0.9666
Train, Epoch: 6, Batch: 768, Step num: 8363, Learning rate: 0.00009665, Avg batch loss: 0.0254, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 769, Step num: 8364, Learning rate: 0.00009665, Avg batch loss: 0.0214, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 770, Step num: 8365, Learning rate: 0.00009664, Avg batch loss: 0.0224, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 771, Step num: 8366, Learning rate: 0.00009664, Avg batch loss: 0.0278, Avg batch acc: 0.9731
Train, Epoch: 6, Batch: 772, Step num: 8367, Learning rate: 0.00009663, Avg batch loss: 0.0247, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 773, Step num: 8368, Learning rate: 0.00009662, Avg batch loss: 0.0434, Avg batch acc: 0.9676
Train, Epoch: 6, Batch: 774, Step num: 8369, Learning rate: 0.00009662, Avg batch loss: 0.0272, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 775, Step num: 8370, Learning rate: 0.00009661, Avg batch loss: 0.0245, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 776, Step num: 8371, Learning rate: 0.00009661, Avg batch loss: 0.0274, Avg batch acc: 0.9670
Train, Epoch: 6, Batch: 777, Step num: 8372, Learning rate: 0.00009660, Avg batch loss: 0.0325, Avg batch acc: 0.9714
Train, Epoch: 6, Batch: 778, Step num: 8373, Learning rate: 0.00009659, Avg batch loss: 0.0237, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 779, Step num: 8374, Learning rate: 0.00009659, Avg batch loss: 0.0280, Avg batch acc: 0.9697
Train, Epoch: 6, Batch: 780, Step num: 8375, Learning rate: 0.00009658, Avg batch loss: 0.0280, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 781, Step num: 8376, Learning rate: 0.00009658, Avg batch loss: 0.0257, Avg batch acc: 0.9725
Train, Epoch: 6, Batch: 782, Step num: 8377, Learning rate: 0.00009657, Avg batch loss: 0.0236, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 783, Step num: 8378, Learning rate: 0.00009657, Avg batch loss: 0.0235, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 784, Step num: 8379, Learning rate: 0.00009656, Avg batch loss: 0.0267, Avg batch acc: 0.9702
Train, Epoch: 6, Batch: 785, Step num: 8380, Learning rate: 0.00009655, Avg batch loss: 0.0251, Avg batch acc: 0.9702
Train, Epoch: 6, Batch: 786, Step num: 8381, Learning rate: 0.00009655, Avg batch loss: 0.0336, Avg batch acc: 0.9638
Train, Epoch: 6, Batch: 787, Step num: 8382, Learning rate: 0.00009654, Avg batch loss: 0.0211, Avg batch acc: 0.9777
Train, Epoch: 6, Batch: 788, Step num: 8383, Learning rate: 0.00009654, Avg batch loss: 0.0249, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 789, Step num: 8384, Learning rate: 0.00009653, Avg batch loss: 0.0337, Avg batch acc: 0.9710
Train, Epoch: 6, Batch: 790, Step num: 8385, Learning rate: 0.00009653, Avg batch loss: 0.0242, Avg batch acc: 0.9766
Train, Epoch: 6, Batch: 791, Step num: 8386, Learning rate: 0.00009652, Avg batch loss: 0.0256, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 792, Step num: 8387, Learning rate: 0.00009651, Avg batch loss: 0.0271, Avg batch acc: 0.9747
Train, Epoch: 6, Batch: 793, Step num: 8388, Learning rate: 0.00009651, Avg batch loss: 0.0222, Avg batch acc: 0.9783
Train, Epoch: 6, Batch: 794, Step num: 8389, Learning rate: 0.00009650, Avg batch loss: 0.0241, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 795, Step num: 8390, Learning rate: 0.00009650, Avg batch loss: 0.0440, Avg batch acc: 0.9645
Train, Epoch: 6, Batch: 796, Step num: 8391, Learning rate: 0.00009649, Avg batch loss: 0.0236, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 797, Step num: 8392, Learning rate: 0.00009649, Avg batch loss: 0.0264, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 798, Step num: 8393, Learning rate: 0.00009648, Avg batch loss: 0.0389, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 799, Step num: 8394, Learning rate: 0.00009647, Avg batch loss: 0.0251, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 800, Step num: 8395, Learning rate: 0.00009647, Avg batch loss: 0.0273, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 801, Step num: 8396, Learning rate: 0.00009646, Avg batch loss: 0.0256, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 802, Step num: 8397, Learning rate: 0.00009646, Avg batch loss: 0.0223, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 803, Step num: 8398, Learning rate: 0.00009645, Avg batch loss: 0.0258, Avg batch acc: 0.9776
Train, Epoch: 6, Batch: 804, Step num: 8399, Learning rate: 0.00009645, Avg batch loss: 0.0259, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 805, Step num: 8400, Learning rate: 0.00009644, Avg batch loss: 0.0285, Avg batch acc: 0.9695
Train, Epoch: 6, Batch: 806, Step num: 8401, Learning rate: 0.00009643, Avg batch loss: 0.0341, Avg batch acc: 0.9664
Train, Epoch: 6, Batch: 807, Step num: 8402, Learning rate: 0.00009643, Avg batch loss: 0.0267, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 808, Step num: 8403, Learning rate: 0.00009642, Avg batch loss: 0.0407, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 809, Step num: 8404, Learning rate: 0.00009642, Avg batch loss: 0.0227, Avg batch acc: 0.9725
Train, Epoch: 6, Batch: 810, Step num: 8405, Learning rate: 0.00009641, Avg batch loss: 0.0241, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 811, Step num: 8406, Learning rate: 0.00009641, Avg batch loss: 0.0254, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 812, Step num: 8407, Learning rate: 0.00009640, Avg batch loss: 0.0262, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 813, Step num: 8408, Learning rate: 0.00009639, Avg batch loss: 0.0345, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 814, Step num: 8409, Learning rate: 0.00009639, Avg batch loss: 0.0250, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 815, Step num: 8410, Learning rate: 0.00009638, Avg batch loss: 0.0234, Avg batch acc: 0.9773
Train, Epoch: 6, Batch: 816, Step num: 8411, Learning rate: 0.00009638, Avg batch loss: 0.0232, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 817, Step num: 8412, Learning rate: 0.00009637, Avg batch loss: 0.0272, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 818, Step num: 8413, Learning rate: 0.00009637, Avg batch loss: 0.0211, Avg batch acc: 0.9772
Train, Epoch: 6, Batch: 819, Step num: 8414, Learning rate: 0.00009636, Avg batch loss: 0.0225, Avg batch acc: 0.9779
Train, Epoch: 6, Batch: 820, Step num: 8415, Learning rate: 0.00009635, Avg batch loss: 0.0226, Avg batch acc: 0.9800
Train, Epoch: 6, Batch: 821, Step num: 8416, Learning rate: 0.00009635, Avg batch loss: 0.0258, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 822, Step num: 8417, Learning rate: 0.00009634, Avg batch loss: 0.0254, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 823, Step num: 8418, Learning rate: 0.00009634, Avg batch loss: 0.0289, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 824, Step num: 8419, Learning rate: 0.00009633, Avg batch loss: 0.0220, Avg batch acc: 0.9797
Train, Epoch: 6, Batch: 825, Step num: 8420, Learning rate: 0.00009632, Avg batch loss: 0.0358, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 826, Step num: 8421, Learning rate: 0.00009632, Avg batch loss: 0.0259, Avg batch acc: 0.9695
Train, Epoch: 6, Batch: 827, Step num: 8422, Learning rate: 0.00009631, Avg batch loss: 0.0256, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 828, Step num: 8423, Learning rate: 0.00009631, Avg batch loss: 0.0246, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 829, Step num: 8424, Learning rate: 0.00009630, Avg batch loss: 0.0247, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 830, Step num: 8425, Learning rate: 0.00009630, Avg batch loss: 0.0333, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 831, Step num: 8426, Learning rate: 0.00009629, Avg batch loss: 0.0258, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 832, Step num: 8427, Learning rate: 0.00009628, Avg batch loss: 0.0248, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 833, Step num: 8428, Learning rate: 0.00009628, Avg batch loss: 0.0216, Avg batch acc: 0.9795
Train, Epoch: 6, Batch: 834, Step num: 8429, Learning rate: 0.00009627, Avg batch loss: 0.0255, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 835, Step num: 8430, Learning rate: 0.00009627, Avg batch loss: 0.0282, Avg batch acc: 0.9739
Train, Epoch: 6, Batch: 836, Step num: 8431, Learning rate: 0.00009626, Avg batch loss: 0.0283, Avg batch acc: 0.9727
Train, Epoch: 6, Batch: 837, Step num: 8432, Learning rate: 0.00009626, Avg batch loss: 0.0257, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 838, Step num: 8433, Learning rate: 0.00009625, Avg batch loss: 0.0243, Avg batch acc: 0.9775
Train, Epoch: 6, Batch: 839, Step num: 8434, Learning rate: 0.00009625, Avg batch loss: 0.0289, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 840, Step num: 8435, Learning rate: 0.00009624, Avg batch loss: 0.0247, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 841, Step num: 8436, Learning rate: 0.00009623, Avg batch loss: 0.0248, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 842, Step num: 8437, Learning rate: 0.00009623, Avg batch loss: 0.0234, Avg batch acc: 0.9772
Train, Epoch: 6, Batch: 843, Step num: 8438, Learning rate: 0.00009622, Avg batch loss: 0.0342, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 844, Step num: 8439, Learning rate: 0.00009622, Avg batch loss: 0.0270, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 845, Step num: 8440, Learning rate: 0.00009621, Avg batch loss: 0.0234, Avg batch acc: 0.9747
Train, Epoch: 6, Batch: 846, Step num: 8441, Learning rate: 0.00009621, Avg batch loss: 0.0250, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 847, Step num: 8442, Learning rate: 0.00009620, Avg batch loss: 0.0244, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 848, Step num: 8443, Learning rate: 0.00009619, Avg batch loss: 0.0281, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 849, Step num: 8444, Learning rate: 0.00009619, Avg batch loss: 0.0254, Avg batch acc: 0.9674
Train, Epoch: 6, Batch: 850, Step num: 8445, Learning rate: 0.00009618, Avg batch loss: 0.0266, Avg batch acc: 0.9781
Train, Epoch: 6, Batch: 851, Step num: 8446, Learning rate: 0.00009618, Avg batch loss: 0.0466, Avg batch acc: 0.9600
Train, Epoch: 6, Batch: 852, Step num: 8447, Learning rate: 0.00009617, Avg batch loss: 0.0255, Avg batch acc: 0.9714
Train, Epoch: 6, Batch: 853, Step num: 8448, Learning rate: 0.00009617, Avg batch loss: 0.0263, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 854, Step num: 8449, Learning rate: 0.00009616, Avg batch loss: 0.0301, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 855, Step num: 8450, Learning rate: 0.00009615, Avg batch loss: 0.0240, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 856, Step num: 8451, Learning rate: 0.00009615, Avg batch loss: 0.0199, Avg batch acc: 0.9781
Train, Epoch: 6, Batch: 857, Step num: 8452, Learning rate: 0.00009614, Avg batch loss: 0.0251, Avg batch acc: 0.9725
Train, Epoch: 6, Batch: 858, Step num: 8453, Learning rate: 0.00009614, Avg batch loss: 0.0235, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 859, Step num: 8454, Learning rate: 0.00009613, Avg batch loss: 0.0267, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 860, Step num: 8455, Learning rate: 0.00009613, Avg batch loss: 0.0240, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 861, Step num: 8456, Learning rate: 0.00009612, Avg batch loss: 0.0273, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 862, Step num: 8457, Learning rate: 0.00009611, Avg batch loss: 0.0257, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 863, Step num: 8458, Learning rate: 0.00009611, Avg batch loss: 0.0235, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 864, Step num: 8459, Learning rate: 0.00009610, Avg batch loss: 0.0224, Avg batch acc: 0.9752
Train, Epoch: 6, Batch: 865, Step num: 8460, Learning rate: 0.00009610, Avg batch loss: 0.0264, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 866, Step num: 8461, Learning rate: 0.00009609, Avg batch loss: 0.0229, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 867, Step num: 8462, Learning rate: 0.00009609, Avg batch loss: 0.0252, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 868, Step num: 8463, Learning rate: 0.00009608, Avg batch loss: 0.0245, Avg batch acc: 0.9778
Train, Epoch: 6, Batch: 869, Step num: 8464, Learning rate: 0.00009607, Avg batch loss: 0.0250, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 870, Step num: 8465, Learning rate: 0.00009607, Avg batch loss: 0.0264, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 871, Step num: 8466, Learning rate: 0.00009606, Avg batch loss: 0.0216, Avg batch acc: 0.9799
Train, Epoch: 6, Batch: 872, Step num: 8467, Learning rate: 0.00009606, Avg batch loss: 0.0258, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 873, Step num: 8468, Learning rate: 0.00009605, Avg batch loss: 0.0210, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 874, Step num: 8469, Learning rate: 0.00009605, Avg batch loss: 0.0288, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 875, Step num: 8470, Learning rate: 0.00009604, Avg batch loss: 0.0232, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 876, Step num: 8471, Learning rate: 0.00009603, Avg batch loss: 0.0308, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 877, Step num: 8472, Learning rate: 0.00009603, Avg batch loss: 0.0239, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 878, Step num: 8473, Learning rate: 0.00009602, Avg batch loss: 0.0199, Avg batch acc: 0.9783
Train, Epoch: 6, Batch: 879, Step num: 8474, Learning rate: 0.00009602, Avg batch loss: 0.0186, Avg batch acc: 0.9808
Train, Epoch: 6, Batch: 880, Step num: 8475, Learning rate: 0.00009601, Avg batch loss: 0.0199, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 881, Step num: 8476, Learning rate: 0.00009601, Avg batch loss: 0.0214, Avg batch acc: 0.9775
Train, Epoch: 6, Batch: 882, Step num: 8477, Learning rate: 0.00009600, Avg batch loss: 0.0227, Avg batch acc: 0.9799
Train, Epoch: 6, Batch: 883, Step num: 8478, Learning rate: 0.00009599, Avg batch loss: 0.0231, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 884, Step num: 8479, Learning rate: 0.00009599, Avg batch loss: 0.0267, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 885, Step num: 8480, Learning rate: 0.00009598, Avg batch loss: 0.0213, Avg batch acc: 0.9789
Train, Epoch: 6, Batch: 886, Step num: 8481, Learning rate: 0.00009598, Avg batch loss: 0.0258, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 887, Step num: 8482, Learning rate: 0.00009597, Avg batch loss: 0.0287, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 888, Step num: 8483, Learning rate: 0.00009597, Avg batch loss: 0.0194, Avg batch acc: 0.9817
Train, Epoch: 6, Batch: 889, Step num: 8484, Learning rate: 0.00009596, Avg batch loss: 0.0247, Avg batch acc: 0.9754
Train, Epoch: 6, Batch: 890, Step num: 8485, Learning rate: 0.00009596, Avg batch loss: 0.0232, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 891, Step num: 8486, Learning rate: 0.00009595, Avg batch loss: 0.0203, Avg batch acc: 0.9784
Train, Epoch: 6, Batch: 892, Step num: 8487, Learning rate: 0.00009594, Avg batch loss: 0.0253, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 893, Step num: 8488, Learning rate: 0.00009594, Avg batch loss: 0.0241, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 894, Step num: 8489, Learning rate: 0.00009593, Avg batch loss: 0.0218, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 895, Step num: 8490, Learning rate: 0.00009593, Avg batch loss: 0.0243, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 896, Step num: 8491, Learning rate: 0.00009592, Avg batch loss: 0.0173, Avg batch acc: 0.9798
Train, Epoch: 6, Batch: 897, Step num: 8492, Learning rate: 0.00009592, Avg batch loss: 0.0337, Avg batch acc: 0.9686
Train, Epoch: 6, Batch: 898, Step num: 8493, Learning rate: 0.00009591, Avg batch loss: 0.0211, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 899, Step num: 8494, Learning rate: 0.00009590, Avg batch loss: 0.0254, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 900, Step num: 8495, Learning rate: 0.00009590, Avg batch loss: 0.0205, Avg batch acc: 0.9763
Train, Epoch: 6, Batch: 901, Step num: 8496, Learning rate: 0.00009589, Avg batch loss: 0.0262, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 902, Step num: 8497, Learning rate: 0.00009589, Avg batch loss: 0.0254, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 903, Step num: 8498, Learning rate: 0.00009588, Avg batch loss: 0.0217, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 904, Step num: 8499, Learning rate: 0.00009588, Avg batch loss: 0.0269, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 905, Step num: 8500, Learning rate: 0.00009587, Avg batch loss: 0.0268, Avg batch acc: 0.9690
Train, Epoch: 6, Batch: 906, Step num: 8501, Learning rate: 0.00009586, Avg batch loss: 0.0218, Avg batch acc: 0.9777
Train, Epoch: 6, Batch: 907, Step num: 8502, Learning rate: 0.00009586, Avg batch loss: 0.0235, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 908, Step num: 8503, Learning rate: 0.00009585, Avg batch loss: 0.0242, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 909, Step num: 8504, Learning rate: 0.00009585, Avg batch loss: 0.0225, Avg batch acc: 0.9725
Train, Epoch: 6, Batch: 910, Step num: 8505, Learning rate: 0.00009584, Avg batch loss: 0.0205, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 911, Step num: 8506, Learning rate: 0.00009584, Avg batch loss: 0.0256, Avg batch acc: 0.9747
Train, Epoch: 6, Batch: 912, Step num: 8507, Learning rate: 0.00009583, Avg batch loss: 0.0258, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 913, Step num: 8508, Learning rate: 0.00009583, Avg batch loss: 0.0228, Avg batch acc: 0.9776
Train, Epoch: 6, Batch: 914, Step num: 8509, Learning rate: 0.00009582, Avg batch loss: 0.0269, Avg batch acc: 0.9754
Train, Epoch: 6, Batch: 915, Step num: 8510, Learning rate: 0.00009581, Avg batch loss: 0.0236, Avg batch acc: 0.9774
Train, Epoch: 6, Batch: 916, Step num: 8511, Learning rate: 0.00009581, Avg batch loss: 0.0230, Avg batch acc: 0.9786
Train, Epoch: 6, Batch: 917, Step num: 8512, Learning rate: 0.00009580, Avg batch loss: 0.0238, Avg batch acc: 0.9705
Train, Epoch: 6, Batch: 918, Step num: 8513, Learning rate: 0.00009580, Avg batch loss: 0.0393, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 919, Step num: 8514, Learning rate: 0.00009579, Avg batch loss: 0.0232, Avg batch acc: 0.9712
Train, Epoch: 6, Batch: 920, Step num: 8515, Learning rate: 0.00009579, Avg batch loss: 0.0336, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 921, Step num: 8516, Learning rate: 0.00009578, Avg batch loss: 0.0267, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 922, Step num: 8517, Learning rate: 0.00009577, Avg batch loss: 0.0234, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 923, Step num: 8518, Learning rate: 0.00009577, Avg batch loss: 0.0399, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 924, Step num: 8519, Learning rate: 0.00009576, Avg batch loss: 0.0486, Avg batch acc: 0.9641
Train, Epoch: 6, Batch: 925, Step num: 8520, Learning rate: 0.00009576, Avg batch loss: 0.0360, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 926, Step num: 8521, Learning rate: 0.00009575, Avg batch loss: 0.0304, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 927, Step num: 8522, Learning rate: 0.00009575, Avg batch loss: 0.0245, Avg batch acc: 0.9710
Train, Epoch: 6, Batch: 928, Step num: 8523, Learning rate: 0.00009574, Avg batch loss: 0.0249, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 929, Step num: 8524, Learning rate: 0.00009574, Avg batch loss: 0.0508, Avg batch acc: 0.9621
Train, Epoch: 6, Batch: 930, Step num: 8525, Learning rate: 0.00009573, Avg batch loss: 0.0243, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 931, Step num: 8526, Learning rate: 0.00009572, Avg batch loss: 0.0497, Avg batch acc: 0.9628
Train, Epoch: 6, Batch: 932, Step num: 8527, Learning rate: 0.00009572, Avg batch loss: 0.0424, Avg batch acc: 0.9641
Train, Epoch: 6, Batch: 933, Step num: 8528, Learning rate: 0.00009571, Avg batch loss: 0.0250, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 934, Step num: 8529, Learning rate: 0.00009571, Avg batch loss: 0.0239, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 935, Step num: 8530, Learning rate: 0.00009570, Avg batch loss: 0.0276, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 936, Step num: 8531, Learning rate: 0.00009570, Avg batch loss: 0.0264, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 937, Step num: 8532, Learning rate: 0.00009569, Avg batch loss: 0.0256, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 938, Step num: 8533, Learning rate: 0.00009569, Avg batch loss: 0.0246, Avg batch acc: 0.9714
Train, Epoch: 6, Batch: 939, Step num: 8534, Learning rate: 0.00009568, Avg batch loss: 0.0274, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 940, Step num: 8535, Learning rate: 0.00009567, Avg batch loss: 0.0682, Avg batch acc: 0.9607
Train, Epoch: 6, Batch: 941, Step num: 8536, Learning rate: 0.00009567, Avg batch loss: 0.0549, Avg batch acc: 0.9611
Train, Epoch: 6, Batch: 942, Step num: 8537, Learning rate: 0.00009566, Avg batch loss: 0.0461, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 943, Step num: 8538, Learning rate: 0.00009566, Avg batch loss: 0.0257, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 944, Step num: 8539, Learning rate: 0.00009565, Avg batch loss: 0.0278, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 945, Step num: 8540, Learning rate: 0.00009565, Avg batch loss: 0.0263, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 946, Step num: 8541, Learning rate: 0.00009564, Avg batch loss: 0.0246, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 947, Step num: 8542, Learning rate: 0.00009563, Avg batch loss: 0.0243, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 948, Step num: 8543, Learning rate: 0.00009563, Avg batch loss: 0.0259, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 949, Step num: 8544, Learning rate: 0.00009562, Avg batch loss: 0.0263, Avg batch acc: 0.9691
Train, Epoch: 6, Batch: 950, Step num: 8545, Learning rate: 0.00009562, Avg batch loss: 0.0217, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 951, Step num: 8546, Learning rate: 0.00009561, Avg batch loss: 0.0247, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 952, Step num: 8547, Learning rate: 0.00009561, Avg batch loss: 0.0231, Avg batch acc: 0.9757
Train, Epoch: 6, Batch: 953, Step num: 8548, Learning rate: 0.00009560, Avg batch loss: 0.0253, Avg batch acc: 0.9659
Train, Epoch: 6, Batch: 954, Step num: 8549, Learning rate: 0.00009560, Avg batch loss: 0.0309, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 955, Step num: 8550, Learning rate: 0.00009559, Avg batch loss: 0.0280, Avg batch acc: 0.9696
Train, Epoch: 6, Batch: 956, Step num: 8551, Learning rate: 0.00009558, Avg batch loss: 0.0279, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 957, Step num: 8552, Learning rate: 0.00009558, Avg batch loss: 0.0245, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 958, Step num: 8553, Learning rate: 0.00009557, Avg batch loss: 0.0240, Avg batch acc: 0.9714
Train, Epoch: 6, Batch: 959, Step num: 8554, Learning rate: 0.00009557, Avg batch loss: 0.0291, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 960, Step num: 8555, Learning rate: 0.00009556, Avg batch loss: 0.0259, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 961, Step num: 8556, Learning rate: 0.00009556, Avg batch loss: 0.0201, Avg batch acc: 0.9805
Train, Epoch: 6, Batch: 962, Step num: 8557, Learning rate: 0.00009555, Avg batch loss: 0.0247, Avg batch acc: 0.9676
Train, Epoch: 6, Batch: 963, Step num: 8558, Learning rate: 0.00009555, Avg batch loss: 0.0233, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 964, Step num: 8559, Learning rate: 0.00009554, Avg batch loss: 0.0241, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 965, Step num: 8560, Learning rate: 0.00009553, Avg batch loss: 0.0234, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 966, Step num: 8561, Learning rate: 0.00009553, Avg batch loss: 0.0226, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 967, Step num: 8562, Learning rate: 0.00009552, Avg batch loss: 0.0235, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 968, Step num: 8563, Learning rate: 0.00009552, Avg batch loss: 0.0232, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 969, Step num: 8564, Learning rate: 0.00009551, Avg batch loss: 0.0277, Avg batch acc: 0.9675
Train, Epoch: 6, Batch: 970, Step num: 8565, Learning rate: 0.00009551, Avg batch loss: 0.0297, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 971, Step num: 8566, Learning rate: 0.00009550, Avg batch loss: 0.0313, Avg batch acc: 0.9689
Train, Epoch: 6, Batch: 972, Step num: 8567, Learning rate: 0.00009549, Avg batch loss: 0.0391, Avg batch acc: 0.9695
Train, Epoch: 6, Batch: 973, Step num: 8568, Learning rate: 0.00009549, Avg batch loss: 0.0272, Avg batch acc: 0.9661
Train, Epoch: 6, Batch: 974, Step num: 8569, Learning rate: 0.00009548, Avg batch loss: 0.0247, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 975, Step num: 8570, Learning rate: 0.00009548, Avg batch loss: 0.0247, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 976, Step num: 8571, Learning rate: 0.00009547, Avg batch loss: 0.0318, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 977, Step num: 8572, Learning rate: 0.00009547, Avg batch loss: 0.0290, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 978, Step num: 8573, Learning rate: 0.00009546, Avg batch loss: 0.0269, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 979, Step num: 8574, Learning rate: 0.00009546, Avg batch loss: 0.0235, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 980, Step num: 8575, Learning rate: 0.00009545, Avg batch loss: 0.0220, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 981, Step num: 8576, Learning rate: 0.00009544, Avg batch loss: 0.0312, Avg batch acc: 0.9676
Train, Epoch: 6, Batch: 982, Step num: 8577, Learning rate: 0.00009544, Avg batch loss: 0.0269, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 983, Step num: 8578, Learning rate: 0.00009543, Avg batch loss: 0.0202, Avg batch acc: 0.9789
Train, Epoch: 6, Batch: 984, Step num: 8579, Learning rate: 0.00009543, Avg batch loss: 0.0239, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 985, Step num: 8580, Learning rate: 0.00009542, Avg batch loss: 0.0233, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 986, Step num: 8581, Learning rate: 0.00009542, Avg batch loss: 0.0254, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 987, Step num: 8582, Learning rate: 0.00009541, Avg batch loss: 0.0243, Avg batch acc: 0.9788
Train, Epoch: 6, Batch: 988, Step num: 8583, Learning rate: 0.00009541, Avg batch loss: 0.0328, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 989, Step num: 8584, Learning rate: 0.00009540, Avg batch loss: 0.0295, Avg batch acc: 0.9690
Train, Epoch: 6, Batch: 990, Step num: 8585, Learning rate: 0.00009539, Avg batch loss: 0.0192, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 991, Step num: 8586, Learning rate: 0.00009539, Avg batch loss: 0.0222, Avg batch acc: 0.9739
Train, Epoch: 6, Batch: 992, Step num: 8587, Learning rate: 0.00009538, Avg batch loss: 0.0239, Avg batch acc: 0.9682
Train, Epoch: 6, Batch: 993, Step num: 8588, Learning rate: 0.00009538, Avg batch loss: 0.0280, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 994, Step num: 8589, Learning rate: 0.00009537, Avg batch loss: 0.0223, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 995, Step num: 8590, Learning rate: 0.00009537, Avg batch loss: 0.0358, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 996, Step num: 8591, Learning rate: 0.00009536, Avg batch loss: 0.0232, Avg batch acc: 0.9790
Train, Epoch: 6, Batch: 997, Step num: 8592, Learning rate: 0.00009536, Avg batch loss: 0.0250, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 998, Step num: 8593, Learning rate: 0.00009535, Avg batch loss: 0.0252, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 999, Step num: 8594, Learning rate: 0.00009534, Avg batch loss: 0.0226, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 1000, Step num: 8595, Learning rate: 0.00009534, Avg batch loss: 0.0204, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1001, Step num: 8596, Learning rate: 0.00009533, Avg batch loss: 0.0269, Avg batch acc: 0.9679
Train, Epoch: 6, Batch: 1002, Step num: 8597, Learning rate: 0.00009533, Avg batch loss: 0.0244, Avg batch acc: 0.9757
Train, Epoch: 6, Batch: 1003, Step num: 8598, Learning rate: 0.00009532, Avg batch loss: 0.0263, Avg batch acc: 0.9731
Train, Epoch: 6, Batch: 1004, Step num: 8599, Learning rate: 0.00009532, Avg batch loss: 0.0190, Avg batch acc: 0.9757
Train, Epoch: 6, Batch: 1005, Step num: 8600, Learning rate: 0.00009531, Avg batch loss: 0.0281, Avg batch acc: 0.9693
Train, Epoch: 6, Batch: 1006, Step num: 8601, Learning rate: 0.00009531, Avg batch loss: 0.0196, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 1007, Step num: 8602, Learning rate: 0.00009530, Avg batch loss: 0.0257, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 1008, Step num: 8603, Learning rate: 0.00009529, Avg batch loss: 0.0204, Avg batch acc: 0.9811
Train, Epoch: 6, Batch: 1009, Step num: 8604, Learning rate: 0.00009529, Avg batch loss: 0.0239, Avg batch acc: 0.9719
Train, Epoch: 6, Batch: 1010, Step num: 8605, Learning rate: 0.00009528, Avg batch loss: 0.0248, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 1011, Step num: 8606, Learning rate: 0.00009528, Avg batch loss: 0.0280, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 1012, Step num: 8607, Learning rate: 0.00009527, Avg batch loss: 0.0293, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 1013, Step num: 8608, Learning rate: 0.00009527, Avg batch loss: 0.0192, Avg batch acc: 0.9812
Train, Epoch: 6, Batch: 1014, Step num: 8609, Learning rate: 0.00009526, Avg batch loss: 0.0256, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 1015, Step num: 8610, Learning rate: 0.00009526, Avg batch loss: 0.0247, Avg batch acc: 0.9786
Train, Epoch: 6, Batch: 1016, Step num: 8611, Learning rate: 0.00009525, Avg batch loss: 0.0297, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 1017, Step num: 8612, Learning rate: 0.00009525, Avg batch loss: 0.0275, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 1018, Step num: 8613, Learning rate: 0.00009524, Avg batch loss: 0.0247, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 1019, Step num: 8614, Learning rate: 0.00009523, Avg batch loss: 0.0246, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 1020, Step num: 8615, Learning rate: 0.00009523, Avg batch loss: 0.0350, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 1021, Step num: 8616, Learning rate: 0.00009522, Avg batch loss: 0.0202, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 1022, Step num: 8617, Learning rate: 0.00009522, Avg batch loss: 0.0272, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 1023, Step num: 8618, Learning rate: 0.00009521, Avg batch loss: 0.0241, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 1024, Step num: 8619, Learning rate: 0.00009521, Avg batch loss: 0.0213, Avg batch acc: 0.9781
Train, Epoch: 6, Batch: 1025, Step num: 8620, Learning rate: 0.00009520, Avg batch loss: 0.0242, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 1026, Step num: 8621, Learning rate: 0.00009520, Avg batch loss: 0.0275, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 1027, Step num: 8622, Learning rate: 0.00009519, Avg batch loss: 0.0231, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 1028, Step num: 8623, Learning rate: 0.00009518, Avg batch loss: 0.0244, Avg batch acc: 0.9688
Train, Epoch: 6, Batch: 1029, Step num: 8624, Learning rate: 0.00009518, Avg batch loss: 0.0247, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 1030, Step num: 8625, Learning rate: 0.00009517, Avg batch loss: 0.0216, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 1031, Step num: 8626, Learning rate: 0.00009517, Avg batch loss: 0.0242, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 1032, Step num: 8627, Learning rate: 0.00009516, Avg batch loss: 0.0199, Avg batch acc: 0.9772
Train, Epoch: 6, Batch: 1033, Step num: 8628, Learning rate: 0.00009516, Avg batch loss: 0.0276, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 1034, Step num: 8629, Learning rate: 0.00009515, Avg batch loss: 0.0225, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 1035, Step num: 8630, Learning rate: 0.00009515, Avg batch loss: 0.0220, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 1036, Step num: 8631, Learning rate: 0.00009514, Avg batch loss: 0.0232, Avg batch acc: 0.9778
Train, Epoch: 6, Batch: 1037, Step num: 8632, Learning rate: 0.00009513, Avg batch loss: 0.0179, Avg batch acc: 0.9778
Train, Epoch: 6, Batch: 1038, Step num: 8633, Learning rate: 0.00009513, Avg batch loss: 0.0273, Avg batch acc: 0.9677
Train, Epoch: 6, Batch: 1039, Step num: 8634, Learning rate: 0.00009512, Avg batch loss: 0.0197, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 1040, Step num: 8635, Learning rate: 0.00009512, Avg batch loss: 0.0248, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 1041, Step num: 8636, Learning rate: 0.00009511, Avg batch loss: 0.0261, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 1042, Step num: 8637, Learning rate: 0.00009511, Avg batch loss: 0.0298, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 1043, Step num: 8638, Learning rate: 0.00009510, Avg batch loss: 0.0240, Avg batch acc: 0.9782
Train, Epoch: 6, Batch: 1044, Step num: 8639, Learning rate: 0.00009510, Avg batch loss: 0.0203, Avg batch acc: 0.9798
Train, Epoch: 6, Batch: 1045, Step num: 8640, Learning rate: 0.00009509, Avg batch loss: 0.0259, Avg batch acc: 0.9731
Train, Epoch: 6, Batch: 1046, Step num: 8641, Learning rate: 0.00009509, Avg batch loss: 0.0184, Avg batch acc: 0.9821
Train, Epoch: 6, Batch: 1047, Step num: 8642, Learning rate: 0.00009508, Avg batch loss: 0.0275, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 1048, Step num: 8643, Learning rate: 0.00009507, Avg batch loss: 0.0217, Avg batch acc: 0.9812
Train, Epoch: 6, Batch: 1049, Step num: 8644, Learning rate: 0.00009507, Avg batch loss: 0.0247, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 1050, Step num: 8645, Learning rate: 0.00009506, Avg batch loss: 0.0171, Avg batch acc: 0.9830
Train, Epoch: 6, Batch: 1051, Step num: 8646, Learning rate: 0.00009506, Avg batch loss: 0.0202, Avg batch acc: 0.9804
Train, Epoch: 6, Batch: 1052, Step num: 8647, Learning rate: 0.00009505, Avg batch loss: 0.0270, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1053, Step num: 8648, Learning rate: 0.00009505, Avg batch loss: 0.0253, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 1054, Step num: 8649, Learning rate: 0.00009504, Avg batch loss: 0.0238, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 1055, Step num: 8650, Learning rate: 0.00009504, Avg batch loss: 0.0262, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 1056, Step num: 8651, Learning rate: 0.00009503, Avg batch loss: 0.0215, Avg batch acc: 0.9773
Train, Epoch: 6, Batch: 1057, Step num: 8652, Learning rate: 0.00009502, Avg batch loss: 0.0290, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 1058, Step num: 8653, Learning rate: 0.00009502, Avg batch loss: 0.0197, Avg batch acc: 0.9811
Train, Epoch: 6, Batch: 1059, Step num: 8654, Learning rate: 0.00009501, Avg batch loss: 0.0211, Avg batch acc: 0.9789
Train, Epoch: 6, Batch: 1060, Step num: 8655, Learning rate: 0.00009501, Avg batch loss: 0.0161, Avg batch acc: 0.9816
Train, Epoch: 6, Batch: 1061, Step num: 8656, Learning rate: 0.00009500, Avg batch loss: 0.0239, Avg batch acc: 0.9695
Train, Epoch: 6, Batch: 1062, Step num: 8657, Learning rate: 0.00009500, Avg batch loss: 0.0270, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 1063, Step num: 8658, Learning rate: 0.00009499, Avg batch loss: 0.0243, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 1064, Step num: 8659, Learning rate: 0.00009499, Avg batch loss: 0.0269, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 1065, Step num: 8660, Learning rate: 0.00009498, Avg batch loss: 0.0248, Avg batch acc: 0.9750
Train, Epoch: 6, Batch: 1066, Step num: 8661, Learning rate: 0.00009498, Avg batch loss: 0.0284, Avg batch acc: 0.9674
Train, Epoch: 6, Batch: 1067, Step num: 8662, Learning rate: 0.00009497, Avg batch loss: 0.0231, Avg batch acc: 0.9782
Train, Epoch: 6, Batch: 1068, Step num: 8663, Learning rate: 0.00009496, Avg batch loss: 0.0225, Avg batch acc: 0.9752
Train, Epoch: 6, Batch: 1069, Step num: 8664, Learning rate: 0.00009496, Avg batch loss: 0.0220, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 1070, Step num: 8665, Learning rate: 0.00009495, Avg batch loss: 0.0225, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 1071, Step num: 8666, Learning rate: 0.00009495, Avg batch loss: 0.0246, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1072, Step num: 8667, Learning rate: 0.00009494, Avg batch loss: 0.0245, Avg batch acc: 0.9788
Train, Epoch: 6, Batch: 1073, Step num: 8668, Learning rate: 0.00009494, Avg batch loss: 0.0346, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 1074, Step num: 8669, Learning rate: 0.00009493, Avg batch loss: 0.0200, Avg batch acc: 0.9774
Train, Epoch: 6, Batch: 1075, Step num: 8670, Learning rate: 0.00009493, Avg batch loss: 0.0218, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 1076, Step num: 8671, Learning rate: 0.00009492, Avg batch loss: 0.0229, Avg batch acc: 0.9785
Train, Epoch: 6, Batch: 1077, Step num: 8672, Learning rate: 0.00009492, Avg batch loss: 0.0268, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 1078, Step num: 8673, Learning rate: 0.00009491, Avg batch loss: 0.0286, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 1079, Step num: 8674, Learning rate: 0.00009490, Avg batch loss: 0.0187, Avg batch acc: 0.9810
Train, Epoch: 6, Batch: 1080, Step num: 8675, Learning rate: 0.00009490, Avg batch loss: 0.0231, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 1081, Step num: 8676, Learning rate: 0.00009489, Avg batch loss: 0.0246, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 1082, Step num: 8677, Learning rate: 0.00009489, Avg batch loss: 0.0203, Avg batch acc: 0.9785
Train, Epoch: 6, Batch: 1083, Step num: 8678, Learning rate: 0.00009488, Avg batch loss: 0.0285, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 1084, Step num: 8679, Learning rate: 0.00009488, Avg batch loss: 0.0236, Avg batch acc: 0.9782
Train, Epoch: 6, Batch: 1085, Step num: 8680, Learning rate: 0.00009487, Avg batch loss: 0.0189, Avg batch acc: 0.9798
Train, Epoch: 6, Batch: 1086, Step num: 8681, Learning rate: 0.00009487, Avg batch loss: 0.0461, Avg batch acc: 0.9686
Train, Epoch: 6, Batch: 1087, Step num: 8682, Learning rate: 0.00009486, Avg batch loss: 0.0277, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1088, Step num: 8683, Learning rate: 0.00009485, Avg batch loss: 0.0259, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 1089, Step num: 8684, Learning rate: 0.00009485, Avg batch loss: 0.0274, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 1090, Step num: 8685, Learning rate: 0.00009484, Avg batch loss: 0.0218, Avg batch acc: 0.9777
Train, Epoch: 6, Batch: 1091, Step num: 8686, Learning rate: 0.00009484, Avg batch loss: 0.0233, Avg batch acc: 0.9818
Train, Epoch: 6, Batch: 1092, Step num: 8687, Learning rate: 0.00009483, Avg batch loss: 0.0302, Avg batch acc: 0.9669
Train, Epoch: 6, Batch: 1093, Step num: 8688, Learning rate: 0.00009483, Avg batch loss: 0.0226, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1094, Step num: 8689, Learning rate: 0.00009482, Avg batch loss: 0.0227, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 1095, Step num: 8690, Learning rate: 0.00009482, Avg batch loss: 0.0270, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 1096, Step num: 8691, Learning rate: 0.00009481, Avg batch loss: 0.0264, Avg batch acc: 0.9776
Train, Epoch: 6, Batch: 1097, Step num: 8692, Learning rate: 0.00009481, Avg batch loss: 0.0312, Avg batch acc: 0.9659
Train, Epoch: 6, Batch: 1098, Step num: 8693, Learning rate: 0.00009480, Avg batch loss: 0.0253, Avg batch acc: 0.9714
Train, Epoch: 6, Batch: 1099, Step num: 8694, Learning rate: 0.00009479, Avg batch loss: 0.0337, Avg batch acc: 0.9643
Train, Epoch: 6, Batch: 1100, Step num: 8695, Learning rate: 0.00009479, Avg batch loss: 0.0234, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 1101, Step num: 8696, Learning rate: 0.00009478, Avg batch loss: 0.0235, Avg batch acc: 0.9786
Train, Epoch: 6, Batch: 1102, Step num: 8697, Learning rate: 0.00009478, Avg batch loss: 0.0254, Avg batch acc: 0.9704
Train, Epoch: 6, Batch: 1103, Step num: 8698, Learning rate: 0.00009477, Avg batch loss: 0.0254, Avg batch acc: 0.9772
Train, Epoch: 6, Batch: 1104, Step num: 8699, Learning rate: 0.00009477, Avg batch loss: 0.0211, Avg batch acc: 0.9779
Train, Epoch: 6, Batch: 1105, Step num: 8700, Learning rate: 0.00009476, Avg batch loss: 0.0180, Avg batch acc: 0.9834
Train, Epoch: 6, Batch: 1106, Step num: 8701, Learning rate: 0.00009476, Avg batch loss: 0.0237, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 1107, Step num: 8702, Learning rate: 0.00009475, Avg batch loss: 0.0263, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 1108, Step num: 8703, Learning rate: 0.00009475, Avg batch loss: 0.0284, Avg batch acc: 0.9710
Train, Epoch: 6, Batch: 1109, Step num: 8704, Learning rate: 0.00009474, Avg batch loss: 0.0271, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 1110, Step num: 8705, Learning rate: 0.00009474, Avg batch loss: 0.0238, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 1111, Step num: 8706, Learning rate: 0.00009473, Avg batch loss: 0.0331, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 1112, Step num: 8707, Learning rate: 0.00009472, Avg batch loss: 0.0214, Avg batch acc: 0.9778
Train, Epoch: 6, Batch: 1113, Step num: 8708, Learning rate: 0.00009472, Avg batch loss: 0.0226, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 1114, Step num: 8709, Learning rate: 0.00009471, Avg batch loss: 0.0248, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1115, Step num: 8710, Learning rate: 0.00009471, Avg batch loss: 0.0254, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 1116, Step num: 8711, Learning rate: 0.00009470, Avg batch loss: 0.0208, Avg batch acc: 0.9778
Train, Epoch: 6, Batch: 1117, Step num: 8712, Learning rate: 0.00009470, Avg batch loss: 0.0250, Avg batch acc: 0.9702
Train, Epoch: 6, Batch: 1118, Step num: 8713, Learning rate: 0.00009469, Avg batch loss: 0.0232, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1119, Step num: 8714, Learning rate: 0.00009469, Avg batch loss: 0.0244, Avg batch acc: 0.9772
Train, Epoch: 6, Batch: 1120, Step num: 8715, Learning rate: 0.00009468, Avg batch loss: 0.0237, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 1121, Step num: 8716, Learning rate: 0.00009468, Avg batch loss: 0.0311, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 1122, Step num: 8717, Learning rate: 0.00009467, Avg batch loss: 0.0242, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 1123, Step num: 8718, Learning rate: 0.00009466, Avg batch loss: 0.0232, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 1124, Step num: 8719, Learning rate: 0.00009466, Avg batch loss: 0.0350, Avg batch acc: 0.9642
Train, Epoch: 6, Batch: 1125, Step num: 8720, Learning rate: 0.00009465, Avg batch loss: 0.0271, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 1126, Step num: 8721, Learning rate: 0.00009465, Avg batch loss: 0.0244, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 1127, Step num: 8722, Learning rate: 0.00009464, Avg batch loss: 0.0228, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 1128, Step num: 8723, Learning rate: 0.00009464, Avg batch loss: 0.0215, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 1129, Step num: 8724, Learning rate: 0.00009463, Avg batch loss: 0.0256, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 1130, Step num: 8725, Learning rate: 0.00009463, Avg batch loss: 0.0193, Avg batch acc: 0.9772
Train, Epoch: 6, Batch: 1131, Step num: 8726, Learning rate: 0.00009462, Avg batch loss: 0.0239, Avg batch acc: 0.9795
Train, Epoch: 6, Batch: 1132, Step num: 8727, Learning rate: 0.00009462, Avg batch loss: 0.0248, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 1133, Step num: 8728, Learning rate: 0.00009461, Avg batch loss: 0.0240, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 1134, Step num: 8729, Learning rate: 0.00009460, Avg batch loss: 0.0236, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 1135, Step num: 8730, Learning rate: 0.00009460, Avg batch loss: 0.0240, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 1136, Step num: 8731, Learning rate: 0.00009459, Avg batch loss: 0.0263, Avg batch acc: 0.9697
Train, Epoch: 6, Batch: 1137, Step num: 8732, Learning rate: 0.00009459, Avg batch loss: 0.0256, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 1138, Step num: 8733, Learning rate: 0.00009458, Avg batch loss: 0.0252, Avg batch acc: 0.9712
Train, Epoch: 6, Batch: 1139, Step num: 8734, Learning rate: 0.00009458, Avg batch loss: 0.0223, Avg batch acc: 0.9785
Train, Epoch: 6, Batch: 1140, Step num: 8735, Learning rate: 0.00009457, Avg batch loss: 0.0291, Avg batch acc: 0.9702
Train, Epoch: 6, Batch: 1141, Step num: 8736, Learning rate: 0.00009457, Avg batch loss: 0.0193, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 1142, Step num: 8737, Learning rate: 0.00009456, Avg batch loss: 0.0218, Avg batch acc: 0.9817
Train, Epoch: 6, Batch: 1143, Step num: 8738, Learning rate: 0.00009456, Avg batch loss: 0.0230, Avg batch acc: 0.9747
Train, Epoch: 6, Batch: 1144, Step num: 8739, Learning rate: 0.00009455, Avg batch loss: 0.0195, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 1145, Step num: 8740, Learning rate: 0.00009455, Avg batch loss: 0.0196, Avg batch acc: 0.9812
Train, Epoch: 6, Batch: 1146, Step num: 8741, Learning rate: 0.00009454, Avg batch loss: 0.0249, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 1147, Step num: 8742, Learning rate: 0.00009453, Avg batch loss: 0.0281, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 1148, Step num: 8743, Learning rate: 0.00009453, Avg batch loss: 0.0253, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 1149, Step num: 8744, Learning rate: 0.00009452, Avg batch loss: 0.0261, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 1150, Step num: 8745, Learning rate: 0.00009452, Avg batch loss: 0.0271, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1151, Step num: 8746, Learning rate: 0.00009451, Avg batch loss: 0.0255, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 1152, Step num: 8747, Learning rate: 0.00009451, Avg batch loss: 0.0256, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 1153, Step num: 8748, Learning rate: 0.00009450, Avg batch loss: 0.0213, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 1154, Step num: 8749, Learning rate: 0.00009450, Avg batch loss: 0.0356, Avg batch acc: 0.9695
Train, Epoch: 6, Batch: 1155, Step num: 8750, Learning rate: 0.00009449, Avg batch loss: 0.0257, Avg batch acc: 0.9700
Train, Epoch: 6, Batch: 1156, Step num: 8751, Learning rate: 0.00009449, Avg batch loss: 0.0265, Avg batch acc: 0.9731
Train, Epoch: 6, Batch: 1157, Step num: 8752, Learning rate: 0.00009448, Avg batch loss: 0.0225, Avg batch acc: 0.9750
Train, Epoch: 6, Batch: 1158, Step num: 8753, Learning rate: 0.00009447, Avg batch loss: 0.0247, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 1159, Step num: 8754, Learning rate: 0.00009447, Avg batch loss: 0.0191, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 1160, Step num: 8755, Learning rate: 0.00009446, Avg batch loss: 0.0214, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 1161, Step num: 8756, Learning rate: 0.00009446, Avg batch loss: 0.0219, Avg batch acc: 0.9763
Train, Epoch: 6, Batch: 1162, Step num: 8757, Learning rate: 0.00009445, Avg batch loss: 0.0259, Avg batch acc: 0.9709
Train, Epoch: 6, Batch: 1163, Step num: 8758, Learning rate: 0.00009445, Avg batch loss: 0.0267, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 1164, Step num: 8759, Learning rate: 0.00009444, Avg batch loss: 0.0404, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 1165, Step num: 8760, Learning rate: 0.00009444, Avg batch loss: 0.0385, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 1166, Step num: 8761, Learning rate: 0.00009443, Avg batch loss: 0.0242, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 1167, Step num: 8762, Learning rate: 0.00009443, Avg batch loss: 0.0207, Avg batch acc: 0.9827
Train, Epoch: 6, Batch: 1168, Step num: 8763, Learning rate: 0.00009442, Avg batch loss: 0.0349, Avg batch acc: 0.9747
Train, Epoch: 6, Batch: 1169, Step num: 8764, Learning rate: 0.00009442, Avg batch loss: 0.0238, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1170, Step num: 8765, Learning rate: 0.00009441, Avg batch loss: 0.0264, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 1171, Step num: 8766, Learning rate: 0.00009440, Avg batch loss: 0.0193, Avg batch acc: 0.9809
Train, Epoch: 6, Batch: 1172, Step num: 8767, Learning rate: 0.00009440, Avg batch loss: 0.0236, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 1173, Step num: 8768, Learning rate: 0.00009439, Avg batch loss: 0.0211, Avg batch acc: 0.9781
Train, Epoch: 6, Batch: 1174, Step num: 8769, Learning rate: 0.00009439, Avg batch loss: 0.0227, Avg batch acc: 0.9789
Train, Epoch: 6, Batch: 1175, Step num: 8770, Learning rate: 0.00009438, Avg batch loss: 0.0234, Avg batch acc: 0.9785
Train, Epoch: 6, Batch: 1176, Step num: 8771, Learning rate: 0.00009438, Avg batch loss: 0.0234, Avg batch acc: 0.9793
Train, Epoch: 6, Batch: 1177, Step num: 8772, Learning rate: 0.00009437, Avg batch loss: 0.0322, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 1178, Step num: 8773, Learning rate: 0.00009437, Avg batch loss: 0.0288, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 1179, Step num: 8774, Learning rate: 0.00009436, Avg batch loss: 0.0231, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 1180, Step num: 8775, Learning rate: 0.00009436, Avg batch loss: 0.0206, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1181, Step num: 8776, Learning rate: 0.00009435, Avg batch loss: 0.0205, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 1182, Step num: 8777, Learning rate: 0.00009435, Avg batch loss: 0.0229, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 1183, Step num: 8778, Learning rate: 0.00009434, Avg batch loss: 0.0248, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 1184, Step num: 8779, Learning rate: 0.00009433, Avg batch loss: 0.0252, Avg batch acc: 0.9731
Train, Epoch: 6, Batch: 1185, Step num: 8780, Learning rate: 0.00009433, Avg batch loss: 0.0232, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 1186, Step num: 8781, Learning rate: 0.00009432, Avg batch loss: 0.0239, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 1187, Step num: 8782, Learning rate: 0.00009432, Avg batch loss: 0.0244, Avg batch acc: 0.9771
Train, Epoch: 6, Batch: 1188, Step num: 8783, Learning rate: 0.00009431, Avg batch loss: 0.0204, Avg batch acc: 0.9763
Train, Epoch: 6, Batch: 1189, Step num: 8784, Learning rate: 0.00009431, Avg batch loss: 0.0191, Avg batch acc: 0.9811
Train, Epoch: 6, Batch: 1190, Step num: 8785, Learning rate: 0.00009430, Avg batch loss: 0.0355, Avg batch acc: 0.9757
Train, Epoch: 6, Batch: 1191, Step num: 8786, Learning rate: 0.00009430, Avg batch loss: 0.0247, Avg batch acc: 0.9703
Train, Epoch: 6, Batch: 1192, Step num: 8787, Learning rate: 0.00009429, Avg batch loss: 0.0260, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 1193, Step num: 8788, Learning rate: 0.00009429, Avg batch loss: 0.0289, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 1194, Step num: 8789, Learning rate: 0.00009428, Avg batch loss: 0.0213, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 1195, Step num: 8790, Learning rate: 0.00009428, Avg batch loss: 0.0233, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 1196, Step num: 8791, Learning rate: 0.00009427, Avg batch loss: 0.0324, Avg batch acc: 0.9731
Train, Epoch: 6, Batch: 1197, Step num: 8792, Learning rate: 0.00009427, Avg batch loss: 0.0248, Avg batch acc: 0.9698
Train, Epoch: 6, Batch: 1198, Step num: 8793, Learning rate: 0.00009426, Avg batch loss: 0.0249, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 1199, Step num: 8794, Learning rate: 0.00009425, Avg batch loss: 0.0206, Avg batch acc: 0.9795
Train, Epoch: 6, Batch: 1200, Step num: 8795, Learning rate: 0.00009425, Avg batch loss: 0.0227, Avg batch acc: 0.9798
Train, Epoch: 6, Batch: 1201, Step num: 8796, Learning rate: 0.00009424, Avg batch loss: 0.0213, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 1202, Step num: 8797, Learning rate: 0.00009424, Avg batch loss: 0.0302, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 1203, Step num: 8798, Learning rate: 0.00009423, Avg batch loss: 0.0204, Avg batch acc: 0.9784
Train, Epoch: 6, Batch: 1204, Step num: 8799, Learning rate: 0.00009423, Avg batch loss: 0.0208, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 1205, Step num: 8800, Learning rate: 0.00009422, Avg batch loss: 0.0255, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 1206, Step num: 8801, Learning rate: 0.00009422, Avg batch loss: 0.0229, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 1207, Step num: 8802, Learning rate: 0.00009421, Avg batch loss: 0.0221, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 1208, Step num: 8803, Learning rate: 0.00009421, Avg batch loss: 0.0234, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 1209, Step num: 8804, Learning rate: 0.00009420, Avg batch loss: 0.0351, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 1210, Step num: 8805, Learning rate: 0.00009420, Avg batch loss: 0.0213, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 1211, Step num: 8806, Learning rate: 0.00009419, Avg batch loss: 0.0205, Avg batch acc: 0.9777
Train, Epoch: 6, Batch: 1212, Step num: 8807, Learning rate: 0.00009418, Avg batch loss: 0.0178, Avg batch acc: 0.9800
Train, Epoch: 6, Batch: 1213, Step num: 8808, Learning rate: 0.00009418, Avg batch loss: 0.0236, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 1214, Step num: 8809, Learning rate: 0.00009417, Avg batch loss: 0.0241, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 1215, Step num: 8810, Learning rate: 0.00009417, Avg batch loss: 0.0248, Avg batch acc: 0.9782
Train, Epoch: 6, Batch: 1216, Step num: 8811, Learning rate: 0.00009416, Avg batch loss: 0.0234, Avg batch acc: 0.9754
Train, Epoch: 6, Batch: 1217, Step num: 8812, Learning rate: 0.00009416, Avg batch loss: 0.0271, Avg batch acc: 0.9687
Train, Epoch: 6, Batch: 1218, Step num: 8813, Learning rate: 0.00009415, Avg batch loss: 0.0248, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 1219, Step num: 8814, Learning rate: 0.00009415, Avg batch loss: 0.0226, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 1220, Step num: 8815, Learning rate: 0.00009414, Avg batch loss: 0.0196, Avg batch acc: 0.9778
Train, Epoch: 6, Batch: 1221, Step num: 8816, Learning rate: 0.00009414, Avg batch loss: 0.0218, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 1222, Step num: 8817, Learning rate: 0.00009413, Avg batch loss: 0.0218, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 1223, Step num: 8818, Learning rate: 0.00009413, Avg batch loss: 0.0321, Avg batch acc: 0.9636
Train, Epoch: 6, Batch: 1224, Step num: 8819, Learning rate: 0.00009412, Avg batch loss: 0.0459, Avg batch acc: 0.9685
Train, Epoch: 6, Batch: 1225, Step num: 8820, Learning rate: 0.00009412, Avg batch loss: 0.0243, Avg batch acc: 0.9699
Train, Epoch: 6, Batch: 1226, Step num: 8821, Learning rate: 0.00009411, Avg batch loss: 0.0215, Avg batch acc: 0.9795
Train, Epoch: 6, Batch: 1227, Step num: 8822, Learning rate: 0.00009410, Avg batch loss: 0.0216, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 1228, Step num: 8823, Learning rate: 0.00009410, Avg batch loss: 0.0239, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 1229, Step num: 8824, Learning rate: 0.00009409, Avg batch loss: 0.0193, Avg batch acc: 0.9794
Train, Epoch: 6, Batch: 1230, Step num: 8825, Learning rate: 0.00009409, Avg batch loss: 0.0212, Avg batch acc: 0.9754
Train, Epoch: 6, Batch: 1231, Step num: 8826, Learning rate: 0.00009408, Avg batch loss: 0.0191, Avg batch acc: 0.9772
Train, Epoch: 6, Batch: 1232, Step num: 8827, Learning rate: 0.00009408, Avg batch loss: 0.0239, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 1233, Step num: 8828, Learning rate: 0.00009407, Avg batch loss: 0.0218, Avg batch acc: 0.9772
Train, Epoch: 6, Batch: 1234, Step num: 8829, Learning rate: 0.00009407, Avg batch loss: 0.0259, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 1235, Step num: 8830, Learning rate: 0.00009406, Avg batch loss: 0.0247, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 1236, Step num: 8831, Learning rate: 0.00009406, Avg batch loss: 0.0229, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 1237, Step num: 8832, Learning rate: 0.00009405, Avg batch loss: 0.0251, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 1238, Step num: 8833, Learning rate: 0.00009405, Avg batch loss: 0.0202, Avg batch acc: 0.9810
Train, Epoch: 6, Batch: 1239, Step num: 8834, Learning rate: 0.00009404, Avg batch loss: 0.0266, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1240, Step num: 8835, Learning rate: 0.00009404, Avg batch loss: 0.0189, Avg batch acc: 0.9795
Train, Epoch: 6, Batch: 1241, Step num: 8836, Learning rate: 0.00009403, Avg batch loss: 0.0280, Avg batch acc: 0.9750
Train, Epoch: 6, Batch: 1242, Step num: 8837, Learning rate: 0.00009402, Avg batch loss: 0.0227, Avg batch acc: 0.9763
Train, Epoch: 6, Batch: 1243, Step num: 8838, Learning rate: 0.00009402, Avg batch loss: 0.0169, Avg batch acc: 0.9805
Train, Epoch: 6, Batch: 1244, Step num: 8839, Learning rate: 0.00009401, Avg batch loss: 0.0209, Avg batch acc: 0.9751
Train, Epoch: 6, Batch: 1245, Step num: 8840, Learning rate: 0.00009401, Avg batch loss: 0.0186, Avg batch acc: 0.9814
Train, Epoch: 6, Batch: 1246, Step num: 8841, Learning rate: 0.00009400, Avg batch loss: 0.0201, Avg batch acc: 0.9792
Train, Epoch: 6, Batch: 1247, Step num: 8842, Learning rate: 0.00009400, Avg batch loss: 0.0251, Avg batch acc: 0.9766
Train, Epoch: 6, Batch: 1248, Step num: 8843, Learning rate: 0.00009399, Avg batch loss: 0.0248, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 1249, Step num: 8844, Learning rate: 0.00009399, Avg batch loss: 0.0228, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 1250, Step num: 8845, Learning rate: 0.00009398, Avg batch loss: 0.0257, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 1251, Step num: 8846, Learning rate: 0.00009398, Avg batch loss: 0.0307, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 1252, Step num: 8847, Learning rate: 0.00009397, Avg batch loss: 0.0186, Avg batch acc: 0.9799
Train, Epoch: 6, Batch: 1253, Step num: 8848, Learning rate: 0.00009397, Avg batch loss: 0.0222, Avg batch acc: 0.9734
Train, Epoch: 6, Batch: 1254, Step num: 8849, Learning rate: 0.00009396, Avg batch loss: 0.0264, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 1255, Step num: 8850, Learning rate: 0.00009396, Avg batch loss: 0.0249, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 1256, Step num: 8851, Learning rate: 0.00009395, Avg batch loss: 0.0245, Avg batch acc: 0.9724
Train, Epoch: 6, Batch: 1257, Step num: 8852, Learning rate: 0.00009395, Avg batch loss: 0.0262, Avg batch acc: 0.9741
Train, Epoch: 6, Batch: 1258, Step num: 8853, Learning rate: 0.00009394, Avg batch loss: 0.0255, Avg batch acc: 0.9702
Train, Epoch: 6, Batch: 1259, Step num: 8854, Learning rate: 0.00009393, Avg batch loss: 0.0238, Avg batch acc: 0.9781
Train, Epoch: 6, Batch: 1260, Step num: 8855, Learning rate: 0.00009393, Avg batch loss: 0.0281, Avg batch acc: 0.9694
Train, Epoch: 6, Batch: 1261, Step num: 8856, Learning rate: 0.00009392, Avg batch loss: 0.0175, Avg batch acc: 0.9802
Train, Epoch: 6, Batch: 1262, Step num: 8857, Learning rate: 0.00009392, Avg batch loss: 0.0201, Avg batch acc: 0.9791
Train, Epoch: 6, Batch: 1263, Step num: 8858, Learning rate: 0.00009391, Avg batch loss: 0.0186, Avg batch acc: 0.9800
Train, Epoch: 6, Batch: 1264, Step num: 8859, Learning rate: 0.00009391, Avg batch loss: 0.0227, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 1265, Step num: 8860, Learning rate: 0.00009390, Avg batch loss: 0.0244, Avg batch acc: 0.9674
Train, Epoch: 6, Batch: 1266, Step num: 8861, Learning rate: 0.00009390, Avg batch loss: 0.0203, Avg batch acc: 0.9788
Train, Epoch: 6, Batch: 1267, Step num: 8862, Learning rate: 0.00009389, Avg batch loss: 0.0258, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 1268, Step num: 8863, Learning rate: 0.00009389, Avg batch loss: 0.0254, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 1269, Step num: 8864, Learning rate: 0.00009388, Avg batch loss: 0.0241, Avg batch acc: 0.9739
Train, Epoch: 6, Batch: 1270, Step num: 8865, Learning rate: 0.00009388, Avg batch loss: 0.0227, Avg batch acc: 0.9777
Train, Epoch: 6, Batch: 1271, Step num: 8866, Learning rate: 0.00009387, Avg batch loss: 0.0222, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 1272, Step num: 8867, Learning rate: 0.00009387, Avg batch loss: 0.0250, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 1273, Step num: 8868, Learning rate: 0.00009386, Avg batch loss: 0.0257, Avg batch acc: 0.9711
Train, Epoch: 6, Batch: 1274, Step num: 8869, Learning rate: 0.00009386, Avg batch loss: 0.0205, Avg batch acc: 0.9792
Train, Epoch: 6, Batch: 1275, Step num: 8870, Learning rate: 0.00009385, Avg batch loss: 0.0163, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 1276, Step num: 8871, Learning rate: 0.00009384, Avg batch loss: 0.0224, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 1277, Step num: 8872, Learning rate: 0.00009384, Avg batch loss: 0.0207, Avg batch acc: 0.9779
Train, Epoch: 6, Batch: 1278, Step num: 8873, Learning rate: 0.00009383, Avg batch loss: 0.0230, Avg batch acc: 0.9791
Train, Epoch: 6, Batch: 1279, Step num: 8874, Learning rate: 0.00009383, Avg batch loss: 0.0185, Avg batch acc: 0.9775
Train, Epoch: 6, Batch: 1280, Step num: 8875, Learning rate: 0.00009382, Avg batch loss: 0.0248, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 1281, Step num: 8876, Learning rate: 0.00009382, Avg batch loss: 0.0229, Avg batch acc: 0.9771
Train, Epoch: 6, Batch: 1282, Step num: 8877, Learning rate: 0.00009381, Avg batch loss: 0.0267, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1283, Step num: 8878, Learning rate: 0.00009381, Avg batch loss: 0.0309, Avg batch acc: 0.9706
Train, Epoch: 6, Batch: 1284, Step num: 8879, Learning rate: 0.00009380, Avg batch loss: 0.0229, Avg batch acc: 0.9800
Train, Epoch: 6, Batch: 1285, Step num: 8880, Learning rate: 0.00009380, Avg batch loss: 0.0257, Avg batch acc: 0.9794
Train, Epoch: 6, Batch: 1286, Step num: 8881, Learning rate: 0.00009379, Avg batch loss: 0.0279, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 1287, Step num: 8882, Learning rate: 0.00009379, Avg batch loss: 0.0213, Avg batch acc: 0.9806
Train, Epoch: 6, Batch: 1288, Step num: 8883, Learning rate: 0.00009378, Avg batch loss: 0.0244, Avg batch acc: 0.9774
Train, Epoch: 6, Batch: 1289, Step num: 8884, Learning rate: 0.00009378, Avg batch loss: 0.0198, Avg batch acc: 0.9773
Train, Epoch: 6, Batch: 1290, Step num: 8885, Learning rate: 0.00009377, Avg batch loss: 0.0203, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 1291, Step num: 8886, Learning rate: 0.00009377, Avg batch loss: 0.0215, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 1292, Step num: 8887, Learning rate: 0.00009376, Avg batch loss: 0.0233, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 1293, Step num: 8888, Learning rate: 0.00009375, Avg batch loss: 0.0237, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 1294, Step num: 8889, Learning rate: 0.00009375, Avg batch loss: 0.0228, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 1295, Step num: 8890, Learning rate: 0.00009374, Avg batch loss: 0.0231, Avg batch acc: 0.9740
Train, Epoch: 6, Batch: 1296, Step num: 8891, Learning rate: 0.00009374, Avg batch loss: 0.0280, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 1297, Step num: 8892, Learning rate: 0.00009373, Avg batch loss: 0.0207, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 1298, Step num: 8893, Learning rate: 0.00009373, Avg batch loss: 0.0227, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 1299, Step num: 8894, Learning rate: 0.00009372, Avg batch loss: 0.0233, Avg batch acc: 0.9658
Train, Epoch: 6, Batch: 1300, Step num: 8895, Learning rate: 0.00009372, Avg batch loss: 0.0232, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 1301, Step num: 8896, Learning rate: 0.00009371, Avg batch loss: 0.0252, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 1302, Step num: 8897, Learning rate: 0.00009371, Avg batch loss: 0.0258, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 1303, Step num: 8898, Learning rate: 0.00009370, Avg batch loss: 0.0214, Avg batch acc: 0.9781
Train, Epoch: 6, Batch: 1304, Step num: 8899, Learning rate: 0.00009370, Avg batch loss: 0.0184, Avg batch acc: 0.9811
Train, Epoch: 6, Batch: 1305, Step num: 8900, Learning rate: 0.00009369, Avg batch loss: 0.0239, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 1306, Step num: 8901, Learning rate: 0.00009369, Avg batch loss: 0.0227, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 1307, Step num: 8902, Learning rate: 0.00009368, Avg batch loss: 0.0258, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 1308, Step num: 8903, Learning rate: 0.00009368, Avg batch loss: 0.0297, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 1309, Step num: 8904, Learning rate: 0.00009367, Avg batch loss: 0.0205, Avg batch acc: 0.9779
Train, Epoch: 6, Batch: 1310, Step num: 8905, Learning rate: 0.00009367, Avg batch loss: 0.0232, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 1311, Step num: 8906, Learning rate: 0.00009366, Avg batch loss: 0.0194, Avg batch acc: 0.9816
Train, Epoch: 6, Batch: 1312, Step num: 8907, Learning rate: 0.00009365, Avg batch loss: 0.0324, Avg batch acc: 0.9678
Train, Epoch: 6, Batch: 1313, Step num: 8908, Learning rate: 0.00009365, Avg batch loss: 0.0206, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 1314, Step num: 8909, Learning rate: 0.00009364, Avg batch loss: 0.0233, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 1315, Step num: 8910, Learning rate: 0.00009364, Avg batch loss: 0.0190, Avg batch acc: 0.9781
Train, Epoch: 6, Batch: 1316, Step num: 8911, Learning rate: 0.00009363, Avg batch loss: 0.0198, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 1317, Step num: 8912, Learning rate: 0.00009363, Avg batch loss: 0.0209, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 1318, Step num: 8913, Learning rate: 0.00009362, Avg batch loss: 0.0299, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 1319, Step num: 8914, Learning rate: 0.00009362, Avg batch loss: 0.0211, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 1320, Step num: 8915, Learning rate: 0.00009361, Avg batch loss: 0.0187, Avg batch acc: 0.9812
Train, Epoch: 6, Batch: 1321, Step num: 8916, Learning rate: 0.00009361, Avg batch loss: 0.0235, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 1322, Step num: 8917, Learning rate: 0.00009360, Avg batch loss: 0.0249, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 1323, Step num: 8918, Learning rate: 0.00009360, Avg batch loss: 0.0263, Avg batch acc: 0.9702
Train, Epoch: 6, Batch: 1324, Step num: 8919, Learning rate: 0.00009359, Avg batch loss: 0.0179, Avg batch acc: 0.9787
Train, Epoch: 6, Batch: 1325, Step num: 8920, Learning rate: 0.00009359, Avg batch loss: 0.0327, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 1326, Step num: 8921, Learning rate: 0.00009358, Avg batch loss: 0.0219, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 1327, Step num: 8922, Learning rate: 0.00009358, Avg batch loss: 0.0233, Avg batch acc: 0.9755
Train, Epoch: 6, Batch: 1328, Step num: 8923, Learning rate: 0.00009357, Avg batch loss: 0.0218, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 1329, Step num: 8924, Learning rate: 0.00009357, Avg batch loss: 0.0275, Avg batch acc: 0.9714
Train, Epoch: 6, Batch: 1330, Step num: 8925, Learning rate: 0.00009356, Avg batch loss: 0.0260, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 1331, Step num: 8926, Learning rate: 0.00009355, Avg batch loss: 0.0227, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 1332, Step num: 8927, Learning rate: 0.00009355, Avg batch loss: 0.0220, Avg batch acc: 0.9809
Train, Epoch: 6, Batch: 1333, Step num: 8928, Learning rate: 0.00009354, Avg batch loss: 0.0372, Avg batch acc: 0.9665
Train, Epoch: 6, Batch: 1334, Step num: 8929, Learning rate: 0.00009354, Avg batch loss: 0.0186, Avg batch acc: 0.9799
Train, Epoch: 6, Batch: 1335, Step num: 8930, Learning rate: 0.00009353, Avg batch loss: 0.0201, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 1336, Step num: 8931, Learning rate: 0.00009353, Avg batch loss: 0.0255, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 1337, Step num: 8932, Learning rate: 0.00009352, Avg batch loss: 0.0203, Avg batch acc: 0.9797
Train, Epoch: 6, Batch: 1338, Step num: 8933, Learning rate: 0.00009352, Avg batch loss: 0.0206, Avg batch acc: 0.9794
Train, Epoch: 6, Batch: 1339, Step num: 8934, Learning rate: 0.00009351, Avg batch loss: 0.0220, Avg batch acc: 0.9775
Train, Epoch: 6, Batch: 1340, Step num: 8935, Learning rate: 0.00009351, Avg batch loss: 0.0206, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 1341, Step num: 8936, Learning rate: 0.00009350, Avg batch loss: 0.0224, Avg batch acc: 0.9778
Train, Epoch: 6, Batch: 1342, Step num: 8937, Learning rate: 0.00009350, Avg batch loss: 0.0282, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 1343, Step num: 8938, Learning rate: 0.00009349, Avg batch loss: 0.0273, Avg batch acc: 0.9684
Train, Epoch: 6, Batch: 1344, Step num: 8939, Learning rate: 0.00009349, Avg batch loss: 0.0254, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 1345, Step num: 8940, Learning rate: 0.00009348, Avg batch loss: 0.0216, Avg batch acc: 0.9782
Train, Epoch: 6, Batch: 1346, Step num: 8941, Learning rate: 0.00009348, Avg batch loss: 0.0196, Avg batch acc: 0.9777
Train, Epoch: 6, Batch: 1347, Step num: 8942, Learning rate: 0.00009347, Avg batch loss: 0.0219, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 1348, Step num: 8943, Learning rate: 0.00009347, Avg batch loss: 0.0263, Avg batch acc: 0.9713
Train, Epoch: 6, Batch: 1349, Step num: 8944, Learning rate: 0.00009346, Avg batch loss: 0.0215, Avg batch acc: 0.9774
Train, Epoch: 6, Batch: 1350, Step num: 8945, Learning rate: 0.00009346, Avg batch loss: 0.0203, Avg batch acc: 0.9723
Train, Epoch: 6, Batch: 1351, Step num: 8946, Learning rate: 0.00009345, Avg batch loss: 0.0246, Avg batch acc: 0.9763
Train, Epoch: 6, Batch: 1352, Step num: 8947, Learning rate: 0.00009345, Avg batch loss: 0.0251, Avg batch acc: 0.9697
Train, Epoch: 6, Batch: 1353, Step num: 8948, Learning rate: 0.00009344, Avg batch loss: 0.0210, Avg batch acc: 0.9806
Train, Epoch: 6, Batch: 1354, Step num: 8949, Learning rate: 0.00009343, Avg batch loss: 0.0240, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 1355, Step num: 8950, Learning rate: 0.00009343, Avg batch loss: 0.0241, Avg batch acc: 0.9779
Train, Epoch: 6, Batch: 1356, Step num: 8951, Learning rate: 0.00009342, Avg batch loss: 0.0229, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 1357, Step num: 8952, Learning rate: 0.00009342, Avg batch loss: 0.0258, Avg batch acc: 0.9763
Train, Epoch: 6, Batch: 1358, Step num: 8953, Learning rate: 0.00009341, Avg batch loss: 0.0277, Avg batch acc: 0.9701
Train, Epoch: 6, Batch: 1359, Step num: 8954, Learning rate: 0.00009341, Avg batch loss: 0.0180, Avg batch acc: 0.9837
Train, Epoch: 6, Batch: 1360, Step num: 8955, Learning rate: 0.00009340, Avg batch loss: 0.0249, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 1361, Step num: 8956, Learning rate: 0.00009340, Avg batch loss: 0.0252, Avg batch acc: 0.9744
Train, Epoch: 6, Batch: 1362, Step num: 8957, Learning rate: 0.00009339, Avg batch loss: 0.0280, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 1363, Step num: 8958, Learning rate: 0.00009339, Avg batch loss: 0.0198, Avg batch acc: 0.9779
Train, Epoch: 6, Batch: 1364, Step num: 8959, Learning rate: 0.00009338, Avg batch loss: 0.0221, Avg batch acc: 0.9733
Train, Epoch: 6, Batch: 1365, Step num: 8960, Learning rate: 0.00009338, Avg batch loss: 0.0225, Avg batch acc: 0.9726
Train, Epoch: 6, Batch: 1366, Step num: 8961, Learning rate: 0.00009337, Avg batch loss: 0.0232, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 1367, Step num: 8962, Learning rate: 0.00009337, Avg batch loss: 0.0227, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 1368, Step num: 8963, Learning rate: 0.00009336, Avg batch loss: 0.0246, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 1369, Step num: 8964, Learning rate: 0.00009336, Avg batch loss: 0.0211, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 1370, Step num: 8965, Learning rate: 0.00009335, Avg batch loss: 0.0228, Avg batch acc: 0.9708
Train, Epoch: 6, Batch: 1371, Step num: 8966, Learning rate: 0.00009335, Avg batch loss: 0.0301, Avg batch acc: 0.9707
Train, Epoch: 6, Batch: 1372, Step num: 8967, Learning rate: 0.00009334, Avg batch loss: 0.0197, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 1373, Step num: 8968, Learning rate: 0.00009334, Avg batch loss: 0.0232, Avg batch acc: 0.9786
Train, Epoch: 6, Batch: 1374, Step num: 8969, Learning rate: 0.00009333, Avg batch loss: 0.0218, Avg batch acc: 0.9772
Train, Epoch: 6, Batch: 1375, Step num: 8970, Learning rate: 0.00009333, Avg batch loss: 0.0242, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 1376, Step num: 8971, Learning rate: 0.00009332, Avg batch loss: 0.0205, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 1377, Step num: 8972, Learning rate: 0.00009331, Avg batch loss: 0.0318, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 1378, Step num: 8973, Learning rate: 0.00009331, Avg batch loss: 0.0203, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 1379, Step num: 8974, Learning rate: 0.00009330, Avg batch loss: 0.0510, Avg batch acc: 0.9747
Train, Epoch: 6, Batch: 1380, Step num: 8975, Learning rate: 0.00009330, Avg batch loss: 0.0219, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 1381, Step num: 8976, Learning rate: 0.00009329, Avg batch loss: 0.0228, Avg batch acc: 0.9732
Train, Epoch: 6, Batch: 1382, Step num: 8977, Learning rate: 0.00009329, Avg batch loss: 0.0274, Avg batch acc: 0.9669
Train, Epoch: 6, Batch: 1383, Step num: 8978, Learning rate: 0.00009328, Avg batch loss: 0.0196, Avg batch acc: 0.9810
Train, Epoch: 6, Batch: 1384, Step num: 8979, Learning rate: 0.00009328, Avg batch loss: 0.0233, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 1385, Step num: 8980, Learning rate: 0.00009327, Avg batch loss: 0.0228, Avg batch acc: 0.9763
Train, Epoch: 6, Batch: 1386, Step num: 8981, Learning rate: 0.00009327, Avg batch loss: 0.0235, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 1387, Step num: 8982, Learning rate: 0.00009326, Avg batch loss: 0.0220, Avg batch acc: 0.9774
Train, Epoch: 6, Batch: 1388, Step num: 8983, Learning rate: 0.00009326, Avg batch loss: 0.0187, Avg batch acc: 0.9814
Train, Epoch: 6, Batch: 1389, Step num: 8984, Learning rate: 0.00009325, Avg batch loss: 0.0234, Avg batch acc: 0.9737
Train, Epoch: 6, Batch: 1390, Step num: 8985, Learning rate: 0.00009325, Avg batch loss: 0.0208, Avg batch acc: 0.9720
Train, Epoch: 6, Batch: 1391, Step num: 8986, Learning rate: 0.00009324, Avg batch loss: 0.0229, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1392, Step num: 8987, Learning rate: 0.00009324, Avg batch loss: 0.0184, Avg batch acc: 0.9818
Train, Epoch: 6, Batch: 1393, Step num: 8988, Learning rate: 0.00009323, Avg batch loss: 0.0231, Avg batch acc: 0.9743
Train, Epoch: 6, Batch: 1394, Step num: 8989, Learning rate: 0.00009323, Avg batch loss: 0.0198, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1395, Step num: 8990, Learning rate: 0.00009322, Avg batch loss: 0.0184, Avg batch acc: 0.9822
Train, Epoch: 6, Batch: 1396, Step num: 8991, Learning rate: 0.00009322, Avg batch loss: 0.0283, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 1397, Step num: 8992, Learning rate: 0.00009321, Avg batch loss: 0.0234, Avg batch acc: 0.9752
Train, Epoch: 6, Batch: 1398, Step num: 8993, Learning rate: 0.00009321, Avg batch loss: 0.0191, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 1399, Step num: 8994, Learning rate: 0.00009320, Avg batch loss: 0.0235, Avg batch acc: 0.9766
Train, Epoch: 6, Batch: 1400, Step num: 8995, Learning rate: 0.00009320, Avg batch loss: 0.0208, Avg batch acc: 0.9784
Train, Epoch: 6, Batch: 1401, Step num: 8996, Learning rate: 0.00009319, Avg batch loss: 0.0202, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1402, Step num: 8997, Learning rate: 0.00009319, Avg batch loss: 0.0232, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 1403, Step num: 8998, Learning rate: 0.00009318, Avg batch loss: 0.0236, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 1404, Step num: 8999, Learning rate: 0.00009317, Avg batch loss: 0.0214, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1405, Step num: 9000, Learning rate: 0.00009317, Avg batch loss: 0.0273, Avg batch acc: 0.9725
Train, Epoch: 6, Batch: 1406, Step num: 9001, Learning rate: 0.00009316, Avg batch loss: 0.0214, Avg batch acc: 0.9795
Train, Epoch: 6, Batch: 1407, Step num: 9002, Learning rate: 0.00009316, Avg batch loss: 0.0215, Avg batch acc: 0.9793
Train, Epoch: 6, Batch: 1408, Step num: 9003, Learning rate: 0.00009315, Avg batch loss: 0.0231, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 1409, Step num: 9004, Learning rate: 0.00009315, Avg batch loss: 0.0234, Avg batch acc: 0.9783
Train, Epoch: 6, Batch: 1410, Step num: 9005, Learning rate: 0.00009314, Avg batch loss: 0.0237, Avg batch acc: 0.9796
Train, Epoch: 6, Batch: 1411, Step num: 9006, Learning rate: 0.00009314, Avg batch loss: 0.0198, Avg batch acc: 0.9782
Train, Epoch: 6, Batch: 1412, Step num: 9007, Learning rate: 0.00009313, Avg batch loss: 0.0158, Avg batch acc: 0.9833
Train, Epoch: 6, Batch: 1413, Step num: 9008, Learning rate: 0.00009313, Avg batch loss: 0.0249, Avg batch acc: 0.9760
Train, Epoch: 6, Batch: 1414, Step num: 9009, Learning rate: 0.00009312, Avg batch loss: 0.0214, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 1415, Step num: 9010, Learning rate: 0.00009312, Avg batch loss: 0.0158, Avg batch acc: 0.9796
Train, Epoch: 6, Batch: 1416, Step num: 9011, Learning rate: 0.00009311, Avg batch loss: 0.0234, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 1417, Step num: 9012, Learning rate: 0.00009311, Avg batch loss: 0.0221, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1418, Step num: 9013, Learning rate: 0.00009310, Avg batch loss: 0.0280, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 1419, Step num: 9014, Learning rate: 0.00009310, Avg batch loss: 0.0245, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 1420, Step num: 9015, Learning rate: 0.00009309, Avg batch loss: 0.0273, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 1421, Step num: 9016, Learning rate: 0.00009309, Avg batch loss: 0.0238, Avg batch acc: 0.9736
Train, Epoch: 6, Batch: 1422, Step num: 9017, Learning rate: 0.00009308, Avg batch loss: 0.0235, Avg batch acc: 0.9753
Train, Epoch: 6, Batch: 1423, Step num: 9018, Learning rate: 0.00009308, Avg batch loss: 0.0231, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1424, Step num: 9019, Learning rate: 0.00009307, Avg batch loss: 0.0200, Avg batch acc: 0.9813
Train, Epoch: 6, Batch: 1425, Step num: 9020, Learning rate: 0.00009307, Avg batch loss: 0.0185, Avg batch acc: 0.9803
Train, Epoch: 6, Batch: 1426, Step num: 9021, Learning rate: 0.00009306, Avg batch loss: 0.0250, Avg batch acc: 0.9697
Train, Epoch: 6, Batch: 1427, Step num: 9022, Learning rate: 0.00009306, Avg batch loss: 0.0207, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 1428, Step num: 9023, Learning rate: 0.00009305, Avg batch loss: 0.0373, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 1429, Step num: 9024, Learning rate: 0.00009305, Avg batch loss: 0.0265, Avg batch acc: 0.9757
Train, Epoch: 6, Batch: 1430, Step num: 9025, Learning rate: 0.00009304, Avg batch loss: 0.0367, Avg batch acc: 0.9756
Train, Epoch: 6, Batch: 1431, Step num: 9026, Learning rate: 0.00009304, Avg batch loss: 0.0194, Avg batch acc: 0.9788
Train, Epoch: 6, Batch: 1432, Step num: 9027, Learning rate: 0.00009303, Avg batch loss: 0.0263, Avg batch acc: 0.9677
Train, Epoch: 6, Batch: 1433, Step num: 9028, Learning rate: 0.00009302, Avg batch loss: 0.0198, Avg batch acc: 0.9796
Train, Epoch: 6, Batch: 1434, Step num: 9029, Learning rate: 0.00009302, Avg batch loss: 0.0237, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 1435, Step num: 9030, Learning rate: 0.00009301, Avg batch loss: 0.0407, Avg batch acc: 0.9654
Train, Epoch: 6, Batch: 1436, Step num: 9031, Learning rate: 0.00009301, Avg batch loss: 0.0219, Avg batch acc: 0.9774
Train, Epoch: 6, Batch: 1437, Step num: 9032, Learning rate: 0.00009300, Avg batch loss: 0.0227, Avg batch acc: 0.9770
Train, Epoch: 6, Batch: 1438, Step num: 9033, Learning rate: 0.00009300, Avg batch loss: 0.0233, Avg batch acc: 0.9721
Train, Epoch: 6, Batch: 1439, Step num: 9034, Learning rate: 0.00009299, Avg batch loss: 0.0211, Avg batch acc: 0.9794
Train, Epoch: 6, Batch: 1440, Step num: 9035, Learning rate: 0.00009299, Avg batch loss: 0.0221, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 1441, Step num: 9036, Learning rate: 0.00009298, Avg batch loss: 0.0263, Avg batch acc: 0.9710
Train, Epoch: 6, Batch: 1442, Step num: 9037, Learning rate: 0.00009298, Avg batch loss: 0.0265, Avg batch acc: 0.9764
Train, Epoch: 6, Batch: 1443, Step num: 9038, Learning rate: 0.00009297, Avg batch loss: 0.0213, Avg batch acc: 0.9787
Train, Epoch: 6, Batch: 1444, Step num: 9039, Learning rate: 0.00009297, Avg batch loss: 0.0202, Avg batch acc: 0.9802
Train, Epoch: 6, Batch: 1445, Step num: 9040, Learning rate: 0.00009296, Avg batch loss: 0.0199, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 1446, Step num: 9041, Learning rate: 0.00009296, Avg batch loss: 0.0302, Avg batch acc: 0.9758
Train, Epoch: 6, Batch: 1447, Step num: 9042, Learning rate: 0.00009295, Avg batch loss: 0.0279, Avg batch acc: 0.9745
Train, Epoch: 6, Batch: 1448, Step num: 9043, Learning rate: 0.00009295, Avg batch loss: 0.0215, Avg batch acc: 0.9780
Train, Epoch: 6, Batch: 1449, Step num: 9044, Learning rate: 0.00009294, Avg batch loss: 0.0166, Avg batch acc: 0.9801
Train, Epoch: 6, Batch: 1450, Step num: 9045, Learning rate: 0.00009294, Avg batch loss: 0.0256, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 1451, Step num: 9046, Learning rate: 0.00009293, Avg batch loss: 0.0221, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 1452, Step num: 9047, Learning rate: 0.00009293, Avg batch loss: 0.0236, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1453, Step num: 9048, Learning rate: 0.00009292, Avg batch loss: 0.0250, Avg batch acc: 0.9717
Train, Epoch: 6, Batch: 1454, Step num: 9049, Learning rate: 0.00009292, Avg batch loss: 0.0219, Avg batch acc: 0.9752
Train, Epoch: 6, Batch: 1455, Step num: 9050, Learning rate: 0.00009291, Avg batch loss: 0.0181, Avg batch acc: 0.9819
Train, Epoch: 6, Batch: 1456, Step num: 9051, Learning rate: 0.00009291, Avg batch loss: 0.0207, Avg batch acc: 0.9754
Train, Epoch: 6, Batch: 1457, Step num: 9052, Learning rate: 0.00009290, Avg batch loss: 0.0198, Avg batch acc: 0.9841
Train, Epoch: 6, Batch: 1458, Step num: 9053, Learning rate: 0.00009290, Avg batch loss: 0.0232, Avg batch acc: 0.9762
Train, Epoch: 6, Batch: 1459, Step num: 9054, Learning rate: 0.00009289, Avg batch loss: 0.0239, Avg batch acc: 0.9742
Train, Epoch: 6, Batch: 1460, Step num: 9055, Learning rate: 0.00009289, Avg batch loss: 0.0210, Avg batch acc: 0.9790
Train, Epoch: 6, Batch: 1461, Step num: 9056, Learning rate: 0.00009288, Avg batch loss: 0.0176, Avg batch acc: 0.9823
Train, Epoch: 6, Batch: 1462, Step num: 9057, Learning rate: 0.00009288, Avg batch loss: 0.0240, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 1463, Step num: 9058, Learning rate: 0.00009287, Avg batch loss: 0.0251, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 1464, Step num: 9059, Learning rate: 0.00009287, Avg batch loss: 0.0218, Avg batch acc: 0.9797
Train, Epoch: 6, Batch: 1465, Step num: 9060, Learning rate: 0.00009286, Avg batch loss: 0.0243, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 1466, Step num: 9061, Learning rate: 0.00009286, Avg batch loss: 0.0231, Avg batch acc: 0.9786
Train, Epoch: 6, Batch: 1467, Step num: 9062, Learning rate: 0.00009285, Avg batch loss: 0.0193, Avg batch acc: 0.9804
Train, Epoch: 6, Batch: 1468, Step num: 9063, Learning rate: 0.00009285, Avg batch loss: 0.0216, Avg batch acc: 0.9765
Train, Epoch: 6, Batch: 1469, Step num: 9064, Learning rate: 0.00009284, Avg batch loss: 0.0217, Avg batch acc: 0.9804
Train, Epoch: 6, Batch: 1470, Step num: 9065, Learning rate: 0.00009283, Avg batch loss: 0.0191, Avg batch acc: 0.9771
Train, Epoch: 6, Batch: 1471, Step num: 9066, Learning rate: 0.00009283, Avg batch loss: 0.0237, Avg batch acc: 0.9773
Train, Epoch: 6, Batch: 1472, Step num: 9067, Learning rate: 0.00009282, Avg batch loss: 0.0222, Avg batch acc: 0.9757
Train, Epoch: 6, Batch: 1473, Step num: 9068, Learning rate: 0.00009282, Avg batch loss: 0.0246, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 1474, Step num: 9069, Learning rate: 0.00009281, Avg batch loss: 0.0222, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 1475, Step num: 9070, Learning rate: 0.00009281, Avg batch loss: 0.0256, Avg batch acc: 0.9788
Train, Epoch: 6, Batch: 1476, Step num: 9071, Learning rate: 0.00009280, Avg batch loss: 0.0143, Avg batch acc: 0.9860
Train, Epoch: 6, Batch: 1477, Step num: 9072, Learning rate: 0.00009280, Avg batch loss: 0.0241, Avg batch acc: 0.9728
Train, Epoch: 6, Batch: 1478, Step num: 9073, Learning rate: 0.00009279, Avg batch loss: 0.0242, Avg batch acc: 0.9777
Train, Epoch: 6, Batch: 1479, Step num: 9074, Learning rate: 0.00009279, Avg batch loss: 0.0206, Avg batch acc: 0.9735
Train, Epoch: 6, Batch: 1480, Step num: 9075, Learning rate: 0.00009278, Avg batch loss: 0.0235, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 1481, Step num: 9076, Learning rate: 0.00009278, Avg batch loss: 0.0189, Avg batch acc: 0.9767
Train, Epoch: 6, Batch: 1482, Step num: 9077, Learning rate: 0.00009277, Avg batch loss: 0.0209, Avg batch acc: 0.9779
Train, Epoch: 6, Batch: 1483, Step num: 9078, Learning rate: 0.00009277, Avg batch loss: 0.0195, Avg batch acc: 0.9837
Train, Epoch: 6, Batch: 1484, Step num: 9079, Learning rate: 0.00009276, Avg batch loss: 0.0225, Avg batch acc: 0.9786
Train, Epoch: 6, Batch: 1485, Step num: 9080, Learning rate: 0.00009276, Avg batch loss: 0.0215, Avg batch acc: 0.9775
Train, Epoch: 6, Batch: 1486, Step num: 9081, Learning rate: 0.00009275, Avg batch loss: 0.0183, Avg batch acc: 0.9776
Train, Epoch: 6, Batch: 1487, Step num: 9082, Learning rate: 0.00009275, Avg batch loss: 0.0192, Avg batch acc: 0.9768
Train, Epoch: 6, Batch: 1488, Step num: 9083, Learning rate: 0.00009274, Avg batch loss: 0.0240, Avg batch acc: 0.9716
Train, Epoch: 6, Batch: 1489, Step num: 9084, Learning rate: 0.00009274, Avg batch loss: 0.0235, Avg batch acc: 0.9759
Train, Epoch: 6, Batch: 1490, Step num: 9085, Learning rate: 0.00009273, Avg batch loss: 0.0332, Avg batch acc: 0.9722
Train, Epoch: 6, Batch: 1491, Step num: 9086, Learning rate: 0.00009273, Avg batch loss: 0.0269, Avg batch acc: 0.9730
Train, Epoch: 6, Batch: 1492, Step num: 9087, Learning rate: 0.00009272, Avg batch loss: 0.0205, Avg batch acc: 0.9764
Train, Epoch: 6, Batch: 1493, Step num: 9088, Learning rate: 0.00009272, Avg batch loss: 0.0192, Avg batch acc: 0.9790
Train, Epoch: 6, Batch: 1494, Step num: 9089, Learning rate: 0.00009271, Avg batch loss: 0.0262, Avg batch acc: 0.9729
Train, Epoch: 6, Batch: 1495, Step num: 9090, Learning rate: 0.00009271, Avg batch loss: 0.0208, Avg batch acc: 0.9805
Train, Epoch: 6, Batch: 1496, Step num: 9091, Learning rate: 0.00009270, Avg batch loss: 0.0203, Avg batch acc: 0.9766
Train, Epoch: 6, Batch: 1497, Step num: 9092, Learning rate: 0.00009270, Avg batch loss: 0.0235, Avg batch acc: 0.9746
Train, Epoch: 6, Batch: 1498, Step num: 9093, Learning rate: 0.00009269, Avg batch loss: 0.0242, Avg batch acc: 0.9738
Train, Epoch: 6, Batch: 1499, Step num: 9094, Learning rate: 0.00009269, Avg batch loss: 0.0226, Avg batch acc: 0.9748
Train, Epoch: 6, Batch: 1500, Step num: 9095, Learning rate: 0.00009268, Avg batch loss: 0.0185, Avg batch acc: 0.9800
Train, Epoch: 6, Batch: 1501, Step num: 9096, Learning rate: 0.00009268, Avg batch loss: 0.0220, Avg batch acc: 0.9792
Train, Epoch: 6, Batch: 1502, Step num: 9097, Learning rate: 0.00009267, Avg batch loss: 0.0190, Avg batch acc: 0.9764
Train, Epoch: 6, Batch: 1503, Step num: 9098, Learning rate: 0.00009267, Avg batch loss: 0.0194, Avg batch acc: 0.9784
Train, Epoch: 6, Batch: 1504, Step num: 9099, Learning rate: 0.00009266, Avg batch loss: 0.0193, Avg batch acc: 0.9810
Train, Epoch: 6, Batch: 1505, Step num: 9100, Learning rate: 0.00009266, Avg batch loss: 0.0198, Avg batch acc: 0.9826
Train, Epoch: 6, Batch: 1506, Step num: 9101, Learning rate: 0.00009265, Avg batch loss: 0.0197, Avg batch acc: 0.9761
Train, Epoch: 6, Batch: 1507, Step num: 9102, Learning rate: 0.00009265, Avg batch loss: 0.0225, Avg batch acc: 0.9766
Train, Epoch: 6, Batch: 1508, Step num: 9103, Learning rate: 0.00009264, Avg batch loss: 0.0207, Avg batch acc: 0.9775
Train, Epoch: 6, Batch: 1509, Step num: 9104, Learning rate: 0.00009264, Avg batch loss: 0.0169, Avg batch acc: 0.9817
Train, Epoch: 6, Batch: 1510, Step num: 9105, Learning rate: 0.00009263, Avg batch loss: 0.0202, Avg batch acc: 0.9777
Train, Epoch: 6, Batch: 1511, Step num: 9106, Learning rate: 0.00009263, Avg batch loss: 0.0248, Avg batch acc: 0.9715
Train, Epoch: 6, Batch: 1512, Step num: 9107, Learning rate: 0.00009262, Avg batch loss: 0.0196, Avg batch acc: 0.9811
Train, Epoch: 6, Batch: 1513, Step num: 9108, Learning rate: 0.00009262, Avg batch loss: 0.0275, Avg batch acc: 0.9718
Train, Epoch: 6, Batch: 1514, Step num: 9109, Learning rate: 0.00009261, Avg batch loss: 0.0152, Avg batch acc: 0.9859
Train, Epoch: 6, Batch: 1515, Step num: 9110, Learning rate: 0.00009261, Avg batch loss: 0.0220, Avg batch acc: 0.9792
Train, Epoch: 6, Batch: 1516, Step num: 9111, Learning rate: 0.00009260, Avg batch loss: 0.0176, Avg batch acc: 0.9795
Train, Epoch: 6, Batch: 1517, Step num: 9112, Learning rate: 0.00009260, Avg batch loss: 0.0245, Avg batch acc: 0.9749
Train, Epoch: 6, Batch: 1518, Step num: 9113, Learning rate: 0.00009259, Avg batch loss: 0.0213, Avg batch acc: 0.9769
Train, Epoch: 6, Batch: 1519, Step num: 9114, Learning rate: 0.00009258, Avg batch loss: 0.0210, Avg batch acc: 0.9763
Train, Epoch: 6, Avg epoch loss: 0.0273, Avg epoch acc: 0.9723, Overall time: 971.7 s, Speed: 4479.4 tokens/s on cuda:1

Validate, Epoch: 6, Batch: 1, Avg batch loss: 0.0226, Avg batch acc: 0.9777
Validate, Epoch: 6, Batch: 2, Avg batch loss: 0.0232, Avg batch acc: 0.9781
Validate, Epoch: 6, Batch: 3, Avg batch loss: 0.0178, Avg batch acc: 0.9825
Validate, Epoch: 6, Batch: 4, Avg batch loss: 0.0197, Avg batch acc: 0.9809
Validate, Epoch: 6, Batch: 5, Avg batch loss: 0.0349, Avg batch acc: 0.9728
Validate, Epoch: 6, Batch: 6, Avg batch loss: 0.0234, Avg batch acc: 0.9785
Validate, Epoch: 6, Batch: 7, Avg batch loss: 0.0211, Avg batch acc: 0.9778
Validate, Epoch: 6, Batch: 8, Avg batch loss: 0.0175, Avg batch acc: 0.9822
Validate, Epoch: 6, Batch: 9, Avg batch loss: 0.0187, Avg batch acc: 0.9802
Validate, Epoch: 6, Batch: 10, Avg batch loss: 0.0203, Avg batch acc: 0.9794
Validate, Epoch: 6, Batch: 11, Avg batch loss: 0.0256, Avg batch acc: 0.9732
Validate, Epoch: 6, Batch: 12, Avg batch loss: 0.0231, Avg batch acc: 0.9733
Validate, Epoch: 6, Batch: 13, Avg batch loss: 0.0251, Avg batch acc: 0.9783
Validate, Epoch: 6, Batch: 14, Avg batch loss: 0.0214, Avg batch acc: 0.9814
Validate, Epoch: 6, Batch: 15, Avg batch loss: 0.0198, Avg batch acc: 0.9757
Validate, Epoch: 6, Batch: 16, Avg batch loss: 0.0261, Avg batch acc: 0.9746
Validate, Epoch: 6, Batch: 17, Avg batch loss: 0.0213, Avg batch acc: 0.9770
Validate, Epoch: 6, Batch: 18, Avg batch loss: 0.0175, Avg batch acc: 0.9797
Validate, Epoch: 6, Batch: 19, Avg batch loss: 0.0173, Avg batch acc: 0.9763
Validate, Epoch: 6, Batch: 20, Avg batch loss: 0.0199, Avg batch acc: 0.9738
Validate, Epoch: 6, Batch: 21, Avg batch loss: 0.0188, Avg batch acc: 0.9739
Validate, Epoch: 6, Batch: 22, Avg batch loss: 0.0194, Avg batch acc: 0.9795
Validate, Epoch: 6, Batch: 23, Avg batch loss: 0.0128, Avg batch acc: 0.9865
Validate, Epoch: 6, Batch: 24, Avg batch loss: 0.0211, Avg batch acc: 0.9710
Validate, Epoch: 6, Batch: 25, Avg batch loss: 0.0194, Avg batch acc: 0.9798
Validate, Epoch: 6, Batch: 26, Avg batch loss: 0.0151, Avg batch acc: 0.9846
Validate, Epoch: 6, Batch: 27, Avg batch loss: 0.0194, Avg batch acc: 0.9778
Validate, Epoch: 6, Batch: 28, Avg batch loss: 0.0187, Avg batch acc: 0.9814
Validate, Epoch: 6, Batch: 29, Avg batch loss: 0.0204, Avg batch acc: 0.9749
Validate, Epoch: 6, Batch: 30, Avg batch loss: 0.0228, Avg batch acc: 0.9732
Validate, Epoch: 6, Batch: 31, Avg batch loss: 0.0192, Avg batch acc: 0.9777
Validate, Epoch: 6, Batch: 32, Avg batch loss: 0.0190, Avg batch acc: 0.9768
Validate, Epoch: 6, Batch: 33, Avg batch loss: 0.0202, Avg batch acc: 0.9822
Validate, Epoch: 6, Batch: 34, Avg batch loss: 0.0240, Avg batch acc: 0.9731
Validate, Epoch: 6, Batch: 35, Avg batch loss: 0.0356, Avg batch acc: 0.9759
Validate, Epoch: 6, Batch: 36, Avg batch loss: 0.0213, Avg batch acc: 0.9782
Validate, Epoch: 6, Batch: 37, Avg batch loss: 0.0320, Avg batch acc: 0.9665
Validate, Epoch: 6, Batch: 38, Avg batch loss: 0.0180, Avg batch acc: 0.9812
Validate, Epoch: 6, Batch: 39, Avg batch loss: 0.0196, Avg batch acc: 0.9772
Validate, Epoch: 6, Batch: 40, Avg batch loss: 0.0197, Avg batch acc: 0.9782
Validate, Epoch: 6, Batch: 41, Avg batch loss: 0.0196, Avg batch acc: 0.9794
Validate, Epoch: 6, Batch: 42, Avg batch loss: 0.0220, Avg batch acc: 0.9773
Validate, Epoch: 6, Batch: 43, Avg batch loss: 0.0358, Avg batch acc: 0.9747
Validate, Epoch: 6, Batch: 44, Avg batch loss: 0.0228, Avg batch acc: 0.9723
Validate, Epoch: 6, Batch: 45, Avg batch loss: 0.0267, Avg batch acc: 0.9799
Validate, Epoch: 6, Batch: 46, Avg batch loss: 0.0213, Avg batch acc: 0.9789
Validate, Epoch: 6, Batch: 47, Avg batch loss: 0.0189, Avg batch acc: 0.9777
Validate, Epoch: 6, Batch: 48, Avg batch loss: 0.0229, Avg batch acc: 0.9757
Validate, Epoch: 6, Batch: 49, Avg batch loss: 0.0182, Avg batch acc: 0.9770
Validate, Epoch: 6, Batch: 50, Avg batch loss: 0.0204, Avg batch acc: 0.9760
Validate, Epoch: 6, Batch: 51, Avg batch loss: 0.0241, Avg batch acc: 0.9775
Validate, Epoch: 6, Batch: 52, Avg batch loss: 0.0285, Avg batch acc: 0.9770
Validate, Epoch: 6, Batch: 53, Avg batch loss: 0.0220, Avg batch acc: 0.9798
Validate, Epoch: 6, Batch: 54, Avg batch loss: 0.0222, Avg batch acc: 0.9787
Validate, Epoch: 6, Batch: 55, Avg batch loss: 0.0202, Avg batch acc: 0.9757
Validate, Epoch: 6, Batch: 56, Avg batch loss: 0.0179, Avg batch acc: 0.9810
Validate, Epoch: 6, Batch: 57, Avg batch loss: 0.0199, Avg batch acc: 0.9818
Validate, Epoch: 6, Batch: 58, Avg batch loss: 0.0177, Avg batch acc: 0.9807
Validate, Epoch: 6, Batch: 59, Avg batch loss: 0.0224, Avg batch acc: 0.9753
Validate, Epoch: 6, Batch: 60, Avg batch loss: 0.0213, Avg batch acc: 0.9797
Validate, Epoch: 6, Batch: 61, Avg batch loss: 0.0170, Avg batch acc: 0.9802
Validate, Epoch: 6, Batch: 62, Avg batch loss: 0.0240, Avg batch acc: 0.9763
Validate, Epoch: 6, Batch: 63, Avg batch loss: 0.0220, Avg batch acc: 0.9720
Validate, Epoch: 6, Batch: 64, Avg batch loss: 0.0245, Avg batch acc: 0.9741
Validate, Epoch: 6, Batch: 65, Avg batch loss: 0.0249, Avg batch acc: 0.9796
Validate, Epoch: 6, Batch: 66, Avg batch loss: 0.0200, Avg batch acc: 0.9753
Validate, Epoch: 6, Batch: 67, Avg batch loss: 0.0239, Avg batch acc: 0.9758
Validate, Epoch: 6, Batch: 68, Avg batch loss: 0.0213, Avg batch acc: 0.9746
Validate, Epoch: 6, Batch: 69, Avg batch loss: 0.0166, Avg batch acc: 0.9815
Validate, Epoch: 6, Batch: 70, Avg batch loss: 0.0223, Avg batch acc: 0.9785
Validate, Epoch: 6, Batch: 71, Avg batch loss: 0.0210, Avg batch acc: 0.9743
Validate, Epoch: 6, Batch: 72, Avg batch loss: 0.0229, Avg batch acc: 0.9770
Validate, Epoch: 6, Batch: 73, Avg batch loss: 0.0194, Avg batch acc: 0.9787
Validate, Epoch: 6, Batch: 74, Avg batch loss: 0.0191, Avg batch acc: 0.9796
Validate, Epoch: 6, Batch: 75, Avg batch loss: 0.0479, Avg batch acc: 0.9713
Validate, Epoch: 6, Batch: 76, Avg batch loss: 0.0209, Avg batch acc: 0.9762
Validate, Epoch: 6, Batch: 77, Avg batch loss: 0.0242, Avg batch acc: 0.9793
Validate, Epoch: 6, Batch: 78, Avg batch loss: 0.0178, Avg batch acc: 0.9830
Validate, Epoch: 6, Batch: 79, Avg batch loss: 0.0175, Avg batch acc: 0.9821
Validate, Epoch: 6, Batch: 80, Avg batch loss: 0.0203, Avg batch acc: 0.9786
Validate, Epoch: 6, Batch: 81, Avg batch loss: 0.0312, Avg batch acc: 0.9785
Validate, Epoch: 6, Batch: 82, Avg batch loss: 0.0214, Avg batch acc: 0.9770
Validate, Epoch: 6, Batch: 83, Avg batch loss: 0.0184, Avg batch acc: 0.9819
Validate, Epoch: 6, Batch: 84, Avg batch loss: 0.0238, Avg batch acc: 0.9715
Validate, Epoch: 6, Batch: 85, Avg batch loss: 0.0248, Avg batch acc: 0.9752
Validate, Epoch: 6, Batch: 86, Avg batch loss: 0.0188, Avg batch acc: 0.9798
Validate, Epoch: 6, Batch: 87, Avg batch loss: 0.0233, Avg batch acc: 0.9742
Validate, Epoch: 6, Batch: 88, Avg batch loss: 0.0186, Avg batch acc: 0.9775
Validate, Epoch: 6, Batch: 89, Avg batch loss: 0.0209, Avg batch acc: 0.9773
Validate, Epoch: 6, Batch: 90, Avg batch loss: 0.0221, Avg batch acc: 0.9786
Validate, Epoch: 6, Batch: 91, Avg batch loss: 0.0276, Avg batch acc: 0.9789
Validate, Epoch: 6, Batch: 92, Avg batch loss: 0.0227, Avg batch acc: 0.9786
Validate, Epoch: 6, Batch: 93, Avg batch loss: 0.0217, Avg batch acc: 0.9782
Validate, Epoch: 6, Batch: 94, Avg batch loss: 0.0243, Avg batch acc: 0.9751
Validate, Epoch: 6, Batch: 95, Avg batch loss: 0.0196, Avg batch acc: 0.9776
Validate, Epoch: 6, Batch: 96, Avg batch loss: 0.0156, Avg batch acc: 0.9788
Validate, Epoch: 6, Batch: 97, Avg batch loss: 0.0198, Avg batch acc: 0.9846
Validate, Epoch: 6, Batch: 98, Avg batch loss: 0.0217, Avg batch acc: 0.9775
Validate, Epoch: 6, Batch: 99, Avg batch loss: 0.0170, Avg batch acc: 0.9826
Validate, Epoch: 6, Batch: 100, Avg batch loss: 0.0187, Avg batch acc: 0.9785
Validate, Epoch: 6, Batch: 101, Avg batch loss: 0.0227, Avg batch acc: 0.9734
Validate, Epoch: 6, Batch: 102, Avg batch loss: 0.0206, Avg batch acc: 0.9754
Validate, Epoch: 6, Batch: 103, Avg batch loss: 0.0217, Avg batch acc: 0.9767
Validate, Epoch: 6, Batch: 104, Avg batch loss: 0.0212, Avg batch acc: 0.9780
Validate, Epoch: 6, Batch: 105, Avg batch loss: 0.0187, Avg batch acc: 0.9780
Validate, Epoch: 6, Batch: 106, Avg batch loss: 0.0220, Avg batch acc: 0.9750
Validate, Epoch: 6, Batch: 107, Avg batch loss: 0.0203, Avg batch acc: 0.9824
Validate, Epoch: 6, Batch: 108, Avg batch loss: 0.0231, Avg batch acc: 0.9799
Validate, Epoch: 6, Batch: 109, Avg batch loss: 0.0195, Avg batch acc: 0.9800
Validate, Epoch: 6, Batch: 110, Avg batch loss: 0.0241, Avg batch acc: 0.9768
Validate, Epoch: 6, Batch: 111, Avg batch loss: 0.0216, Avg batch acc: 0.9780
Validate, Epoch: 6, Batch: 112, Avg batch loss: 0.0194, Avg batch acc: 0.9795
Validate, Epoch: 6, Batch: 113, Avg batch loss: 0.0224, Avg batch acc: 0.9736
Validate, Epoch: 6, Batch: 114, Avg batch loss: 0.0203, Avg batch acc: 0.9762
Validate, Epoch: 6, Batch: 115, Avg batch loss: 0.0251, Avg batch acc: 0.9782
Validate, Epoch: 6, Batch: 116, Avg batch loss: 0.0185, Avg batch acc: 0.9810
Validate, Epoch: 6, Batch: 117, Avg batch loss: 0.0192, Avg batch acc: 0.9777
Validate, Epoch: 6, Batch: 118, Avg batch loss: 0.0200, Avg batch acc: 0.9803
Validate, Epoch: 6, Batch: 119, Avg batch loss: 0.0193, Avg batch acc: 0.9788
Validate, Epoch: 6, Batch: 120, Avg batch loss: 0.0177, Avg batch acc: 0.9838
Validate, Epoch: 6, Batch: 121, Avg batch loss: 0.0262, Avg batch acc: 0.9725
Validate, Epoch: 6, Batch: 122, Avg batch loss: 0.0167, Avg batch acc: 0.9809
Validate, Epoch: 6, Batch: 123, Avg batch loss: 0.0248, Avg batch acc: 0.9755
Validate, Epoch: 6, Batch: 124, Avg batch loss: 0.0181, Avg batch acc: 0.9779
Validate, Epoch: 6, Batch: 125, Avg batch loss: 0.0204, Avg batch acc: 0.9753
Validate, Epoch: 6, Batch: 126, Avg batch loss: 0.0193, Avg batch acc: 0.9790
Validate, Epoch: 6, Batch: 127, Avg batch loss: 0.0246, Avg batch acc: 0.9707
Validate, Epoch: 6, Batch: 128, Avg batch loss: 0.0209, Avg batch acc: 0.9800
Validate, Epoch: 6, Batch: 129, Avg batch loss: 0.0225, Avg batch acc: 0.9752
Validate, Epoch: 6, Batch: 130, Avg batch loss: 0.0210, Avg batch acc: 0.9801
Validate, Epoch: 6, Batch: 131, Avg batch loss: 0.0201, Avg batch acc: 0.9801
Validate, Epoch: 6, Batch: 132, Avg batch loss: 0.0223, Avg batch acc: 0.9767
Validate, Epoch: 6, Batch: 133, Avg batch loss: 0.0210, Avg batch acc: 0.9750
Validate, Epoch: 6, Batch: 134, Avg batch loss: 0.0357, Avg batch acc: 0.9705
Validate, Epoch: 6, Batch: 135, Avg batch loss: 0.0357, Avg batch acc: 0.9715
Validate, Epoch: 6, Batch: 136, Avg batch loss: 0.0213, Avg batch acc: 0.9774
Validate, Epoch: 6, Batch: 137, Avg batch loss: 0.0199, Avg batch acc: 0.9766
Validate, Epoch: 6, Batch: 138, Avg batch loss: 0.0166, Avg batch acc: 0.9839
Validate, Epoch: 6, Batch: 139, Avg batch loss: 0.0202, Avg batch acc: 0.9747
Validate, Epoch: 6, Batch: 140, Avg batch loss: 0.0225, Avg batch acc: 0.9758
Validate, Epoch: 6, Batch: 141, Avg batch loss: 0.0209, Avg batch acc: 0.9759
Validate, Epoch: 6, Batch: 142, Avg batch loss: 0.0194, Avg batch acc: 0.9811
Validate, Epoch: 6, Batch: 143, Avg batch loss: 0.0315, Avg batch acc: 0.9760
Validate, Epoch: 6, Batch: 144, Avg batch loss: 0.0256, Avg batch acc: 0.9698
Validate, Epoch: 6, Batch: 145, Avg batch loss: 0.0203, Avg batch acc: 0.9818
Validate, Epoch: 6, Batch: 146, Avg batch loss: 0.0209, Avg batch acc: 0.9779
Validate, Epoch: 6, Batch: 147, Avg batch loss: 0.0210, Avg batch acc: 0.9805
Validate, Epoch: 6, Batch: 148, Avg batch loss: 0.0250, Avg batch acc: 0.9714
Validate, Epoch: 6, Batch: 149, Avg batch loss: 0.0221, Avg batch acc: 0.9760
Validate, Epoch: 6, Batch: 150, Avg batch loss: 0.0227, Avg batch acc: 0.9761
Validate, Epoch: 6, Batch: 151, Avg batch loss: 0.0210, Avg batch acc: 0.9748
Validate, Epoch: 6, Batch: 152, Avg batch loss: 0.0201, Avg batch acc: 0.9780
Validate, Epoch: 6, Batch: 153, Avg batch loss: 0.0177, Avg batch acc: 0.9800
Validate, Epoch: 6, Batch: 154, Avg batch loss: 0.0186, Avg batch acc: 0.9815
Validate, Epoch: 6, Batch: 155, Avg batch loss: 0.0203, Avg batch acc: 0.9792
Validate, Epoch: 6, Batch: 156, Avg batch loss: 0.0221, Avg batch acc: 0.9755
Validate, Epoch: 6, Batch: 157, Avg batch loss: 0.0213, Avg batch acc: 0.9742
Validate, Epoch: 6, Batch: 158, Avg batch loss: 0.0243, Avg batch acc: 0.9732
Validate, Epoch: 6, Batch: 159, Avg batch loss: 0.0230, Avg batch acc: 0.9750
Validate, Epoch: 6, Batch: 160, Avg batch loss: 0.0199, Avg batch acc: 0.9791
Validate, Epoch: 6, Batch: 161, Avg batch loss: 0.0199, Avg batch acc: 0.9806
Validate, Epoch: 6, Batch: 162, Avg batch loss: 0.0189, Avg batch acc: 0.9833
Validate, Epoch: 6, Batch: 163, Avg batch loss: 0.0304, Avg batch acc: 0.9741
Validate, Epoch: 6, Batch: 164, Avg batch loss: 0.0227, Avg batch acc: 0.9751
Validate, Epoch: 6, Batch: 165, Avg batch loss: 0.0196, Avg batch acc: 0.9774
Validate, Epoch: 6, Batch: 166, Avg batch loss: 0.0245, Avg batch acc: 0.9713
Validate, Epoch: 6, Batch: 167, Avg batch loss: 0.0216, Avg batch acc: 0.9723
Validate, Epoch: 6, Batch: 168, Avg batch loss: 0.0185, Avg batch acc: 0.9755
Validate, Epoch: 6, Batch: 169, Avg batch loss: 0.0174, Avg batch acc: 0.9842
Validate, Epoch: 6, Avg epoch loss: 0.0218, Avg epoch acc: 0.9775, Overall time: 37.6 s, Speed: 12822.7 tokens/s on cuda:1

Train, Epoch: 7, Batch: 1, Step num: 9115, Learning rate: 0.00009258, Avg batch loss: 0.0220, Avg batch acc: 0.9758
Train, Epoch: 7, Batch: 2, Step num: 9116, Learning rate: 0.00009257, Avg batch loss: 0.0211, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 3, Step num: 9117, Learning rate: 0.00009257, Avg batch loss: 0.0219, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 4, Step num: 9118, Learning rate: 0.00009256, Avg batch loss: 0.0183, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 5, Step num: 9119, Learning rate: 0.00009256, Avg batch loss: 0.0206, Avg batch acc: 0.9772
Train, Epoch: 7, Batch: 6, Step num: 9120, Learning rate: 0.00009255, Avg batch loss: 0.0206, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 7, Step num: 9121, Learning rate: 0.00009255, Avg batch loss: 0.0203, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 8, Step num: 9122, Learning rate: 0.00009254, Avg batch loss: 0.0190, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 9, Step num: 9123, Learning rate: 0.00009254, Avg batch loss: 0.0193, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 10, Step num: 9124, Learning rate: 0.00009253, Avg batch loss: 0.0206, Avg batch acc: 0.9757
Train, Epoch: 7, Batch: 11, Step num: 9125, Learning rate: 0.00009253, Avg batch loss: 0.0233, Avg batch acc: 0.9761
Train, Epoch: 7, Batch: 12, Step num: 9126, Learning rate: 0.00009252, Avg batch loss: 0.0231, Avg batch acc: 0.9727
Train, Epoch: 7, Batch: 13, Step num: 9127, Learning rate: 0.00009252, Avg batch loss: 0.0258, Avg batch acc: 0.9751
Train, Epoch: 7, Batch: 14, Step num: 9128, Learning rate: 0.00009251, Avg batch loss: 0.0200, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 15, Step num: 9129, Learning rate: 0.00009251, Avg batch loss: 0.0147, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 16, Step num: 9130, Learning rate: 0.00009250, Avg batch loss: 0.0183, Avg batch acc: 0.9769
Train, Epoch: 7, Batch: 17, Step num: 9131, Learning rate: 0.00009250, Avg batch loss: 0.0208, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 18, Step num: 9132, Learning rate: 0.00009249, Avg batch loss: 0.0252, Avg batch acc: 0.9772
Train, Epoch: 7, Batch: 19, Step num: 9133, Learning rate: 0.00009249, Avg batch loss: 0.0262, Avg batch acc: 0.9769
Train, Epoch: 7, Batch: 20, Step num: 9134, Learning rate: 0.00009248, Avg batch loss: 0.0209, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 21, Step num: 9135, Learning rate: 0.00009248, Avg batch loss: 0.0200, Avg batch acc: 0.9801
Train, Epoch: 7, Batch: 22, Step num: 9136, Learning rate: 0.00009247, Avg batch loss: 0.0223, Avg batch acc: 0.9745
Train, Epoch: 7, Batch: 23, Step num: 9137, Learning rate: 0.00009247, Avg batch loss: 0.0142, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 24, Step num: 9138, Learning rate: 0.00009246, Avg batch loss: 0.0216, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 25, Step num: 9139, Learning rate: 0.00009246, Avg batch loss: 0.0229, Avg batch acc: 0.9778
Train, Epoch: 7, Batch: 26, Step num: 9140, Learning rate: 0.00009245, Avg batch loss: 0.0256, Avg batch acc: 0.9733
Train, Epoch: 7, Batch: 27, Step num: 9141, Learning rate: 0.00009245, Avg batch loss: 0.0198, Avg batch acc: 0.9801
Train, Epoch: 7, Batch: 28, Step num: 9142, Learning rate: 0.00009244, Avg batch loss: 0.0182, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 29, Step num: 9143, Learning rate: 0.00009244, Avg batch loss: 0.0307, Avg batch acc: 0.9760
Train, Epoch: 7, Batch: 30, Step num: 9144, Learning rate: 0.00009243, Avg batch loss: 0.0250, Avg batch acc: 0.9761
Train, Epoch: 7, Batch: 31, Step num: 9145, Learning rate: 0.00009243, Avg batch loss: 0.0239, Avg batch acc: 0.9763
Train, Epoch: 7, Batch: 32, Step num: 9146, Learning rate: 0.00009242, Avg batch loss: 0.0254, Avg batch acc: 0.9748
Train, Epoch: 7, Batch: 33, Step num: 9147, Learning rate: 0.00009242, Avg batch loss: 0.0221, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 34, Step num: 9148, Learning rate: 0.00009241, Avg batch loss: 0.0144, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 35, Step num: 9149, Learning rate: 0.00009241, Avg batch loss: 0.0223, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 36, Step num: 9150, Learning rate: 0.00009240, Avg batch loss: 0.0235, Avg batch acc: 0.9750
Train, Epoch: 7, Batch: 37, Step num: 9151, Learning rate: 0.00009240, Avg batch loss: 0.0253, Avg batch acc: 0.9747
Train, Epoch: 7, Batch: 38, Step num: 9152, Learning rate: 0.00009239, Avg batch loss: 0.0200, Avg batch acc: 0.9787
Train, Epoch: 7, Batch: 39, Step num: 9153, Learning rate: 0.00009239, Avg batch loss: 0.0183, Avg batch acc: 0.9794
Train, Epoch: 7, Batch: 40, Step num: 9154, Learning rate: 0.00009238, Avg batch loss: 0.0198, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 41, Step num: 9155, Learning rate: 0.00009238, Avg batch loss: 0.0196, Avg batch acc: 0.9749
Train, Epoch: 7, Batch: 42, Step num: 9156, Learning rate: 0.00009237, Avg batch loss: 0.0232, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 43, Step num: 9157, Learning rate: 0.00009237, Avg batch loss: 0.0198, Avg batch acc: 0.9813
Train, Epoch: 7, Batch: 44, Step num: 9158, Learning rate: 0.00009236, Avg batch loss: 0.0237, Avg batch acc: 0.9761
Train, Epoch: 7, Batch: 45, Step num: 9159, Learning rate: 0.00009236, Avg batch loss: 0.0205, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 46, Step num: 9160, Learning rate: 0.00009235, Avg batch loss: 0.0224, Avg batch acc: 0.9763
Train, Epoch: 7, Batch: 47, Step num: 9161, Learning rate: 0.00009235, Avg batch loss: 0.0230, Avg batch acc: 0.9748
Train, Epoch: 7, Batch: 48, Step num: 9162, Learning rate: 0.00009234, Avg batch loss: 0.0196, Avg batch acc: 0.9764
Train, Epoch: 7, Batch: 49, Step num: 9163, Learning rate: 0.00009234, Avg batch loss: 0.0227, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 50, Step num: 9164, Learning rate: 0.00009233, Avg batch loss: 0.0218, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 51, Step num: 9165, Learning rate: 0.00009233, Avg batch loss: 0.0216, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 52, Step num: 9166, Learning rate: 0.00009232, Avg batch loss: 0.0191, Avg batch acc: 0.9771
Train, Epoch: 7, Batch: 53, Step num: 9167, Learning rate: 0.00009232, Avg batch loss: 0.0225, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 54, Step num: 9168, Learning rate: 0.00009231, Avg batch loss: 0.0226, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 55, Step num: 9169, Learning rate: 0.00009231, Avg batch loss: 0.0215, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 56, Step num: 9170, Learning rate: 0.00009230, Avg batch loss: 0.0236, Avg batch acc: 0.9736
Train, Epoch: 7, Batch: 57, Step num: 9171, Learning rate: 0.00009230, Avg batch loss: 0.0167, Avg batch acc: 0.9778
Train, Epoch: 7, Batch: 58, Step num: 9172, Learning rate: 0.00009229, Avg batch loss: 0.0224, Avg batch acc: 0.9767
Train, Epoch: 7, Batch: 59, Step num: 9173, Learning rate: 0.00009229, Avg batch loss: 0.0223, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 60, Step num: 9174, Learning rate: 0.00009228, Avg batch loss: 0.0196, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 61, Step num: 9175, Learning rate: 0.00009228, Avg batch loss: 0.0297, Avg batch acc: 0.9771
Train, Epoch: 7, Batch: 62, Step num: 9176, Learning rate: 0.00009227, Avg batch loss: 0.0219, Avg batch acc: 0.9748
Train, Epoch: 7, Batch: 63, Step num: 9177, Learning rate: 0.00009227, Avg batch loss: 0.0227, Avg batch acc: 0.9733
Train, Epoch: 7, Batch: 64, Step num: 9178, Learning rate: 0.00009226, Avg batch loss: 0.0227, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 65, Step num: 9179, Learning rate: 0.00009226, Avg batch loss: 0.0174, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 66, Step num: 9180, Learning rate: 0.00009225, Avg batch loss: 0.0232, Avg batch acc: 0.9778
Train, Epoch: 7, Batch: 67, Step num: 9181, Learning rate: 0.00009225, Avg batch loss: 0.0203, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 68, Step num: 9182, Learning rate: 0.00009224, Avg batch loss: 0.0212, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 69, Step num: 9183, Learning rate: 0.00009224, Avg batch loss: 0.0210, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 70, Step num: 9184, Learning rate: 0.00009223, Avg batch loss: 0.0230, Avg batch acc: 0.9747
Train, Epoch: 7, Batch: 71, Step num: 9185, Learning rate: 0.00009223, Avg batch loss: 0.0234, Avg batch acc: 0.9723
Train, Epoch: 7, Batch: 72, Step num: 9186, Learning rate: 0.00009222, Avg batch loss: 0.0203, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 73, Step num: 9187, Learning rate: 0.00009222, Avg batch loss: 0.0213, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 74, Step num: 9188, Learning rate: 0.00009221, Avg batch loss: 0.0199, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 75, Step num: 9189, Learning rate: 0.00009221, Avg batch loss: 0.0227, Avg batch acc: 0.9767
Train, Epoch: 7, Batch: 76, Step num: 9190, Learning rate: 0.00009220, Avg batch loss: 0.0214, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 77, Step num: 9191, Learning rate: 0.00009220, Avg batch loss: 0.0204, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 78, Step num: 9192, Learning rate: 0.00009219, Avg batch loss: 0.0228, Avg batch acc: 0.9763
Train, Epoch: 7, Batch: 79, Step num: 9193, Learning rate: 0.00009219, Avg batch loss: 0.0261, Avg batch acc: 0.9774
Train, Epoch: 7, Batch: 80, Step num: 9194, Learning rate: 0.00009218, Avg batch loss: 0.0189, Avg batch acc: 0.9775
Train, Epoch: 7, Batch: 81, Step num: 9195, Learning rate: 0.00009218, Avg batch loss: 0.0174, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 82, Step num: 9196, Learning rate: 0.00009217, Avg batch loss: 0.0195, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 83, Step num: 9197, Learning rate: 0.00009217, Avg batch loss: 0.0203, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 84, Step num: 9198, Learning rate: 0.00009216, Avg batch loss: 0.0207, Avg batch acc: 0.9742
Train, Epoch: 7, Batch: 85, Step num: 9199, Learning rate: 0.00009216, Avg batch loss: 0.0220, Avg batch acc: 0.9748
Train, Epoch: 7, Batch: 86, Step num: 9200, Learning rate: 0.00009215, Avg batch loss: 0.0210, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 87, Step num: 9201, Learning rate: 0.00009215, Avg batch loss: 0.0242, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 88, Step num: 9202, Learning rate: 0.00009214, Avg batch loss: 0.0284, Avg batch acc: 0.9709
Train, Epoch: 7, Batch: 89, Step num: 9203, Learning rate: 0.00009214, Avg batch loss: 0.0201, Avg batch acc: 0.9760
Train, Epoch: 7, Batch: 90, Step num: 9204, Learning rate: 0.00009213, Avg batch loss: 0.0180, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 91, Step num: 9205, Learning rate: 0.00009213, Avg batch loss: 0.0198, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 92, Step num: 9206, Learning rate: 0.00009212, Avg batch loss: 0.0212, Avg batch acc: 0.9769
Train, Epoch: 7, Batch: 93, Step num: 9207, Learning rate: 0.00009212, Avg batch loss: 0.0212, Avg batch acc: 0.9751
Train, Epoch: 7, Batch: 94, Step num: 9208, Learning rate: 0.00009211, Avg batch loss: 0.0238, Avg batch acc: 0.9726
Train, Epoch: 7, Batch: 95, Step num: 9209, Learning rate: 0.00009211, Avg batch loss: 0.0188, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 96, Step num: 9210, Learning rate: 0.00009210, Avg batch loss: 0.0226, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 97, Step num: 9211, Learning rate: 0.00009210, Avg batch loss: 0.0270, Avg batch acc: 0.9738
Train, Epoch: 7, Batch: 98, Step num: 9212, Learning rate: 0.00009209, Avg batch loss: 0.0256, Avg batch acc: 0.9679
Train, Epoch: 7, Batch: 99, Step num: 9213, Learning rate: 0.00009209, Avg batch loss: 0.0209, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 100, Step num: 9214, Learning rate: 0.00009208, Avg batch loss: 0.0221, Avg batch acc: 0.9755
Train, Epoch: 7, Batch: 101, Step num: 9215, Learning rate: 0.00009208, Avg batch loss: 0.0170, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 102, Step num: 9216, Learning rate: 0.00009207, Avg batch loss: 0.0194, Avg batch acc: 0.9754
Train, Epoch: 7, Batch: 103, Step num: 9217, Learning rate: 0.00009207, Avg batch loss: 0.0175, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 104, Step num: 9218, Learning rate: 0.00009206, Avg batch loss: 0.0188, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 105, Step num: 9219, Learning rate: 0.00009206, Avg batch loss: 0.0182, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 106, Step num: 9220, Learning rate: 0.00009205, Avg batch loss: 0.0290, Avg batch acc: 0.9762
Train, Epoch: 7, Batch: 107, Step num: 9221, Learning rate: 0.00009205, Avg batch loss: 0.0209, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 108, Step num: 9222, Learning rate: 0.00009204, Avg batch loss: 0.0184, Avg batch acc: 0.9777
Train, Epoch: 7, Batch: 109, Step num: 9223, Learning rate: 0.00009204, Avg batch loss: 0.0175, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 110, Step num: 9224, Learning rate: 0.00009203, Avg batch loss: 0.0250, Avg batch acc: 0.9743
Train, Epoch: 7, Batch: 111, Step num: 9225, Learning rate: 0.00009203, Avg batch loss: 0.0162, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 112, Step num: 9226, Learning rate: 0.00009202, Avg batch loss: 0.0179, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 113, Step num: 9227, Learning rate: 0.00009202, Avg batch loss: 0.0223, Avg batch acc: 0.9760
Train, Epoch: 7, Batch: 114, Step num: 9228, Learning rate: 0.00009201, Avg batch loss: 0.0303, Avg batch acc: 0.9689
Train, Epoch: 7, Batch: 115, Step num: 9229, Learning rate: 0.00009201, Avg batch loss: 0.0215, Avg batch acc: 0.9737
Train, Epoch: 7, Batch: 116, Step num: 9230, Learning rate: 0.00009200, Avg batch loss: 0.0227, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 117, Step num: 9231, Learning rate: 0.00009200, Avg batch loss: 0.0167, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 118, Step num: 9232, Learning rate: 0.00009199, Avg batch loss: 0.0298, Avg batch acc: 0.9774
Train, Epoch: 7, Batch: 119, Step num: 9233, Learning rate: 0.00009199, Avg batch loss: 0.0221, Avg batch acc: 0.9755
Train, Epoch: 7, Batch: 120, Step num: 9234, Learning rate: 0.00009198, Avg batch loss: 0.0235, Avg batch acc: 0.9697
Train, Epoch: 7, Batch: 121, Step num: 9235, Learning rate: 0.00009198, Avg batch loss: 0.0236, Avg batch acc: 0.9759
Train, Epoch: 7, Batch: 122, Step num: 9236, Learning rate: 0.00009197, Avg batch loss: 0.0240, Avg batch acc: 0.9732
Train, Epoch: 7, Batch: 123, Step num: 9237, Learning rate: 0.00009197, Avg batch loss: 0.0187, Avg batch acc: 0.9743
Train, Epoch: 7, Batch: 124, Step num: 9238, Learning rate: 0.00009196, Avg batch loss: 0.0217, Avg batch acc: 0.9781
Train, Epoch: 7, Batch: 125, Step num: 9239, Learning rate: 0.00009196, Avg batch loss: 0.0197, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 126, Step num: 9240, Learning rate: 0.00009195, Avg batch loss: 0.0175, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 127, Step num: 9241, Learning rate: 0.00009195, Avg batch loss: 0.0199, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 128, Step num: 9242, Learning rate: 0.00009194, Avg batch loss: 0.0177, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 129, Step num: 9243, Learning rate: 0.00009194, Avg batch loss: 0.0204, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 130, Step num: 9244, Learning rate: 0.00009193, Avg batch loss: 0.0157, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 131, Step num: 9245, Learning rate: 0.00009193, Avg batch loss: 0.0206, Avg batch acc: 0.9768
Train, Epoch: 7, Batch: 132, Step num: 9246, Learning rate: 0.00009192, Avg batch loss: 0.0171, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 133, Step num: 9247, Learning rate: 0.00009192, Avg batch loss: 0.0181, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 134, Step num: 9248, Learning rate: 0.00009191, Avg batch loss: 0.0216, Avg batch acc: 0.9747
Train, Epoch: 7, Batch: 135, Step num: 9249, Learning rate: 0.00009191, Avg batch loss: 0.0184, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 136, Step num: 9250, Learning rate: 0.00009190, Avg batch loss: 0.0204, Avg batch acc: 0.9767
Train, Epoch: 7, Batch: 137, Step num: 9251, Learning rate: 0.00009190, Avg batch loss: 0.0194, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 138, Step num: 9252, Learning rate: 0.00009189, Avg batch loss: 0.0162, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 139, Step num: 9253, Learning rate: 0.00009189, Avg batch loss: 0.0177, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 140, Step num: 9254, Learning rate: 0.00009188, Avg batch loss: 0.0190, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 141, Step num: 9255, Learning rate: 0.00009188, Avg batch loss: 0.0177, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 142, Step num: 9256, Learning rate: 0.00009187, Avg batch loss: 0.0169, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 143, Step num: 9257, Learning rate: 0.00009187, Avg batch loss: 0.0157, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 144, Step num: 9258, Learning rate: 0.00009186, Avg batch loss: 0.0187, Avg batch acc: 0.9763
Train, Epoch: 7, Batch: 145, Step num: 9259, Learning rate: 0.00009186, Avg batch loss: 0.0204, Avg batch acc: 0.9777
Train, Epoch: 7, Batch: 146, Step num: 9260, Learning rate: 0.00009185, Avg batch loss: 0.0186, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 147, Step num: 9261, Learning rate: 0.00009185, Avg batch loss: 0.0205, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 148, Step num: 9262, Learning rate: 0.00009184, Avg batch loss: 0.0178, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 149, Step num: 9263, Learning rate: 0.00009184, Avg batch loss: 0.0235, Avg batch acc: 0.9750
Train, Epoch: 7, Batch: 150, Step num: 9264, Learning rate: 0.00009183, Avg batch loss: 0.0210, Avg batch acc: 0.9791
Train, Epoch: 7, Batch: 151, Step num: 9265, Learning rate: 0.00009183, Avg batch loss: 0.0255, Avg batch acc: 0.9757
Train, Epoch: 7, Batch: 152, Step num: 9266, Learning rate: 0.00009182, Avg batch loss: 0.0168, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 153, Step num: 9267, Learning rate: 0.00009182, Avg batch loss: 0.0189, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 154, Step num: 9268, Learning rate: 0.00009181, Avg batch loss: 0.0203, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 155, Step num: 9269, Learning rate: 0.00009181, Avg batch loss: 0.0190, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 156, Step num: 9270, Learning rate: 0.00009180, Avg batch loss: 0.0190, Avg batch acc: 0.9775
Train, Epoch: 7, Batch: 157, Step num: 9271, Learning rate: 0.00009180, Avg batch loss: 0.0174, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 158, Step num: 9272, Learning rate: 0.00009179, Avg batch loss: 0.0186, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 159, Step num: 9273, Learning rate: 0.00009179, Avg batch loss: 0.0241, Avg batch acc: 0.9774
Train, Epoch: 7, Batch: 160, Step num: 9274, Learning rate: 0.00009178, Avg batch loss: 0.0210, Avg batch acc: 0.9791
Train, Epoch: 7, Batch: 161, Step num: 9275, Learning rate: 0.00009178, Avg batch loss: 0.0187, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 162, Step num: 9276, Learning rate: 0.00009177, Avg batch loss: 0.0179, Avg batch acc: 0.9769
Train, Epoch: 7, Batch: 163, Step num: 9277, Learning rate: 0.00009177, Avg batch loss: 0.0230, Avg batch acc: 0.9762
Train, Epoch: 7, Batch: 164, Step num: 9278, Learning rate: 0.00009176, Avg batch loss: 0.0208, Avg batch acc: 0.9761
Train, Epoch: 7, Batch: 165, Step num: 9279, Learning rate: 0.00009176, Avg batch loss: 0.0201, Avg batch acc: 0.9785
Train, Epoch: 7, Batch: 166, Step num: 9280, Learning rate: 0.00009175, Avg batch loss: 0.0150, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 167, Step num: 9281, Learning rate: 0.00009175, Avg batch loss: 0.0198, Avg batch acc: 0.9813
Train, Epoch: 7, Batch: 168, Step num: 9282, Learning rate: 0.00009174, Avg batch loss: 0.0179, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 169, Step num: 9283, Learning rate: 0.00009174, Avg batch loss: 0.0224, Avg batch acc: 0.9759
Train, Epoch: 7, Batch: 170, Step num: 9284, Learning rate: 0.00009173, Avg batch loss: 0.0249, Avg batch acc: 0.9749
Train, Epoch: 7, Batch: 171, Step num: 9285, Learning rate: 0.00009173, Avg batch loss: 0.0198, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 172, Step num: 9286, Learning rate: 0.00009172, Avg batch loss: 0.0416, Avg batch acc: 0.9734
Train, Epoch: 7, Batch: 173, Step num: 9287, Learning rate: 0.00009172, Avg batch loss: 0.0178, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 174, Step num: 9288, Learning rate: 0.00009171, Avg batch loss: 0.0173, Avg batch acc: 0.9787
Train, Epoch: 7, Batch: 175, Step num: 9289, Learning rate: 0.00009171, Avg batch loss: 0.0220, Avg batch acc: 0.9756
Train, Epoch: 7, Batch: 176, Step num: 9290, Learning rate: 0.00009170, Avg batch loss: 0.0233, Avg batch acc: 0.9757
Train, Epoch: 7, Batch: 177, Step num: 9291, Learning rate: 0.00009170, Avg batch loss: 0.0204, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 178, Step num: 9292, Learning rate: 0.00009169, Avg batch loss: 0.0190, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 179, Step num: 9293, Learning rate: 0.00009169, Avg batch loss: 0.0259, Avg batch acc: 0.9751
Train, Epoch: 7, Batch: 180, Step num: 9294, Learning rate: 0.00009168, Avg batch loss: 0.0300, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 181, Step num: 9295, Learning rate: 0.00009168, Avg batch loss: 0.0261, Avg batch acc: 0.9768
Train, Epoch: 7, Batch: 182, Step num: 9296, Learning rate: 0.00009167, Avg batch loss: 0.0200, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 183, Step num: 9297, Learning rate: 0.00009167, Avg batch loss: 0.0332, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 184, Step num: 9298, Learning rate: 0.00009166, Avg batch loss: 0.0185, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 185, Step num: 9299, Learning rate: 0.00009166, Avg batch loss: 0.0148, Avg batch acc: 0.9824
Train, Epoch: 7, Batch: 186, Step num: 9300, Learning rate: 0.00009165, Avg batch loss: 0.0207, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 187, Step num: 9301, Learning rate: 0.00009165, Avg batch loss: 0.0191, Avg batch acc: 0.9787
Train, Epoch: 7, Batch: 188, Step num: 9302, Learning rate: 0.00009164, Avg batch loss: 0.0201, Avg batch acc: 0.9775
Train, Epoch: 7, Batch: 189, Step num: 9303, Learning rate: 0.00009164, Avg batch loss: 0.0303, Avg batch acc: 0.9730
Train, Epoch: 7, Batch: 190, Step num: 9304, Learning rate: 0.00009163, Avg batch loss: 0.0144, Avg batch acc: 0.9869
Train, Epoch: 7, Batch: 191, Step num: 9305, Learning rate: 0.00009163, Avg batch loss: 0.0210, Avg batch acc: 0.9773
Train, Epoch: 7, Batch: 192, Step num: 9306, Learning rate: 0.00009162, Avg batch loss: 0.0193, Avg batch acc: 0.9738
Train, Epoch: 7, Batch: 193, Step num: 9307, Learning rate: 0.00009162, Avg batch loss: 0.0219, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 194, Step num: 9308, Learning rate: 0.00009162, Avg batch loss: 0.0185, Avg batch acc: 0.9774
Train, Epoch: 7, Batch: 195, Step num: 9309, Learning rate: 0.00009161, Avg batch loss: 0.0239, Avg batch acc: 0.9747
Train, Epoch: 7, Batch: 196, Step num: 9310, Learning rate: 0.00009161, Avg batch loss: 0.0239, Avg batch acc: 0.9733
Train, Epoch: 7, Batch: 197, Step num: 9311, Learning rate: 0.00009160, Avg batch loss: 0.0279, Avg batch acc: 0.9742
Train, Epoch: 7, Batch: 198, Step num: 9312, Learning rate: 0.00009160, Avg batch loss: 0.0237, Avg batch acc: 0.9764
Train, Epoch: 7, Batch: 199, Step num: 9313, Learning rate: 0.00009159, Avg batch loss: 0.0236, Avg batch acc: 0.9726
Train, Epoch: 7, Batch: 200, Step num: 9314, Learning rate: 0.00009159, Avg batch loss: 0.0178, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 201, Step num: 9315, Learning rate: 0.00009158, Avg batch loss: 0.0160, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 202, Step num: 9316, Learning rate: 0.00009158, Avg batch loss: 0.0181, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 203, Step num: 9317, Learning rate: 0.00009157, Avg batch loss: 0.0173, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 204, Step num: 9318, Learning rate: 0.00009157, Avg batch loss: 0.0245, Avg batch acc: 0.9743
Train, Epoch: 7, Batch: 205, Step num: 9319, Learning rate: 0.00009156, Avg batch loss: 0.0339, Avg batch acc: 0.9762
Train, Epoch: 7, Batch: 206, Step num: 9320, Learning rate: 0.00009156, Avg batch loss: 0.0196, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 207, Step num: 9321, Learning rate: 0.00009155, Avg batch loss: 0.0195, Avg batch acc: 0.9780
Train, Epoch: 7, Batch: 208, Step num: 9322, Learning rate: 0.00009155, Avg batch loss: 0.0184, Avg batch acc: 0.9771
Train, Epoch: 7, Batch: 209, Step num: 9323, Learning rate: 0.00009154, Avg batch loss: 0.0214, Avg batch acc: 0.9775
Train, Epoch: 7, Batch: 210, Step num: 9324, Learning rate: 0.00009154, Avg batch loss: 0.0241, Avg batch acc: 0.9752
Train, Epoch: 7, Batch: 211, Step num: 9325, Learning rate: 0.00009153, Avg batch loss: 0.0219, Avg batch acc: 0.9769
Train, Epoch: 7, Batch: 212, Step num: 9326, Learning rate: 0.00009153, Avg batch loss: 0.0164, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 213, Step num: 9327, Learning rate: 0.00009152, Avg batch loss: 0.0293, Avg batch acc: 0.9704
Train, Epoch: 7, Batch: 214, Step num: 9328, Learning rate: 0.00009152, Avg batch loss: 0.0188, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 215, Step num: 9329, Learning rate: 0.00009151, Avg batch loss: 0.0199, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 216, Step num: 9330, Learning rate: 0.00009151, Avg batch loss: 0.0351, Avg batch acc: 0.9780
Train, Epoch: 7, Batch: 217, Step num: 9331, Learning rate: 0.00009150, Avg batch loss: 0.0228, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 218, Step num: 9332, Learning rate: 0.00009150, Avg batch loss: 0.0237, Avg batch acc: 0.9740
Train, Epoch: 7, Batch: 219, Step num: 9333, Learning rate: 0.00009149, Avg batch loss: 0.0192, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 220, Step num: 9334, Learning rate: 0.00009149, Avg batch loss: 0.0199, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 221, Step num: 9335, Learning rate: 0.00009148, Avg batch loss: 0.0215, Avg batch acc: 0.9745
Train, Epoch: 7, Batch: 222, Step num: 9336, Learning rate: 0.00009148, Avg batch loss: 0.0200, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 223, Step num: 9337, Learning rate: 0.00009147, Avg batch loss: 0.0166, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 224, Step num: 9338, Learning rate: 0.00009147, Avg batch loss: 0.0149, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 225, Step num: 9339, Learning rate: 0.00009146, Avg batch loss: 0.0211, Avg batch acc: 0.9769
Train, Epoch: 7, Batch: 226, Step num: 9340, Learning rate: 0.00009146, Avg batch loss: 0.0234, Avg batch acc: 0.9756
Train, Epoch: 7, Batch: 227, Step num: 9341, Learning rate: 0.00009145, Avg batch loss: 0.0202, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 228, Step num: 9342, Learning rate: 0.00009145, Avg batch loss: 0.0277, Avg batch acc: 0.9741
Train, Epoch: 7, Batch: 229, Step num: 9343, Learning rate: 0.00009144, Avg batch loss: 0.0193, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 230, Step num: 9344, Learning rate: 0.00009144, Avg batch loss: 0.0183, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 231, Step num: 9345, Learning rate: 0.00009143, Avg batch loss: 0.0202, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 232, Step num: 9346, Learning rate: 0.00009143, Avg batch loss: 0.0170, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 233, Step num: 9347, Learning rate: 0.00009142, Avg batch loss: 0.0219, Avg batch acc: 0.9755
Train, Epoch: 7, Batch: 234, Step num: 9348, Learning rate: 0.00009142, Avg batch loss: 0.0192, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 235, Step num: 9349, Learning rate: 0.00009141, Avg batch loss: 0.0199, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 236, Step num: 9350, Learning rate: 0.00009141, Avg batch loss: 0.0213, Avg batch acc: 0.9726
Train, Epoch: 7, Batch: 237, Step num: 9351, Learning rate: 0.00009140, Avg batch loss: 0.0208, Avg batch acc: 0.9757
Train, Epoch: 7, Batch: 238, Step num: 9352, Learning rate: 0.00009140, Avg batch loss: 0.0174, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 239, Step num: 9353, Learning rate: 0.00009139, Avg batch loss: 0.0205, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 240, Step num: 9354, Learning rate: 0.00009139, Avg batch loss: 0.0181, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 241, Step num: 9355, Learning rate: 0.00009138, Avg batch loss: 0.0186, Avg batch acc: 0.9813
Train, Epoch: 7, Batch: 242, Step num: 9356, Learning rate: 0.00009138, Avg batch loss: 0.0230, Avg batch acc: 0.9752
Train, Epoch: 7, Batch: 243, Step num: 9357, Learning rate: 0.00009137, Avg batch loss: 0.0216, Avg batch acc: 0.9785
Train, Epoch: 7, Batch: 244, Step num: 9358, Learning rate: 0.00009137, Avg batch loss: 0.0197, Avg batch acc: 0.9767
Train, Epoch: 7, Batch: 245, Step num: 9359, Learning rate: 0.00009137, Avg batch loss: 0.0165, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 246, Step num: 9360, Learning rate: 0.00009136, Avg batch loss: 0.0238, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 247, Step num: 9361, Learning rate: 0.00009136, Avg batch loss: 0.0202, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 248, Step num: 9362, Learning rate: 0.00009135, Avg batch loss: 0.0198, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 249, Step num: 9363, Learning rate: 0.00009135, Avg batch loss: 0.0187, Avg batch acc: 0.9777
Train, Epoch: 7, Batch: 250, Step num: 9364, Learning rate: 0.00009134, Avg batch loss: 0.0226, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 251, Step num: 9365, Learning rate: 0.00009134, Avg batch loss: 0.0177, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 252, Step num: 9366, Learning rate: 0.00009133, Avg batch loss: 0.0152, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 253, Step num: 9367, Learning rate: 0.00009133, Avg batch loss: 0.0260, Avg batch acc: 0.9741
Train, Epoch: 7, Batch: 254, Step num: 9368, Learning rate: 0.00009132, Avg batch loss: 0.0194, Avg batch acc: 0.9836
Train, Epoch: 7, Batch: 255, Step num: 9369, Learning rate: 0.00009132, Avg batch loss: 0.0182, Avg batch acc: 0.9801
Train, Epoch: 7, Batch: 256, Step num: 9370, Learning rate: 0.00009131, Avg batch loss: 0.0189, Avg batch acc: 0.9787
Train, Epoch: 7, Batch: 257, Step num: 9371, Learning rate: 0.00009131, Avg batch loss: 0.0199, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 258, Step num: 9372, Learning rate: 0.00009130, Avg batch loss: 0.0231, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 259, Step num: 9373, Learning rate: 0.00009130, Avg batch loss: 0.0207, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 260, Step num: 9374, Learning rate: 0.00009129, Avg batch loss: 0.0207, Avg batch acc: 0.9764
Train, Epoch: 7, Batch: 261, Step num: 9375, Learning rate: 0.00009129, Avg batch loss: 0.0156, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 262, Step num: 9376, Learning rate: 0.00009128, Avg batch loss: 0.0212, Avg batch acc: 0.9760
Train, Epoch: 7, Batch: 263, Step num: 9377, Learning rate: 0.00009128, Avg batch loss: 0.0214, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 264, Step num: 9378, Learning rate: 0.00009127, Avg batch loss: 0.0171, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 265, Step num: 9379, Learning rate: 0.00009127, Avg batch loss: 0.0195, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 266, Step num: 9380, Learning rate: 0.00009126, Avg batch loss: 0.0167, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 267, Step num: 9381, Learning rate: 0.00009126, Avg batch loss: 0.0191, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 268, Step num: 9382, Learning rate: 0.00009125, Avg batch loss: 0.0155, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 269, Step num: 9383, Learning rate: 0.00009125, Avg batch loss: 0.0192, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 270, Step num: 9384, Learning rate: 0.00009124, Avg batch loss: 0.0170, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 271, Step num: 9385, Learning rate: 0.00009124, Avg batch loss: 0.0202, Avg batch acc: 0.9742
Train, Epoch: 7, Batch: 272, Step num: 9386, Learning rate: 0.00009123, Avg batch loss: 0.0205, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 273, Step num: 9387, Learning rate: 0.00009123, Avg batch loss: 0.0184, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 274, Step num: 9388, Learning rate: 0.00009122, Avg batch loss: 0.0189, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 275, Step num: 9389, Learning rate: 0.00009122, Avg batch loss: 0.0213, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 276, Step num: 9390, Learning rate: 0.00009121, Avg batch loss: 0.0165, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 277, Step num: 9391, Learning rate: 0.00009121, Avg batch loss: 0.0187, Avg batch acc: 0.9771
Train, Epoch: 7, Batch: 278, Step num: 9392, Learning rate: 0.00009120, Avg batch loss: 0.0196, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 279, Step num: 9393, Learning rate: 0.00009120, Avg batch loss: 0.0173, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 280, Step num: 9394, Learning rate: 0.00009119, Avg batch loss: 0.0193, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 281, Step num: 9395, Learning rate: 0.00009119, Avg batch loss: 0.0221, Avg batch acc: 0.9742
Train, Epoch: 7, Batch: 282, Step num: 9396, Learning rate: 0.00009119, Avg batch loss: 0.0201, Avg batch acc: 0.9760
Train, Epoch: 7, Batch: 283, Step num: 9397, Learning rate: 0.00009118, Avg batch loss: 0.0220, Avg batch acc: 0.9760
Train, Epoch: 7, Batch: 284, Step num: 9398, Learning rate: 0.00009118, Avg batch loss: 0.0197, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 285, Step num: 9399, Learning rate: 0.00009117, Avg batch loss: 0.0215, Avg batch acc: 0.9751
Train, Epoch: 7, Batch: 286, Step num: 9400, Learning rate: 0.00009117, Avg batch loss: 0.0200, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 287, Step num: 9401, Learning rate: 0.00009116, Avg batch loss: 0.0200, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 288, Step num: 9402, Learning rate: 0.00009116, Avg batch loss: 0.0181, Avg batch acc: 0.9785
Train, Epoch: 7, Batch: 289, Step num: 9403, Learning rate: 0.00009115, Avg batch loss: 0.0194, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 290, Step num: 9404, Learning rate: 0.00009115, Avg batch loss: 0.0142, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 291, Step num: 9405, Learning rate: 0.00009114, Avg batch loss: 0.0227, Avg batch acc: 0.9772
Train, Epoch: 7, Batch: 292, Step num: 9406, Learning rate: 0.00009114, Avg batch loss: 0.0168, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 293, Step num: 9407, Learning rate: 0.00009113, Avg batch loss: 0.0173, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 294, Step num: 9408, Learning rate: 0.00009113, Avg batch loss: 0.0251, Avg batch acc: 0.9766
Train, Epoch: 7, Batch: 295, Step num: 9409, Learning rate: 0.00009112, Avg batch loss: 0.0169, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 296, Step num: 9410, Learning rate: 0.00009112, Avg batch loss: 0.0214, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 297, Step num: 9411, Learning rate: 0.00009111, Avg batch loss: 0.0225, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 298, Step num: 9412, Learning rate: 0.00009111, Avg batch loss: 0.0175, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 299, Step num: 9413, Learning rate: 0.00009110, Avg batch loss: 0.0182, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 300, Step num: 9414, Learning rate: 0.00009110, Avg batch loss: 0.0190, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 301, Step num: 9415, Learning rate: 0.00009109, Avg batch loss: 0.0215, Avg batch acc: 0.9791
Train, Epoch: 7, Batch: 302, Step num: 9416, Learning rate: 0.00009109, Avg batch loss: 0.0168, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 303, Step num: 9417, Learning rate: 0.00009108, Avg batch loss: 0.0171, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 304, Step num: 9418, Learning rate: 0.00009108, Avg batch loss: 0.0183, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 305, Step num: 9419, Learning rate: 0.00009107, Avg batch loss: 0.0207, Avg batch acc: 0.9780
Train, Epoch: 7, Batch: 306, Step num: 9420, Learning rate: 0.00009107, Avg batch loss: 0.0184, Avg batch acc: 0.9784
Train, Epoch: 7, Batch: 307, Step num: 9421, Learning rate: 0.00009106, Avg batch loss: 0.0304, Avg batch acc: 0.9785
Train, Epoch: 7, Batch: 308, Step num: 9422, Learning rate: 0.00009106, Avg batch loss: 0.0183, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 309, Step num: 9423, Learning rate: 0.00009105, Avg batch loss: 0.0214, Avg batch acc: 0.9791
Train, Epoch: 7, Batch: 310, Step num: 9424, Learning rate: 0.00009105, Avg batch loss: 0.0176, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 311, Step num: 9425, Learning rate: 0.00009104, Avg batch loss: 0.0182, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 312, Step num: 9426, Learning rate: 0.00009104, Avg batch loss: 0.0214, Avg batch acc: 0.9767
Train, Epoch: 7, Batch: 313, Step num: 9427, Learning rate: 0.00009103, Avg batch loss: 0.0192, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 314, Step num: 9428, Learning rate: 0.00009103, Avg batch loss: 0.0173, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 315, Step num: 9429, Learning rate: 0.00009103, Avg batch loss: 0.0308, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 316, Step num: 9430, Learning rate: 0.00009102, Avg batch loss: 0.0164, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 317, Step num: 9431, Learning rate: 0.00009102, Avg batch loss: 0.0173, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 318, Step num: 9432, Learning rate: 0.00009101, Avg batch loss: 0.0187, Avg batch acc: 0.9758
Train, Epoch: 7, Batch: 319, Step num: 9433, Learning rate: 0.00009101, Avg batch loss: 0.0183, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 320, Step num: 9434, Learning rate: 0.00009100, Avg batch loss: 0.0295, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 321, Step num: 9435, Learning rate: 0.00009100, Avg batch loss: 0.0189, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 322, Step num: 9436, Learning rate: 0.00009099, Avg batch loss: 0.0230, Avg batch acc: 0.9754
Train, Epoch: 7, Batch: 323, Step num: 9437, Learning rate: 0.00009099, Avg batch loss: 0.0171, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 324, Step num: 9438, Learning rate: 0.00009098, Avg batch loss: 0.0163, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 325, Step num: 9439, Learning rate: 0.00009098, Avg batch loss: 0.0155, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 326, Step num: 9440, Learning rate: 0.00009097, Avg batch loss: 0.0176, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 327, Step num: 9441, Learning rate: 0.00009097, Avg batch loss: 0.0266, Avg batch acc: 0.9764
Train, Epoch: 7, Batch: 328, Step num: 9442, Learning rate: 0.00009096, Avg batch loss: 0.0151, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 329, Step num: 9443, Learning rate: 0.00009096, Avg batch loss: 0.0207, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 330, Step num: 9444, Learning rate: 0.00009095, Avg batch loss: 0.0199, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 331, Step num: 9445, Learning rate: 0.00009095, Avg batch loss: 0.0187, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 332, Step num: 9446, Learning rate: 0.00009094, Avg batch loss: 0.0240, Avg batch acc: 0.9766
Train, Epoch: 7, Batch: 333, Step num: 9447, Learning rate: 0.00009094, Avg batch loss: 0.0215, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 334, Step num: 9448, Learning rate: 0.00009093, Avg batch loss: 0.0196, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 335, Step num: 9449, Learning rate: 0.00009093, Avg batch loss: 0.0192, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 336, Step num: 9450, Learning rate: 0.00009092, Avg batch loss: 0.0163, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 337, Step num: 9451, Learning rate: 0.00009092, Avg batch loss: 0.0186, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 338, Step num: 9452, Learning rate: 0.00009091, Avg batch loss: 0.0175, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 339, Step num: 9453, Learning rate: 0.00009091, Avg batch loss: 0.0164, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 340, Step num: 9454, Learning rate: 0.00009090, Avg batch loss: 0.0189, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 341, Step num: 9455, Learning rate: 0.00009090, Avg batch loss: 0.0167, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 342, Step num: 9456, Learning rate: 0.00009090, Avg batch loss: 0.0177, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 343, Step num: 9457, Learning rate: 0.00009089, Avg batch loss: 0.0190, Avg batch acc: 0.9781
Train, Epoch: 7, Batch: 344, Step num: 9458, Learning rate: 0.00009089, Avg batch loss: 0.0206, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 345, Step num: 9459, Learning rate: 0.00009088, Avg batch loss: 0.0162, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 346, Step num: 9460, Learning rate: 0.00009088, Avg batch loss: 0.0189, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 347, Step num: 9461, Learning rate: 0.00009087, Avg batch loss: 0.0277, Avg batch acc: 0.9729
Train, Epoch: 7, Batch: 348, Step num: 9462, Learning rate: 0.00009087, Avg batch loss: 0.0159, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 349, Step num: 9463, Learning rate: 0.00009086, Avg batch loss: 0.0146, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 350, Step num: 9464, Learning rate: 0.00009086, Avg batch loss: 0.0183, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 351, Step num: 9465, Learning rate: 0.00009085, Avg batch loss: 0.0209, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 352, Step num: 9466, Learning rate: 0.00009085, Avg batch loss: 0.0176, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 353, Step num: 9467, Learning rate: 0.00009084, Avg batch loss: 0.0197, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 354, Step num: 9468, Learning rate: 0.00009084, Avg batch loss: 0.0182, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 355, Step num: 9469, Learning rate: 0.00009083, Avg batch loss: 0.0160, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 356, Step num: 9470, Learning rate: 0.00009083, Avg batch loss: 0.0198, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 357, Step num: 9471, Learning rate: 0.00009082, Avg batch loss: 0.0165, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 358, Step num: 9472, Learning rate: 0.00009082, Avg batch loss: 0.0180, Avg batch acc: 0.9773
Train, Epoch: 7, Batch: 359, Step num: 9473, Learning rate: 0.00009081, Avg batch loss: 0.0200, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 360, Step num: 9474, Learning rate: 0.00009081, Avg batch loss: 0.0195, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 361, Step num: 9475, Learning rate: 0.00009080, Avg batch loss: 0.0189, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 362, Step num: 9476, Learning rate: 0.00009080, Avg batch loss: 0.0213, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 363, Step num: 9477, Learning rate: 0.00009079, Avg batch loss: 0.0180, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 364, Step num: 9478, Learning rate: 0.00009079, Avg batch loss: 0.0234, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 365, Step num: 9479, Learning rate: 0.00009078, Avg batch loss: 0.0216, Avg batch acc: 0.9794
Train, Epoch: 7, Batch: 366, Step num: 9480, Learning rate: 0.00009078, Avg batch loss: 0.0161, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 367, Step num: 9481, Learning rate: 0.00009078, Avg batch loss: 0.0181, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 368, Step num: 9482, Learning rate: 0.00009077, Avg batch loss: 0.0206, Avg batch acc: 0.9774
Train, Epoch: 7, Batch: 369, Step num: 9483, Learning rate: 0.00009077, Avg batch loss: 0.0200, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 370, Step num: 9484, Learning rate: 0.00009076, Avg batch loss: 0.0201, Avg batch acc: 0.9781
Train, Epoch: 7, Batch: 371, Step num: 9485, Learning rate: 0.00009076, Avg batch loss: 0.0203, Avg batch acc: 0.9752
Train, Epoch: 7, Batch: 372, Step num: 9486, Learning rate: 0.00009075, Avg batch loss: 0.0204, Avg batch acc: 0.9766
Train, Epoch: 7, Batch: 373, Step num: 9487, Learning rate: 0.00009075, Avg batch loss: 0.0208, Avg batch acc: 0.9762
Train, Epoch: 7, Batch: 374, Step num: 9488, Learning rate: 0.00009074, Avg batch loss: 0.0141, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 375, Step num: 9489, Learning rate: 0.00009074, Avg batch loss: 0.0185, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 376, Step num: 9490, Learning rate: 0.00009073, Avg batch loss: 0.0193, Avg batch acc: 0.9755
Train, Epoch: 7, Batch: 377, Step num: 9491, Learning rate: 0.00009073, Avg batch loss: 0.0206, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 378, Step num: 9492, Learning rate: 0.00009072, Avg batch loss: 0.0184, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 379, Step num: 9493, Learning rate: 0.00009072, Avg batch loss: 0.0144, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 380, Step num: 9494, Learning rate: 0.00009071, Avg batch loss: 0.0144, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 381, Step num: 9495, Learning rate: 0.00009071, Avg batch loss: 0.0204, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 382, Step num: 9496, Learning rate: 0.00009070, Avg batch loss: 0.0204, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 383, Step num: 9497, Learning rate: 0.00009070, Avg batch loss: 0.0178, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 384, Step num: 9498, Learning rate: 0.00009069, Avg batch loss: 0.0226, Avg batch acc: 0.9744
Train, Epoch: 7, Batch: 385, Step num: 9499, Learning rate: 0.00009069, Avg batch loss: 0.0167, Avg batch acc: 0.9780
Train, Epoch: 7, Batch: 386, Step num: 9500, Learning rate: 0.00009068, Avg batch loss: 0.0179, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 387, Step num: 9501, Learning rate: 0.00009068, Avg batch loss: 0.0202, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 388, Step num: 9502, Learning rate: 0.00009067, Avg batch loss: 0.0185, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 389, Step num: 9503, Learning rate: 0.00009067, Avg batch loss: 0.0162, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 390, Step num: 9504, Learning rate: 0.00009067, Avg batch loss: 0.0169, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 391, Step num: 9505, Learning rate: 0.00009066, Avg batch loss: 0.0192, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 392, Step num: 9506, Learning rate: 0.00009066, Avg batch loss: 0.0184, Avg batch acc: 0.9777
Train, Epoch: 7, Batch: 393, Step num: 9507, Learning rate: 0.00009065, Avg batch loss: 0.0192, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 394, Step num: 9508, Learning rate: 0.00009065, Avg batch loss: 0.0209, Avg batch acc: 0.9747
Train, Epoch: 7, Batch: 395, Step num: 9509, Learning rate: 0.00009064, Avg batch loss: 0.0222, Avg batch acc: 0.9813
Train, Epoch: 7, Batch: 396, Step num: 9510, Learning rate: 0.00009064, Avg batch loss: 0.0170, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 397, Step num: 9511, Learning rate: 0.00009063, Avg batch loss: 0.0180, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 398, Step num: 9512, Learning rate: 0.00009063, Avg batch loss: 0.0155, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 399, Step num: 9513, Learning rate: 0.00009062, Avg batch loss: 0.0173, Avg batch acc: 0.9787
Train, Epoch: 7, Batch: 400, Step num: 9514, Learning rate: 0.00009062, Avg batch loss: 0.0197, Avg batch acc: 0.9762
Train, Epoch: 7, Batch: 401, Step num: 9515, Learning rate: 0.00009061, Avg batch loss: 0.0132, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 402, Step num: 9516, Learning rate: 0.00009061, Avg batch loss: 0.0200, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 403, Step num: 9517, Learning rate: 0.00009060, Avg batch loss: 0.0196, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 404, Step num: 9518, Learning rate: 0.00009060, Avg batch loss: 0.0235, Avg batch acc: 0.9747
Train, Epoch: 7, Batch: 405, Step num: 9519, Learning rate: 0.00009059, Avg batch loss: 0.0187, Avg batch acc: 0.9759
Train, Epoch: 7, Batch: 406, Step num: 9520, Learning rate: 0.00009059, Avg batch loss: 0.0178, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 407, Step num: 9521, Learning rate: 0.00009058, Avg batch loss: 0.0211, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 408, Step num: 9522, Learning rate: 0.00009058, Avg batch loss: 0.0195, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 409, Step num: 9523, Learning rate: 0.00009057, Avg batch loss: 0.0178, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 410, Step num: 9524, Learning rate: 0.00009057, Avg batch loss: 0.0185, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 411, Step num: 9525, Learning rate: 0.00009057, Avg batch loss: 0.0133, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 412, Step num: 9526, Learning rate: 0.00009056, Avg batch loss: 0.0214, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 413, Step num: 9527, Learning rate: 0.00009056, Avg batch loss: 0.0232, Avg batch acc: 0.9737
Train, Epoch: 7, Batch: 414, Step num: 9528, Learning rate: 0.00009055, Avg batch loss: 0.0210, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 415, Step num: 9529, Learning rate: 0.00009055, Avg batch loss: 0.0164, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 416, Step num: 9530, Learning rate: 0.00009054, Avg batch loss: 0.0196, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 417, Step num: 9531, Learning rate: 0.00009054, Avg batch loss: 0.0155, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 418, Step num: 9532, Learning rate: 0.00009053, Avg batch loss: 0.0166, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 419, Step num: 9533, Learning rate: 0.00009053, Avg batch loss: 0.0167, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 420, Step num: 9534, Learning rate: 0.00009052, Avg batch loss: 0.0227, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 421, Step num: 9535, Learning rate: 0.00009052, Avg batch loss: 0.0252, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 422, Step num: 9536, Learning rate: 0.00009051, Avg batch loss: 0.0149, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 423, Step num: 9537, Learning rate: 0.00009051, Avg batch loss: 0.0243, Avg batch acc: 0.9739
Train, Epoch: 7, Batch: 424, Step num: 9538, Learning rate: 0.00009050, Avg batch loss: 0.0191, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 425, Step num: 9539, Learning rate: 0.00009050, Avg batch loss: 0.0156, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 426, Step num: 9540, Learning rate: 0.00009049, Avg batch loss: 0.0217, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 427, Step num: 9541, Learning rate: 0.00009049, Avg batch loss: 0.0227, Avg batch acc: 0.9773
Train, Epoch: 7, Batch: 428, Step num: 9542, Learning rate: 0.00009048, Avg batch loss: 0.0176, Avg batch acc: 0.9769
Train, Epoch: 7, Batch: 429, Step num: 9543, Learning rate: 0.00009048, Avg batch loss: 0.0265, Avg batch acc: 0.9777
Train, Epoch: 7, Batch: 430, Step num: 9544, Learning rate: 0.00009048, Avg batch loss: 0.0201, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 431, Step num: 9545, Learning rate: 0.00009047, Avg batch loss: 0.0258, Avg batch acc: 0.9763
Train, Epoch: 7, Batch: 432, Step num: 9546, Learning rate: 0.00009047, Avg batch loss: 0.0177, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 433, Step num: 9547, Learning rate: 0.00009046, Avg batch loss: 0.0219, Avg batch acc: 0.9731
Train, Epoch: 7, Batch: 434, Step num: 9548, Learning rate: 0.00009046, Avg batch loss: 0.0181, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 435, Step num: 9549, Learning rate: 0.00009045, Avg batch loss: 0.0164, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 436, Step num: 9550, Learning rate: 0.00009045, Avg batch loss: 0.0197, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 437, Step num: 9551, Learning rate: 0.00009044, Avg batch loss: 0.0142, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 438, Step num: 9552, Learning rate: 0.00009044, Avg batch loss: 0.0182, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 439, Step num: 9553, Learning rate: 0.00009043, Avg batch loss: 0.0145, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 440, Step num: 9554, Learning rate: 0.00009043, Avg batch loss: 0.0159, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 441, Step num: 9555, Learning rate: 0.00009042, Avg batch loss: 0.0164, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 442, Step num: 9556, Learning rate: 0.00009042, Avg batch loss: 0.0167, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 443, Step num: 9557, Learning rate: 0.00009041, Avg batch loss: 0.0176, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 444, Step num: 9558, Learning rate: 0.00009041, Avg batch loss: 0.0336, Avg batch acc: 0.9741
Train, Epoch: 7, Batch: 445, Step num: 9559, Learning rate: 0.00009040, Avg batch loss: 0.0197, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 446, Step num: 9560, Learning rate: 0.00009040, Avg batch loss: 0.0317, Avg batch acc: 0.9766
Train, Epoch: 7, Batch: 447, Step num: 9561, Learning rate: 0.00009039, Avg batch loss: 0.0130, Avg batch acc: 0.9888
Train, Epoch: 7, Batch: 448, Step num: 9562, Learning rate: 0.00009039, Avg batch loss: 0.0185, Avg batch acc: 0.9769
Train, Epoch: 7, Batch: 449, Step num: 9563, Learning rate: 0.00009039, Avg batch loss: 0.0182, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 450, Step num: 9564, Learning rate: 0.00009038, Avg batch loss: 0.0191, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 451, Step num: 9565, Learning rate: 0.00009038, Avg batch loss: 0.0215, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 452, Step num: 9566, Learning rate: 0.00009037, Avg batch loss: 0.0185, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 453, Step num: 9567, Learning rate: 0.00009037, Avg batch loss: 0.0151, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 454, Step num: 9568, Learning rate: 0.00009036, Avg batch loss: 0.0204, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 455, Step num: 9569, Learning rate: 0.00009036, Avg batch loss: 0.0162, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 456, Step num: 9570, Learning rate: 0.00009035, Avg batch loss: 0.0225, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 457, Step num: 9571, Learning rate: 0.00009035, Avg batch loss: 0.0198, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 458, Step num: 9572, Learning rate: 0.00009034, Avg batch loss: 0.0219, Avg batch acc: 0.9766
Train, Epoch: 7, Batch: 459, Step num: 9573, Learning rate: 0.00009034, Avg batch loss: 0.0171, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 460, Step num: 9574, Learning rate: 0.00009033, Avg batch loss: 0.0175, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 461, Step num: 9575, Learning rate: 0.00009033, Avg batch loss: 0.0279, Avg batch acc: 0.9784
Train, Epoch: 7, Batch: 462, Step num: 9576, Learning rate: 0.00009032, Avg batch loss: 0.0179, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 463, Step num: 9577, Learning rate: 0.00009032, Avg batch loss: 0.0166, Avg batch acc: 0.9854
Train, Epoch: 7, Batch: 464, Step num: 9578, Learning rate: 0.00009031, Avg batch loss: 0.0185, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 465, Step num: 9579, Learning rate: 0.00009031, Avg batch loss: 0.0215, Avg batch acc: 0.9784
Train, Epoch: 7, Batch: 466, Step num: 9580, Learning rate: 0.00009031, Avg batch loss: 0.0161, Avg batch acc: 0.9781
Train, Epoch: 7, Batch: 467, Step num: 9581, Learning rate: 0.00009030, Avg batch loss: 0.0191, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 468, Step num: 9582, Learning rate: 0.00009030, Avg batch loss: 0.0174, Avg batch acc: 0.9824
Train, Epoch: 7, Batch: 469, Step num: 9583, Learning rate: 0.00009029, Avg batch loss: 0.0181, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 470, Step num: 9584, Learning rate: 0.00009029, Avg batch loss: 0.0230, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 471, Step num: 9585, Learning rate: 0.00009028, Avg batch loss: 0.0177, Avg batch acc: 0.9785
Train, Epoch: 7, Batch: 472, Step num: 9586, Learning rate: 0.00009028, Avg batch loss: 0.0204, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 473, Step num: 9587, Learning rate: 0.00009027, Avg batch loss: 0.0162, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 474, Step num: 9588, Learning rate: 0.00009027, Avg batch loss: 0.0167, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 475, Step num: 9589, Learning rate: 0.00009026, Avg batch loss: 0.0159, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 476, Step num: 9590, Learning rate: 0.00009026, Avg batch loss: 0.0166, Avg batch acc: 0.9869
Train, Epoch: 7, Batch: 477, Step num: 9591, Learning rate: 0.00009025, Avg batch loss: 0.0149, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 478, Step num: 9592, Learning rate: 0.00009025, Avg batch loss: 0.0180, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 479, Step num: 9593, Learning rate: 0.00009024, Avg batch loss: 0.0150, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 480, Step num: 9594, Learning rate: 0.00009024, Avg batch loss: 0.0243, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 481, Step num: 9595, Learning rate: 0.00009023, Avg batch loss: 0.0250, Avg batch acc: 0.9741
Train, Epoch: 7, Batch: 482, Step num: 9596, Learning rate: 0.00009023, Avg batch loss: 0.0206, Avg batch acc: 0.9752
Train, Epoch: 7, Batch: 483, Step num: 9597, Learning rate: 0.00009023, Avg batch loss: 0.0162, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 484, Step num: 9598, Learning rate: 0.00009022, Avg batch loss: 0.0244, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 485, Step num: 9599, Learning rate: 0.00009022, Avg batch loss: 0.0162, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 486, Step num: 9600, Learning rate: 0.00009021, Avg batch loss: 0.0206, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 487, Step num: 9601, Learning rate: 0.00009021, Avg batch loss: 0.0148, Avg batch acc: 0.9868
Train, Epoch: 7, Batch: 488, Step num: 9602, Learning rate: 0.00009020, Avg batch loss: 0.0191, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 489, Step num: 9603, Learning rate: 0.00009020, Avg batch loss: 0.0186, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 490, Step num: 9604, Learning rate: 0.00009019, Avg batch loss: 0.0181, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 491, Step num: 9605, Learning rate: 0.00009019, Avg batch loss: 0.0167, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 492, Step num: 9606, Learning rate: 0.00009018, Avg batch loss: 0.0180, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 493, Step num: 9607, Learning rate: 0.00009018, Avg batch loss: 0.0197, Avg batch acc: 0.9768
Train, Epoch: 7, Batch: 494, Step num: 9608, Learning rate: 0.00009017, Avg batch loss: 0.0176, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 495, Step num: 9609, Learning rate: 0.00009017, Avg batch loss: 0.0191, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 496, Step num: 9610, Learning rate: 0.00009016, Avg batch loss: 0.0170, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 497, Step num: 9611, Learning rate: 0.00009016, Avg batch loss: 0.0177, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 498, Step num: 9612, Learning rate: 0.00009015, Avg batch loss: 0.0165, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 499, Step num: 9613, Learning rate: 0.00009015, Avg batch loss: 0.0190, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 500, Step num: 9614, Learning rate: 0.00009015, Avg batch loss: 0.0187, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 501, Step num: 9615, Learning rate: 0.00009014, Avg batch loss: 0.0182, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 502, Step num: 9616, Learning rate: 0.00009014, Avg batch loss: 0.0174, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 503, Step num: 9617, Learning rate: 0.00009013, Avg batch loss: 0.0178, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 504, Step num: 9618, Learning rate: 0.00009013, Avg batch loss: 0.0196, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 505, Step num: 9619, Learning rate: 0.00009012, Avg batch loss: 0.0167, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 506, Step num: 9620, Learning rate: 0.00009012, Avg batch loss: 0.0215, Avg batch acc: 0.9767
Train, Epoch: 7, Batch: 507, Step num: 9621, Learning rate: 0.00009011, Avg batch loss: 0.0160, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 508, Step num: 9622, Learning rate: 0.00009011, Avg batch loss: 0.0163, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 509, Step num: 9623, Learning rate: 0.00009010, Avg batch loss: 0.0158, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 510, Step num: 9624, Learning rate: 0.00009010, Avg batch loss: 0.0178, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 511, Step num: 9625, Learning rate: 0.00009009, Avg batch loss: 0.0405, Avg batch acc: 0.9734
Train, Epoch: 7, Batch: 512, Step num: 9626, Learning rate: 0.00009009, Avg batch loss: 0.0208, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 513, Step num: 9627, Learning rate: 0.00009008, Avg batch loss: 0.0175, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 514, Step num: 9628, Learning rate: 0.00009008, Avg batch loss: 0.0209, Avg batch acc: 0.9777
Train, Epoch: 7, Batch: 515, Step num: 9629, Learning rate: 0.00009008, Avg batch loss: 0.0176, Avg batch acc: 0.9801
Train, Epoch: 7, Batch: 516, Step num: 9630, Learning rate: 0.00009007, Avg batch loss: 0.0173, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 517, Step num: 9631, Learning rate: 0.00009007, Avg batch loss: 0.0134, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 518, Step num: 9632, Learning rate: 0.00009006, Avg batch loss: 0.0177, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 519, Step num: 9633, Learning rate: 0.00009006, Avg batch loss: 0.0175, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 520, Step num: 9634, Learning rate: 0.00009005, Avg batch loss: 0.0162, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 521, Step num: 9635, Learning rate: 0.00009005, Avg batch loss: 0.0179, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 522, Step num: 9636, Learning rate: 0.00009004, Avg batch loss: 0.0157, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 523, Step num: 9637, Learning rate: 0.00009004, Avg batch loss: 0.0203, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 524, Step num: 9638, Learning rate: 0.00009003, Avg batch loss: 0.0170, Avg batch acc: 0.9813
Train, Epoch: 7, Batch: 525, Step num: 9639, Learning rate: 0.00009003, Avg batch loss: 0.0266, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 526, Step num: 9640, Learning rate: 0.00009002, Avg batch loss: 0.0145, Avg batch acc: 0.9824
Train, Epoch: 7, Batch: 527, Step num: 9641, Learning rate: 0.00009002, Avg batch loss: 0.0181, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 528, Step num: 9642, Learning rate: 0.00009001, Avg batch loss: 0.0191, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 529, Step num: 9643, Learning rate: 0.00009001, Avg batch loss: 0.0165, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 530, Step num: 9644, Learning rate: 0.00009000, Avg batch loss: 0.0197, Avg batch acc: 0.9740
Train, Epoch: 7, Batch: 531, Step num: 9645, Learning rate: 0.00009000, Avg batch loss: 0.0183, Avg batch acc: 0.9781
Train, Epoch: 7, Batch: 532, Step num: 9646, Learning rate: 0.00009000, Avg batch loss: 0.0181, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 533, Step num: 9647, Learning rate: 0.00008999, Avg batch loss: 0.0176, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 534, Step num: 9648, Learning rate: 0.00008999, Avg batch loss: 0.0197, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 535, Step num: 9649, Learning rate: 0.00008998, Avg batch loss: 0.0168, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 536, Step num: 9650, Learning rate: 0.00008998, Avg batch loss: 0.0169, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 537, Step num: 9651, Learning rate: 0.00008997, Avg batch loss: 0.0176, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 538, Step num: 9652, Learning rate: 0.00008997, Avg batch loss: 0.0165, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 539, Step num: 9653, Learning rate: 0.00008996, Avg batch loss: 0.0203, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 540, Step num: 9654, Learning rate: 0.00008996, Avg batch loss: 0.0206, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 541, Step num: 9655, Learning rate: 0.00008995, Avg batch loss: 0.0227, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 542, Step num: 9656, Learning rate: 0.00008995, Avg batch loss: 0.0151, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 543, Step num: 9657, Learning rate: 0.00008994, Avg batch loss: 0.0240, Avg batch acc: 0.9781
Train, Epoch: 7, Batch: 544, Step num: 9658, Learning rate: 0.00008994, Avg batch loss: 0.0156, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 545, Step num: 9659, Learning rate: 0.00008994, Avg batch loss: 0.0134, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 546, Step num: 9660, Learning rate: 0.00008993, Avg batch loss: 0.0183, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 547, Step num: 9661, Learning rate: 0.00008993, Avg batch loss: 0.0220, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 548, Step num: 9662, Learning rate: 0.00008992, Avg batch loss: 0.0262, Avg batch acc: 0.9766
Train, Epoch: 7, Batch: 549, Step num: 9663, Learning rate: 0.00008992, Avg batch loss: 0.0239, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 550, Step num: 9664, Learning rate: 0.00008991, Avg batch loss: 0.0169, Avg batch acc: 0.9816
Train, Epoch: 7, Batch: 551, Step num: 9665, Learning rate: 0.00008991, Avg batch loss: 0.0200, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 552, Step num: 9666, Learning rate: 0.00008990, Avg batch loss: 0.0195, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 553, Step num: 9667, Learning rate: 0.00008990, Avg batch loss: 0.0178, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 554, Step num: 9668, Learning rate: 0.00008989, Avg batch loss: 0.0321, Avg batch acc: 0.9721
Train, Epoch: 7, Batch: 555, Step num: 9669, Learning rate: 0.00008989, Avg batch loss: 0.0141, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 556, Step num: 9670, Learning rate: 0.00008988, Avg batch loss: 0.0202, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 557, Step num: 9671, Learning rate: 0.00008988, Avg batch loss: 0.0176, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 558, Step num: 9672, Learning rate: 0.00008987, Avg batch loss: 0.0177, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 559, Step num: 9673, Learning rate: 0.00008987, Avg batch loss: 0.0154, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 560, Step num: 9674, Learning rate: 0.00008987, Avg batch loss: 0.0202, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 561, Step num: 9675, Learning rate: 0.00008986, Avg batch loss: 0.0187, Avg batch acc: 0.9836
Train, Epoch: 7, Batch: 562, Step num: 9676, Learning rate: 0.00008986, Avg batch loss: 0.0192, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 563, Step num: 9677, Learning rate: 0.00008985, Avg batch loss: 0.0132, Avg batch acc: 0.9884
Train, Epoch: 7, Batch: 564, Step num: 9678, Learning rate: 0.00008985, Avg batch loss: 0.0156, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 565, Step num: 9679, Learning rate: 0.00008984, Avg batch loss: 0.0209, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 566, Step num: 9680, Learning rate: 0.00008984, Avg batch loss: 0.0151, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 567, Step num: 9681, Learning rate: 0.00008983, Avg batch loss: 0.0259, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 568, Step num: 9682, Learning rate: 0.00008983, Avg batch loss: 0.0174, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 569, Step num: 9683, Learning rate: 0.00008982, Avg batch loss: 0.0453, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 570, Step num: 9684, Learning rate: 0.00008982, Avg batch loss: 0.0181, Avg batch acc: 0.9824
Train, Epoch: 7, Batch: 571, Step num: 9685, Learning rate: 0.00008981, Avg batch loss: 0.0160, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 572, Step num: 9686, Learning rate: 0.00008981, Avg batch loss: 0.0226, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 573, Step num: 9687, Learning rate: 0.00008980, Avg batch loss: 0.0186, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 574, Step num: 9688, Learning rate: 0.00008980, Avg batch loss: 0.0199, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 575, Step num: 9689, Learning rate: 0.00008980, Avg batch loss: 0.0169, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 576, Step num: 9690, Learning rate: 0.00008979, Avg batch loss: 0.0242, Avg batch acc: 0.9767
Train, Epoch: 7, Batch: 577, Step num: 9691, Learning rate: 0.00008979, Avg batch loss: 0.0163, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 578, Step num: 9692, Learning rate: 0.00008978, Avg batch loss: 0.0208, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 579, Step num: 9693, Learning rate: 0.00008978, Avg batch loss: 0.0202, Avg batch acc: 0.9791
Train, Epoch: 7, Batch: 580, Step num: 9694, Learning rate: 0.00008977, Avg batch loss: 0.0324, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 581, Step num: 9695, Learning rate: 0.00008977, Avg batch loss: 0.0156, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 582, Step num: 9696, Learning rate: 0.00008976, Avg batch loss: 0.0227, Avg batch acc: 0.9794
Train, Epoch: 7, Batch: 583, Step num: 9697, Learning rate: 0.00008976, Avg batch loss: 0.0346, Avg batch acc: 0.9753
Train, Epoch: 7, Batch: 584, Step num: 9698, Learning rate: 0.00008975, Avg batch loss: 0.0218, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 585, Step num: 9699, Learning rate: 0.00008975, Avg batch loss: 0.0206, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 586, Step num: 9700, Learning rate: 0.00008974, Avg batch loss: 0.0176, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 587, Step num: 9701, Learning rate: 0.00008974, Avg batch loss: 0.0198, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 588, Step num: 9702, Learning rate: 0.00008974, Avg batch loss: 0.0224, Avg batch acc: 0.9768
Train, Epoch: 7, Batch: 589, Step num: 9703, Learning rate: 0.00008973, Avg batch loss: 0.0162, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 590, Step num: 9704, Learning rate: 0.00008973, Avg batch loss: 0.0203, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 591, Step num: 9705, Learning rate: 0.00008972, Avg batch loss: 0.0201, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 592, Step num: 9706, Learning rate: 0.00008972, Avg batch loss: 0.0198, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 593, Step num: 9707, Learning rate: 0.00008971, Avg batch loss: 0.0200, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 594, Step num: 9708, Learning rate: 0.00008971, Avg batch loss: 0.0177, Avg batch acc: 0.9765
Train, Epoch: 7, Batch: 595, Step num: 9709, Learning rate: 0.00008970, Avg batch loss: 0.0198, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 596, Step num: 9710, Learning rate: 0.00008970, Avg batch loss: 0.0231, Avg batch acc: 0.9776
Train, Epoch: 7, Batch: 597, Step num: 9711, Learning rate: 0.00008969, Avg batch loss: 0.0198, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 598, Step num: 9712, Learning rate: 0.00008969, Avg batch loss: 0.0165, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 599, Step num: 9713, Learning rate: 0.00008968, Avg batch loss: 0.0152, Avg batch acc: 0.9816
Train, Epoch: 7, Batch: 600, Step num: 9714, Learning rate: 0.00008968, Avg batch loss: 0.0201, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 601, Step num: 9715, Learning rate: 0.00008968, Avg batch loss: 0.0141, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 602, Step num: 9716, Learning rate: 0.00008967, Avg batch loss: 0.0175, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 603, Step num: 9717, Learning rate: 0.00008967, Avg batch loss: 0.0203, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 604, Step num: 9718, Learning rate: 0.00008966, Avg batch loss: 0.0137, Avg batch acc: 0.9893
Train, Epoch: 7, Batch: 605, Step num: 9719, Learning rate: 0.00008966, Avg batch loss: 0.0169, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 606, Step num: 9720, Learning rate: 0.00008965, Avg batch loss: 0.0155, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 607, Step num: 9721, Learning rate: 0.00008965, Avg batch loss: 0.0190, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 608, Step num: 9722, Learning rate: 0.00008964, Avg batch loss: 0.0150, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 609, Step num: 9723, Learning rate: 0.00008964, Avg batch loss: 0.0198, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 610, Step num: 9724, Learning rate: 0.00008963, Avg batch loss: 0.0200, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 611, Step num: 9725, Learning rate: 0.00008963, Avg batch loss: 0.0145, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 612, Step num: 9726, Learning rate: 0.00008962, Avg batch loss: 0.0163, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 613, Step num: 9727, Learning rate: 0.00008962, Avg batch loss: 0.0154, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 614, Step num: 9728, Learning rate: 0.00008962, Avg batch loss: 0.0179, Avg batch acc: 0.9780
Train, Epoch: 7, Batch: 615, Step num: 9729, Learning rate: 0.00008961, Avg batch loss: 0.0177, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 616, Step num: 9730, Learning rate: 0.00008961, Avg batch loss: 0.0220, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 617, Step num: 9731, Learning rate: 0.00008960, Avg batch loss: 0.0190, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 618, Step num: 9732, Learning rate: 0.00008960, Avg batch loss: 0.0212, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 619, Step num: 9733, Learning rate: 0.00008959, Avg batch loss: 0.0156, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 620, Step num: 9734, Learning rate: 0.00008959, Avg batch loss: 0.0158, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 621, Step num: 9735, Learning rate: 0.00008958, Avg batch loss: 0.0179, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 622, Step num: 9736, Learning rate: 0.00008958, Avg batch loss: 0.0154, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 623, Step num: 9737, Learning rate: 0.00008957, Avg batch loss: 0.0158, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 624, Step num: 9738, Learning rate: 0.00008957, Avg batch loss: 0.0201, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 625, Step num: 9739, Learning rate: 0.00008956, Avg batch loss: 0.0150, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 626, Step num: 9740, Learning rate: 0.00008956, Avg batch loss: 0.0175, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 627, Step num: 9741, Learning rate: 0.00008956, Avg batch loss: 0.0152, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 628, Step num: 9742, Learning rate: 0.00008955, Avg batch loss: 0.0181, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 629, Step num: 9743, Learning rate: 0.00008955, Avg batch loss: 0.0156, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 630, Step num: 9744, Learning rate: 0.00008954, Avg batch loss: 0.0167, Avg batch acc: 0.9824
Train, Epoch: 7, Batch: 631, Step num: 9745, Learning rate: 0.00008954, Avg batch loss: 0.0199, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 632, Step num: 9746, Learning rate: 0.00008953, Avg batch loss: 0.0175, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 633, Step num: 9747, Learning rate: 0.00008953, Avg batch loss: 0.0154, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 634, Step num: 9748, Learning rate: 0.00008952, Avg batch loss: 0.0257, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 635, Step num: 9749, Learning rate: 0.00008952, Avg batch loss: 0.0176, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 636, Step num: 9750, Learning rate: 0.00008951, Avg batch loss: 0.0149, Avg batch acc: 0.9876
Train, Epoch: 7, Batch: 637, Step num: 9751, Learning rate: 0.00008951, Avg batch loss: 0.0164, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 638, Step num: 9752, Learning rate: 0.00008951, Avg batch loss: 0.0189, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 639, Step num: 9753, Learning rate: 0.00008950, Avg batch loss: 0.0144, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 640, Step num: 9754, Learning rate: 0.00008950, Avg batch loss: 0.0171, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 641, Step num: 9755, Learning rate: 0.00008949, Avg batch loss: 0.0169, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 642, Step num: 9756, Learning rate: 0.00008949, Avg batch loss: 0.0271, Avg batch acc: 0.9772
Train, Epoch: 7, Batch: 643, Step num: 9757, Learning rate: 0.00008948, Avg batch loss: 0.0154, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 644, Step num: 9758, Learning rate: 0.00008948, Avg batch loss: 0.0166, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 645, Step num: 9759, Learning rate: 0.00008947, Avg batch loss: 0.0165, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 646, Step num: 9760, Learning rate: 0.00008947, Avg batch loss: 0.0230, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 647, Step num: 9761, Learning rate: 0.00008946, Avg batch loss: 0.0128, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 648, Step num: 9762, Learning rate: 0.00008946, Avg batch loss: 0.0185, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 649, Step num: 9763, Learning rate: 0.00008945, Avg batch loss: 0.0168, Avg batch acc: 0.9836
Train, Epoch: 7, Batch: 650, Step num: 9764, Learning rate: 0.00008945, Avg batch loss: 0.0191, Avg batch acc: 0.9787
Train, Epoch: 7, Batch: 651, Step num: 9765, Learning rate: 0.00008945, Avg batch loss: 0.0201, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 652, Step num: 9766, Learning rate: 0.00008944, Avg batch loss: 0.0156, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 653, Step num: 9767, Learning rate: 0.00008944, Avg batch loss: 0.0159, Avg batch acc: 0.9870
Train, Epoch: 7, Batch: 654, Step num: 9768, Learning rate: 0.00008943, Avg batch loss: 0.0138, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 655, Step num: 9769, Learning rate: 0.00008943, Avg batch loss: 0.0177, Avg batch acc: 0.9770
Train, Epoch: 7, Batch: 656, Step num: 9770, Learning rate: 0.00008942, Avg batch loss: 0.0170, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 657, Step num: 9771, Learning rate: 0.00008942, Avg batch loss: 0.0208, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 658, Step num: 9772, Learning rate: 0.00008941, Avg batch loss: 0.0153, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 659, Step num: 9773, Learning rate: 0.00008941, Avg batch loss: 0.0196, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 660, Step num: 9774, Learning rate: 0.00008940, Avg batch loss: 0.0182, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 661, Step num: 9775, Learning rate: 0.00008940, Avg batch loss: 0.0191, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 662, Step num: 9776, Learning rate: 0.00008940, Avg batch loss: 0.0169, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 663, Step num: 9777, Learning rate: 0.00008939, Avg batch loss: 0.0157, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 664, Step num: 9778, Learning rate: 0.00008939, Avg batch loss: 0.0323, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 665, Step num: 9779, Learning rate: 0.00008938, Avg batch loss: 0.0159, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 666, Step num: 9780, Learning rate: 0.00008938, Avg batch loss: 0.0241, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 667, Step num: 9781, Learning rate: 0.00008937, Avg batch loss: 0.0132, Avg batch acc: 0.9891
Train, Epoch: 7, Batch: 668, Step num: 9782, Learning rate: 0.00008937, Avg batch loss: 0.0177, Avg batch acc: 0.9847
Train, Epoch: 7, Batch: 669, Step num: 9783, Learning rate: 0.00008936, Avg batch loss: 0.0270, Avg batch acc: 0.9766
Train, Epoch: 7, Batch: 670, Step num: 9784, Learning rate: 0.00008936, Avg batch loss: 0.0163, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 671, Step num: 9785, Learning rate: 0.00008935, Avg batch loss: 0.0205, Avg batch acc: 0.9777
Train, Epoch: 7, Batch: 672, Step num: 9786, Learning rate: 0.00008935, Avg batch loss: 0.0154, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 673, Step num: 9787, Learning rate: 0.00008934, Avg batch loss: 0.0176, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 674, Step num: 9788, Learning rate: 0.00008934, Avg batch loss: 0.0152, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 675, Step num: 9789, Learning rate: 0.00008934, Avg batch loss: 0.0165, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 676, Step num: 9790, Learning rate: 0.00008933, Avg batch loss: 0.0167, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 677, Step num: 9791, Learning rate: 0.00008933, Avg batch loss: 0.0458, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 678, Step num: 9792, Learning rate: 0.00008932, Avg batch loss: 0.0154, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 679, Step num: 9793, Learning rate: 0.00008932, Avg batch loss: 0.0323, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 680, Step num: 9794, Learning rate: 0.00008931, Avg batch loss: 0.0237, Avg batch acc: 0.9772
Train, Epoch: 7, Batch: 681, Step num: 9795, Learning rate: 0.00008931, Avg batch loss: 0.0194, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 682, Step num: 9796, Learning rate: 0.00008930, Avg batch loss: 0.0199, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 683, Step num: 9797, Learning rate: 0.00008930, Avg batch loss: 0.0159, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 684, Step num: 9798, Learning rate: 0.00008929, Avg batch loss: 0.0170, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 685, Step num: 9799, Learning rate: 0.00008929, Avg batch loss: 0.0206, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 686, Step num: 9800, Learning rate: 0.00008929, Avg batch loss: 0.0211, Avg batch acc: 0.9781
Train, Epoch: 7, Batch: 687, Step num: 9801, Learning rate: 0.00008928, Avg batch loss: 0.0239, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 688, Step num: 9802, Learning rate: 0.00008928, Avg batch loss: 0.0254, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 689, Step num: 9803, Learning rate: 0.00008927, Avg batch loss: 0.0184, Avg batch acc: 0.9785
Train, Epoch: 7, Batch: 690, Step num: 9804, Learning rate: 0.00008927, Avg batch loss: 0.0156, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 691, Step num: 9805, Learning rate: 0.00008926, Avg batch loss: 0.0195, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 692, Step num: 9806, Learning rate: 0.00008926, Avg batch loss: 0.0203, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 693, Step num: 9807, Learning rate: 0.00008925, Avg batch loss: 0.0194, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 694, Step num: 9808, Learning rate: 0.00008925, Avg batch loss: 0.0269, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 695, Step num: 9809, Learning rate: 0.00008924, Avg batch loss: 0.0183, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 696, Step num: 9810, Learning rate: 0.00008924, Avg batch loss: 0.0189, Avg batch acc: 0.9787
Train, Epoch: 7, Batch: 697, Step num: 9811, Learning rate: 0.00008924, Avg batch loss: 0.0196, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 698, Step num: 9812, Learning rate: 0.00008923, Avg batch loss: 0.0203, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 699, Step num: 9813, Learning rate: 0.00008923, Avg batch loss: 0.0180, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 700, Step num: 9814, Learning rate: 0.00008922, Avg batch loss: 0.0183, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 701, Step num: 9815, Learning rate: 0.00008922, Avg batch loss: 0.0217, Avg batch acc: 0.9740
Train, Epoch: 7, Batch: 702, Step num: 9816, Learning rate: 0.00008921, Avg batch loss: 0.0222, Avg batch acc: 0.9767
Train, Epoch: 7, Batch: 703, Step num: 9817, Learning rate: 0.00008921, Avg batch loss: 0.0226, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 704, Step num: 9818, Learning rate: 0.00008920, Avg batch loss: 0.0152, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 705, Step num: 9819, Learning rate: 0.00008920, Avg batch loss: 0.0160, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 706, Step num: 9820, Learning rate: 0.00008919, Avg batch loss: 0.0152, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 707, Step num: 9821, Learning rate: 0.00008919, Avg batch loss: 0.0167, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 708, Step num: 9822, Learning rate: 0.00008919, Avg batch loss: 0.0192, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 709, Step num: 9823, Learning rate: 0.00008918, Avg batch loss: 0.0172, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 710, Step num: 9824, Learning rate: 0.00008918, Avg batch loss: 0.0164, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 711, Step num: 9825, Learning rate: 0.00008917, Avg batch loss: 0.0176, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 712, Step num: 9826, Learning rate: 0.00008917, Avg batch loss: 0.0154, Avg batch acc: 0.9816
Train, Epoch: 7, Batch: 713, Step num: 9827, Learning rate: 0.00008916, Avg batch loss: 0.0150, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 714, Step num: 9828, Learning rate: 0.00008916, Avg batch loss: 0.0178, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 715, Step num: 9829, Learning rate: 0.00008915, Avg batch loss: 0.0178, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 716, Step num: 9830, Learning rate: 0.00008915, Avg batch loss: 0.0160, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 717, Step num: 9831, Learning rate: 0.00008914, Avg batch loss: 0.0113, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 718, Step num: 9832, Learning rate: 0.00008914, Avg batch loss: 0.0168, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 719, Step num: 9833, Learning rate: 0.00008914, Avg batch loss: 0.0140, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 720, Step num: 9834, Learning rate: 0.00008913, Avg batch loss: 0.0144, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 721, Step num: 9835, Learning rate: 0.00008913, Avg batch loss: 0.0184, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 722, Step num: 9836, Learning rate: 0.00008912, Avg batch loss: 0.0183, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 723, Step num: 9837, Learning rate: 0.00008912, Avg batch loss: 0.0286, Avg batch acc: 0.9790
Train, Epoch: 7, Batch: 724, Step num: 9838, Learning rate: 0.00008911, Avg batch loss: 0.0167, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 725, Step num: 9839, Learning rate: 0.00008911, Avg batch loss: 0.0182, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 726, Step num: 9840, Learning rate: 0.00008910, Avg batch loss: 0.0164, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 727, Step num: 9841, Learning rate: 0.00008910, Avg batch loss: 0.0152, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 728, Step num: 9842, Learning rate: 0.00008910, Avg batch loss: 0.0179, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 729, Step num: 9843, Learning rate: 0.00008909, Avg batch loss: 0.0136, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 730, Step num: 9844, Learning rate: 0.00008909, Avg batch loss: 0.0159, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 731, Step num: 9845, Learning rate: 0.00008908, Avg batch loss: 0.0154, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 732, Step num: 9846, Learning rate: 0.00008908, Avg batch loss: 0.0361, Avg batch acc: 0.9773
Train, Epoch: 7, Batch: 733, Step num: 9847, Learning rate: 0.00008907, Avg batch loss: 0.0191, Avg batch acc: 0.9847
Train, Epoch: 7, Batch: 734, Step num: 9848, Learning rate: 0.00008907, Avg batch loss: 0.0201, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 735, Step num: 9849, Learning rate: 0.00008906, Avg batch loss: 0.0165, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 736, Step num: 9850, Learning rate: 0.00008906, Avg batch loss: 0.0183, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 737, Step num: 9851, Learning rate: 0.00008905, Avg batch loss: 0.0168, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 738, Step num: 9852, Learning rate: 0.00008905, Avg batch loss: 0.0214, Avg batch acc: 0.9775
Train, Epoch: 7, Batch: 739, Step num: 9853, Learning rate: 0.00008905, Avg batch loss: 0.0181, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 740, Step num: 9854, Learning rate: 0.00008904, Avg batch loss: 0.0274, Avg batch acc: 0.9759
Train, Epoch: 7, Batch: 741, Step num: 9855, Learning rate: 0.00008904, Avg batch loss: 0.0189, Avg batch acc: 0.9836
Train, Epoch: 7, Batch: 742, Step num: 9856, Learning rate: 0.00008903, Avg batch loss: 0.0227, Avg batch acc: 0.9801
Train, Epoch: 7, Batch: 743, Step num: 9857, Learning rate: 0.00008903, Avg batch loss: 0.0181, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 744, Step num: 9858, Learning rate: 0.00008902, Avg batch loss: 0.0159, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 745, Step num: 9859, Learning rate: 0.00008902, Avg batch loss: 0.0226, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 746, Step num: 9860, Learning rate: 0.00008901, Avg batch loss: 0.0183, Avg batch acc: 0.9857
Train, Epoch: 7, Batch: 747, Step num: 9861, Learning rate: 0.00008901, Avg batch loss: 0.0122, Avg batch acc: 0.9879
Train, Epoch: 7, Batch: 748, Step num: 9862, Learning rate: 0.00008900, Avg batch loss: 0.0211, Avg batch acc: 0.9796
Train, Epoch: 7, Batch: 749, Step num: 9863, Learning rate: 0.00008900, Avg batch loss: 0.0171, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 750, Step num: 9864, Learning rate: 0.00008900, Avg batch loss: 0.0173, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 751, Step num: 9865, Learning rate: 0.00008899, Avg batch loss: 0.0170, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 752, Step num: 9866, Learning rate: 0.00008899, Avg batch loss: 0.0200, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 753, Step num: 9867, Learning rate: 0.00008898, Avg batch loss: 0.0154, Avg batch acc: 0.9847
Train, Epoch: 7, Batch: 754, Step num: 9868, Learning rate: 0.00008898, Avg batch loss: 0.0177, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 755, Step num: 9869, Learning rate: 0.00008897, Avg batch loss: 0.0200, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 756, Step num: 9870, Learning rate: 0.00008897, Avg batch loss: 0.0203, Avg batch acc: 0.9769
Train, Epoch: 7, Batch: 757, Step num: 9871, Learning rate: 0.00008896, Avg batch loss: 0.0173, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 758, Step num: 9872, Learning rate: 0.00008896, Avg batch loss: 0.0161, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 759, Step num: 9873, Learning rate: 0.00008896, Avg batch loss: 0.0192, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 760, Step num: 9874, Learning rate: 0.00008895, Avg batch loss: 0.0321, Avg batch acc: 0.9766
Train, Epoch: 7, Batch: 761, Step num: 9875, Learning rate: 0.00008895, Avg batch loss: 0.0120, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 762, Step num: 9876, Learning rate: 0.00008894, Avg batch loss: 0.0192, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 763, Step num: 9877, Learning rate: 0.00008894, Avg batch loss: 0.0166, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 764, Step num: 9878, Learning rate: 0.00008893, Avg batch loss: 0.0179, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 765, Step num: 9879, Learning rate: 0.00008893, Avg batch loss: 0.0231, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 766, Step num: 9880, Learning rate: 0.00008892, Avg batch loss: 0.0453, Avg batch acc: 0.9732
Train, Epoch: 7, Batch: 767, Step num: 9881, Learning rate: 0.00008892, Avg batch loss: 0.0153, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 768, Step num: 9882, Learning rate: 0.00008891, Avg batch loss: 0.0142, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 769, Step num: 9883, Learning rate: 0.00008891, Avg batch loss: 0.0217, Avg batch acc: 0.9824
Train, Epoch: 7, Batch: 770, Step num: 9884, Learning rate: 0.00008891, Avg batch loss: 0.0176, Avg batch acc: 0.9785
Train, Epoch: 7, Batch: 771, Step num: 9885, Learning rate: 0.00008890, Avg batch loss: 0.0161, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 772, Step num: 9886, Learning rate: 0.00008890, Avg batch loss: 0.0143, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 773, Step num: 9887, Learning rate: 0.00008889, Avg batch loss: 0.0224, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 774, Step num: 9888, Learning rate: 0.00008889, Avg batch loss: 0.0182, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 775, Step num: 9889, Learning rate: 0.00008888, Avg batch loss: 0.0147, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 776, Step num: 9890, Learning rate: 0.00008888, Avg batch loss: 0.0185, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 777, Step num: 9891, Learning rate: 0.00008887, Avg batch loss: 0.0169, Avg batch acc: 0.9779
Train, Epoch: 7, Batch: 778, Step num: 9892, Learning rate: 0.00008887, Avg batch loss: 0.0174, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 779, Step num: 9893, Learning rate: 0.00008887, Avg batch loss: 0.0335, Avg batch acc: 0.9794
Train, Epoch: 7, Batch: 780, Step num: 9894, Learning rate: 0.00008886, Avg batch loss: 0.0151, Avg batch acc: 0.9871
Train, Epoch: 7, Batch: 781, Step num: 9895, Learning rate: 0.00008886, Avg batch loss: 0.0199, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 782, Step num: 9896, Learning rate: 0.00008885, Avg batch loss: 0.0174, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 783, Step num: 9897, Learning rate: 0.00008885, Avg batch loss: 0.0218, Avg batch acc: 0.9759
Train, Epoch: 7, Batch: 784, Step num: 9898, Learning rate: 0.00008884, Avg batch loss: 0.0172, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 785, Step num: 9899, Learning rate: 0.00008884, Avg batch loss: 0.0209, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 786, Step num: 9900, Learning rate: 0.00008883, Avg batch loss: 0.0335, Avg batch acc: 0.9712
Train, Epoch: 7, Batch: 787, Step num: 9901, Learning rate: 0.00008883, Avg batch loss: 0.0185, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 788, Step num: 9902, Learning rate: 0.00008882, Avg batch loss: 0.0201, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 789, Step num: 9903, Learning rate: 0.00008882, Avg batch loss: 0.0155, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 790, Step num: 9904, Learning rate: 0.00008882, Avg batch loss: 0.0516, Avg batch acc: 0.9772
Train, Epoch: 7, Batch: 791, Step num: 9905, Learning rate: 0.00008881, Avg batch loss: 0.0134, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 792, Step num: 9906, Learning rate: 0.00008881, Avg batch loss: 0.0189, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 793, Step num: 9907, Learning rate: 0.00008880, Avg batch loss: 0.0218, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 794, Step num: 9908, Learning rate: 0.00008880, Avg batch loss: 0.0172, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 795, Step num: 9909, Learning rate: 0.00008879, Avg batch loss: 0.0168, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 796, Step num: 9910, Learning rate: 0.00008879, Avg batch loss: 0.0171, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 797, Step num: 9911, Learning rate: 0.00008878, Avg batch loss: 0.0219, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 798, Step num: 9912, Learning rate: 0.00008878, Avg batch loss: 0.0158, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 799, Step num: 9913, Learning rate: 0.00008878, Avg batch loss: 0.0211, Avg batch acc: 0.9777
Train, Epoch: 7, Batch: 800, Step num: 9914, Learning rate: 0.00008877, Avg batch loss: 0.0163, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 801, Step num: 9915, Learning rate: 0.00008877, Avg batch loss: 0.0208, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 802, Step num: 9916, Learning rate: 0.00008876, Avg batch loss: 0.0172, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 803, Step num: 9917, Learning rate: 0.00008876, Avg batch loss: 0.0170, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 804, Step num: 9918, Learning rate: 0.00008875, Avg batch loss: 0.0162, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 805, Step num: 9919, Learning rate: 0.00008875, Avg batch loss: 0.0194, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 806, Step num: 9920, Learning rate: 0.00008874, Avg batch loss: 0.0179, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 807, Step num: 9921, Learning rate: 0.00008874, Avg batch loss: 0.0153, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 808, Step num: 9922, Learning rate: 0.00008874, Avg batch loss: 0.0159, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 809, Step num: 9923, Learning rate: 0.00008873, Avg batch loss: 0.0134, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 810, Step num: 9924, Learning rate: 0.00008873, Avg batch loss: 0.0182, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 811, Step num: 9925, Learning rate: 0.00008872, Avg batch loss: 0.0158, Avg batch acc: 0.9877
Train, Epoch: 7, Batch: 812, Step num: 9926, Learning rate: 0.00008872, Avg batch loss: 0.0178, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 813, Step num: 9927, Learning rate: 0.00008871, Avg batch loss: 0.0159, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 814, Step num: 9928, Learning rate: 0.00008871, Avg batch loss: 0.0192, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 815, Step num: 9929, Learning rate: 0.00008870, Avg batch loss: 0.0171, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 816, Step num: 9930, Learning rate: 0.00008870, Avg batch loss: 0.0155, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 817, Step num: 9931, Learning rate: 0.00008869, Avg batch loss: 0.0164, Avg batch acc: 0.9836
Train, Epoch: 7, Batch: 818, Step num: 9932, Learning rate: 0.00008869, Avg batch loss: 0.0156, Avg batch acc: 0.9854
Train, Epoch: 7, Batch: 819, Step num: 9933, Learning rate: 0.00008869, Avg batch loss: 0.0175, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 820, Step num: 9934, Learning rate: 0.00008868, Avg batch loss: 0.0167, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 821, Step num: 9935, Learning rate: 0.00008868, Avg batch loss: 0.0151, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 822, Step num: 9936, Learning rate: 0.00008867, Avg batch loss: 0.0146, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 823, Step num: 9937, Learning rate: 0.00008867, Avg batch loss: 0.0190, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 824, Step num: 9938, Learning rate: 0.00008866, Avg batch loss: 0.0155, Avg batch acc: 0.9813
Train, Epoch: 7, Batch: 825, Step num: 9939, Learning rate: 0.00008866, Avg batch loss: 0.0133, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 826, Step num: 9940, Learning rate: 0.00008865, Avg batch loss: 0.0203, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 827, Step num: 9941, Learning rate: 0.00008865, Avg batch loss: 0.0140, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 828, Step num: 9942, Learning rate: 0.00008865, Avg batch loss: 0.0191, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 829, Step num: 9943, Learning rate: 0.00008864, Avg batch loss: 0.0161, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 830, Step num: 9944, Learning rate: 0.00008864, Avg batch loss: 0.0147, Avg batch acc: 0.9839
Train, Epoch: 7, Batch: 831, Step num: 9945, Learning rate: 0.00008863, Avg batch loss: 0.0125, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 832, Step num: 9946, Learning rate: 0.00008863, Avg batch loss: 0.0219, Avg batch acc: 0.9774
Train, Epoch: 7, Batch: 833, Step num: 9947, Learning rate: 0.00008862, Avg batch loss: 0.0266, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 834, Step num: 9948, Learning rate: 0.00008862, Avg batch loss: 0.0181, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 835, Step num: 9949, Learning rate: 0.00008861, Avg batch loss: 0.0122, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 836, Step num: 9950, Learning rate: 0.00008861, Avg batch loss: 0.0144, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 837, Step num: 9951, Learning rate: 0.00008861, Avg batch loss: 0.0154, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 838, Step num: 9952, Learning rate: 0.00008860, Avg batch loss: 0.0160, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 839, Step num: 9953, Learning rate: 0.00008860, Avg batch loss: 0.0152, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 840, Step num: 9954, Learning rate: 0.00008859, Avg batch loss: 0.0144, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 841, Step num: 9955, Learning rate: 0.00008859, Avg batch loss: 0.0136, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 842, Step num: 9956, Learning rate: 0.00008858, Avg batch loss: 0.0166, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 843, Step num: 9957, Learning rate: 0.00008858, Avg batch loss: 0.0211, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 844, Step num: 9958, Learning rate: 0.00008857, Avg batch loss: 0.0212, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 845, Step num: 9959, Learning rate: 0.00008857, Avg batch loss: 0.0151, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 846, Step num: 9960, Learning rate: 0.00008857, Avg batch loss: 0.0223, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 847, Step num: 9961, Learning rate: 0.00008856, Avg batch loss: 0.0164, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 848, Step num: 9962, Learning rate: 0.00008856, Avg batch loss: 0.0159, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 849, Step num: 9963, Learning rate: 0.00008855, Avg batch loss: 0.0158, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 850, Step num: 9964, Learning rate: 0.00008855, Avg batch loss: 0.0136, Avg batch acc: 0.9877
Train, Epoch: 7, Batch: 851, Step num: 9965, Learning rate: 0.00008854, Avg batch loss: 0.0123, Avg batch acc: 0.9883
Train, Epoch: 7, Batch: 852, Step num: 9966, Learning rate: 0.00008854, Avg batch loss: 0.0176, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 853, Step num: 9967, Learning rate: 0.00008853, Avg batch loss: 0.0169, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 854, Step num: 9968, Learning rate: 0.00008853, Avg batch loss: 0.0170, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 855, Step num: 9969, Learning rate: 0.00008853, Avg batch loss: 0.0158, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 856, Step num: 9970, Learning rate: 0.00008852, Avg batch loss: 0.0154, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 857, Step num: 9971, Learning rate: 0.00008852, Avg batch loss: 0.0123, Avg batch acc: 0.9886
Train, Epoch: 7, Batch: 858, Step num: 9972, Learning rate: 0.00008851, Avg batch loss: 0.0186, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 859, Step num: 9973, Learning rate: 0.00008851, Avg batch loss: 0.0176, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 860, Step num: 9974, Learning rate: 0.00008850, Avg batch loss: 0.0196, Avg batch acc: 0.9816
Train, Epoch: 7, Batch: 861, Step num: 9975, Learning rate: 0.00008850, Avg batch loss: 0.0151, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 862, Step num: 9976, Learning rate: 0.00008849, Avg batch loss: 0.0189, Avg batch acc: 0.9764
Train, Epoch: 7, Batch: 863, Step num: 9977, Learning rate: 0.00008849, Avg batch loss: 0.0196, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 864, Step num: 9978, Learning rate: 0.00008849, Avg batch loss: 0.0171, Avg batch acc: 0.9871
Train, Epoch: 7, Batch: 865, Step num: 9979, Learning rate: 0.00008848, Avg batch loss: 0.0167, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 866, Step num: 9980, Learning rate: 0.00008848, Avg batch loss: 0.0149, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 867, Step num: 9981, Learning rate: 0.00008847, Avg batch loss: 0.0224, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 868, Step num: 9982, Learning rate: 0.00008847, Avg batch loss: 0.0182, Avg batch acc: 0.9775
Train, Epoch: 7, Batch: 869, Step num: 9983, Learning rate: 0.00008846, Avg batch loss: 0.0161, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 870, Step num: 9984, Learning rate: 0.00008846, Avg batch loss: 0.0190, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 871, Step num: 9985, Learning rate: 0.00008845, Avg batch loss: 0.0187, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 872, Step num: 9986, Learning rate: 0.00008845, Avg batch loss: 0.0200, Avg batch acc: 0.9768
Train, Epoch: 7, Batch: 873, Step num: 9987, Learning rate: 0.00008845, Avg batch loss: 0.0142, Avg batch acc: 0.9867
Train, Epoch: 7, Batch: 874, Step num: 9988, Learning rate: 0.00008844, Avg batch loss: 0.0171, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 875, Step num: 9989, Learning rate: 0.00008844, Avg batch loss: 0.0140, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 876, Step num: 9990, Learning rate: 0.00008843, Avg batch loss: 0.0145, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 877, Step num: 9991, Learning rate: 0.00008843, Avg batch loss: 0.0187, Avg batch acc: 0.9775
Train, Epoch: 7, Batch: 878, Step num: 9992, Learning rate: 0.00008842, Avg batch loss: 0.0174, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 879, Step num: 9993, Learning rate: 0.00008842, Avg batch loss: 0.0146, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 880, Step num: 9994, Learning rate: 0.00008841, Avg batch loss: 0.0187, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 881, Step num: 9995, Learning rate: 0.00008841, Avg batch loss: 0.0484, Avg batch acc: 0.9785
Train, Epoch: 7, Batch: 882, Step num: 9996, Learning rate: 0.00008841, Avg batch loss: 0.0121, Avg batch acc: 0.9870
Train, Epoch: 7, Batch: 883, Step num: 9997, Learning rate: 0.00008840, Avg batch loss: 0.0144, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 884, Step num: 9998, Learning rate: 0.00008840, Avg batch loss: 0.0186, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 885, Step num: 9999, Learning rate: 0.00008839, Avg batch loss: 0.0177, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 886, Step num: 10000, Learning rate: 0.00008839, Avg batch loss: 0.0187, Avg batch acc: 0.9771
Train, Epoch: 7, Batch: 887, Step num: 10001, Learning rate: 0.00008838, Avg batch loss: 0.0162, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 888, Step num: 10002, Learning rate: 0.00008838, Avg batch loss: 0.0161, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 889, Step num: 10003, Learning rate: 0.00008838, Avg batch loss: 0.0186, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 890, Step num: 10004, Learning rate: 0.00008837, Avg batch loss: 0.0166, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 891, Step num: 10005, Learning rate: 0.00008837, Avg batch loss: 0.0139, Avg batch acc: 0.9816
Train, Epoch: 7, Batch: 892, Step num: 10006, Learning rate: 0.00008836, Avg batch loss: 0.0134, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 893, Step num: 10007, Learning rate: 0.00008836, Avg batch loss: 0.0152, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 894, Step num: 10008, Learning rate: 0.00008835, Avg batch loss: 0.0180, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 895, Step num: 10009, Learning rate: 0.00008835, Avg batch loss: 0.0177, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 896, Step num: 10010, Learning rate: 0.00008834, Avg batch loss: 0.0148, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 897, Step num: 10011, Learning rate: 0.00008834, Avg batch loss: 0.0193, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 898, Step num: 10012, Learning rate: 0.00008834, Avg batch loss: 0.0116, Avg batch acc: 0.9871
Train, Epoch: 7, Batch: 899, Step num: 10013, Learning rate: 0.00008833, Avg batch loss: 0.0193, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 900, Step num: 10014, Learning rate: 0.00008833, Avg batch loss: 0.0146, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 901, Step num: 10015, Learning rate: 0.00008832, Avg batch loss: 0.0158, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 902, Step num: 10016, Learning rate: 0.00008832, Avg batch loss: 0.0146, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 903, Step num: 10017, Learning rate: 0.00008831, Avg batch loss: 0.0153, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 904, Step num: 10018, Learning rate: 0.00008831, Avg batch loss: 0.0147, Avg batch acc: 0.9871
Train, Epoch: 7, Batch: 905, Step num: 10019, Learning rate: 0.00008830, Avg batch loss: 0.0131, Avg batch acc: 0.9883
Train, Epoch: 7, Batch: 906, Step num: 10020, Learning rate: 0.00008830, Avg batch loss: 0.0204, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 907, Step num: 10021, Learning rate: 0.00008830, Avg batch loss: 0.0152, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 908, Step num: 10022, Learning rate: 0.00008829, Avg batch loss: 0.0120, Avg batch acc: 0.9887
Train, Epoch: 7, Batch: 909, Step num: 10023, Learning rate: 0.00008829, Avg batch loss: 0.0185, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 910, Step num: 10024, Learning rate: 0.00008828, Avg batch loss: 0.0164, Avg batch acc: 0.9839
Train, Epoch: 7, Batch: 911, Step num: 10025, Learning rate: 0.00008828, Avg batch loss: 0.0156, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 912, Step num: 10026, Learning rate: 0.00008827, Avg batch loss: 0.0148, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 913, Step num: 10027, Learning rate: 0.00008827, Avg batch loss: 0.0186, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 914, Step num: 10028, Learning rate: 0.00008826, Avg batch loss: 0.0204, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 915, Step num: 10029, Learning rate: 0.00008826, Avg batch loss: 0.0128, Avg batch acc: 0.9877
Train, Epoch: 7, Batch: 916, Step num: 10030, Learning rate: 0.00008826, Avg batch loss: 0.0161, Avg batch acc: 0.9801
Train, Epoch: 7, Batch: 917, Step num: 10031, Learning rate: 0.00008825, Avg batch loss: 0.0153, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 918, Step num: 10032, Learning rate: 0.00008825, Avg batch loss: 0.0177, Avg batch acc: 0.9813
Train, Epoch: 7, Batch: 919, Step num: 10033, Learning rate: 0.00008824, Avg batch loss: 0.0143, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 920, Step num: 10034, Learning rate: 0.00008824, Avg batch loss: 0.0153, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 921, Step num: 10035, Learning rate: 0.00008823, Avg batch loss: 0.0180, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 922, Step num: 10036, Learning rate: 0.00008823, Avg batch loss: 0.0193, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 923, Step num: 10037, Learning rate: 0.00008823, Avg batch loss: 0.0151, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 924, Step num: 10038, Learning rate: 0.00008822, Avg batch loss: 0.0230, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 925, Step num: 10039, Learning rate: 0.00008822, Avg batch loss: 0.0146, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 926, Step num: 10040, Learning rate: 0.00008821, Avg batch loss: 0.0167, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 927, Step num: 10041, Learning rate: 0.00008821, Avg batch loss: 0.0183, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 928, Step num: 10042, Learning rate: 0.00008820, Avg batch loss: 0.0177, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 929, Step num: 10043, Learning rate: 0.00008820, Avg batch loss: 0.0151, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 930, Step num: 10044, Learning rate: 0.00008819, Avg batch loss: 0.0128, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 931, Step num: 10045, Learning rate: 0.00008819, Avg batch loss: 0.0195, Avg batch acc: 0.9788
Train, Epoch: 7, Batch: 932, Step num: 10046, Learning rate: 0.00008819, Avg batch loss: 0.0300, Avg batch acc: 0.9750
Train, Epoch: 7, Batch: 933, Step num: 10047, Learning rate: 0.00008818, Avg batch loss: 0.0202, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 934, Step num: 10048, Learning rate: 0.00008818, Avg batch loss: 0.0141, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 935, Step num: 10049, Learning rate: 0.00008817, Avg batch loss: 0.0181, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 936, Step num: 10050, Learning rate: 0.00008817, Avg batch loss: 0.0219, Avg batch acc: 0.9778
Train, Epoch: 7, Batch: 937, Step num: 10051, Learning rate: 0.00008816, Avg batch loss: 0.0312, Avg batch acc: 0.9782
Train, Epoch: 7, Batch: 938, Step num: 10052, Learning rate: 0.00008816, Avg batch loss: 0.0149, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 939, Step num: 10053, Learning rate: 0.00008816, Avg batch loss: 0.0154, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 940, Step num: 10054, Learning rate: 0.00008815, Avg batch loss: 0.0150, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 941, Step num: 10055, Learning rate: 0.00008815, Avg batch loss: 0.0196, Avg batch acc: 0.9801
Train, Epoch: 7, Batch: 942, Step num: 10056, Learning rate: 0.00008814, Avg batch loss: 0.0204, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 943, Step num: 10057, Learning rate: 0.00008814, Avg batch loss: 0.0191, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 944, Step num: 10058, Learning rate: 0.00008813, Avg batch loss: 0.0196, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 945, Step num: 10059, Learning rate: 0.00008813, Avg batch loss: 0.0219, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 946, Step num: 10060, Learning rate: 0.00008812, Avg batch loss: 0.0167, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 947, Step num: 10061, Learning rate: 0.00008812, Avg batch loss: 0.0153, Avg batch acc: 0.9874
Train, Epoch: 7, Batch: 948, Step num: 10062, Learning rate: 0.00008812, Avg batch loss: 0.0137, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 949, Step num: 10063, Learning rate: 0.00008811, Avg batch loss: 0.0172, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 950, Step num: 10064, Learning rate: 0.00008811, Avg batch loss: 0.0156, Avg batch acc: 0.9789
Train, Epoch: 7, Batch: 951, Step num: 10065, Learning rate: 0.00008810, Avg batch loss: 0.0165, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 952, Step num: 10066, Learning rate: 0.00008810, Avg batch loss: 0.0200, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 953, Step num: 10067, Learning rate: 0.00008809, Avg batch loss: 0.0167, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 954, Step num: 10068, Learning rate: 0.00008809, Avg batch loss: 0.0182, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 955, Step num: 10069, Learning rate: 0.00008808, Avg batch loss: 0.0188, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 956, Step num: 10070, Learning rate: 0.00008808, Avg batch loss: 0.0236, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 957, Step num: 10071, Learning rate: 0.00008808, Avg batch loss: 0.0204, Avg batch acc: 0.9781
Train, Epoch: 7, Batch: 958, Step num: 10072, Learning rate: 0.00008807, Avg batch loss: 0.0141, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 959, Step num: 10073, Learning rate: 0.00008807, Avg batch loss: 0.0177, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 960, Step num: 10074, Learning rate: 0.00008806, Avg batch loss: 0.0153, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 961, Step num: 10075, Learning rate: 0.00008806, Avg batch loss: 0.0161, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 962, Step num: 10076, Learning rate: 0.00008805, Avg batch loss: 0.0151, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 963, Step num: 10077, Learning rate: 0.00008805, Avg batch loss: 0.0118, Avg batch acc: 0.9883
Train, Epoch: 7, Batch: 964, Step num: 10078, Learning rate: 0.00008805, Avg batch loss: 0.0163, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 965, Step num: 10079, Learning rate: 0.00008804, Avg batch loss: 0.0136, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 966, Step num: 10080, Learning rate: 0.00008804, Avg batch loss: 0.0146, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 967, Step num: 10081, Learning rate: 0.00008803, Avg batch loss: 0.0148, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 968, Step num: 10082, Learning rate: 0.00008803, Avg batch loss: 0.0143, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 969, Step num: 10083, Learning rate: 0.00008802, Avg batch loss: 0.0176, Avg batch acc: 0.9786
Train, Epoch: 7, Batch: 970, Step num: 10084, Learning rate: 0.00008802, Avg batch loss: 0.0145, Avg batch acc: 0.9867
Train, Epoch: 7, Batch: 971, Step num: 10085, Learning rate: 0.00008802, Avg batch loss: 0.0138, Avg batch acc: 0.9814
Train, Epoch: 7, Batch: 972, Step num: 10086, Learning rate: 0.00008801, Avg batch loss: 0.0158, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 973, Step num: 10087, Learning rate: 0.00008801, Avg batch loss: 0.0169, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 974, Step num: 10088, Learning rate: 0.00008800, Avg batch loss: 0.0141, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 975, Step num: 10089, Learning rate: 0.00008800, Avg batch loss: 0.0178, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 976, Step num: 10090, Learning rate: 0.00008799, Avg batch loss: 0.0158, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 977, Step num: 10091, Learning rate: 0.00008799, Avg batch loss: 0.0125, Avg batch acc: 0.9879
Train, Epoch: 7, Batch: 978, Step num: 10092, Learning rate: 0.00008798, Avg batch loss: 0.0159, Avg batch acc: 0.9847
Train, Epoch: 7, Batch: 979, Step num: 10093, Learning rate: 0.00008798, Avg batch loss: 0.0155, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 980, Step num: 10094, Learning rate: 0.00008798, Avg batch loss: 0.0133, Avg batch acc: 0.9873
Train, Epoch: 7, Batch: 981, Step num: 10095, Learning rate: 0.00008797, Avg batch loss: 0.0118, Avg batch acc: 0.9887
Train, Epoch: 7, Batch: 982, Step num: 10096, Learning rate: 0.00008797, Avg batch loss: 0.0237, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 983, Step num: 10097, Learning rate: 0.00008796, Avg batch loss: 0.0133, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 984, Step num: 10098, Learning rate: 0.00008796, Avg batch loss: 0.0191, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 985, Step num: 10099, Learning rate: 0.00008795, Avg batch loss: 0.0203, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 986, Step num: 10100, Learning rate: 0.00008795, Avg batch loss: 0.0149, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 987, Step num: 10101, Learning rate: 0.00008795, Avg batch loss: 0.0158, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 988, Step num: 10102, Learning rate: 0.00008794, Avg batch loss: 0.0148, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 989, Step num: 10103, Learning rate: 0.00008794, Avg batch loss: 0.0161, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 990, Step num: 10104, Learning rate: 0.00008793, Avg batch loss: 0.0160, Avg batch acc: 0.9839
Train, Epoch: 7, Batch: 991, Step num: 10105, Learning rate: 0.00008793, Avg batch loss: 0.0163, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 992, Step num: 10106, Learning rate: 0.00008792, Avg batch loss: 0.0157, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 993, Step num: 10107, Learning rate: 0.00008792, Avg batch loss: 0.0155, Avg batch acc: 0.9857
Train, Epoch: 7, Batch: 994, Step num: 10108, Learning rate: 0.00008791, Avg batch loss: 0.0152, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 995, Step num: 10109, Learning rate: 0.00008791, Avg batch loss: 0.0157, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 996, Step num: 10110, Learning rate: 0.00008791, Avg batch loss: 0.0147, Avg batch acc: 0.9847
Train, Epoch: 7, Batch: 997, Step num: 10111, Learning rate: 0.00008790, Avg batch loss: 0.0152, Avg batch acc: 0.9870
Train, Epoch: 7, Batch: 998, Step num: 10112, Learning rate: 0.00008790, Avg batch loss: 0.0141, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 999, Step num: 10113, Learning rate: 0.00008789, Avg batch loss: 0.0139, Avg batch acc: 0.9869
Train, Epoch: 7, Batch: 1000, Step num: 10114, Learning rate: 0.00008789, Avg batch loss: 0.0159, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 1001, Step num: 10115, Learning rate: 0.00008788, Avg batch loss: 0.0180, Avg batch acc: 0.9764
Train, Epoch: 7, Batch: 1002, Step num: 10116, Learning rate: 0.00008788, Avg batch loss: 0.0187, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 1003, Step num: 10117, Learning rate: 0.00008788, Avg batch loss: 0.0144, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 1004, Step num: 10118, Learning rate: 0.00008787, Avg batch loss: 0.0160, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 1005, Step num: 10119, Learning rate: 0.00008787, Avg batch loss: 0.0185, Avg batch acc: 0.9763
Train, Epoch: 7, Batch: 1006, Step num: 10120, Learning rate: 0.00008786, Avg batch loss: 0.0113, Avg batch acc: 0.9873
Train, Epoch: 7, Batch: 1007, Step num: 10121, Learning rate: 0.00008786, Avg batch loss: 0.0109, Avg batch acc: 0.9898
Train, Epoch: 7, Batch: 1008, Step num: 10122, Learning rate: 0.00008785, Avg batch loss: 0.0165, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1009, Step num: 10123, Learning rate: 0.00008785, Avg batch loss: 0.0149, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 1010, Step num: 10124, Learning rate: 0.00008785, Avg batch loss: 0.0170, Avg batch acc: 0.9857
Train, Epoch: 7, Batch: 1011, Step num: 10125, Learning rate: 0.00008784, Avg batch loss: 0.0170, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 1012, Step num: 10126, Learning rate: 0.00008784, Avg batch loss: 0.0162, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 1013, Step num: 10127, Learning rate: 0.00008783, Avg batch loss: 0.0142, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 1014, Step num: 10128, Learning rate: 0.00008783, Avg batch loss: 0.0165, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 1015, Step num: 10129, Learning rate: 0.00008782, Avg batch loss: 0.0157, Avg batch acc: 0.9854
Train, Epoch: 7, Batch: 1016, Step num: 10130, Learning rate: 0.00008782, Avg batch loss: 0.0215, Avg batch acc: 0.9824
Train, Epoch: 7, Batch: 1017, Step num: 10131, Learning rate: 0.00008782, Avg batch loss: 0.0131, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 1018, Step num: 10132, Learning rate: 0.00008781, Avg batch loss: 0.0165, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 1019, Step num: 10133, Learning rate: 0.00008781, Avg batch loss: 0.0139, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1020, Step num: 10134, Learning rate: 0.00008780, Avg batch loss: 0.0151, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 1021, Step num: 10135, Learning rate: 0.00008780, Avg batch loss: 0.0169, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 1022, Step num: 10136, Learning rate: 0.00008779, Avg batch loss: 0.0130, Avg batch acc: 0.9887
Train, Epoch: 7, Batch: 1023, Step num: 10137, Learning rate: 0.00008779, Avg batch loss: 0.0184, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 1024, Step num: 10138, Learning rate: 0.00008778, Avg batch loss: 0.0172, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 1025, Step num: 10139, Learning rate: 0.00008778, Avg batch loss: 0.0167, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 1026, Step num: 10140, Learning rate: 0.00008778, Avg batch loss: 0.0136, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 1027, Step num: 10141, Learning rate: 0.00008777, Avg batch loss: 0.0162, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1028, Step num: 10142, Learning rate: 0.00008777, Avg batch loss: 0.0105, Avg batch acc: 0.9898
Train, Epoch: 7, Batch: 1029, Step num: 10143, Learning rate: 0.00008776, Avg batch loss: 0.0148, Avg batch acc: 0.9874
Train, Epoch: 7, Batch: 1030, Step num: 10144, Learning rate: 0.00008776, Avg batch loss: 0.0160, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 1031, Step num: 10145, Learning rate: 0.00008775, Avg batch loss: 0.0183, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 1032, Step num: 10146, Learning rate: 0.00008775, Avg batch loss: 0.0162, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 1033, Step num: 10147, Learning rate: 0.00008775, Avg batch loss: 0.0124, Avg batch acc: 0.9876
Train, Epoch: 7, Batch: 1034, Step num: 10148, Learning rate: 0.00008774, Avg batch loss: 0.0149, Avg batch acc: 0.9885
Train, Epoch: 7, Batch: 1035, Step num: 10149, Learning rate: 0.00008774, Avg batch loss: 0.0144, Avg batch acc: 0.9868
Train, Epoch: 7, Batch: 1036, Step num: 10150, Learning rate: 0.00008773, Avg batch loss: 0.0160, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1037, Step num: 10151, Learning rate: 0.00008773, Avg batch loss: 0.0139, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1038, Step num: 10152, Learning rate: 0.00008772, Avg batch loss: 0.0174, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 1039, Step num: 10153, Learning rate: 0.00008772, Avg batch loss: 0.0196, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 1040, Step num: 10154, Learning rate: 0.00008772, Avg batch loss: 0.0146, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 1041, Step num: 10155, Learning rate: 0.00008771, Avg batch loss: 0.0159, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 1042, Step num: 10156, Learning rate: 0.00008771, Avg batch loss: 0.0163, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 1043, Step num: 10157, Learning rate: 0.00008770, Avg batch loss: 0.0160, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 1044, Step num: 10158, Learning rate: 0.00008770, Avg batch loss: 0.0133, Avg batch acc: 0.9854
Train, Epoch: 7, Batch: 1045, Step num: 10159, Learning rate: 0.00008769, Avg batch loss: 0.0134, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1046, Step num: 10160, Learning rate: 0.00008769, Avg batch loss: 0.0125, Avg batch acc: 0.9906
Train, Epoch: 7, Batch: 1047, Step num: 10161, Learning rate: 0.00008769, Avg batch loss: 0.0139, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1048, Step num: 10162, Learning rate: 0.00008768, Avg batch loss: 0.0125, Avg batch acc: 0.9883
Train, Epoch: 7, Batch: 1049, Step num: 10163, Learning rate: 0.00008768, Avg batch loss: 0.0163, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1050, Step num: 10164, Learning rate: 0.00008767, Avg batch loss: 0.0168, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 1051, Step num: 10165, Learning rate: 0.00008767, Avg batch loss: 0.0177, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 1052, Step num: 10166, Learning rate: 0.00008766, Avg batch loss: 0.0190, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 1053, Step num: 10167, Learning rate: 0.00008766, Avg batch loss: 0.0151, Avg batch acc: 0.9876
Train, Epoch: 7, Batch: 1054, Step num: 10168, Learning rate: 0.00008766, Avg batch loss: 0.0166, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 1055, Step num: 10169, Learning rate: 0.00008765, Avg batch loss: 0.0153, Avg batch acc: 0.9877
Train, Epoch: 7, Batch: 1056, Step num: 10170, Learning rate: 0.00008765, Avg batch loss: 0.0161, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 1057, Step num: 10171, Learning rate: 0.00008764, Avg batch loss: 0.0157, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 1058, Step num: 10172, Learning rate: 0.00008764, Avg batch loss: 0.0169, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 1059, Step num: 10173, Learning rate: 0.00008763, Avg batch loss: 0.0167, Avg batch acc: 0.9797
Train, Epoch: 7, Batch: 1060, Step num: 10174, Learning rate: 0.00008763, Avg batch loss: 0.0143, Avg batch acc: 0.9857
Train, Epoch: 7, Batch: 1061, Step num: 10175, Learning rate: 0.00008762, Avg batch loss: 0.0144, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 1062, Step num: 10176, Learning rate: 0.00008762, Avg batch loss: 0.0182, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 1063, Step num: 10177, Learning rate: 0.00008762, Avg batch loss: 0.0149, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 1064, Step num: 10178, Learning rate: 0.00008761, Avg batch loss: 0.0182, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 1065, Step num: 10179, Learning rate: 0.00008761, Avg batch loss: 0.0143, Avg batch acc: 0.9871
Train, Epoch: 7, Batch: 1066, Step num: 10180, Learning rate: 0.00008760, Avg batch loss: 0.0178, Avg batch acc: 0.9847
Train, Epoch: 7, Batch: 1067, Step num: 10181, Learning rate: 0.00008760, Avg batch loss: 0.0150, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 1068, Step num: 10182, Learning rate: 0.00008759, Avg batch loss: 0.0139, Avg batch acc: 0.9881
Train, Epoch: 7, Batch: 1069, Step num: 10183, Learning rate: 0.00008759, Avg batch loss: 0.0168, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 1070, Step num: 10184, Learning rate: 0.00008759, Avg batch loss: 0.0172, Avg batch acc: 0.9781
Train, Epoch: 7, Batch: 1071, Step num: 10185, Learning rate: 0.00008758, Avg batch loss: 0.0142, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1072, Step num: 10186, Learning rate: 0.00008758, Avg batch loss: 0.0303, Avg batch acc: 0.9764
Train, Epoch: 7, Batch: 1073, Step num: 10187, Learning rate: 0.00008757, Avg batch loss: 0.0146, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 1074, Step num: 10188, Learning rate: 0.00008757, Avg batch loss: 0.0150, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 1075, Step num: 10189, Learning rate: 0.00008756, Avg batch loss: 0.0387, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 1076, Step num: 10190, Learning rate: 0.00008756, Avg batch loss: 0.0130, Avg batch acc: 0.9879
Train, Epoch: 7, Batch: 1077, Step num: 10191, Learning rate: 0.00008756, Avg batch loss: 0.0184, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 1078, Step num: 10192, Learning rate: 0.00008755, Avg batch loss: 0.0112, Avg batch acc: 0.9899
Train, Epoch: 7, Batch: 1079, Step num: 10193, Learning rate: 0.00008755, Avg batch loss: 0.0148, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 1080, Step num: 10194, Learning rate: 0.00008754, Avg batch loss: 0.0150, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 1081, Step num: 10195, Learning rate: 0.00008754, Avg batch loss: 0.0168, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 1082, Step num: 10196, Learning rate: 0.00008753, Avg batch loss: 0.0155, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 1083, Step num: 10197, Learning rate: 0.00008753, Avg batch loss: 0.0165, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1084, Step num: 10198, Learning rate: 0.00008753, Avg batch loss: 0.0115, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 1085, Step num: 10199, Learning rate: 0.00008752, Avg batch loss: 0.0145, Avg batch acc: 0.9854
Train, Epoch: 7, Batch: 1086, Step num: 10200, Learning rate: 0.00008752, Avg batch loss: 0.0124, Avg batch acc: 0.9877
Train, Epoch: 7, Batch: 1087, Step num: 10201, Learning rate: 0.00008751, Avg batch loss: 0.0352, Avg batch acc: 0.9749
Train, Epoch: 7, Batch: 1088, Step num: 10202, Learning rate: 0.00008751, Avg batch loss: 0.0175, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 1089, Step num: 10203, Learning rate: 0.00008750, Avg batch loss: 0.0153, Avg batch acc: 0.9878
Train, Epoch: 7, Batch: 1090, Step num: 10204, Learning rate: 0.00008750, Avg batch loss: 0.0187, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 1091, Step num: 10205, Learning rate: 0.00008750, Avg batch loss: 0.0144, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1092, Step num: 10206, Learning rate: 0.00008749, Avg batch loss: 0.0142, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 1093, Step num: 10207, Learning rate: 0.00008749, Avg batch loss: 0.0174, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 1094, Step num: 10208, Learning rate: 0.00008748, Avg batch loss: 0.0161, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 1095, Step num: 10209, Learning rate: 0.00008748, Avg batch loss: 0.0153, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 1096, Step num: 10210, Learning rate: 0.00008747, Avg batch loss: 0.0154, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 1097, Step num: 10211, Learning rate: 0.00008747, Avg batch loss: 0.0190, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 1098, Step num: 10212, Learning rate: 0.00008747, Avg batch loss: 0.0156, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 1099, Step num: 10213, Learning rate: 0.00008746, Avg batch loss: 0.0151, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 1100, Step num: 10214, Learning rate: 0.00008746, Avg batch loss: 0.0110, Avg batch acc: 0.9898
Train, Epoch: 7, Batch: 1101, Step num: 10215, Learning rate: 0.00008745, Avg batch loss: 0.0137, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 1102, Step num: 10216, Learning rate: 0.00008745, Avg batch loss: 0.0169, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 1103, Step num: 10217, Learning rate: 0.00008744, Avg batch loss: 0.0153, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 1104, Step num: 10218, Learning rate: 0.00008744, Avg batch loss: 0.0158, Avg batch acc: 0.9874
Train, Epoch: 7, Batch: 1105, Step num: 10219, Learning rate: 0.00008744, Avg batch loss: 0.0104, Avg batch acc: 0.9920
Train, Epoch: 7, Batch: 1106, Step num: 10220, Learning rate: 0.00008743, Avg batch loss: 0.0150, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 1107, Step num: 10221, Learning rate: 0.00008743, Avg batch loss: 0.0143, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1108, Step num: 10222, Learning rate: 0.00008742, Avg batch loss: 0.0137, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 1109, Step num: 10223, Learning rate: 0.00008742, Avg batch loss: 0.0223, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 1110, Step num: 10224, Learning rate: 0.00008741, Avg batch loss: 0.0167, Avg batch acc: 0.9816
Train, Epoch: 7, Batch: 1111, Step num: 10225, Learning rate: 0.00008741, Avg batch loss: 0.0144, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 1112, Step num: 10226, Learning rate: 0.00008741, Avg batch loss: 0.0143, Avg batch acc: 0.9877
Train, Epoch: 7, Batch: 1113, Step num: 10227, Learning rate: 0.00008740, Avg batch loss: 0.0162, Avg batch acc: 0.9847
Train, Epoch: 7, Batch: 1114, Step num: 10228, Learning rate: 0.00008740, Avg batch loss: 0.0108, Avg batch acc: 0.9885
Train, Epoch: 7, Batch: 1115, Step num: 10229, Learning rate: 0.00008739, Avg batch loss: 0.0171, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 1116, Step num: 10230, Learning rate: 0.00008739, Avg batch loss: 0.0168, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 1117, Step num: 10231, Learning rate: 0.00008738, Avg batch loss: 0.0148, Avg batch acc: 0.9854
Train, Epoch: 7, Batch: 1118, Step num: 10232, Learning rate: 0.00008738, Avg batch loss: 0.0144, Avg batch acc: 0.9813
Train, Epoch: 7, Batch: 1119, Step num: 10233, Learning rate: 0.00008738, Avg batch loss: 0.0124, Avg batch acc: 0.9876
Train, Epoch: 7, Batch: 1120, Step num: 10234, Learning rate: 0.00008737, Avg batch loss: 0.0165, Avg batch acc: 0.9839
Train, Epoch: 7, Batch: 1121, Step num: 10235, Learning rate: 0.00008737, Avg batch loss: 0.0133, Avg batch acc: 0.9900
Train, Epoch: 7, Batch: 1122, Step num: 10236, Learning rate: 0.00008736, Avg batch loss: 0.0156, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1123, Step num: 10237, Learning rate: 0.00008736, Avg batch loss: 0.0176, Avg batch acc: 0.9806
Train, Epoch: 7, Batch: 1124, Step num: 10238, Learning rate: 0.00008735, Avg batch loss: 0.0172, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 1125, Step num: 10239, Learning rate: 0.00008735, Avg batch loss: 0.0163, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 1126, Step num: 10240, Learning rate: 0.00008735, Avg batch loss: 0.0192, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 1127, Step num: 10241, Learning rate: 0.00008734, Avg batch loss: 0.0186, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 1128, Step num: 10242, Learning rate: 0.00008734, Avg batch loss: 0.0122, Avg batch acc: 0.9888
Train, Epoch: 7, Batch: 1129, Step num: 10243, Learning rate: 0.00008733, Avg batch loss: 0.0184, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 1130, Step num: 10244, Learning rate: 0.00008733, Avg batch loss: 0.0201, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 1131, Step num: 10245, Learning rate: 0.00008733, Avg batch loss: 0.0175, Avg batch acc: 0.9799
Train, Epoch: 7, Batch: 1132, Step num: 10246, Learning rate: 0.00008732, Avg batch loss: 0.0176, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 1133, Step num: 10247, Learning rate: 0.00008732, Avg batch loss: 0.0236, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 1134, Step num: 10248, Learning rate: 0.00008731, Avg batch loss: 0.0200, Avg batch acc: 0.9815
Train, Epoch: 7, Batch: 1135, Step num: 10249, Learning rate: 0.00008731, Avg batch loss: 0.0171, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1136, Step num: 10250, Learning rate: 0.00008730, Avg batch loss: 0.0149, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1137, Step num: 10251, Learning rate: 0.00008730, Avg batch loss: 0.0138, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 1138, Step num: 10252, Learning rate: 0.00008730, Avg batch loss: 0.0192, Avg batch acc: 0.9791
Train, Epoch: 7, Batch: 1139, Step num: 10253, Learning rate: 0.00008729, Avg batch loss: 0.0148, Avg batch acc: 0.9847
Train, Epoch: 7, Batch: 1140, Step num: 10254, Learning rate: 0.00008729, Avg batch loss: 0.0113, Avg batch acc: 0.9889
Train, Epoch: 7, Batch: 1141, Step num: 10255, Learning rate: 0.00008728, Avg batch loss: 0.0143, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 1142, Step num: 10256, Learning rate: 0.00008728, Avg batch loss: 0.0197, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 1143, Step num: 10257, Learning rate: 0.00008727, Avg batch loss: 0.0137, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 1144, Step num: 10258, Learning rate: 0.00008727, Avg batch loss: 0.0248, Avg batch acc: 0.9754
Train, Epoch: 7, Batch: 1145, Step num: 10259, Learning rate: 0.00008727, Avg batch loss: 0.0120, Avg batch acc: 0.9869
Train, Epoch: 7, Batch: 1146, Step num: 10260, Learning rate: 0.00008726, Avg batch loss: 0.0146, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 1147, Step num: 10261, Learning rate: 0.00008726, Avg batch loss: 0.0125, Avg batch acc: 0.9890
Train, Epoch: 7, Batch: 1148, Step num: 10262, Learning rate: 0.00008725, Avg batch loss: 0.0171, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1149, Step num: 10263, Learning rate: 0.00008725, Avg batch loss: 0.0176, Avg batch acc: 0.9792
Train, Epoch: 7, Batch: 1150, Step num: 10264, Learning rate: 0.00008724, Avg batch loss: 0.0133, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 1151, Step num: 10265, Learning rate: 0.00008724, Avg batch loss: 0.0167, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 1152, Step num: 10266, Learning rate: 0.00008724, Avg batch loss: 0.0175, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 1153, Step num: 10267, Learning rate: 0.00008723, Avg batch loss: 0.0142, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 1154, Step num: 10268, Learning rate: 0.00008723, Avg batch loss: 0.0125, Avg batch acc: 0.9874
Train, Epoch: 7, Batch: 1155, Step num: 10269, Learning rate: 0.00008722, Avg batch loss: 0.0165, Avg batch acc: 0.9826
Train, Epoch: 7, Batch: 1156, Step num: 10270, Learning rate: 0.00008722, Avg batch loss: 0.0141, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 1157, Step num: 10271, Learning rate: 0.00008721, Avg batch loss: 0.0146, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 1158, Step num: 10272, Learning rate: 0.00008721, Avg batch loss: 0.0162, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 1159, Step num: 10273, Learning rate: 0.00008721, Avg batch loss: 0.0167, Avg batch acc: 0.9836
Train, Epoch: 7, Batch: 1160, Step num: 10274, Learning rate: 0.00008720, Avg batch loss: 0.0132, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1161, Step num: 10275, Learning rate: 0.00008720, Avg batch loss: 0.0129, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 1162, Step num: 10276, Learning rate: 0.00008719, Avg batch loss: 0.0151, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 1163, Step num: 10277, Learning rate: 0.00008719, Avg batch loss: 0.0158, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 1164, Step num: 10278, Learning rate: 0.00008718, Avg batch loss: 0.0154, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 1165, Step num: 10279, Learning rate: 0.00008718, Avg batch loss: 0.0149, Avg batch acc: 0.9867
Train, Epoch: 7, Batch: 1166, Step num: 10280, Learning rate: 0.00008718, Avg batch loss: 0.0168, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 1167, Step num: 10281, Learning rate: 0.00008717, Avg batch loss: 0.0138, Avg batch acc: 0.9875
Train, Epoch: 7, Batch: 1168, Step num: 10282, Learning rate: 0.00008717, Avg batch loss: 0.0212, Avg batch acc: 0.9771
Train, Epoch: 7, Batch: 1169, Step num: 10283, Learning rate: 0.00008716, Avg batch loss: 0.0139, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 1170, Step num: 10284, Learning rate: 0.00008716, Avg batch loss: 0.0175, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 1171, Step num: 10285, Learning rate: 0.00008716, Avg batch loss: 0.0136, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1172, Step num: 10286, Learning rate: 0.00008715, Avg batch loss: 0.0178, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 1173, Step num: 10287, Learning rate: 0.00008715, Avg batch loss: 0.0174, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 1174, Step num: 10288, Learning rate: 0.00008714, Avg batch loss: 0.0131, Avg batch acc: 0.9895
Train, Epoch: 7, Batch: 1175, Step num: 10289, Learning rate: 0.00008714, Avg batch loss: 0.0154, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1176, Step num: 10290, Learning rate: 0.00008713, Avg batch loss: 0.0207, Avg batch acc: 0.9740
Train, Epoch: 7, Batch: 1177, Step num: 10291, Learning rate: 0.00008713, Avg batch loss: 0.0130, Avg batch acc: 0.9907
Train, Epoch: 7, Batch: 1178, Step num: 10292, Learning rate: 0.00008713, Avg batch loss: 0.0165, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 1179, Step num: 10293, Learning rate: 0.00008712, Avg batch loss: 0.0150, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1180, Step num: 10294, Learning rate: 0.00008712, Avg batch loss: 0.0137, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1181, Step num: 10295, Learning rate: 0.00008711, Avg batch loss: 0.0151, Avg batch acc: 0.9867
Train, Epoch: 7, Batch: 1182, Step num: 10296, Learning rate: 0.00008711, Avg batch loss: 0.0146, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 1183, Step num: 10297, Learning rate: 0.00008710, Avg batch loss: 0.0171, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 1184, Step num: 10298, Learning rate: 0.00008710, Avg batch loss: 0.0145, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 1185, Step num: 10299, Learning rate: 0.00008710, Avg batch loss: 0.0157, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 1186, Step num: 10300, Learning rate: 0.00008709, Avg batch loss: 0.0171, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 1187, Step num: 10301, Learning rate: 0.00008709, Avg batch loss: 0.0142, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 1188, Step num: 10302, Learning rate: 0.00008708, Avg batch loss: 0.0138, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 1189, Step num: 10303, Learning rate: 0.00008708, Avg batch loss: 0.0160, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 1190, Step num: 10304, Learning rate: 0.00008707, Avg batch loss: 0.0140, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 1191, Step num: 10305, Learning rate: 0.00008707, Avg batch loss: 0.0099, Avg batch acc: 0.9923
Train, Epoch: 7, Batch: 1192, Step num: 10306, Learning rate: 0.00008707, Avg batch loss: 0.0158, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 1193, Step num: 10307, Learning rate: 0.00008706, Avg batch loss: 0.0139, Avg batch acc: 0.9874
Train, Epoch: 7, Batch: 1194, Step num: 10308, Learning rate: 0.00008706, Avg batch loss: 0.0125, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 1195, Step num: 10309, Learning rate: 0.00008705, Avg batch loss: 0.0169, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 1196, Step num: 10310, Learning rate: 0.00008705, Avg batch loss: 0.0133, Avg batch acc: 0.9878
Train, Epoch: 7, Batch: 1197, Step num: 10311, Learning rate: 0.00008705, Avg batch loss: 0.0152, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 1198, Step num: 10312, Learning rate: 0.00008704, Avg batch loss: 0.0114, Avg batch acc: 0.9883
Train, Epoch: 7, Batch: 1199, Step num: 10313, Learning rate: 0.00008704, Avg batch loss: 0.0124, Avg batch acc: 0.9902
Train, Epoch: 7, Batch: 1200, Step num: 10314, Learning rate: 0.00008703, Avg batch loss: 0.0158, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 1201, Step num: 10315, Learning rate: 0.00008703, Avg batch loss: 0.0088, Avg batch acc: 0.9916
Train, Epoch: 7, Batch: 1202, Step num: 10316, Learning rate: 0.00008702, Avg batch loss: 0.0148, Avg batch acc: 0.9868
Train, Epoch: 7, Batch: 1203, Step num: 10317, Learning rate: 0.00008702, Avg batch loss: 0.0136, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 1204, Step num: 10318, Learning rate: 0.00008702, Avg batch loss: 0.0114, Avg batch acc: 0.9881
Train, Epoch: 7, Batch: 1205, Step num: 10319, Learning rate: 0.00008701, Avg batch loss: 0.0170, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1206, Step num: 10320, Learning rate: 0.00008701, Avg batch loss: 0.0146, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1207, Step num: 10321, Learning rate: 0.00008700, Avg batch loss: 0.0143, Avg batch acc: 0.9886
Train, Epoch: 7, Batch: 1208, Step num: 10322, Learning rate: 0.00008700, Avg batch loss: 0.0113, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 1209, Step num: 10323, Learning rate: 0.00008699, Avg batch loss: 0.0143, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 1210, Step num: 10324, Learning rate: 0.00008699, Avg batch loss: 0.0136, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 1211, Step num: 10325, Learning rate: 0.00008699, Avg batch loss: 0.0123, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 1212, Step num: 10326, Learning rate: 0.00008698, Avg batch loss: 0.0134, Avg batch acc: 0.9898
Train, Epoch: 7, Batch: 1213, Step num: 10327, Learning rate: 0.00008698, Avg batch loss: 0.0126, Avg batch acc: 0.9893
Train, Epoch: 7, Batch: 1214, Step num: 10328, Learning rate: 0.00008697, Avg batch loss: 0.0122, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 1215, Step num: 10329, Learning rate: 0.00008697, Avg batch loss: 0.0147, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 1216, Step num: 10330, Learning rate: 0.00008697, Avg batch loss: 0.0120, Avg batch acc: 0.9881
Train, Epoch: 7, Batch: 1217, Step num: 10331, Learning rate: 0.00008696, Avg batch loss: 0.0166, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 1218, Step num: 10332, Learning rate: 0.00008696, Avg batch loss: 0.0266, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 1219, Step num: 10333, Learning rate: 0.00008695, Avg batch loss: 0.0174, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 1220, Step num: 10334, Learning rate: 0.00008695, Avg batch loss: 0.0151, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 1221, Step num: 10335, Learning rate: 0.00008694, Avg batch loss: 0.0135, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1222, Step num: 10336, Learning rate: 0.00008694, Avg batch loss: 0.0312, Avg batch acc: 0.9801
Train, Epoch: 7, Batch: 1223, Step num: 10337, Learning rate: 0.00008694, Avg batch loss: 0.0138, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 1224, Step num: 10338, Learning rate: 0.00008693, Avg batch loss: 0.0150, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 1225, Step num: 10339, Learning rate: 0.00008693, Avg batch loss: 0.0145, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1226, Step num: 10340, Learning rate: 0.00008692, Avg batch loss: 0.0184, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 1227, Step num: 10341, Learning rate: 0.00008692, Avg batch loss: 0.0169, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 1228, Step num: 10342, Learning rate: 0.00008691, Avg batch loss: 0.0125, Avg batch acc: 0.9878
Train, Epoch: 7, Batch: 1229, Step num: 10343, Learning rate: 0.00008691, Avg batch loss: 0.0166, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 1230, Step num: 10344, Learning rate: 0.00008691, Avg batch loss: 0.0148, Avg batch acc: 0.9869
Train, Epoch: 7, Batch: 1231, Step num: 10345, Learning rate: 0.00008690, Avg batch loss: 0.0144, Avg batch acc: 0.9892
Train, Epoch: 7, Batch: 1232, Step num: 10346, Learning rate: 0.00008690, Avg batch loss: 0.0157, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 1233, Step num: 10347, Learning rate: 0.00008689, Avg batch loss: 0.0113, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 1234, Step num: 10348, Learning rate: 0.00008689, Avg batch loss: 0.0138, Avg batch acc: 0.9891
Train, Epoch: 7, Batch: 1235, Step num: 10349, Learning rate: 0.00008689, Avg batch loss: 0.0146, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 1236, Step num: 10350, Learning rate: 0.00008688, Avg batch loss: 0.0127, Avg batch acc: 0.9879
Train, Epoch: 7, Batch: 1237, Step num: 10351, Learning rate: 0.00008688, Avg batch loss: 0.0145, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 1238, Step num: 10352, Learning rate: 0.00008687, Avg batch loss: 0.0164, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 1239, Step num: 10353, Learning rate: 0.00008687, Avg batch loss: 0.0142, Avg batch acc: 0.9879
Train, Epoch: 7, Batch: 1240, Step num: 10354, Learning rate: 0.00008686, Avg batch loss: 0.0160, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 1241, Step num: 10355, Learning rate: 0.00008686, Avg batch loss: 0.0143, Avg batch acc: 0.9895
Train, Epoch: 7, Batch: 1242, Step num: 10356, Learning rate: 0.00008686, Avg batch loss: 0.0118, Avg batch acc: 0.9880
Train, Epoch: 7, Batch: 1243, Step num: 10357, Learning rate: 0.00008685, Avg batch loss: 0.0176, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 1244, Step num: 10358, Learning rate: 0.00008685, Avg batch loss: 0.0143, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1245, Step num: 10359, Learning rate: 0.00008684, Avg batch loss: 0.0137, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 1246, Step num: 10360, Learning rate: 0.00008684, Avg batch loss: 0.0132, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 1247, Step num: 10361, Learning rate: 0.00008683, Avg batch loss: 0.0136, Avg batch acc: 0.9877
Train, Epoch: 7, Batch: 1248, Step num: 10362, Learning rate: 0.00008683, Avg batch loss: 0.0108, Avg batch acc: 0.9908
Train, Epoch: 7, Batch: 1249, Step num: 10363, Learning rate: 0.00008683, Avg batch loss: 0.0186, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 1250, Step num: 10364, Learning rate: 0.00008682, Avg batch loss: 0.0148, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 1251, Step num: 10365, Learning rate: 0.00008682, Avg batch loss: 0.0115, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1252, Step num: 10366, Learning rate: 0.00008681, Avg batch loss: 0.0135, Avg batch acc: 0.9886
Train, Epoch: 7, Batch: 1253, Step num: 10367, Learning rate: 0.00008681, Avg batch loss: 0.0144, Avg batch acc: 0.9872
Train, Epoch: 7, Batch: 1254, Step num: 10368, Learning rate: 0.00008681, Avg batch loss: 0.0138, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1255, Step num: 10369, Learning rate: 0.00008680, Avg batch loss: 0.0113, Avg batch acc: 0.9893
Train, Epoch: 7, Batch: 1256, Step num: 10370, Learning rate: 0.00008680, Avg batch loss: 0.0180, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1257, Step num: 10371, Learning rate: 0.00008679, Avg batch loss: 0.0112, Avg batch acc: 0.9894
Train, Epoch: 7, Batch: 1258, Step num: 10372, Learning rate: 0.00008679, Avg batch loss: 0.0163, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 1259, Step num: 10373, Learning rate: 0.00008678, Avg batch loss: 0.0136, Avg batch acc: 0.9875
Train, Epoch: 7, Batch: 1260, Step num: 10374, Learning rate: 0.00008678, Avg batch loss: 0.0177, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1261, Step num: 10375, Learning rate: 0.00008678, Avg batch loss: 0.0135, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 1262, Step num: 10376, Learning rate: 0.00008677, Avg batch loss: 0.0193, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1263, Step num: 10377, Learning rate: 0.00008677, Avg batch loss: 0.0136, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 1264, Step num: 10378, Learning rate: 0.00008676, Avg batch loss: 0.0165, Avg batch acc: 0.9839
Train, Epoch: 7, Batch: 1265, Step num: 10379, Learning rate: 0.00008676, Avg batch loss: 0.0135, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 1266, Step num: 10380, Learning rate: 0.00008676, Avg batch loss: 0.0133, Avg batch acc: 0.9876
Train, Epoch: 7, Batch: 1267, Step num: 10381, Learning rate: 0.00008675, Avg batch loss: 0.0103, Avg batch acc: 0.9883
Train, Epoch: 7, Batch: 1268, Step num: 10382, Learning rate: 0.00008675, Avg batch loss: 0.0163, Avg batch acc: 0.9821
Train, Epoch: 7, Batch: 1269, Step num: 10383, Learning rate: 0.00008674, Avg batch loss: 0.0378, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1270, Step num: 10384, Learning rate: 0.00008674, Avg batch loss: 0.0103, Avg batch acc: 0.9881
Train, Epoch: 7, Batch: 1271, Step num: 10385, Learning rate: 0.00008673, Avg batch loss: 0.0176, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 1272, Step num: 10386, Learning rate: 0.00008673, Avg batch loss: 0.0160, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1273, Step num: 10387, Learning rate: 0.00008673, Avg batch loss: 0.0195, Avg batch acc: 0.9822
Train, Epoch: 7, Batch: 1274, Step num: 10388, Learning rate: 0.00008672, Avg batch loss: 0.0130, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1275, Step num: 10389, Learning rate: 0.00008672, Avg batch loss: 0.0186, Avg batch acc: 0.9804
Train, Epoch: 7, Batch: 1276, Step num: 10390, Learning rate: 0.00008671, Avg batch loss: 0.0131, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 1277, Step num: 10391, Learning rate: 0.00008671, Avg batch loss: 0.0149, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 1278, Step num: 10392, Learning rate: 0.00008671, Avg batch loss: 0.0127, Avg batch acc: 0.9884
Train, Epoch: 7, Batch: 1279, Step num: 10393, Learning rate: 0.00008670, Avg batch loss: 0.0143, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1280, Step num: 10394, Learning rate: 0.00008670, Avg batch loss: 0.0147, Avg batch acc: 0.9880
Train, Epoch: 7, Batch: 1281, Step num: 10395, Learning rate: 0.00008669, Avg batch loss: 0.0107, Avg batch acc: 0.9911
Train, Epoch: 7, Batch: 1282, Step num: 10396, Learning rate: 0.00008669, Avg batch loss: 0.0156, Avg batch acc: 0.9874
Train, Epoch: 7, Batch: 1283, Step num: 10397, Learning rate: 0.00008668, Avg batch loss: 0.0118, Avg batch acc: 0.9888
Train, Epoch: 7, Batch: 1284, Step num: 10398, Learning rate: 0.00008668, Avg batch loss: 0.0150, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 1285, Step num: 10399, Learning rate: 0.00008668, Avg batch loss: 0.0150, Avg batch acc: 0.9820
Train, Epoch: 7, Batch: 1286, Step num: 10400, Learning rate: 0.00008667, Avg batch loss: 0.0281, Avg batch acc: 0.9793
Train, Epoch: 7, Batch: 1287, Step num: 10401, Learning rate: 0.00008667, Avg batch loss: 0.0169, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 1288, Step num: 10402, Learning rate: 0.00008666, Avg batch loss: 0.0167, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 1289, Step num: 10403, Learning rate: 0.00008666, Avg batch loss: 0.0114, Avg batch acc: 0.9872
Train, Epoch: 7, Batch: 1290, Step num: 10404, Learning rate: 0.00008666, Avg batch loss: 0.0164, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 1291, Step num: 10405, Learning rate: 0.00008665, Avg batch loss: 0.0157, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 1292, Step num: 10406, Learning rate: 0.00008665, Avg batch loss: 0.0154, Avg batch acc: 0.9803
Train, Epoch: 7, Batch: 1293, Step num: 10407, Learning rate: 0.00008664, Avg batch loss: 0.0135, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 1294, Step num: 10408, Learning rate: 0.00008664, Avg batch loss: 0.0147, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 1295, Step num: 10409, Learning rate: 0.00008663, Avg batch loss: 0.0183, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 1296, Step num: 10410, Learning rate: 0.00008663, Avg batch loss: 0.0167, Avg batch acc: 0.9813
Train, Epoch: 7, Batch: 1297, Step num: 10411, Learning rate: 0.00008663, Avg batch loss: 0.0125, Avg batch acc: 0.9870
Train, Epoch: 7, Batch: 1298, Step num: 10412, Learning rate: 0.00008662, Avg batch loss: 0.0150, Avg batch acc: 0.9869
Train, Epoch: 7, Batch: 1299, Step num: 10413, Learning rate: 0.00008662, Avg batch loss: 0.0159, Avg batch acc: 0.9880
Train, Epoch: 7, Batch: 1300, Step num: 10414, Learning rate: 0.00008661, Avg batch loss: 0.0136, Avg batch acc: 0.9886
Train, Epoch: 7, Batch: 1301, Step num: 10415, Learning rate: 0.00008661, Avg batch loss: 0.0181, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 1302, Step num: 10416, Learning rate: 0.00008661, Avg batch loss: 0.0142, Avg batch acc: 0.9854
Train, Epoch: 7, Batch: 1303, Step num: 10417, Learning rate: 0.00008660, Avg batch loss: 0.0151, Avg batch acc: 0.9876
Train, Epoch: 7, Batch: 1304, Step num: 10418, Learning rate: 0.00008660, Avg batch loss: 0.0141, Avg batch acc: 0.9873
Train, Epoch: 7, Batch: 1305, Step num: 10419, Learning rate: 0.00008659, Avg batch loss: 0.0166, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1306, Step num: 10420, Learning rate: 0.00008659, Avg batch loss: 0.0117, Avg batch acc: 0.9878
Train, Epoch: 7, Batch: 1307, Step num: 10421, Learning rate: 0.00008658, Avg batch loss: 0.0393, Avg batch acc: 0.9800
Train, Epoch: 7, Batch: 1308, Step num: 10422, Learning rate: 0.00008658, Avg batch loss: 0.0174, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 1309, Step num: 10423, Learning rate: 0.00008658, Avg batch loss: 0.0128, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1310, Step num: 10424, Learning rate: 0.00008657, Avg batch loss: 0.0157, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 1311, Step num: 10425, Learning rate: 0.00008657, Avg batch loss: 0.0153, Avg batch acc: 0.9868
Train, Epoch: 7, Batch: 1312, Step num: 10426, Learning rate: 0.00008656, Avg batch loss: 0.0149, Avg batch acc: 0.9857
Train, Epoch: 7, Batch: 1313, Step num: 10427, Learning rate: 0.00008656, Avg batch loss: 0.0139, Avg batch acc: 0.9879
Train, Epoch: 7, Batch: 1314, Step num: 10428, Learning rate: 0.00008656, Avg batch loss: 0.0133, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 1315, Step num: 10429, Learning rate: 0.00008655, Avg batch loss: 0.0151, Avg batch acc: 0.9877
Train, Epoch: 7, Batch: 1316, Step num: 10430, Learning rate: 0.00008655, Avg batch loss: 0.0168, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 1317, Step num: 10431, Learning rate: 0.00008654, Avg batch loss: 0.0136, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 1318, Step num: 10432, Learning rate: 0.00008654, Avg batch loss: 0.0133, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1319, Step num: 10433, Learning rate: 0.00008653, Avg batch loss: 0.0149, Avg batch acc: 0.9871
Train, Epoch: 7, Batch: 1320, Step num: 10434, Learning rate: 0.00008653, Avg batch loss: 0.0136, Avg batch acc: 0.9878
Train, Epoch: 7, Batch: 1321, Step num: 10435, Learning rate: 0.00008653, Avg batch loss: 0.0195, Avg batch acc: 0.9798
Train, Epoch: 7, Batch: 1322, Step num: 10436, Learning rate: 0.00008652, Avg batch loss: 0.0135, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1323, Step num: 10437, Learning rate: 0.00008652, Avg batch loss: 0.0167, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1324, Step num: 10438, Learning rate: 0.00008651, Avg batch loss: 0.0117, Avg batch acc: 0.9904
Train, Epoch: 7, Batch: 1325, Step num: 10439, Learning rate: 0.00008651, Avg batch loss: 0.0132, Avg batch acc: 0.9886
Train, Epoch: 7, Batch: 1326, Step num: 10440, Learning rate: 0.00008651, Avg batch loss: 0.0168, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 1327, Step num: 10441, Learning rate: 0.00008650, Avg batch loss: 0.0370, Avg batch acc: 0.9758
Train, Epoch: 7, Batch: 1328, Step num: 10442, Learning rate: 0.00008650, Avg batch loss: 0.0131, Avg batch acc: 0.9893
Train, Epoch: 7, Batch: 1329, Step num: 10443, Learning rate: 0.00008649, Avg batch loss: 0.0117, Avg batch acc: 0.9912
Train, Epoch: 7, Batch: 1330, Step num: 10444, Learning rate: 0.00008649, Avg batch loss: 0.0112, Avg batch acc: 0.9876
Train, Epoch: 7, Batch: 1331, Step num: 10445, Learning rate: 0.00008649, Avg batch loss: 0.0137, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 1332, Step num: 10446, Learning rate: 0.00008648, Avg batch loss: 0.0204, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 1333, Step num: 10447, Learning rate: 0.00008648, Avg batch loss: 0.0161, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 1334, Step num: 10448, Learning rate: 0.00008647, Avg batch loss: 0.0130, Avg batch acc: 0.9871
Train, Epoch: 7, Batch: 1335, Step num: 10449, Learning rate: 0.00008647, Avg batch loss: 0.0134, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1336, Step num: 10450, Learning rate: 0.00008646, Avg batch loss: 0.0120, Avg batch acc: 0.9898
Train, Epoch: 7, Batch: 1337, Step num: 10451, Learning rate: 0.00008646, Avg batch loss: 0.0159, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 1338, Step num: 10452, Learning rate: 0.00008646, Avg batch loss: 0.0167, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 1339, Step num: 10453, Learning rate: 0.00008645, Avg batch loss: 0.0128, Avg batch acc: 0.9884
Train, Epoch: 7, Batch: 1340, Step num: 10454, Learning rate: 0.00008645, Avg batch loss: 0.0159, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 1341, Step num: 10455, Learning rate: 0.00008644, Avg batch loss: 0.0124, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 1342, Step num: 10456, Learning rate: 0.00008644, Avg batch loss: 0.0111, Avg batch acc: 0.9900
Train, Epoch: 7, Batch: 1343, Step num: 10457, Learning rate: 0.00008644, Avg batch loss: 0.0182, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 1344, Step num: 10458, Learning rate: 0.00008643, Avg batch loss: 0.0126, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1345, Step num: 10459, Learning rate: 0.00008643, Avg batch loss: 0.0181, Avg batch acc: 0.9807
Train, Epoch: 7, Batch: 1346, Step num: 10460, Learning rate: 0.00008642, Avg batch loss: 0.0151, Avg batch acc: 0.9876
Train, Epoch: 7, Batch: 1347, Step num: 10461, Learning rate: 0.00008642, Avg batch loss: 0.0108, Avg batch acc: 0.9881
Train, Epoch: 7, Batch: 1348, Step num: 10462, Learning rate: 0.00008641, Avg batch loss: 0.0176, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 1349, Step num: 10463, Learning rate: 0.00008641, Avg batch loss: 0.0272, Avg batch acc: 0.9879
Train, Epoch: 7, Batch: 1350, Step num: 10464, Learning rate: 0.00008641, Avg batch loss: 0.0205, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 1351, Step num: 10465, Learning rate: 0.00008640, Avg batch loss: 0.0137, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 1352, Step num: 10466, Learning rate: 0.00008640, Avg batch loss: 0.0165, Avg batch acc: 0.9836
Train, Epoch: 7, Batch: 1353, Step num: 10467, Learning rate: 0.00008639, Avg batch loss: 0.0142, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 1354, Step num: 10468, Learning rate: 0.00008639, Avg batch loss: 0.0159, Avg batch acc: 0.9840
Train, Epoch: 7, Batch: 1355, Step num: 10469, Learning rate: 0.00008639, Avg batch loss: 0.0132, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 1356, Step num: 10470, Learning rate: 0.00008638, Avg batch loss: 0.0097, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1357, Step num: 10471, Learning rate: 0.00008638, Avg batch loss: 0.0132, Avg batch acc: 0.9882
Train, Epoch: 7, Batch: 1358, Step num: 10472, Learning rate: 0.00008637, Avg batch loss: 0.0173, Avg batch acc: 0.9838
Train, Epoch: 7, Batch: 1359, Step num: 10473, Learning rate: 0.00008637, Avg batch loss: 0.0123, Avg batch acc: 0.9916
Train, Epoch: 7, Batch: 1360, Step num: 10474, Learning rate: 0.00008637, Avg batch loss: 0.0176, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 1361, Step num: 10475, Learning rate: 0.00008636, Avg batch loss: 0.0159, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 1362, Step num: 10476, Learning rate: 0.00008636, Avg batch loss: 0.0140, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 1363, Step num: 10477, Learning rate: 0.00008635, Avg batch loss: 0.0125, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1364, Step num: 10478, Learning rate: 0.00008635, Avg batch loss: 0.0142, Avg batch acc: 0.9876
Train, Epoch: 7, Batch: 1365, Step num: 10479, Learning rate: 0.00008634, Avg batch loss: 0.0203, Avg batch acc: 0.9783
Train, Epoch: 7, Batch: 1366, Step num: 10480, Learning rate: 0.00008634, Avg batch loss: 0.0143, Avg batch acc: 0.9870
Train, Epoch: 7, Batch: 1367, Step num: 10481, Learning rate: 0.00008634, Avg batch loss: 0.0144, Avg batch acc: 0.9870
Train, Epoch: 7, Batch: 1368, Step num: 10482, Learning rate: 0.00008633, Avg batch loss: 0.0107, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1369, Step num: 10483, Learning rate: 0.00008633, Avg batch loss: 0.0120, Avg batch acc: 0.9899
Train, Epoch: 7, Batch: 1370, Step num: 10484, Learning rate: 0.00008632, Avg batch loss: 0.0158, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 1371, Step num: 10485, Learning rate: 0.00008632, Avg batch loss: 0.0148, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 1372, Step num: 10486, Learning rate: 0.00008632, Avg batch loss: 0.0113, Avg batch acc: 0.9885
Train, Epoch: 7, Batch: 1373, Step num: 10487, Learning rate: 0.00008631, Avg batch loss: 0.0101, Avg batch acc: 0.9918
Train, Epoch: 7, Batch: 1374, Step num: 10488, Learning rate: 0.00008631, Avg batch loss: 0.0150, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 1375, Step num: 10489, Learning rate: 0.00008630, Avg batch loss: 0.0134, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 1376, Step num: 10490, Learning rate: 0.00008630, Avg batch loss: 0.0124, Avg batch acc: 0.9873
Train, Epoch: 7, Batch: 1377, Step num: 10491, Learning rate: 0.00008630, Avg batch loss: 0.0157, Avg batch acc: 0.9819
Train, Epoch: 7, Batch: 1378, Step num: 10492, Learning rate: 0.00008629, Avg batch loss: 0.0136, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 1379, Step num: 10493, Learning rate: 0.00008629, Avg batch loss: 0.0133, Avg batch acc: 0.9817
Train, Epoch: 7, Batch: 1380, Step num: 10494, Learning rate: 0.00008628, Avg batch loss: 0.0153, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 1381, Step num: 10495, Learning rate: 0.00008628, Avg batch loss: 0.0126, Avg batch acc: 0.9887
Train, Epoch: 7, Batch: 1382, Step num: 10496, Learning rate: 0.00008627, Avg batch loss: 0.0125, Avg batch acc: 0.9887
Train, Epoch: 7, Batch: 1383, Step num: 10497, Learning rate: 0.00008627, Avg batch loss: 0.0129, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1384, Step num: 10498, Learning rate: 0.00008627, Avg batch loss: 0.0108, Avg batch acc: 0.9896
Train, Epoch: 7, Batch: 1385, Step num: 10499, Learning rate: 0.00008626, Avg batch loss: 0.0166, Avg batch acc: 0.9808
Train, Epoch: 7, Batch: 1386, Step num: 10500, Learning rate: 0.00008626, Avg batch loss: 0.0192, Avg batch acc: 0.9766
Train, Epoch: 7, Batch: 1387, Step num: 10501, Learning rate: 0.00008625, Avg batch loss: 0.0169, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 1388, Step num: 10502, Learning rate: 0.00008625, Avg batch loss: 0.0134, Avg batch acc: 0.9882
Train, Epoch: 7, Batch: 1389, Step num: 10503, Learning rate: 0.00008625, Avg batch loss: 0.0153, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 1390, Step num: 10504, Learning rate: 0.00008624, Avg batch loss: 0.0121, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1391, Step num: 10505, Learning rate: 0.00008624, Avg batch loss: 0.0137, Avg batch acc: 0.9858
Train, Epoch: 7, Batch: 1392, Step num: 10506, Learning rate: 0.00008623, Avg batch loss: 0.0135, Avg batch acc: 0.9868
Train, Epoch: 7, Batch: 1393, Step num: 10507, Learning rate: 0.00008623, Avg batch loss: 0.0135, Avg batch acc: 0.9874
Train, Epoch: 7, Batch: 1394, Step num: 10508, Learning rate: 0.00008623, Avg batch loss: 0.0124, Avg batch acc: 0.9871
Train, Epoch: 7, Batch: 1395, Step num: 10509, Learning rate: 0.00008622, Avg batch loss: 0.0133, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 1396, Step num: 10510, Learning rate: 0.00008622, Avg batch loss: 0.0149, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 1397, Step num: 10511, Learning rate: 0.00008621, Avg batch loss: 0.0139, Avg batch acc: 0.9888
Train, Epoch: 7, Batch: 1398, Step num: 10512, Learning rate: 0.00008621, Avg batch loss: 0.0150, Avg batch acc: 0.9823
Train, Epoch: 7, Batch: 1399, Step num: 10513, Learning rate: 0.00008620, Avg batch loss: 0.0120, Avg batch acc: 0.9882
Train, Epoch: 7, Batch: 1400, Step num: 10514, Learning rate: 0.00008620, Avg batch loss: 0.0140, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 1401, Step num: 10515, Learning rate: 0.00008620, Avg batch loss: 0.0144, Avg batch acc: 0.9827
Train, Epoch: 7, Batch: 1402, Step num: 10516, Learning rate: 0.00008619, Avg batch loss: 0.0134, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1403, Step num: 10517, Learning rate: 0.00008619, Avg batch loss: 0.0131, Avg batch acc: 0.9889
Train, Epoch: 7, Batch: 1404, Step num: 10518, Learning rate: 0.00008618, Avg batch loss: 0.0172, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 1405, Step num: 10519, Learning rate: 0.00008618, Avg batch loss: 0.0138, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 1406, Step num: 10520, Learning rate: 0.00008618, Avg batch loss: 0.0155, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1407, Step num: 10521, Learning rate: 0.00008617, Avg batch loss: 0.0138, Avg batch acc: 0.9874
Train, Epoch: 7, Batch: 1408, Step num: 10522, Learning rate: 0.00008617, Avg batch loss: 0.0141, Avg batch acc: 0.9859
Train, Epoch: 7, Batch: 1409, Step num: 10523, Learning rate: 0.00008616, Avg batch loss: 0.0170, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1410, Step num: 10524, Learning rate: 0.00008616, Avg batch loss: 0.0114, Avg batch acc: 0.9901
Train, Epoch: 7, Batch: 1411, Step num: 10525, Learning rate: 0.00008616, Avg batch loss: 0.0165, Avg batch acc: 0.9845
Train, Epoch: 7, Batch: 1412, Step num: 10526, Learning rate: 0.00008615, Avg batch loss: 0.0148, Avg batch acc: 0.9839
Train, Epoch: 7, Batch: 1413, Step num: 10527, Learning rate: 0.00008615, Avg batch loss: 0.0164, Avg batch acc: 0.9833
Train, Epoch: 7, Batch: 1414, Step num: 10528, Learning rate: 0.00008614, Avg batch loss: 0.0110, Avg batch acc: 0.9875
Train, Epoch: 7, Batch: 1415, Step num: 10529, Learning rate: 0.00008614, Avg batch loss: 0.0131, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 1416, Step num: 10530, Learning rate: 0.00008614, Avg batch loss: 0.0166, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1417, Step num: 10531, Learning rate: 0.00008613, Avg batch loss: 0.0154, Avg batch acc: 0.9846
Train, Epoch: 7, Batch: 1418, Step num: 10532, Learning rate: 0.00008613, Avg batch loss: 0.0126, Avg batch acc: 0.9880
Train, Epoch: 7, Batch: 1419, Step num: 10533, Learning rate: 0.00008612, Avg batch loss: 0.0152, Avg batch acc: 0.9818
Train, Epoch: 7, Batch: 1420, Step num: 10534, Learning rate: 0.00008612, Avg batch loss: 0.0149, Avg batch acc: 0.9853
Train, Epoch: 7, Batch: 1421, Step num: 10535, Learning rate: 0.00008611, Avg batch loss: 0.0151, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1422, Step num: 10536, Learning rate: 0.00008611, Avg batch loss: 0.0137, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 1423, Step num: 10537, Learning rate: 0.00008611, Avg batch loss: 0.0329, Avg batch acc: 0.9837
Train, Epoch: 7, Batch: 1424, Step num: 10538, Learning rate: 0.00008610, Avg batch loss: 0.0149, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 1425, Step num: 10539, Learning rate: 0.00008610, Avg batch loss: 0.0182, Avg batch acc: 0.9836
Train, Epoch: 7, Batch: 1426, Step num: 10540, Learning rate: 0.00008609, Avg batch loss: 0.0179, Avg batch acc: 0.9801
Train, Epoch: 7, Batch: 1427, Step num: 10541, Learning rate: 0.00008609, Avg batch loss: 0.0126, Avg batch acc: 0.9889
Train, Epoch: 7, Batch: 1428, Step num: 10542, Learning rate: 0.00008609, Avg batch loss: 0.0158, Avg batch acc: 0.9885
Train, Epoch: 7, Batch: 1429, Step num: 10543, Learning rate: 0.00008608, Avg batch loss: 0.0155, Avg batch acc: 0.9795
Train, Epoch: 7, Batch: 1430, Step num: 10544, Learning rate: 0.00008608, Avg batch loss: 0.0126, Avg batch acc: 0.9868
Train, Epoch: 7, Batch: 1431, Step num: 10545, Learning rate: 0.00008607, Avg batch loss: 0.0160, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 1432, Step num: 10546, Learning rate: 0.00008607, Avg batch loss: 0.0141, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 1433, Step num: 10547, Learning rate: 0.00008607, Avg batch loss: 0.0216, Avg batch acc: 0.9802
Train, Epoch: 7, Batch: 1434, Step num: 10548, Learning rate: 0.00008606, Avg batch loss: 0.0137, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 1435, Step num: 10549, Learning rate: 0.00008606, Avg batch loss: 0.0141, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 1436, Step num: 10550, Learning rate: 0.00008605, Avg batch loss: 0.0141, Avg batch acc: 0.9867
Train, Epoch: 7, Batch: 1437, Step num: 10551, Learning rate: 0.00008605, Avg batch loss: 0.0130, Avg batch acc: 0.9894
Train, Epoch: 7, Batch: 1438, Step num: 10552, Learning rate: 0.00008605, Avg batch loss: 0.0162, Avg batch acc: 0.9834
Train, Epoch: 7, Batch: 1439, Step num: 10553, Learning rate: 0.00008604, Avg batch loss: 0.0145, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1440, Step num: 10554, Learning rate: 0.00008604, Avg batch loss: 0.0137, Avg batch acc: 0.9878
Train, Epoch: 7, Batch: 1441, Step num: 10555, Learning rate: 0.00008603, Avg batch loss: 0.0115, Avg batch acc: 0.9914
Train, Epoch: 7, Batch: 1442, Step num: 10556, Learning rate: 0.00008603, Avg batch loss: 0.0173, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 1443, Step num: 10557, Learning rate: 0.00008603, Avg batch loss: 0.0201, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 1444, Step num: 10558, Learning rate: 0.00008602, Avg batch loss: 0.0171, Avg batch acc: 0.9828
Train, Epoch: 7, Batch: 1445, Step num: 10559, Learning rate: 0.00008602, Avg batch loss: 0.0117, Avg batch acc: 0.9892
Train, Epoch: 7, Batch: 1446, Step num: 10560, Learning rate: 0.00008601, Avg batch loss: 0.0145, Avg batch acc: 0.9898
Train, Epoch: 7, Batch: 1447, Step num: 10561, Learning rate: 0.00008601, Avg batch loss: 0.0109, Avg batch acc: 0.9886
Train, Epoch: 7, Batch: 1448, Step num: 10562, Learning rate: 0.00008600, Avg batch loss: 0.0119, Avg batch acc: 0.9881
Train, Epoch: 7, Batch: 1449, Step num: 10563, Learning rate: 0.00008600, Avg batch loss: 0.0163, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1450, Step num: 10564, Learning rate: 0.00008600, Avg batch loss: 0.0230, Avg batch acc: 0.9854
Train, Epoch: 7, Batch: 1451, Step num: 10565, Learning rate: 0.00008599, Avg batch loss: 0.0132, Avg batch acc: 0.9874
Train, Epoch: 7, Batch: 1452, Step num: 10566, Learning rate: 0.00008599, Avg batch loss: 0.0163, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1453, Step num: 10567, Learning rate: 0.00008598, Avg batch loss: 0.0124, Avg batch acc: 0.9854
Train, Epoch: 7, Batch: 1454, Step num: 10568, Learning rate: 0.00008598, Avg batch loss: 0.0161, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 1455, Step num: 10569, Learning rate: 0.00008598, Avg batch loss: 0.0185, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 1456, Step num: 10570, Learning rate: 0.00008597, Avg batch loss: 0.0163, Avg batch acc: 0.9880
Train, Epoch: 7, Batch: 1457, Step num: 10571, Learning rate: 0.00008597, Avg batch loss: 0.0246, Avg batch acc: 0.9805
Train, Epoch: 7, Batch: 1458, Step num: 10572, Learning rate: 0.00008596, Avg batch loss: 0.0148, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 1459, Step num: 10573, Learning rate: 0.00008596, Avg batch loss: 0.0149, Avg batch acc: 0.9863
Train, Epoch: 7, Batch: 1460, Step num: 10574, Learning rate: 0.00008596, Avg batch loss: 0.0145, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 1461, Step num: 10575, Learning rate: 0.00008595, Avg batch loss: 0.0163, Avg batch acc: 0.9860
Train, Epoch: 7, Batch: 1462, Step num: 10576, Learning rate: 0.00008595, Avg batch loss: 0.0302, Avg batch acc: 0.9825
Train, Epoch: 7, Batch: 1463, Step num: 10577, Learning rate: 0.00008594, Avg batch loss: 0.0149, Avg batch acc: 0.9852
Train, Epoch: 7, Batch: 1464, Step num: 10578, Learning rate: 0.00008594, Avg batch loss: 0.0153, Avg batch acc: 0.9843
Train, Epoch: 7, Batch: 1465, Step num: 10579, Learning rate: 0.00008594, Avg batch loss: 0.0154, Avg batch acc: 0.9875
Train, Epoch: 7, Batch: 1466, Step num: 10580, Learning rate: 0.00008593, Avg batch loss: 0.0379, Avg batch acc: 0.9812
Train, Epoch: 7, Batch: 1467, Step num: 10581, Learning rate: 0.00008593, Avg batch loss: 0.0167, Avg batch acc: 0.9829
Train, Epoch: 7, Batch: 1468, Step num: 10582, Learning rate: 0.00008592, Avg batch loss: 0.0134, Avg batch acc: 0.9879
Train, Epoch: 7, Batch: 1469, Step num: 10583, Learning rate: 0.00008592, Avg batch loss: 0.0161, Avg batch acc: 0.9836
Train, Epoch: 7, Batch: 1470, Step num: 10584, Learning rate: 0.00008592, Avg batch loss: 0.0143, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1471, Step num: 10585, Learning rate: 0.00008591, Avg batch loss: 0.0144, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1472, Step num: 10586, Learning rate: 0.00008591, Avg batch loss: 0.0117, Avg batch acc: 0.9885
Train, Epoch: 7, Batch: 1473, Step num: 10587, Learning rate: 0.00008590, Avg batch loss: 0.0170, Avg batch acc: 0.9839
Train, Epoch: 7, Batch: 1474, Step num: 10588, Learning rate: 0.00008590, Avg batch loss: 0.0158, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 1475, Step num: 10589, Learning rate: 0.00008589, Avg batch loss: 0.0174, Avg batch acc: 0.9831
Train, Epoch: 7, Batch: 1476, Step num: 10590, Learning rate: 0.00008589, Avg batch loss: 0.0113, Avg batch acc: 0.9905
Train, Epoch: 7, Batch: 1477, Step num: 10591, Learning rate: 0.00008589, Avg batch loss: 0.0177, Avg batch acc: 0.9844
Train, Epoch: 7, Batch: 1478, Step num: 10592, Learning rate: 0.00008588, Avg batch loss: 0.0160, Avg batch acc: 0.9841
Train, Epoch: 7, Batch: 1479, Step num: 10593, Learning rate: 0.00008588, Avg batch loss: 0.0162, Avg batch acc: 0.9810
Train, Epoch: 7, Batch: 1480, Step num: 10594, Learning rate: 0.00008587, Avg batch loss: 0.0225, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1481, Step num: 10595, Learning rate: 0.00008587, Avg batch loss: 0.0114, Avg batch acc: 0.9904
Train, Epoch: 7, Batch: 1482, Step num: 10596, Learning rate: 0.00008587, Avg batch loss: 0.0170, Avg batch acc: 0.9849
Train, Epoch: 7, Batch: 1483, Step num: 10597, Learning rate: 0.00008586, Avg batch loss: 0.0120, Avg batch acc: 0.9865
Train, Epoch: 7, Batch: 1484, Step num: 10598, Learning rate: 0.00008586, Avg batch loss: 0.0146, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1485, Step num: 10599, Learning rate: 0.00008585, Avg batch loss: 0.0170, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 1486, Step num: 10600, Learning rate: 0.00008585, Avg batch loss: 0.0227, Avg batch acc: 0.9809
Train, Epoch: 7, Batch: 1487, Step num: 10601, Learning rate: 0.00008585, Avg batch loss: 0.0141, Avg batch acc: 0.9873
Train, Epoch: 7, Batch: 1488, Step num: 10602, Learning rate: 0.00008584, Avg batch loss: 0.0145, Avg batch acc: 0.9878
Train, Epoch: 7, Batch: 1489, Step num: 10603, Learning rate: 0.00008584, Avg batch loss: 0.0140, Avg batch acc: 0.9857
Train, Epoch: 7, Batch: 1490, Step num: 10604, Learning rate: 0.00008583, Avg batch loss: 0.0139, Avg batch acc: 0.9864
Train, Epoch: 7, Batch: 1491, Step num: 10605, Learning rate: 0.00008583, Avg batch loss: 0.0157, Avg batch acc: 0.9867
Train, Epoch: 7, Batch: 1492, Step num: 10606, Learning rate: 0.00008583, Avg batch loss: 0.0109, Avg batch acc: 0.9906
Train, Epoch: 7, Batch: 1493, Step num: 10607, Learning rate: 0.00008582, Avg batch loss: 0.0154, Avg batch acc: 0.9902
Train, Epoch: 7, Batch: 1494, Step num: 10608, Learning rate: 0.00008582, Avg batch loss: 0.0188, Avg batch acc: 0.9856
Train, Epoch: 7, Batch: 1495, Step num: 10609, Learning rate: 0.00008581, Avg batch loss: 0.0147, Avg batch acc: 0.9855
Train, Epoch: 7, Batch: 1496, Step num: 10610, Learning rate: 0.00008581, Avg batch loss: 0.0179, Avg batch acc: 0.9842
Train, Epoch: 7, Batch: 1497, Step num: 10611, Learning rate: 0.00008581, Avg batch loss: 0.0147, Avg batch acc: 0.9857
Train, Epoch: 7, Batch: 1498, Step num: 10612, Learning rate: 0.00008580, Avg batch loss: 0.0180, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 1499, Step num: 10613, Learning rate: 0.00008580, Avg batch loss: 0.0129, Avg batch acc: 0.9883
Train, Epoch: 7, Batch: 1500, Step num: 10614, Learning rate: 0.00008579, Avg batch loss: 0.0186, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 1501, Step num: 10615, Learning rate: 0.00008579, Avg batch loss: 0.0142, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 1502, Step num: 10616, Learning rate: 0.00008579, Avg batch loss: 0.0124, Avg batch acc: 0.9899
Train, Epoch: 7, Batch: 1503, Step num: 10617, Learning rate: 0.00008578, Avg batch loss: 0.0120, Avg batch acc: 0.9895
Train, Epoch: 7, Batch: 1504, Step num: 10618, Learning rate: 0.00008578, Avg batch loss: 0.0121, Avg batch acc: 0.9861
Train, Epoch: 7, Batch: 1505, Step num: 10619, Learning rate: 0.00008577, Avg batch loss: 0.0107, Avg batch acc: 0.9906
Train, Epoch: 7, Batch: 1506, Step num: 10620, Learning rate: 0.00008577, Avg batch loss: 0.0171, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 1507, Step num: 10621, Learning rate: 0.00008577, Avg batch loss: 0.0126, Avg batch acc: 0.9850
Train, Epoch: 7, Batch: 1508, Step num: 10622, Learning rate: 0.00008576, Avg batch loss: 0.0112, Avg batch acc: 0.9866
Train, Epoch: 7, Batch: 1509, Step num: 10623, Learning rate: 0.00008576, Avg batch loss: 0.0137, Avg batch acc: 0.9870
Train, Epoch: 7, Batch: 1510, Step num: 10624, Learning rate: 0.00008575, Avg batch loss: 0.0211, Avg batch acc: 0.9832
Train, Epoch: 7, Batch: 1511, Step num: 10625, Learning rate: 0.00008575, Avg batch loss: 0.0157, Avg batch acc: 0.9835
Train, Epoch: 7, Batch: 1512, Step num: 10626, Learning rate: 0.00008575, Avg batch loss: 0.0132, Avg batch acc: 0.9889
Train, Epoch: 7, Batch: 1513, Step num: 10627, Learning rate: 0.00008574, Avg batch loss: 0.0154, Avg batch acc: 0.9811
Train, Epoch: 7, Batch: 1514, Step num: 10628, Learning rate: 0.00008574, Avg batch loss: 0.0146, Avg batch acc: 0.9862
Train, Epoch: 7, Batch: 1515, Step num: 10629, Learning rate: 0.00008573, Avg batch loss: 0.0129, Avg batch acc: 0.9851
Train, Epoch: 7, Batch: 1516, Step num: 10630, Learning rate: 0.00008573, Avg batch loss: 0.0166, Avg batch acc: 0.9830
Train, Epoch: 7, Batch: 1517, Step num: 10631, Learning rate: 0.00008573, Avg batch loss: 0.0114, Avg batch acc: 0.9848
Train, Epoch: 7, Batch: 1518, Step num: 10632, Learning rate: 0.00008572, Avg batch loss: 0.0131, Avg batch acc: 0.9894
Train, Epoch: 7, Batch: 1519, Step num: 10633, Learning rate: 0.00008572, Avg batch loss: 0.0116, Avg batch acc: 0.9892
Train, Epoch: 7, Avg epoch loss: 0.0179, Avg epoch acc: 0.9821, Overall time: 970.0 s, Speed: 4487.4 tokens/s on cuda:1

Validate, Epoch: 7, Batch: 1, Avg batch loss: 0.0126, Avg batch acc: 0.9874
Validate, Epoch: 7, Batch: 2, Avg batch loss: 0.0138, Avg batch acc: 0.9880
Validate, Epoch: 7, Batch: 3, Avg batch loss: 0.0125, Avg batch acc: 0.9880
Validate, Epoch: 7, Batch: 4, Avg batch loss: 0.0153, Avg batch acc: 0.9868
Validate, Epoch: 7, Batch: 5, Avg batch loss: 0.0104, Avg batch acc: 0.9911
Validate, Epoch: 7, Batch: 6, Avg batch loss: 0.0153, Avg batch acc: 0.9845
Validate, Epoch: 7, Batch: 7, Avg batch loss: 0.0124, Avg batch acc: 0.9892
Validate, Epoch: 7, Batch: 8, Avg batch loss: 0.0163, Avg batch acc: 0.9802
Validate, Epoch: 7, Batch: 9, Avg batch loss: 0.0115, Avg batch acc: 0.9875
Validate, Epoch: 7, Batch: 10, Avg batch loss: 0.0099, Avg batch acc: 0.9897
Validate, Epoch: 7, Batch: 11, Avg batch loss: 0.0126, Avg batch acc: 0.9860
Validate, Epoch: 7, Batch: 12, Avg batch loss: 0.0131, Avg batch acc: 0.9860
Validate, Epoch: 7, Batch: 13, Avg batch loss: 0.0119, Avg batch acc: 0.9883
Validate, Epoch: 7, Batch: 14, Avg batch loss: 0.0115, Avg batch acc: 0.9902
Validate, Epoch: 7, Batch: 15, Avg batch loss: 0.0130, Avg batch acc: 0.9877
Validate, Epoch: 7, Batch: 16, Avg batch loss: 0.0165, Avg batch acc: 0.9822
Validate, Epoch: 7, Batch: 17, Avg batch loss: 0.0162, Avg batch acc: 0.9857
Validate, Epoch: 7, Batch: 18, Avg batch loss: 0.0150, Avg batch acc: 0.9845
Validate, Epoch: 7, Batch: 19, Avg batch loss: 0.0127, Avg batch acc: 0.9882
Validate, Epoch: 7, Batch: 20, Avg batch loss: 0.0091, Avg batch acc: 0.9901
Validate, Epoch: 7, Batch: 21, Avg batch loss: 0.0109, Avg batch acc: 0.9905
Validate, Epoch: 7, Batch: 22, Avg batch loss: 0.0114, Avg batch acc: 0.9923
Validate, Epoch: 7, Batch: 23, Avg batch loss: 0.0123, Avg batch acc: 0.9882
Validate, Epoch: 7, Batch: 24, Avg batch loss: 0.0123, Avg batch acc: 0.9860
Validate, Epoch: 7, Batch: 25, Avg batch loss: 0.0156, Avg batch acc: 0.9854
Validate, Epoch: 7, Batch: 26, Avg batch loss: 0.0146, Avg batch acc: 0.9872
Validate, Epoch: 7, Batch: 27, Avg batch loss: 0.0190, Avg batch acc: 0.9848
Validate, Epoch: 7, Batch: 28, Avg batch loss: 0.0145, Avg batch acc: 0.9860
Validate, Epoch: 7, Batch: 29, Avg batch loss: 0.0158, Avg batch acc: 0.9850
Validate, Epoch: 7, Batch: 30, Avg batch loss: 0.0192, Avg batch acc: 0.9845
Validate, Epoch: 7, Batch: 31, Avg batch loss: 0.0135, Avg batch acc: 0.9880
Validate, Epoch: 7, Batch: 32, Avg batch loss: 0.0138, Avg batch acc: 0.9855
Validate, Epoch: 7, Batch: 33, Avg batch loss: 0.0151, Avg batch acc: 0.9831
Validate, Epoch: 7, Batch: 34, Avg batch loss: 0.0157, Avg batch acc: 0.9852
Validate, Epoch: 7, Batch: 35, Avg batch loss: 0.0129, Avg batch acc: 0.9847
Validate, Epoch: 7, Batch: 36, Avg batch loss: 0.0104, Avg batch acc: 0.9888
Validate, Epoch: 7, Batch: 37, Avg batch loss: 0.0164, Avg batch acc: 0.9864
Validate, Epoch: 7, Batch: 38, Avg batch loss: 0.0133, Avg batch acc: 0.9874
Validate, Epoch: 7, Batch: 39, Avg batch loss: 0.0129, Avg batch acc: 0.9884
Validate, Epoch: 7, Batch: 40, Avg batch loss: 0.0160, Avg batch acc: 0.9858
Validate, Epoch: 7, Batch: 41, Avg batch loss: 0.0119, Avg batch acc: 0.9851
Validate, Epoch: 7, Batch: 42, Avg batch loss: 0.0128, Avg batch acc: 0.9829
Validate, Epoch: 7, Batch: 43, Avg batch loss: 0.0168, Avg batch acc: 0.9846
Validate, Epoch: 7, Batch: 44, Avg batch loss: 0.0115, Avg batch acc: 0.9852
Validate, Epoch: 7, Batch: 45, Avg batch loss: 0.0160, Avg batch acc: 0.9844
Validate, Epoch: 7, Batch: 46, Avg batch loss: 0.0281, Avg batch acc: 0.9875
Validate, Epoch: 7, Batch: 47, Avg batch loss: 0.0140, Avg batch acc: 0.9868
Validate, Epoch: 7, Batch: 48, Avg batch loss: 0.0162, Avg batch acc: 0.9811
Validate, Epoch: 7, Batch: 49, Avg batch loss: 0.0125, Avg batch acc: 0.9896
Validate, Epoch: 7, Batch: 50, Avg batch loss: 0.0138, Avg batch acc: 0.9837
Validate, Epoch: 7, Batch: 51, Avg batch loss: 0.0149, Avg batch acc: 0.9872
Validate, Epoch: 7, Batch: 52, Avg batch loss: 0.0130, Avg batch acc: 0.9904
Validate, Epoch: 7, Batch: 53, Avg batch loss: 0.0173, Avg batch acc: 0.9825
Validate, Epoch: 7, Batch: 54, Avg batch loss: 0.0143, Avg batch acc: 0.9863
Validate, Epoch: 7, Batch: 55, Avg batch loss: 0.0116, Avg batch acc: 0.9868
Validate, Epoch: 7, Batch: 56, Avg batch loss: 0.0134, Avg batch acc: 0.9871
Validate, Epoch: 7, Batch: 57, Avg batch loss: 0.0140, Avg batch acc: 0.9861
Validate, Epoch: 7, Batch: 58, Avg batch loss: 0.0134, Avg batch acc: 0.9885
Validate, Epoch: 7, Batch: 59, Avg batch loss: 0.0129, Avg batch acc: 0.9874
Validate, Epoch: 7, Batch: 60, Avg batch loss: 0.0125, Avg batch acc: 0.9900
Validate, Epoch: 7, Batch: 61, Avg batch loss: 0.0186, Avg batch acc: 0.9805
Validate, Epoch: 7, Batch: 62, Avg batch loss: 0.0120, Avg batch acc: 0.9875
Validate, Epoch: 7, Batch: 63, Avg batch loss: 0.0084, Avg batch acc: 0.9909
Validate, Epoch: 7, Batch: 64, Avg batch loss: 0.0147, Avg batch acc: 0.9838
Validate, Epoch: 7, Batch: 65, Avg batch loss: 0.0279, Avg batch acc: 0.9810
Validate, Epoch: 7, Batch: 66, Avg batch loss: 0.0125, Avg batch acc: 0.9864
Validate, Epoch: 7, Batch: 67, Avg batch loss: 0.0130, Avg batch acc: 0.9791
Validate, Epoch: 7, Batch: 68, Avg batch loss: 0.0106, Avg batch acc: 0.9879
Validate, Epoch: 7, Batch: 69, Avg batch loss: 0.0142, Avg batch acc: 0.9855
Validate, Epoch: 7, Batch: 70, Avg batch loss: 0.0127, Avg batch acc: 0.9894
Validate, Epoch: 7, Batch: 71, Avg batch loss: 0.0140, Avg batch acc: 0.9863
Validate, Epoch: 7, Batch: 72, Avg batch loss: 0.0133, Avg batch acc: 0.9842
Validate, Epoch: 7, Batch: 73, Avg batch loss: 0.0165, Avg batch acc: 0.9832
Validate, Epoch: 7, Batch: 74, Avg batch loss: 0.0167, Avg batch acc: 0.9828
Validate, Epoch: 7, Batch: 75, Avg batch loss: 0.0132, Avg batch acc: 0.9863
Validate, Epoch: 7, Batch: 76, Avg batch loss: 0.0121, Avg batch acc: 0.9866
Validate, Epoch: 7, Batch: 77, Avg batch loss: 0.0132, Avg batch acc: 0.9878
Validate, Epoch: 7, Batch: 78, Avg batch loss: 0.0115, Avg batch acc: 0.9887
Validate, Epoch: 7, Batch: 79, Avg batch loss: 0.0138, Avg batch acc: 0.9876
Validate, Epoch: 7, Batch: 80, Avg batch loss: 0.0160, Avg batch acc: 0.9839
Validate, Epoch: 7, Batch: 81, Avg batch loss: 0.0132, Avg batch acc: 0.9869
Validate, Epoch: 7, Batch: 82, Avg batch loss: 0.0163, Avg batch acc: 0.9828
Validate, Epoch: 7, Batch: 83, Avg batch loss: 0.0106, Avg batch acc: 0.9883
Validate, Epoch: 7, Batch: 84, Avg batch loss: 0.0132, Avg batch acc: 0.9875
Validate, Epoch: 7, Batch: 85, Avg batch loss: 0.0148, Avg batch acc: 0.9850
Validate, Epoch: 7, Batch: 86, Avg batch loss: 0.0133, Avg batch acc: 0.9889
Validate, Epoch: 7, Batch: 87, Avg batch loss: 0.0097, Avg batch acc: 0.9880
Validate, Epoch: 7, Batch: 88, Avg batch loss: 0.0169, Avg batch acc: 0.9805
Validate, Epoch: 7, Batch: 89, Avg batch loss: 0.0152, Avg batch acc: 0.9859
Validate, Epoch: 7, Batch: 90, Avg batch loss: 0.0127, Avg batch acc: 0.9891
Validate, Epoch: 7, Batch: 91, Avg batch loss: 0.0146, Avg batch acc: 0.9863
Validate, Epoch: 7, Batch: 92, Avg batch loss: 0.0126, Avg batch acc: 0.9864
Validate, Epoch: 7, Batch: 93, Avg batch loss: 0.0152, Avg batch acc: 0.9856
Validate, Epoch: 7, Batch: 94, Avg batch loss: 0.0133, Avg batch acc: 0.9885
Validate, Epoch: 7, Batch: 95, Avg batch loss: 0.0115, Avg batch acc: 0.9889
Validate, Epoch: 7, Batch: 96, Avg batch loss: 0.0119, Avg batch acc: 0.9879
Validate, Epoch: 7, Batch: 97, Avg batch loss: 0.0123, Avg batch acc: 0.9885
Validate, Epoch: 7, Batch: 98, Avg batch loss: 0.0128, Avg batch acc: 0.9869
Validate, Epoch: 7, Batch: 99, Avg batch loss: 0.0131, Avg batch acc: 0.9870
Validate, Epoch: 7, Batch: 100, Avg batch loss: 0.0137, Avg batch acc: 0.9837
Validate, Epoch: 7, Batch: 101, Avg batch loss: 0.0128, Avg batch acc: 0.9878
Validate, Epoch: 7, Batch: 102, Avg batch loss: 0.0146, Avg batch acc: 0.9850
Validate, Epoch: 7, Batch: 103, Avg batch loss: 0.0147, Avg batch acc: 0.9851
Validate, Epoch: 7, Batch: 104, Avg batch loss: 0.0139, Avg batch acc: 0.9871
Validate, Epoch: 7, Batch: 105, Avg batch loss: 0.0164, Avg batch acc: 0.9835
Validate, Epoch: 7, Batch: 106, Avg batch loss: 0.0111, Avg batch acc: 0.9881
Validate, Epoch: 7, Batch: 107, Avg batch loss: 0.0128, Avg batch acc: 0.9901
Validate, Epoch: 7, Batch: 108, Avg batch loss: 0.0137, Avg batch acc: 0.9839
Validate, Epoch: 7, Batch: 109, Avg batch loss: 0.0131, Avg batch acc: 0.9887
Validate, Epoch: 7, Batch: 110, Avg batch loss: 0.0127, Avg batch acc: 0.9893
Validate, Epoch: 7, Batch: 111, Avg batch loss: 0.0144, Avg batch acc: 0.9874
Validate, Epoch: 7, Batch: 112, Avg batch loss: 0.0140, Avg batch acc: 0.9856
Validate, Epoch: 7, Batch: 113, Avg batch loss: 0.0128, Avg batch acc: 0.9848
Validate, Epoch: 7, Batch: 114, Avg batch loss: 0.0139, Avg batch acc: 0.9863
Validate, Epoch: 7, Batch: 115, Avg batch loss: 0.0110, Avg batch acc: 0.9874
Validate, Epoch: 7, Batch: 116, Avg batch loss: 0.0122, Avg batch acc: 0.9865
Validate, Epoch: 7, Batch: 117, Avg batch loss: 0.0132, Avg batch acc: 0.9854
Validate, Epoch: 7, Batch: 118, Avg batch loss: 0.0141, Avg batch acc: 0.9872
Validate, Epoch: 7, Batch: 119, Avg batch loss: 0.0124, Avg batch acc: 0.9866
Validate, Epoch: 7, Batch: 120, Avg batch loss: 0.0169, Avg batch acc: 0.9844
Validate, Epoch: 7, Batch: 121, Avg batch loss: 0.0212, Avg batch acc: 0.9816
Validate, Epoch: 7, Batch: 122, Avg batch loss: 0.0107, Avg batch acc: 0.9895
Validate, Epoch: 7, Batch: 123, Avg batch loss: 0.0133, Avg batch acc: 0.9858
Validate, Epoch: 7, Batch: 124, Avg batch loss: 0.0128, Avg batch acc: 0.9863
Validate, Epoch: 7, Batch: 125, Avg batch loss: 0.0148, Avg batch acc: 0.9822
Validate, Epoch: 7, Batch: 126, Avg batch loss: 0.0126, Avg batch acc: 0.9867
Validate, Epoch: 7, Batch: 127, Avg batch loss: 0.0108, Avg batch acc: 0.9890
Validate, Epoch: 7, Batch: 128, Avg batch loss: 0.0122, Avg batch acc: 0.9847
Validate, Epoch: 7, Batch: 129, Avg batch loss: 0.0106, Avg batch acc: 0.9917
Validate, Epoch: 7, Batch: 130, Avg batch loss: 0.0130, Avg batch acc: 0.9867
Validate, Epoch: 7, Batch: 131, Avg batch loss: 0.0162, Avg batch acc: 0.9867
Validate, Epoch: 7, Batch: 132, Avg batch loss: 0.0097, Avg batch acc: 0.9875
Validate, Epoch: 7, Batch: 133, Avg batch loss: 0.0110, Avg batch acc: 0.9877
Validate, Epoch: 7, Batch: 134, Avg batch loss: 0.0100, Avg batch acc: 0.9903
Validate, Epoch: 7, Batch: 135, Avg batch loss: 0.0151, Avg batch acc: 0.9807
Validate, Epoch: 7, Batch: 136, Avg batch loss: 0.0190, Avg batch acc: 0.9844
Validate, Epoch: 7, Batch: 137, Avg batch loss: 0.0100, Avg batch acc: 0.9906
Validate, Epoch: 7, Batch: 138, Avg batch loss: 0.0177, Avg batch acc: 0.9838
Validate, Epoch: 7, Batch: 139, Avg batch loss: 0.0157, Avg batch acc: 0.9858
Validate, Epoch: 7, Batch: 140, Avg batch loss: 0.0160, Avg batch acc: 0.9866
Validate, Epoch: 7, Batch: 141, Avg batch loss: 0.0161, Avg batch acc: 0.9802
Validate, Epoch: 7, Batch: 142, Avg batch loss: 0.0186, Avg batch acc: 0.9835
Validate, Epoch: 7, Batch: 143, Avg batch loss: 0.0155, Avg batch acc: 0.9846
Validate, Epoch: 7, Batch: 144, Avg batch loss: 0.0171, Avg batch acc: 0.9816
Validate, Epoch: 7, Batch: 145, Avg batch loss: 0.0164, Avg batch acc: 0.9853
Validate, Epoch: 7, Batch: 146, Avg batch loss: 0.0150, Avg batch acc: 0.9858
Validate, Epoch: 7, Batch: 147, Avg batch loss: 0.0116, Avg batch acc: 0.9900
Validate, Epoch: 7, Batch: 148, Avg batch loss: 0.0137, Avg batch acc: 0.9874
Validate, Epoch: 7, Batch: 149, Avg batch loss: 0.0129, Avg batch acc: 0.9851
Validate, Epoch: 7, Batch: 150, Avg batch loss: 0.0169, Avg batch acc: 0.9874
Validate, Epoch: 7, Batch: 151, Avg batch loss: 0.0147, Avg batch acc: 0.9891
Validate, Epoch: 7, Batch: 152, Avg batch loss: 0.0160, Avg batch acc: 0.9814
Validate, Epoch: 7, Batch: 153, Avg batch loss: 0.0139, Avg batch acc: 0.9853
Validate, Epoch: 7, Batch: 154, Avg batch loss: 0.0171, Avg batch acc: 0.9844
Validate, Epoch: 7, Batch: 155, Avg batch loss: 0.0140, Avg batch acc: 0.9844
Validate, Epoch: 7, Batch: 156, Avg batch loss: 0.0157, Avg batch acc: 0.9833
Validate, Epoch: 7, Batch: 157, Avg batch loss: 0.0162, Avg batch acc: 0.9807
Validate, Epoch: 7, Batch: 158, Avg batch loss: 0.0111, Avg batch acc: 0.9909
Validate, Epoch: 7, Batch: 159, Avg batch loss: 0.0156, Avg batch acc: 0.9867
Validate, Epoch: 7, Batch: 160, Avg batch loss: 0.0135, Avg batch acc: 0.9884
Validate, Epoch: 7, Batch: 161, Avg batch loss: 0.0101, Avg batch acc: 0.9911
Validate, Epoch: 7, Batch: 162, Avg batch loss: 0.0140, Avg batch acc: 0.9847
Validate, Epoch: 7, Batch: 163, Avg batch loss: 0.0125, Avg batch acc: 0.9865
Validate, Epoch: 7, Batch: 164, Avg batch loss: 0.0119, Avg batch acc: 0.9891
Validate, Epoch: 7, Batch: 165, Avg batch loss: 0.0090, Avg batch acc: 0.9908
Validate, Epoch: 7, Batch: 166, Avg batch loss: 0.0151, Avg batch acc: 0.9845
Validate, Epoch: 7, Batch: 167, Avg batch loss: 0.0142, Avg batch acc: 0.9843
Validate, Epoch: 7, Batch: 168, Avg batch loss: 0.0157, Avg batch acc: 0.9877
Validate, Epoch: 7, Batch: 169, Avg batch loss: 0.0131, Avg batch acc: 0.9868
Validate, Epoch: 7, Avg epoch loss: 0.0139, Avg epoch acc: 0.9863, Overall time: 37.6 s, Speed: 12843.4 tokens/s on cuda:1

Train, Epoch: 8, Batch: 1, Step num: 10634, Learning rate: 0.00008571, Avg batch loss: 0.0127, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 2, Step num: 10635, Learning rate: 0.00008571, Avg batch loss: 0.0111, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 3, Step num: 10636, Learning rate: 0.00008570, Avg batch loss: 0.0127, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 4, Step num: 10637, Learning rate: 0.00008570, Avg batch loss: 0.0169, Avg batch acc: 0.9826
Train, Epoch: 8, Batch: 5, Step num: 10638, Learning rate: 0.00008570, Avg batch loss: 0.0138, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 6, Step num: 10639, Learning rate: 0.00008569, Avg batch loss: 0.0120, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 7, Step num: 10640, Learning rate: 0.00008569, Avg batch loss: 0.0136, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 8, Step num: 10641, Learning rate: 0.00008568, Avg batch loss: 0.0226, Avg batch acc: 0.9823
Train, Epoch: 8, Batch: 9, Step num: 10642, Learning rate: 0.00008568, Avg batch loss: 0.0120, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 10, Step num: 10643, Learning rate: 0.00008568, Avg batch loss: 0.0145, Avg batch acc: 0.9841
Train, Epoch: 8, Batch: 11, Step num: 10644, Learning rate: 0.00008567, Avg batch loss: 0.0129, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 12, Step num: 10645, Learning rate: 0.00008567, Avg batch loss: 0.0139, Avg batch acc: 0.9860
Train, Epoch: 8, Batch: 13, Step num: 10646, Learning rate: 0.00008566, Avg batch loss: 0.0154, Avg batch acc: 0.9847
Train, Epoch: 8, Batch: 14, Step num: 10647, Learning rate: 0.00008566, Avg batch loss: 0.0108, Avg batch acc: 0.9853
Train, Epoch: 8, Batch: 15, Step num: 10648, Learning rate: 0.00008566, Avg batch loss: 0.0151, Avg batch acc: 0.9834
Train, Epoch: 8, Batch: 16, Step num: 10649, Learning rate: 0.00008565, Avg batch loss: 0.0118, Avg batch acc: 0.9857
Train, Epoch: 8, Batch: 17, Step num: 10650, Learning rate: 0.00008565, Avg batch loss: 0.0098, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 18, Step num: 10651, Learning rate: 0.00008564, Avg batch loss: 0.0163, Avg batch acc: 0.9828
Train, Epoch: 8, Batch: 19, Step num: 10652, Learning rate: 0.00008564, Avg batch loss: 0.0105, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 20, Step num: 10653, Learning rate: 0.00008564, Avg batch loss: 0.0096, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 21, Step num: 10654, Learning rate: 0.00008563, Avg batch loss: 0.0140, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 22, Step num: 10655, Learning rate: 0.00008563, Avg batch loss: 0.0142, Avg batch acc: 0.9850
Train, Epoch: 8, Batch: 23, Step num: 10656, Learning rate: 0.00008562, Avg batch loss: 0.0120, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 24, Step num: 10657, Learning rate: 0.00008562, Avg batch loss: 0.0151, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 25, Step num: 10658, Learning rate: 0.00008562, Avg batch loss: 0.0150, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 26, Step num: 10659, Learning rate: 0.00008561, Avg batch loss: 0.0123, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 27, Step num: 10660, Learning rate: 0.00008561, Avg batch loss: 0.0122, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 28, Step num: 10661, Learning rate: 0.00008560, Avg batch loss: 0.0139, Avg batch acc: 0.9812
Train, Epoch: 8, Batch: 29, Step num: 10662, Learning rate: 0.00008560, Avg batch loss: 0.0141, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 30, Step num: 10663, Learning rate: 0.00008560, Avg batch loss: 0.0149, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 31, Step num: 10664, Learning rate: 0.00008559, Avg batch loss: 0.0257, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 32, Step num: 10665, Learning rate: 0.00008559, Avg batch loss: 0.0138, Avg batch acc: 0.9851
Train, Epoch: 8, Batch: 33, Step num: 10666, Learning rate: 0.00008558, Avg batch loss: 0.0110, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 34, Step num: 10667, Learning rate: 0.00008558, Avg batch loss: 0.0142, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 35, Step num: 10668, Learning rate: 0.00008558, Avg batch loss: 0.0168, Avg batch acc: 0.9834
Train, Epoch: 8, Batch: 36, Step num: 10669, Learning rate: 0.00008557, Avg batch loss: 0.0124, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 37, Step num: 10670, Learning rate: 0.00008557, Avg batch loss: 0.0138, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 38, Step num: 10671, Learning rate: 0.00008556, Avg batch loss: 0.0287, Avg batch acc: 0.9819
Train, Epoch: 8, Batch: 39, Step num: 10672, Learning rate: 0.00008556, Avg batch loss: 0.0159, Avg batch acc: 0.9824
Train, Epoch: 8, Batch: 40, Step num: 10673, Learning rate: 0.00008556, Avg batch loss: 0.0102, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 41, Step num: 10674, Learning rate: 0.00008555, Avg batch loss: 0.0169, Avg batch acc: 0.9840
Train, Epoch: 8, Batch: 42, Step num: 10675, Learning rate: 0.00008555, Avg batch loss: 0.0143, Avg batch acc: 0.9852
Train, Epoch: 8, Batch: 43, Step num: 10676, Learning rate: 0.00008554, Avg batch loss: 0.0127, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 44, Step num: 10677, Learning rate: 0.00008554, Avg batch loss: 0.0171, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 45, Step num: 10678, Learning rate: 0.00008554, Avg batch loss: 0.0115, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 46, Step num: 10679, Learning rate: 0.00008553, Avg batch loss: 0.0187, Avg batch acc: 0.9802
Train, Epoch: 8, Batch: 47, Step num: 10680, Learning rate: 0.00008553, Avg batch loss: 0.0144, Avg batch acc: 0.9826
Train, Epoch: 8, Batch: 48, Step num: 10681, Learning rate: 0.00008552, Avg batch loss: 0.0145, Avg batch acc: 0.9845
Train, Epoch: 8, Batch: 49, Step num: 10682, Learning rate: 0.00008552, Avg batch loss: 0.0112, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 50, Step num: 10683, Learning rate: 0.00008552, Avg batch loss: 0.0117, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 51, Step num: 10684, Learning rate: 0.00008551, Avg batch loss: 0.0125, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 52, Step num: 10685, Learning rate: 0.00008551, Avg batch loss: 0.0155, Avg batch acc: 0.9839
Train, Epoch: 8, Batch: 53, Step num: 10686, Learning rate: 0.00008550, Avg batch loss: 0.0152, Avg batch acc: 0.9816
Train, Epoch: 8, Batch: 54, Step num: 10687, Learning rate: 0.00008550, Avg batch loss: 0.0149, Avg batch acc: 0.9839
Train, Epoch: 8, Batch: 55, Step num: 10688, Learning rate: 0.00008550, Avg batch loss: 0.0120, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 56, Step num: 10689, Learning rate: 0.00008549, Avg batch loss: 0.0152, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 57, Step num: 10690, Learning rate: 0.00008549, Avg batch loss: 0.0455, Avg batch acc: 0.9805
Train, Epoch: 8, Batch: 58, Step num: 10691, Learning rate: 0.00008548, Avg batch loss: 0.0130, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 59, Step num: 10692, Learning rate: 0.00008548, Avg batch loss: 0.0127, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 60, Step num: 10693, Learning rate: 0.00008548, Avg batch loss: 0.0155, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 61, Step num: 10694, Learning rate: 0.00008547, Avg batch loss: 0.0137, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 62, Step num: 10695, Learning rate: 0.00008547, Avg batch loss: 0.0125, Avg batch acc: 0.9827
Train, Epoch: 8, Batch: 63, Step num: 10696, Learning rate: 0.00008546, Avg batch loss: 0.0123, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 64, Step num: 10697, Learning rate: 0.00008546, Avg batch loss: 0.0120, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 65, Step num: 10698, Learning rate: 0.00008546, Avg batch loss: 0.0151, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 66, Step num: 10699, Learning rate: 0.00008545, Avg batch loss: 0.0133, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 67, Step num: 10700, Learning rate: 0.00008545, Avg batch loss: 0.0127, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 68, Step num: 10701, Learning rate: 0.00008544, Avg batch loss: 0.0119, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 69, Step num: 10702, Learning rate: 0.00008544, Avg batch loss: 0.0161, Avg batch acc: 0.9832
Train, Epoch: 8, Batch: 70, Step num: 10703, Learning rate: 0.00008544, Avg batch loss: 0.0199, Avg batch acc: 0.9822
Train, Epoch: 8, Batch: 71, Step num: 10704, Learning rate: 0.00008543, Avg batch loss: 0.0147, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 72, Step num: 10705, Learning rate: 0.00008543, Avg batch loss: 0.0144, Avg batch acc: 0.9837
Train, Epoch: 8, Batch: 73, Step num: 10706, Learning rate: 0.00008542, Avg batch loss: 0.0167, Avg batch acc: 0.9839
Train, Epoch: 8, Batch: 74, Step num: 10707, Learning rate: 0.00008542, Avg batch loss: 0.0123, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 75, Step num: 10708, Learning rate: 0.00008542, Avg batch loss: 0.0150, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 76, Step num: 10709, Learning rate: 0.00008541, Avg batch loss: 0.0118, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 77, Step num: 10710, Learning rate: 0.00008541, Avg batch loss: 0.0131, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 78, Step num: 10711, Learning rate: 0.00008540, Avg batch loss: 0.0117, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 79, Step num: 10712, Learning rate: 0.00008540, Avg batch loss: 0.0127, Avg batch acc: 0.9867
Train, Epoch: 8, Batch: 80, Step num: 10713, Learning rate: 0.00008540, Avg batch loss: 0.0131, Avg batch acc: 0.9841
Train, Epoch: 8, Batch: 81, Step num: 10714, Learning rate: 0.00008539, Avg batch loss: 0.0142, Avg batch acc: 0.9860
Train, Epoch: 8, Batch: 82, Step num: 10715, Learning rate: 0.00008539, Avg batch loss: 0.0162, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 83, Step num: 10716, Learning rate: 0.00008538, Avg batch loss: 0.0088, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 84, Step num: 10717, Learning rate: 0.00008538, Avg batch loss: 0.0141, Avg batch acc: 0.9848
Train, Epoch: 8, Batch: 85, Step num: 10718, Learning rate: 0.00008538, Avg batch loss: 0.0092, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 86, Step num: 10719, Learning rate: 0.00008537, Avg batch loss: 0.0145, Avg batch acc: 0.9852
Train, Epoch: 8, Batch: 87, Step num: 10720, Learning rate: 0.00008537, Avg batch loss: 0.0124, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 88, Step num: 10721, Learning rate: 0.00008536, Avg batch loss: 0.0129, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 89, Step num: 10722, Learning rate: 0.00008536, Avg batch loss: 0.0143, Avg batch acc: 0.9839
Train, Epoch: 8, Batch: 90, Step num: 10723, Learning rate: 0.00008536, Avg batch loss: 0.0163, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 91, Step num: 10724, Learning rate: 0.00008535, Avg batch loss: 0.0123, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 92, Step num: 10725, Learning rate: 0.00008535, Avg batch loss: 0.0158, Avg batch acc: 0.9782
Train, Epoch: 8, Batch: 93, Step num: 10726, Learning rate: 0.00008534, Avg batch loss: 0.0134, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 94, Step num: 10727, Learning rate: 0.00008534, Avg batch loss: 0.0127, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 95, Step num: 10728, Learning rate: 0.00008534, Avg batch loss: 0.0146, Avg batch acc: 0.9841
Train, Epoch: 8, Batch: 96, Step num: 10729, Learning rate: 0.00008533, Avg batch loss: 0.0141, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 97, Step num: 10730, Learning rate: 0.00008533, Avg batch loss: 0.0136, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 98, Step num: 10731, Learning rate: 0.00008532, Avg batch loss: 0.0112, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 99, Step num: 10732, Learning rate: 0.00008532, Avg batch loss: 0.0108, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 100, Step num: 10733, Learning rate: 0.00008532, Avg batch loss: 0.0108, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 101, Step num: 10734, Learning rate: 0.00008531, Avg batch loss: 0.0116, Avg batch acc: 0.9851
Train, Epoch: 8, Batch: 102, Step num: 10735, Learning rate: 0.00008531, Avg batch loss: 0.0126, Avg batch acc: 0.9848
Train, Epoch: 8, Batch: 103, Step num: 10736, Learning rate: 0.00008530, Avg batch loss: 0.0152, Avg batch acc: 0.9837
Train, Epoch: 8, Batch: 104, Step num: 10737, Learning rate: 0.00008530, Avg batch loss: 0.0126, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 105, Step num: 10738, Learning rate: 0.00008530, Avg batch loss: 0.0134, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 106, Step num: 10739, Learning rate: 0.00008529, Avg batch loss: 0.0154, Avg batch acc: 0.9826
Train, Epoch: 8, Batch: 107, Step num: 10740, Learning rate: 0.00008529, Avg batch loss: 0.0119, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 108, Step num: 10741, Learning rate: 0.00008529, Avg batch loss: 0.0143, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 109, Step num: 10742, Learning rate: 0.00008528, Avg batch loss: 0.0109, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 110, Step num: 10743, Learning rate: 0.00008528, Avg batch loss: 0.0117, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 111, Step num: 10744, Learning rate: 0.00008527, Avg batch loss: 0.0106, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 112, Step num: 10745, Learning rate: 0.00008527, Avg batch loss: 0.0115, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 113, Step num: 10746, Learning rate: 0.00008527, Avg batch loss: 0.0145, Avg batch acc: 0.9837
Train, Epoch: 8, Batch: 114, Step num: 10747, Learning rate: 0.00008526, Avg batch loss: 0.0104, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 115, Step num: 10748, Learning rate: 0.00008526, Avg batch loss: 0.0122, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 116, Step num: 10749, Learning rate: 0.00008525, Avg batch loss: 0.0150, Avg batch acc: 0.9857
Train, Epoch: 8, Batch: 117, Step num: 10750, Learning rate: 0.00008525, Avg batch loss: 0.0111, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 118, Step num: 10751, Learning rate: 0.00008525, Avg batch loss: 0.0101, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 119, Step num: 10752, Learning rate: 0.00008524, Avg batch loss: 0.0115, Avg batch acc: 0.9853
Train, Epoch: 8, Batch: 120, Step num: 10753, Learning rate: 0.00008524, Avg batch loss: 0.0127, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 121, Step num: 10754, Learning rate: 0.00008523, Avg batch loss: 0.0141, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 122, Step num: 10755, Learning rate: 0.00008523, Avg batch loss: 0.0224, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 123, Step num: 10756, Learning rate: 0.00008523, Avg batch loss: 0.0192, Avg batch acc: 0.9794
Train, Epoch: 8, Batch: 124, Step num: 10757, Learning rate: 0.00008522, Avg batch loss: 0.0160, Avg batch acc: 0.9851
Train, Epoch: 8, Batch: 125, Step num: 10758, Learning rate: 0.00008522, Avg batch loss: 0.0134, Avg batch acc: 0.9842
Train, Epoch: 8, Batch: 126, Step num: 10759, Learning rate: 0.00008521, Avg batch loss: 0.0156, Avg batch acc: 0.9839
Train, Epoch: 8, Batch: 127, Step num: 10760, Learning rate: 0.00008521, Avg batch loss: 0.0125, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 128, Step num: 10761, Learning rate: 0.00008521, Avg batch loss: 0.0105, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 129, Step num: 10762, Learning rate: 0.00008520, Avg batch loss: 0.0106, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 130, Step num: 10763, Learning rate: 0.00008520, Avg batch loss: 0.0102, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 131, Step num: 10764, Learning rate: 0.00008519, Avg batch loss: 0.0146, Avg batch acc: 0.9843
Train, Epoch: 8, Batch: 132, Step num: 10765, Learning rate: 0.00008519, Avg batch loss: 0.0109, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 133, Step num: 10766, Learning rate: 0.00008519, Avg batch loss: 0.0124, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 134, Step num: 10767, Learning rate: 0.00008518, Avg batch loss: 0.0139, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 135, Step num: 10768, Learning rate: 0.00008518, Avg batch loss: 0.0114, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 136, Step num: 10769, Learning rate: 0.00008517, Avg batch loss: 0.0139, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 137, Step num: 10770, Learning rate: 0.00008517, Avg batch loss: 0.0134, Avg batch acc: 0.9841
Train, Epoch: 8, Batch: 138, Step num: 10771, Learning rate: 0.00008517, Avg batch loss: 0.0095, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 139, Step num: 10772, Learning rate: 0.00008516, Avg batch loss: 0.0111, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 140, Step num: 10773, Learning rate: 0.00008516, Avg batch loss: 0.0133, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 141, Step num: 10774, Learning rate: 0.00008515, Avg batch loss: 0.0109, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 142, Step num: 10775, Learning rate: 0.00008515, Avg batch loss: 0.0098, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 143, Step num: 10776, Learning rate: 0.00008515, Avg batch loss: 0.0122, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 144, Step num: 10777, Learning rate: 0.00008514, Avg batch loss: 0.0166, Avg batch acc: 0.9850
Train, Epoch: 8, Batch: 145, Step num: 10778, Learning rate: 0.00008514, Avg batch loss: 0.0148, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 146, Step num: 10779, Learning rate: 0.00008513, Avg batch loss: 0.0140, Avg batch acc: 0.9844
Train, Epoch: 8, Batch: 147, Step num: 10780, Learning rate: 0.00008513, Avg batch loss: 0.0113, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 148, Step num: 10781, Learning rate: 0.00008513, Avg batch loss: 0.0139, Avg batch acc: 0.9843
Train, Epoch: 8, Batch: 149, Step num: 10782, Learning rate: 0.00008512, Avg batch loss: 0.0113, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 150, Step num: 10783, Learning rate: 0.00008512, Avg batch loss: 0.0149, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 151, Step num: 10784, Learning rate: 0.00008511, Avg batch loss: 0.0115, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 152, Step num: 10785, Learning rate: 0.00008511, Avg batch loss: 0.0111, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 153, Step num: 10786, Learning rate: 0.00008511, Avg batch loss: 0.0149, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 154, Step num: 10787, Learning rate: 0.00008510, Avg batch loss: 0.0110, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 155, Step num: 10788, Learning rate: 0.00008510, Avg batch loss: 0.0117, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 156, Step num: 10789, Learning rate: 0.00008510, Avg batch loss: 0.0174, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 157, Step num: 10790, Learning rate: 0.00008509, Avg batch loss: 0.0104, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 158, Step num: 10791, Learning rate: 0.00008509, Avg batch loss: 0.0111, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 159, Step num: 10792, Learning rate: 0.00008508, Avg batch loss: 0.0161, Avg batch acc: 0.9846
Train, Epoch: 8, Batch: 160, Step num: 10793, Learning rate: 0.00008508, Avg batch loss: 0.0139, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 161, Step num: 10794, Learning rate: 0.00008508, Avg batch loss: 0.0142, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 162, Step num: 10795, Learning rate: 0.00008507, Avg batch loss: 0.0129, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 163, Step num: 10796, Learning rate: 0.00008507, Avg batch loss: 0.0132, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 164, Step num: 10797, Learning rate: 0.00008506, Avg batch loss: 0.0168, Avg batch acc: 0.9805
Train, Epoch: 8, Batch: 165, Step num: 10798, Learning rate: 0.00008506, Avg batch loss: 0.0123, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 166, Step num: 10799, Learning rate: 0.00008506, Avg batch loss: 0.0124, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 167, Step num: 10800, Learning rate: 0.00008505, Avg batch loss: 0.0120, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 168, Step num: 10801, Learning rate: 0.00008505, Avg batch loss: 0.0160, Avg batch acc: 0.9829
Train, Epoch: 8, Batch: 169, Step num: 10802, Learning rate: 0.00008504, Avg batch loss: 0.0123, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 170, Step num: 10803, Learning rate: 0.00008504, Avg batch loss: 0.0145, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 171, Step num: 10804, Learning rate: 0.00008504, Avg batch loss: 0.0121, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 172, Step num: 10805, Learning rate: 0.00008503, Avg batch loss: 0.0151, Avg batch acc: 0.9853
Train, Epoch: 8, Batch: 173, Step num: 10806, Learning rate: 0.00008503, Avg batch loss: 0.0142, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 174, Step num: 10807, Learning rate: 0.00008502, Avg batch loss: 0.0133, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 175, Step num: 10808, Learning rate: 0.00008502, Avg batch loss: 0.0113, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 176, Step num: 10809, Learning rate: 0.00008502, Avg batch loss: 0.0167, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 177, Step num: 10810, Learning rate: 0.00008501, Avg batch loss: 0.0252, Avg batch acc: 0.9824
Train, Epoch: 8, Batch: 178, Step num: 10811, Learning rate: 0.00008501, Avg batch loss: 0.0112, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 179, Step num: 10812, Learning rate: 0.00008500, Avg batch loss: 0.0135, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 180, Step num: 10813, Learning rate: 0.00008500, Avg batch loss: 0.0150, Avg batch acc: 0.9850
Train, Epoch: 8, Batch: 181, Step num: 10814, Learning rate: 0.00008500, Avg batch loss: 0.0127, Avg batch acc: 0.9846
Train, Epoch: 8, Batch: 182, Step num: 10815, Learning rate: 0.00008499, Avg batch loss: 0.0158, Avg batch acc: 0.9830
Train, Epoch: 8, Batch: 183, Step num: 10816, Learning rate: 0.00008499, Avg batch loss: 0.0161, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 184, Step num: 10817, Learning rate: 0.00008498, Avg batch loss: 0.0150, Avg batch acc: 0.9848
Train, Epoch: 8, Batch: 185, Step num: 10818, Learning rate: 0.00008498, Avg batch loss: 0.0133, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 186, Step num: 10819, Learning rate: 0.00008498, Avg batch loss: 0.0103, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 187, Step num: 10820, Learning rate: 0.00008497, Avg batch loss: 0.0156, Avg batch acc: 0.9851
Train, Epoch: 8, Batch: 188, Step num: 10821, Learning rate: 0.00008497, Avg batch loss: 0.0138, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 189, Step num: 10822, Learning rate: 0.00008497, Avg batch loss: 0.0110, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 190, Step num: 10823, Learning rate: 0.00008496, Avg batch loss: 0.0120, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 191, Step num: 10824, Learning rate: 0.00008496, Avg batch loss: 0.0247, Avg batch acc: 0.9842
Train, Epoch: 8, Batch: 192, Step num: 10825, Learning rate: 0.00008495, Avg batch loss: 0.0097, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 193, Step num: 10826, Learning rate: 0.00008495, Avg batch loss: 0.0124, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 194, Step num: 10827, Learning rate: 0.00008495, Avg batch loss: 0.0130, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 195, Step num: 10828, Learning rate: 0.00008494, Avg batch loss: 0.0119, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 196, Step num: 10829, Learning rate: 0.00008494, Avg batch loss: 0.0134, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 197, Step num: 10830, Learning rate: 0.00008493, Avg batch loss: 0.0108, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 198, Step num: 10831, Learning rate: 0.00008493, Avg batch loss: 0.0111, Avg batch acc: 0.9846
Train, Epoch: 8, Batch: 199, Step num: 10832, Learning rate: 0.00008493, Avg batch loss: 0.0162, Avg batch acc: 0.9836
Train, Epoch: 8, Batch: 200, Step num: 10833, Learning rate: 0.00008492, Avg batch loss: 0.0132, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 201, Step num: 10834, Learning rate: 0.00008492, Avg batch loss: 0.0116, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 202, Step num: 10835, Learning rate: 0.00008491, Avg batch loss: 0.0180, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 203, Step num: 10836, Learning rate: 0.00008491, Avg batch loss: 0.0146, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 204, Step num: 10837, Learning rate: 0.00008491, Avg batch loss: 0.0172, Avg batch acc: 0.9839
Train, Epoch: 8, Batch: 205, Step num: 10838, Learning rate: 0.00008490, Avg batch loss: 0.0137, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 206, Step num: 10839, Learning rate: 0.00008490, Avg batch loss: 0.0140, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 207, Step num: 10840, Learning rate: 0.00008489, Avg batch loss: 0.0132, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 208, Step num: 10841, Learning rate: 0.00008489, Avg batch loss: 0.0138, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 209, Step num: 10842, Learning rate: 0.00008489, Avg batch loss: 0.0131, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 210, Step num: 10843, Learning rate: 0.00008488, Avg batch loss: 0.0111, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 211, Step num: 10844, Learning rate: 0.00008488, Avg batch loss: 0.0140, Avg batch acc: 0.9848
Train, Epoch: 8, Batch: 212, Step num: 10845, Learning rate: 0.00008488, Avg batch loss: 0.0091, Avg batch acc: 0.9928
Train, Epoch: 8, Batch: 213, Step num: 10846, Learning rate: 0.00008487, Avg batch loss: 0.0132, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 214, Step num: 10847, Learning rate: 0.00008487, Avg batch loss: 0.0145, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 215, Step num: 10848, Learning rate: 0.00008486, Avg batch loss: 0.0103, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 216, Step num: 10849, Learning rate: 0.00008486, Avg batch loss: 0.0120, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 217, Step num: 10850, Learning rate: 0.00008486, Avg batch loss: 0.0085, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 218, Step num: 10851, Learning rate: 0.00008485, Avg batch loss: 0.0143, Avg batch acc: 0.9846
Train, Epoch: 8, Batch: 219, Step num: 10852, Learning rate: 0.00008485, Avg batch loss: 0.0144, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 220, Step num: 10853, Learning rate: 0.00008484, Avg batch loss: 0.0114, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 221, Step num: 10854, Learning rate: 0.00008484, Avg batch loss: 0.0184, Avg batch acc: 0.9812
Train, Epoch: 8, Batch: 222, Step num: 10855, Learning rate: 0.00008484, Avg batch loss: 0.0166, Avg batch acc: 0.9849
Train, Epoch: 8, Batch: 223, Step num: 10856, Learning rate: 0.00008483, Avg batch loss: 0.0112, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 224, Step num: 10857, Learning rate: 0.00008483, Avg batch loss: 0.0135, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 225, Step num: 10858, Learning rate: 0.00008482, Avg batch loss: 0.0139, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 226, Step num: 10859, Learning rate: 0.00008482, Avg batch loss: 0.0114, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 227, Step num: 10860, Learning rate: 0.00008482, Avg batch loss: 0.0088, Avg batch acc: 0.9932
Train, Epoch: 8, Batch: 228, Step num: 10861, Learning rate: 0.00008481, Avg batch loss: 0.0146, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 229, Step num: 10862, Learning rate: 0.00008481, Avg batch loss: 0.0113, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 230, Step num: 10863, Learning rate: 0.00008480, Avg batch loss: 0.0113, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 231, Step num: 10864, Learning rate: 0.00008480, Avg batch loss: 0.0132, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 232, Step num: 10865, Learning rate: 0.00008480, Avg batch loss: 0.0138, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 233, Step num: 10866, Learning rate: 0.00008479, Avg batch loss: 0.0140, Avg batch acc: 0.9847
Train, Epoch: 8, Batch: 234, Step num: 10867, Learning rate: 0.00008479, Avg batch loss: 0.0106, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 235, Step num: 10868, Learning rate: 0.00008479, Avg batch loss: 0.0133, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 236, Step num: 10869, Learning rate: 0.00008478, Avg batch loss: 0.0121, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 237, Step num: 10870, Learning rate: 0.00008478, Avg batch loss: 0.0122, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 238, Step num: 10871, Learning rate: 0.00008477, Avg batch loss: 0.0124, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 239, Step num: 10872, Learning rate: 0.00008477, Avg batch loss: 0.0122, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 240, Step num: 10873, Learning rate: 0.00008477, Avg batch loss: 0.0123, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 241, Step num: 10874, Learning rate: 0.00008476, Avg batch loss: 0.0135, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 242, Step num: 10875, Learning rate: 0.00008476, Avg batch loss: 0.0151, Avg batch acc: 0.9847
Train, Epoch: 8, Batch: 243, Step num: 10876, Learning rate: 0.00008475, Avg batch loss: 0.0127, Avg batch acc: 0.9843
Train, Epoch: 8, Batch: 244, Step num: 10877, Learning rate: 0.00008475, Avg batch loss: 0.0140, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 245, Step num: 10878, Learning rate: 0.00008475, Avg batch loss: 0.0124, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 246, Step num: 10879, Learning rate: 0.00008474, Avg batch loss: 0.0154, Avg batch acc: 0.9821
Train, Epoch: 8, Batch: 247, Step num: 10880, Learning rate: 0.00008474, Avg batch loss: 0.0142, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 248, Step num: 10881, Learning rate: 0.00008473, Avg batch loss: 0.0111, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 249, Step num: 10882, Learning rate: 0.00008473, Avg batch loss: 0.0117, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 250, Step num: 10883, Learning rate: 0.00008473, Avg batch loss: 0.0159, Avg batch acc: 0.9867
Train, Epoch: 8, Batch: 251, Step num: 10884, Learning rate: 0.00008472, Avg batch loss: 0.0120, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 252, Step num: 10885, Learning rate: 0.00008472, Avg batch loss: 0.0117, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 253, Step num: 10886, Learning rate: 0.00008472, Avg batch loss: 0.0148, Avg batch acc: 0.9811
Train, Epoch: 8, Batch: 254, Step num: 10887, Learning rate: 0.00008471, Avg batch loss: 0.0134, Avg batch acc: 0.9833
Train, Epoch: 8, Batch: 255, Step num: 10888, Learning rate: 0.00008471, Avg batch loss: 0.0117, Avg batch acc: 0.9867
Train, Epoch: 8, Batch: 256, Step num: 10889, Learning rate: 0.00008470, Avg batch loss: 0.0160, Avg batch acc: 0.9840
Train, Epoch: 8, Batch: 257, Step num: 10890, Learning rate: 0.00008470, Avg batch loss: 0.0093, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 258, Step num: 10891, Learning rate: 0.00008470, Avg batch loss: 0.0134, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 259, Step num: 10892, Learning rate: 0.00008469, Avg batch loss: 0.0141, Avg batch acc: 0.9837
Train, Epoch: 8, Batch: 260, Step num: 10893, Learning rate: 0.00008469, Avg batch loss: 0.0128, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 261, Step num: 10894, Learning rate: 0.00008468, Avg batch loss: 0.0106, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 262, Step num: 10895, Learning rate: 0.00008468, Avg batch loss: 0.0115, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 263, Step num: 10896, Learning rate: 0.00008468, Avg batch loss: 0.0121, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 264, Step num: 10897, Learning rate: 0.00008467, Avg batch loss: 0.0101, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 265, Step num: 10898, Learning rate: 0.00008467, Avg batch loss: 0.0108, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 266, Step num: 10899, Learning rate: 0.00008466, Avg batch loss: 0.0110, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 267, Step num: 10900, Learning rate: 0.00008466, Avg batch loss: 0.0148, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 268, Step num: 10901, Learning rate: 0.00008466, Avg batch loss: 0.0115, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 269, Step num: 10902, Learning rate: 0.00008465, Avg batch loss: 0.0135, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 270, Step num: 10903, Learning rate: 0.00008465, Avg batch loss: 0.0113, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 271, Step num: 10904, Learning rate: 0.00008465, Avg batch loss: 0.0103, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 272, Step num: 10905, Learning rate: 0.00008464, Avg batch loss: 0.0136, Avg batch acc: 0.9853
Train, Epoch: 8, Batch: 273, Step num: 10906, Learning rate: 0.00008464, Avg batch loss: 0.0112, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 274, Step num: 10907, Learning rate: 0.00008463, Avg batch loss: 0.0100, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 275, Step num: 10908, Learning rate: 0.00008463, Avg batch loss: 0.0148, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 276, Step num: 10909, Learning rate: 0.00008463, Avg batch loss: 0.0127, Avg batch acc: 0.9845
Train, Epoch: 8, Batch: 277, Step num: 10910, Learning rate: 0.00008462, Avg batch loss: 0.0141, Avg batch acc: 0.9837
Train, Epoch: 8, Batch: 278, Step num: 10911, Learning rate: 0.00008462, Avg batch loss: 0.0138, Avg batch acc: 0.9842
Train, Epoch: 8, Batch: 279, Step num: 10912, Learning rate: 0.00008461, Avg batch loss: 0.0167, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 280, Step num: 10913, Learning rate: 0.00008461, Avg batch loss: 0.0101, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 281, Step num: 10914, Learning rate: 0.00008461, Avg batch loss: 0.0125, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 282, Step num: 10915, Learning rate: 0.00008460, Avg batch loss: 0.0127, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 283, Step num: 10916, Learning rate: 0.00008460, Avg batch loss: 0.0124, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 284, Step num: 10917, Learning rate: 0.00008459, Avg batch loss: 0.0138, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 285, Step num: 10918, Learning rate: 0.00008459, Avg batch loss: 0.0128, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 286, Step num: 10919, Learning rate: 0.00008459, Avg batch loss: 0.0160, Avg batch acc: 0.9844
Train, Epoch: 8, Batch: 287, Step num: 10920, Learning rate: 0.00008458, Avg batch loss: 0.0124, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 288, Step num: 10921, Learning rate: 0.00008458, Avg batch loss: 0.0146, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 289, Step num: 10922, Learning rate: 0.00008458, Avg batch loss: 0.0110, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 290, Step num: 10923, Learning rate: 0.00008457, Avg batch loss: 0.0105, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 291, Step num: 10924, Learning rate: 0.00008457, Avg batch loss: 0.0124, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 292, Step num: 10925, Learning rate: 0.00008456, Avg batch loss: 0.0112, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 293, Step num: 10926, Learning rate: 0.00008456, Avg batch loss: 0.0113, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 294, Step num: 10927, Learning rate: 0.00008456, Avg batch loss: 0.0162, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 295, Step num: 10928, Learning rate: 0.00008455, Avg batch loss: 0.0138, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 296, Step num: 10929, Learning rate: 0.00008455, Avg batch loss: 0.0106, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 297, Step num: 10930, Learning rate: 0.00008454, Avg batch loss: 0.0129, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 298, Step num: 10931, Learning rate: 0.00008454, Avg batch loss: 0.0193, Avg batch acc: 0.9812
Train, Epoch: 8, Batch: 299, Step num: 10932, Learning rate: 0.00008454, Avg batch loss: 0.0114, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 300, Step num: 10933, Learning rate: 0.00008453, Avg batch loss: 0.0148, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 301, Step num: 10934, Learning rate: 0.00008453, Avg batch loss: 0.0099, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 302, Step num: 10935, Learning rate: 0.00008453, Avg batch loss: 0.0096, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 303, Step num: 10936, Learning rate: 0.00008452, Avg batch loss: 0.0094, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 304, Step num: 10937, Learning rate: 0.00008452, Avg batch loss: 0.0129, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 305, Step num: 10938, Learning rate: 0.00008451, Avg batch loss: 0.0149, Avg batch acc: 0.9842
Train, Epoch: 8, Batch: 306, Step num: 10939, Learning rate: 0.00008451, Avg batch loss: 0.0107, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 307, Step num: 10940, Learning rate: 0.00008451, Avg batch loss: 0.0116, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 308, Step num: 10941, Learning rate: 0.00008450, Avg batch loss: 0.0126, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 309, Step num: 10942, Learning rate: 0.00008450, Avg batch loss: 0.0115, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 310, Step num: 10943, Learning rate: 0.00008449, Avg batch loss: 0.0135, Avg batch acc: 0.9857
Train, Epoch: 8, Batch: 311, Step num: 10944, Learning rate: 0.00008449, Avg batch loss: 0.0132, Avg batch acc: 0.9853
Train, Epoch: 8, Batch: 312, Step num: 10945, Learning rate: 0.00008449, Avg batch loss: 0.0133, Avg batch acc: 0.9850
Train, Epoch: 8, Batch: 313, Step num: 10946, Learning rate: 0.00008448, Avg batch loss: 0.0119, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 314, Step num: 10947, Learning rate: 0.00008448, Avg batch loss: 0.0127, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 315, Step num: 10948, Learning rate: 0.00008447, Avg batch loss: 0.0128, Avg batch acc: 0.9848
Train, Epoch: 8, Batch: 316, Step num: 10949, Learning rate: 0.00008447, Avg batch loss: 0.0087, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 317, Step num: 10950, Learning rate: 0.00008447, Avg batch loss: 0.0151, Avg batch acc: 0.9847
Train, Epoch: 8, Batch: 318, Step num: 10951, Learning rate: 0.00008446, Avg batch loss: 0.0144, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 319, Step num: 10952, Learning rate: 0.00008446, Avg batch loss: 0.0133, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 320, Step num: 10953, Learning rate: 0.00008446, Avg batch loss: 0.0109, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 321, Step num: 10954, Learning rate: 0.00008445, Avg batch loss: 0.0157, Avg batch acc: 0.9841
Train, Epoch: 8, Batch: 322, Step num: 10955, Learning rate: 0.00008445, Avg batch loss: 0.0094, Avg batch acc: 0.9920
Train, Epoch: 8, Batch: 323, Step num: 10956, Learning rate: 0.00008444, Avg batch loss: 0.0166, Avg batch acc: 0.9841
Train, Epoch: 8, Batch: 324, Step num: 10957, Learning rate: 0.00008444, Avg batch loss: 0.0220, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 325, Step num: 10958, Learning rate: 0.00008444, Avg batch loss: 0.0122, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 326, Step num: 10959, Learning rate: 0.00008443, Avg batch loss: 0.0142, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 327, Step num: 10960, Learning rate: 0.00008443, Avg batch loss: 0.0108, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 328, Step num: 10961, Learning rate: 0.00008442, Avg batch loss: 0.0123, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 329, Step num: 10962, Learning rate: 0.00008442, Avg batch loss: 0.0119, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 330, Step num: 10963, Learning rate: 0.00008442, Avg batch loss: 0.0138, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 331, Step num: 10964, Learning rate: 0.00008441, Avg batch loss: 0.0150, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 332, Step num: 10965, Learning rate: 0.00008441, Avg batch loss: 0.0134, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 333, Step num: 10966, Learning rate: 0.00008441, Avg batch loss: 0.0098, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 334, Step num: 10967, Learning rate: 0.00008440, Avg batch loss: 0.0106, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 335, Step num: 10968, Learning rate: 0.00008440, Avg batch loss: 0.0113, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 336, Step num: 10969, Learning rate: 0.00008439, Avg batch loss: 0.0155, Avg batch acc: 0.9795
Train, Epoch: 8, Batch: 337, Step num: 10970, Learning rate: 0.00008439, Avg batch loss: 0.0202, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 338, Step num: 10971, Learning rate: 0.00008439, Avg batch loss: 0.0113, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 339, Step num: 10972, Learning rate: 0.00008438, Avg batch loss: 0.0114, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 340, Step num: 10973, Learning rate: 0.00008438, Avg batch loss: 0.0117, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 341, Step num: 10974, Learning rate: 0.00008437, Avg batch loss: 0.0111, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 342, Step num: 10975, Learning rate: 0.00008437, Avg batch loss: 0.0149, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 343, Step num: 10976, Learning rate: 0.00008437, Avg batch loss: 0.0171, Avg batch acc: 0.9842
Train, Epoch: 8, Batch: 344, Step num: 10977, Learning rate: 0.00008436, Avg batch loss: 0.0121, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 345, Step num: 10978, Learning rate: 0.00008436, Avg batch loss: 0.0152, Avg batch acc: 0.9854
Train, Epoch: 8, Batch: 346, Step num: 10979, Learning rate: 0.00008436, Avg batch loss: 0.0114, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 347, Step num: 10980, Learning rate: 0.00008435, Avg batch loss: 0.0152, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 348, Step num: 10981, Learning rate: 0.00008435, Avg batch loss: 0.0147, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 349, Step num: 10982, Learning rate: 0.00008434, Avg batch loss: 0.0113, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 350, Step num: 10983, Learning rate: 0.00008434, Avg batch loss: 0.0123, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 351, Step num: 10984, Learning rate: 0.00008434, Avg batch loss: 0.0145, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 352, Step num: 10985, Learning rate: 0.00008433, Avg batch loss: 0.0135, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 353, Step num: 10986, Learning rate: 0.00008433, Avg batch loss: 0.0158, Avg batch acc: 0.9818
Train, Epoch: 8, Batch: 354, Step num: 10987, Learning rate: 0.00008432, Avg batch loss: 0.0128, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 355, Step num: 10988, Learning rate: 0.00008432, Avg batch loss: 0.0118, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 356, Step num: 10989, Learning rate: 0.00008432, Avg batch loss: 0.0157, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 357, Step num: 10990, Learning rate: 0.00008431, Avg batch loss: 0.0141, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 358, Step num: 10991, Learning rate: 0.00008431, Avg batch loss: 0.0495, Avg batch acc: 0.9828
Train, Epoch: 8, Batch: 359, Step num: 10992, Learning rate: 0.00008431, Avg batch loss: 0.0173, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 360, Step num: 10993, Learning rate: 0.00008430, Avg batch loss: 0.0136, Avg batch acc: 0.9840
Train, Epoch: 8, Batch: 361, Step num: 10994, Learning rate: 0.00008430, Avg batch loss: 0.0145, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 362, Step num: 10995, Learning rate: 0.00008429, Avg batch loss: 0.0104, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 363, Step num: 10996, Learning rate: 0.00008429, Avg batch loss: 0.0165, Avg batch acc: 0.9854
Train, Epoch: 8, Batch: 364, Step num: 10997, Learning rate: 0.00008429, Avg batch loss: 0.0140, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 365, Step num: 10998, Learning rate: 0.00008428, Avg batch loss: 0.0145, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 366, Step num: 10999, Learning rate: 0.00008428, Avg batch loss: 0.0152, Avg batch acc: 0.9832
Train, Epoch: 8, Batch: 367, Step num: 11000, Learning rate: 0.00008427, Avg batch loss: 0.0130, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 368, Step num: 11001, Learning rate: 0.00008427, Avg batch loss: 0.0128, Avg batch acc: 0.9851
Train, Epoch: 8, Batch: 369, Step num: 11002, Learning rate: 0.00008427, Avg batch loss: 0.0162, Avg batch acc: 0.9832
Train, Epoch: 8, Batch: 370, Step num: 11003, Learning rate: 0.00008426, Avg batch loss: 0.0183, Avg batch acc: 0.9849
Train, Epoch: 8, Batch: 371, Step num: 11004, Learning rate: 0.00008426, Avg batch loss: 0.0129, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 372, Step num: 11005, Learning rate: 0.00008426, Avg batch loss: 0.0120, Avg batch acc: 0.9846
Train, Epoch: 8, Batch: 373, Step num: 11006, Learning rate: 0.00008425, Avg batch loss: 0.0084, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 374, Step num: 11007, Learning rate: 0.00008425, Avg batch loss: 0.0156, Avg batch acc: 0.9824
Train, Epoch: 8, Batch: 375, Step num: 11008, Learning rate: 0.00008424, Avg batch loss: 0.0135, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 376, Step num: 11009, Learning rate: 0.00008424, Avg batch loss: 0.0131, Avg batch acc: 0.9850
Train, Epoch: 8, Batch: 377, Step num: 11010, Learning rate: 0.00008424, Avg batch loss: 0.0139, Avg batch acc: 0.9834
Train, Epoch: 8, Batch: 378, Step num: 11011, Learning rate: 0.00008423, Avg batch loss: 0.0110, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 379, Step num: 11012, Learning rate: 0.00008423, Avg batch loss: 0.0132, Avg batch acc: 0.9832
Train, Epoch: 8, Batch: 380, Step num: 11013, Learning rate: 0.00008423, Avg batch loss: 0.0108, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 381, Step num: 11014, Learning rate: 0.00008422, Avg batch loss: 0.0171, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 382, Step num: 11015, Learning rate: 0.00008422, Avg batch loss: 0.0148, Avg batch acc: 0.9818
Train, Epoch: 8, Batch: 383, Step num: 11016, Learning rate: 0.00008421, Avg batch loss: 0.0112, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 384, Step num: 11017, Learning rate: 0.00008421, Avg batch loss: 0.0158, Avg batch acc: 0.9849
Train, Epoch: 8, Batch: 385, Step num: 11018, Learning rate: 0.00008421, Avg batch loss: 0.0120, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 386, Step num: 11019, Learning rate: 0.00008420, Avg batch loss: 0.0122, Avg batch acc: 0.9851
Train, Epoch: 8, Batch: 387, Step num: 11020, Learning rate: 0.00008420, Avg batch loss: 0.0083, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 388, Step num: 11021, Learning rate: 0.00008419, Avg batch loss: 0.0125, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 389, Step num: 11022, Learning rate: 0.00008419, Avg batch loss: 0.0150, Avg batch acc: 0.9842
Train, Epoch: 8, Batch: 390, Step num: 11023, Learning rate: 0.00008419, Avg batch loss: 0.0138, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 391, Step num: 11024, Learning rate: 0.00008418, Avg batch loss: 0.0114, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 392, Step num: 11025, Learning rate: 0.00008418, Avg batch loss: 0.0115, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 393, Step num: 11026, Learning rate: 0.00008418, Avg batch loss: 0.0118, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 394, Step num: 11027, Learning rate: 0.00008417, Avg batch loss: 0.0125, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 395, Step num: 11028, Learning rate: 0.00008417, Avg batch loss: 0.0109, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 396, Step num: 11029, Learning rate: 0.00008416, Avg batch loss: 0.0110, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 397, Step num: 11030, Learning rate: 0.00008416, Avg batch loss: 0.0124, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 398, Step num: 11031, Learning rate: 0.00008416, Avg batch loss: 0.0124, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 399, Step num: 11032, Learning rate: 0.00008415, Avg batch loss: 0.0155, Avg batch acc: 0.9825
Train, Epoch: 8, Batch: 400, Step num: 11033, Learning rate: 0.00008415, Avg batch loss: 0.0106, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 401, Step num: 11034, Learning rate: 0.00008415, Avg batch loss: 0.0101, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 402, Step num: 11035, Learning rate: 0.00008414, Avg batch loss: 0.0106, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 403, Step num: 11036, Learning rate: 0.00008414, Avg batch loss: 0.0170, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 404, Step num: 11037, Learning rate: 0.00008413, Avg batch loss: 0.0114, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 405, Step num: 11038, Learning rate: 0.00008413, Avg batch loss: 0.0097, Avg batch acc: 0.9924
Train, Epoch: 8, Batch: 406, Step num: 11039, Learning rate: 0.00008413, Avg batch loss: 0.0127, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 407, Step num: 11040, Learning rate: 0.00008412, Avg batch loss: 0.0113, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 408, Step num: 11041, Learning rate: 0.00008412, Avg batch loss: 0.0085, Avg batch acc: 0.9944
Train, Epoch: 8, Batch: 409, Step num: 11042, Learning rate: 0.00008411, Avg batch loss: 0.0112, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 410, Step num: 11043, Learning rate: 0.00008411, Avg batch loss: 0.0130, Avg batch acc: 0.9852
Train, Epoch: 8, Batch: 411, Step num: 11044, Learning rate: 0.00008411, Avg batch loss: 0.0121, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 412, Step num: 11045, Learning rate: 0.00008410, Avg batch loss: 0.0115, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 413, Step num: 11046, Learning rate: 0.00008410, Avg batch loss: 0.0109, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 414, Step num: 11047, Learning rate: 0.00008410, Avg batch loss: 0.0089, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 415, Step num: 11048, Learning rate: 0.00008409, Avg batch loss: 0.0119, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 416, Step num: 11049, Learning rate: 0.00008409, Avg batch loss: 0.0098, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 417, Step num: 11050, Learning rate: 0.00008408, Avg batch loss: 0.0146, Avg batch acc: 0.9830
Train, Epoch: 8, Batch: 418, Step num: 11051, Learning rate: 0.00008408, Avg batch loss: 0.0123, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 419, Step num: 11052, Learning rate: 0.00008408, Avg batch loss: 0.0108, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 420, Step num: 11053, Learning rate: 0.00008407, Avg batch loss: 0.0118, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 421, Step num: 11054, Learning rate: 0.00008407, Avg batch loss: 0.0126, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 422, Step num: 11055, Learning rate: 0.00008407, Avg batch loss: 0.0127, Avg batch acc: 0.9830
Train, Epoch: 8, Batch: 423, Step num: 11056, Learning rate: 0.00008406, Avg batch loss: 0.0069, Avg batch acc: 0.9939
Train, Epoch: 8, Batch: 424, Step num: 11057, Learning rate: 0.00008406, Avg batch loss: 0.0109, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 425, Step num: 11058, Learning rate: 0.00008405, Avg batch loss: 0.0094, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 426, Step num: 11059, Learning rate: 0.00008405, Avg batch loss: 0.0098, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 427, Step num: 11060, Learning rate: 0.00008405, Avg batch loss: 0.0136, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 428, Step num: 11061, Learning rate: 0.00008404, Avg batch loss: 0.0118, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 429, Step num: 11062, Learning rate: 0.00008404, Avg batch loss: 0.0099, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 430, Step num: 11063, Learning rate: 0.00008403, Avg batch loss: 0.0112, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 431, Step num: 11064, Learning rate: 0.00008403, Avg batch loss: 0.0111, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 432, Step num: 11065, Learning rate: 0.00008403, Avg batch loss: 0.0108, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 433, Step num: 11066, Learning rate: 0.00008402, Avg batch loss: 0.0101, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 434, Step num: 11067, Learning rate: 0.00008402, Avg batch loss: 0.0157, Avg batch acc: 0.9843
Train, Epoch: 8, Batch: 435, Step num: 11068, Learning rate: 0.00008402, Avg batch loss: 0.0155, Avg batch acc: 0.9853
Train, Epoch: 8, Batch: 436, Step num: 11069, Learning rate: 0.00008401, Avg batch loss: 0.0109, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 437, Step num: 11070, Learning rate: 0.00008401, Avg batch loss: 0.0154, Avg batch acc: 0.9846
Train, Epoch: 8, Batch: 438, Step num: 11071, Learning rate: 0.00008400, Avg batch loss: 0.0117, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 439, Step num: 11072, Learning rate: 0.00008400, Avg batch loss: 0.0112, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 440, Step num: 11073, Learning rate: 0.00008400, Avg batch loss: 0.0130, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 441, Step num: 11074, Learning rate: 0.00008399, Avg batch loss: 0.0115, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 442, Step num: 11075, Learning rate: 0.00008399, Avg batch loss: 0.0135, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 443, Step num: 11076, Learning rate: 0.00008399, Avg batch loss: 0.0123, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 444, Step num: 11077, Learning rate: 0.00008398, Avg batch loss: 0.0108, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 445, Step num: 11078, Learning rate: 0.00008398, Avg batch loss: 0.0129, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 446, Step num: 11079, Learning rate: 0.00008397, Avg batch loss: 0.0107, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 447, Step num: 11080, Learning rate: 0.00008397, Avg batch loss: 0.0110, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 448, Step num: 11081, Learning rate: 0.00008397, Avg batch loss: 0.0129, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 449, Step num: 11082, Learning rate: 0.00008396, Avg batch loss: 0.0122, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 450, Step num: 11083, Learning rate: 0.00008396, Avg batch loss: 0.0105, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 451, Step num: 11084, Learning rate: 0.00008396, Avg batch loss: 0.0177, Avg batch acc: 0.9841
Train, Epoch: 8, Batch: 452, Step num: 11085, Learning rate: 0.00008395, Avg batch loss: 0.0109, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 453, Step num: 11086, Learning rate: 0.00008395, Avg batch loss: 0.0116, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 454, Step num: 11087, Learning rate: 0.00008394, Avg batch loss: 0.0103, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 455, Step num: 11088, Learning rate: 0.00008394, Avg batch loss: 0.0142, Avg batch acc: 0.9857
Train, Epoch: 8, Batch: 456, Step num: 11089, Learning rate: 0.00008394, Avg batch loss: 0.0138, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 457, Step num: 11090, Learning rate: 0.00008393, Avg batch loss: 0.0100, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 458, Step num: 11091, Learning rate: 0.00008393, Avg batch loss: 0.0134, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 459, Step num: 11092, Learning rate: 0.00008392, Avg batch loss: 0.0133, Avg batch acc: 0.9838
Train, Epoch: 8, Batch: 460, Step num: 11093, Learning rate: 0.00008392, Avg batch loss: 0.0111, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 461, Step num: 11094, Learning rate: 0.00008392, Avg batch loss: 0.0108, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 462, Step num: 11095, Learning rate: 0.00008391, Avg batch loss: 0.0121, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 463, Step num: 11096, Learning rate: 0.00008391, Avg batch loss: 0.0112, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 464, Step num: 11097, Learning rate: 0.00008391, Avg batch loss: 0.0101, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 465, Step num: 11098, Learning rate: 0.00008390, Avg batch loss: 0.0092, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 466, Step num: 11099, Learning rate: 0.00008390, Avg batch loss: 0.0114, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 467, Step num: 11100, Learning rate: 0.00008389, Avg batch loss: 0.0116, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 468, Step num: 11101, Learning rate: 0.00008389, Avg batch loss: 0.0100, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 469, Step num: 11102, Learning rate: 0.00008389, Avg batch loss: 0.0110, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 470, Step num: 11103, Learning rate: 0.00008388, Avg batch loss: 0.0134, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 471, Step num: 11104, Learning rate: 0.00008388, Avg batch loss: 0.0122, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 472, Step num: 11105, Learning rate: 0.00008388, Avg batch loss: 0.0101, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 473, Step num: 11106, Learning rate: 0.00008387, Avg batch loss: 0.0135, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 474, Step num: 11107, Learning rate: 0.00008387, Avg batch loss: 0.0157, Avg batch acc: 0.9823
Train, Epoch: 8, Batch: 475, Step num: 11108, Learning rate: 0.00008386, Avg batch loss: 0.0137, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 476, Step num: 11109, Learning rate: 0.00008386, Avg batch loss: 0.0123, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 477, Step num: 11110, Learning rate: 0.00008386, Avg batch loss: 0.0129, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 478, Step num: 11111, Learning rate: 0.00008385, Avg batch loss: 0.0174, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 479, Step num: 11112, Learning rate: 0.00008385, Avg batch loss: 0.0119, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 480, Step num: 11113, Learning rate: 0.00008385, Avg batch loss: 0.0106, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 481, Step num: 11114, Learning rate: 0.00008384, Avg batch loss: 0.0085, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 482, Step num: 11115, Learning rate: 0.00008384, Avg batch loss: 0.0123, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 483, Step num: 11116, Learning rate: 0.00008383, Avg batch loss: 0.0118, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 484, Step num: 11117, Learning rate: 0.00008383, Avg batch loss: 0.0131, Avg batch acc: 0.9839
Train, Epoch: 8, Batch: 485, Step num: 11118, Learning rate: 0.00008383, Avg batch loss: 0.0118, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 486, Step num: 11119, Learning rate: 0.00008382, Avg batch loss: 0.0137, Avg batch acc: 0.9851
Train, Epoch: 8, Batch: 487, Step num: 11120, Learning rate: 0.00008382, Avg batch loss: 0.0139, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 488, Step num: 11121, Learning rate: 0.00008382, Avg batch loss: 0.0148, Avg batch acc: 0.9850
Train, Epoch: 8, Batch: 489, Step num: 11122, Learning rate: 0.00008381, Avg batch loss: 0.0114, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 490, Step num: 11123, Learning rate: 0.00008381, Avg batch loss: 0.0108, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 491, Step num: 11124, Learning rate: 0.00008380, Avg batch loss: 0.0149, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 492, Step num: 11125, Learning rate: 0.00008380, Avg batch loss: 0.0103, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 493, Step num: 11126, Learning rate: 0.00008380, Avg batch loss: 0.0102, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 494, Step num: 11127, Learning rate: 0.00008379, Avg batch loss: 0.0105, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 495, Step num: 11128, Learning rate: 0.00008379, Avg batch loss: 0.0123, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 496, Step num: 11129, Learning rate: 0.00008379, Avg batch loss: 0.0110, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 497, Step num: 11130, Learning rate: 0.00008378, Avg batch loss: 0.0095, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 498, Step num: 11131, Learning rate: 0.00008378, Avg batch loss: 0.0104, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 499, Step num: 11132, Learning rate: 0.00008377, Avg batch loss: 0.0102, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 500, Step num: 11133, Learning rate: 0.00008377, Avg batch loss: 0.0141, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 501, Step num: 11134, Learning rate: 0.00008377, Avg batch loss: 0.0095, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 502, Step num: 11135, Learning rate: 0.00008376, Avg batch loss: 0.0121, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 503, Step num: 11136, Learning rate: 0.00008376, Avg batch loss: 0.0088, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 504, Step num: 11137, Learning rate: 0.00008376, Avg batch loss: 0.0111, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 505, Step num: 11138, Learning rate: 0.00008375, Avg batch loss: 0.0113, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 506, Step num: 11139, Learning rate: 0.00008375, Avg batch loss: 0.0120, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 507, Step num: 11140, Learning rate: 0.00008374, Avg batch loss: 0.0139, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 508, Step num: 11141, Learning rate: 0.00008374, Avg batch loss: 0.0128, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 509, Step num: 11142, Learning rate: 0.00008374, Avg batch loss: 0.0123, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 510, Step num: 11143, Learning rate: 0.00008373, Avg batch loss: 0.0096, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 511, Step num: 11144, Learning rate: 0.00008373, Avg batch loss: 0.0127, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 512, Step num: 11145, Learning rate: 0.00008372, Avg batch loss: 0.0119, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 513, Step num: 11146, Learning rate: 0.00008372, Avg batch loss: 0.0097, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 514, Step num: 11147, Learning rate: 0.00008372, Avg batch loss: 0.0111, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 515, Step num: 11148, Learning rate: 0.00008371, Avg batch loss: 0.0113, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 516, Step num: 11149, Learning rate: 0.00008371, Avg batch loss: 0.0114, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 517, Step num: 11150, Learning rate: 0.00008371, Avg batch loss: 0.0098, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 518, Step num: 11151, Learning rate: 0.00008370, Avg batch loss: 0.0107, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 519, Step num: 11152, Learning rate: 0.00008370, Avg batch loss: 0.0107, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 520, Step num: 11153, Learning rate: 0.00008369, Avg batch loss: 0.0137, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 521, Step num: 11154, Learning rate: 0.00008369, Avg batch loss: 0.0114, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 522, Step num: 11155, Learning rate: 0.00008369, Avg batch loss: 0.0096, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 523, Step num: 11156, Learning rate: 0.00008368, Avg batch loss: 0.0128, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 524, Step num: 11157, Learning rate: 0.00008368, Avg batch loss: 0.0104, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 525, Step num: 11158, Learning rate: 0.00008368, Avg batch loss: 0.0103, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 526, Step num: 11159, Learning rate: 0.00008367, Avg batch loss: 0.0118, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 527, Step num: 11160, Learning rate: 0.00008367, Avg batch loss: 0.0141, Avg batch acc: 0.9844
Train, Epoch: 8, Batch: 528, Step num: 11161, Learning rate: 0.00008366, Avg batch loss: 0.0117, Avg batch acc: 0.9846
Train, Epoch: 8, Batch: 529, Step num: 11162, Learning rate: 0.00008366, Avg batch loss: 0.0099, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 530, Step num: 11163, Learning rate: 0.00008366, Avg batch loss: 0.0097, Avg batch acc: 0.9920
Train, Epoch: 8, Batch: 531, Step num: 11164, Learning rate: 0.00008365, Avg batch loss: 0.0107, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 532, Step num: 11165, Learning rate: 0.00008365, Avg batch loss: 0.0090, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 533, Step num: 11166, Learning rate: 0.00008365, Avg batch loss: 0.0080, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 534, Step num: 11167, Learning rate: 0.00008364, Avg batch loss: 0.0134, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 535, Step num: 11168, Learning rate: 0.00008364, Avg batch loss: 0.0127, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 536, Step num: 11169, Learning rate: 0.00008363, Avg batch loss: 0.0091, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 537, Step num: 11170, Learning rate: 0.00008363, Avg batch loss: 0.0091, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 538, Step num: 11171, Learning rate: 0.00008363, Avg batch loss: 0.0126, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 539, Step num: 11172, Learning rate: 0.00008362, Avg batch loss: 0.0103, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 540, Step num: 11173, Learning rate: 0.00008362, Avg batch loss: 0.0126, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 541, Step num: 11174, Learning rate: 0.00008362, Avg batch loss: 0.0166, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 542, Step num: 11175, Learning rate: 0.00008361, Avg batch loss: 0.0128, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 543, Step num: 11176, Learning rate: 0.00008361, Avg batch loss: 0.0115, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 544, Step num: 11177, Learning rate: 0.00008361, Avg batch loss: 0.0123, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 545, Step num: 11178, Learning rate: 0.00008360, Avg batch loss: 0.0115, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 546, Step num: 11179, Learning rate: 0.00008360, Avg batch loss: 0.0098, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 547, Step num: 11180, Learning rate: 0.00008359, Avg batch loss: 0.0100, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 548, Step num: 11181, Learning rate: 0.00008359, Avg batch loss: 0.0133, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 549, Step num: 11182, Learning rate: 0.00008359, Avg batch loss: 0.0090, Avg batch acc: 0.9915
Train, Epoch: 8, Batch: 550, Step num: 11183, Learning rate: 0.00008358, Avg batch loss: 0.0110, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 551, Step num: 11184, Learning rate: 0.00008358, Avg batch loss: 0.0094, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 552, Step num: 11185, Learning rate: 0.00008358, Avg batch loss: 0.0124, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 553, Step num: 11186, Learning rate: 0.00008357, Avg batch loss: 0.0152, Avg batch acc: 0.9831
Train, Epoch: 8, Batch: 554, Step num: 11187, Learning rate: 0.00008357, Avg batch loss: 0.0128, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 555, Step num: 11188, Learning rate: 0.00008356, Avg batch loss: 0.0143, Avg batch acc: 0.9849
Train, Epoch: 8, Batch: 556, Step num: 11189, Learning rate: 0.00008356, Avg batch loss: 0.0125, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 557, Step num: 11190, Learning rate: 0.00008356, Avg batch loss: 0.0429, Avg batch acc: 0.9790
Train, Epoch: 8, Batch: 558, Step num: 11191, Learning rate: 0.00008355, Avg batch loss: 0.0112, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 559, Step num: 11192, Learning rate: 0.00008355, Avg batch loss: 0.0137, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 560, Step num: 11193, Learning rate: 0.00008355, Avg batch loss: 0.0102, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 561, Step num: 11194, Learning rate: 0.00008354, Avg batch loss: 0.0089, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 562, Step num: 11195, Learning rate: 0.00008354, Avg batch loss: 0.0098, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 563, Step num: 11196, Learning rate: 0.00008353, Avg batch loss: 0.0132, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 564, Step num: 11197, Learning rate: 0.00008353, Avg batch loss: 0.0101, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 565, Step num: 11198, Learning rate: 0.00008353, Avg batch loss: 0.0109, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 566, Step num: 11199, Learning rate: 0.00008352, Avg batch loss: 0.0116, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 567, Step num: 11200, Learning rate: 0.00008352, Avg batch loss: 0.0161, Avg batch acc: 0.9823
Train, Epoch: 8, Batch: 568, Step num: 11201, Learning rate: 0.00008352, Avg batch loss: 0.0148, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 569, Step num: 11202, Learning rate: 0.00008351, Avg batch loss: 0.0114, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 570, Step num: 11203, Learning rate: 0.00008351, Avg batch loss: 0.0126, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 571, Step num: 11204, Learning rate: 0.00008350, Avg batch loss: 0.0111, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 572, Step num: 11205, Learning rate: 0.00008350, Avg batch loss: 0.0148, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 573, Step num: 11206, Learning rate: 0.00008350, Avg batch loss: 0.0101, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 574, Step num: 11207, Learning rate: 0.00008349, Avg batch loss: 0.0081, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 575, Step num: 11208, Learning rate: 0.00008349, Avg batch loss: 0.0379, Avg batch acc: 0.9854
Train, Epoch: 8, Batch: 576, Step num: 11209, Learning rate: 0.00008349, Avg batch loss: 0.0118, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 577, Step num: 11210, Learning rate: 0.00008348, Avg batch loss: 0.0112, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 578, Step num: 11211, Learning rate: 0.00008348, Avg batch loss: 0.0688, Avg batch acc: 0.9832
Train, Epoch: 8, Batch: 579, Step num: 11212, Learning rate: 0.00008347, Avg batch loss: 0.0147, Avg batch acc: 0.9852
Train, Epoch: 8, Batch: 580, Step num: 11213, Learning rate: 0.00008347, Avg batch loss: 0.0152, Avg batch acc: 0.9830
Train, Epoch: 8, Batch: 581, Step num: 11214, Learning rate: 0.00008347, Avg batch loss: 0.0090, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 582, Step num: 11215, Learning rate: 0.00008346, Avg batch loss: 0.0100, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 583, Step num: 11216, Learning rate: 0.00008346, Avg batch loss: 0.0129, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 584, Step num: 11217, Learning rate: 0.00008346, Avg batch loss: 0.0127, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 585, Step num: 11218, Learning rate: 0.00008345, Avg batch loss: 0.0142, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 586, Step num: 11219, Learning rate: 0.00008345, Avg batch loss: 0.0086, Avg batch acc: 0.9932
Train, Epoch: 8, Batch: 587, Step num: 11220, Learning rate: 0.00008344, Avg batch loss: 0.0113, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 588, Step num: 11221, Learning rate: 0.00008344, Avg batch loss: 0.0128, Avg batch acc: 0.9857
Train, Epoch: 8, Batch: 589, Step num: 11222, Learning rate: 0.00008344, Avg batch loss: 0.0114, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 590, Step num: 11223, Learning rate: 0.00008343, Avg batch loss: 0.0118, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 591, Step num: 11224, Learning rate: 0.00008343, Avg batch loss: 0.0117, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 592, Step num: 11225, Learning rate: 0.00008343, Avg batch loss: 0.0159, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 593, Step num: 11226, Learning rate: 0.00008342, Avg batch loss: 0.0100, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 594, Step num: 11227, Learning rate: 0.00008342, Avg batch loss: 0.0113, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 595, Step num: 11228, Learning rate: 0.00008341, Avg batch loss: 0.0221, Avg batch acc: 0.9804
Train, Epoch: 8, Batch: 596, Step num: 11229, Learning rate: 0.00008341, Avg batch loss: 0.0085, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 597, Step num: 11230, Learning rate: 0.00008341, Avg batch loss: 0.0089, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 598, Step num: 11231, Learning rate: 0.00008340, Avg batch loss: 0.0095, Avg batch acc: 0.9931
Train, Epoch: 8, Batch: 599, Step num: 11232, Learning rate: 0.00008340, Avg batch loss: 0.0100, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 600, Step num: 11233, Learning rate: 0.00008340, Avg batch loss: 0.0102, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 601, Step num: 11234, Learning rate: 0.00008339, Avg batch loss: 0.0135, Avg batch acc: 0.9824
Train, Epoch: 8, Batch: 602, Step num: 11235, Learning rate: 0.00008339, Avg batch loss: 0.0121, Avg batch acc: 0.9853
Train, Epoch: 8, Batch: 603, Step num: 11236, Learning rate: 0.00008339, Avg batch loss: 0.0139, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 604, Step num: 11237, Learning rate: 0.00008338, Avg batch loss: 0.0098, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 605, Step num: 11238, Learning rate: 0.00008338, Avg batch loss: 0.0116, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 606, Step num: 11239, Learning rate: 0.00008337, Avg batch loss: 0.0142, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 607, Step num: 11240, Learning rate: 0.00008337, Avg batch loss: 0.0129, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 608, Step num: 11241, Learning rate: 0.00008337, Avg batch loss: 0.0124, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 609, Step num: 11242, Learning rate: 0.00008336, Avg batch loss: 0.0128, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 610, Step num: 11243, Learning rate: 0.00008336, Avg batch loss: 0.0105, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 611, Step num: 11244, Learning rate: 0.00008336, Avg batch loss: 0.0142, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 612, Step num: 11245, Learning rate: 0.00008335, Avg batch loss: 0.0117, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 613, Step num: 11246, Learning rate: 0.00008335, Avg batch loss: 0.0134, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 614, Step num: 11247, Learning rate: 0.00008334, Avg batch loss: 0.0104, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 615, Step num: 11248, Learning rate: 0.00008334, Avg batch loss: 0.0136, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 616, Step num: 11249, Learning rate: 0.00008334, Avg batch loss: 0.0150, Avg batch acc: 0.9791
Train, Epoch: 8, Batch: 617, Step num: 11250, Learning rate: 0.00008333, Avg batch loss: 0.0104, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 618, Step num: 11251, Learning rate: 0.00008333, Avg batch loss: 0.0109, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 619, Step num: 11252, Learning rate: 0.00008333, Avg batch loss: 0.0122, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 620, Step num: 11253, Learning rate: 0.00008332, Avg batch loss: 0.0082, Avg batch acc: 0.9933
Train, Epoch: 8, Batch: 621, Step num: 11254, Learning rate: 0.00008332, Avg batch loss: 0.0105, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 622, Step num: 11255, Learning rate: 0.00008331, Avg batch loss: 0.0081, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 623, Step num: 11256, Learning rate: 0.00008331, Avg batch loss: 0.0222, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 624, Step num: 11257, Learning rate: 0.00008331, Avg batch loss: 0.0132, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 625, Step num: 11258, Learning rate: 0.00008330, Avg batch loss: 0.0109, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 626, Step num: 11259, Learning rate: 0.00008330, Avg batch loss: 0.0095, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 627, Step num: 11260, Learning rate: 0.00008330, Avg batch loss: 0.0131, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 628, Step num: 11261, Learning rate: 0.00008329, Avg batch loss: 0.0107, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 629, Step num: 11262, Learning rate: 0.00008329, Avg batch loss: 0.0135, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 630, Step num: 11263, Learning rate: 0.00008329, Avg batch loss: 0.0102, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 631, Step num: 11264, Learning rate: 0.00008328, Avg batch loss: 0.0116, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 632, Step num: 11265, Learning rate: 0.00008328, Avg batch loss: 0.0085, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 633, Step num: 11266, Learning rate: 0.00008327, Avg batch loss: 0.0084, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 634, Step num: 11267, Learning rate: 0.00008327, Avg batch loss: 0.0101, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 635, Step num: 11268, Learning rate: 0.00008327, Avg batch loss: 0.0094, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 636, Step num: 11269, Learning rate: 0.00008326, Avg batch loss: 0.0102, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 637, Step num: 11270, Learning rate: 0.00008326, Avg batch loss: 0.0125, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 638, Step num: 11271, Learning rate: 0.00008326, Avg batch loss: 0.0141, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 639, Step num: 11272, Learning rate: 0.00008325, Avg batch loss: 0.0129, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 640, Step num: 11273, Learning rate: 0.00008325, Avg batch loss: 0.0116, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 641, Step num: 11274, Learning rate: 0.00008324, Avg batch loss: 0.0106, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 642, Step num: 11275, Learning rate: 0.00008324, Avg batch loss: 0.0092, Avg batch acc: 0.9920
Train, Epoch: 8, Batch: 643, Step num: 11276, Learning rate: 0.00008324, Avg batch loss: 0.0133, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 644, Step num: 11277, Learning rate: 0.00008323, Avg batch loss: 0.0133, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 645, Step num: 11278, Learning rate: 0.00008323, Avg batch loss: 0.0115, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 646, Step num: 11279, Learning rate: 0.00008323, Avg batch loss: 0.0109, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 647, Step num: 11280, Learning rate: 0.00008322, Avg batch loss: 0.0097, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 648, Step num: 11281, Learning rate: 0.00008322, Avg batch loss: 0.0093, Avg batch acc: 0.9920
Train, Epoch: 8, Batch: 649, Step num: 11282, Learning rate: 0.00008322, Avg batch loss: 0.0134, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 650, Step num: 11283, Learning rate: 0.00008321, Avg batch loss: 0.0131, Avg batch acc: 0.9826
Train, Epoch: 8, Batch: 651, Step num: 11284, Learning rate: 0.00008321, Avg batch loss: 0.0121, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 652, Step num: 11285, Learning rate: 0.00008320, Avg batch loss: 0.0081, Avg batch acc: 0.9948
Train, Epoch: 8, Batch: 653, Step num: 11286, Learning rate: 0.00008320, Avg batch loss: 0.0099, Avg batch acc: 0.9931
Train, Epoch: 8, Batch: 654, Step num: 11287, Learning rate: 0.00008320, Avg batch loss: 0.0122, Avg batch acc: 0.9867
Train, Epoch: 8, Batch: 655, Step num: 11288, Learning rate: 0.00008319, Avg batch loss: 0.0104, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 656, Step num: 11289, Learning rate: 0.00008319, Avg batch loss: 0.0092, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 657, Step num: 11290, Learning rate: 0.00008319, Avg batch loss: 0.0099, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 658, Step num: 11291, Learning rate: 0.00008318, Avg batch loss: 0.0112, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 659, Step num: 11292, Learning rate: 0.00008318, Avg batch loss: 0.0092, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 660, Step num: 11293, Learning rate: 0.00008317, Avg batch loss: 0.0114, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 661, Step num: 11294, Learning rate: 0.00008317, Avg batch loss: 0.0092, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 662, Step num: 11295, Learning rate: 0.00008317, Avg batch loss: 0.0116, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 663, Step num: 11296, Learning rate: 0.00008316, Avg batch loss: 0.0128, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 664, Step num: 11297, Learning rate: 0.00008316, Avg batch loss: 0.0107, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 665, Step num: 11298, Learning rate: 0.00008316, Avg batch loss: 0.0114, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 666, Step num: 11299, Learning rate: 0.00008315, Avg batch loss: 0.0096, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 667, Step num: 11300, Learning rate: 0.00008315, Avg batch loss: 0.0083, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 668, Step num: 11301, Learning rate: 0.00008315, Avg batch loss: 0.0120, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 669, Step num: 11302, Learning rate: 0.00008314, Avg batch loss: 0.0090, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 670, Step num: 11303, Learning rate: 0.00008314, Avg batch loss: 0.0171, Avg batch acc: 0.9789
Train, Epoch: 8, Batch: 671, Step num: 11304, Learning rate: 0.00008313, Avg batch loss: 0.0111, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 672, Step num: 11305, Learning rate: 0.00008313, Avg batch loss: 0.0099, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 673, Step num: 11306, Learning rate: 0.00008313, Avg batch loss: 0.0110, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 674, Step num: 11307, Learning rate: 0.00008312, Avg batch loss: 0.0115, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 675, Step num: 11308, Learning rate: 0.00008312, Avg batch loss: 0.0114, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 676, Step num: 11309, Learning rate: 0.00008312, Avg batch loss: 0.0112, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 677, Step num: 11310, Learning rate: 0.00008311, Avg batch loss: 0.0106, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 678, Step num: 11311, Learning rate: 0.00008311, Avg batch loss: 0.0101, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 679, Step num: 11312, Learning rate: 0.00008310, Avg batch loss: 0.0082, Avg batch acc: 0.9939
Train, Epoch: 8, Batch: 680, Step num: 11313, Learning rate: 0.00008310, Avg batch loss: 0.0102, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 681, Step num: 11314, Learning rate: 0.00008310, Avg batch loss: 0.0111, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 682, Step num: 11315, Learning rate: 0.00008309, Avg batch loss: 0.0137, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 683, Step num: 11316, Learning rate: 0.00008309, Avg batch loss: 0.0087, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 684, Step num: 11317, Learning rate: 0.00008309, Avg batch loss: 0.0140, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 685, Step num: 11318, Learning rate: 0.00008308, Avg batch loss: 0.0071, Avg batch acc: 0.9957
Train, Epoch: 8, Batch: 686, Step num: 11319, Learning rate: 0.00008308, Avg batch loss: 0.0101, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 687, Step num: 11320, Learning rate: 0.00008308, Avg batch loss: 0.0117, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 688, Step num: 11321, Learning rate: 0.00008307, Avg batch loss: 0.0083, Avg batch acc: 0.9924
Train, Epoch: 8, Batch: 689, Step num: 11322, Learning rate: 0.00008307, Avg batch loss: 0.0098, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 690, Step num: 11323, Learning rate: 0.00008306, Avg batch loss: 0.0127, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 691, Step num: 11324, Learning rate: 0.00008306, Avg batch loss: 0.0124, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 692, Step num: 11325, Learning rate: 0.00008306, Avg batch loss: 0.0102, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 693, Step num: 11326, Learning rate: 0.00008305, Avg batch loss: 0.0157, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 694, Step num: 11327, Learning rate: 0.00008305, Avg batch loss: 0.0098, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 695, Step num: 11328, Learning rate: 0.00008305, Avg batch loss: 0.0111, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 696, Step num: 11329, Learning rate: 0.00008304, Avg batch loss: 0.0133, Avg batch acc: 0.9833
Train, Epoch: 8, Batch: 697, Step num: 11330, Learning rate: 0.00008304, Avg batch loss: 0.0099, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 698, Step num: 11331, Learning rate: 0.00008303, Avg batch loss: 0.0113, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 699, Step num: 11332, Learning rate: 0.00008303, Avg batch loss: 0.0119, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 700, Step num: 11333, Learning rate: 0.00008303, Avg batch loss: 0.0088, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 701, Step num: 11334, Learning rate: 0.00008302, Avg batch loss: 0.0113, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 702, Step num: 11335, Learning rate: 0.00008302, Avg batch loss: 0.0099, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 703, Step num: 11336, Learning rate: 0.00008302, Avg batch loss: 0.0123, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 704, Step num: 11337, Learning rate: 0.00008301, Avg batch loss: 0.0083, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 705, Step num: 11338, Learning rate: 0.00008301, Avg batch loss: 0.0115, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 706, Step num: 11339, Learning rate: 0.00008301, Avg batch loss: 0.0091, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 707, Step num: 11340, Learning rate: 0.00008300, Avg batch loss: 0.0077, Avg batch acc: 0.9932
Train, Epoch: 8, Batch: 708, Step num: 11341, Learning rate: 0.00008300, Avg batch loss: 0.0092, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 709, Step num: 11342, Learning rate: 0.00008299, Avg batch loss: 0.0072, Avg batch acc: 0.9934
Train, Epoch: 8, Batch: 710, Step num: 11343, Learning rate: 0.00008299, Avg batch loss: 0.0114, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 711, Step num: 11344, Learning rate: 0.00008299, Avg batch loss: 0.0106, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 712, Step num: 11345, Learning rate: 0.00008298, Avg batch loss: 0.0141, Avg batch acc: 0.9839
Train, Epoch: 8, Batch: 713, Step num: 11346, Learning rate: 0.00008298, Avg batch loss: 0.0098, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 714, Step num: 11347, Learning rate: 0.00008298, Avg batch loss: 0.0115, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 715, Step num: 11348, Learning rate: 0.00008297, Avg batch loss: 0.0122, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 716, Step num: 11349, Learning rate: 0.00008297, Avg batch loss: 0.0106, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 717, Step num: 11350, Learning rate: 0.00008297, Avg batch loss: 0.0124, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 718, Step num: 11351, Learning rate: 0.00008296, Avg batch loss: 0.0111, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 719, Step num: 11352, Learning rate: 0.00008296, Avg batch loss: 0.0105, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 720, Step num: 11353, Learning rate: 0.00008295, Avg batch loss: 0.0100, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 721, Step num: 11354, Learning rate: 0.00008295, Avg batch loss: 0.0118, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 722, Step num: 11355, Learning rate: 0.00008295, Avg batch loss: 0.0106, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 723, Step num: 11356, Learning rate: 0.00008294, Avg batch loss: 0.0100, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 724, Step num: 11357, Learning rate: 0.00008294, Avg batch loss: 0.0098, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 725, Step num: 11358, Learning rate: 0.00008294, Avg batch loss: 0.0112, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 726, Step num: 11359, Learning rate: 0.00008293, Avg batch loss: 0.0095, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 727, Step num: 11360, Learning rate: 0.00008293, Avg batch loss: 0.0108, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 728, Step num: 11361, Learning rate: 0.00008293, Avg batch loss: 0.0110, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 729, Step num: 11362, Learning rate: 0.00008292, Avg batch loss: 0.0097, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 730, Step num: 11363, Learning rate: 0.00008292, Avg batch loss: 0.0105, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 731, Step num: 11364, Learning rate: 0.00008291, Avg batch loss: 0.0118, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 732, Step num: 11365, Learning rate: 0.00008291, Avg batch loss: 0.0105, Avg batch acc: 0.9932
Train, Epoch: 8, Batch: 733, Step num: 11366, Learning rate: 0.00008291, Avg batch loss: 0.0113, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 734, Step num: 11367, Learning rate: 0.00008290, Avg batch loss: 0.0122, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 735, Step num: 11368, Learning rate: 0.00008290, Avg batch loss: 0.0115, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 736, Step num: 11369, Learning rate: 0.00008290, Avg batch loss: 0.0097, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 737, Step num: 11370, Learning rate: 0.00008289, Avg batch loss: 0.0112, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 738, Step num: 11371, Learning rate: 0.00008289, Avg batch loss: 0.0103, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 739, Step num: 11372, Learning rate: 0.00008289, Avg batch loss: 0.0115, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 740, Step num: 11373, Learning rate: 0.00008288, Avg batch loss: 0.0096, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 741, Step num: 11374, Learning rate: 0.00008288, Avg batch loss: 0.0122, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 742, Step num: 11375, Learning rate: 0.00008287, Avg batch loss: 0.0107, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 743, Step num: 11376, Learning rate: 0.00008287, Avg batch loss: 0.0099, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 744, Step num: 11377, Learning rate: 0.00008287, Avg batch loss: 0.0126, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 745, Step num: 11378, Learning rate: 0.00008286, Avg batch loss: 0.0136, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 746, Step num: 11379, Learning rate: 0.00008286, Avg batch loss: 0.0061, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 747, Step num: 11380, Learning rate: 0.00008286, Avg batch loss: 0.0086, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 748, Step num: 11381, Learning rate: 0.00008285, Avg batch loss: 0.0108, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 749, Step num: 11382, Learning rate: 0.00008285, Avg batch loss: 0.0101, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 750, Step num: 11383, Learning rate: 0.00008285, Avg batch loss: 0.0115, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 751, Step num: 11384, Learning rate: 0.00008284, Avg batch loss: 0.0092, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 752, Step num: 11385, Learning rate: 0.00008284, Avg batch loss: 0.0089, Avg batch acc: 0.9927
Train, Epoch: 8, Batch: 753, Step num: 11386, Learning rate: 0.00008283, Avg batch loss: 0.0120, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 754, Step num: 11387, Learning rate: 0.00008283, Avg batch loss: 0.0081, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 755, Step num: 11388, Learning rate: 0.00008283, Avg batch loss: 0.0118, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 756, Step num: 11389, Learning rate: 0.00008282, Avg batch loss: 0.0101, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 757, Step num: 11390, Learning rate: 0.00008282, Avg batch loss: 0.0134, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 758, Step num: 11391, Learning rate: 0.00008282, Avg batch loss: 0.0123, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 759, Step num: 11392, Learning rate: 0.00008281, Avg batch loss: 0.0077, Avg batch acc: 0.9938
Train, Epoch: 8, Batch: 760, Step num: 11393, Learning rate: 0.00008281, Avg batch loss: 0.0097, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 761, Step num: 11394, Learning rate: 0.00008281, Avg batch loss: 0.0107, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 762, Step num: 11395, Learning rate: 0.00008280, Avg batch loss: 0.0079, Avg batch acc: 0.9924
Train, Epoch: 8, Batch: 763, Step num: 11396, Learning rate: 0.00008280, Avg batch loss: 0.0110, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 764, Step num: 11397, Learning rate: 0.00008279, Avg batch loss: 0.0092, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 765, Step num: 11398, Learning rate: 0.00008279, Avg batch loss: 0.0125, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 766, Step num: 11399, Learning rate: 0.00008279, Avg batch loss: 0.0114, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 767, Step num: 11400, Learning rate: 0.00008278, Avg batch loss: 0.0086, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 768, Step num: 11401, Learning rate: 0.00008278, Avg batch loss: 0.0097, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 769, Step num: 11402, Learning rate: 0.00008278, Avg batch loss: 0.0116, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 770, Step num: 11403, Learning rate: 0.00008277, Avg batch loss: 0.0081, Avg batch acc: 0.9952
Train, Epoch: 8, Batch: 771, Step num: 11404, Learning rate: 0.00008277, Avg batch loss: 0.0115, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 772, Step num: 11405, Learning rate: 0.00008277, Avg batch loss: 0.0133, Avg batch acc: 0.9847
Train, Epoch: 8, Batch: 773, Step num: 11406, Learning rate: 0.00008276, Avg batch loss: 0.0131, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 774, Step num: 11407, Learning rate: 0.00008276, Avg batch loss: 0.0080, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 775, Step num: 11408, Learning rate: 0.00008275, Avg batch loss: 0.0115, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 776, Step num: 11409, Learning rate: 0.00008275, Avg batch loss: 0.0115, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 777, Step num: 11410, Learning rate: 0.00008275, Avg batch loss: 0.0084, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 778, Step num: 11411, Learning rate: 0.00008274, Avg batch loss: 0.0115, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 779, Step num: 11412, Learning rate: 0.00008274, Avg batch loss: 0.0107, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 780, Step num: 11413, Learning rate: 0.00008274, Avg batch loss: 0.0115, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 781, Step num: 11414, Learning rate: 0.00008273, Avg batch loss: 0.0131, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 782, Step num: 11415, Learning rate: 0.00008273, Avg batch loss: 0.0100, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 783, Step num: 11416, Learning rate: 0.00008273, Avg batch loss: 0.0118, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 784, Step num: 11417, Learning rate: 0.00008272, Avg batch loss: 0.0086, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 785, Step num: 11418, Learning rate: 0.00008272, Avg batch loss: 0.0101, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 786, Step num: 11419, Learning rate: 0.00008271, Avg batch loss: 0.0100, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 787, Step num: 11420, Learning rate: 0.00008271, Avg batch loss: 0.0135, Avg batch acc: 0.9851
Train, Epoch: 8, Batch: 788, Step num: 11421, Learning rate: 0.00008271, Avg batch loss: 0.0094, Avg batch acc: 0.9924
Train, Epoch: 8, Batch: 789, Step num: 11422, Learning rate: 0.00008270, Avg batch loss: 0.0088, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 790, Step num: 11423, Learning rate: 0.00008270, Avg batch loss: 0.0088, Avg batch acc: 0.9931
Train, Epoch: 8, Batch: 791, Step num: 11424, Learning rate: 0.00008270, Avg batch loss: 0.0095, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 792, Step num: 11425, Learning rate: 0.00008269, Avg batch loss: 0.0105, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 793, Step num: 11426, Learning rate: 0.00008269, Avg batch loss: 0.0097, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 794, Step num: 11427, Learning rate: 0.00008269, Avg batch loss: 0.0123, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 795, Step num: 11428, Learning rate: 0.00008268, Avg batch loss: 0.0079, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 796, Step num: 11429, Learning rate: 0.00008268, Avg batch loss: 0.0098, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 797, Step num: 11430, Learning rate: 0.00008267, Avg batch loss: 0.0150, Avg batch acc: 0.9832
Train, Epoch: 8, Batch: 798, Step num: 11431, Learning rate: 0.00008267, Avg batch loss: 0.0088, Avg batch acc: 0.9924
Train, Epoch: 8, Batch: 799, Step num: 11432, Learning rate: 0.00008267, Avg batch loss: 0.0128, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 800, Step num: 11433, Learning rate: 0.00008266, Avg batch loss: 0.0119, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 801, Step num: 11434, Learning rate: 0.00008266, Avg batch loss: 0.0111, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 802, Step num: 11435, Learning rate: 0.00008266, Avg batch loss: 0.0125, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 803, Step num: 11436, Learning rate: 0.00008265, Avg batch loss: 0.0102, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 804, Step num: 11437, Learning rate: 0.00008265, Avg batch loss: 0.0093, Avg batch acc: 0.9915
Train, Epoch: 8, Batch: 805, Step num: 11438, Learning rate: 0.00008265, Avg batch loss: 0.0088, Avg batch acc: 0.9927
Train, Epoch: 8, Batch: 806, Step num: 11439, Learning rate: 0.00008264, Avg batch loss: 0.0095, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 807, Step num: 11440, Learning rate: 0.00008264, Avg batch loss: 0.0115, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 808, Step num: 11441, Learning rate: 0.00008263, Avg batch loss: 0.0126, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 809, Step num: 11442, Learning rate: 0.00008263, Avg batch loss: 0.0127, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 810, Step num: 11443, Learning rate: 0.00008263, Avg batch loss: 0.0147, Avg batch acc: 0.9860
Train, Epoch: 8, Batch: 811, Step num: 11444, Learning rate: 0.00008262, Avg batch loss: 0.0106, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 812, Step num: 11445, Learning rate: 0.00008262, Avg batch loss: 0.0119, Avg batch acc: 0.9849
Train, Epoch: 8, Batch: 813, Step num: 11446, Learning rate: 0.00008262, Avg batch loss: 0.0109, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 814, Step num: 11447, Learning rate: 0.00008261, Avg batch loss: 0.0097, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 815, Step num: 11448, Learning rate: 0.00008261, Avg batch loss: 0.0131, Avg batch acc: 0.9852
Train, Epoch: 8, Batch: 816, Step num: 11449, Learning rate: 0.00008261, Avg batch loss: 0.0110, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 817, Step num: 11450, Learning rate: 0.00008260, Avg batch loss: 0.0128, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 818, Step num: 11451, Learning rate: 0.00008260, Avg batch loss: 0.0613, Avg batch acc: 0.9772
Train, Epoch: 8, Batch: 819, Step num: 11452, Learning rate: 0.00008260, Avg batch loss: 0.0123, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 820, Step num: 11453, Learning rate: 0.00008259, Avg batch loss: 0.0128, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 821, Step num: 11454, Learning rate: 0.00008259, Avg batch loss: 0.0137, Avg batch acc: 0.9837
Train, Epoch: 8, Batch: 822, Step num: 11455, Learning rate: 0.00008258, Avg batch loss: 0.0090, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 823, Step num: 11456, Learning rate: 0.00008258, Avg batch loss: 0.0096, Avg batch acc: 0.9920
Train, Epoch: 8, Batch: 824, Step num: 11457, Learning rate: 0.00008258, Avg batch loss: 0.0131, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 825, Step num: 11458, Learning rate: 0.00008257, Avg batch loss: 0.0139, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 826, Step num: 11459, Learning rate: 0.00008257, Avg batch loss: 0.0080, Avg batch acc: 0.9934
Train, Epoch: 8, Batch: 827, Step num: 11460, Learning rate: 0.00008257, Avg batch loss: 0.0121, Avg batch acc: 0.9861
Train, Epoch: 8, Batch: 828, Step num: 11461, Learning rate: 0.00008256, Avg batch loss: 0.0183, Avg batch acc: 0.9840
Train, Epoch: 8, Batch: 829, Step num: 11462, Learning rate: 0.00008256, Avg batch loss: 0.0181, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 830, Step num: 11463, Learning rate: 0.00008256, Avg batch loss: 0.0130, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 831, Step num: 11464, Learning rate: 0.00008255, Avg batch loss: 0.0101, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 832, Step num: 11465, Learning rate: 0.00008255, Avg batch loss: 0.0113, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 833, Step num: 11466, Learning rate: 0.00008254, Avg batch loss: 0.0090, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 834, Step num: 11467, Learning rate: 0.00008254, Avg batch loss: 0.0136, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 835, Step num: 11468, Learning rate: 0.00008254, Avg batch loss: 0.0099, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 836, Step num: 11469, Learning rate: 0.00008253, Avg batch loss: 0.0110, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 837, Step num: 11470, Learning rate: 0.00008253, Avg batch loss: 0.0141, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 838, Step num: 11471, Learning rate: 0.00008253, Avg batch loss: 0.0128, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 839, Step num: 11472, Learning rate: 0.00008252, Avg batch loss: 0.0127, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 840, Step num: 11473, Learning rate: 0.00008252, Avg batch loss: 0.0111, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 841, Step num: 11474, Learning rate: 0.00008252, Avg batch loss: 0.0211, Avg batch acc: 0.9836
Train, Epoch: 8, Batch: 842, Step num: 11475, Learning rate: 0.00008251, Avg batch loss: 0.0097, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 843, Step num: 11476, Learning rate: 0.00008251, Avg batch loss: 0.0104, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 844, Step num: 11477, Learning rate: 0.00008251, Avg batch loss: 0.0119, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 845, Step num: 11478, Learning rate: 0.00008250, Avg batch loss: 0.0121, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 846, Step num: 11479, Learning rate: 0.00008250, Avg batch loss: 0.0137, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 847, Step num: 11480, Learning rate: 0.00008249, Avg batch loss: 0.0142, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 848, Step num: 11481, Learning rate: 0.00008249, Avg batch loss: 0.0142, Avg batch acc: 0.9869
Train, Epoch: 8, Batch: 849, Step num: 11482, Learning rate: 0.00008249, Avg batch loss: 0.0104, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 850, Step num: 11483, Learning rate: 0.00008248, Avg batch loss: 0.0112, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 851, Step num: 11484, Learning rate: 0.00008248, Avg batch loss: 0.0105, Avg batch acc: 0.9860
Train, Epoch: 8, Batch: 852, Step num: 11485, Learning rate: 0.00008248, Avg batch loss: 0.0094, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 853, Step num: 11486, Learning rate: 0.00008247, Avg batch loss: 0.0109, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 854, Step num: 11487, Learning rate: 0.00008247, Avg batch loss: 0.0128, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 855, Step num: 11488, Learning rate: 0.00008247, Avg batch loss: 0.0124, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 856, Step num: 11489, Learning rate: 0.00008246, Avg batch loss: 0.0119, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 857, Step num: 11490, Learning rate: 0.00008246, Avg batch loss: 0.0115, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 858, Step num: 11491, Learning rate: 0.00008245, Avg batch loss: 0.0104, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 859, Step num: 11492, Learning rate: 0.00008245, Avg batch loss: 0.0120, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 860, Step num: 11493, Learning rate: 0.00008245, Avg batch loss: 0.0103, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 861, Step num: 11494, Learning rate: 0.00008244, Avg batch loss: 0.0093, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 862, Step num: 11495, Learning rate: 0.00008244, Avg batch loss: 0.0100, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 863, Step num: 11496, Learning rate: 0.00008244, Avg batch loss: 0.0111, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 864, Step num: 11497, Learning rate: 0.00008243, Avg batch loss: 0.0100, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 865, Step num: 11498, Learning rate: 0.00008243, Avg batch loss: 0.0099, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 866, Step num: 11499, Learning rate: 0.00008243, Avg batch loss: 0.0111, Avg batch acc: 0.9860
Train, Epoch: 8, Batch: 867, Step num: 11500, Learning rate: 0.00008242, Avg batch loss: 0.0291, Avg batch acc: 0.9828
Train, Epoch: 8, Batch: 868, Step num: 11501, Learning rate: 0.00008242, Avg batch loss: 0.0095, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 869, Step num: 11502, Learning rate: 0.00008242, Avg batch loss: 0.0095, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 870, Step num: 11503, Learning rate: 0.00008241, Avg batch loss: 0.0073, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 871, Step num: 11504, Learning rate: 0.00008241, Avg batch loss: 0.0115, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 872, Step num: 11505, Learning rate: 0.00008240, Avg batch loss: 0.0115, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 873, Step num: 11506, Learning rate: 0.00008240, Avg batch loss: 0.0104, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 874, Step num: 11507, Learning rate: 0.00008240, Avg batch loss: 0.0083, Avg batch acc: 0.9920
Train, Epoch: 8, Batch: 875, Step num: 11508, Learning rate: 0.00008239, Avg batch loss: 0.0133, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 876, Step num: 11509, Learning rate: 0.00008239, Avg batch loss: 0.0123, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 877, Step num: 11510, Learning rate: 0.00008239, Avg batch loss: 0.0089, Avg batch acc: 0.9927
Train, Epoch: 8, Batch: 878, Step num: 11511, Learning rate: 0.00008238, Avg batch loss: 0.0105, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 879, Step num: 11512, Learning rate: 0.00008238, Avg batch loss: 0.0117, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 880, Step num: 11513, Learning rate: 0.00008238, Avg batch loss: 0.0097, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 881, Step num: 11514, Learning rate: 0.00008237, Avg batch loss: 0.0090, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 882, Step num: 11515, Learning rate: 0.00008237, Avg batch loss: 0.0093, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 883, Step num: 11516, Learning rate: 0.00008237, Avg batch loss: 0.0085, Avg batch acc: 0.9939
Train, Epoch: 8, Batch: 884, Step num: 11517, Learning rate: 0.00008236, Avg batch loss: 0.0106, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 885, Step num: 11518, Learning rate: 0.00008236, Avg batch loss: 0.0088, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 886, Step num: 11519, Learning rate: 0.00008235, Avg batch loss: 0.0101, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 887, Step num: 11520, Learning rate: 0.00008235, Avg batch loss: 0.0129, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 888, Step num: 11521, Learning rate: 0.00008235, Avg batch loss: 0.0109, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 889, Step num: 11522, Learning rate: 0.00008234, Avg batch loss: 0.0106, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 890, Step num: 11523, Learning rate: 0.00008234, Avg batch loss: 0.0105, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 891, Step num: 11524, Learning rate: 0.00008234, Avg batch loss: 0.0144, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 892, Step num: 11525, Learning rate: 0.00008233, Avg batch loss: 0.0112, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 893, Step num: 11526, Learning rate: 0.00008233, Avg batch loss: 0.0086, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 894, Step num: 11527, Learning rate: 0.00008233, Avg batch loss: 0.0115, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 895, Step num: 11528, Learning rate: 0.00008232, Avg batch loss: 0.0113, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 896, Step num: 11529, Learning rate: 0.00008232, Avg batch loss: 0.0122, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 897, Step num: 11530, Learning rate: 0.00008232, Avg batch loss: 0.0084, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 898, Step num: 11531, Learning rate: 0.00008231, Avg batch loss: 0.0112, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 899, Step num: 11532, Learning rate: 0.00008231, Avg batch loss: 0.0092, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 900, Step num: 11533, Learning rate: 0.00008230, Avg batch loss: 0.0124, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 901, Step num: 11534, Learning rate: 0.00008230, Avg batch loss: 0.0101, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 902, Step num: 11535, Learning rate: 0.00008230, Avg batch loss: 0.0116, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 903, Step num: 11536, Learning rate: 0.00008229, Avg batch loss: 0.0065, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 904, Step num: 11537, Learning rate: 0.00008229, Avg batch loss: 0.0098, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 905, Step num: 11538, Learning rate: 0.00008229, Avg batch loss: 0.0131, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 906, Step num: 11539, Learning rate: 0.00008228, Avg batch loss: 0.0112, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 907, Step num: 11540, Learning rate: 0.00008228, Avg batch loss: 0.0110, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 908, Step num: 11541, Learning rate: 0.00008228, Avg batch loss: 0.0098, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 909, Step num: 11542, Learning rate: 0.00008227, Avg batch loss: 0.0111, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 910, Step num: 11543, Learning rate: 0.00008227, Avg batch loss: 0.0093, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 911, Step num: 11544, Learning rate: 0.00008227, Avg batch loss: 0.0107, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 912, Step num: 11545, Learning rate: 0.00008226, Avg batch loss: 0.0129, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 913, Step num: 11546, Learning rate: 0.00008226, Avg batch loss: 0.0117, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 914, Step num: 11547, Learning rate: 0.00008225, Avg batch loss: 0.0097, Avg batch acc: 0.9928
Train, Epoch: 8, Batch: 915, Step num: 11548, Learning rate: 0.00008225, Avg batch loss: 0.0116, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 916, Step num: 11549, Learning rate: 0.00008225, Avg batch loss: 0.0082, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 917, Step num: 11550, Learning rate: 0.00008224, Avg batch loss: 0.0082, Avg batch acc: 0.9940
Train, Epoch: 8, Batch: 918, Step num: 11551, Learning rate: 0.00008224, Avg batch loss: 0.0120, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 919, Step num: 11552, Learning rate: 0.00008224, Avg batch loss: 0.0125, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 920, Step num: 11553, Learning rate: 0.00008223, Avg batch loss: 0.0103, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 921, Step num: 11554, Learning rate: 0.00008223, Avg batch loss: 0.0096, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 922, Step num: 11555, Learning rate: 0.00008223, Avg batch loss: 0.0108, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 923, Step num: 11556, Learning rate: 0.00008222, Avg batch loss: 0.0131, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 924, Step num: 11557, Learning rate: 0.00008222, Avg batch loss: 0.0131, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 925, Step num: 11558, Learning rate: 0.00008222, Avg batch loss: 0.0092, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 926, Step num: 11559, Learning rate: 0.00008221, Avg batch loss: 0.0099, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 927, Step num: 11560, Learning rate: 0.00008221, Avg batch loss: 0.0101, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 928, Step num: 11561, Learning rate: 0.00008220, Avg batch loss: 0.0084, Avg batch acc: 0.9935
Train, Epoch: 8, Batch: 929, Step num: 11562, Learning rate: 0.00008220, Avg batch loss: 0.0115, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 930, Step num: 11563, Learning rate: 0.00008220, Avg batch loss: 0.0094, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 931, Step num: 11564, Learning rate: 0.00008219, Avg batch loss: 0.0109, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 932, Step num: 11565, Learning rate: 0.00008219, Avg batch loss: 0.0105, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 933, Step num: 11566, Learning rate: 0.00008219, Avg batch loss: 0.0146, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 934, Step num: 11567, Learning rate: 0.00008218, Avg batch loss: 0.0091, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 935, Step num: 11568, Learning rate: 0.00008218, Avg batch loss: 0.0115, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 936, Step num: 11569, Learning rate: 0.00008218, Avg batch loss: 0.0106, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 937, Step num: 11570, Learning rate: 0.00008217, Avg batch loss: 0.0111, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 938, Step num: 11571, Learning rate: 0.00008217, Avg batch loss: 0.0114, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 939, Step num: 11572, Learning rate: 0.00008217, Avg batch loss: 0.0083, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 940, Step num: 11573, Learning rate: 0.00008216, Avg batch loss: 0.0108, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 941, Step num: 11574, Learning rate: 0.00008216, Avg batch loss: 0.0097, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 942, Step num: 11575, Learning rate: 0.00008216, Avg batch loss: 0.0107, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 943, Step num: 11576, Learning rate: 0.00008215, Avg batch loss: 0.0108, Avg batch acc: 0.9867
Train, Epoch: 8, Batch: 944, Step num: 11577, Learning rate: 0.00008215, Avg batch loss: 0.0106, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 945, Step num: 11578, Learning rate: 0.00008214, Avg batch loss: 0.0098, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 946, Step num: 11579, Learning rate: 0.00008214, Avg batch loss: 0.0131, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 947, Step num: 11580, Learning rate: 0.00008214, Avg batch loss: 0.0100, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 948, Step num: 11581, Learning rate: 0.00008213, Avg batch loss: 0.0098, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 949, Step num: 11582, Learning rate: 0.00008213, Avg batch loss: 0.0135, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 950, Step num: 11583, Learning rate: 0.00008213, Avg batch loss: 0.0099, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 951, Step num: 11584, Learning rate: 0.00008212, Avg batch loss: 0.0090, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 952, Step num: 11585, Learning rate: 0.00008212, Avg batch loss: 0.0110, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 953, Step num: 11586, Learning rate: 0.00008212, Avg batch loss: 0.0110, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 954, Step num: 11587, Learning rate: 0.00008211, Avg batch loss: 0.0107, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 955, Step num: 11588, Learning rate: 0.00008211, Avg batch loss: 0.0082, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 956, Step num: 11589, Learning rate: 0.00008211, Avg batch loss: 0.0146, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 957, Step num: 11590, Learning rate: 0.00008210, Avg batch loss: 0.0116, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 958, Step num: 11591, Learning rate: 0.00008210, Avg batch loss: 0.0105, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 959, Step num: 11592, Learning rate: 0.00008209, Avg batch loss: 0.0112, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 960, Step num: 11593, Learning rate: 0.00008209, Avg batch loss: 0.0104, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 961, Step num: 11594, Learning rate: 0.00008209, Avg batch loss: 0.0101, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 962, Step num: 11595, Learning rate: 0.00008208, Avg batch loss: 0.0105, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 963, Step num: 11596, Learning rate: 0.00008208, Avg batch loss: 0.0109, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 964, Step num: 11597, Learning rate: 0.00008208, Avg batch loss: 0.0131, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 965, Step num: 11598, Learning rate: 0.00008207, Avg batch loss: 0.0115, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 966, Step num: 11599, Learning rate: 0.00008207, Avg batch loss: 0.0102, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 967, Step num: 11600, Learning rate: 0.00008207, Avg batch loss: 0.0125, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 968, Step num: 11601, Learning rate: 0.00008206, Avg batch loss: 0.0120, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 969, Step num: 11602, Learning rate: 0.00008206, Avg batch loss: 0.0123, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 970, Step num: 11603, Learning rate: 0.00008206, Avg batch loss: 0.0136, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 971, Step num: 11604, Learning rate: 0.00008205, Avg batch loss: 0.0118, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 972, Step num: 11605, Learning rate: 0.00008205, Avg batch loss: 0.0138, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 973, Step num: 11606, Learning rate: 0.00008205, Avg batch loss: 0.0132, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 974, Step num: 11607, Learning rate: 0.00008204, Avg batch loss: 0.0088, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 975, Step num: 11608, Learning rate: 0.00008204, Avg batch loss: 0.0095, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 976, Step num: 11609, Learning rate: 0.00008203, Avg batch loss: 0.0107, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 977, Step num: 11610, Learning rate: 0.00008203, Avg batch loss: 0.0116, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 978, Step num: 11611, Learning rate: 0.00008203, Avg batch loss: 0.0104, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 979, Step num: 11612, Learning rate: 0.00008202, Avg batch loss: 0.0085, Avg batch acc: 0.9940
Train, Epoch: 8, Batch: 980, Step num: 11613, Learning rate: 0.00008202, Avg batch loss: 0.0113, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 981, Step num: 11614, Learning rate: 0.00008202, Avg batch loss: 0.0105, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 982, Step num: 11615, Learning rate: 0.00008201, Avg batch loss: 0.0078, Avg batch acc: 0.9948
Train, Epoch: 8, Batch: 983, Step num: 11616, Learning rate: 0.00008201, Avg batch loss: 0.0096, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 984, Step num: 11617, Learning rate: 0.00008201, Avg batch loss: 0.0097, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 985, Step num: 11618, Learning rate: 0.00008200, Avg batch loss: 0.0138, Avg batch acc: 0.9865
Train, Epoch: 8, Batch: 986, Step num: 11619, Learning rate: 0.00008200, Avg batch loss: 0.0096, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 987, Step num: 11620, Learning rate: 0.00008200, Avg batch loss: 0.0091, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 988, Step num: 11621, Learning rate: 0.00008199, Avg batch loss: 0.0138, Avg batch acc: 0.9838
Train, Epoch: 8, Batch: 989, Step num: 11622, Learning rate: 0.00008199, Avg batch loss: 0.0124, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 990, Step num: 11623, Learning rate: 0.00008199, Avg batch loss: 0.0117, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 991, Step num: 11624, Learning rate: 0.00008198, Avg batch loss: 0.0133, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 992, Step num: 11625, Learning rate: 0.00008198, Avg batch loss: 0.0102, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 993, Step num: 11626, Learning rate: 0.00008197, Avg batch loss: 0.0084, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 994, Step num: 11627, Learning rate: 0.00008197, Avg batch loss: 0.0090, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 995, Step num: 11628, Learning rate: 0.00008197, Avg batch loss: 0.0088, Avg batch acc: 0.9931
Train, Epoch: 8, Batch: 996, Step num: 11629, Learning rate: 0.00008196, Avg batch loss: 0.0091, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 997, Step num: 11630, Learning rate: 0.00008196, Avg batch loss: 0.0112, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 998, Step num: 11631, Learning rate: 0.00008196, Avg batch loss: 0.0118, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 999, Step num: 11632, Learning rate: 0.00008195, Avg batch loss: 0.0110, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1000, Step num: 11633, Learning rate: 0.00008195, Avg batch loss: 0.0092, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 1001, Step num: 11634, Learning rate: 0.00008195, Avg batch loss: 0.0077, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1002, Step num: 11635, Learning rate: 0.00008194, Avg batch loss: 0.0091, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1003, Step num: 11636, Learning rate: 0.00008194, Avg batch loss: 0.0083, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1004, Step num: 11637, Learning rate: 0.00008194, Avg batch loss: 0.0112, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 1005, Step num: 11638, Learning rate: 0.00008193, Avg batch loss: 0.0077, Avg batch acc: 0.9937
Train, Epoch: 8, Batch: 1006, Step num: 11639, Learning rate: 0.00008193, Avg batch loss: 0.0086, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 1007, Step num: 11640, Learning rate: 0.00008193, Avg batch loss: 0.0119, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 1008, Step num: 11641, Learning rate: 0.00008192, Avg batch loss: 0.0098, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1009, Step num: 11642, Learning rate: 0.00008192, Avg batch loss: 0.0088, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1010, Step num: 11643, Learning rate: 0.00008191, Avg batch loss: 0.0103, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 1011, Step num: 11644, Learning rate: 0.00008191, Avg batch loss: 0.0108, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1012, Step num: 11645, Learning rate: 0.00008191, Avg batch loss: 0.0092, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 1013, Step num: 11646, Learning rate: 0.00008190, Avg batch loss: 0.0100, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1014, Step num: 11647, Learning rate: 0.00008190, Avg batch loss: 0.0104, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 1015, Step num: 11648, Learning rate: 0.00008190, Avg batch loss: 0.0108, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 1016, Step num: 11649, Learning rate: 0.00008189, Avg batch loss: 0.0085, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 1017, Step num: 11650, Learning rate: 0.00008189, Avg batch loss: 0.0141, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1018, Step num: 11651, Learning rate: 0.00008189, Avg batch loss: 0.0095, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1019, Step num: 11652, Learning rate: 0.00008188, Avg batch loss: 0.0122, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 1020, Step num: 11653, Learning rate: 0.00008188, Avg batch loss: 0.0077, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 1021, Step num: 11654, Learning rate: 0.00008188, Avg batch loss: 0.0087, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1022, Step num: 11655, Learning rate: 0.00008187, Avg batch loss: 0.0135, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 1023, Step num: 11656, Learning rate: 0.00008187, Avg batch loss: 0.0085, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 1024, Step num: 11657, Learning rate: 0.00008187, Avg batch loss: 0.0252, Avg batch acc: 0.9867
Train, Epoch: 8, Batch: 1025, Step num: 11658, Learning rate: 0.00008186, Avg batch loss: 0.0110, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1026, Step num: 11659, Learning rate: 0.00008186, Avg batch loss: 0.0082, Avg batch acc: 0.9935
Train, Epoch: 8, Batch: 1027, Step num: 11660, Learning rate: 0.00008186, Avg batch loss: 0.0132, Avg batch acc: 0.9867
Train, Epoch: 8, Batch: 1028, Step num: 11661, Learning rate: 0.00008185, Avg batch loss: 0.0110, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 1029, Step num: 11662, Learning rate: 0.00008185, Avg batch loss: 0.0107, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 1030, Step num: 11663, Learning rate: 0.00008184, Avg batch loss: 0.0105, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 1031, Step num: 11664, Learning rate: 0.00008184, Avg batch loss: 0.0136, Avg batch acc: 0.9867
Train, Epoch: 8, Batch: 1032, Step num: 11665, Learning rate: 0.00008184, Avg batch loss: 0.0146, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 1033, Step num: 11666, Learning rate: 0.00008183, Avg batch loss: 0.0154, Avg batch acc: 0.9848
Train, Epoch: 8, Batch: 1034, Step num: 11667, Learning rate: 0.00008183, Avg batch loss: 0.0082, Avg batch acc: 0.9932
Train, Epoch: 8, Batch: 1035, Step num: 11668, Learning rate: 0.00008183, Avg batch loss: 0.0096, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 1036, Step num: 11669, Learning rate: 0.00008182, Avg batch loss: 0.0099, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 1037, Step num: 11670, Learning rate: 0.00008182, Avg batch loss: 0.0116, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1038, Step num: 11671, Learning rate: 0.00008182, Avg batch loss: 0.0084, Avg batch acc: 0.9933
Train, Epoch: 8, Batch: 1039, Step num: 11672, Learning rate: 0.00008181, Avg batch loss: 0.0200, Avg batch acc: 0.9833
Train, Epoch: 8, Batch: 1040, Step num: 11673, Learning rate: 0.00008181, Avg batch loss: 0.0145, Avg batch acc: 0.9840
Train, Epoch: 8, Batch: 1041, Step num: 11674, Learning rate: 0.00008181, Avg batch loss: 0.0099, Avg batch acc: 0.9936
Train, Epoch: 8, Batch: 1042, Step num: 11675, Learning rate: 0.00008180, Avg batch loss: 0.0113, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 1043, Step num: 11676, Learning rate: 0.00008180, Avg batch loss: 0.0113, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 1044, Step num: 11677, Learning rate: 0.00008180, Avg batch loss: 0.0212, Avg batch acc: 0.9825
Train, Epoch: 8, Batch: 1045, Step num: 11678, Learning rate: 0.00008179, Avg batch loss: 0.0111, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 1046, Step num: 11679, Learning rate: 0.00008179, Avg batch loss: 0.0091, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1047, Step num: 11680, Learning rate: 0.00008178, Avg batch loss: 0.0087, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 1048, Step num: 11681, Learning rate: 0.00008178, Avg batch loss: 0.0121, Avg batch acc: 0.9847
Train, Epoch: 8, Batch: 1049, Step num: 11682, Learning rate: 0.00008178, Avg batch loss: 0.0098, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1050, Step num: 11683, Learning rate: 0.00008177, Avg batch loss: 0.0112, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 1051, Step num: 11684, Learning rate: 0.00008177, Avg batch loss: 0.0074, Avg batch acc: 0.9939
Train, Epoch: 8, Batch: 1052, Step num: 11685, Learning rate: 0.00008177, Avg batch loss: 0.0092, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1053, Step num: 11686, Learning rate: 0.00008176, Avg batch loss: 0.0104, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1054, Step num: 11687, Learning rate: 0.00008176, Avg batch loss: 0.0132, Avg batch acc: 0.9858
Train, Epoch: 8, Batch: 1055, Step num: 11688, Learning rate: 0.00008176, Avg batch loss: 0.0101, Avg batch acc: 0.9836
Train, Epoch: 8, Batch: 1056, Step num: 11689, Learning rate: 0.00008175, Avg batch loss: 0.0096, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 1057, Step num: 11690, Learning rate: 0.00008175, Avg batch loss: 0.0109, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 1058, Step num: 11691, Learning rate: 0.00008175, Avg batch loss: 0.0120, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 1059, Step num: 11692, Learning rate: 0.00008174, Avg batch loss: 0.0103, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1060, Step num: 11693, Learning rate: 0.00008174, Avg batch loss: 0.0101, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1061, Step num: 11694, Learning rate: 0.00008174, Avg batch loss: 0.0111, Avg batch acc: 0.9871
Train, Epoch: 8, Batch: 1062, Step num: 11695, Learning rate: 0.00008173, Avg batch loss: 0.0102, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 1063, Step num: 11696, Learning rate: 0.00008173, Avg batch loss: 0.0119, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 1064, Step num: 11697, Learning rate: 0.00008173, Avg batch loss: 0.0084, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 1065, Step num: 11698, Learning rate: 0.00008172, Avg batch loss: 0.0105, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1066, Step num: 11699, Learning rate: 0.00008172, Avg batch loss: 0.0095, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 1067, Step num: 11700, Learning rate: 0.00008172, Avg batch loss: 0.0118, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 1068, Step num: 11701, Learning rate: 0.00008171, Avg batch loss: 0.0104, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1069, Step num: 11702, Learning rate: 0.00008171, Avg batch loss: 0.0104, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 1070, Step num: 11703, Learning rate: 0.00008170, Avg batch loss: 0.0109, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 1071, Step num: 11704, Learning rate: 0.00008170, Avg batch loss: 0.0093, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 1072, Step num: 11705, Learning rate: 0.00008170, Avg batch loss: 0.0090, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 1073, Step num: 11706, Learning rate: 0.00008169, Avg batch loss: 0.0102, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 1074, Step num: 11707, Learning rate: 0.00008169, Avg batch loss: 0.0097, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 1075, Step num: 11708, Learning rate: 0.00008169, Avg batch loss: 0.0089, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 1076, Step num: 11709, Learning rate: 0.00008168, Avg batch loss: 0.0086, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1077, Step num: 11710, Learning rate: 0.00008168, Avg batch loss: 0.0082, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1078, Step num: 11711, Learning rate: 0.00008168, Avg batch loss: 0.0064, Avg batch acc: 0.9939
Train, Epoch: 8, Batch: 1079, Step num: 11712, Learning rate: 0.00008167, Avg batch loss: 0.0099, Avg batch acc: 0.9936
Train, Epoch: 8, Batch: 1080, Step num: 11713, Learning rate: 0.00008167, Avg batch loss: 0.0108, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 1081, Step num: 11714, Learning rate: 0.00008167, Avg batch loss: 0.0109, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1082, Step num: 11715, Learning rate: 0.00008166, Avg batch loss: 0.0075, Avg batch acc: 0.9936
Train, Epoch: 8, Batch: 1083, Step num: 11716, Learning rate: 0.00008166, Avg batch loss: 0.0092, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1084, Step num: 11717, Learning rate: 0.00008166, Avg batch loss: 0.0094, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 1085, Step num: 11718, Learning rate: 0.00008165, Avg batch loss: 0.0097, Avg batch acc: 0.9915
Train, Epoch: 8, Batch: 1086, Step num: 11719, Learning rate: 0.00008165, Avg batch loss: 0.0101, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1087, Step num: 11720, Learning rate: 0.00008165, Avg batch loss: 0.0119, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 1088, Step num: 11721, Learning rate: 0.00008164, Avg batch loss: 0.0108, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1089, Step num: 11722, Learning rate: 0.00008164, Avg batch loss: 0.0102, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 1090, Step num: 11723, Learning rate: 0.00008163, Avg batch loss: 0.0074, Avg batch acc: 0.9920
Train, Epoch: 8, Batch: 1091, Step num: 11724, Learning rate: 0.00008163, Avg batch loss: 0.0072, Avg batch acc: 0.9939
Train, Epoch: 8, Batch: 1092, Step num: 11725, Learning rate: 0.00008163, Avg batch loss: 0.0108, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1093, Step num: 11726, Learning rate: 0.00008162, Avg batch loss: 0.0141, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1094, Step num: 11727, Learning rate: 0.00008162, Avg batch loss: 0.0092, Avg batch acc: 0.9915
Train, Epoch: 8, Batch: 1095, Step num: 11728, Learning rate: 0.00008162, Avg batch loss: 0.0097, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 1096, Step num: 11729, Learning rate: 0.00008161, Avg batch loss: 0.0083, Avg batch acc: 0.9915
Train, Epoch: 8, Batch: 1097, Step num: 11730, Learning rate: 0.00008161, Avg batch loss: 0.0088, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 1098, Step num: 11731, Learning rate: 0.00008161, Avg batch loss: 0.0103, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1099, Step num: 11732, Learning rate: 0.00008160, Avg batch loss: 0.0141, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 1100, Step num: 11733, Learning rate: 0.00008160, Avg batch loss: 0.0096, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1101, Step num: 11734, Learning rate: 0.00008160, Avg batch loss: 0.0084, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 1102, Step num: 11735, Learning rate: 0.00008159, Avg batch loss: 0.0116, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 1103, Step num: 11736, Learning rate: 0.00008159, Avg batch loss: 0.0109, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1104, Step num: 11737, Learning rate: 0.00008159, Avg batch loss: 0.0077, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1105, Step num: 11738, Learning rate: 0.00008158, Avg batch loss: 0.0118, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 1106, Step num: 11739, Learning rate: 0.00008158, Avg batch loss: 0.0096, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1107, Step num: 11740, Learning rate: 0.00008158, Avg batch loss: 0.0077, Avg batch acc: 0.9915
Train, Epoch: 8, Batch: 1108, Step num: 11741, Learning rate: 0.00008157, Avg batch loss: 0.0073, Avg batch acc: 0.9928
Train, Epoch: 8, Batch: 1109, Step num: 11742, Learning rate: 0.00008157, Avg batch loss: 0.0099, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 1110, Step num: 11743, Learning rate: 0.00008157, Avg batch loss: 0.0092, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 1111, Step num: 11744, Learning rate: 0.00008156, Avg batch loss: 0.0078, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 1112, Step num: 11745, Learning rate: 0.00008156, Avg batch loss: 0.0122, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 1113, Step num: 11746, Learning rate: 0.00008155, Avg batch loss: 0.0105, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1114, Step num: 11747, Learning rate: 0.00008155, Avg batch loss: 0.0099, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1115, Step num: 11748, Learning rate: 0.00008155, Avg batch loss: 0.0118, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 1116, Step num: 11749, Learning rate: 0.00008154, Avg batch loss: 0.0072, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1117, Step num: 11750, Learning rate: 0.00008154, Avg batch loss: 0.0114, Avg batch acc: 0.9859
Train, Epoch: 8, Batch: 1118, Step num: 11751, Learning rate: 0.00008154, Avg batch loss: 0.0069, Avg batch acc: 0.9926
Train, Epoch: 8, Batch: 1119, Step num: 11752, Learning rate: 0.00008153, Avg batch loss: 0.0085, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1120, Step num: 11753, Learning rate: 0.00008153, Avg batch loss: 0.0102, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 1121, Step num: 11754, Learning rate: 0.00008153, Avg batch loss: 0.0091, Avg batch acc: 0.9932
Train, Epoch: 8, Batch: 1122, Step num: 11755, Learning rate: 0.00008152, Avg batch loss: 0.0098, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 1123, Step num: 11756, Learning rate: 0.00008152, Avg batch loss: 0.0081, Avg batch acc: 0.9936
Train, Epoch: 8, Batch: 1124, Step num: 11757, Learning rate: 0.00008152, Avg batch loss: 0.0090, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1125, Step num: 11758, Learning rate: 0.00008151, Avg batch loss: 0.0087, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 1126, Step num: 11759, Learning rate: 0.00008151, Avg batch loss: 0.0095, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1127, Step num: 11760, Learning rate: 0.00008151, Avg batch loss: 0.0089, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 1128, Step num: 11761, Learning rate: 0.00008150, Avg batch loss: 0.0129, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 1129, Step num: 11762, Learning rate: 0.00008150, Avg batch loss: 0.0127, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1130, Step num: 11763, Learning rate: 0.00008150, Avg batch loss: 0.0075, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1131, Step num: 11764, Learning rate: 0.00008149, Avg batch loss: 0.0102, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1132, Step num: 11765, Learning rate: 0.00008149, Avg batch loss: 0.0109, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 1133, Step num: 11766, Learning rate: 0.00008149, Avg batch loss: 0.0077, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1134, Step num: 11767, Learning rate: 0.00008148, Avg batch loss: 0.0081, Avg batch acc: 0.9936
Train, Epoch: 8, Batch: 1135, Step num: 11768, Learning rate: 0.00008148, Avg batch loss: 0.0117, Avg batch acc: 0.9848
Train, Epoch: 8, Batch: 1136, Step num: 11769, Learning rate: 0.00008148, Avg batch loss: 0.0090, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 1137, Step num: 11770, Learning rate: 0.00008147, Avg batch loss: 0.0104, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1138, Step num: 11771, Learning rate: 0.00008147, Avg batch loss: 0.0131, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 1139, Step num: 11772, Learning rate: 0.00008146, Avg batch loss: 0.0113, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 1140, Step num: 11773, Learning rate: 0.00008146, Avg batch loss: 0.0086, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1141, Step num: 11774, Learning rate: 0.00008146, Avg batch loss: 0.0098, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1142, Step num: 11775, Learning rate: 0.00008145, Avg batch loss: 0.0108, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1143, Step num: 11776, Learning rate: 0.00008145, Avg batch loss: 0.0082, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 1144, Step num: 11777, Learning rate: 0.00008145, Avg batch loss: 0.0080, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1145, Step num: 11778, Learning rate: 0.00008144, Avg batch loss: 0.0099, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1146, Step num: 11779, Learning rate: 0.00008144, Avg batch loss: 0.0108, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 1147, Step num: 11780, Learning rate: 0.00008144, Avg batch loss: 0.0103, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 1148, Step num: 11781, Learning rate: 0.00008143, Avg batch loss: 0.0115, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1149, Step num: 11782, Learning rate: 0.00008143, Avg batch loss: 0.0092, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 1150, Step num: 11783, Learning rate: 0.00008143, Avg batch loss: 0.0120, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 1151, Step num: 11784, Learning rate: 0.00008142, Avg batch loss: 0.0083, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1152, Step num: 11785, Learning rate: 0.00008142, Avg batch loss: 0.0089, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1153, Step num: 11786, Learning rate: 0.00008142, Avg batch loss: 0.0115, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 1154, Step num: 11787, Learning rate: 0.00008141, Avg batch loss: 0.0092, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1155, Step num: 11788, Learning rate: 0.00008141, Avg batch loss: 0.0116, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 1156, Step num: 11789, Learning rate: 0.00008141, Avg batch loss: 0.0091, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 1157, Step num: 11790, Learning rate: 0.00008140, Avg batch loss: 0.0123, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 1158, Step num: 11791, Learning rate: 0.00008140, Avg batch loss: 0.0106, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1159, Step num: 11792, Learning rate: 0.00008140, Avg batch loss: 0.0096, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 1160, Step num: 11793, Learning rate: 0.00008139, Avg batch loss: 0.0097, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 1161, Step num: 11794, Learning rate: 0.00008139, Avg batch loss: 0.0114, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 1162, Step num: 11795, Learning rate: 0.00008139, Avg batch loss: 0.0087, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1163, Step num: 11796, Learning rate: 0.00008138, Avg batch loss: 0.0109, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1164, Step num: 11797, Learning rate: 0.00008138, Avg batch loss: 0.0125, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 1165, Step num: 11798, Learning rate: 0.00008137, Avg batch loss: 0.0101, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 1166, Step num: 11799, Learning rate: 0.00008137, Avg batch loss: 0.0072, Avg batch acc: 0.9933
Train, Epoch: 8, Batch: 1167, Step num: 11800, Learning rate: 0.00008137, Avg batch loss: 0.0080, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 1168, Step num: 11801, Learning rate: 0.00008136, Avg batch loss: 0.0129, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 1169, Step num: 11802, Learning rate: 0.00008136, Avg batch loss: 0.0107, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 1170, Step num: 11803, Learning rate: 0.00008136, Avg batch loss: 0.0078, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 1171, Step num: 11804, Learning rate: 0.00008135, Avg batch loss: 0.0113, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1172, Step num: 11805, Learning rate: 0.00008135, Avg batch loss: 0.0073, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 1173, Step num: 11806, Learning rate: 0.00008135, Avg batch loss: 0.0082, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1174, Step num: 11807, Learning rate: 0.00008134, Avg batch loss: 0.0113, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 1175, Step num: 11808, Learning rate: 0.00008134, Avg batch loss: 0.0101, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1176, Step num: 11809, Learning rate: 0.00008134, Avg batch loss: 0.0102, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 1177, Step num: 11810, Learning rate: 0.00008133, Avg batch loss: 0.0087, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 1178, Step num: 11811, Learning rate: 0.00008133, Avg batch loss: 0.0101, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 1179, Step num: 11812, Learning rate: 0.00008133, Avg batch loss: 0.0105, Avg batch acc: 0.9881
Train, Epoch: 8, Batch: 1180, Step num: 11813, Learning rate: 0.00008132, Avg batch loss: 0.0105, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 1181, Step num: 11814, Learning rate: 0.00008132, Avg batch loss: 0.0075, Avg batch acc: 0.9926
Train, Epoch: 8, Batch: 1182, Step num: 11815, Learning rate: 0.00008132, Avg batch loss: 0.0104, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1183, Step num: 11816, Learning rate: 0.00008131, Avg batch loss: 0.0078, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 1184, Step num: 11817, Learning rate: 0.00008131, Avg batch loss: 0.0084, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 1185, Step num: 11818, Learning rate: 0.00008131, Avg batch loss: 0.0103, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 1186, Step num: 11819, Learning rate: 0.00008130, Avg batch loss: 0.0103, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 1187, Step num: 11820, Learning rate: 0.00008130, Avg batch loss: 0.0100, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 1188, Step num: 11821, Learning rate: 0.00008130, Avg batch loss: 0.0087, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 1189, Step num: 11822, Learning rate: 0.00008129, Avg batch loss: 0.0091, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 1190, Step num: 11823, Learning rate: 0.00008129, Avg batch loss: 0.0082, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1191, Step num: 11824, Learning rate: 0.00008129, Avg batch loss: 0.0092, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1192, Step num: 11825, Learning rate: 0.00008128, Avg batch loss: 0.0079, Avg batch acc: 0.9926
Train, Epoch: 8, Batch: 1193, Step num: 11826, Learning rate: 0.00008128, Avg batch loss: 0.0125, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1194, Step num: 11827, Learning rate: 0.00008128, Avg batch loss: 0.0105, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 1195, Step num: 11828, Learning rate: 0.00008127, Avg batch loss: 0.0095, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1196, Step num: 11829, Learning rate: 0.00008127, Avg batch loss: 0.0087, Avg batch acc: 0.9926
Train, Epoch: 8, Batch: 1197, Step num: 11830, Learning rate: 0.00008126, Avg batch loss: 0.0094, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 1198, Step num: 11831, Learning rate: 0.00008126, Avg batch loss: 0.0069, Avg batch acc: 0.9926
Train, Epoch: 8, Batch: 1199, Step num: 11832, Learning rate: 0.00008126, Avg batch loss: 0.0099, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1200, Step num: 11833, Learning rate: 0.00008125, Avg batch loss: 0.0083, Avg batch acc: 0.9926
Train, Epoch: 8, Batch: 1201, Step num: 11834, Learning rate: 0.00008125, Avg batch loss: 0.0089, Avg batch acc: 0.9915
Train, Epoch: 8, Batch: 1202, Step num: 11835, Learning rate: 0.00008125, Avg batch loss: 0.0147, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1203, Step num: 11836, Learning rate: 0.00008124, Avg batch loss: 0.0091, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1204, Step num: 11837, Learning rate: 0.00008124, Avg batch loss: 0.0103, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 1205, Step num: 11838, Learning rate: 0.00008124, Avg batch loss: 0.0085, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1206, Step num: 11839, Learning rate: 0.00008123, Avg batch loss: 0.0106, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 1207, Step num: 11840, Learning rate: 0.00008123, Avg batch loss: 0.0129, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 1208, Step num: 11841, Learning rate: 0.00008123, Avg batch loss: 0.0082, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1209, Step num: 11842, Learning rate: 0.00008122, Avg batch loss: 0.0101, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 1210, Step num: 11843, Learning rate: 0.00008122, Avg batch loss: 0.0096, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 1211, Step num: 11844, Learning rate: 0.00008122, Avg batch loss: 0.0104, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 1212, Step num: 11845, Learning rate: 0.00008121, Avg batch loss: 0.0135, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 1213, Step num: 11846, Learning rate: 0.00008121, Avg batch loss: 0.0134, Avg batch acc: 0.9844
Train, Epoch: 8, Batch: 1214, Step num: 11847, Learning rate: 0.00008121, Avg batch loss: 0.0100, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1215, Step num: 11848, Learning rate: 0.00008120, Avg batch loss: 0.0093, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 1216, Step num: 11849, Learning rate: 0.00008120, Avg batch loss: 0.0121, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 1217, Step num: 11850, Learning rate: 0.00008120, Avg batch loss: 0.0091, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 1218, Step num: 11851, Learning rate: 0.00008119, Avg batch loss: 0.0087, Avg batch acc: 0.9915
Train, Epoch: 8, Batch: 1219, Step num: 11852, Learning rate: 0.00008119, Avg batch loss: 0.0073, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 1220, Step num: 11853, Learning rate: 0.00008119, Avg batch loss: 0.0108, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1221, Step num: 11854, Learning rate: 0.00008118, Avg batch loss: 0.0089, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 1222, Step num: 11855, Learning rate: 0.00008118, Avg batch loss: 0.0164, Avg batch acc: 0.9854
Train, Epoch: 8, Batch: 1223, Step num: 11856, Learning rate: 0.00008118, Avg batch loss: 0.0090, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 1224, Step num: 11857, Learning rate: 0.00008117, Avg batch loss: 0.0078, Avg batch acc: 0.9932
Train, Epoch: 8, Batch: 1225, Step num: 11858, Learning rate: 0.00008117, Avg batch loss: 0.0140, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 1226, Step num: 11859, Learning rate: 0.00008117, Avg batch loss: 0.0071, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 1227, Step num: 11860, Learning rate: 0.00008116, Avg batch loss: 0.0092, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1228, Step num: 11861, Learning rate: 0.00008116, Avg batch loss: 0.0094, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 1229, Step num: 11862, Learning rate: 0.00008116, Avg batch loss: 0.0086, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 1230, Step num: 11863, Learning rate: 0.00008115, Avg batch loss: 0.0091, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 1231, Step num: 11864, Learning rate: 0.00008115, Avg batch loss: 0.0108, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 1232, Step num: 11865, Learning rate: 0.00008114, Avg batch loss: 0.0110, Avg batch acc: 0.9915
Train, Epoch: 8, Batch: 1233, Step num: 11866, Learning rate: 0.00008114, Avg batch loss: 0.0097, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 1234, Step num: 11867, Learning rate: 0.00008114, Avg batch loss: 0.0106, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 1235, Step num: 11868, Learning rate: 0.00008113, Avg batch loss: 0.0079, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1236, Step num: 11869, Learning rate: 0.00008113, Avg batch loss: 0.0082, Avg batch acc: 0.9940
Train, Epoch: 8, Batch: 1237, Step num: 11870, Learning rate: 0.00008113, Avg batch loss: 0.0081, Avg batch acc: 0.9926
Train, Epoch: 8, Batch: 1238, Step num: 11871, Learning rate: 0.00008112, Avg batch loss: 0.0091, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1239, Step num: 11872, Learning rate: 0.00008112, Avg batch loss: 0.0091, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 1240, Step num: 11873, Learning rate: 0.00008112, Avg batch loss: 0.0089, Avg batch acc: 0.9940
Train, Epoch: 8, Batch: 1241, Step num: 11874, Learning rate: 0.00008111, Avg batch loss: 0.0073, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1242, Step num: 11875, Learning rate: 0.00008111, Avg batch loss: 0.0090, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 1243, Step num: 11876, Learning rate: 0.00008111, Avg batch loss: 0.0072, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 1244, Step num: 11877, Learning rate: 0.00008110, Avg batch loss: 0.0139, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 1245, Step num: 11878, Learning rate: 0.00008110, Avg batch loss: 0.0115, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 1246, Step num: 11879, Learning rate: 0.00008110, Avg batch loss: 0.0096, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 1247, Step num: 11880, Learning rate: 0.00008109, Avg batch loss: 0.0108, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1248, Step num: 11881, Learning rate: 0.00008109, Avg batch loss: 0.0101, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1249, Step num: 11882, Learning rate: 0.00008109, Avg batch loss: 0.0084, Avg batch acc: 0.9931
Train, Epoch: 8, Batch: 1250, Step num: 11883, Learning rate: 0.00008108, Avg batch loss: 0.0084, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1251, Step num: 11884, Learning rate: 0.00008108, Avg batch loss: 0.0086, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1252, Step num: 11885, Learning rate: 0.00008108, Avg batch loss: 0.0091, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1253, Step num: 11886, Learning rate: 0.00008107, Avg batch loss: 0.0111, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 1254, Step num: 11887, Learning rate: 0.00008107, Avg batch loss: 0.0119, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 1255, Step num: 11888, Learning rate: 0.00008107, Avg batch loss: 0.0090, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1256, Step num: 11889, Learning rate: 0.00008106, Avg batch loss: 0.0094, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 1257, Step num: 11890, Learning rate: 0.00008106, Avg batch loss: 0.0112, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1258, Step num: 11891, Learning rate: 0.00008106, Avg batch loss: 0.0109, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 1259, Step num: 11892, Learning rate: 0.00008105, Avg batch loss: 0.0085, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 1260, Step num: 11893, Learning rate: 0.00008105, Avg batch loss: 0.0096, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1261, Step num: 11894, Learning rate: 0.00008105, Avg batch loss: 0.0107, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1262, Step num: 11895, Learning rate: 0.00008104, Avg batch loss: 0.0099, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 1263, Step num: 11896, Learning rate: 0.00008104, Avg batch loss: 0.0100, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1264, Step num: 11897, Learning rate: 0.00008104, Avg batch loss: 0.0126, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 1265, Step num: 11898, Learning rate: 0.00008103, Avg batch loss: 0.0081, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1266, Step num: 11899, Learning rate: 0.00008103, Avg batch loss: 0.0073, Avg batch acc: 0.9928
Train, Epoch: 8, Batch: 1267, Step num: 11900, Learning rate: 0.00008103, Avg batch loss: 0.0080, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1268, Step num: 11901, Learning rate: 0.00008102, Avg batch loss: 0.0076, Avg batch acc: 0.9941
Train, Epoch: 8, Batch: 1269, Step num: 11902, Learning rate: 0.00008102, Avg batch loss: 0.0105, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1270, Step num: 11903, Learning rate: 0.00008102, Avg batch loss: 0.0104, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 1271, Step num: 11904, Learning rate: 0.00008101, Avg batch loss: 0.0087, Avg batch acc: 0.9926
Train, Epoch: 8, Batch: 1272, Step num: 11905, Learning rate: 0.00008101, Avg batch loss: 0.0103, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 1273, Step num: 11906, Learning rate: 0.00008101, Avg batch loss: 0.0099, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 1274, Step num: 11907, Learning rate: 0.00008100, Avg batch loss: 0.0081, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 1275, Step num: 11908, Learning rate: 0.00008100, Avg batch loss: 0.0090, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 1276, Step num: 11909, Learning rate: 0.00008099, Avg batch loss: 0.0108, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1277, Step num: 11910, Learning rate: 0.00008099, Avg batch loss: 0.0097, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1278, Step num: 11911, Learning rate: 0.00008099, Avg batch loss: 0.0103, Avg batch acc: 0.9870
Train, Epoch: 8, Batch: 1279, Step num: 11912, Learning rate: 0.00008098, Avg batch loss: 0.0089, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1280, Step num: 11913, Learning rate: 0.00008098, Avg batch loss: 0.0080, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 1281, Step num: 11914, Learning rate: 0.00008098, Avg batch loss: 0.0115, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 1282, Step num: 11915, Learning rate: 0.00008097, Avg batch loss: 0.0068, Avg batch acc: 0.9941
Train, Epoch: 8, Batch: 1283, Step num: 11916, Learning rate: 0.00008097, Avg batch loss: 0.0119, Avg batch acc: 0.9848
Train, Epoch: 8, Batch: 1284, Step num: 11917, Learning rate: 0.00008097, Avg batch loss: 0.0087, Avg batch acc: 0.9934
Train, Epoch: 8, Batch: 1285, Step num: 11918, Learning rate: 0.00008096, Avg batch loss: 0.0085, Avg batch acc: 0.9928
Train, Epoch: 8, Batch: 1286, Step num: 11919, Learning rate: 0.00008096, Avg batch loss: 0.0103, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 1287, Step num: 11920, Learning rate: 0.00008096, Avg batch loss: 0.0081, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1288, Step num: 11921, Learning rate: 0.00008095, Avg batch loss: 0.0145, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 1289, Step num: 11922, Learning rate: 0.00008095, Avg batch loss: 0.0092, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1290, Step num: 11923, Learning rate: 0.00008095, Avg batch loss: 0.0075, Avg batch acc: 0.9927
Train, Epoch: 8, Batch: 1291, Step num: 11924, Learning rate: 0.00008094, Avg batch loss: 0.0109, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 1292, Step num: 11925, Learning rate: 0.00008094, Avg batch loss: 0.0108, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 1293, Step num: 11926, Learning rate: 0.00008094, Avg batch loss: 0.0084, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 1294, Step num: 11927, Learning rate: 0.00008093, Avg batch loss: 0.0086, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 1295, Step num: 11928, Learning rate: 0.00008093, Avg batch loss: 0.0084, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1296, Step num: 11929, Learning rate: 0.00008093, Avg batch loss: 0.0117, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 1297, Step num: 11930, Learning rate: 0.00008092, Avg batch loss: 0.0076, Avg batch acc: 0.9946
Train, Epoch: 8, Batch: 1298, Step num: 11931, Learning rate: 0.00008092, Avg batch loss: 0.0083, Avg batch acc: 0.9933
Train, Epoch: 8, Batch: 1299, Step num: 11932, Learning rate: 0.00008092, Avg batch loss: 0.0096, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 1300, Step num: 11933, Learning rate: 0.00008091, Avg batch loss: 0.0087, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1301, Step num: 11934, Learning rate: 0.00008091, Avg batch loss: 0.0085, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 1302, Step num: 11935, Learning rate: 0.00008091, Avg batch loss: 0.0080, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 1303, Step num: 11936, Learning rate: 0.00008090, Avg batch loss: 0.0075, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 1304, Step num: 11937, Learning rate: 0.00008090, Avg batch loss: 0.0123, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 1305, Step num: 11938, Learning rate: 0.00008090, Avg batch loss: 0.0083, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 1306, Step num: 11939, Learning rate: 0.00008089, Avg batch loss: 0.0097, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1307, Step num: 11940, Learning rate: 0.00008089, Avg batch loss: 0.0117, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 1308, Step num: 11941, Learning rate: 0.00008089, Avg batch loss: 0.0204, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 1309, Step num: 11942, Learning rate: 0.00008088, Avg batch loss: 0.0097, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 1310, Step num: 11943, Learning rate: 0.00008088, Avg batch loss: 0.0093, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 1311, Step num: 11944, Learning rate: 0.00008088, Avg batch loss: 0.0109, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1312, Step num: 11945, Learning rate: 0.00008087, Avg batch loss: 0.0108, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 1313, Step num: 11946, Learning rate: 0.00008087, Avg batch loss: 0.0295, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 1314, Step num: 11947, Learning rate: 0.00008087, Avg batch loss: 0.0099, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 1315, Step num: 11948, Learning rate: 0.00008086, Avg batch loss: 0.0317, Avg batch acc: 0.9800
Train, Epoch: 8, Batch: 1316, Step num: 11949, Learning rate: 0.00008086, Avg batch loss: 0.0098, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1317, Step num: 11950, Learning rate: 0.00008086, Avg batch loss: 0.0097, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1318, Step num: 11951, Learning rate: 0.00008085, Avg batch loss: 0.0111, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 1319, Step num: 11952, Learning rate: 0.00008085, Avg batch loss: 0.0125, Avg batch acc: 0.9829
Train, Epoch: 8, Batch: 1320, Step num: 11953, Learning rate: 0.00008085, Avg batch loss: 0.0109, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 1321, Step num: 11954, Learning rate: 0.00008084, Avg batch loss: 0.0091, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1322, Step num: 11955, Learning rate: 0.00008084, Avg batch loss: 0.0075, Avg batch acc: 0.9927
Train, Epoch: 8, Batch: 1323, Step num: 11956, Learning rate: 0.00008084, Avg batch loss: 0.0130, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 1324, Step num: 11957, Learning rate: 0.00008083, Avg batch loss: 0.0114, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 1325, Step num: 11958, Learning rate: 0.00008083, Avg batch loss: 0.0159, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1326, Step num: 11959, Learning rate: 0.00008083, Avg batch loss: 0.0097, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1327, Step num: 11960, Learning rate: 0.00008082, Avg batch loss: 0.0115, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1328, Step num: 11961, Learning rate: 0.00008082, Avg batch loss: 0.0135, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 1329, Step num: 11962, Learning rate: 0.00008082, Avg batch loss: 0.0084, Avg batch acc: 0.9928
Train, Epoch: 8, Batch: 1330, Step num: 11963, Learning rate: 0.00008081, Avg batch loss: 0.0106, Avg batch acc: 0.9877
Train, Epoch: 8, Batch: 1331, Step num: 11964, Learning rate: 0.00008081, Avg batch loss: 0.0108, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 1332, Step num: 11965, Learning rate: 0.00008081, Avg batch loss: 0.0125, Avg batch acc: 0.9853
Train, Epoch: 8, Batch: 1333, Step num: 11966, Learning rate: 0.00008080, Avg batch loss: 0.0102, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 1334, Step num: 11967, Learning rate: 0.00008080, Avg batch loss: 0.0081, Avg batch acc: 0.9929
Train, Epoch: 8, Batch: 1335, Step num: 11968, Learning rate: 0.00008079, Avg batch loss: 0.0072, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 1336, Step num: 11969, Learning rate: 0.00008079, Avg batch loss: 0.0128, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1337, Step num: 11970, Learning rate: 0.00008079, Avg batch loss: 0.0086, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1338, Step num: 11971, Learning rate: 0.00008078, Avg batch loss: 0.0114, Avg batch acc: 0.9884
Train, Epoch: 8, Batch: 1339, Step num: 11972, Learning rate: 0.00008078, Avg batch loss: 0.0072, Avg batch acc: 0.9936
Train, Epoch: 8, Batch: 1340, Step num: 11973, Learning rate: 0.00008078, Avg batch loss: 0.0112, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1341, Step num: 11974, Learning rate: 0.00008077, Avg batch loss: 0.0110, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1342, Step num: 11975, Learning rate: 0.00008077, Avg batch loss: 0.0248, Avg batch acc: 0.9830
Train, Epoch: 8, Batch: 1343, Step num: 11976, Learning rate: 0.00008077, Avg batch loss: 0.0111, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 1344, Step num: 11977, Learning rate: 0.00008076, Avg batch loss: 0.0093, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 1345, Step num: 11978, Learning rate: 0.00008076, Avg batch loss: 0.0081, Avg batch acc: 0.9937
Train, Epoch: 8, Batch: 1346, Step num: 11979, Learning rate: 0.00008076, Avg batch loss: 0.0095, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 1347, Step num: 11980, Learning rate: 0.00008075, Avg batch loss: 0.0108, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1348, Step num: 11981, Learning rate: 0.00008075, Avg batch loss: 0.0084, Avg batch acc: 0.9942
Train, Epoch: 8, Batch: 1349, Step num: 11982, Learning rate: 0.00008075, Avg batch loss: 0.0091, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 1350, Step num: 11983, Learning rate: 0.00008074, Avg batch loss: 0.0102, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 1351, Step num: 11984, Learning rate: 0.00008074, Avg batch loss: 0.0119, Avg batch acc: 0.9868
Train, Epoch: 8, Batch: 1352, Step num: 11985, Learning rate: 0.00008074, Avg batch loss: 0.0123, Avg batch acc: 0.9880
Train, Epoch: 8, Batch: 1353, Step num: 11986, Learning rate: 0.00008073, Avg batch loss: 0.0103, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 1354, Step num: 11987, Learning rate: 0.00008073, Avg batch loss: 0.0082, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1355, Step num: 11988, Learning rate: 0.00008073, Avg batch loss: 0.0223, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 1356, Step num: 11989, Learning rate: 0.00008072, Avg batch loss: 0.0099, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1357, Step num: 11990, Learning rate: 0.00008072, Avg batch loss: 0.0139, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 1358, Step num: 11991, Learning rate: 0.00008072, Avg batch loss: 0.0085, Avg batch acc: 0.9891
Train, Epoch: 8, Batch: 1359, Step num: 11992, Learning rate: 0.00008071, Avg batch loss: 0.0248, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 1360, Step num: 11993, Learning rate: 0.00008071, Avg batch loss: 0.0088, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 1361, Step num: 11994, Learning rate: 0.00008071, Avg batch loss: 0.0138, Avg batch acc: 0.9888
Train, Epoch: 8, Batch: 1362, Step num: 11995, Learning rate: 0.00008070, Avg batch loss: 0.0091, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1363, Step num: 11996, Learning rate: 0.00008070, Avg batch loss: 0.0186, Avg batch acc: 0.9856
Train, Epoch: 8, Batch: 1364, Step num: 11997, Learning rate: 0.00008070, Avg batch loss: 0.0076, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 1365, Step num: 11998, Learning rate: 0.00008069, Avg batch loss: 0.0093, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1366, Step num: 11999, Learning rate: 0.00008069, Avg batch loss: 0.0114, Avg batch acc: 0.9904
Train, Epoch: 8, Batch: 1367, Step num: 12000, Learning rate: 0.00008069, Avg batch loss: 0.0080, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1368, Step num: 12001, Learning rate: 0.00008068, Avg batch loss: 0.0145, Avg batch acc: 0.9885
Train, Epoch: 8, Batch: 1369, Step num: 12002, Learning rate: 0.00008068, Avg batch loss: 0.0104, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1370, Step num: 12003, Learning rate: 0.00008068, Avg batch loss: 0.0077, Avg batch acc: 0.9928
Train, Epoch: 8, Batch: 1371, Step num: 12004, Learning rate: 0.00008067, Avg batch loss: 0.0095, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1372, Step num: 12005, Learning rate: 0.00008067, Avg batch loss: 0.0113, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 1373, Step num: 12006, Learning rate: 0.00008067, Avg batch loss: 0.0113, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 1374, Step num: 12007, Learning rate: 0.00008066, Avg batch loss: 0.0090, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1375, Step num: 12008, Learning rate: 0.00008066, Avg batch loss: 0.0089, Avg batch acc: 0.9913
Train, Epoch: 8, Batch: 1376, Step num: 12009, Learning rate: 0.00008066, Avg batch loss: 0.0074, Avg batch acc: 0.9941
Train, Epoch: 8, Batch: 1377, Step num: 12010, Learning rate: 0.00008065, Avg batch loss: 0.0095, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 1378, Step num: 12011, Learning rate: 0.00008065, Avg batch loss: 0.0116, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1379, Step num: 12012, Learning rate: 0.00008065, Avg batch loss: 0.0118, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1380, Step num: 12013, Learning rate: 0.00008064, Avg batch loss: 0.0131, Avg batch acc: 0.9850
Train, Epoch: 8, Batch: 1381, Step num: 12014, Learning rate: 0.00008064, Avg batch loss: 0.0103, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1382, Step num: 12015, Learning rate: 0.00008064, Avg batch loss: 0.0096, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 1383, Step num: 12016, Learning rate: 0.00008063, Avg batch loss: 0.0108, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 1384, Step num: 12017, Learning rate: 0.00008063, Avg batch loss: 0.0107, Avg batch acc: 0.9901
Train, Epoch: 8, Batch: 1385, Step num: 12018, Learning rate: 0.00008063, Avg batch loss: 0.0095, Avg batch acc: 0.9878
Train, Epoch: 8, Batch: 1386, Step num: 12019, Learning rate: 0.00008062, Avg batch loss: 0.0087, Avg batch acc: 0.9920
Train, Epoch: 8, Batch: 1387, Step num: 12020, Learning rate: 0.00008062, Avg batch loss: 0.0128, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 1388, Step num: 12021, Learning rate: 0.00008062, Avg batch loss: 0.0099, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1389, Step num: 12022, Learning rate: 0.00008061, Avg batch loss: 0.0113, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 1390, Step num: 12023, Learning rate: 0.00008061, Avg batch loss: 0.0115, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 1391, Step num: 12024, Learning rate: 0.00008061, Avg batch loss: 0.0069, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1392, Step num: 12025, Learning rate: 0.00008060, Avg batch loss: 0.0119, Avg batch acc: 0.9872
Train, Epoch: 8, Batch: 1393, Step num: 12026, Learning rate: 0.00008060, Avg batch loss: 0.0099, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1394, Step num: 12027, Learning rate: 0.00008060, Avg batch loss: 0.0108, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1395, Step num: 12028, Learning rate: 0.00008059, Avg batch loss: 0.0074, Avg batch acc: 0.9937
Train, Epoch: 8, Batch: 1396, Step num: 12029, Learning rate: 0.00008059, Avg batch loss: 0.0096, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1397, Step num: 12030, Learning rate: 0.00008059, Avg batch loss: 0.0090, Avg batch acc: 0.9896
Train, Epoch: 8, Batch: 1398, Step num: 12031, Learning rate: 0.00008058, Avg batch loss: 0.0158, Avg batch acc: 0.9862
Train, Epoch: 8, Batch: 1399, Step num: 12032, Learning rate: 0.00008058, Avg batch loss: 0.0108, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 1400, Step num: 12033, Learning rate: 0.00008058, Avg batch loss: 0.0086, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1401, Step num: 12034, Learning rate: 0.00008057, Avg batch loss: 0.0095, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1402, Step num: 12035, Learning rate: 0.00008057, Avg batch loss: 0.0112, Avg batch acc: 0.9886
Train, Epoch: 8, Batch: 1403, Step num: 12036, Learning rate: 0.00008057, Avg batch loss: 0.0114, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 1404, Step num: 12037, Learning rate: 0.00008056, Avg batch loss: 0.0096, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 1405, Step num: 12038, Learning rate: 0.00008056, Avg batch loss: 0.0095, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 1406, Step num: 12039, Learning rate: 0.00008056, Avg batch loss: 0.0118, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 1407, Step num: 12040, Learning rate: 0.00008055, Avg batch loss: 0.0124, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 1408, Step num: 12041, Learning rate: 0.00008055, Avg batch loss: 0.0102, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 1409, Step num: 12042, Learning rate: 0.00008055, Avg batch loss: 0.0100, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 1410, Step num: 12043, Learning rate: 0.00008054, Avg batch loss: 0.0105, Avg batch acc: 0.9866
Train, Epoch: 8, Batch: 1411, Step num: 12044, Learning rate: 0.00008054, Avg batch loss: 0.0093, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1412, Step num: 12045, Learning rate: 0.00008054, Avg batch loss: 0.0147, Avg batch acc: 0.9874
Train, Epoch: 8, Batch: 1413, Step num: 12046, Learning rate: 0.00008053, Avg batch loss: 0.0075, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 1414, Step num: 12047, Learning rate: 0.00008053, Avg batch loss: 0.0079, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1415, Step num: 12048, Learning rate: 0.00008053, Avg batch loss: 0.0081, Avg batch acc: 0.9924
Train, Epoch: 8, Batch: 1416, Step num: 12049, Learning rate: 0.00008052, Avg batch loss: 0.0084, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1417, Step num: 12050, Learning rate: 0.00008052, Avg batch loss: 0.0144, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 1418, Step num: 12051, Learning rate: 0.00008052, Avg batch loss: 0.0085, Avg batch acc: 0.9921
Train, Epoch: 8, Batch: 1419, Step num: 12052, Learning rate: 0.00008051, Avg batch loss: 0.0048, Avg batch acc: 0.9952
Train, Epoch: 8, Batch: 1420, Step num: 12053, Learning rate: 0.00008051, Avg batch loss: 0.0073, Avg batch acc: 0.9934
Train, Epoch: 8, Batch: 1421, Step num: 12054, Learning rate: 0.00008051, Avg batch loss: 0.0083, Avg batch acc: 0.9934
Train, Epoch: 8, Batch: 1422, Step num: 12055, Learning rate: 0.00008050, Avg batch loss: 0.0072, Avg batch acc: 0.9944
Train, Epoch: 8, Batch: 1423, Step num: 12056, Learning rate: 0.00008050, Avg batch loss: 0.0113, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1424, Step num: 12057, Learning rate: 0.00008050, Avg batch loss: 0.0101, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 1425, Step num: 12058, Learning rate: 0.00008049, Avg batch loss: 0.0136, Avg batch acc: 0.9831
Train, Epoch: 8, Batch: 1426, Step num: 12059, Learning rate: 0.00008049, Avg batch loss: 0.0103, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 1427, Step num: 12060, Learning rate: 0.00008049, Avg batch loss: 0.0114, Avg batch acc: 0.9851
Train, Epoch: 8, Batch: 1428, Step num: 12061, Learning rate: 0.00008048, Avg batch loss: 0.0095, Avg batch acc: 0.9906
Train, Epoch: 8, Batch: 1429, Step num: 12062, Learning rate: 0.00008048, Avg batch loss: 0.0095, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 1430, Step num: 12063, Learning rate: 0.00008048, Avg batch loss: 0.0115, Avg batch acc: 0.9863
Train, Epoch: 8, Batch: 1431, Step num: 12064, Learning rate: 0.00008047, Avg batch loss: 0.0093, Avg batch acc: 0.9925
Train, Epoch: 8, Batch: 1432, Step num: 12065, Learning rate: 0.00008047, Avg batch loss: 0.0095, Avg batch acc: 0.9924
Train, Epoch: 8, Batch: 1433, Step num: 12066, Learning rate: 0.00008047, Avg batch loss: 0.0100, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1434, Step num: 12067, Learning rate: 0.00008046, Avg batch loss: 0.0050, Avg batch acc: 0.9949
Train, Epoch: 8, Batch: 1435, Step num: 12068, Learning rate: 0.00008046, Avg batch loss: 0.0062, Avg batch acc: 0.9935
Train, Epoch: 8, Batch: 1436, Step num: 12069, Learning rate: 0.00008046, Avg batch loss: 0.0109, Avg batch acc: 0.9903
Train, Epoch: 8, Batch: 1437, Step num: 12070, Learning rate: 0.00008045, Avg batch loss: 0.0105, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 1438, Step num: 12071, Learning rate: 0.00008045, Avg batch loss: 0.0071, Avg batch acc: 0.9927
Train, Epoch: 8, Batch: 1439, Step num: 12072, Learning rate: 0.00008045, Avg batch loss: 0.0106, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1440, Step num: 12073, Learning rate: 0.00008044, Avg batch loss: 0.0106, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 1441, Step num: 12074, Learning rate: 0.00008044, Avg batch loss: 0.0071, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 1442, Step num: 12075, Learning rate: 0.00008044, Avg batch loss: 0.0084, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1443, Step num: 12076, Learning rate: 0.00008043, Avg batch loss: 0.0094, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1444, Step num: 12077, Learning rate: 0.00008043, Avg batch loss: 0.0068, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1445, Step num: 12078, Learning rate: 0.00008043, Avg batch loss: 0.0083, Avg batch acc: 0.9933
Train, Epoch: 8, Batch: 1446, Step num: 12079, Learning rate: 0.00008042, Avg batch loss: 0.0100, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 1447, Step num: 12080, Learning rate: 0.00008042, Avg batch loss: 0.0103, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 1448, Step num: 12081, Learning rate: 0.00008042, Avg batch loss: 0.0087, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1449, Step num: 12082, Learning rate: 0.00008041, Avg batch loss: 0.0109, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 1450, Step num: 12083, Learning rate: 0.00008041, Avg batch loss: 0.0094, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 1451, Step num: 12084, Learning rate: 0.00008041, Avg batch loss: 0.0087, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1452, Step num: 12085, Learning rate: 0.00008040, Avg batch loss: 0.0095, Avg batch acc: 0.9910
Train, Epoch: 8, Batch: 1453, Step num: 12086, Learning rate: 0.00008040, Avg batch loss: 0.0098, Avg batch acc: 0.9883
Train, Epoch: 8, Batch: 1454, Step num: 12087, Learning rate: 0.00008040, Avg batch loss: 0.0092, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1455, Step num: 12088, Learning rate: 0.00008039, Avg batch loss: 0.0088, Avg batch acc: 0.9933
Train, Epoch: 8, Batch: 1456, Step num: 12089, Learning rate: 0.00008039, Avg batch loss: 0.0107, Avg batch acc: 0.9864
Train, Epoch: 8, Batch: 1457, Step num: 12090, Learning rate: 0.00008039, Avg batch loss: 0.0103, Avg batch acc: 0.9889
Train, Epoch: 8, Batch: 1458, Step num: 12091, Learning rate: 0.00008038, Avg batch loss: 0.0076, Avg batch acc: 0.9938
Train, Epoch: 8, Batch: 1459, Step num: 12092, Learning rate: 0.00008038, Avg batch loss: 0.0078, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 1460, Step num: 12093, Learning rate: 0.00008038, Avg batch loss: 0.0091, Avg batch acc: 0.9932
Train, Epoch: 8, Batch: 1461, Step num: 12094, Learning rate: 0.00008037, Avg batch loss: 0.0096, Avg batch acc: 0.9912
Train, Epoch: 8, Batch: 1462, Step num: 12095, Learning rate: 0.00008037, Avg batch loss: 0.0210, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 1463, Step num: 12096, Learning rate: 0.00008037, Avg batch loss: 0.0084, Avg batch acc: 0.9917
Train, Epoch: 8, Batch: 1464, Step num: 12097, Learning rate: 0.00008036, Avg batch loss: 0.0079, Avg batch acc: 0.9936
Train, Epoch: 8, Batch: 1465, Step num: 12098, Learning rate: 0.00008036, Avg batch loss: 0.0107, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 1466, Step num: 12099, Learning rate: 0.00008036, Avg batch loss: 0.0082, Avg batch acc: 0.9940
Train, Epoch: 8, Batch: 1467, Step num: 12100, Learning rate: 0.00008035, Avg batch loss: 0.0128, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 1468, Step num: 12101, Learning rate: 0.00008035, Avg batch loss: 0.0081, Avg batch acc: 0.9926
Train, Epoch: 8, Batch: 1469, Step num: 12102, Learning rate: 0.00008035, Avg batch loss: 0.0113, Avg batch acc: 0.9893
Train, Epoch: 8, Batch: 1470, Step num: 12103, Learning rate: 0.00008034, Avg batch loss: 0.0075, Avg batch acc: 0.9947
Train, Epoch: 8, Batch: 1471, Step num: 12104, Learning rate: 0.00008034, Avg batch loss: 0.0382, Avg batch acc: 0.9855
Train, Epoch: 8, Batch: 1472, Step num: 12105, Learning rate: 0.00008034, Avg batch loss: 0.0101, Avg batch acc: 0.9850
Train, Epoch: 8, Batch: 1473, Step num: 12106, Learning rate: 0.00008033, Avg batch loss: 0.0132, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 1474, Step num: 12107, Learning rate: 0.00008033, Avg batch loss: 0.0096, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1475, Step num: 12108, Learning rate: 0.00008033, Avg batch loss: 0.0103, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 1476, Step num: 12109, Learning rate: 0.00008032, Avg batch loss: 0.0123, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 1477, Step num: 12110, Learning rate: 0.00008032, Avg batch loss: 0.0095, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 1478, Step num: 12111, Learning rate: 0.00008032, Avg batch loss: 0.0079, Avg batch acc: 0.9892
Train, Epoch: 8, Batch: 1479, Step num: 12112, Learning rate: 0.00008031, Avg batch loss: 0.0079, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1480, Step num: 12113, Learning rate: 0.00008031, Avg batch loss: 0.0198, Avg batch acc: 0.9860
Train, Epoch: 8, Batch: 1481, Step num: 12114, Learning rate: 0.00008031, Avg batch loss: 0.0079, Avg batch acc: 0.9936
Train, Epoch: 8, Batch: 1482, Step num: 12115, Learning rate: 0.00008030, Avg batch loss: 0.0117, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 1483, Step num: 12116, Learning rate: 0.00008030, Avg batch loss: 0.0095, Avg batch acc: 0.9879
Train, Epoch: 8, Batch: 1484, Step num: 12117, Learning rate: 0.00008030, Avg batch loss: 0.0161, Avg batch acc: 0.9827
Train, Epoch: 8, Batch: 1485, Step num: 12118, Learning rate: 0.00008029, Avg batch loss: 0.0081, Avg batch acc: 0.9897
Train, Epoch: 8, Batch: 1486, Step num: 12119, Learning rate: 0.00008029, Avg batch loss: 0.0071, Avg batch acc: 0.9923
Train, Epoch: 8, Batch: 1487, Step num: 12120, Learning rate: 0.00008029, Avg batch loss: 0.0077, Avg batch acc: 0.9933
Train, Epoch: 8, Batch: 1488, Step num: 12121, Learning rate: 0.00008028, Avg batch loss: 0.0088, Avg batch acc: 0.9918
Train, Epoch: 8, Batch: 1489, Step num: 12122, Learning rate: 0.00008028, Avg batch loss: 0.0076, Avg batch acc: 0.9920
Train, Epoch: 8, Batch: 1490, Step num: 12123, Learning rate: 0.00008028, Avg batch loss: 0.0072, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 1491, Step num: 12124, Learning rate: 0.00008027, Avg batch loss: 0.0065, Avg batch acc: 0.9948
Train, Epoch: 8, Batch: 1492, Step num: 12125, Learning rate: 0.00008027, Avg batch loss: 0.0095, Avg batch acc: 0.9922
Train, Epoch: 8, Batch: 1493, Step num: 12126, Learning rate: 0.00008027, Avg batch loss: 0.0126, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1494, Step num: 12127, Learning rate: 0.00008026, Avg batch loss: 0.0120, Avg batch acc: 0.9890
Train, Epoch: 8, Batch: 1495, Step num: 12128, Learning rate: 0.00008026, Avg batch loss: 0.0109, Avg batch acc: 0.9899
Train, Epoch: 8, Batch: 1496, Step num: 12129, Learning rate: 0.00008026, Avg batch loss: 0.0098, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1497, Step num: 12130, Learning rate: 0.00008025, Avg batch loss: 0.0090, Avg batch acc: 0.9911
Train, Epoch: 8, Batch: 1498, Step num: 12131, Learning rate: 0.00008025, Avg batch loss: 0.0077, Avg batch acc: 0.9916
Train, Epoch: 8, Batch: 1499, Step num: 12132, Learning rate: 0.00008025, Avg batch loss: 0.0096, Avg batch acc: 0.9894
Train, Epoch: 8, Batch: 1500, Step num: 12133, Learning rate: 0.00008024, Avg batch loss: 0.0093, Avg batch acc: 0.9908
Train, Epoch: 8, Batch: 1501, Step num: 12134, Learning rate: 0.00008024, Avg batch loss: 0.0100, Avg batch acc: 0.9930
Train, Epoch: 8, Batch: 1502, Step num: 12135, Learning rate: 0.00008024, Avg batch loss: 0.0128, Avg batch acc: 0.9882
Train, Epoch: 8, Batch: 1503, Step num: 12136, Learning rate: 0.00008023, Avg batch loss: 0.0128, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1504, Step num: 12137, Learning rate: 0.00008023, Avg batch loss: 0.0122, Avg batch acc: 0.9900
Train, Epoch: 8, Batch: 1505, Step num: 12138, Learning rate: 0.00008023, Avg batch loss: 0.0104, Avg batch acc: 0.9887
Train, Epoch: 8, Batch: 1506, Step num: 12139, Learning rate: 0.00008022, Avg batch loss: 0.0091, Avg batch acc: 0.9895
Train, Epoch: 8, Batch: 1507, Step num: 12140, Learning rate: 0.00008022, Avg batch loss: 0.0093, Avg batch acc: 0.9909
Train, Epoch: 8, Batch: 1508, Step num: 12141, Learning rate: 0.00008022, Avg batch loss: 0.0096, Avg batch acc: 0.9898
Train, Epoch: 8, Batch: 1509, Step num: 12142, Learning rate: 0.00008021, Avg batch loss: 0.0083, Avg batch acc: 0.9919
Train, Epoch: 8, Batch: 1510, Step num: 12143, Learning rate: 0.00008021, Avg batch loss: 0.0076, Avg batch acc: 0.9914
Train, Epoch: 8, Batch: 1511, Step num: 12144, Learning rate: 0.00008021, Avg batch loss: 0.0111, Avg batch acc: 0.9902
Train, Epoch: 8, Batch: 1512, Step num: 12145, Learning rate: 0.00008020, Avg batch loss: 0.0099, Avg batch acc: 0.9905
Train, Epoch: 8, Batch: 1513, Step num: 12146, Learning rate: 0.00008020, Avg batch loss: 0.0071, Avg batch acc: 0.9941
Train, Epoch: 8, Batch: 1514, Step num: 12147, Learning rate: 0.00008020, Avg batch loss: 0.0112, Avg batch acc: 0.9873
Train, Epoch: 8, Batch: 1515, Step num: 12148, Learning rate: 0.00008019, Avg batch loss: 0.0117, Avg batch acc: 0.9875
Train, Epoch: 8, Batch: 1516, Step num: 12149, Learning rate: 0.00008019, Avg batch loss: 0.0112, Avg batch acc: 0.9907
Train, Epoch: 8, Batch: 1517, Step num: 12150, Learning rate: 0.00008019, Avg batch loss: 0.0078, Avg batch acc: 0.9927
Train, Epoch: 8, Batch: 1518, Step num: 12151, Learning rate: 0.00008018, Avg batch loss: 0.0099, Avg batch acc: 0.9876
Train, Epoch: 8, Batch: 1519, Step num: 12152, Learning rate: 0.00008018, Avg batch loss: 0.0082, Avg batch acc: 0.9928
Train, Epoch: 8, Avg epoch loss: 0.0116, Avg epoch acc: 0.9889, Overall time: 977.7 s, Speed: 4452.1 tokens/s on cuda:1

Validate, Epoch: 8, Batch: 1, Avg batch loss: 0.0090, Avg batch acc: 0.9915
Validate, Epoch: 8, Batch: 2, Avg batch loss: 0.0089, Avg batch acc: 0.9915
Validate, Epoch: 8, Batch: 3, Avg batch loss: 0.0099, Avg batch acc: 0.9895
Validate, Epoch: 8, Batch: 4, Avg batch loss: 0.0096, Avg batch acc: 0.9909
Validate, Epoch: 8, Batch: 5, Avg batch loss: 0.0102, Avg batch acc: 0.9908
Validate, Epoch: 8, Batch: 6, Avg batch loss: 0.0089, Avg batch acc: 0.9903
Validate, Epoch: 8, Batch: 7, Avg batch loss: 0.0102, Avg batch acc: 0.9903
Validate, Epoch: 8, Batch: 8, Avg batch loss: 0.0082, Avg batch acc: 0.9924
Validate, Epoch: 8, Batch: 9, Avg batch loss: 0.0124, Avg batch acc: 0.9874
Validate, Epoch: 8, Batch: 10, Avg batch loss: 0.0077, Avg batch acc: 0.9925
Validate, Epoch: 8, Batch: 11, Avg batch loss: 0.0093, Avg batch acc: 0.9920
Validate, Epoch: 8, Batch: 12, Avg batch loss: 0.0093, Avg batch acc: 0.9916
Validate, Epoch: 8, Batch: 13, Avg batch loss: 0.0086, Avg batch acc: 0.9886
Validate, Epoch: 8, Batch: 14, Avg batch loss: 0.0089, Avg batch acc: 0.9893
Validate, Epoch: 8, Batch: 15, Avg batch loss: 0.0107, Avg batch acc: 0.9892
Validate, Epoch: 8, Batch: 16, Avg batch loss: 0.0068, Avg batch acc: 0.9926
Validate, Epoch: 8, Batch: 17, Avg batch loss: 0.0087, Avg batch acc: 0.9924
Validate, Epoch: 8, Batch: 18, Avg batch loss: 0.0108, Avg batch acc: 0.9895
Validate, Epoch: 8, Batch: 19, Avg batch loss: 0.0110, Avg batch acc: 0.9902
Validate, Epoch: 8, Batch: 20, Avg batch loss: 0.0089, Avg batch acc: 0.9888
Validate, Epoch: 8, Batch: 21, Avg batch loss: 0.0079, Avg batch acc: 0.9922
Validate, Epoch: 8, Batch: 22, Avg batch loss: 0.0073, Avg batch acc: 0.9922
Validate, Epoch: 8, Batch: 23, Avg batch loss: 0.0099, Avg batch acc: 0.9884
Validate, Epoch: 8, Batch: 24, Avg batch loss: 0.0116, Avg batch acc: 0.9922
Validate, Epoch: 8, Batch: 25, Avg batch loss: 0.0079, Avg batch acc: 0.9916
Validate, Epoch: 8, Batch: 26, Avg batch loss: 0.0106, Avg batch acc: 0.9883
Validate, Epoch: 8, Batch: 27, Avg batch loss: 0.0085, Avg batch acc: 0.9915
Validate, Epoch: 8, Batch: 28, Avg batch loss: 0.0097, Avg batch acc: 0.9903
Validate, Epoch: 8, Batch: 29, Avg batch loss: 0.0088, Avg batch acc: 0.9902
Validate, Epoch: 8, Batch: 30, Avg batch loss: 0.0112, Avg batch acc: 0.9903
Validate, Epoch: 8, Batch: 31, Avg batch loss: 0.0081, Avg batch acc: 0.9904
Validate, Epoch: 8, Batch: 32, Avg batch loss: 0.0095, Avg batch acc: 0.9920
Validate, Epoch: 8, Batch: 33, Avg batch loss: 0.0125, Avg batch acc: 0.9874
Validate, Epoch: 8, Batch: 34, Avg batch loss: 0.0069, Avg batch acc: 0.9931
Validate, Epoch: 8, Batch: 35, Avg batch loss: 0.0074, Avg batch acc: 0.9943
Validate, Epoch: 8, Batch: 36, Avg batch loss: 0.0105, Avg batch acc: 0.9884
Validate, Epoch: 8, Batch: 37, Avg batch loss: 0.0112, Avg batch acc: 0.9885
Validate, Epoch: 8, Batch: 38, Avg batch loss: 0.0085, Avg batch acc: 0.9915
Validate, Epoch: 8, Batch: 39, Avg batch loss: 0.0259, Avg batch acc: 0.9878
Validate, Epoch: 8, Batch: 40, Avg batch loss: 0.0120, Avg batch acc: 0.9849
Validate, Epoch: 8, Batch: 41, Avg batch loss: 0.0090, Avg batch acc: 0.9907
Validate, Epoch: 8, Batch: 42, Avg batch loss: 0.0100, Avg batch acc: 0.9868
Validate, Epoch: 8, Batch: 43, Avg batch loss: 0.0075, Avg batch acc: 0.9915
Validate, Epoch: 8, Batch: 44, Avg batch loss: 0.0127, Avg batch acc: 0.9865
Validate, Epoch: 8, Batch: 45, Avg batch loss: 0.0121, Avg batch acc: 0.9894
Validate, Epoch: 8, Batch: 46, Avg batch loss: 0.0087, Avg batch acc: 0.9892
Validate, Epoch: 8, Batch: 47, Avg batch loss: 0.0081, Avg batch acc: 0.9931
Validate, Epoch: 8, Batch: 48, Avg batch loss: 0.0126, Avg batch acc: 0.9880
Validate, Epoch: 8, Batch: 49, Avg batch loss: 0.0089, Avg batch acc: 0.9913
Validate, Epoch: 8, Batch: 50, Avg batch loss: 0.0096, Avg batch acc: 0.9904
Validate, Epoch: 8, Batch: 51, Avg batch loss: 0.0076, Avg batch acc: 0.9911
Validate, Epoch: 8, Batch: 52, Avg batch loss: 0.0086, Avg batch acc: 0.9896
Validate, Epoch: 8, Batch: 53, Avg batch loss: 0.0089, Avg batch acc: 0.9903
Validate, Epoch: 8, Batch: 54, Avg batch loss: 0.0106, Avg batch acc: 0.9900
Validate, Epoch: 8, Batch: 55, Avg batch loss: 0.0090, Avg batch acc: 0.9902
Validate, Epoch: 8, Batch: 56, Avg batch loss: 0.0109, Avg batch acc: 0.9906
Validate, Epoch: 8, Batch: 57, Avg batch loss: 0.0111, Avg batch acc: 0.9865
Validate, Epoch: 8, Batch: 58, Avg batch loss: 0.0082, Avg batch acc: 0.9917
Validate, Epoch: 8, Batch: 59, Avg batch loss: 0.0085, Avg batch acc: 0.9908
Validate, Epoch: 8, Batch: 60, Avg batch loss: 0.0066, Avg batch acc: 0.9945
Validate, Epoch: 8, Batch: 61, Avg batch loss: 0.0094, Avg batch acc: 0.9900
Validate, Epoch: 8, Batch: 62, Avg batch loss: 0.0109, Avg batch acc: 0.9915
Validate, Epoch: 8, Batch: 63, Avg batch loss: 0.0096, Avg batch acc: 0.9896
Validate, Epoch: 8, Batch: 64, Avg batch loss: 0.0095, Avg batch acc: 0.9896
Validate, Epoch: 8, Batch: 65, Avg batch loss: 0.0101, Avg batch acc: 0.9925
Validate, Epoch: 8, Batch: 66, Avg batch loss: 0.0104, Avg batch acc: 0.9890
Validate, Epoch: 8, Batch: 67, Avg batch loss: 0.0084, Avg batch acc: 0.9928
Validate, Epoch: 8, Batch: 68, Avg batch loss: 0.0103, Avg batch acc: 0.9862
Validate, Epoch: 8, Batch: 69, Avg batch loss: 0.0081, Avg batch acc: 0.9900
Validate, Epoch: 8, Batch: 70, Avg batch loss: 0.0123, Avg batch acc: 0.9871
Validate, Epoch: 8, Batch: 71, Avg batch loss: 0.0105, Avg batch acc: 0.9888
Validate, Epoch: 8, Batch: 72, Avg batch loss: 0.0071, Avg batch acc: 0.9934
Validate, Epoch: 8, Batch: 73, Avg batch loss: 0.0155, Avg batch acc: 0.9881
Validate, Epoch: 8, Batch: 74, Avg batch loss: 0.0088, Avg batch acc: 0.9918
Validate, Epoch: 8, Batch: 75, Avg batch loss: 0.0085, Avg batch acc: 0.9925
Validate, Epoch: 8, Batch: 76, Avg batch loss: 0.0080, Avg batch acc: 0.9924
Validate, Epoch: 8, Batch: 77, Avg batch loss: 0.0108, Avg batch acc: 0.9859
Validate, Epoch: 8, Batch: 78, Avg batch loss: 0.0119, Avg batch acc: 0.9900
Validate, Epoch: 8, Batch: 79, Avg batch loss: 0.0081, Avg batch acc: 0.9935
Validate, Epoch: 8, Batch: 80, Avg batch loss: 0.0116, Avg batch acc: 0.9900
Validate, Epoch: 8, Batch: 81, Avg batch loss: 0.0110, Avg batch acc: 0.9916
Validate, Epoch: 8, Batch: 82, Avg batch loss: 0.0096, Avg batch acc: 0.9916
Validate, Epoch: 8, Batch: 83, Avg batch loss: 0.0090, Avg batch acc: 0.9905
Validate, Epoch: 8, Batch: 84, Avg batch loss: 0.0129, Avg batch acc: 0.9898
Validate, Epoch: 8, Batch: 85, Avg batch loss: 0.0073, Avg batch acc: 0.9934
Validate, Epoch: 8, Batch: 86, Avg batch loss: 0.0073, Avg batch acc: 0.9900
Validate, Epoch: 8, Batch: 87, Avg batch loss: 0.0078, Avg batch acc: 0.9934
Validate, Epoch: 8, Batch: 88, Avg batch loss: 0.0084, Avg batch acc: 0.9913
Validate, Epoch: 8, Batch: 89, Avg batch loss: 0.0071, Avg batch acc: 0.9927
Validate, Epoch: 8, Batch: 90, Avg batch loss: 0.0108, Avg batch acc: 0.9882
Validate, Epoch: 8, Batch: 91, Avg batch loss: 0.0086, Avg batch acc: 0.9910
Validate, Epoch: 8, Batch: 92, Avg batch loss: 0.0122, Avg batch acc: 0.9882
Validate, Epoch: 8, Batch: 93, Avg batch loss: 0.0103, Avg batch acc: 0.9883
Validate, Epoch: 8, Batch: 94, Avg batch loss: 0.0070, Avg batch acc: 0.9922
Validate, Epoch: 8, Batch: 95, Avg batch loss: 0.0112, Avg batch acc: 0.9909
Validate, Epoch: 8, Batch: 96, Avg batch loss: 0.0105, Avg batch acc: 0.9888
Validate, Epoch: 8, Batch: 97, Avg batch loss: 0.0088, Avg batch acc: 0.9922
Validate, Epoch: 8, Batch: 98, Avg batch loss: 0.0081, Avg batch acc: 0.9948
Validate, Epoch: 8, Batch: 99, Avg batch loss: 0.0080, Avg batch acc: 0.9892
Validate, Epoch: 8, Batch: 100, Avg batch loss: 0.0098, Avg batch acc: 0.9921
Validate, Epoch: 8, Batch: 101, Avg batch loss: 0.0099, Avg batch acc: 0.9878
Validate, Epoch: 8, Batch: 102, Avg batch loss: 0.0067, Avg batch acc: 0.9953
Validate, Epoch: 8, Batch: 103, Avg batch loss: 0.0069, Avg batch acc: 0.9923
Validate, Epoch: 8, Batch: 104, Avg batch loss: 0.0110, Avg batch acc: 0.9909
Validate, Epoch: 8, Batch: 105, Avg batch loss: 0.0090, Avg batch acc: 0.9910
Validate, Epoch: 8, Batch: 106, Avg batch loss: 0.0107, Avg batch acc: 0.9885
Validate, Epoch: 8, Batch: 107, Avg batch loss: 0.0093, Avg batch acc: 0.9927
Validate, Epoch: 8, Batch: 108, Avg batch loss: 0.0096, Avg batch acc: 0.9926
Validate, Epoch: 8, Batch: 109, Avg batch loss: 0.0095, Avg batch acc: 0.9918
Validate, Epoch: 8, Batch: 110, Avg batch loss: 0.0090, Avg batch acc: 0.9911
Validate, Epoch: 8, Batch: 111, Avg batch loss: 0.0092, Avg batch acc: 0.9871
Validate, Epoch: 8, Batch: 112, Avg batch loss: 0.0100, Avg batch acc: 0.9896
Validate, Epoch: 8, Batch: 113, Avg batch loss: 0.0137, Avg batch acc: 0.9822
Validate, Epoch: 8, Batch: 114, Avg batch loss: 0.0070, Avg batch acc: 0.9944
Validate, Epoch: 8, Batch: 115, Avg batch loss: 0.0112, Avg batch acc: 0.9887
Validate, Epoch: 8, Batch: 116, Avg batch loss: 0.0111, Avg batch acc: 0.9895
Validate, Epoch: 8, Batch: 117, Avg batch loss: 0.0099, Avg batch acc: 0.9914
Validate, Epoch: 8, Batch: 118, Avg batch loss: 0.0078, Avg batch acc: 0.9909
Validate, Epoch: 8, Batch: 119, Avg batch loss: 0.0115, Avg batch acc: 0.9879
Validate, Epoch: 8, Batch: 120, Avg batch loss: 0.0100, Avg batch acc: 0.9857
Validate, Epoch: 8, Batch: 121, Avg batch loss: 0.0083, Avg batch acc: 0.9919
Validate, Epoch: 8, Batch: 122, Avg batch loss: 0.0079, Avg batch acc: 0.9912
Validate, Epoch: 8, Batch: 123, Avg batch loss: 0.0126, Avg batch acc: 0.9868
Validate, Epoch: 8, Batch: 124, Avg batch loss: 0.0078, Avg batch acc: 0.9909
Validate, Epoch: 8, Batch: 125, Avg batch loss: 0.0133, Avg batch acc: 0.9872
Validate, Epoch: 8, Batch: 126, Avg batch loss: 0.0076, Avg batch acc: 0.9936
Validate, Epoch: 8, Batch: 127, Avg batch loss: 0.0082, Avg batch acc: 0.9933
Validate, Epoch: 8, Batch: 128, Avg batch loss: 0.0101, Avg batch acc: 0.9913
Validate, Epoch: 8, Batch: 129, Avg batch loss: 0.0113, Avg batch acc: 0.9865
Validate, Epoch: 8, Batch: 130, Avg batch loss: 0.0083, Avg batch acc: 0.9891
Validate, Epoch: 8, Batch: 131, Avg batch loss: 0.0110, Avg batch acc: 0.9901
Validate, Epoch: 8, Batch: 132, Avg batch loss: 0.0137, Avg batch acc: 0.9890
Validate, Epoch: 8, Batch: 133, Avg batch loss: 0.0102, Avg batch acc: 0.9931
Validate, Epoch: 8, Batch: 134, Avg batch loss: 0.0098, Avg batch acc: 0.9894
Validate, Epoch: 8, Batch: 135, Avg batch loss: 0.0099, Avg batch acc: 0.9914
Validate, Epoch: 8, Batch: 136, Avg batch loss: 0.0083, Avg batch acc: 0.9909
Validate, Epoch: 8, Batch: 137, Avg batch loss: 0.0096, Avg batch acc: 0.9910
Validate, Epoch: 8, Batch: 138, Avg batch loss: 0.0122, Avg batch acc: 0.9867
Validate, Epoch: 8, Batch: 139, Avg batch loss: 0.0103, Avg batch acc: 0.9918
Validate, Epoch: 8, Batch: 140, Avg batch loss: 0.0125, Avg batch acc: 0.9890
Validate, Epoch: 8, Batch: 141, Avg batch loss: 0.0157, Avg batch acc: 0.9871
Validate, Epoch: 8, Batch: 142, Avg batch loss: 0.0097, Avg batch acc: 0.9930
Validate, Epoch: 8, Batch: 143, Avg batch loss: 0.0116, Avg batch acc: 0.9881
Validate, Epoch: 8, Batch: 144, Avg batch loss: 0.0102, Avg batch acc: 0.9929
Validate, Epoch: 8, Batch: 145, Avg batch loss: 0.0103, Avg batch acc: 0.9893
Validate, Epoch: 8, Batch: 146, Avg batch loss: 0.0114, Avg batch acc: 0.9852
Validate, Epoch: 8, Batch: 147, Avg batch loss: 0.0112, Avg batch acc: 0.9907
Validate, Epoch: 8, Batch: 148, Avg batch loss: 0.0359, Avg batch acc: 0.9856
Validate, Epoch: 8, Batch: 149, Avg batch loss: 0.0084, Avg batch acc: 0.9901
Validate, Epoch: 8, Batch: 150, Avg batch loss: 0.0098, Avg batch acc: 0.9917
Validate, Epoch: 8, Batch: 151, Avg batch loss: 0.0086, Avg batch acc: 0.9919
Validate, Epoch: 8, Batch: 152, Avg batch loss: 0.0088, Avg batch acc: 0.9934
Validate, Epoch: 8, Batch: 153, Avg batch loss: 0.0080, Avg batch acc: 0.9928
Validate, Epoch: 8, Batch: 154, Avg batch loss: 0.0221, Avg batch acc: 0.9888
Validate, Epoch: 8, Batch: 155, Avg batch loss: 0.0130, Avg batch acc: 0.9912
Validate, Epoch: 8, Batch: 156, Avg batch loss: 0.0089, Avg batch acc: 0.9898
Validate, Epoch: 8, Batch: 157, Avg batch loss: 0.0117, Avg batch acc: 0.9898
Validate, Epoch: 8, Batch: 158, Avg batch loss: 0.0082, Avg batch acc: 0.9939
Validate, Epoch: 8, Batch: 159, Avg batch loss: 0.0100, Avg batch acc: 0.9900
Validate, Epoch: 8, Batch: 160, Avg batch loss: 0.0068, Avg batch acc: 0.9944
Validate, Epoch: 8, Batch: 161, Avg batch loss: 0.0095, Avg batch acc: 0.9898
Validate, Epoch: 8, Batch: 162, Avg batch loss: 0.0121, Avg batch acc: 0.9881
Validate, Epoch: 8, Batch: 163, Avg batch loss: 0.0105, Avg batch acc: 0.9905
Validate, Epoch: 8, Batch: 164, Avg batch loss: 0.0081, Avg batch acc: 0.9932
Validate, Epoch: 8, Batch: 165, Avg batch loss: 0.0112, Avg batch acc: 0.9887
Validate, Epoch: 8, Batch: 166, Avg batch loss: 0.0095, Avg batch acc: 0.9886
Validate, Epoch: 8, Batch: 167, Avg batch loss: 0.0065, Avg batch acc: 0.9936
Validate, Epoch: 8, Batch: 168, Avg batch loss: 0.0103, Avg batch acc: 0.9910
Validate, Epoch: 8, Batch: 169, Avg batch loss: 0.0128, Avg batch acc: 0.9908
Validate, Epoch: 8, Avg epoch loss: 0.0100, Avg epoch acc: 0.9904, Overall time: 36.3 s, Speed: 13283.7 tokens/s on cuda:1

Train, Epoch: 9, Batch: 1, Step num: 12153, Learning rate: 0.00008018, Avg batch loss: 0.0093, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 2, Step num: 12154, Learning rate: 0.00008017, Avg batch loss: 0.0114, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 3, Step num: 12155, Learning rate: 0.00008017, Avg batch loss: 0.0091, Avg batch acc: 0.9878
Train, Epoch: 9, Batch: 4, Step num: 12156, Learning rate: 0.00008017, Avg batch loss: 0.0061, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 5, Step num: 12157, Learning rate: 0.00008016, Avg batch loss: 0.0083, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 6, Step num: 12158, Learning rate: 0.00008016, Avg batch loss: 0.0103, Avg batch acc: 0.9887
Train, Epoch: 9, Batch: 7, Step num: 12159, Learning rate: 0.00008016, Avg batch loss: 0.0097, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 8, Step num: 12160, Learning rate: 0.00008015, Avg batch loss: 0.0110, Avg batch acc: 0.9893
Train, Epoch: 9, Batch: 9, Step num: 12161, Learning rate: 0.00008015, Avg batch loss: 0.0070, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 10, Step num: 12162, Learning rate: 0.00008015, Avg batch loss: 0.0105, Avg batch acc: 0.9871
Train, Epoch: 9, Batch: 11, Step num: 12163, Learning rate: 0.00008014, Avg batch loss: 0.0080, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 12, Step num: 12164, Learning rate: 0.00008014, Avg batch loss: 0.0085, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 13, Step num: 12165, Learning rate: 0.00008014, Avg batch loss: 0.0088, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 14, Step num: 12166, Learning rate: 0.00008013, Avg batch loss: 0.0106, Avg batch acc: 0.9852
Train, Epoch: 9, Batch: 15, Step num: 12167, Learning rate: 0.00008013, Avg batch loss: 0.0103, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 16, Step num: 12168, Learning rate: 0.00008013, Avg batch loss: 0.0097, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 17, Step num: 12169, Learning rate: 0.00008012, Avg batch loss: 0.0095, Avg batch acc: 0.9886
Train, Epoch: 9, Batch: 18, Step num: 12170, Learning rate: 0.00008012, Avg batch loss: 0.0108, Avg batch acc: 0.9874
Train, Epoch: 9, Batch: 19, Step num: 12171, Learning rate: 0.00008012, Avg batch loss: 0.0093, Avg batch acc: 0.9867
Train, Epoch: 9, Batch: 20, Step num: 12172, Learning rate: 0.00008012, Avg batch loss: 0.0068, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 21, Step num: 12173, Learning rate: 0.00008011, Avg batch loss: 0.0085, Avg batch acc: 0.9876
Train, Epoch: 9, Batch: 22, Step num: 12174, Learning rate: 0.00008011, Avg batch loss: 0.0090, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 23, Step num: 12175, Learning rate: 0.00008011, Avg batch loss: 0.0073, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 24, Step num: 12176, Learning rate: 0.00008010, Avg batch loss: 0.0092, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 25, Step num: 12177, Learning rate: 0.00008010, Avg batch loss: 0.0091, Avg batch acc: 0.9898
Train, Epoch: 9, Batch: 26, Step num: 12178, Learning rate: 0.00008010, Avg batch loss: 0.0090, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 27, Step num: 12179, Learning rate: 0.00008009, Avg batch loss: 0.0082, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 28, Step num: 12180, Learning rate: 0.00008009, Avg batch loss: 0.0071, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 29, Step num: 12181, Learning rate: 0.00008009, Avg batch loss: 0.0098, Avg batch acc: 0.9887
Train, Epoch: 9, Batch: 30, Step num: 12182, Learning rate: 0.00008008, Avg batch loss: 0.0088, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 31, Step num: 12183, Learning rate: 0.00008008, Avg batch loss: 0.0076, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 32, Step num: 12184, Learning rate: 0.00008008, Avg batch loss: 0.0092, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 33, Step num: 12185, Learning rate: 0.00008007, Avg batch loss: 0.0073, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 34, Step num: 12186, Learning rate: 0.00008007, Avg batch loss: 0.0072, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 35, Step num: 12187, Learning rate: 0.00008007, Avg batch loss: 0.0081, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 36, Step num: 12188, Learning rate: 0.00008006, Avg batch loss: 0.0086, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 37, Step num: 12189, Learning rate: 0.00008006, Avg batch loss: 0.0098, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 38, Step num: 12190, Learning rate: 0.00008006, Avg batch loss: 0.0089, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 39, Step num: 12191, Learning rate: 0.00008005, Avg batch loss: 0.0079, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 40, Step num: 12192, Learning rate: 0.00008005, Avg batch loss: 0.0118, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 41, Step num: 12193, Learning rate: 0.00008005, Avg batch loss: 0.0084, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 42, Step num: 12194, Learning rate: 0.00008004, Avg batch loss: 0.0118, Avg batch acc: 0.9890
Train, Epoch: 9, Batch: 43, Step num: 12195, Learning rate: 0.00008004, Avg batch loss: 0.0105, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 44, Step num: 12196, Learning rate: 0.00008004, Avg batch loss: 0.0068, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 45, Step num: 12197, Learning rate: 0.00008003, Avg batch loss: 0.0091, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 46, Step num: 12198, Learning rate: 0.00008003, Avg batch loss: 0.0106, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 47, Step num: 12199, Learning rate: 0.00008003, Avg batch loss: 0.0086, Avg batch acc: 0.9889
Train, Epoch: 9, Batch: 48, Step num: 12200, Learning rate: 0.00008002, Avg batch loss: 0.0088, Avg batch acc: 0.9886
Train, Epoch: 9, Batch: 49, Step num: 12201, Learning rate: 0.00008002, Avg batch loss: 0.0100, Avg batch acc: 0.9894
Train, Epoch: 9, Batch: 50, Step num: 12202, Learning rate: 0.00008002, Avg batch loss: 0.0097, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 51, Step num: 12203, Learning rate: 0.00008001, Avg batch loss: 0.0079, Avg batch acc: 0.9959
Train, Epoch: 9, Batch: 52, Step num: 12204, Learning rate: 0.00008001, Avg batch loss: 0.0063, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 53, Step num: 12205, Learning rate: 0.00008001, Avg batch loss: 0.0056, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 54, Step num: 12206, Learning rate: 0.00008000, Avg batch loss: 0.0087, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 55, Step num: 12207, Learning rate: 0.00008000, Avg batch loss: 0.0061, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 56, Step num: 12208, Learning rate: 0.00008000, Avg batch loss: 0.0114, Avg batch acc: 0.9886
Train, Epoch: 9, Batch: 57, Step num: 12209, Learning rate: 0.00007999, Avg batch loss: 0.0084, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 58, Step num: 12210, Learning rate: 0.00007999, Avg batch loss: 0.0067, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 59, Step num: 12211, Learning rate: 0.00007999, Avg batch loss: 0.0099, Avg batch acc: 0.9887
Train, Epoch: 9, Batch: 60, Step num: 12212, Learning rate: 0.00007998, Avg batch loss: 0.0096, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 61, Step num: 12213, Learning rate: 0.00007998, Avg batch loss: 0.0067, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 62, Step num: 12214, Learning rate: 0.00007998, Avg batch loss: 0.0111, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 63, Step num: 12215, Learning rate: 0.00007997, Avg batch loss: 0.0080, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 64, Step num: 12216, Learning rate: 0.00007997, Avg batch loss: 0.0104, Avg batch acc: 0.9886
Train, Epoch: 9, Batch: 65, Step num: 12217, Learning rate: 0.00007997, Avg batch loss: 0.0094, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 66, Step num: 12218, Learning rate: 0.00007996, Avg batch loss: 0.0059, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 67, Step num: 12219, Learning rate: 0.00007996, Avg batch loss: 0.0098, Avg batch acc: 0.9886
Train, Epoch: 9, Batch: 68, Step num: 12220, Learning rate: 0.00007996, Avg batch loss: 0.0092, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 69, Step num: 12221, Learning rate: 0.00007995, Avg batch loss: 0.0087, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 70, Step num: 12222, Learning rate: 0.00007995, Avg batch loss: 0.0082, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 71, Step num: 12223, Learning rate: 0.00007995, Avg batch loss: 0.0102, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 72, Step num: 12224, Learning rate: 0.00007994, Avg batch loss: 0.0115, Avg batch acc: 0.9898
Train, Epoch: 9, Batch: 73, Step num: 12225, Learning rate: 0.00007994, Avg batch loss: 0.0080, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 74, Step num: 12226, Learning rate: 0.00007994, Avg batch loss: 0.0089, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 75, Step num: 12227, Learning rate: 0.00007993, Avg batch loss: 0.0050, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 76, Step num: 12228, Learning rate: 0.00007993, Avg batch loss: 0.0080, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 77, Step num: 12229, Learning rate: 0.00007993, Avg batch loss: 0.0091, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 78, Step num: 12230, Learning rate: 0.00007992, Avg batch loss: 0.0072, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 79, Step num: 12231, Learning rate: 0.00007992, Avg batch loss: 0.0082, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 80, Step num: 12232, Learning rate: 0.00007992, Avg batch loss: 0.0071, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 81, Step num: 12233, Learning rate: 0.00007992, Avg batch loss: 0.0098, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 82, Step num: 12234, Learning rate: 0.00007991, Avg batch loss: 0.0107, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 83, Step num: 12235, Learning rate: 0.00007991, Avg batch loss: 0.0069, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 84, Step num: 12236, Learning rate: 0.00007991, Avg batch loss: 0.0055, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 85, Step num: 12237, Learning rate: 0.00007990, Avg batch loss: 0.0103, Avg batch acc: 0.9890
Train, Epoch: 9, Batch: 86, Step num: 12238, Learning rate: 0.00007990, Avg batch loss: 0.0083, Avg batch acc: 0.9893
Train, Epoch: 9, Batch: 87, Step num: 12239, Learning rate: 0.00007990, Avg batch loss: 0.0112, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 88, Step num: 12240, Learning rate: 0.00007989, Avg batch loss: 0.0088, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 89, Step num: 12241, Learning rate: 0.00007989, Avg batch loss: 0.0082, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 90, Step num: 12242, Learning rate: 0.00007989, Avg batch loss: 0.0109, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 91, Step num: 12243, Learning rate: 0.00007988, Avg batch loss: 0.0077, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 92, Step num: 12244, Learning rate: 0.00007988, Avg batch loss: 0.0111, Avg batch acc: 0.9894
Train, Epoch: 9, Batch: 93, Step num: 12245, Learning rate: 0.00007988, Avg batch loss: 0.0073, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 94, Step num: 12246, Learning rate: 0.00007987, Avg batch loss: 0.0085, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 95, Step num: 12247, Learning rate: 0.00007987, Avg batch loss: 0.0070, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 96, Step num: 12248, Learning rate: 0.00007987, Avg batch loss: 0.0095, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 97, Step num: 12249, Learning rate: 0.00007986, Avg batch loss: 0.0068, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 98, Step num: 12250, Learning rate: 0.00007986, Avg batch loss: 0.0086, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 99, Step num: 12251, Learning rate: 0.00007986, Avg batch loss: 0.0094, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 100, Step num: 12252, Learning rate: 0.00007985, Avg batch loss: 0.0101, Avg batch acc: 0.9889
Train, Epoch: 9, Batch: 101, Step num: 12253, Learning rate: 0.00007985, Avg batch loss: 0.0066, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 102, Step num: 12254, Learning rate: 0.00007985, Avg batch loss: 0.0092, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 103, Step num: 12255, Learning rate: 0.00007984, Avg batch loss: 0.0089, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 104, Step num: 12256, Learning rate: 0.00007984, Avg batch loss: 0.0097, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 105, Step num: 12257, Learning rate: 0.00007984, Avg batch loss: 0.0085, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 106, Step num: 12258, Learning rate: 0.00007983, Avg batch loss: 0.0102, Avg batch acc: 0.9878
Train, Epoch: 9, Batch: 107, Step num: 12259, Learning rate: 0.00007983, Avg batch loss: 0.0108, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 108, Step num: 12260, Learning rate: 0.00007983, Avg batch loss: 0.0115, Avg batch acc: 0.9878
Train, Epoch: 9, Batch: 109, Step num: 12261, Learning rate: 0.00007982, Avg batch loss: 0.0086, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 110, Step num: 12262, Learning rate: 0.00007982, Avg batch loss: 0.0114, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 111, Step num: 12263, Learning rate: 0.00007982, Avg batch loss: 0.0078, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 112, Step num: 12264, Learning rate: 0.00007981, Avg batch loss: 0.0093, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 113, Step num: 12265, Learning rate: 0.00007981, Avg batch loss: 0.0084, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 114, Step num: 12266, Learning rate: 0.00007981, Avg batch loss: 0.0091, Avg batch acc: 0.9893
Train, Epoch: 9, Batch: 115, Step num: 12267, Learning rate: 0.00007980, Avg batch loss: 0.0082, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 116, Step num: 12268, Learning rate: 0.00007980, Avg batch loss: 0.0098, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 117, Step num: 12269, Learning rate: 0.00007980, Avg batch loss: 0.0093, Avg batch acc: 0.9891
Train, Epoch: 9, Batch: 118, Step num: 12270, Learning rate: 0.00007979, Avg batch loss: 0.0076, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 119, Step num: 12271, Learning rate: 0.00007979, Avg batch loss: 0.0082, Avg batch acc: 0.9898
Train, Epoch: 9, Batch: 120, Step num: 12272, Learning rate: 0.00007979, Avg batch loss: 0.0075, Avg batch acc: 0.9893
Train, Epoch: 9, Batch: 121, Step num: 12273, Learning rate: 0.00007978, Avg batch loss: 0.0059, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 122, Step num: 12274, Learning rate: 0.00007978, Avg batch loss: 0.0112, Avg batch acc: 0.9875
Train, Epoch: 9, Batch: 123, Step num: 12275, Learning rate: 0.00007978, Avg batch loss: 0.0090, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 124, Step num: 12276, Learning rate: 0.00007977, Avg batch loss: 0.0100, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 125, Step num: 12277, Learning rate: 0.00007977, Avg batch loss: 0.0056, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 126, Step num: 12278, Learning rate: 0.00007977, Avg batch loss: 0.0100, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 127, Step num: 12279, Learning rate: 0.00007977, Avg batch loss: 0.0117, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 128, Step num: 12280, Learning rate: 0.00007976, Avg batch loss: 0.0087, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 129, Step num: 12281, Learning rate: 0.00007976, Avg batch loss: 0.0078, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 130, Step num: 12282, Learning rate: 0.00007976, Avg batch loss: 0.0090, Avg batch acc: 0.9890
Train, Epoch: 9, Batch: 131, Step num: 12283, Learning rate: 0.00007975, Avg batch loss: 0.0056, Avg batch acc: 0.9963
Train, Epoch: 9, Batch: 132, Step num: 12284, Learning rate: 0.00007975, Avg batch loss: 0.0098, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 133, Step num: 12285, Learning rate: 0.00007975, Avg batch loss: 0.0103, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 134, Step num: 12286, Learning rate: 0.00007974, Avg batch loss: 0.0102, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 135, Step num: 12287, Learning rate: 0.00007974, Avg batch loss: 0.0108, Avg batch acc: 0.9887
Train, Epoch: 9, Batch: 136, Step num: 12288, Learning rate: 0.00007974, Avg batch loss: 0.0070, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 137, Step num: 12289, Learning rate: 0.00007973, Avg batch loss: 0.0090, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 138, Step num: 12290, Learning rate: 0.00007973, Avg batch loss: 0.0103, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 139, Step num: 12291, Learning rate: 0.00007973, Avg batch loss: 0.0073, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 140, Step num: 12292, Learning rate: 0.00007972, Avg batch loss: 0.0082, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 141, Step num: 12293, Learning rate: 0.00007972, Avg batch loss: 0.0100, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 142, Step num: 12294, Learning rate: 0.00007972, Avg batch loss: 0.0082, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 143, Step num: 12295, Learning rate: 0.00007971, Avg batch loss: 0.0066, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 144, Step num: 12296, Learning rate: 0.00007971, Avg batch loss: 0.0091, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 145, Step num: 12297, Learning rate: 0.00007971, Avg batch loss: 0.0077, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 146, Step num: 12298, Learning rate: 0.00007970, Avg batch loss: 0.0080, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 147, Step num: 12299, Learning rate: 0.00007970, Avg batch loss: 0.0078, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 148, Step num: 12300, Learning rate: 0.00007970, Avg batch loss: 0.0073, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 149, Step num: 12301, Learning rate: 0.00007969, Avg batch loss: 0.0092, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 150, Step num: 12302, Learning rate: 0.00007969, Avg batch loss: 0.0096, Avg batch acc: 0.9875
Train, Epoch: 9, Batch: 151, Step num: 12303, Learning rate: 0.00007969, Avg batch loss: 0.0090, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 152, Step num: 12304, Learning rate: 0.00007968, Avg batch loss: 0.0084, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 153, Step num: 12305, Learning rate: 0.00007968, Avg batch loss: 0.0107, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 154, Step num: 12306, Learning rate: 0.00007968, Avg batch loss: 0.0075, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 155, Step num: 12307, Learning rate: 0.00007967, Avg batch loss: 0.0098, Avg batch acc: 0.9889
Train, Epoch: 9, Batch: 156, Step num: 12308, Learning rate: 0.00007967, Avg batch loss: 0.0070, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 157, Step num: 12309, Learning rate: 0.00007967, Avg batch loss: 0.0088, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 158, Step num: 12310, Learning rate: 0.00007966, Avg batch loss: 0.0114, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 159, Step num: 12311, Learning rate: 0.00007966, Avg batch loss: 0.0079, Avg batch acc: 0.9898
Train, Epoch: 9, Batch: 160, Step num: 12312, Learning rate: 0.00007966, Avg batch loss: 0.0086, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 161, Step num: 12313, Learning rate: 0.00007966, Avg batch loss: 0.0106, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 162, Step num: 12314, Learning rate: 0.00007965, Avg batch loss: 0.0066, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 163, Step num: 12315, Learning rate: 0.00007965, Avg batch loss: 0.0118, Avg batch acc: 0.9873
Train, Epoch: 9, Batch: 164, Step num: 12316, Learning rate: 0.00007965, Avg batch loss: 0.0098, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 165, Step num: 12317, Learning rate: 0.00007964, Avg batch loss: 0.0092, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 166, Step num: 12318, Learning rate: 0.00007964, Avg batch loss: 0.0073, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 167, Step num: 12319, Learning rate: 0.00007964, Avg batch loss: 0.0090, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 168, Step num: 12320, Learning rate: 0.00007963, Avg batch loss: 0.0090, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 169, Step num: 12321, Learning rate: 0.00007963, Avg batch loss: 0.0073, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 170, Step num: 12322, Learning rate: 0.00007963, Avg batch loss: 0.0082, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 171, Step num: 12323, Learning rate: 0.00007962, Avg batch loss: 0.0081, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 172, Step num: 12324, Learning rate: 0.00007962, Avg batch loss: 0.0081, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 173, Step num: 12325, Learning rate: 0.00007962, Avg batch loss: 0.0079, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 174, Step num: 12326, Learning rate: 0.00007961, Avg batch loss: 0.0095, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 175, Step num: 12327, Learning rate: 0.00007961, Avg batch loss: 0.0097, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 176, Step num: 12328, Learning rate: 0.00007961, Avg batch loss: 0.0115, Avg batch acc: 0.9878
Train, Epoch: 9, Batch: 177, Step num: 12329, Learning rate: 0.00007960, Avg batch loss: 0.0080, Avg batch acc: 0.9896
Train, Epoch: 9, Batch: 178, Step num: 12330, Learning rate: 0.00007960, Avg batch loss: 0.0080, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 179, Step num: 12331, Learning rate: 0.00007960, Avg batch loss: 0.0106, Avg batch acc: 0.9896
Train, Epoch: 9, Batch: 180, Step num: 12332, Learning rate: 0.00007959, Avg batch loss: 0.0086, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 181, Step num: 12333, Learning rate: 0.00007959, Avg batch loss: 0.0297, Avg batch acc: 0.9887
Train, Epoch: 9, Batch: 182, Step num: 12334, Learning rate: 0.00007959, Avg batch loss: 0.0128, Avg batch acc: 0.9868
Train, Epoch: 9, Batch: 183, Step num: 12335, Learning rate: 0.00007958, Avg batch loss: 0.0085, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 184, Step num: 12336, Learning rate: 0.00007958, Avg batch loss: 0.0090, Avg batch acc: 0.9894
Train, Epoch: 9, Batch: 185, Step num: 12337, Learning rate: 0.00007958, Avg batch loss: 0.0094, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 186, Step num: 12338, Learning rate: 0.00007957, Avg batch loss: 0.0100, Avg batch acc: 0.9896
Train, Epoch: 9, Batch: 187, Step num: 12339, Learning rate: 0.00007957, Avg batch loss: 0.0115, Avg batch acc: 0.9889
Train, Epoch: 9, Batch: 188, Step num: 12340, Learning rate: 0.00007957, Avg batch loss: 0.0081, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 189, Step num: 12341, Learning rate: 0.00007956, Avg batch loss: 0.0081, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 190, Step num: 12342, Learning rate: 0.00007956, Avg batch loss: 0.0096, Avg batch acc: 0.9891
Train, Epoch: 9, Batch: 191, Step num: 12343, Learning rate: 0.00007956, Avg batch loss: 0.0098, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 192, Step num: 12344, Learning rate: 0.00007955, Avg batch loss: 0.0068, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 193, Step num: 12345, Learning rate: 0.00007955, Avg batch loss: 0.0057, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 194, Step num: 12346, Learning rate: 0.00007955, Avg batch loss: 0.0065, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 195, Step num: 12347, Learning rate: 0.00007955, Avg batch loss: 0.0080, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 196, Step num: 12348, Learning rate: 0.00007954, Avg batch loss: 0.0062, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 197, Step num: 12349, Learning rate: 0.00007954, Avg batch loss: 0.0110, Avg batch acc: 0.9884
Train, Epoch: 9, Batch: 198, Step num: 12350, Learning rate: 0.00007954, Avg batch loss: 0.0096, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 199, Step num: 12351, Learning rate: 0.00007953, Avg batch loss: 0.0101, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 200, Step num: 12352, Learning rate: 0.00007953, Avg batch loss: 0.0085, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 201, Step num: 12353, Learning rate: 0.00007953, Avg batch loss: 0.0078, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 202, Step num: 12354, Learning rate: 0.00007952, Avg batch loss: 0.0077, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 203, Step num: 12355, Learning rate: 0.00007952, Avg batch loss: 0.0062, Avg batch acc: 0.9962
Train, Epoch: 9, Batch: 204, Step num: 12356, Learning rate: 0.00007952, Avg batch loss: 0.0109, Avg batch acc: 0.9882
Train, Epoch: 9, Batch: 205, Step num: 12357, Learning rate: 0.00007951, Avg batch loss: 0.0060, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 206, Step num: 12358, Learning rate: 0.00007951, Avg batch loss: 0.0127, Avg batch acc: 0.9835
Train, Epoch: 9, Batch: 207, Step num: 12359, Learning rate: 0.00007951, Avg batch loss: 0.0088, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 208, Step num: 12360, Learning rate: 0.00007950, Avg batch loss: 0.0080, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 209, Step num: 12361, Learning rate: 0.00007950, Avg batch loss: 0.0101, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 210, Step num: 12362, Learning rate: 0.00007950, Avg batch loss: 0.0074, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 211, Step num: 12363, Learning rate: 0.00007949, Avg batch loss: 0.0069, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 212, Step num: 12364, Learning rate: 0.00007949, Avg batch loss: 0.0078, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 213, Step num: 12365, Learning rate: 0.00007949, Avg batch loss: 0.0075, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 214, Step num: 12366, Learning rate: 0.00007948, Avg batch loss: 0.0165, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 215, Step num: 12367, Learning rate: 0.00007948, Avg batch loss: 0.0057, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 216, Step num: 12368, Learning rate: 0.00007948, Avg batch loss: 0.0075, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 217, Step num: 12369, Learning rate: 0.00007947, Avg batch loss: 0.0076, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 218, Step num: 12370, Learning rate: 0.00007947, Avg batch loss: 0.0066, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 219, Step num: 12371, Learning rate: 0.00007947, Avg batch loss: 0.0053, Avg batch acc: 0.9966
Train, Epoch: 9, Batch: 220, Step num: 12372, Learning rate: 0.00007946, Avg batch loss: 0.0108, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 221, Step num: 12373, Learning rate: 0.00007946, Avg batch loss: 0.0081, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 222, Step num: 12374, Learning rate: 0.00007946, Avg batch loss: 0.0087, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 223, Step num: 12375, Learning rate: 0.00007946, Avg batch loss: 0.0064, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 224, Step num: 12376, Learning rate: 0.00007945, Avg batch loss: 0.0077, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 225, Step num: 12377, Learning rate: 0.00007945, Avg batch loss: 0.0095, Avg batch acc: 0.9879
Train, Epoch: 9, Batch: 226, Step num: 12378, Learning rate: 0.00007945, Avg batch loss: 0.0082, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 227, Step num: 12379, Learning rate: 0.00007944, Avg batch loss: 0.0078, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 228, Step num: 12380, Learning rate: 0.00007944, Avg batch loss: 0.0061, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 229, Step num: 12381, Learning rate: 0.00007944, Avg batch loss: 0.0099, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 230, Step num: 12382, Learning rate: 0.00007943, Avg batch loss: 0.0069, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 231, Step num: 12383, Learning rate: 0.00007943, Avg batch loss: 0.0055, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 232, Step num: 12384, Learning rate: 0.00007943, Avg batch loss: 0.0101, Avg batch acc: 0.9893
Train, Epoch: 9, Batch: 233, Step num: 12385, Learning rate: 0.00007942, Avg batch loss: 0.0064, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 234, Step num: 12386, Learning rate: 0.00007942, Avg batch loss: 0.0065, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 235, Step num: 12387, Learning rate: 0.00007942, Avg batch loss: 0.0085, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 236, Step num: 12388, Learning rate: 0.00007941, Avg batch loss: 0.0073, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 237, Step num: 12389, Learning rate: 0.00007941, Avg batch loss: 0.0079, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 238, Step num: 12390, Learning rate: 0.00007941, Avg batch loss: 0.0093, Avg batch acc: 0.9898
Train, Epoch: 9, Batch: 239, Step num: 12391, Learning rate: 0.00007940, Avg batch loss: 0.0093, Avg batch acc: 0.9891
Train, Epoch: 9, Batch: 240, Step num: 12392, Learning rate: 0.00007940, Avg batch loss: 0.0087, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 241, Step num: 12393, Learning rate: 0.00007940, Avg batch loss: 0.0068, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 242, Step num: 12394, Learning rate: 0.00007939, Avg batch loss: 0.0082, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 243, Step num: 12395, Learning rate: 0.00007939, Avg batch loss: 0.0085, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 244, Step num: 12396, Learning rate: 0.00007939, Avg batch loss: 0.0107, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 245, Step num: 12397, Learning rate: 0.00007938, Avg batch loss: 0.0053, Avg batch acc: 0.9963
Train, Epoch: 9, Batch: 246, Step num: 12398, Learning rate: 0.00007938, Avg batch loss: 0.0092, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 247, Step num: 12399, Learning rate: 0.00007938, Avg batch loss: 0.0097, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 248, Step num: 12400, Learning rate: 0.00007938, Avg batch loss: 0.0089, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 249, Step num: 12401, Learning rate: 0.00007937, Avg batch loss: 0.0089, Avg batch acc: 0.9889
Train, Epoch: 9, Batch: 250, Step num: 12402, Learning rate: 0.00007937, Avg batch loss: 0.0062, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 251, Step num: 12403, Learning rate: 0.00007937, Avg batch loss: 0.0094, Avg batch acc: 0.9895
Train, Epoch: 9, Batch: 252, Step num: 12404, Learning rate: 0.00007936, Avg batch loss: 0.0077, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 253, Step num: 12405, Learning rate: 0.00007936, Avg batch loss: 0.0082, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 254, Step num: 12406, Learning rate: 0.00007936, Avg batch loss: 0.0071, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 255, Step num: 12407, Learning rate: 0.00007935, Avg batch loss: 0.0078, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 256, Step num: 12408, Learning rate: 0.00007935, Avg batch loss: 0.0087, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 257, Step num: 12409, Learning rate: 0.00007935, Avg batch loss: 0.0089, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 258, Step num: 12410, Learning rate: 0.00007934, Avg batch loss: 0.0064, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 259, Step num: 12411, Learning rate: 0.00007934, Avg batch loss: 0.0086, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 260, Step num: 12412, Learning rate: 0.00007934, Avg batch loss: 0.0074, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 261, Step num: 12413, Learning rate: 0.00007933, Avg batch loss: 0.0063, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 262, Step num: 12414, Learning rate: 0.00007933, Avg batch loss: 0.0076, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 263, Step num: 12415, Learning rate: 0.00007933, Avg batch loss: 0.0090, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 264, Step num: 12416, Learning rate: 0.00007932, Avg batch loss: 0.0080, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 265, Step num: 12417, Learning rate: 0.00007932, Avg batch loss: 0.0092, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 266, Step num: 12418, Learning rate: 0.00007932, Avg batch loss: 0.0071, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 267, Step num: 12419, Learning rate: 0.00007931, Avg batch loss: 0.0074, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 268, Step num: 12420, Learning rate: 0.00007931, Avg batch loss: 0.0061, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 269, Step num: 12421, Learning rate: 0.00007931, Avg batch loss: 0.0149, Avg batch acc: 0.9856
Train, Epoch: 9, Batch: 270, Step num: 12422, Learning rate: 0.00007930, Avg batch loss: 0.0073, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 271, Step num: 12423, Learning rate: 0.00007930, Avg batch loss: 0.0068, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 272, Step num: 12424, Learning rate: 0.00007930, Avg batch loss: 0.0094, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 273, Step num: 12425, Learning rate: 0.00007930, Avg batch loss: 0.0069, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 274, Step num: 12426, Learning rate: 0.00007929, Avg batch loss: 0.0104, Avg batch acc: 0.9890
Train, Epoch: 9, Batch: 275, Step num: 12427, Learning rate: 0.00007929, Avg batch loss: 0.0081, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 276, Step num: 12428, Learning rate: 0.00007929, Avg batch loss: 0.0088, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 277, Step num: 12429, Learning rate: 0.00007928, Avg batch loss: 0.0071, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 278, Step num: 12430, Learning rate: 0.00007928, Avg batch loss: 0.0079, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 279, Step num: 12431, Learning rate: 0.00007928, Avg batch loss: 0.0101, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 280, Step num: 12432, Learning rate: 0.00007927, Avg batch loss: 0.0067, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 281, Step num: 12433, Learning rate: 0.00007927, Avg batch loss: 0.0084, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 282, Step num: 12434, Learning rate: 0.00007927, Avg batch loss: 0.0085, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 283, Step num: 12435, Learning rate: 0.00007926, Avg batch loss: 0.0069, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 284, Step num: 12436, Learning rate: 0.00007926, Avg batch loss: 0.0086, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 285, Step num: 12437, Learning rate: 0.00007926, Avg batch loss: 0.0077, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 286, Step num: 12438, Learning rate: 0.00007925, Avg batch loss: 0.0083, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 287, Step num: 12439, Learning rate: 0.00007925, Avg batch loss: 0.0090, Avg batch acc: 0.9896
Train, Epoch: 9, Batch: 288, Step num: 12440, Learning rate: 0.00007925, Avg batch loss: 0.0103, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 289, Step num: 12441, Learning rate: 0.00007924, Avg batch loss: 0.0066, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 290, Step num: 12442, Learning rate: 0.00007924, Avg batch loss: 0.0099, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 291, Step num: 12443, Learning rate: 0.00007924, Avg batch loss: 0.0083, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 292, Step num: 12444, Learning rate: 0.00007923, Avg batch loss: 0.0118, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 293, Step num: 12445, Learning rate: 0.00007923, Avg batch loss: 0.0068, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 294, Step num: 12446, Learning rate: 0.00007923, Avg batch loss: 0.0096, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 295, Step num: 12447, Learning rate: 0.00007923, Avg batch loss: 0.0085, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 296, Step num: 12448, Learning rate: 0.00007922, Avg batch loss: 0.0086, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 297, Step num: 12449, Learning rate: 0.00007922, Avg batch loss: 0.0064, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 298, Step num: 12450, Learning rate: 0.00007922, Avg batch loss: 0.0272, Avg batch acc: 0.9867
Train, Epoch: 9, Batch: 299, Step num: 12451, Learning rate: 0.00007921, Avg batch loss: 0.0062, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 300, Step num: 12452, Learning rate: 0.00007921, Avg batch loss: 0.0115, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 301, Step num: 12453, Learning rate: 0.00007921, Avg batch loss: 0.0096, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 302, Step num: 12454, Learning rate: 0.00007920, Avg batch loss: 0.0087, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 303, Step num: 12455, Learning rate: 0.00007920, Avg batch loss: 0.0113, Avg batch acc: 0.9881
Train, Epoch: 9, Batch: 304, Step num: 12456, Learning rate: 0.00007920, Avg batch loss: 0.0079, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 305, Step num: 12457, Learning rate: 0.00007919, Avg batch loss: 0.0099, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 306, Step num: 12458, Learning rate: 0.00007919, Avg batch loss: 0.0085, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 307, Step num: 12459, Learning rate: 0.00007919, Avg batch loss: 0.0077, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 308, Step num: 12460, Learning rate: 0.00007918, Avg batch loss: 0.0065, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 309, Step num: 12461, Learning rate: 0.00007918, Avg batch loss: 0.0082, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 310, Step num: 12462, Learning rate: 0.00007918, Avg batch loss: 0.0108, Avg batch acc: 0.9887
Train, Epoch: 9, Batch: 311, Step num: 12463, Learning rate: 0.00007917, Avg batch loss: 0.0058, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 312, Step num: 12464, Learning rate: 0.00007917, Avg batch loss: 0.0098, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 313, Step num: 12465, Learning rate: 0.00007917, Avg batch loss: 0.0095, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 314, Step num: 12466, Learning rate: 0.00007916, Avg batch loss: 0.0081, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 315, Step num: 12467, Learning rate: 0.00007916, Avg batch loss: 0.0115, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 316, Step num: 12468, Learning rate: 0.00007916, Avg batch loss: 0.0093, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 317, Step num: 12469, Learning rate: 0.00007916, Avg batch loss: 0.0259, Avg batch acc: 0.9883
Train, Epoch: 9, Batch: 318, Step num: 12470, Learning rate: 0.00007915, Avg batch loss: 0.0108, Avg batch acc: 0.9875
Train, Epoch: 9, Batch: 319, Step num: 12471, Learning rate: 0.00007915, Avg batch loss: 0.0095, Avg batch acc: 0.9893
Train, Epoch: 9, Batch: 320, Step num: 12472, Learning rate: 0.00007915, Avg batch loss: 0.0122, Avg batch acc: 0.9877
Train, Epoch: 9, Batch: 321, Step num: 12473, Learning rate: 0.00007914, Avg batch loss: 0.0085, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 322, Step num: 12474, Learning rate: 0.00007914, Avg batch loss: 0.0057, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 323, Step num: 12475, Learning rate: 0.00007914, Avg batch loss: 0.0073, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 324, Step num: 12476, Learning rate: 0.00007913, Avg batch loss: 0.0108, Avg batch acc: 0.9873
Train, Epoch: 9, Batch: 325, Step num: 12477, Learning rate: 0.00007913, Avg batch loss: 0.0097, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 326, Step num: 12478, Learning rate: 0.00007913, Avg batch loss: 0.0079, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 327, Step num: 12479, Learning rate: 0.00007912, Avg batch loss: 0.0079, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 328, Step num: 12480, Learning rate: 0.00007912, Avg batch loss: 0.0098, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 329, Step num: 12481, Learning rate: 0.00007912, Avg batch loss: 0.0136, Avg batch acc: 0.9881
Train, Epoch: 9, Batch: 330, Step num: 12482, Learning rate: 0.00007911, Avg batch loss: 0.0094, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 331, Step num: 12483, Learning rate: 0.00007911, Avg batch loss: 0.0090, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 332, Step num: 12484, Learning rate: 0.00007911, Avg batch loss: 0.0115, Avg batch acc: 0.9889
Train, Epoch: 9, Batch: 333, Step num: 12485, Learning rate: 0.00007910, Avg batch loss: 0.0096, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 334, Step num: 12486, Learning rate: 0.00007910, Avg batch loss: 0.0092, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 335, Step num: 12487, Learning rate: 0.00007910, Avg batch loss: 0.0098, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 336, Step num: 12488, Learning rate: 0.00007909, Avg batch loss: 0.0099, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 337, Step num: 12489, Learning rate: 0.00007909, Avg batch loss: 0.0082, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 338, Step num: 12490, Learning rate: 0.00007909, Avg batch loss: 0.0086, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 339, Step num: 12491, Learning rate: 0.00007909, Avg batch loss: 0.0083, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 340, Step num: 12492, Learning rate: 0.00007908, Avg batch loss: 0.0087, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 341, Step num: 12493, Learning rate: 0.00007908, Avg batch loss: 0.0094, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 342, Step num: 12494, Learning rate: 0.00007908, Avg batch loss: 0.0072, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 343, Step num: 12495, Learning rate: 0.00007907, Avg batch loss: 0.0067, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 344, Step num: 12496, Learning rate: 0.00007907, Avg batch loss: 0.0082, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 345, Step num: 12497, Learning rate: 0.00007907, Avg batch loss: 0.0088, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 346, Step num: 12498, Learning rate: 0.00007906, Avg batch loss: 0.0100, Avg batch acc: 0.9885
Train, Epoch: 9, Batch: 347, Step num: 12499, Learning rate: 0.00007906, Avg batch loss: 0.0089, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 348, Step num: 12500, Learning rate: 0.00007906, Avg batch loss: 0.0057, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 349, Step num: 12501, Learning rate: 0.00007905, Avg batch loss: 0.0096, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 350, Step num: 12502, Learning rate: 0.00007905, Avg batch loss: 0.0100, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 351, Step num: 12503, Learning rate: 0.00007905, Avg batch loss: 0.0096, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 352, Step num: 12504, Learning rate: 0.00007904, Avg batch loss: 0.0068, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 353, Step num: 12505, Learning rate: 0.00007904, Avg batch loss: 0.0089, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 354, Step num: 12506, Learning rate: 0.00007904, Avg batch loss: 0.0071, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 355, Step num: 12507, Learning rate: 0.00007903, Avg batch loss: 0.0063, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 356, Step num: 12508, Learning rate: 0.00007903, Avg batch loss: 0.0073, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 357, Step num: 12509, Learning rate: 0.00007903, Avg batch loss: 0.0085, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 358, Step num: 12510, Learning rate: 0.00007903, Avg batch loss: 0.0087, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 359, Step num: 12511, Learning rate: 0.00007902, Avg batch loss: 0.0077, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 360, Step num: 12512, Learning rate: 0.00007902, Avg batch loss: 0.0089, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 361, Step num: 12513, Learning rate: 0.00007902, Avg batch loss: 0.0075, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 362, Step num: 12514, Learning rate: 0.00007901, Avg batch loss: 0.0060, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 363, Step num: 12515, Learning rate: 0.00007901, Avg batch loss: 0.0066, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 364, Step num: 12516, Learning rate: 0.00007901, Avg batch loss: 0.0089, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 365, Step num: 12517, Learning rate: 0.00007900, Avg batch loss: 0.0068, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 366, Step num: 12518, Learning rate: 0.00007900, Avg batch loss: 0.0062, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 367, Step num: 12519, Learning rate: 0.00007900, Avg batch loss: 0.0101, Avg batch acc: 0.9896
Train, Epoch: 9, Batch: 368, Step num: 12520, Learning rate: 0.00007899, Avg batch loss: 0.0074, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 369, Step num: 12521, Learning rate: 0.00007899, Avg batch loss: 0.0111, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 370, Step num: 12522, Learning rate: 0.00007899, Avg batch loss: 0.0107, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 371, Step num: 12523, Learning rate: 0.00007898, Avg batch loss: 0.0078, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 372, Step num: 12524, Learning rate: 0.00007898, Avg batch loss: 0.0092, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 373, Step num: 12525, Learning rate: 0.00007898, Avg batch loss: 0.0095, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 374, Step num: 12526, Learning rate: 0.00007897, Avg batch loss: 0.0076, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 375, Step num: 12527, Learning rate: 0.00007897, Avg batch loss: 0.0095, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 376, Step num: 12528, Learning rate: 0.00007897, Avg batch loss: 0.0072, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 377, Step num: 12529, Learning rate: 0.00007897, Avg batch loss: 0.0089, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 378, Step num: 12530, Learning rate: 0.00007896, Avg batch loss: 0.0095, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 379, Step num: 12531, Learning rate: 0.00007896, Avg batch loss: 0.0081, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 380, Step num: 12532, Learning rate: 0.00007896, Avg batch loss: 0.0062, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 381, Step num: 12533, Learning rate: 0.00007895, Avg batch loss: 0.0080, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 382, Step num: 12534, Learning rate: 0.00007895, Avg batch loss: 0.0081, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 383, Step num: 12535, Learning rate: 0.00007895, Avg batch loss: 0.0117, Avg batch acc: 0.9886
Train, Epoch: 9, Batch: 384, Step num: 12536, Learning rate: 0.00007894, Avg batch loss: 0.0100, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 385, Step num: 12537, Learning rate: 0.00007894, Avg batch loss: 0.0086, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 386, Step num: 12538, Learning rate: 0.00007894, Avg batch loss: 0.0111, Avg batch acc: 0.9886
Train, Epoch: 9, Batch: 387, Step num: 12539, Learning rate: 0.00007893, Avg batch loss: 0.0088, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 388, Step num: 12540, Learning rate: 0.00007893, Avg batch loss: 0.0088, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 389, Step num: 12541, Learning rate: 0.00007893, Avg batch loss: 0.0066, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 390, Step num: 12542, Learning rate: 0.00007892, Avg batch loss: 0.0060, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 391, Step num: 12543, Learning rate: 0.00007892, Avg batch loss: 0.0078, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 392, Step num: 12544, Learning rate: 0.00007892, Avg batch loss: 0.0081, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 393, Step num: 12545, Learning rate: 0.00007892, Avg batch loss: 0.0076, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 394, Step num: 12546, Learning rate: 0.00007891, Avg batch loss: 0.0091, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 395, Step num: 12547, Learning rate: 0.00007891, Avg batch loss: 0.0088, Avg batch acc: 0.9885
Train, Epoch: 9, Batch: 396, Step num: 12548, Learning rate: 0.00007891, Avg batch loss: 0.0093, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 397, Step num: 12549, Learning rate: 0.00007890, Avg batch loss: 0.0074, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 398, Step num: 12550, Learning rate: 0.00007890, Avg batch loss: 0.0070, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 399, Step num: 12551, Learning rate: 0.00007890, Avg batch loss: 0.0063, Avg batch acc: 0.9959
Train, Epoch: 9, Batch: 400, Step num: 12552, Learning rate: 0.00007889, Avg batch loss: 0.0077, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 401, Step num: 12553, Learning rate: 0.00007889, Avg batch loss: 0.0079, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 402, Step num: 12554, Learning rate: 0.00007889, Avg batch loss: 0.0077, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 403, Step num: 12555, Learning rate: 0.00007888, Avg batch loss: 0.0069, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 404, Step num: 12556, Learning rate: 0.00007888, Avg batch loss: 0.0080, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 405, Step num: 12557, Learning rate: 0.00007888, Avg batch loss: 0.0087, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 406, Step num: 12558, Learning rate: 0.00007887, Avg batch loss: 0.0097, Avg batch acc: 0.9873
Train, Epoch: 9, Batch: 407, Step num: 12559, Learning rate: 0.00007887, Avg batch loss: 0.0083, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 408, Step num: 12560, Learning rate: 0.00007887, Avg batch loss: 0.0091, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 409, Step num: 12561, Learning rate: 0.00007886, Avg batch loss: 0.0071, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 410, Step num: 12562, Learning rate: 0.00007886, Avg batch loss: 0.0086, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 411, Step num: 12563, Learning rate: 0.00007886, Avg batch loss: 0.0094, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 412, Step num: 12564, Learning rate: 0.00007886, Avg batch loss: 0.0054, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 413, Step num: 12565, Learning rate: 0.00007885, Avg batch loss: 0.0076, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 414, Step num: 12566, Learning rate: 0.00007885, Avg batch loss: 0.0066, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 415, Step num: 12567, Learning rate: 0.00007885, Avg batch loss: 0.0098, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 416, Step num: 12568, Learning rate: 0.00007884, Avg batch loss: 0.0094, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 417, Step num: 12569, Learning rate: 0.00007884, Avg batch loss: 0.0082, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 418, Step num: 12570, Learning rate: 0.00007884, Avg batch loss: 0.0075, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 419, Step num: 12571, Learning rate: 0.00007883, Avg batch loss: 0.0079, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 420, Step num: 12572, Learning rate: 0.00007883, Avg batch loss: 0.0080, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 421, Step num: 12573, Learning rate: 0.00007883, Avg batch loss: 0.0068, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 422, Step num: 12574, Learning rate: 0.00007882, Avg batch loss: 0.0130, Avg batch acc: 0.9872
Train, Epoch: 9, Batch: 423, Step num: 12575, Learning rate: 0.00007882, Avg batch loss: 0.0084, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 424, Step num: 12576, Learning rate: 0.00007882, Avg batch loss: 0.0069, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 425, Step num: 12577, Learning rate: 0.00007881, Avg batch loss: 0.0080, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 426, Step num: 12578, Learning rate: 0.00007881, Avg batch loss: 0.0079, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 427, Step num: 12579, Learning rate: 0.00007881, Avg batch loss: 0.0053, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 428, Step num: 12580, Learning rate: 0.00007881, Avg batch loss: 0.0073, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 429, Step num: 12581, Learning rate: 0.00007880, Avg batch loss: 0.0062, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 430, Step num: 12582, Learning rate: 0.00007880, Avg batch loss: 0.0073, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 431, Step num: 12583, Learning rate: 0.00007880, Avg batch loss: 0.0081, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 432, Step num: 12584, Learning rate: 0.00007879, Avg batch loss: 0.0060, Avg batch acc: 0.9954
Train, Epoch: 9, Batch: 433, Step num: 12585, Learning rate: 0.00007879, Avg batch loss: 0.0079, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 434, Step num: 12586, Learning rate: 0.00007879, Avg batch loss: 0.0094, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 435, Step num: 12587, Learning rate: 0.00007878, Avg batch loss: 0.0076, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 436, Step num: 12588, Learning rate: 0.00007878, Avg batch loss: 0.0073, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 437, Step num: 12589, Learning rate: 0.00007878, Avg batch loss: 0.0080, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 438, Step num: 12590, Learning rate: 0.00007877, Avg batch loss: 0.0113, Avg batch acc: 0.9879
Train, Epoch: 9, Batch: 439, Step num: 12591, Learning rate: 0.00007877, Avg batch loss: 0.0065, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 440, Step num: 12592, Learning rate: 0.00007877, Avg batch loss: 0.0095, Avg batch acc: 0.9895
Train, Epoch: 9, Batch: 441, Step num: 12593, Learning rate: 0.00007876, Avg batch loss: 0.0102, Avg batch acc: 0.9898
Train, Epoch: 9, Batch: 442, Step num: 12594, Learning rate: 0.00007876, Avg batch loss: 0.0090, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 443, Step num: 12595, Learning rate: 0.00007876, Avg batch loss: 0.0054, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 444, Step num: 12596, Learning rate: 0.00007876, Avg batch loss: 0.0085, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 445, Step num: 12597, Learning rate: 0.00007875, Avg batch loss: 0.0088, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 446, Step num: 12598, Learning rate: 0.00007875, Avg batch loss: 0.0064, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 447, Step num: 12599, Learning rate: 0.00007875, Avg batch loss: 0.0101, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 448, Step num: 12600, Learning rate: 0.00007874, Avg batch loss: 0.0110, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 449, Step num: 12601, Learning rate: 0.00007874, Avg batch loss: 0.0067, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 450, Step num: 12602, Learning rate: 0.00007874, Avg batch loss: 0.0070, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 451, Step num: 12603, Learning rate: 0.00007873, Avg batch loss: 0.0066, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 452, Step num: 12604, Learning rate: 0.00007873, Avg batch loss: 0.0076, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 453, Step num: 12605, Learning rate: 0.00007873, Avg batch loss: 0.0071, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 454, Step num: 12606, Learning rate: 0.00007872, Avg batch loss: 0.0076, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 455, Step num: 12607, Learning rate: 0.00007872, Avg batch loss: 0.0081, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 456, Step num: 12608, Learning rate: 0.00007872, Avg batch loss: 0.0092, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 457, Step num: 12609, Learning rate: 0.00007871, Avg batch loss: 0.0095, Avg batch acc: 0.9889
Train, Epoch: 9, Batch: 458, Step num: 12610, Learning rate: 0.00007871, Avg batch loss: 0.0088, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 459, Step num: 12611, Learning rate: 0.00007871, Avg batch loss: 0.0096, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 460, Step num: 12612, Learning rate: 0.00007871, Avg batch loss: 0.0085, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 461, Step num: 12613, Learning rate: 0.00007870, Avg batch loss: 0.0097, Avg batch acc: 0.9893
Train, Epoch: 9, Batch: 462, Step num: 12614, Learning rate: 0.00007870, Avg batch loss: 0.0070, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 463, Step num: 12615, Learning rate: 0.00007870, Avg batch loss: 0.0117, Avg batch acc: 0.9882
Train, Epoch: 9, Batch: 464, Step num: 12616, Learning rate: 0.00007869, Avg batch loss: 0.0061, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 465, Step num: 12617, Learning rate: 0.00007869, Avg batch loss: 0.0080, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 466, Step num: 12618, Learning rate: 0.00007869, Avg batch loss: 0.0111, Avg batch acc: 0.9876
Train, Epoch: 9, Batch: 467, Step num: 12619, Learning rate: 0.00007868, Avg batch loss: 0.0092, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 468, Step num: 12620, Learning rate: 0.00007868, Avg batch loss: 0.0093, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 469, Step num: 12621, Learning rate: 0.00007868, Avg batch loss: 0.0262, Avg batch acc: 0.9856
Train, Epoch: 9, Batch: 470, Step num: 12622, Learning rate: 0.00007867, Avg batch loss: 0.0089, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 471, Step num: 12623, Learning rate: 0.00007867, Avg batch loss: 0.0097, Avg batch acc: 0.9881
Train, Epoch: 9, Batch: 472, Step num: 12624, Learning rate: 0.00007867, Avg batch loss: 0.0090, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 473, Step num: 12625, Learning rate: 0.00007866, Avg batch loss: 0.0086, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 474, Step num: 12626, Learning rate: 0.00007866, Avg batch loss: 0.0101, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 475, Step num: 12627, Learning rate: 0.00007866, Avg batch loss: 0.0064, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 476, Step num: 12628, Learning rate: 0.00007866, Avg batch loss: 0.0095, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 477, Step num: 12629, Learning rate: 0.00007865, Avg batch loss: 0.0088, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 478, Step num: 12630, Learning rate: 0.00007865, Avg batch loss: 0.0497, Avg batch acc: 0.9829
Train, Epoch: 9, Batch: 479, Step num: 12631, Learning rate: 0.00007865, Avg batch loss: 0.0095, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 480, Step num: 12632, Learning rate: 0.00007864, Avg batch loss: 0.0096, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 481, Step num: 12633, Learning rate: 0.00007864, Avg batch loss: 0.0089, Avg batch acc: 0.9890
Train, Epoch: 9, Batch: 482, Step num: 12634, Learning rate: 0.00007864, Avg batch loss: 0.0065, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 483, Step num: 12635, Learning rate: 0.00007863, Avg batch loss: 0.0089, Avg batch acc: 0.9884
Train, Epoch: 9, Batch: 484, Step num: 12636, Learning rate: 0.00007863, Avg batch loss: 0.0086, Avg batch acc: 0.9882
Train, Epoch: 9, Batch: 485, Step num: 12637, Learning rate: 0.00007863, Avg batch loss: 0.0220, Avg batch acc: 0.9882
Train, Epoch: 9, Batch: 486, Step num: 12638, Learning rate: 0.00007862, Avg batch loss: 0.0068, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 487, Step num: 12639, Learning rate: 0.00007862, Avg batch loss: 0.0182, Avg batch acc: 0.9877
Train, Epoch: 9, Batch: 488, Step num: 12640, Learning rate: 0.00007862, Avg batch loss: 0.0077, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 489, Step num: 12641, Learning rate: 0.00007861, Avg batch loss: 0.0064, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 490, Step num: 12642, Learning rate: 0.00007861, Avg batch loss: 0.0067, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 491, Step num: 12643, Learning rate: 0.00007861, Avg batch loss: 0.0098, Avg batch acc: 0.9896
Train, Epoch: 9, Batch: 492, Step num: 12644, Learning rate: 0.00007861, Avg batch loss: 0.0099, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 493, Step num: 12645, Learning rate: 0.00007860, Avg batch loss: 0.0049, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 494, Step num: 12646, Learning rate: 0.00007860, Avg batch loss: 0.0083, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 495, Step num: 12647, Learning rate: 0.00007860, Avg batch loss: 0.0112, Avg batch acc: 0.9882
Train, Epoch: 9, Batch: 496, Step num: 12648, Learning rate: 0.00007859, Avg batch loss: 0.0060, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 497, Step num: 12649, Learning rate: 0.00007859, Avg batch loss: 0.0083, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 498, Step num: 12650, Learning rate: 0.00007859, Avg batch loss: 0.0085, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 499, Step num: 12651, Learning rate: 0.00007858, Avg batch loss: 0.0152, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 500, Step num: 12652, Learning rate: 0.00007858, Avg batch loss: 0.0097, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 501, Step num: 12653, Learning rate: 0.00007858, Avg batch loss: 0.0079, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 502, Step num: 12654, Learning rate: 0.00007857, Avg batch loss: 0.0073, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 503, Step num: 12655, Learning rate: 0.00007857, Avg batch loss: 0.0071, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 504, Step num: 12656, Learning rate: 0.00007857, Avg batch loss: 0.0141, Avg batch acc: 0.9877
Train, Epoch: 9, Batch: 505, Step num: 12657, Learning rate: 0.00007857, Avg batch loss: 0.0092, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 506, Step num: 12658, Learning rate: 0.00007856, Avg batch loss: 0.0081, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 507, Step num: 12659, Learning rate: 0.00007856, Avg batch loss: 0.0085, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 508, Step num: 12660, Learning rate: 0.00007856, Avg batch loss: 0.0069, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 509, Step num: 12661, Learning rate: 0.00007855, Avg batch loss: 0.0103, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 510, Step num: 12662, Learning rate: 0.00007855, Avg batch loss: 0.0105, Avg batch acc: 0.9867
Train, Epoch: 9, Batch: 511, Step num: 12663, Learning rate: 0.00007855, Avg batch loss: 0.0083, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 512, Step num: 12664, Learning rate: 0.00007854, Avg batch loss: 0.0088, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 513, Step num: 12665, Learning rate: 0.00007854, Avg batch loss: 0.0084, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 514, Step num: 12666, Learning rate: 0.00007854, Avg batch loss: 0.0071, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 515, Step num: 12667, Learning rate: 0.00007853, Avg batch loss: 0.0077, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 516, Step num: 12668, Learning rate: 0.00007853, Avg batch loss: 0.0079, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 517, Step num: 12669, Learning rate: 0.00007853, Avg batch loss: 0.0125, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 518, Step num: 12670, Learning rate: 0.00007852, Avg batch loss: 0.0067, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 519, Step num: 12671, Learning rate: 0.00007852, Avg batch loss: 0.0092, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 520, Step num: 12672, Learning rate: 0.00007852, Avg batch loss: 0.0068, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 521, Step num: 12673, Learning rate: 0.00007852, Avg batch loss: 0.0072, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 522, Step num: 12674, Learning rate: 0.00007851, Avg batch loss: 0.0090, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 523, Step num: 12675, Learning rate: 0.00007851, Avg batch loss: 0.0079, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 524, Step num: 12676, Learning rate: 0.00007851, Avg batch loss: 0.0077, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 525, Step num: 12677, Learning rate: 0.00007850, Avg batch loss: 0.0072, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 526, Step num: 12678, Learning rate: 0.00007850, Avg batch loss: 0.0083, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 527, Step num: 12679, Learning rate: 0.00007850, Avg batch loss: 0.0091, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 528, Step num: 12680, Learning rate: 0.00007849, Avg batch loss: 0.0070, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 529, Step num: 12681, Learning rate: 0.00007849, Avg batch loss: 0.0101, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 530, Step num: 12682, Learning rate: 0.00007849, Avg batch loss: 0.0095, Avg batch acc: 0.9894
Train, Epoch: 9, Batch: 531, Step num: 12683, Learning rate: 0.00007848, Avg batch loss: 0.0083, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 532, Step num: 12684, Learning rate: 0.00007848, Avg batch loss: 0.0078, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 533, Step num: 12685, Learning rate: 0.00007848, Avg batch loss: 0.0067, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 534, Step num: 12686, Learning rate: 0.00007848, Avg batch loss: 0.0053, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 535, Step num: 12687, Learning rate: 0.00007847, Avg batch loss: 0.0058, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 536, Step num: 12688, Learning rate: 0.00007847, Avg batch loss: 0.0088, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 537, Step num: 12689, Learning rate: 0.00007847, Avg batch loss: 0.0072, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 538, Step num: 12690, Learning rate: 0.00007846, Avg batch loss: 0.0091, Avg batch acc: 0.9886
Train, Epoch: 9, Batch: 539, Step num: 12691, Learning rate: 0.00007846, Avg batch loss: 0.0096, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 540, Step num: 12692, Learning rate: 0.00007846, Avg batch loss: 0.0069, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 541, Step num: 12693, Learning rate: 0.00007845, Avg batch loss: 0.0086, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 542, Step num: 12694, Learning rate: 0.00007845, Avg batch loss: 0.0078, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 543, Step num: 12695, Learning rate: 0.00007845, Avg batch loss: 0.0074, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 544, Step num: 12696, Learning rate: 0.00007844, Avg batch loss: 0.0070, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 545, Step num: 12697, Learning rate: 0.00007844, Avg batch loss: 0.0081, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 546, Step num: 12698, Learning rate: 0.00007844, Avg batch loss: 0.0084, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 547, Step num: 12699, Learning rate: 0.00007844, Avg batch loss: 0.0077, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 548, Step num: 12700, Learning rate: 0.00007843, Avg batch loss: 0.0093, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 549, Step num: 12701, Learning rate: 0.00007843, Avg batch loss: 0.0072, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 550, Step num: 12702, Learning rate: 0.00007843, Avg batch loss: 0.0078, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 551, Step num: 12703, Learning rate: 0.00007842, Avg batch loss: 0.0077, Avg batch acc: 0.9896
Train, Epoch: 9, Batch: 552, Step num: 12704, Learning rate: 0.00007842, Avg batch loss: 0.0056, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 553, Step num: 12705, Learning rate: 0.00007842, Avg batch loss: 0.0058, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 554, Step num: 12706, Learning rate: 0.00007841, Avg batch loss: 0.0064, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 555, Step num: 12707, Learning rate: 0.00007841, Avg batch loss: 0.0085, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 556, Step num: 12708, Learning rate: 0.00007841, Avg batch loss: 0.0083, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 557, Step num: 12709, Learning rate: 0.00007840, Avg batch loss: 0.0072, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 558, Step num: 12710, Learning rate: 0.00007840, Avg batch loss: 0.0076, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 559, Step num: 12711, Learning rate: 0.00007840, Avg batch loss: 0.0085, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 560, Step num: 12712, Learning rate: 0.00007839, Avg batch loss: 0.0086, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 561, Step num: 12713, Learning rate: 0.00007839, Avg batch loss: 0.0097, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 562, Step num: 12714, Learning rate: 0.00007839, Avg batch loss: 0.0058, Avg batch acc: 0.9964
Train, Epoch: 9, Batch: 563, Step num: 12715, Learning rate: 0.00007839, Avg batch loss: 0.0078, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 564, Step num: 12716, Learning rate: 0.00007838, Avg batch loss: 0.0091, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 565, Step num: 12717, Learning rate: 0.00007838, Avg batch loss: 0.0065, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 566, Step num: 12718, Learning rate: 0.00007838, Avg batch loss: 0.0074, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 567, Step num: 12719, Learning rate: 0.00007837, Avg batch loss: 0.0046, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 568, Step num: 12720, Learning rate: 0.00007837, Avg batch loss: 0.0088, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 569, Step num: 12721, Learning rate: 0.00007837, Avg batch loss: 0.0072, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 570, Step num: 12722, Learning rate: 0.00007836, Avg batch loss: 0.0071, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 571, Step num: 12723, Learning rate: 0.00007836, Avg batch loss: 0.0060, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 572, Step num: 12724, Learning rate: 0.00007836, Avg batch loss: 0.0061, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 573, Step num: 12725, Learning rate: 0.00007835, Avg batch loss: 0.0074, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 574, Step num: 12726, Learning rate: 0.00007835, Avg batch loss: 0.0090, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 575, Step num: 12727, Learning rate: 0.00007835, Avg batch loss: 0.0066, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 576, Step num: 12728, Learning rate: 0.00007835, Avg batch loss: 0.0068, Avg batch acc: 0.9959
Train, Epoch: 9, Batch: 577, Step num: 12729, Learning rate: 0.00007834, Avg batch loss: 0.0072, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 578, Step num: 12730, Learning rate: 0.00007834, Avg batch loss: 0.0068, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 579, Step num: 12731, Learning rate: 0.00007834, Avg batch loss: 0.0070, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 580, Step num: 12732, Learning rate: 0.00007833, Avg batch loss: 0.0057, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 581, Step num: 12733, Learning rate: 0.00007833, Avg batch loss: 0.0064, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 582, Step num: 12734, Learning rate: 0.00007833, Avg batch loss: 0.0076, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 583, Step num: 12735, Learning rate: 0.00007832, Avg batch loss: 0.0079, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 584, Step num: 12736, Learning rate: 0.00007832, Avg batch loss: 0.0090, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 585, Step num: 12737, Learning rate: 0.00007832, Avg batch loss: 0.0074, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 586, Step num: 12738, Learning rate: 0.00007831, Avg batch loss: 0.0076, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 587, Step num: 12739, Learning rate: 0.00007831, Avg batch loss: 0.0097, Avg batch acc: 0.9859
Train, Epoch: 9, Batch: 588, Step num: 12740, Learning rate: 0.00007831, Avg batch loss: 0.0087, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 589, Step num: 12741, Learning rate: 0.00007831, Avg batch loss: 0.0269, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 590, Step num: 12742, Learning rate: 0.00007830, Avg batch loss: 0.0080, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 591, Step num: 12743, Learning rate: 0.00007830, Avg batch loss: 0.0087, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 592, Step num: 12744, Learning rate: 0.00007830, Avg batch loss: 0.0065, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 593, Step num: 12745, Learning rate: 0.00007829, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 594, Step num: 12746, Learning rate: 0.00007829, Avg batch loss: 0.0067, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 595, Step num: 12747, Learning rate: 0.00007829, Avg batch loss: 0.0068, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 596, Step num: 12748, Learning rate: 0.00007828, Avg batch loss: 0.0060, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 597, Step num: 12749, Learning rate: 0.00007828, Avg batch loss: 0.0106, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 598, Step num: 12750, Learning rate: 0.00007828, Avg batch loss: 0.0052, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 599, Step num: 12751, Learning rate: 0.00007827, Avg batch loss: 0.0085, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 600, Step num: 12752, Learning rate: 0.00007827, Avg batch loss: 0.0054, Avg batch acc: 0.9967
Train, Epoch: 9, Batch: 601, Step num: 12753, Learning rate: 0.00007827, Avg batch loss: 0.0071, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 602, Step num: 12754, Learning rate: 0.00007827, Avg batch loss: 0.0079, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 603, Step num: 12755, Learning rate: 0.00007826, Avg batch loss: 0.0088, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 604, Step num: 12756, Learning rate: 0.00007826, Avg batch loss: 0.0060, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 605, Step num: 12757, Learning rate: 0.00007826, Avg batch loss: 0.0097, Avg batch acc: 0.9881
Train, Epoch: 9, Batch: 606, Step num: 12758, Learning rate: 0.00007825, Avg batch loss: 0.0071, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 607, Step num: 12759, Learning rate: 0.00007825, Avg batch loss: 0.0071, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 608, Step num: 12760, Learning rate: 0.00007825, Avg batch loss: 0.0075, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 609, Step num: 12761, Learning rate: 0.00007824, Avg batch loss: 0.0078, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 610, Step num: 12762, Learning rate: 0.00007824, Avg batch loss: 0.0081, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 611, Step num: 12763, Learning rate: 0.00007824, Avg batch loss: 0.0090, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 612, Step num: 12764, Learning rate: 0.00007824, Avg batch loss: 0.0072, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 613, Step num: 12765, Learning rate: 0.00007823, Avg batch loss: 0.0107, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 614, Step num: 12766, Learning rate: 0.00007823, Avg batch loss: 0.0080, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 615, Step num: 12767, Learning rate: 0.00007823, Avg batch loss: 0.0084, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 616, Step num: 12768, Learning rate: 0.00007822, Avg batch loss: 0.0069, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 617, Step num: 12769, Learning rate: 0.00007822, Avg batch loss: 0.0085, Avg batch acc: 0.9955
Train, Epoch: 9, Batch: 618, Step num: 12770, Learning rate: 0.00007822, Avg batch loss: 0.0080, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 619, Step num: 12771, Learning rate: 0.00007821, Avg batch loss: 0.0126, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 620, Step num: 12772, Learning rate: 0.00007821, Avg batch loss: 0.0073, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 621, Step num: 12773, Learning rate: 0.00007821, Avg batch loss: 0.0121, Avg batch acc: 0.9863
Train, Epoch: 9, Batch: 622, Step num: 12774, Learning rate: 0.00007820, Avg batch loss: 0.0062, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 623, Step num: 12775, Learning rate: 0.00007820, Avg batch loss: 0.0048, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 624, Step num: 12776, Learning rate: 0.00007820, Avg batch loss: 0.0064, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 625, Step num: 12777, Learning rate: 0.00007820, Avg batch loss: 0.0076, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 626, Step num: 12778, Learning rate: 0.00007819, Avg batch loss: 0.0094, Avg batch acc: 0.9890
Train, Epoch: 9, Batch: 627, Step num: 12779, Learning rate: 0.00007819, Avg batch loss: 0.0093, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 628, Step num: 12780, Learning rate: 0.00007819, Avg batch loss: 0.0063, Avg batch acc: 0.9955
Train, Epoch: 9, Batch: 629, Step num: 12781, Learning rate: 0.00007818, Avg batch loss: 0.0064, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 630, Step num: 12782, Learning rate: 0.00007818, Avg batch loss: 0.0079, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 631, Step num: 12783, Learning rate: 0.00007818, Avg batch loss: 0.0104, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 632, Step num: 12784, Learning rate: 0.00007817, Avg batch loss: 0.0094, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 633, Step num: 12785, Learning rate: 0.00007817, Avg batch loss: 0.0082, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 634, Step num: 12786, Learning rate: 0.00007817, Avg batch loss: 0.0088, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 635, Step num: 12787, Learning rate: 0.00007816, Avg batch loss: 0.0086, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 636, Step num: 12788, Learning rate: 0.00007816, Avg batch loss: 0.0081, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 637, Step num: 12789, Learning rate: 0.00007816, Avg batch loss: 0.0085, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 638, Step num: 12790, Learning rate: 0.00007816, Avg batch loss: 0.0165, Avg batch acc: 0.9856
Train, Epoch: 9, Batch: 639, Step num: 12791, Learning rate: 0.00007815, Avg batch loss: 0.0103, Avg batch acc: 0.9896
Train, Epoch: 9, Batch: 640, Step num: 12792, Learning rate: 0.00007815, Avg batch loss: 0.0068, Avg batch acc: 0.9955
Train, Epoch: 9, Batch: 641, Step num: 12793, Learning rate: 0.00007815, Avg batch loss: 0.0102, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 642, Step num: 12794, Learning rate: 0.00007814, Avg batch loss: 0.0069, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 643, Step num: 12795, Learning rate: 0.00007814, Avg batch loss: 0.0067, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 644, Step num: 12796, Learning rate: 0.00007814, Avg batch loss: 0.0087, Avg batch acc: 0.9891
Train, Epoch: 9, Batch: 645, Step num: 12797, Learning rate: 0.00007813, Avg batch loss: 0.0106, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 646, Step num: 12798, Learning rate: 0.00007813, Avg batch loss: 0.0107, Avg batch acc: 0.9890
Train, Epoch: 9, Batch: 647, Step num: 12799, Learning rate: 0.00007813, Avg batch loss: 0.0102, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 648, Step num: 12800, Learning rate: 0.00007813, Avg batch loss: 0.0076, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 649, Step num: 12801, Learning rate: 0.00007812, Avg batch loss: 0.0115, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 650, Step num: 12802, Learning rate: 0.00007812, Avg batch loss: 0.0072, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 651, Step num: 12803, Learning rate: 0.00007812, Avg batch loss: 0.0076, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 652, Step num: 12804, Learning rate: 0.00007811, Avg batch loss: 0.0092, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 653, Step num: 12805, Learning rate: 0.00007811, Avg batch loss: 0.0073, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 654, Step num: 12806, Learning rate: 0.00007811, Avg batch loss: 0.0092, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 655, Step num: 12807, Learning rate: 0.00007810, Avg batch loss: 0.0107, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 656, Step num: 12808, Learning rate: 0.00007810, Avg batch loss: 0.0092, Avg batch acc: 0.9891
Train, Epoch: 9, Batch: 657, Step num: 12809, Learning rate: 0.00007810, Avg batch loss: 0.0070, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 658, Step num: 12810, Learning rate: 0.00007809, Avg batch loss: 0.0074, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 659, Step num: 12811, Learning rate: 0.00007809, Avg batch loss: 0.0082, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 660, Step num: 12812, Learning rate: 0.00007809, Avg batch loss: 0.0091, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 661, Step num: 12813, Learning rate: 0.00007809, Avg batch loss: 0.0110, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 662, Step num: 12814, Learning rate: 0.00007808, Avg batch loss: 0.0069, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 663, Step num: 12815, Learning rate: 0.00007808, Avg batch loss: 0.0090, Avg batch acc: 0.9890
Train, Epoch: 9, Batch: 664, Step num: 12816, Learning rate: 0.00007808, Avg batch loss: 0.0099, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 665, Step num: 12817, Learning rate: 0.00007807, Avg batch loss: 0.0081, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 666, Step num: 12818, Learning rate: 0.00007807, Avg batch loss: 0.0091, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 667, Step num: 12819, Learning rate: 0.00007807, Avg batch loss: 0.0079, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 668, Step num: 12820, Learning rate: 0.00007806, Avg batch loss: 0.0078, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 669, Step num: 12821, Learning rate: 0.00007806, Avg batch loss: 0.0063, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 670, Step num: 12822, Learning rate: 0.00007806, Avg batch loss: 0.0065, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 671, Step num: 12823, Learning rate: 0.00007805, Avg batch loss: 0.0077, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 672, Step num: 12824, Learning rate: 0.00007805, Avg batch loss: 0.0080, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 673, Step num: 12825, Learning rate: 0.00007805, Avg batch loss: 0.0095, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 674, Step num: 12826, Learning rate: 0.00007805, Avg batch loss: 0.0082, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 675, Step num: 12827, Learning rate: 0.00007804, Avg batch loss: 0.0076, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 676, Step num: 12828, Learning rate: 0.00007804, Avg batch loss: 0.0070, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 677, Step num: 12829, Learning rate: 0.00007804, Avg batch loss: 0.0108, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 678, Step num: 12830, Learning rate: 0.00007803, Avg batch loss: 0.0081, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 679, Step num: 12831, Learning rate: 0.00007803, Avg batch loss: 0.0128, Avg batch acc: 0.9881
Train, Epoch: 9, Batch: 680, Step num: 12832, Learning rate: 0.00007803, Avg batch loss: 0.0076, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 681, Step num: 12833, Learning rate: 0.00007802, Avg batch loss: 0.0056, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 682, Step num: 12834, Learning rate: 0.00007802, Avg batch loss: 0.0076, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 683, Step num: 12835, Learning rate: 0.00007802, Avg batch loss: 0.0086, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 684, Step num: 12836, Learning rate: 0.00007802, Avg batch loss: 0.0073, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 685, Step num: 12837, Learning rate: 0.00007801, Avg batch loss: 0.0063, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 686, Step num: 12838, Learning rate: 0.00007801, Avg batch loss: 0.0067, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 687, Step num: 12839, Learning rate: 0.00007801, Avg batch loss: 0.0069, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 688, Step num: 12840, Learning rate: 0.00007800, Avg batch loss: 0.0072, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 689, Step num: 12841, Learning rate: 0.00007800, Avg batch loss: 0.0068, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 690, Step num: 12842, Learning rate: 0.00007800, Avg batch loss: 0.0075, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 691, Step num: 12843, Learning rate: 0.00007799, Avg batch loss: 0.0081, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 692, Step num: 12844, Learning rate: 0.00007799, Avg batch loss: 0.0066, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 693, Step num: 12845, Learning rate: 0.00007799, Avg batch loss: 0.0116, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 694, Step num: 12846, Learning rate: 0.00007798, Avg batch loss: 0.0083, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 695, Step num: 12847, Learning rate: 0.00007798, Avg batch loss: 0.0068, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 696, Step num: 12848, Learning rate: 0.00007798, Avg batch loss: 0.0074, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 697, Step num: 12849, Learning rate: 0.00007798, Avg batch loss: 0.0075, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 698, Step num: 12850, Learning rate: 0.00007797, Avg batch loss: 0.0060, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 699, Step num: 12851, Learning rate: 0.00007797, Avg batch loss: 0.0067, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 700, Step num: 12852, Learning rate: 0.00007797, Avg batch loss: 0.0080, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 701, Step num: 12853, Learning rate: 0.00007796, Avg batch loss: 0.0072, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 702, Step num: 12854, Learning rate: 0.00007796, Avg batch loss: 0.0077, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 703, Step num: 12855, Learning rate: 0.00007796, Avg batch loss: 0.0077, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 704, Step num: 12856, Learning rate: 0.00007795, Avg batch loss: 0.0070, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 705, Step num: 12857, Learning rate: 0.00007795, Avg batch loss: 0.0085, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 706, Step num: 12858, Learning rate: 0.00007795, Avg batch loss: 0.0080, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 707, Step num: 12859, Learning rate: 0.00007795, Avg batch loss: 0.0064, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 708, Step num: 12860, Learning rate: 0.00007794, Avg batch loss: 0.0067, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 709, Step num: 12861, Learning rate: 0.00007794, Avg batch loss: 0.0095, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 710, Step num: 12862, Learning rate: 0.00007794, Avg batch loss: 0.0051, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 711, Step num: 12863, Learning rate: 0.00007793, Avg batch loss: 0.0107, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 712, Step num: 12864, Learning rate: 0.00007793, Avg batch loss: 0.0145, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 713, Step num: 12865, Learning rate: 0.00007793, Avg batch loss: 0.0092, Avg batch acc: 0.9890
Train, Epoch: 9, Batch: 714, Step num: 12866, Learning rate: 0.00007792, Avg batch loss: 0.0088, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 715, Step num: 12867, Learning rate: 0.00007792, Avg batch loss: 0.0066, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 716, Step num: 12868, Learning rate: 0.00007792, Avg batch loss: 0.0067, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 717, Step num: 12869, Learning rate: 0.00007792, Avg batch loss: 0.0075, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 718, Step num: 12870, Learning rate: 0.00007791, Avg batch loss: 0.0101, Avg batch acc: 0.9891
Train, Epoch: 9, Batch: 719, Step num: 12871, Learning rate: 0.00007791, Avg batch loss: 0.0074, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 720, Step num: 12872, Learning rate: 0.00007791, Avg batch loss: 0.0068, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 721, Step num: 12873, Learning rate: 0.00007790, Avg batch loss: 0.0083, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 722, Step num: 12874, Learning rate: 0.00007790, Avg batch loss: 0.0078, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 723, Step num: 12875, Learning rate: 0.00007790, Avg batch loss: 0.0092, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 724, Step num: 12876, Learning rate: 0.00007789, Avg batch loss: 0.0094, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 725, Step num: 12877, Learning rate: 0.00007789, Avg batch loss: 0.0087, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 726, Step num: 12878, Learning rate: 0.00007789, Avg batch loss: 0.0072, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 727, Step num: 12879, Learning rate: 0.00007789, Avg batch loss: 0.0076, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 728, Step num: 12880, Learning rate: 0.00007788, Avg batch loss: 0.0070, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 729, Step num: 12881, Learning rate: 0.00007788, Avg batch loss: 0.0071, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 730, Step num: 12882, Learning rate: 0.00007788, Avg batch loss: 0.0071, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 731, Step num: 12883, Learning rate: 0.00007787, Avg batch loss: 0.0070, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 732, Step num: 12884, Learning rate: 0.00007787, Avg batch loss: 0.0078, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 733, Step num: 12885, Learning rate: 0.00007787, Avg batch loss: 0.0050, Avg batch acc: 0.9967
Train, Epoch: 9, Batch: 734, Step num: 12886, Learning rate: 0.00007786, Avg batch loss: 0.0078, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 735, Step num: 12887, Learning rate: 0.00007786, Avg batch loss: 0.0081, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 736, Step num: 12888, Learning rate: 0.00007786, Avg batch loss: 0.0085, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 737, Step num: 12889, Learning rate: 0.00007785, Avg batch loss: 0.0070, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 738, Step num: 12890, Learning rate: 0.00007785, Avg batch loss: 0.0085, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 739, Step num: 12891, Learning rate: 0.00007785, Avg batch loss: 0.0117, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 740, Step num: 12892, Learning rate: 0.00007785, Avg batch loss: 0.0077, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 741, Step num: 12893, Learning rate: 0.00007784, Avg batch loss: 0.0069, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 742, Step num: 12894, Learning rate: 0.00007784, Avg batch loss: 0.0085, Avg batch acc: 0.9870
Train, Epoch: 9, Batch: 743, Step num: 12895, Learning rate: 0.00007784, Avg batch loss: 0.0066, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 744, Step num: 12896, Learning rate: 0.00007783, Avg batch loss: 0.0090, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 745, Step num: 12897, Learning rate: 0.00007783, Avg batch loss: 0.0073, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 746, Step num: 12898, Learning rate: 0.00007783, Avg batch loss: 0.0085, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 747, Step num: 12899, Learning rate: 0.00007782, Avg batch loss: 0.0080, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 748, Step num: 12900, Learning rate: 0.00007782, Avg batch loss: 0.0077, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 749, Step num: 12901, Learning rate: 0.00007782, Avg batch loss: 0.0055, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 750, Step num: 12902, Learning rate: 0.00007782, Avg batch loss: 0.0076, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 751, Step num: 12903, Learning rate: 0.00007781, Avg batch loss: 0.0057, Avg batch acc: 0.9954
Train, Epoch: 9, Batch: 752, Step num: 12904, Learning rate: 0.00007781, Avg batch loss: 0.0088, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 753, Step num: 12905, Learning rate: 0.00007781, Avg batch loss: 0.0074, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 754, Step num: 12906, Learning rate: 0.00007780, Avg batch loss: 0.0057, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 755, Step num: 12907, Learning rate: 0.00007780, Avg batch loss: 0.0089, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 756, Step num: 12908, Learning rate: 0.00007780, Avg batch loss: 0.0072, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 757, Step num: 12909, Learning rate: 0.00007779, Avg batch loss: 0.0083, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 758, Step num: 12910, Learning rate: 0.00007779, Avg batch loss: 0.0080, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 759, Step num: 12911, Learning rate: 0.00007779, Avg batch loss: 0.0067, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 760, Step num: 12912, Learning rate: 0.00007779, Avg batch loss: 0.0082, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 761, Step num: 12913, Learning rate: 0.00007778, Avg batch loss: 0.0070, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 762, Step num: 12914, Learning rate: 0.00007778, Avg batch loss: 0.0052, Avg batch acc: 0.9955
Train, Epoch: 9, Batch: 763, Step num: 12915, Learning rate: 0.00007778, Avg batch loss: 0.0056, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 764, Step num: 12916, Learning rate: 0.00007777, Avg batch loss: 0.0086, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 765, Step num: 12917, Learning rate: 0.00007777, Avg batch loss: 0.0073, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 766, Step num: 12918, Learning rate: 0.00007777, Avg batch loss: 0.0113, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 767, Step num: 12919, Learning rate: 0.00007776, Avg batch loss: 0.0070, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 768, Step num: 12920, Learning rate: 0.00007776, Avg batch loss: 0.0074, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 769, Step num: 12921, Learning rate: 0.00007776, Avg batch loss: 0.0086, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 770, Step num: 12922, Learning rate: 0.00007776, Avg batch loss: 0.0077, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 771, Step num: 12923, Learning rate: 0.00007775, Avg batch loss: 0.0050, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 772, Step num: 12924, Learning rate: 0.00007775, Avg batch loss: 0.0078, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 773, Step num: 12925, Learning rate: 0.00007775, Avg batch loss: 0.0085, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 774, Step num: 12926, Learning rate: 0.00007774, Avg batch loss: 0.0065, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 775, Step num: 12927, Learning rate: 0.00007774, Avg batch loss: 0.0058, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 776, Step num: 12928, Learning rate: 0.00007774, Avg batch loss: 0.0046, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 777, Step num: 12929, Learning rate: 0.00007773, Avg batch loss: 0.0079, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 778, Step num: 12930, Learning rate: 0.00007773, Avg batch loss: 0.0064, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 779, Step num: 12931, Learning rate: 0.00007773, Avg batch loss: 0.0073, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 780, Step num: 12932, Learning rate: 0.00007773, Avg batch loss: 0.0055, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 781, Step num: 12933, Learning rate: 0.00007772, Avg batch loss: 0.0069, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 782, Step num: 12934, Learning rate: 0.00007772, Avg batch loss: 0.0071, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 783, Step num: 12935, Learning rate: 0.00007772, Avg batch loss: 0.0074, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 784, Step num: 12936, Learning rate: 0.00007771, Avg batch loss: 0.0071, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 785, Step num: 12937, Learning rate: 0.00007771, Avg batch loss: 0.0071, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 786, Step num: 12938, Learning rate: 0.00007771, Avg batch loss: 0.0071, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 787, Step num: 12939, Learning rate: 0.00007770, Avg batch loss: 0.0058, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 788, Step num: 12940, Learning rate: 0.00007770, Avg batch loss: 0.0100, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 789, Step num: 12941, Learning rate: 0.00007770, Avg batch loss: 0.0051, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 790, Step num: 12942, Learning rate: 0.00007770, Avg batch loss: 0.0049, Avg batch acc: 0.9965
Train, Epoch: 9, Batch: 791, Step num: 12943, Learning rate: 0.00007769, Avg batch loss: 0.0074, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 792, Step num: 12944, Learning rate: 0.00007769, Avg batch loss: 0.0065, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 793, Step num: 12945, Learning rate: 0.00007769, Avg batch loss: 0.0090, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 794, Step num: 12946, Learning rate: 0.00007768, Avg batch loss: 0.0067, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 795, Step num: 12947, Learning rate: 0.00007768, Avg batch loss: 0.0071, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 796, Step num: 12948, Learning rate: 0.00007768, Avg batch loss: 0.0081, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 797, Step num: 12949, Learning rate: 0.00007767, Avg batch loss: 0.0068, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 798, Step num: 12950, Learning rate: 0.00007767, Avg batch loss: 0.0089, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 799, Step num: 12951, Learning rate: 0.00007767, Avg batch loss: 0.0084, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 800, Step num: 12952, Learning rate: 0.00007767, Avg batch loss: 0.0062, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 801, Step num: 12953, Learning rate: 0.00007766, Avg batch loss: 0.0093, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 802, Step num: 12954, Learning rate: 0.00007766, Avg batch loss: 0.0082, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 803, Step num: 12955, Learning rate: 0.00007766, Avg batch loss: 0.0062, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 804, Step num: 12956, Learning rate: 0.00007765, Avg batch loss: 0.0101, Avg batch acc: 0.9873
Train, Epoch: 9, Batch: 805, Step num: 12957, Learning rate: 0.00007765, Avg batch loss: 0.0047, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 806, Step num: 12958, Learning rate: 0.00007765, Avg batch loss: 0.0072, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 807, Step num: 12959, Learning rate: 0.00007764, Avg batch loss: 0.0077, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 808, Step num: 12960, Learning rate: 0.00007764, Avg batch loss: 0.0107, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 809, Step num: 12961, Learning rate: 0.00007764, Avg batch loss: 0.0070, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 810, Step num: 12962, Learning rate: 0.00007764, Avg batch loss: 0.0076, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 811, Step num: 12963, Learning rate: 0.00007763, Avg batch loss: 0.0083, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 812, Step num: 12964, Learning rate: 0.00007763, Avg batch loss: 0.0116, Avg batch acc: 0.9877
Train, Epoch: 9, Batch: 813, Step num: 12965, Learning rate: 0.00007763, Avg batch loss: 0.0080, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 814, Step num: 12966, Learning rate: 0.00007762, Avg batch loss: 0.0092, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 815, Step num: 12967, Learning rate: 0.00007762, Avg batch loss: 0.0056, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 816, Step num: 12968, Learning rate: 0.00007762, Avg batch loss: 0.0111, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 817, Step num: 12969, Learning rate: 0.00007761, Avg batch loss: 0.0069, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 818, Step num: 12970, Learning rate: 0.00007761, Avg batch loss: 0.0082, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 819, Step num: 12971, Learning rate: 0.00007761, Avg batch loss: 0.0092, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 820, Step num: 12972, Learning rate: 0.00007761, Avg batch loss: 0.0082, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 821, Step num: 12973, Learning rate: 0.00007760, Avg batch loss: 0.0066, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 822, Step num: 12974, Learning rate: 0.00007760, Avg batch loss: 0.0071, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 823, Step num: 12975, Learning rate: 0.00007760, Avg batch loss: 0.0083, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 824, Step num: 12976, Learning rate: 0.00007759, Avg batch loss: 0.0082, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 825, Step num: 12977, Learning rate: 0.00007759, Avg batch loss: 0.0066, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 826, Step num: 12978, Learning rate: 0.00007759, Avg batch loss: 0.0069, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 827, Step num: 12979, Learning rate: 0.00007758, Avg batch loss: 0.0095, Avg batch acc: 0.9883
Train, Epoch: 9, Batch: 828, Step num: 12980, Learning rate: 0.00007758, Avg batch loss: 0.0070, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 829, Step num: 12981, Learning rate: 0.00007758, Avg batch loss: 0.0088, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 830, Step num: 12982, Learning rate: 0.00007758, Avg batch loss: 0.0059, Avg batch acc: 0.9963
Train, Epoch: 9, Batch: 831, Step num: 12983, Learning rate: 0.00007757, Avg batch loss: 0.0059, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 832, Step num: 12984, Learning rate: 0.00007757, Avg batch loss: 0.0037, Avg batch acc: 0.9978
Train, Epoch: 9, Batch: 833, Step num: 12985, Learning rate: 0.00007757, Avg batch loss: 0.0066, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 834, Step num: 12986, Learning rate: 0.00007756, Avg batch loss: 0.0080, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 835, Step num: 12987, Learning rate: 0.00007756, Avg batch loss: 0.0116, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 836, Step num: 12988, Learning rate: 0.00007756, Avg batch loss: 0.0074, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 837, Step num: 12989, Learning rate: 0.00007755, Avg batch loss: 0.0082, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 838, Step num: 12990, Learning rate: 0.00007755, Avg batch loss: 0.0080, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 839, Step num: 12991, Learning rate: 0.00007755, Avg batch loss: 0.0081, Avg batch acc: 0.9891
Train, Epoch: 9, Batch: 840, Step num: 12992, Learning rate: 0.00007755, Avg batch loss: 0.0077, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 841, Step num: 12993, Learning rate: 0.00007754, Avg batch loss: 0.0060, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 842, Step num: 12994, Learning rate: 0.00007754, Avg batch loss: 0.0073, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 843, Step num: 12995, Learning rate: 0.00007754, Avg batch loss: 0.0099, Avg batch acc: 0.9886
Train, Epoch: 9, Batch: 844, Step num: 12996, Learning rate: 0.00007753, Avg batch loss: 0.0058, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 845, Step num: 12997, Learning rate: 0.00007753, Avg batch loss: 0.0085, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 846, Step num: 12998, Learning rate: 0.00007753, Avg batch loss: 0.0077, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 847, Step num: 12999, Learning rate: 0.00007752, Avg batch loss: 0.0093, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 848, Step num: 13000, Learning rate: 0.00007752, Avg batch loss: 0.0064, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 849, Step num: 13001, Learning rate: 0.00007752, Avg batch loss: 0.0057, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 850, Step num: 13002, Learning rate: 0.00007752, Avg batch loss: 0.0091, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 851, Step num: 13003, Learning rate: 0.00007751, Avg batch loss: 0.0127, Avg batch acc: 0.9891
Train, Epoch: 9, Batch: 852, Step num: 13004, Learning rate: 0.00007751, Avg batch loss: 0.0077, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 853, Step num: 13005, Learning rate: 0.00007751, Avg batch loss: 0.0055, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 854, Step num: 13006, Learning rate: 0.00007750, Avg batch loss: 0.0070, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 855, Step num: 13007, Learning rate: 0.00007750, Avg batch loss: 0.0070, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 856, Step num: 13008, Learning rate: 0.00007750, Avg batch loss: 0.0065, Avg batch acc: 0.9955
Train, Epoch: 9, Batch: 857, Step num: 13009, Learning rate: 0.00007749, Avg batch loss: 0.0078, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 858, Step num: 13010, Learning rate: 0.00007749, Avg batch loss: 0.0062, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 859, Step num: 13011, Learning rate: 0.00007749, Avg batch loss: 0.0078, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 860, Step num: 13012, Learning rate: 0.00007749, Avg batch loss: 0.0071, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 861, Step num: 13013, Learning rate: 0.00007748, Avg batch loss: 0.0064, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 862, Step num: 13014, Learning rate: 0.00007748, Avg batch loss: 0.0082, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 863, Step num: 13015, Learning rate: 0.00007748, Avg batch loss: 0.0055, Avg batch acc: 0.9960
Train, Epoch: 9, Batch: 864, Step num: 13016, Learning rate: 0.00007747, Avg batch loss: 0.0177, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 865, Step num: 13017, Learning rate: 0.00007747, Avg batch loss: 0.0117, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 866, Step num: 13018, Learning rate: 0.00007747, Avg batch loss: 0.0098, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 867, Step num: 13019, Learning rate: 0.00007747, Avg batch loss: 0.0082, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 868, Step num: 13020, Learning rate: 0.00007746, Avg batch loss: 0.0078, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 869, Step num: 13021, Learning rate: 0.00007746, Avg batch loss: 0.0080, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 870, Step num: 13022, Learning rate: 0.00007746, Avg batch loss: 0.0072, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 871, Step num: 13023, Learning rate: 0.00007745, Avg batch loss: 0.0093, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 872, Step num: 13024, Learning rate: 0.00007745, Avg batch loss: 0.0109, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 873, Step num: 13025, Learning rate: 0.00007745, Avg batch loss: 0.0077, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 874, Step num: 13026, Learning rate: 0.00007744, Avg batch loss: 0.0084, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 875, Step num: 13027, Learning rate: 0.00007744, Avg batch loss: 0.0084, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 876, Step num: 13028, Learning rate: 0.00007744, Avg batch loss: 0.0070, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 877, Step num: 13029, Learning rate: 0.00007744, Avg batch loss: 0.0112, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 878, Step num: 13030, Learning rate: 0.00007743, Avg batch loss: 0.0185, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 879, Step num: 13031, Learning rate: 0.00007743, Avg batch loss: 0.0075, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 880, Step num: 13032, Learning rate: 0.00007743, Avg batch loss: 0.0079, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 881, Step num: 13033, Learning rate: 0.00007742, Avg batch loss: 0.0089, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 882, Step num: 13034, Learning rate: 0.00007742, Avg batch loss: 0.0099, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 883, Step num: 13035, Learning rate: 0.00007742, Avg batch loss: 0.0078, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 884, Step num: 13036, Learning rate: 0.00007741, Avg batch loss: 0.0119, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 885, Step num: 13037, Learning rate: 0.00007741, Avg batch loss: 0.0076, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 886, Step num: 13038, Learning rate: 0.00007741, Avg batch loss: 0.0070, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 887, Step num: 13039, Learning rate: 0.00007741, Avg batch loss: 0.0098, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 888, Step num: 13040, Learning rate: 0.00007740, Avg batch loss: 0.0065, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 889, Step num: 13041, Learning rate: 0.00007740, Avg batch loss: 0.0094, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 890, Step num: 13042, Learning rate: 0.00007740, Avg batch loss: 0.0121, Avg batch acc: 0.9895
Train, Epoch: 9, Batch: 891, Step num: 13043, Learning rate: 0.00007739, Avg batch loss: 0.0096, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 892, Step num: 13044, Learning rate: 0.00007739, Avg batch loss: 0.0150, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 893, Step num: 13045, Learning rate: 0.00007739, Avg batch loss: 0.0098, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 894, Step num: 13046, Learning rate: 0.00007738, Avg batch loss: 0.0083, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 895, Step num: 13047, Learning rate: 0.00007738, Avg batch loss: 0.0088, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 896, Step num: 13048, Learning rate: 0.00007738, Avg batch loss: 0.0061, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 897, Step num: 13049, Learning rate: 0.00007738, Avg batch loss: 0.0080, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 898, Step num: 13050, Learning rate: 0.00007737, Avg batch loss: 0.0067, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 899, Step num: 13051, Learning rate: 0.00007737, Avg batch loss: 0.0097, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 900, Step num: 13052, Learning rate: 0.00007737, Avg batch loss: 0.0080, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 901, Step num: 13053, Learning rate: 0.00007736, Avg batch loss: 0.0070, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 902, Step num: 13054, Learning rate: 0.00007736, Avg batch loss: 0.0073, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 903, Step num: 13055, Learning rate: 0.00007736, Avg batch loss: 0.0071, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 904, Step num: 13056, Learning rate: 0.00007736, Avg batch loss: 0.0086, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 905, Step num: 13057, Learning rate: 0.00007735, Avg batch loss: 0.0081, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 906, Step num: 13058, Learning rate: 0.00007735, Avg batch loss: 0.0077, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 907, Step num: 13059, Learning rate: 0.00007735, Avg batch loss: 0.0149, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 908, Step num: 13060, Learning rate: 0.00007734, Avg batch loss: 0.0065, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 909, Step num: 13061, Learning rate: 0.00007734, Avg batch loss: 0.0075, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 910, Step num: 13062, Learning rate: 0.00007734, Avg batch loss: 0.0102, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 911, Step num: 13063, Learning rate: 0.00007733, Avg batch loss: 0.0072, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 912, Step num: 13064, Learning rate: 0.00007733, Avg batch loss: 0.0082, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 913, Step num: 13065, Learning rate: 0.00007733, Avg batch loss: 0.0093, Avg batch acc: 0.9893
Train, Epoch: 9, Batch: 914, Step num: 13066, Learning rate: 0.00007733, Avg batch loss: 0.0048, Avg batch acc: 0.9961
Train, Epoch: 9, Batch: 915, Step num: 13067, Learning rate: 0.00007732, Avg batch loss: 0.0089, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 916, Step num: 13068, Learning rate: 0.00007732, Avg batch loss: 0.0064, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 917, Step num: 13069, Learning rate: 0.00007732, Avg batch loss: 0.0069, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 918, Step num: 13070, Learning rate: 0.00007731, Avg batch loss: 0.0065, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 919, Step num: 13071, Learning rate: 0.00007731, Avg batch loss: 0.0263, Avg batch acc: 0.9882
Train, Epoch: 9, Batch: 920, Step num: 13072, Learning rate: 0.00007731, Avg batch loss: 0.0089, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 921, Step num: 13073, Learning rate: 0.00007730, Avg batch loss: 0.0060, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 922, Step num: 13074, Learning rate: 0.00007730, Avg batch loss: 0.0091, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 923, Step num: 13075, Learning rate: 0.00007730, Avg batch loss: 0.0055, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 924, Step num: 13076, Learning rate: 0.00007730, Avg batch loss: 0.0081, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 925, Step num: 13077, Learning rate: 0.00007729, Avg batch loss: 0.0097, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 926, Step num: 13078, Learning rate: 0.00007729, Avg batch loss: 0.0091, Avg batch acc: 0.9894
Train, Epoch: 9, Batch: 927, Step num: 13079, Learning rate: 0.00007729, Avg batch loss: 0.0099, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 928, Step num: 13080, Learning rate: 0.00007728, Avg batch loss: 0.0075, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 929, Step num: 13081, Learning rate: 0.00007728, Avg batch loss: 0.0111, Avg batch acc: 0.9870
Train, Epoch: 9, Batch: 930, Step num: 13082, Learning rate: 0.00007728, Avg batch loss: 0.0064, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 931, Step num: 13083, Learning rate: 0.00007728, Avg batch loss: 0.0073, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 932, Step num: 13084, Learning rate: 0.00007727, Avg batch loss: 0.0089, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 933, Step num: 13085, Learning rate: 0.00007727, Avg batch loss: 0.0078, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 934, Step num: 13086, Learning rate: 0.00007727, Avg batch loss: 0.0061, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 935, Step num: 13087, Learning rate: 0.00007726, Avg batch loss: 0.0081, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 936, Step num: 13088, Learning rate: 0.00007726, Avg batch loss: 0.0089, Avg batch acc: 0.9884
Train, Epoch: 9, Batch: 937, Step num: 13089, Learning rate: 0.00007726, Avg batch loss: 0.0087, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 938, Step num: 13090, Learning rate: 0.00007725, Avg batch loss: 0.0075, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 939, Step num: 13091, Learning rate: 0.00007725, Avg batch loss: 0.0071, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 940, Step num: 13092, Learning rate: 0.00007725, Avg batch loss: 0.0097, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 941, Step num: 13093, Learning rate: 0.00007725, Avg batch loss: 0.0086, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 942, Step num: 13094, Learning rate: 0.00007724, Avg batch loss: 0.0091, Avg batch acc: 0.9894
Train, Epoch: 9, Batch: 943, Step num: 13095, Learning rate: 0.00007724, Avg batch loss: 0.0068, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 944, Step num: 13096, Learning rate: 0.00007724, Avg batch loss: 0.0077, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 945, Step num: 13097, Learning rate: 0.00007723, Avg batch loss: 0.0066, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 946, Step num: 13098, Learning rate: 0.00007723, Avg batch loss: 0.0094, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 947, Step num: 13099, Learning rate: 0.00007723, Avg batch loss: 0.0053, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 948, Step num: 13100, Learning rate: 0.00007723, Avg batch loss: 0.0066, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 949, Step num: 13101, Learning rate: 0.00007722, Avg batch loss: 0.0058, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 950, Step num: 13102, Learning rate: 0.00007722, Avg batch loss: 0.0069, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 951, Step num: 13103, Learning rate: 0.00007722, Avg batch loss: 0.0057, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 952, Step num: 13104, Learning rate: 0.00007721, Avg batch loss: 0.0071, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 953, Step num: 13105, Learning rate: 0.00007721, Avg batch loss: 0.0071, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 954, Step num: 13106, Learning rate: 0.00007721, Avg batch loss: 0.0072, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 955, Step num: 13107, Learning rate: 0.00007720, Avg batch loss: 0.0209, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 956, Step num: 13108, Learning rate: 0.00007720, Avg batch loss: 0.0042, Avg batch acc: 0.9967
Train, Epoch: 9, Batch: 957, Step num: 13109, Learning rate: 0.00007720, Avg batch loss: 0.0050, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 958, Step num: 13110, Learning rate: 0.00007720, Avg batch loss: 0.0092, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 959, Step num: 13111, Learning rate: 0.00007719, Avg batch loss: 0.0056, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 960, Step num: 13112, Learning rate: 0.00007719, Avg batch loss: 0.0067, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 961, Step num: 13113, Learning rate: 0.00007719, Avg batch loss: 0.0072, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 962, Step num: 13114, Learning rate: 0.00007718, Avg batch loss: 0.0079, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 963, Step num: 13115, Learning rate: 0.00007718, Avg batch loss: 0.0058, Avg batch acc: 0.9962
Train, Epoch: 9, Batch: 964, Step num: 13116, Learning rate: 0.00007718, Avg batch loss: 0.0076, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 965, Step num: 13117, Learning rate: 0.00007718, Avg batch loss: 0.0068, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 966, Step num: 13118, Learning rate: 0.00007717, Avg batch loss: 0.0067, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 967, Step num: 13119, Learning rate: 0.00007717, Avg batch loss: 0.0084, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 968, Step num: 13120, Learning rate: 0.00007717, Avg batch loss: 0.0074, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 969, Step num: 13121, Learning rate: 0.00007716, Avg batch loss: 0.0073, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 970, Step num: 13122, Learning rate: 0.00007716, Avg batch loss: 0.0054, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 971, Step num: 13123, Learning rate: 0.00007716, Avg batch loss: 0.0077, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 972, Step num: 13124, Learning rate: 0.00007715, Avg batch loss: 0.0079, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 973, Step num: 13125, Learning rate: 0.00007715, Avg batch loss: 0.0072, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 974, Step num: 13126, Learning rate: 0.00007715, Avg batch loss: 0.0087, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 975, Step num: 13127, Learning rate: 0.00007715, Avg batch loss: 0.0076, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 976, Step num: 13128, Learning rate: 0.00007714, Avg batch loss: 0.0078, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 977, Step num: 13129, Learning rate: 0.00007714, Avg batch loss: 0.0088, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 978, Step num: 13130, Learning rate: 0.00007714, Avg batch loss: 0.0061, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 979, Step num: 13131, Learning rate: 0.00007713, Avg batch loss: 0.0086, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 980, Step num: 13132, Learning rate: 0.00007713, Avg batch loss: 0.0062, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 981, Step num: 13133, Learning rate: 0.00007713, Avg batch loss: 0.0080, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 982, Step num: 13134, Learning rate: 0.00007713, Avg batch loss: 0.0085, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 983, Step num: 13135, Learning rate: 0.00007712, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 984, Step num: 13136, Learning rate: 0.00007712, Avg batch loss: 0.0053, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 985, Step num: 13137, Learning rate: 0.00007712, Avg batch loss: 0.0049, Avg batch acc: 0.9961
Train, Epoch: 9, Batch: 986, Step num: 13138, Learning rate: 0.00007711, Avg batch loss: 0.0054, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 987, Step num: 13139, Learning rate: 0.00007711, Avg batch loss: 0.0099, Avg batch acc: 0.9884
Train, Epoch: 9, Batch: 988, Step num: 13140, Learning rate: 0.00007711, Avg batch loss: 0.0061, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 989, Step num: 13141, Learning rate: 0.00007710, Avg batch loss: 0.0071, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 990, Step num: 13142, Learning rate: 0.00007710, Avg batch loss: 0.0070, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 991, Step num: 13143, Learning rate: 0.00007710, Avg batch loss: 0.0084, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 992, Step num: 13144, Learning rate: 0.00007710, Avg batch loss: 0.0067, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 993, Step num: 13145, Learning rate: 0.00007709, Avg batch loss: 0.0074, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 994, Step num: 13146, Learning rate: 0.00007709, Avg batch loss: 0.0088, Avg batch acc: 0.9883
Train, Epoch: 9, Batch: 995, Step num: 13147, Learning rate: 0.00007709, Avg batch loss: 0.0090, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 996, Step num: 13148, Learning rate: 0.00007708, Avg batch loss: 0.0086, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 997, Step num: 13149, Learning rate: 0.00007708, Avg batch loss: 0.0054, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 998, Step num: 13150, Learning rate: 0.00007708, Avg batch loss: 0.0074, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 999, Step num: 13151, Learning rate: 0.00007708, Avg batch loss: 0.0063, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 1000, Step num: 13152, Learning rate: 0.00007707, Avg batch loss: 0.0084, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 1001, Step num: 13153, Learning rate: 0.00007707, Avg batch loss: 0.0062, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1002, Step num: 13154, Learning rate: 0.00007707, Avg batch loss: 0.0085, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 1003, Step num: 13155, Learning rate: 0.00007706, Avg batch loss: 0.0068, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 1004, Step num: 13156, Learning rate: 0.00007706, Avg batch loss: 0.0091, Avg batch acc: 0.9896
Train, Epoch: 9, Batch: 1005, Step num: 13157, Learning rate: 0.00007706, Avg batch loss: 0.0061, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 1006, Step num: 13158, Learning rate: 0.00007705, Avg batch loss: 0.0049, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 1007, Step num: 13159, Learning rate: 0.00007705, Avg batch loss: 0.0082, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1008, Step num: 13160, Learning rate: 0.00007705, Avg batch loss: 0.0052, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1009, Step num: 13161, Learning rate: 0.00007705, Avg batch loss: 0.0063, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1010, Step num: 13162, Learning rate: 0.00007704, Avg batch loss: 0.0074, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 1011, Step num: 13163, Learning rate: 0.00007704, Avg batch loss: 0.0076, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1012, Step num: 13164, Learning rate: 0.00007704, Avg batch loss: 0.0072, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1013, Step num: 13165, Learning rate: 0.00007703, Avg batch loss: 0.0043, Avg batch acc: 0.9961
Train, Epoch: 9, Batch: 1014, Step num: 13166, Learning rate: 0.00007703, Avg batch loss: 0.0080, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 1015, Step num: 13167, Learning rate: 0.00007703, Avg batch loss: 0.0063, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1016, Step num: 13168, Learning rate: 0.00007703, Avg batch loss: 0.0068, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1017, Step num: 13169, Learning rate: 0.00007702, Avg batch loss: 0.0058, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1018, Step num: 13170, Learning rate: 0.00007702, Avg batch loss: 0.0069, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 1019, Step num: 13171, Learning rate: 0.00007702, Avg batch loss: 0.0065, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 1020, Step num: 13172, Learning rate: 0.00007701, Avg batch loss: 0.0087, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1021, Step num: 13173, Learning rate: 0.00007701, Avg batch loss: 0.0067, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1022, Step num: 13174, Learning rate: 0.00007701, Avg batch loss: 0.0079, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1023, Step num: 13175, Learning rate: 0.00007701, Avg batch loss: 0.0046, Avg batch acc: 0.9967
Train, Epoch: 9, Batch: 1024, Step num: 13176, Learning rate: 0.00007700, Avg batch loss: 0.0069, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1025, Step num: 13177, Learning rate: 0.00007700, Avg batch loss: 0.0058, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 1026, Step num: 13178, Learning rate: 0.00007700, Avg batch loss: 0.0075, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1027, Step num: 13179, Learning rate: 0.00007699, Avg batch loss: 0.0067, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 1028, Step num: 13180, Learning rate: 0.00007699, Avg batch loss: 0.0075, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 1029, Step num: 13181, Learning rate: 0.00007699, Avg batch loss: 0.0065, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1030, Step num: 13182, Learning rate: 0.00007698, Avg batch loss: 0.0071, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1031, Step num: 13183, Learning rate: 0.00007698, Avg batch loss: 0.0081, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1032, Step num: 13184, Learning rate: 0.00007698, Avg batch loss: 0.0073, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 1033, Step num: 13185, Learning rate: 0.00007698, Avg batch loss: 0.0064, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 1034, Step num: 13186, Learning rate: 0.00007697, Avg batch loss: 0.0066, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1035, Step num: 13187, Learning rate: 0.00007697, Avg batch loss: 0.0065, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 1036, Step num: 13188, Learning rate: 0.00007697, Avg batch loss: 0.0073, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 1037, Step num: 13189, Learning rate: 0.00007696, Avg batch loss: 0.0054, Avg batch acc: 0.9959
Train, Epoch: 9, Batch: 1038, Step num: 13190, Learning rate: 0.00007696, Avg batch loss: 0.0062, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1039, Step num: 13191, Learning rate: 0.00007696, Avg batch loss: 0.0075, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 1040, Step num: 13192, Learning rate: 0.00007696, Avg batch loss: 0.0088, Avg batch acc: 0.9883
Train, Epoch: 9, Batch: 1041, Step num: 13193, Learning rate: 0.00007695, Avg batch loss: 0.0080, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 1042, Step num: 13194, Learning rate: 0.00007695, Avg batch loss: 0.0065, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1043, Step num: 13195, Learning rate: 0.00007695, Avg batch loss: 0.0068, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 1044, Step num: 13196, Learning rate: 0.00007694, Avg batch loss: 0.0060, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1045, Step num: 13197, Learning rate: 0.00007694, Avg batch loss: 0.0047, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 1046, Step num: 13198, Learning rate: 0.00007694, Avg batch loss: 0.0074, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 1047, Step num: 13199, Learning rate: 0.00007694, Avg batch loss: 0.0075, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 1048, Step num: 13200, Learning rate: 0.00007693, Avg batch loss: 0.0075, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1049, Step num: 13201, Learning rate: 0.00007693, Avg batch loss: 0.0052, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 1050, Step num: 13202, Learning rate: 0.00007693, Avg batch loss: 0.0074, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1051, Step num: 13203, Learning rate: 0.00007692, Avg batch loss: 0.0068, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1052, Step num: 13204, Learning rate: 0.00007692, Avg batch loss: 0.0077, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1053, Step num: 13205, Learning rate: 0.00007692, Avg batch loss: 0.0077, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1054, Step num: 13206, Learning rate: 0.00007691, Avg batch loss: 0.0112, Avg batch acc: 0.9895
Train, Epoch: 9, Batch: 1055, Step num: 13207, Learning rate: 0.00007691, Avg batch loss: 0.0087, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 1056, Step num: 13208, Learning rate: 0.00007691, Avg batch loss: 0.0075, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1057, Step num: 13209, Learning rate: 0.00007691, Avg batch loss: 0.0076, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 1058, Step num: 13210, Learning rate: 0.00007690, Avg batch loss: 0.0058, Avg batch acc: 0.9966
Train, Epoch: 9, Batch: 1059, Step num: 13211, Learning rate: 0.00007690, Avg batch loss: 0.0067, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1060, Step num: 13212, Learning rate: 0.00007690, Avg batch loss: 0.0090, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 1061, Step num: 13213, Learning rate: 0.00007689, Avg batch loss: 0.0092, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 1062, Step num: 13214, Learning rate: 0.00007689, Avg batch loss: 0.0066, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1063, Step num: 13215, Learning rate: 0.00007689, Avg batch loss: 0.0053, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 1064, Step num: 13216, Learning rate: 0.00007689, Avg batch loss: 0.0065, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1065, Step num: 13217, Learning rate: 0.00007688, Avg batch loss: 0.0065, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 1066, Step num: 13218, Learning rate: 0.00007688, Avg batch loss: 0.0039, Avg batch acc: 0.9975
Train, Epoch: 9, Batch: 1067, Step num: 13219, Learning rate: 0.00007688, Avg batch loss: 0.0076, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 1068, Step num: 13220, Learning rate: 0.00007687, Avg batch loss: 0.0085, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1069, Step num: 13221, Learning rate: 0.00007687, Avg batch loss: 0.0076, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 1070, Step num: 13222, Learning rate: 0.00007687, Avg batch loss: 0.0113, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 1071, Step num: 13223, Learning rate: 0.00007687, Avg batch loss: 0.0069, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1072, Step num: 13224, Learning rate: 0.00007686, Avg batch loss: 0.0094, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 1073, Step num: 13225, Learning rate: 0.00007686, Avg batch loss: 0.0078, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 1074, Step num: 13226, Learning rate: 0.00007686, Avg batch loss: 0.0052, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1075, Step num: 13227, Learning rate: 0.00007685, Avg batch loss: 0.0077, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 1076, Step num: 13228, Learning rate: 0.00007685, Avg batch loss: 0.0083, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1077, Step num: 13229, Learning rate: 0.00007685, Avg batch loss: 0.0054, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 1078, Step num: 13230, Learning rate: 0.00007684, Avg batch loss: 0.0066, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1079, Step num: 13231, Learning rate: 0.00007684, Avg batch loss: 0.0050, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1080, Step num: 13232, Learning rate: 0.00007684, Avg batch loss: 0.0062, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1081, Step num: 13233, Learning rate: 0.00007684, Avg batch loss: 0.0064, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1082, Step num: 13234, Learning rate: 0.00007683, Avg batch loss: 0.0038, Avg batch acc: 0.9975
Train, Epoch: 9, Batch: 1083, Step num: 13235, Learning rate: 0.00007683, Avg batch loss: 0.0054, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1084, Step num: 13236, Learning rate: 0.00007683, Avg batch loss: 0.0074, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 1085, Step num: 13237, Learning rate: 0.00007682, Avg batch loss: 0.0057, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 1086, Step num: 13238, Learning rate: 0.00007682, Avg batch loss: 0.0056, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 1087, Step num: 13239, Learning rate: 0.00007682, Avg batch loss: 0.0052, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 1088, Step num: 13240, Learning rate: 0.00007682, Avg batch loss: 0.0065, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 1089, Step num: 13241, Learning rate: 0.00007681, Avg batch loss: 0.0053, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 1090, Step num: 13242, Learning rate: 0.00007681, Avg batch loss: 0.0060, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1091, Step num: 13243, Learning rate: 0.00007681, Avg batch loss: 0.0058, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 1092, Step num: 13244, Learning rate: 0.00007680, Avg batch loss: 0.0049, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 1093, Step num: 13245, Learning rate: 0.00007680, Avg batch loss: 0.0081, Avg batch acc: 0.9888
Train, Epoch: 9, Batch: 1094, Step num: 13246, Learning rate: 0.00007680, Avg batch loss: 0.0080, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1095, Step num: 13247, Learning rate: 0.00007680, Avg batch loss: 0.0058, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 1096, Step num: 13248, Learning rate: 0.00007679, Avg batch loss: 0.0066, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 1097, Step num: 13249, Learning rate: 0.00007679, Avg batch loss: 0.0079, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 1098, Step num: 13250, Learning rate: 0.00007679, Avg batch loss: 0.0061, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 1099, Step num: 13251, Learning rate: 0.00007678, Avg batch loss: 0.0069, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 1100, Step num: 13252, Learning rate: 0.00007678, Avg batch loss: 0.0077, Avg batch acc: 0.9895
Train, Epoch: 9, Batch: 1101, Step num: 13253, Learning rate: 0.00007678, Avg batch loss: 0.0058, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1102, Step num: 13254, Learning rate: 0.00007678, Avg batch loss: 0.0087, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1103, Step num: 13255, Learning rate: 0.00007677, Avg batch loss: 0.0050, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 1104, Step num: 13256, Learning rate: 0.00007677, Avg batch loss: 0.0087, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1105, Step num: 13257, Learning rate: 0.00007677, Avg batch loss: 0.0059, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1106, Step num: 13258, Learning rate: 0.00007676, Avg batch loss: 0.0070, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1107, Step num: 13259, Learning rate: 0.00007676, Avg batch loss: 0.0048, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1108, Step num: 13260, Learning rate: 0.00007676, Avg batch loss: 0.0069, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 1109, Step num: 13261, Learning rate: 0.00007676, Avg batch loss: 0.0090, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 1110, Step num: 13262, Learning rate: 0.00007675, Avg batch loss: 0.0098, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 1111, Step num: 13263, Learning rate: 0.00007675, Avg batch loss: 0.0080, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 1112, Step num: 13264, Learning rate: 0.00007675, Avg batch loss: 0.0052, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 1113, Step num: 13265, Learning rate: 0.00007674, Avg batch loss: 0.0074, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1114, Step num: 13266, Learning rate: 0.00007674, Avg batch loss: 0.0075, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1115, Step num: 13267, Learning rate: 0.00007674, Avg batch loss: 0.0070, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1116, Step num: 13268, Learning rate: 0.00007673, Avg batch loss: 0.0092, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 1117, Step num: 13269, Learning rate: 0.00007673, Avg batch loss: 0.0084, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 1118, Step num: 13270, Learning rate: 0.00007673, Avg batch loss: 0.0070, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1119, Step num: 13271, Learning rate: 0.00007673, Avg batch loss: 0.0072, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1120, Step num: 13272, Learning rate: 0.00007672, Avg batch loss: 0.0088, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 1121, Step num: 13273, Learning rate: 0.00007672, Avg batch loss: 0.0048, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1122, Step num: 13274, Learning rate: 0.00007672, Avg batch loss: 0.0087, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1123, Step num: 13275, Learning rate: 0.00007671, Avg batch loss: 0.0060, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1124, Step num: 13276, Learning rate: 0.00007671, Avg batch loss: 0.0081, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 1125, Step num: 13277, Learning rate: 0.00007671, Avg batch loss: 0.0051, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1126, Step num: 13278, Learning rate: 0.00007671, Avg batch loss: 0.0072, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 1127, Step num: 13279, Learning rate: 0.00007670, Avg batch loss: 0.0076, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 1128, Step num: 13280, Learning rate: 0.00007670, Avg batch loss: 0.0076, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 1129, Step num: 13281, Learning rate: 0.00007670, Avg batch loss: 0.0074, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1130, Step num: 13282, Learning rate: 0.00007669, Avg batch loss: 0.0054, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1131, Step num: 13283, Learning rate: 0.00007669, Avg batch loss: 0.0080, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 1132, Step num: 13284, Learning rate: 0.00007669, Avg batch loss: 0.0093, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1133, Step num: 13285, Learning rate: 0.00007669, Avg batch loss: 0.0098, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 1134, Step num: 13286, Learning rate: 0.00007668, Avg batch loss: 0.0099, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 1135, Step num: 13287, Learning rate: 0.00007668, Avg batch loss: 0.0071, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1136, Step num: 13288, Learning rate: 0.00007668, Avg batch loss: 0.0076, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1137, Step num: 13289, Learning rate: 0.00007667, Avg batch loss: 0.0054, Avg batch acc: 0.9961
Train, Epoch: 9, Batch: 1138, Step num: 13290, Learning rate: 0.00007667, Avg batch loss: 0.0069, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 1139, Step num: 13291, Learning rate: 0.00007667, Avg batch loss: 0.0093, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 1140, Step num: 13292, Learning rate: 0.00007667, Avg batch loss: 0.0084, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1141, Step num: 13293, Learning rate: 0.00007666, Avg batch loss: 0.0089, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 1142, Step num: 13294, Learning rate: 0.00007666, Avg batch loss: 0.0072, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1143, Step num: 13295, Learning rate: 0.00007666, Avg batch loss: 0.0066, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1144, Step num: 13296, Learning rate: 0.00007665, Avg batch loss: 0.0091, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 1145, Step num: 13297, Learning rate: 0.00007665, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1146, Step num: 13298, Learning rate: 0.00007665, Avg batch loss: 0.0060, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 1147, Step num: 13299, Learning rate: 0.00007665, Avg batch loss: 0.0045, Avg batch acc: 0.9970
Train, Epoch: 9, Batch: 1148, Step num: 13300, Learning rate: 0.00007664, Avg batch loss: 0.0057, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1149, Step num: 13301, Learning rate: 0.00007664, Avg batch loss: 0.0047, Avg batch acc: 0.9961
Train, Epoch: 9, Batch: 1150, Step num: 13302, Learning rate: 0.00007664, Avg batch loss: 0.0052, Avg batch acc: 0.9955
Train, Epoch: 9, Batch: 1151, Step num: 13303, Learning rate: 0.00007663, Avg batch loss: 0.0095, Avg batch acc: 0.9871
Train, Epoch: 9, Batch: 1152, Step num: 13304, Learning rate: 0.00007663, Avg batch loss: 0.0068, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 1153, Step num: 13305, Learning rate: 0.00007663, Avg batch loss: 0.0066, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 1154, Step num: 13306, Learning rate: 0.00007663, Avg batch loss: 0.0068, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 1155, Step num: 13307, Learning rate: 0.00007662, Avg batch loss: 0.0059, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1156, Step num: 13308, Learning rate: 0.00007662, Avg batch loss: 0.0060, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1157, Step num: 13309, Learning rate: 0.00007662, Avg batch loss: 0.0057, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1158, Step num: 13310, Learning rate: 0.00007661, Avg batch loss: 0.0070, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1159, Step num: 13311, Learning rate: 0.00007661, Avg batch loss: 0.0073, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 1160, Step num: 13312, Learning rate: 0.00007661, Avg batch loss: 0.0093, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 1161, Step num: 13313, Learning rate: 0.00007660, Avg batch loss: 0.0070, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1162, Step num: 13314, Learning rate: 0.00007660, Avg batch loss: 0.0052, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1163, Step num: 13315, Learning rate: 0.00007660, Avg batch loss: 0.0077, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1164, Step num: 13316, Learning rate: 0.00007660, Avg batch loss: 0.0093, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 1165, Step num: 13317, Learning rate: 0.00007659, Avg batch loss: 0.0076, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 1166, Step num: 13318, Learning rate: 0.00007659, Avg batch loss: 0.0085, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1167, Step num: 13319, Learning rate: 0.00007659, Avg batch loss: 0.0094, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1168, Step num: 13320, Learning rate: 0.00007658, Avg batch loss: 0.0072, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 1169, Step num: 13321, Learning rate: 0.00007658, Avg batch loss: 0.0063, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1170, Step num: 13322, Learning rate: 0.00007658, Avg batch loss: 0.0092, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 1171, Step num: 13323, Learning rate: 0.00007658, Avg batch loss: 0.0067, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1172, Step num: 13324, Learning rate: 0.00007657, Avg batch loss: 0.0054, Avg batch acc: 0.9955
Train, Epoch: 9, Batch: 1173, Step num: 13325, Learning rate: 0.00007657, Avg batch loss: 0.0086, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1174, Step num: 13326, Learning rate: 0.00007657, Avg batch loss: 0.0049, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1175, Step num: 13327, Learning rate: 0.00007656, Avg batch loss: 0.0059, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 1176, Step num: 13328, Learning rate: 0.00007656, Avg batch loss: 0.0059, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 1177, Step num: 13329, Learning rate: 0.00007656, Avg batch loss: 0.0066, Avg batch acc: 0.9955
Train, Epoch: 9, Batch: 1178, Step num: 13330, Learning rate: 0.00007656, Avg batch loss: 0.0055, Avg batch acc: 0.9954
Train, Epoch: 9, Batch: 1179, Step num: 13331, Learning rate: 0.00007655, Avg batch loss: 0.0064, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1180, Step num: 13332, Learning rate: 0.00007655, Avg batch loss: 0.0067, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 1181, Step num: 13333, Learning rate: 0.00007655, Avg batch loss: 0.0059, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1182, Step num: 13334, Learning rate: 0.00007654, Avg batch loss: 0.0077, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1183, Step num: 13335, Learning rate: 0.00007654, Avg batch loss: 0.0066, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1184, Step num: 13336, Learning rate: 0.00007654, Avg batch loss: 0.0092, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 1185, Step num: 13337, Learning rate: 0.00007654, Avg batch loss: 0.0055, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1186, Step num: 13338, Learning rate: 0.00007653, Avg batch loss: 0.0071, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1187, Step num: 13339, Learning rate: 0.00007653, Avg batch loss: 0.0068, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1188, Step num: 13340, Learning rate: 0.00007653, Avg batch loss: 0.0064, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1189, Step num: 13341, Learning rate: 0.00007652, Avg batch loss: 0.0065, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 1190, Step num: 13342, Learning rate: 0.00007652, Avg batch loss: 0.0078, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1191, Step num: 13343, Learning rate: 0.00007652, Avg batch loss: 0.0059, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 1192, Step num: 13344, Learning rate: 0.00007652, Avg batch loss: 0.0073, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 1193, Step num: 13345, Learning rate: 0.00007651, Avg batch loss: 0.0055, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 1194, Step num: 13346, Learning rate: 0.00007651, Avg batch loss: 0.0070, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1195, Step num: 13347, Learning rate: 0.00007651, Avg batch loss: 0.0071, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1196, Step num: 13348, Learning rate: 0.00007650, Avg batch loss: 0.0073, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1197, Step num: 13349, Learning rate: 0.00007650, Avg batch loss: 0.0070, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 1198, Step num: 13350, Learning rate: 0.00007650, Avg batch loss: 0.0086, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 1199, Step num: 13351, Learning rate: 0.00007650, Avg batch loss: 0.0075, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1200, Step num: 13352, Learning rate: 0.00007649, Avg batch loss: 0.0046, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1201, Step num: 13353, Learning rate: 0.00007649, Avg batch loss: 0.0061, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1202, Step num: 13354, Learning rate: 0.00007649, Avg batch loss: 0.0065, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 1203, Step num: 13355, Learning rate: 0.00007648, Avg batch loss: 0.0059, Avg batch acc: 0.9955
Train, Epoch: 9, Batch: 1204, Step num: 13356, Learning rate: 0.00007648, Avg batch loss: 0.0064, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 1205, Step num: 13357, Learning rate: 0.00007648, Avg batch loss: 0.0064, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1206, Step num: 13358, Learning rate: 0.00007648, Avg batch loss: 0.0061, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1207, Step num: 13359, Learning rate: 0.00007647, Avg batch loss: 0.0061, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1208, Step num: 13360, Learning rate: 0.00007647, Avg batch loss: 0.0040, Avg batch acc: 0.9961
Train, Epoch: 9, Batch: 1209, Step num: 13361, Learning rate: 0.00007647, Avg batch loss: 0.0052, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 1210, Step num: 13362, Learning rate: 0.00007646, Avg batch loss: 0.0072, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 1211, Step num: 13363, Learning rate: 0.00007646, Avg batch loss: 0.0098, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 1212, Step num: 13364, Learning rate: 0.00007646, Avg batch loss: 0.0053, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1213, Step num: 13365, Learning rate: 0.00007646, Avg batch loss: 0.0077, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 1214, Step num: 13366, Learning rate: 0.00007645, Avg batch loss: 0.0071, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1215, Step num: 13367, Learning rate: 0.00007645, Avg batch loss: 0.0069, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1216, Step num: 13368, Learning rate: 0.00007645, Avg batch loss: 0.0070, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 1217, Step num: 13369, Learning rate: 0.00007644, Avg batch loss: 0.0081, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 1218, Step num: 13370, Learning rate: 0.00007644, Avg batch loss: 0.0060, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1219, Step num: 13371, Learning rate: 0.00007644, Avg batch loss: 0.0069, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1220, Step num: 13372, Learning rate: 0.00007644, Avg batch loss: 0.0060, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1221, Step num: 13373, Learning rate: 0.00007643, Avg batch loss: 0.0068, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1222, Step num: 13374, Learning rate: 0.00007643, Avg batch loss: 0.0074, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 1223, Step num: 13375, Learning rate: 0.00007643, Avg batch loss: 0.0076, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 1224, Step num: 13376, Learning rate: 0.00007642, Avg batch loss: 0.0065, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1225, Step num: 13377, Learning rate: 0.00007642, Avg batch loss: 0.0050, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 1226, Step num: 13378, Learning rate: 0.00007642, Avg batch loss: 0.0074, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1227, Step num: 13379, Learning rate: 0.00007642, Avg batch loss: 0.0260, Avg batch acc: 0.9884
Train, Epoch: 9, Batch: 1228, Step num: 13380, Learning rate: 0.00007641, Avg batch loss: 0.0081, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 1229, Step num: 13381, Learning rate: 0.00007641, Avg batch loss: 0.0087, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1230, Step num: 13382, Learning rate: 0.00007641, Avg batch loss: 0.0061, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1231, Step num: 13383, Learning rate: 0.00007640, Avg batch loss: 0.0074, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 1232, Step num: 13384, Learning rate: 0.00007640, Avg batch loss: 0.0064, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1233, Step num: 13385, Learning rate: 0.00007640, Avg batch loss: 0.0045, Avg batch acc: 0.9963
Train, Epoch: 9, Batch: 1234, Step num: 13386, Learning rate: 0.00007640, Avg batch loss: 0.0083, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 1235, Step num: 13387, Learning rate: 0.00007639, Avg batch loss: 0.0073, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1236, Step num: 13388, Learning rate: 0.00007639, Avg batch loss: 0.0092, Avg batch acc: 0.9878
Train, Epoch: 9, Batch: 1237, Step num: 13389, Learning rate: 0.00007639, Avg batch loss: 0.0076, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1238, Step num: 13390, Learning rate: 0.00007638, Avg batch loss: 0.0065, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1239, Step num: 13391, Learning rate: 0.00007638, Avg batch loss: 0.0078, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 1240, Step num: 13392, Learning rate: 0.00007638, Avg batch loss: 0.0083, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 1241, Step num: 13393, Learning rate: 0.00007638, Avg batch loss: 0.0099, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1242, Step num: 13394, Learning rate: 0.00007637, Avg batch loss: 0.0054, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1243, Step num: 13395, Learning rate: 0.00007637, Avg batch loss: 0.0075, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 1244, Step num: 13396, Learning rate: 0.00007637, Avg batch loss: 0.0083, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1245, Step num: 13397, Learning rate: 0.00007636, Avg batch loss: 0.0060, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1246, Step num: 13398, Learning rate: 0.00007636, Avg batch loss: 0.0072, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1247, Step num: 13399, Learning rate: 0.00007636, Avg batch loss: 0.0099, Avg batch acc: 0.9898
Train, Epoch: 9, Batch: 1248, Step num: 13400, Learning rate: 0.00007636, Avg batch loss: 0.0083, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1249, Step num: 13401, Learning rate: 0.00007635, Avg batch loss: 0.0071, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1250, Step num: 13402, Learning rate: 0.00007635, Avg batch loss: 0.0057, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 1251, Step num: 13403, Learning rate: 0.00007635, Avg batch loss: 0.0089, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1252, Step num: 13404, Learning rate: 0.00007634, Avg batch loss: 0.0052, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1253, Step num: 13405, Learning rate: 0.00007634, Avg batch loss: 0.0085, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1254, Step num: 13406, Learning rate: 0.00007634, Avg batch loss: 0.0079, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 1255, Step num: 13407, Learning rate: 0.00007634, Avg batch loss: 0.0047, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 1256, Step num: 13408, Learning rate: 0.00007633, Avg batch loss: 0.0063, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 1257, Step num: 13409, Learning rate: 0.00007633, Avg batch loss: 0.0090, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 1258, Step num: 13410, Learning rate: 0.00007633, Avg batch loss: 0.0063, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1259, Step num: 13411, Learning rate: 0.00007632, Avg batch loss: 0.0081, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 1260, Step num: 13412, Learning rate: 0.00007632, Avg batch loss: 0.0096, Avg batch acc: 0.9903
Train, Epoch: 9, Batch: 1261, Step num: 13413, Learning rate: 0.00007632, Avg batch loss: 0.0064, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 1262, Step num: 13414, Learning rate: 0.00007632, Avg batch loss: 0.0073, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 1263, Step num: 13415, Learning rate: 0.00007631, Avg batch loss: 0.0064, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 1264, Step num: 13416, Learning rate: 0.00007631, Avg batch loss: 0.0062, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1265, Step num: 13417, Learning rate: 0.00007631, Avg batch loss: 0.0055, Avg batch acc: 0.9964
Train, Epoch: 9, Batch: 1266, Step num: 13418, Learning rate: 0.00007630, Avg batch loss: 0.0082, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1267, Step num: 13419, Learning rate: 0.00007630, Avg batch loss: 0.0072, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1268, Step num: 13420, Learning rate: 0.00007630, Avg batch loss: 0.0062, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 1269, Step num: 13421, Learning rate: 0.00007630, Avg batch loss: 0.0068, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 1270, Step num: 13422, Learning rate: 0.00007629, Avg batch loss: 0.0064, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1271, Step num: 13423, Learning rate: 0.00007629, Avg batch loss: 0.0069, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1272, Step num: 13424, Learning rate: 0.00007629, Avg batch loss: 0.0047, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1273, Step num: 13425, Learning rate: 0.00007628, Avg batch loss: 0.0063, Avg batch acc: 0.9898
Train, Epoch: 9, Batch: 1274, Step num: 13426, Learning rate: 0.00007628, Avg batch loss: 0.0083, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1275, Step num: 13427, Learning rate: 0.00007628, Avg batch loss: 0.0049, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 1276, Step num: 13428, Learning rate: 0.00007628, Avg batch loss: 0.0055, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 1277, Step num: 13429, Learning rate: 0.00007627, Avg batch loss: 0.0062, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 1278, Step num: 13430, Learning rate: 0.00007627, Avg batch loss: 0.0071, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1279, Step num: 13431, Learning rate: 0.00007627, Avg batch loss: 0.0061, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1280, Step num: 13432, Learning rate: 0.00007626, Avg batch loss: 0.0042, Avg batch acc: 0.9954
Train, Epoch: 9, Batch: 1281, Step num: 13433, Learning rate: 0.00007626, Avg batch loss: 0.0045, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1282, Step num: 13434, Learning rate: 0.00007626, Avg batch loss: 0.0083, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1283, Step num: 13435, Learning rate: 0.00007626, Avg batch loss: 0.0055, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1284, Step num: 13436, Learning rate: 0.00007625, Avg batch loss: 0.0059, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1285, Step num: 13437, Learning rate: 0.00007625, Avg batch loss: 0.0069, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1286, Step num: 13438, Learning rate: 0.00007625, Avg batch loss: 0.0094, Avg batch acc: 0.9895
Train, Epoch: 9, Batch: 1287, Step num: 13439, Learning rate: 0.00007625, Avg batch loss: 0.0074, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1288, Step num: 13440, Learning rate: 0.00007624, Avg batch loss: 0.0060, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1289, Step num: 13441, Learning rate: 0.00007624, Avg batch loss: 0.0071, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 1290, Step num: 13442, Learning rate: 0.00007624, Avg batch loss: 0.0074, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 1291, Step num: 13443, Learning rate: 0.00007623, Avg batch loss: 0.0062, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1292, Step num: 13444, Learning rate: 0.00007623, Avg batch loss: 0.0071, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 1293, Step num: 13445, Learning rate: 0.00007623, Avg batch loss: 0.0053, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1294, Step num: 13446, Learning rate: 0.00007623, Avg batch loss: 0.0082, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 1295, Step num: 13447, Learning rate: 0.00007622, Avg batch loss: 0.0068, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 1296, Step num: 13448, Learning rate: 0.00007622, Avg batch loss: 0.0080, Avg batch acc: 0.9960
Train, Epoch: 9, Batch: 1297, Step num: 13449, Learning rate: 0.00007622, Avg batch loss: 0.0052, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1298, Step num: 13450, Learning rate: 0.00007621, Avg batch loss: 0.0077, Avg batch acc: 0.9911
Train, Epoch: 9, Batch: 1299, Step num: 13451, Learning rate: 0.00007621, Avg batch loss: 0.0056, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 1300, Step num: 13452, Learning rate: 0.00007621, Avg batch loss: 0.0082, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 1301, Step num: 13453, Learning rate: 0.00007621, Avg batch loss: 0.0057, Avg batch acc: 0.9963
Train, Epoch: 9, Batch: 1302, Step num: 13454, Learning rate: 0.00007620, Avg batch loss: 0.0060, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1303, Step num: 13455, Learning rate: 0.00007620, Avg batch loss: 0.0092, Avg batch acc: 0.9888
Train, Epoch: 9, Batch: 1304, Step num: 13456, Learning rate: 0.00007620, Avg batch loss: 0.0065, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1305, Step num: 13457, Learning rate: 0.00007619, Avg batch loss: 0.0147, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 1306, Step num: 13458, Learning rate: 0.00007619, Avg batch loss: 0.0095, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1307, Step num: 13459, Learning rate: 0.00007619, Avg batch loss: 0.0073, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1308, Step num: 13460, Learning rate: 0.00007619, Avg batch loss: 0.0054, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1309, Step num: 13461, Learning rate: 0.00007618, Avg batch loss: 0.0070, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 1310, Step num: 13462, Learning rate: 0.00007618, Avg batch loss: 0.0046, Avg batch acc: 0.9986
Train, Epoch: 9, Batch: 1311, Step num: 13463, Learning rate: 0.00007618, Avg batch loss: 0.0082, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 1312, Step num: 13464, Learning rate: 0.00007617, Avg batch loss: 0.0066, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 1313, Step num: 13465, Learning rate: 0.00007617, Avg batch loss: 0.0082, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1314, Step num: 13466, Learning rate: 0.00007617, Avg batch loss: 0.0076, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 1315, Step num: 13467, Learning rate: 0.00007617, Avg batch loss: 0.0063, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1316, Step num: 13468, Learning rate: 0.00007616, Avg batch loss: 0.0067, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1317, Step num: 13469, Learning rate: 0.00007616, Avg batch loss: 0.0056, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1318, Step num: 13470, Learning rate: 0.00007616, Avg batch loss: 0.0086, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1319, Step num: 13471, Learning rate: 0.00007615, Avg batch loss: 0.0083, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1320, Step num: 13472, Learning rate: 0.00007615, Avg batch loss: 0.0076, Avg batch acc: 0.9898
Train, Epoch: 9, Batch: 1321, Step num: 13473, Learning rate: 0.00007615, Avg batch loss: 0.0060, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1322, Step num: 13474, Learning rate: 0.00007615, Avg batch loss: 0.0067, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1323, Step num: 13475, Learning rate: 0.00007614, Avg batch loss: 0.0068, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1324, Step num: 13476, Learning rate: 0.00007614, Avg batch loss: 0.0093, Avg batch acc: 0.9909
Train, Epoch: 9, Batch: 1325, Step num: 13477, Learning rate: 0.00007614, Avg batch loss: 0.0064, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1326, Step num: 13478, Learning rate: 0.00007613, Avg batch loss: 0.0080, Avg batch acc: 0.9895
Train, Epoch: 9, Batch: 1327, Step num: 13479, Learning rate: 0.00007613, Avg batch loss: 0.0055, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 1328, Step num: 13480, Learning rate: 0.00007613, Avg batch loss: 0.0064, Avg batch acc: 0.9960
Train, Epoch: 9, Batch: 1329, Step num: 13481, Learning rate: 0.00007613, Avg batch loss: 0.0064, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1330, Step num: 13482, Learning rate: 0.00007612, Avg batch loss: 0.0079, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 1331, Step num: 13483, Learning rate: 0.00007612, Avg batch loss: 0.0080, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1332, Step num: 13484, Learning rate: 0.00007612, Avg batch loss: 0.0085, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 1333, Step num: 13485, Learning rate: 0.00007611, Avg batch loss: 0.0070, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1334, Step num: 13486, Learning rate: 0.00007611, Avg batch loss: 0.0067, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 1335, Step num: 13487, Learning rate: 0.00007611, Avg batch loss: 0.0067, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1336, Step num: 13488, Learning rate: 0.00007611, Avg batch loss: 0.0104, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 1337, Step num: 13489, Learning rate: 0.00007610, Avg batch loss: 0.0053, Avg batch acc: 0.9946
Train, Epoch: 9, Batch: 1338, Step num: 13490, Learning rate: 0.00007610, Avg batch loss: 0.0075, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1339, Step num: 13491, Learning rate: 0.00007610, Avg batch loss: 0.0074, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 1340, Step num: 13492, Learning rate: 0.00007610, Avg batch loss: 0.0052, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 1341, Step num: 13493, Learning rate: 0.00007609, Avg batch loss: 0.0070, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 1342, Step num: 13494, Learning rate: 0.00007609, Avg batch loss: 0.0080, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1343, Step num: 13495, Learning rate: 0.00007609, Avg batch loss: 0.0071, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 1344, Step num: 13496, Learning rate: 0.00007608, Avg batch loss: 0.0073, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 1345, Step num: 13497, Learning rate: 0.00007608, Avg batch loss: 0.0085, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 1346, Step num: 13498, Learning rate: 0.00007608, Avg batch loss: 0.0092, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1347, Step num: 13499, Learning rate: 0.00007608, Avg batch loss: 0.0074, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1348, Step num: 13500, Learning rate: 0.00007607, Avg batch loss: 0.0088, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 1349, Step num: 13501, Learning rate: 0.00007607, Avg batch loss: 0.0068, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1350, Step num: 13502, Learning rate: 0.00007607, Avg batch loss: 0.0060, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1351, Step num: 13503, Learning rate: 0.00007606, Avg batch loss: 0.0068, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 1352, Step num: 13504, Learning rate: 0.00007606, Avg batch loss: 0.0072, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1353, Step num: 13505, Learning rate: 0.00007606, Avg batch loss: 0.0054, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1354, Step num: 13506, Learning rate: 0.00007606, Avg batch loss: 0.0103, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 1355, Step num: 13507, Learning rate: 0.00007605, Avg batch loss: 0.0061, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1356, Step num: 13508, Learning rate: 0.00007605, Avg batch loss: 0.0036, Avg batch acc: 0.9961
Train, Epoch: 9, Batch: 1357, Step num: 13509, Learning rate: 0.00007605, Avg batch loss: 0.0078, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1358, Step num: 13510, Learning rate: 0.00007604, Avg batch loss: 0.0090, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 1359, Step num: 13511, Learning rate: 0.00007604, Avg batch loss: 0.0110, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 1360, Step num: 13512, Learning rate: 0.00007604, Avg batch loss: 0.0181, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 1361, Step num: 13513, Learning rate: 0.00007604, Avg batch loss: 0.0075, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1362, Step num: 13514, Learning rate: 0.00007603, Avg batch loss: 0.0056, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1363, Step num: 13515, Learning rate: 0.00007603, Avg batch loss: 0.0051, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1364, Step num: 13516, Learning rate: 0.00007603, Avg batch loss: 0.0062, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 1365, Step num: 13517, Learning rate: 0.00007602, Avg batch loss: 0.0092, Avg batch acc: 0.9899
Train, Epoch: 9, Batch: 1366, Step num: 13518, Learning rate: 0.00007602, Avg batch loss: 0.0213, Avg batch acc: 0.9876
Train, Epoch: 9, Batch: 1367, Step num: 13519, Learning rate: 0.00007602, Avg batch loss: 0.0085, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1368, Step num: 13520, Learning rate: 0.00007602, Avg batch loss: 0.0078, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1369, Step num: 13521, Learning rate: 0.00007601, Avg batch loss: 0.0072, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1370, Step num: 13522, Learning rate: 0.00007601, Avg batch loss: 0.0084, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1371, Step num: 13523, Learning rate: 0.00007601, Avg batch loss: 0.0062, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 1372, Step num: 13524, Learning rate: 0.00007601, Avg batch loss: 0.0075, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 1373, Step num: 13525, Learning rate: 0.00007600, Avg batch loss: 0.0069, Avg batch acc: 0.9905
Train, Epoch: 9, Batch: 1374, Step num: 13526, Learning rate: 0.00007600, Avg batch loss: 0.0056, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1375, Step num: 13527, Learning rate: 0.00007600, Avg batch loss: 0.0079, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1376, Step num: 13528, Learning rate: 0.00007599, Avg batch loss: 0.0067, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1377, Step num: 13529, Learning rate: 0.00007599, Avg batch loss: 0.0084, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1378, Step num: 13530, Learning rate: 0.00007599, Avg batch loss: 0.0079, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1379, Step num: 13531, Learning rate: 0.00007599, Avg batch loss: 0.0083, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1380, Step num: 13532, Learning rate: 0.00007598, Avg batch loss: 0.0079, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1381, Step num: 13533, Learning rate: 0.00007598, Avg batch loss: 0.0095, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 1382, Step num: 13534, Learning rate: 0.00007598, Avg batch loss: 0.0054, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1383, Step num: 13535, Learning rate: 0.00007597, Avg batch loss: 0.0080, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 1384, Step num: 13536, Learning rate: 0.00007597, Avg batch loss: 0.0081, Avg batch acc: 0.9914
Train, Epoch: 9, Batch: 1385, Step num: 13537, Learning rate: 0.00007597, Avg batch loss: 0.0068, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 1386, Step num: 13538, Learning rate: 0.00007597, Avg batch loss: 0.0113, Avg batch acc: 0.9902
Train, Epoch: 9, Batch: 1387, Step num: 13539, Learning rate: 0.00007596, Avg batch loss: 0.0071, Avg batch acc: 0.9932
Train, Epoch: 9, Batch: 1388, Step num: 13540, Learning rate: 0.00007596, Avg batch loss: 0.0059, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 1389, Step num: 13541, Learning rate: 0.00007596, Avg batch loss: 0.0085, Avg batch acc: 0.9887
Train, Epoch: 9, Batch: 1390, Step num: 13542, Learning rate: 0.00007595, Avg batch loss: 0.0067, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 1391, Step num: 13543, Learning rate: 0.00007595, Avg batch loss: 0.0067, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1392, Step num: 13544, Learning rate: 0.00007595, Avg batch loss: 0.0088, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1393, Step num: 13545, Learning rate: 0.00007595, Avg batch loss: 0.0065, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1394, Step num: 13546, Learning rate: 0.00007594, Avg batch loss: 0.0072, Avg batch acc: 0.9904
Train, Epoch: 9, Batch: 1395, Step num: 13547, Learning rate: 0.00007594, Avg batch loss: 0.0060, Avg batch acc: 0.9956
Train, Epoch: 9, Batch: 1396, Step num: 13548, Learning rate: 0.00007594, Avg batch loss: 0.0046, Avg batch acc: 0.9960
Train, Epoch: 9, Batch: 1397, Step num: 13549, Learning rate: 0.00007593, Avg batch loss: 0.0050, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 1398, Step num: 13550, Learning rate: 0.00007593, Avg batch loss: 0.0074, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1399, Step num: 13551, Learning rate: 0.00007593, Avg batch loss: 0.0080, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 1400, Step num: 13552, Learning rate: 0.00007593, Avg batch loss: 0.0052, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1401, Step num: 13553, Learning rate: 0.00007592, Avg batch loss: 0.0097, Avg batch acc: 0.9900
Train, Epoch: 9, Batch: 1402, Step num: 13554, Learning rate: 0.00007592, Avg batch loss: 0.0047, Avg batch acc: 0.9960
Train, Epoch: 9, Batch: 1403, Step num: 13555, Learning rate: 0.00007592, Avg batch loss: 0.0083, Avg batch acc: 0.9901
Train, Epoch: 9, Batch: 1404, Step num: 13556, Learning rate: 0.00007592, Avg batch loss: 0.0066, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1405, Step num: 13557, Learning rate: 0.00007591, Avg batch loss: 0.0058, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1406, Step num: 13558, Learning rate: 0.00007591, Avg batch loss: 0.0057, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1407, Step num: 13559, Learning rate: 0.00007591, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1408, Step num: 13560, Learning rate: 0.00007590, Avg batch loss: 0.0064, Avg batch acc: 0.9950
Train, Epoch: 9, Batch: 1409, Step num: 13561, Learning rate: 0.00007590, Avg batch loss: 0.0073, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1410, Step num: 13562, Learning rate: 0.00007590, Avg batch loss: 0.0071, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1411, Step num: 13563, Learning rate: 0.00007590, Avg batch loss: 0.0076, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1412, Step num: 13564, Learning rate: 0.00007589, Avg batch loss: 0.0063, Avg batch acc: 0.9961
Train, Epoch: 9, Batch: 1413, Step num: 13565, Learning rate: 0.00007589, Avg batch loss: 0.0055, Avg batch acc: 0.9953
Train, Epoch: 9, Batch: 1414, Step num: 13566, Learning rate: 0.00007589, Avg batch loss: 0.0062, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1415, Step num: 13567, Learning rate: 0.00007588, Avg batch loss: 0.0069, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1416, Step num: 13568, Learning rate: 0.00007588, Avg batch loss: 0.0050, Avg batch acc: 0.9962
Train, Epoch: 9, Batch: 1417, Step num: 13569, Learning rate: 0.00007588, Avg batch loss: 0.0084, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1418, Step num: 13570, Learning rate: 0.00007588, Avg batch loss: 0.0077, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 1419, Step num: 13571, Learning rate: 0.00007587, Avg batch loss: 0.0065, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1420, Step num: 13572, Learning rate: 0.00007587, Avg batch loss: 0.0051, Avg batch acc: 0.9967
Train, Epoch: 9, Batch: 1421, Step num: 13573, Learning rate: 0.00007587, Avg batch loss: 0.0054, Avg batch acc: 0.9959
Train, Epoch: 9, Batch: 1422, Step num: 13574, Learning rate: 0.00007586, Avg batch loss: 0.0081, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1423, Step num: 13575, Learning rate: 0.00007586, Avg batch loss: 0.0135, Avg batch acc: 0.9867
Train, Epoch: 9, Batch: 1424, Step num: 13576, Learning rate: 0.00007586, Avg batch loss: 0.0069, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1425, Step num: 13577, Learning rate: 0.00007586, Avg batch loss: 0.0046, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 1426, Step num: 13578, Learning rate: 0.00007585, Avg batch loss: 0.0067, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1427, Step num: 13579, Learning rate: 0.00007585, Avg batch loss: 0.0061, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1428, Step num: 13580, Learning rate: 0.00007585, Avg batch loss: 0.0043, Avg batch acc: 0.9943
Train, Epoch: 9, Batch: 1429, Step num: 13581, Learning rate: 0.00007585, Avg batch loss: 0.0048, Avg batch acc: 0.9962
Train, Epoch: 9, Batch: 1430, Step num: 13582, Learning rate: 0.00007584, Avg batch loss: 0.0052, Avg batch acc: 0.9959
Train, Epoch: 9, Batch: 1431, Step num: 13583, Learning rate: 0.00007584, Avg batch loss: 0.0081, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 1432, Step num: 13584, Learning rate: 0.00007584, Avg batch loss: 0.0064, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1433, Step num: 13585, Learning rate: 0.00007583, Avg batch loss: 0.0091, Avg batch acc: 0.9916
Train, Epoch: 9, Batch: 1434, Step num: 13586, Learning rate: 0.00007583, Avg batch loss: 0.0057, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1435, Step num: 13587, Learning rate: 0.00007583, Avg batch loss: 0.0069, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1436, Step num: 13588, Learning rate: 0.00007583, Avg batch loss: 0.0068, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1437, Step num: 13589, Learning rate: 0.00007582, Avg batch loss: 0.0047, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 1438, Step num: 13590, Learning rate: 0.00007582, Avg batch loss: 0.0079, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1439, Step num: 13591, Learning rate: 0.00007582, Avg batch loss: 0.0066, Avg batch acc: 0.9951
Train, Epoch: 9, Batch: 1440, Step num: 13592, Learning rate: 0.00007581, Avg batch loss: 0.0052, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1441, Step num: 13593, Learning rate: 0.00007581, Avg batch loss: 0.0055, Avg batch acc: 0.9945
Train, Epoch: 9, Batch: 1442, Step num: 13594, Learning rate: 0.00007581, Avg batch loss: 0.0055, Avg batch acc: 0.9947
Train, Epoch: 9, Batch: 1443, Step num: 13595, Learning rate: 0.00007581, Avg batch loss: 0.0072, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1444, Step num: 13596, Learning rate: 0.00007580, Avg batch loss: 0.0081, Avg batch acc: 0.9912
Train, Epoch: 9, Batch: 1445, Step num: 13597, Learning rate: 0.00007580, Avg batch loss: 0.0076, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 1446, Step num: 13598, Learning rate: 0.00007580, Avg batch loss: 0.0045, Avg batch acc: 0.9979
Train, Epoch: 9, Batch: 1447, Step num: 13599, Learning rate: 0.00007580, Avg batch loss: 0.0071, Avg batch acc: 0.9910
Train, Epoch: 9, Batch: 1448, Step num: 13600, Learning rate: 0.00007579, Avg batch loss: 0.0078, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1449, Step num: 13601, Learning rate: 0.00007579, Avg batch loss: 0.0060, Avg batch acc: 0.9933
Train, Epoch: 9, Batch: 1450, Step num: 13602, Learning rate: 0.00007579, Avg batch loss: 0.0066, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 1451, Step num: 13603, Learning rate: 0.00007578, Avg batch loss: 0.0070, Avg batch acc: 0.9915
Train, Epoch: 9, Batch: 1452, Step num: 13604, Learning rate: 0.00007578, Avg batch loss: 0.0080, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1453, Step num: 13605, Learning rate: 0.00007578, Avg batch loss: 0.0060, Avg batch acc: 0.9949
Train, Epoch: 9, Batch: 1454, Step num: 13606, Learning rate: 0.00007578, Avg batch loss: 0.0066, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 1455, Step num: 13607, Learning rate: 0.00007577, Avg batch loss: 0.0079, Avg batch acc: 0.9920
Train, Epoch: 9, Batch: 1456, Step num: 13608, Learning rate: 0.00007577, Avg batch loss: 0.0067, Avg batch acc: 0.9960
Train, Epoch: 9, Batch: 1457, Step num: 13609, Learning rate: 0.00007577, Avg batch loss: 0.0208, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 1458, Step num: 13610, Learning rate: 0.00007576, Avg batch loss: 0.0065, Avg batch acc: 0.9938
Train, Epoch: 9, Batch: 1459, Step num: 13611, Learning rate: 0.00007576, Avg batch loss: 0.0136, Avg batch acc: 0.9880
Train, Epoch: 9, Batch: 1460, Step num: 13612, Learning rate: 0.00007576, Avg batch loss: 0.0089, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 1461, Step num: 13613, Learning rate: 0.00007576, Avg batch loss: 0.0088, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 1462, Step num: 13614, Learning rate: 0.00007575, Avg batch loss: 0.0086, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 1463, Step num: 13615, Learning rate: 0.00007575, Avg batch loss: 0.0107, Avg batch acc: 0.9893
Train, Epoch: 9, Batch: 1464, Step num: 13616, Learning rate: 0.00007575, Avg batch loss: 0.0066, Avg batch acc: 0.9942
Train, Epoch: 9, Batch: 1465, Step num: 13617, Learning rate: 0.00007575, Avg batch loss: 0.0067, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1466, Step num: 13618, Learning rate: 0.00007574, Avg batch loss: 0.0052, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1467, Step num: 13619, Learning rate: 0.00007574, Avg batch loss: 0.0064, Avg batch acc: 0.9927
Train, Epoch: 9, Batch: 1468, Step num: 13620, Learning rate: 0.00007574, Avg batch loss: 0.0083, Avg batch acc: 0.9908
Train, Epoch: 9, Batch: 1469, Step num: 13621, Learning rate: 0.00007573, Avg batch loss: 0.0067, Avg batch acc: 0.9929
Train, Epoch: 9, Batch: 1470, Step num: 13622, Learning rate: 0.00007573, Avg batch loss: 0.0085, Avg batch acc: 0.9940
Train, Epoch: 9, Batch: 1471, Step num: 13623, Learning rate: 0.00007573, Avg batch loss: 0.0087, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 1472, Step num: 13624, Learning rate: 0.00007573, Avg batch loss: 0.0064, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1473, Step num: 13625, Learning rate: 0.00007572, Avg batch loss: 0.0055, Avg batch acc: 0.9965
Train, Epoch: 9, Batch: 1474, Step num: 13626, Learning rate: 0.00007572, Avg batch loss: 0.0062, Avg batch acc: 0.9957
Train, Epoch: 9, Batch: 1475, Step num: 13627, Learning rate: 0.00007572, Avg batch loss: 0.0090, Avg batch acc: 0.9892
Train, Epoch: 9, Batch: 1476, Step num: 13628, Learning rate: 0.00007571, Avg batch loss: 0.0085, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1477, Step num: 13629, Learning rate: 0.00007571, Avg batch loss: 0.0061, Avg batch acc: 0.9937
Train, Epoch: 9, Batch: 1478, Step num: 13630, Learning rate: 0.00007571, Avg batch loss: 0.0059, Avg batch acc: 0.9930
Train, Epoch: 9, Batch: 1479, Step num: 13631, Learning rate: 0.00007571, Avg batch loss: 0.0090, Avg batch acc: 0.9897
Train, Epoch: 9, Batch: 1480, Step num: 13632, Learning rate: 0.00007570, Avg batch loss: 0.0084, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 1481, Step num: 13633, Learning rate: 0.00007570, Avg batch loss: 0.0052, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 1482, Step num: 13634, Learning rate: 0.00007570, Avg batch loss: 0.0054, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1483, Step num: 13635, Learning rate: 0.00007570, Avg batch loss: 0.0068, Avg batch acc: 0.9907
Train, Epoch: 9, Batch: 1484, Step num: 13636, Learning rate: 0.00007569, Avg batch loss: 0.0076, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 1485, Step num: 13637, Learning rate: 0.00007569, Avg batch loss: 0.0065, Avg batch acc: 0.9958
Train, Epoch: 9, Batch: 1486, Step num: 13638, Learning rate: 0.00007569, Avg batch loss: 0.0069, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1487, Step num: 13639, Learning rate: 0.00007568, Avg batch loss: 0.0070, Avg batch acc: 0.9941
Train, Epoch: 9, Batch: 1488, Step num: 13640, Learning rate: 0.00007568, Avg batch loss: 0.0082, Avg batch acc: 0.9917
Train, Epoch: 9, Batch: 1489, Step num: 13641, Learning rate: 0.00007568, Avg batch loss: 0.0091, Avg batch acc: 0.9906
Train, Epoch: 9, Batch: 1490, Step num: 13642, Learning rate: 0.00007568, Avg batch loss: 0.0075, Avg batch acc: 0.9918
Train, Epoch: 9, Batch: 1491, Step num: 13643, Learning rate: 0.00007567, Avg batch loss: 0.0061, Avg batch acc: 0.9928
Train, Epoch: 9, Batch: 1492, Step num: 13644, Learning rate: 0.00007567, Avg batch loss: 0.0079, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1493, Step num: 13645, Learning rate: 0.00007567, Avg batch loss: 0.0067, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1494, Step num: 13646, Learning rate: 0.00007566, Avg batch loss: 0.0054, Avg batch acc: 0.9934
Train, Epoch: 9, Batch: 1495, Step num: 13647, Learning rate: 0.00007566, Avg batch loss: 0.0080, Avg batch acc: 0.9922
Train, Epoch: 9, Batch: 1496, Step num: 13648, Learning rate: 0.00007566, Avg batch loss: 0.0093, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1497, Step num: 13649, Learning rate: 0.00007566, Avg batch loss: 0.0071, Avg batch acc: 0.9936
Train, Epoch: 9, Batch: 1498, Step num: 13650, Learning rate: 0.00007565, Avg batch loss: 0.0069, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 1499, Step num: 13651, Learning rate: 0.00007565, Avg batch loss: 0.0057, Avg batch acc: 0.9948
Train, Epoch: 9, Batch: 1500, Step num: 13652, Learning rate: 0.00007565, Avg batch loss: 0.0077, Avg batch acc: 0.9944
Train, Epoch: 9, Batch: 1501, Step num: 13653, Learning rate: 0.00007565, Avg batch loss: 0.0042, Avg batch acc: 0.9962
Train, Epoch: 9, Batch: 1502, Step num: 13654, Learning rate: 0.00007564, Avg batch loss: 0.0048, Avg batch acc: 0.9952
Train, Epoch: 9, Batch: 1503, Step num: 13655, Learning rate: 0.00007564, Avg batch loss: 0.0063, Avg batch acc: 0.9884
Train, Epoch: 9, Batch: 1504, Step num: 13656, Learning rate: 0.00007564, Avg batch loss: 0.0068, Avg batch acc: 0.9939
Train, Epoch: 9, Batch: 1505, Step num: 13657, Learning rate: 0.00007563, Avg batch loss: 0.0070, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1506, Step num: 13658, Learning rate: 0.00007563, Avg batch loss: 0.0073, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 1507, Step num: 13659, Learning rate: 0.00007563, Avg batch loss: 0.0076, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1508, Step num: 13660, Learning rate: 0.00007563, Avg batch loss: 0.0081, Avg batch acc: 0.9919
Train, Epoch: 9, Batch: 1509, Step num: 13661, Learning rate: 0.00007562, Avg batch loss: 0.0067, Avg batch acc: 0.9935
Train, Epoch: 9, Batch: 1510, Step num: 13662, Learning rate: 0.00007562, Avg batch loss: 0.0069, Avg batch acc: 0.9926
Train, Epoch: 9, Batch: 1511, Step num: 13663, Learning rate: 0.00007562, Avg batch loss: 0.0037, Avg batch acc: 0.9982
Train, Epoch: 9, Batch: 1512, Step num: 13664, Learning rate: 0.00007561, Avg batch loss: 0.0059, Avg batch acc: 0.9923
Train, Epoch: 9, Batch: 1513, Step num: 13665, Learning rate: 0.00007561, Avg batch loss: 0.0073, Avg batch acc: 0.9924
Train, Epoch: 9, Batch: 1514, Step num: 13666, Learning rate: 0.00007561, Avg batch loss: 0.0076, Avg batch acc: 0.9913
Train, Epoch: 9, Batch: 1515, Step num: 13667, Learning rate: 0.00007561, Avg batch loss: 0.0066, Avg batch acc: 0.9921
Train, Epoch: 9, Batch: 1516, Step num: 13668, Learning rate: 0.00007560, Avg batch loss: 0.0076, Avg batch acc: 0.9891
Train, Epoch: 9, Batch: 1517, Step num: 13669, Learning rate: 0.00007560, Avg batch loss: 0.0057, Avg batch acc: 0.9931
Train, Epoch: 9, Batch: 1518, Step num: 13670, Learning rate: 0.00007560, Avg batch loss: 0.0075, Avg batch acc: 0.9925
Train, Epoch: 9, Batch: 1519, Step num: 13671, Learning rate: 0.00007560, Avg batch loss: 0.0052, Avg batch acc: 0.9941
Train, Epoch: 9, Avg epoch loss: 0.0080, Avg epoch acc: 0.9924, Overall time: 965.7 s, Speed: 4507.4 tokens/s on cuda:1

Validate, Epoch: 9, Batch: 1, Avg batch loss: 0.0056, Avg batch acc: 0.9951
Validate, Epoch: 9, Batch: 2, Avg batch loss: 0.0054, Avg batch acc: 0.9948
Validate, Epoch: 9, Batch: 3, Avg batch loss: 0.0088, Avg batch acc: 0.9935
Validate, Epoch: 9, Batch: 4, Avg batch loss: 0.0066, Avg batch acc: 0.9941
Validate, Epoch: 9, Batch: 5, Avg batch loss: 0.0084, Avg batch acc: 0.9915
Validate, Epoch: 9, Batch: 6, Avg batch loss: 0.0055, Avg batch acc: 0.9948
Validate, Epoch: 9, Batch: 7, Avg batch loss: 0.0067, Avg batch acc: 0.9946
Validate, Epoch: 9, Batch: 8, Avg batch loss: 0.0067, Avg batch acc: 0.9932
Validate, Epoch: 9, Batch: 9, Avg batch loss: 0.0047, Avg batch acc: 0.9965
Validate, Epoch: 9, Batch: 10, Avg batch loss: 0.0068, Avg batch acc: 0.9923
Validate, Epoch: 9, Batch: 11, Avg batch loss: 0.0057, Avg batch acc: 0.9950
Validate, Epoch: 9, Batch: 12, Avg batch loss: 0.0077, Avg batch acc: 0.9922
Validate, Epoch: 9, Batch: 13, Avg batch loss: 0.0077, Avg batch acc: 0.9900
Validate, Epoch: 9, Batch: 14, Avg batch loss: 0.0063, Avg batch acc: 0.9928
Validate, Epoch: 9, Batch: 15, Avg batch loss: 0.0070, Avg batch acc: 0.9941
Validate, Epoch: 9, Batch: 16, Avg batch loss: 0.0053, Avg batch acc: 0.9947
Validate, Epoch: 9, Batch: 17, Avg batch loss: 0.0058, Avg batch acc: 0.9953
Validate, Epoch: 9, Batch: 18, Avg batch loss: 0.0079, Avg batch acc: 0.9925
Validate, Epoch: 9, Batch: 19, Avg batch loss: 0.0073, Avg batch acc: 0.9931
Validate, Epoch: 9, Batch: 20, Avg batch loss: 0.0053, Avg batch acc: 0.9962
Validate, Epoch: 9, Batch: 21, Avg batch loss: 0.0131, Avg batch acc: 0.9938
Validate, Epoch: 9, Batch: 22, Avg batch loss: 0.0059, Avg batch acc: 0.9935
Validate, Epoch: 9, Batch: 23, Avg batch loss: 0.0054, Avg batch acc: 0.9949
Validate, Epoch: 9, Batch: 24, Avg batch loss: 0.0056, Avg batch acc: 0.9939
Validate, Epoch: 9, Batch: 25, Avg batch loss: 0.0068, Avg batch acc: 0.9953
Validate, Epoch: 9, Batch: 26, Avg batch loss: 0.0074, Avg batch acc: 0.9935
Validate, Epoch: 9, Batch: 27, Avg batch loss: 0.0078, Avg batch acc: 0.9937
Validate, Epoch: 9, Batch: 28, Avg batch loss: 0.0054, Avg batch acc: 0.9932
Validate, Epoch: 9, Batch: 29, Avg batch loss: 0.0071, Avg batch acc: 0.9937
Validate, Epoch: 9, Batch: 30, Avg batch loss: 0.0079, Avg batch acc: 0.9922
Validate, Epoch: 9, Batch: 31, Avg batch loss: 0.0043, Avg batch acc: 0.9965
Validate, Epoch: 9, Batch: 32, Avg batch loss: 0.0034, Avg batch acc: 0.9953
Validate, Epoch: 9, Batch: 33, Avg batch loss: 0.0089, Avg batch acc: 0.9909
Validate, Epoch: 9, Batch: 34, Avg batch loss: 0.0075, Avg batch acc: 0.9934
Validate, Epoch: 9, Batch: 35, Avg batch loss: 0.0056, Avg batch acc: 0.9949
Validate, Epoch: 9, Batch: 36, Avg batch loss: 0.0057, Avg batch acc: 0.9913
Validate, Epoch: 9, Batch: 37, Avg batch loss: 0.0063, Avg batch acc: 0.9943
Validate, Epoch: 9, Batch: 38, Avg batch loss: 0.0073, Avg batch acc: 0.9925
Validate, Epoch: 9, Batch: 39, Avg batch loss: 0.0062, Avg batch acc: 0.9945
Validate, Epoch: 9, Batch: 40, Avg batch loss: 0.0072, Avg batch acc: 0.9922
Validate, Epoch: 9, Batch: 41, Avg batch loss: 0.0055, Avg batch acc: 0.9939
Validate, Epoch: 9, Batch: 42, Avg batch loss: 0.0093, Avg batch acc: 0.9910
Validate, Epoch: 9, Batch: 43, Avg batch loss: 0.0061, Avg batch acc: 0.9935
Validate, Epoch: 9, Batch: 44, Avg batch loss: 0.0065, Avg batch acc: 0.9938
Validate, Epoch: 9, Batch: 45, Avg batch loss: 0.0078, Avg batch acc: 0.9935
Validate, Epoch: 9, Batch: 46, Avg batch loss: 0.0060, Avg batch acc: 0.9961
Validate, Epoch: 9, Batch: 47, Avg batch loss: 0.0082, Avg batch acc: 0.9920
Validate, Epoch: 9, Batch: 48, Avg batch loss: 0.0082, Avg batch acc: 0.9927
Validate, Epoch: 9, Batch: 49, Avg batch loss: 0.0067, Avg batch acc: 0.9943
Validate, Epoch: 9, Batch: 50, Avg batch loss: 0.0070, Avg batch acc: 0.9929
Validate, Epoch: 9, Batch: 51, Avg batch loss: 0.0057, Avg batch acc: 0.9932
Validate, Epoch: 9, Batch: 52, Avg batch loss: 0.0064, Avg batch acc: 0.9952
Validate, Epoch: 9, Batch: 53, Avg batch loss: 0.0076, Avg batch acc: 0.9920
Validate, Epoch: 9, Batch: 54, Avg batch loss: 0.0067, Avg batch acc: 0.9934
Validate, Epoch: 9, Batch: 55, Avg batch loss: 0.0089, Avg batch acc: 0.9919
Validate, Epoch: 9, Batch: 56, Avg batch loss: 0.0072, Avg batch acc: 0.9943
Validate, Epoch: 9, Batch: 57, Avg batch loss: 0.0057, Avg batch acc: 0.9947
Validate, Epoch: 9, Batch: 58, Avg batch loss: 0.0072, Avg batch acc: 0.9936
Validate, Epoch: 9, Batch: 59, Avg batch loss: 0.0078, Avg batch acc: 0.9903
Validate, Epoch: 9, Batch: 60, Avg batch loss: 0.0065, Avg batch acc: 0.9932
Validate, Epoch: 9, Batch: 61, Avg batch loss: 0.0094, Avg batch acc: 0.9880
Validate, Epoch: 9, Batch: 62, Avg batch loss: 0.0065, Avg batch acc: 0.9945
Validate, Epoch: 9, Batch: 63, Avg batch loss: 0.0052, Avg batch acc: 0.9959
Validate, Epoch: 9, Batch: 64, Avg batch loss: 0.0066, Avg batch acc: 0.9930
Validate, Epoch: 9, Batch: 65, Avg batch loss: 0.0072, Avg batch acc: 0.9922
Validate, Epoch: 9, Batch: 66, Avg batch loss: 0.0052, Avg batch acc: 0.9917
Validate, Epoch: 9, Batch: 67, Avg batch loss: 0.0045, Avg batch acc: 0.9942
Validate, Epoch: 9, Batch: 68, Avg batch loss: 0.0046, Avg batch acc: 0.9963
Validate, Epoch: 9, Batch: 69, Avg batch loss: 0.0045, Avg batch acc: 0.9953
Validate, Epoch: 9, Batch: 70, Avg batch loss: 0.0077, Avg batch acc: 0.9934
Validate, Epoch: 9, Batch: 71, Avg batch loss: 0.0060, Avg batch acc: 0.9947
Validate, Epoch: 9, Batch: 72, Avg batch loss: 0.0067, Avg batch acc: 0.9946
Validate, Epoch: 9, Batch: 73, Avg batch loss: 0.0067, Avg batch acc: 0.9936
Validate, Epoch: 9, Batch: 74, Avg batch loss: 0.0092, Avg batch acc: 0.9893
Validate, Epoch: 9, Batch: 75, Avg batch loss: 0.0055, Avg batch acc: 0.9956
Validate, Epoch: 9, Batch: 76, Avg batch loss: 0.0073, Avg batch acc: 0.9911
Validate, Epoch: 9, Batch: 77, Avg batch loss: 0.0066, Avg batch acc: 0.9937
Validate, Epoch: 9, Batch: 78, Avg batch loss: 0.0077, Avg batch acc: 0.9927
Validate, Epoch: 9, Batch: 79, Avg batch loss: 0.0055, Avg batch acc: 0.9946
Validate, Epoch: 9, Batch: 80, Avg batch loss: 0.0066, Avg batch acc: 0.9946
Validate, Epoch: 9, Batch: 81, Avg batch loss: 0.0057, Avg batch acc: 0.9962
Validate, Epoch: 9, Batch: 82, Avg batch loss: 0.0053, Avg batch acc: 0.9942
Validate, Epoch: 9, Batch: 83, Avg batch loss: 0.0044, Avg batch acc: 0.9971
Validate, Epoch: 9, Batch: 84, Avg batch loss: 0.0042, Avg batch acc: 0.9966
Validate, Epoch: 9, Batch: 85, Avg batch loss: 0.0074, Avg batch acc: 0.9915
Validate, Epoch: 9, Batch: 86, Avg batch loss: 0.0062, Avg batch acc: 0.9957
Validate, Epoch: 9, Batch: 87, Avg batch loss: 0.0058, Avg batch acc: 0.9934
Validate, Epoch: 9, Batch: 88, Avg batch loss: 0.0061, Avg batch acc: 0.9936
Validate, Epoch: 9, Batch: 89, Avg batch loss: 0.0093, Avg batch acc: 0.9899
Validate, Epoch: 9, Batch: 90, Avg batch loss: 0.0073, Avg batch acc: 0.9930
Validate, Epoch: 9, Batch: 91, Avg batch loss: 0.0093, Avg batch acc: 0.9930
Validate, Epoch: 9, Batch: 92, Avg batch loss: 0.0075, Avg batch acc: 0.9942
Validate, Epoch: 9, Batch: 93, Avg batch loss: 0.0064, Avg batch acc: 0.9918
Validate, Epoch: 9, Batch: 94, Avg batch loss: 0.0121, Avg batch acc: 0.9924
Validate, Epoch: 9, Batch: 95, Avg batch loss: 0.0082, Avg batch acc: 0.9937
Validate, Epoch: 9, Batch: 96, Avg batch loss: 0.0058, Avg batch acc: 0.9933
Validate, Epoch: 9, Batch: 97, Avg batch loss: 0.0081, Avg batch acc: 0.9900
Validate, Epoch: 9, Batch: 98, Avg batch loss: 0.0045, Avg batch acc: 0.9960
Validate, Epoch: 9, Batch: 99, Avg batch loss: 0.0066, Avg batch acc: 0.9917
Validate, Epoch: 9, Batch: 100, Avg batch loss: 0.0050, Avg batch acc: 0.9905
Validate, Epoch: 9, Batch: 101, Avg batch loss: 0.0077, Avg batch acc: 0.9931
Validate, Epoch: 9, Batch: 102, Avg batch loss: 0.0063, Avg batch acc: 0.9958
Validate, Epoch: 9, Batch: 103, Avg batch loss: 0.0069, Avg batch acc: 0.9936
Validate, Epoch: 9, Batch: 104, Avg batch loss: 0.0052, Avg batch acc: 0.9957
Validate, Epoch: 9, Batch: 105, Avg batch loss: 0.0060, Avg batch acc: 0.9938
Validate, Epoch: 9, Batch: 106, Avg batch loss: 0.0062, Avg batch acc: 0.9958
Validate, Epoch: 9, Batch: 107, Avg batch loss: 0.0058, Avg batch acc: 0.9941
Validate, Epoch: 9, Batch: 108, Avg batch loss: 0.0061, Avg batch acc: 0.9945
Validate, Epoch: 9, Batch: 109, Avg batch loss: 0.0057, Avg batch acc: 0.9927
Validate, Epoch: 9, Batch: 110, Avg batch loss: 0.0120, Avg batch acc: 0.9894
Validate, Epoch: 9, Batch: 111, Avg batch loss: 0.0096, Avg batch acc: 0.9906
Validate, Epoch: 9, Batch: 112, Avg batch loss: 0.0051, Avg batch acc: 0.9950
Validate, Epoch: 9, Batch: 113, Avg batch loss: 0.0072, Avg batch acc: 0.9912
Validate, Epoch: 9, Batch: 114, Avg batch loss: 0.0059, Avg batch acc: 0.9955
Validate, Epoch: 9, Batch: 115, Avg batch loss: 0.0081, Avg batch acc: 0.9906
Validate, Epoch: 9, Batch: 116, Avg batch loss: 0.0067, Avg batch acc: 0.9936
Validate, Epoch: 9, Batch: 117, Avg batch loss: 0.0076, Avg batch acc: 0.9924
Validate, Epoch: 9, Batch: 118, Avg batch loss: 0.0049, Avg batch acc: 0.9950
Validate, Epoch: 9, Batch: 119, Avg batch loss: 0.0051, Avg batch acc: 0.9950
Validate, Epoch: 9, Batch: 120, Avg batch loss: 0.0085, Avg batch acc: 0.9898
Validate, Epoch: 9, Batch: 121, Avg batch loss: 0.0071, Avg batch acc: 0.9941
Validate, Epoch: 9, Batch: 122, Avg batch loss: 0.0057, Avg batch acc: 0.9943
Validate, Epoch: 9, Batch: 123, Avg batch loss: 0.0078, Avg batch acc: 0.9920
Validate, Epoch: 9, Batch: 124, Avg batch loss: 0.0071, Avg batch acc: 0.9920
Validate, Epoch: 9, Batch: 125, Avg batch loss: 0.0058, Avg batch acc: 0.9953
Validate, Epoch: 9, Batch: 126, Avg batch loss: 0.0072, Avg batch acc: 0.9941
Validate, Epoch: 9, Batch: 127, Avg batch loss: 0.0051, Avg batch acc: 0.9942
Validate, Epoch: 9, Batch: 128, Avg batch loss: 0.0046, Avg batch acc: 0.9933
Validate, Epoch: 9, Batch: 129, Avg batch loss: 0.0065, Avg batch acc: 0.9940
Validate, Epoch: 9, Batch: 130, Avg batch loss: 0.0080, Avg batch acc: 0.9914
Validate, Epoch: 9, Batch: 131, Avg batch loss: 0.0048, Avg batch acc: 0.9957
Validate, Epoch: 9, Batch: 132, Avg batch loss: 0.0069, Avg batch acc: 0.9959
Validate, Epoch: 9, Batch: 133, Avg batch loss: 0.0058, Avg batch acc: 0.9931
Validate, Epoch: 9, Batch: 134, Avg batch loss: 0.0056, Avg batch acc: 0.9950
Validate, Epoch: 9, Batch: 135, Avg batch loss: 0.0185, Avg batch acc: 0.9912
Validate, Epoch: 9, Batch: 136, Avg batch loss: 0.0076, Avg batch acc: 0.9933
Validate, Epoch: 9, Batch: 137, Avg batch loss: 0.0058, Avg batch acc: 0.9941
Validate, Epoch: 9, Batch: 138, Avg batch loss: 0.0061, Avg batch acc: 0.9929
Validate, Epoch: 9, Batch: 139, Avg batch loss: 0.0072, Avg batch acc: 0.9921
Validate, Epoch: 9, Batch: 140, Avg batch loss: 0.0068, Avg batch acc: 0.9938
Validate, Epoch: 9, Batch: 141, Avg batch loss: 0.0066, Avg batch acc: 0.9930
Validate, Epoch: 9, Batch: 142, Avg batch loss: 0.0065, Avg batch acc: 0.9942
Validate, Epoch: 9, Batch: 143, Avg batch loss: 0.0078, Avg batch acc: 0.9905
Validate, Epoch: 9, Batch: 144, Avg batch loss: 0.0064, Avg batch acc: 0.9934
Validate, Epoch: 9, Batch: 145, Avg batch loss: 0.0079, Avg batch acc: 0.9899
Validate, Epoch: 9, Batch: 146, Avg batch loss: 0.0078, Avg batch acc: 0.9918
Validate, Epoch: 9, Batch: 147, Avg batch loss: 0.0078, Avg batch acc: 0.9939
Validate, Epoch: 9, Batch: 148, Avg batch loss: 0.0078, Avg batch acc: 0.9940
Validate, Epoch: 9, Batch: 149, Avg batch loss: 0.0059, Avg batch acc: 0.9943
Validate, Epoch: 9, Batch: 150, Avg batch loss: 0.0049, Avg batch acc: 0.9943
Validate, Epoch: 9, Batch: 151, Avg batch loss: 0.0070, Avg batch acc: 0.9921
Validate, Epoch: 9, Batch: 152, Avg batch loss: 0.0069, Avg batch acc: 0.9936
Validate, Epoch: 9, Batch: 153, Avg batch loss: 0.0080, Avg batch acc: 0.9945
Validate, Epoch: 9, Batch: 154, Avg batch loss: 0.0059, Avg batch acc: 0.9931
Validate, Epoch: 9, Batch: 155, Avg batch loss: 0.0061, Avg batch acc: 0.9944
Validate, Epoch: 9, Batch: 156, Avg batch loss: 0.0095, Avg batch acc: 0.9899
Validate, Epoch: 9, Batch: 157, Avg batch loss: 0.0068, Avg batch acc: 0.9941
Validate, Epoch: 9, Batch: 158, Avg batch loss: 0.0070, Avg batch acc: 0.9927
Validate, Epoch: 9, Batch: 159, Avg batch loss: 0.0114, Avg batch acc: 0.9930
Validate, Epoch: 9, Batch: 160, Avg batch loss: 0.0063, Avg batch acc: 0.9935
Validate, Epoch: 9, Batch: 161, Avg batch loss: 0.0065, Avg batch acc: 0.9945
Validate, Epoch: 9, Batch: 162, Avg batch loss: 0.0068, Avg batch acc: 0.9918
Validate, Epoch: 9, Batch: 163, Avg batch loss: 0.0071, Avg batch acc: 0.9932
Validate, Epoch: 9, Batch: 164, Avg batch loss: 0.0104, Avg batch acc: 0.9924
Validate, Epoch: 9, Batch: 165, Avg batch loss: 0.0062, Avg batch acc: 0.9928
Validate, Epoch: 9, Batch: 166, Avg batch loss: 0.0066, Avg batch acc: 0.9935
Validate, Epoch: 9, Batch: 167, Avg batch loss: 0.0083, Avg batch acc: 0.9897
Validate, Epoch: 9, Batch: 168, Avg batch loss: 0.0044, Avg batch acc: 0.9956
Validate, Epoch: 9, Batch: 169, Avg batch loss: 0.0067, Avg batch acc: 0.9946
Validate, Epoch: 9, Avg epoch loss: 0.0068, Avg epoch acc: 0.9934, Overall time: 38.3 s, Speed: 12600.2 tokens/s on cuda:1

Train, Epoch: 10, Batch: 1, Step num: 13672, Learning rate: 0.00007559, Avg batch loss: 0.0073, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 2, Step num: 13673, Learning rate: 0.00007559, Avg batch loss: 0.0041, Avg batch acc: 0.9978
Train, Epoch: 10, Batch: 3, Step num: 13674, Learning rate: 0.00007559, Avg batch loss: 0.0055, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 4, Step num: 13675, Learning rate: 0.00007558, Avg batch loss: 0.0061, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 5, Step num: 13676, Learning rate: 0.00007558, Avg batch loss: 0.0055, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 6, Step num: 13677, Learning rate: 0.00007558, Avg batch loss: 0.0054, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 7, Step num: 13678, Learning rate: 0.00007558, Avg batch loss: 0.0058, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 8, Step num: 13679, Learning rate: 0.00007557, Avg batch loss: 0.0087, Avg batch acc: 0.9916
Train, Epoch: 10, Batch: 9, Step num: 13680, Learning rate: 0.00007557, Avg batch loss: 0.0049, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 10, Step num: 13681, Learning rate: 0.00007557, Avg batch loss: 0.0044, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 11, Step num: 13682, Learning rate: 0.00007556, Avg batch loss: 0.0054, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 12, Step num: 13683, Learning rate: 0.00007556, Avg batch loss: 0.0070, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 13, Step num: 13684, Learning rate: 0.00007556, Avg batch loss: 0.0068, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 14, Step num: 13685, Learning rate: 0.00007556, Avg batch loss: 0.0060, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 15, Step num: 13686, Learning rate: 0.00007555, Avg batch loss: 0.0053, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 16, Step num: 13687, Learning rate: 0.00007555, Avg batch loss: 0.0084, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 17, Step num: 13688, Learning rate: 0.00007555, Avg batch loss: 0.0083, Avg batch acc: 0.9912
Train, Epoch: 10, Batch: 18, Step num: 13689, Learning rate: 0.00007555, Avg batch loss: 0.0059, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 19, Step num: 13690, Learning rate: 0.00007554, Avg batch loss: 0.0057, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 20, Step num: 13691, Learning rate: 0.00007554, Avg batch loss: 0.0050, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 21, Step num: 13692, Learning rate: 0.00007554, Avg batch loss: 0.0052, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 22, Step num: 13693, Learning rate: 0.00007553, Avg batch loss: 0.0048, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 23, Step num: 13694, Learning rate: 0.00007553, Avg batch loss: 0.0060, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 24, Step num: 13695, Learning rate: 0.00007553, Avg batch loss: 0.0044, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 25, Step num: 13696, Learning rate: 0.00007553, Avg batch loss: 0.0056, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 26, Step num: 13697, Learning rate: 0.00007552, Avg batch loss: 0.0063, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 27, Step num: 13698, Learning rate: 0.00007552, Avg batch loss: 0.0054, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 28, Step num: 13699, Learning rate: 0.00007552, Avg batch loss: 0.0066, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 29, Step num: 13700, Learning rate: 0.00007552, Avg batch loss: 0.0079, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 30, Step num: 13701, Learning rate: 0.00007551, Avg batch loss: 0.0057, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 31, Step num: 13702, Learning rate: 0.00007551, Avg batch loss: 0.0043, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 32, Step num: 13703, Learning rate: 0.00007551, Avg batch loss: 0.0065, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 33, Step num: 13704, Learning rate: 0.00007550, Avg batch loss: 0.0083, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 34, Step num: 13705, Learning rate: 0.00007550, Avg batch loss: 0.0066, Avg batch acc: 0.9903
Train, Epoch: 10, Batch: 35, Step num: 13706, Learning rate: 0.00007550, Avg batch loss: 0.0060, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 36, Step num: 13707, Learning rate: 0.00007550, Avg batch loss: 0.0072, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 37, Step num: 13708, Learning rate: 0.00007549, Avg batch loss: 0.0061, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 38, Step num: 13709, Learning rate: 0.00007549, Avg batch loss: 0.0048, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 39, Step num: 13710, Learning rate: 0.00007549, Avg batch loss: 0.0064, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 40, Step num: 13711, Learning rate: 0.00007548, Avg batch loss: 0.0076, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 41, Step num: 13712, Learning rate: 0.00007548, Avg batch loss: 0.0056, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 42, Step num: 13713, Learning rate: 0.00007548, Avg batch loss: 0.0050, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 43, Step num: 13714, Learning rate: 0.00007548, Avg batch loss: 0.0058, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 44, Step num: 13715, Learning rate: 0.00007547, Avg batch loss: 0.0065, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 45, Step num: 13716, Learning rate: 0.00007547, Avg batch loss: 0.0053, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 46, Step num: 13717, Learning rate: 0.00007547, Avg batch loss: 0.0058, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 47, Step num: 13718, Learning rate: 0.00007547, Avg batch loss: 0.0058, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 48, Step num: 13719, Learning rate: 0.00007546, Avg batch loss: 0.0051, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 49, Step num: 13720, Learning rate: 0.00007546, Avg batch loss: 0.0048, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 50, Step num: 13721, Learning rate: 0.00007546, Avg batch loss: 0.0067, Avg batch acc: 0.9917
Train, Epoch: 10, Batch: 51, Step num: 13722, Learning rate: 0.00007545, Avg batch loss: 0.0038, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 52, Step num: 13723, Learning rate: 0.00007545, Avg batch loss: 0.0040, Avg batch acc: 0.9973
Train, Epoch: 10, Batch: 53, Step num: 13724, Learning rate: 0.00007545, Avg batch loss: 0.0063, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 54, Step num: 13725, Learning rate: 0.00007545, Avg batch loss: 0.0057, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 55, Step num: 13726, Learning rate: 0.00007544, Avg batch loss: 0.0059, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 56, Step num: 13727, Learning rate: 0.00007544, Avg batch loss: 0.0063, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 57, Step num: 13728, Learning rate: 0.00007544, Avg batch loss: 0.0073, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 58, Step num: 13729, Learning rate: 0.00007544, Avg batch loss: 0.0056, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 59, Step num: 13730, Learning rate: 0.00007543, Avg batch loss: 0.0060, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 60, Step num: 13731, Learning rate: 0.00007543, Avg batch loss: 0.0064, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 61, Step num: 13732, Learning rate: 0.00007543, Avg batch loss: 0.0056, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 62, Step num: 13733, Learning rate: 0.00007542, Avg batch loss: 0.0054, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 63, Step num: 13734, Learning rate: 0.00007542, Avg batch loss: 0.0082, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 64, Step num: 13735, Learning rate: 0.00007542, Avg batch loss: 0.0082, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 65, Step num: 13736, Learning rate: 0.00007542, Avg batch loss: 0.0060, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 66, Step num: 13737, Learning rate: 0.00007541, Avg batch loss: 0.0069, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 67, Step num: 13738, Learning rate: 0.00007541, Avg batch loss: 0.0087, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 68, Step num: 13739, Learning rate: 0.00007541, Avg batch loss: 0.0077, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 69, Step num: 13740, Learning rate: 0.00007541, Avg batch loss: 0.0044, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 70, Step num: 13741, Learning rate: 0.00007540, Avg batch loss: 0.0073, Avg batch acc: 0.9902
Train, Epoch: 10, Batch: 71, Step num: 13742, Learning rate: 0.00007540, Avg batch loss: 0.0075, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 72, Step num: 13743, Learning rate: 0.00007540, Avg batch loss: 0.0073, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 73, Step num: 13744, Learning rate: 0.00007539, Avg batch loss: 0.0042, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 74, Step num: 13745, Learning rate: 0.00007539, Avg batch loss: 0.0042, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 75, Step num: 13746, Learning rate: 0.00007539, Avg batch loss: 0.0071, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 76, Step num: 13747, Learning rate: 0.00007539, Avg batch loss: 0.0070, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 77, Step num: 13748, Learning rate: 0.00007538, Avg batch loss: 0.0095, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 78, Step num: 13749, Learning rate: 0.00007538, Avg batch loss: 0.0050, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 79, Step num: 13750, Learning rate: 0.00007538, Avg batch loss: 0.0058, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 80, Step num: 13751, Learning rate: 0.00007538, Avg batch loss: 0.0065, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 81, Step num: 13752, Learning rate: 0.00007537, Avg batch loss: 0.0071, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 82, Step num: 13753, Learning rate: 0.00007537, Avg batch loss: 0.0053, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 83, Step num: 13754, Learning rate: 0.00007537, Avg batch loss: 0.0061, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 84, Step num: 13755, Learning rate: 0.00007536, Avg batch loss: 0.0067, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 85, Step num: 13756, Learning rate: 0.00007536, Avg batch loss: 0.0072, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 86, Step num: 13757, Learning rate: 0.00007536, Avg batch loss: 0.0080, Avg batch acc: 0.9886
Train, Epoch: 10, Batch: 87, Step num: 13758, Learning rate: 0.00007536, Avg batch loss: 0.0062, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 88, Step num: 13759, Learning rate: 0.00007535, Avg batch loss: 0.0061, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 89, Step num: 13760, Learning rate: 0.00007535, Avg batch loss: 0.0055, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 90, Step num: 13761, Learning rate: 0.00007535, Avg batch loss: 0.0064, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 91, Step num: 13762, Learning rate: 0.00007534, Avg batch loss: 0.0059, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 92, Step num: 13763, Learning rate: 0.00007534, Avg batch loss: 0.0056, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 93, Step num: 13764, Learning rate: 0.00007534, Avg batch loss: 0.0050, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 94, Step num: 13765, Learning rate: 0.00007534, Avg batch loss: 0.0079, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 95, Step num: 13766, Learning rate: 0.00007533, Avg batch loss: 0.0065, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 96, Step num: 13767, Learning rate: 0.00007533, Avg batch loss: 0.0152, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 97, Step num: 13768, Learning rate: 0.00007533, Avg batch loss: 0.0200, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 98, Step num: 13769, Learning rate: 0.00007533, Avg batch loss: 0.0076, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 99, Step num: 13770, Learning rate: 0.00007532, Avg batch loss: 0.0076, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 100, Step num: 13771, Learning rate: 0.00007532, Avg batch loss: 0.0075, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 101, Step num: 13772, Learning rate: 0.00007532, Avg batch loss: 0.0063, Avg batch acc: 0.9898
Train, Epoch: 10, Batch: 102, Step num: 13773, Learning rate: 0.00007531, Avg batch loss: 0.0073, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 103, Step num: 13774, Learning rate: 0.00007531, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 104, Step num: 13775, Learning rate: 0.00007531, Avg batch loss: 0.0061, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 105, Step num: 13776, Learning rate: 0.00007531, Avg batch loss: 0.0049, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 106, Step num: 13777, Learning rate: 0.00007530, Avg batch loss: 0.0053, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 107, Step num: 13778, Learning rate: 0.00007530, Avg batch loss: 0.0070, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 108, Step num: 13779, Learning rate: 0.00007530, Avg batch loss: 0.0071, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 109, Step num: 13780, Learning rate: 0.00007530, Avg batch loss: 0.0060, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 110, Step num: 13781, Learning rate: 0.00007529, Avg batch loss: 0.0066, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 111, Step num: 13782, Learning rate: 0.00007529, Avg batch loss: 0.0071, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 112, Step num: 13783, Learning rate: 0.00007529, Avg batch loss: 0.0079, Avg batch acc: 0.9916
Train, Epoch: 10, Batch: 113, Step num: 13784, Learning rate: 0.00007528, Avg batch loss: 0.0080, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 114, Step num: 13785, Learning rate: 0.00007528, Avg batch loss: 0.0053, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 115, Step num: 13786, Learning rate: 0.00007528, Avg batch loss: 0.0041, Avg batch acc: 0.9973
Train, Epoch: 10, Batch: 116, Step num: 13787, Learning rate: 0.00007528, Avg batch loss: 0.0082, Avg batch acc: 0.9890
Train, Epoch: 10, Batch: 117, Step num: 13788, Learning rate: 0.00007527, Avg batch loss: 0.0062, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 118, Step num: 13789, Learning rate: 0.00007527, Avg batch loss: 0.0070, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 119, Step num: 13790, Learning rate: 0.00007527, Avg batch loss: 0.0068, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 120, Step num: 13791, Learning rate: 0.00007527, Avg batch loss: 0.0074, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 121, Step num: 13792, Learning rate: 0.00007526, Avg batch loss: 0.0068, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 122, Step num: 13793, Learning rate: 0.00007526, Avg batch loss: 0.0077, Avg batch acc: 0.9918
Train, Epoch: 10, Batch: 123, Step num: 13794, Learning rate: 0.00007526, Avg batch loss: 0.0071, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 124, Step num: 13795, Learning rate: 0.00007525, Avg batch loss: 0.0055, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 125, Step num: 13796, Learning rate: 0.00007525, Avg batch loss: 0.0067, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 126, Step num: 13797, Learning rate: 0.00007525, Avg batch loss: 0.0055, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 127, Step num: 13798, Learning rate: 0.00007525, Avg batch loss: 0.0054, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 128, Step num: 13799, Learning rate: 0.00007524, Avg batch loss: 0.0045, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 129, Step num: 13800, Learning rate: 0.00007524, Avg batch loss: 0.0087, Avg batch acc: 0.9918
Train, Epoch: 10, Batch: 130, Step num: 13801, Learning rate: 0.00007524, Avg batch loss: 0.0055, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 131, Step num: 13802, Learning rate: 0.00007524, Avg batch loss: 0.0070, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 132, Step num: 13803, Learning rate: 0.00007523, Avg batch loss: 0.0076, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 133, Step num: 13804, Learning rate: 0.00007523, Avg batch loss: 0.0105, Avg batch acc: 0.9894
Train, Epoch: 10, Batch: 134, Step num: 13805, Learning rate: 0.00007523, Avg batch loss: 0.0059, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 135, Step num: 13806, Learning rate: 0.00007522, Avg batch loss: 0.0097, Avg batch acc: 0.9884
Train, Epoch: 10, Batch: 136, Step num: 13807, Learning rate: 0.00007522, Avg batch loss: 0.0060, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 137, Step num: 13808, Learning rate: 0.00007522, Avg batch loss: 0.0057, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 138, Step num: 13809, Learning rate: 0.00007522, Avg batch loss: 0.0073, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 139, Step num: 13810, Learning rate: 0.00007521, Avg batch loss: 0.0058, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 140, Step num: 13811, Learning rate: 0.00007521, Avg batch loss: 0.0207, Avg batch acc: 0.9894
Train, Epoch: 10, Batch: 141, Step num: 13812, Learning rate: 0.00007521, Avg batch loss: 0.0049, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 142, Step num: 13813, Learning rate: 0.00007521, Avg batch loss: 0.0057, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 143, Step num: 13814, Learning rate: 0.00007520, Avg batch loss: 0.0075, Avg batch acc: 0.9903
Train, Epoch: 10, Batch: 144, Step num: 13815, Learning rate: 0.00007520, Avg batch loss: 0.0055, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 145, Step num: 13816, Learning rate: 0.00007520, Avg batch loss: 0.0070, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 146, Step num: 13817, Learning rate: 0.00007519, Avg batch loss: 0.0387, Avg batch acc: 0.9893
Train, Epoch: 10, Batch: 147, Step num: 13818, Learning rate: 0.00007519, Avg batch loss: 0.0065, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 148, Step num: 13819, Learning rate: 0.00007519, Avg batch loss: 0.0051, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 149, Step num: 13820, Learning rate: 0.00007519, Avg batch loss: 0.0183, Avg batch acc: 0.9892
Train, Epoch: 10, Batch: 150, Step num: 13821, Learning rate: 0.00007518, Avg batch loss: 0.0073, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 151, Step num: 13822, Learning rate: 0.00007518, Avg batch loss: 0.0055, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 152, Step num: 13823, Learning rate: 0.00007518, Avg batch loss: 0.0070, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 153, Step num: 13824, Learning rate: 0.00007518, Avg batch loss: 0.0076, Avg batch acc: 0.9909
Train, Epoch: 10, Batch: 154, Step num: 13825, Learning rate: 0.00007517, Avg batch loss: 0.0087, Avg batch acc: 0.9904
Train, Epoch: 10, Batch: 155, Step num: 13826, Learning rate: 0.00007517, Avg batch loss: 0.0042, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 156, Step num: 13827, Learning rate: 0.00007517, Avg batch loss: 0.0058, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 157, Step num: 13828, Learning rate: 0.00007516, Avg batch loss: 0.0127, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 158, Step num: 13829, Learning rate: 0.00007516, Avg batch loss: 0.0057, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 159, Step num: 13830, Learning rate: 0.00007516, Avg batch loss: 0.0090, Avg batch acc: 0.9900
Train, Epoch: 10, Batch: 160, Step num: 13831, Learning rate: 0.00007516, Avg batch loss: 0.0059, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 161, Step num: 13832, Learning rate: 0.00007515, Avg batch loss: 0.0070, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 162, Step num: 13833, Learning rate: 0.00007515, Avg batch loss: 0.0076, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 163, Step num: 13834, Learning rate: 0.00007515, Avg batch loss: 0.0046, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 164, Step num: 13835, Learning rate: 0.00007515, Avg batch loss: 0.0070, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 165, Step num: 13836, Learning rate: 0.00007514, Avg batch loss: 0.0057, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 166, Step num: 13837, Learning rate: 0.00007514, Avg batch loss: 0.0078, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 167, Step num: 13838, Learning rate: 0.00007514, Avg batch loss: 0.0066, Avg batch acc: 0.9908
Train, Epoch: 10, Batch: 168, Step num: 13839, Learning rate: 0.00007514, Avg batch loss: 0.0099, Avg batch acc: 0.9909
Train, Epoch: 10, Batch: 169, Step num: 13840, Learning rate: 0.00007513, Avg batch loss: 0.0076, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 170, Step num: 13841, Learning rate: 0.00007513, Avg batch loss: 0.0086, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 171, Step num: 13842, Learning rate: 0.00007513, Avg batch loss: 0.0079, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 172, Step num: 13843, Learning rate: 0.00007512, Avg batch loss: 0.0064, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 173, Step num: 13844, Learning rate: 0.00007512, Avg batch loss: 0.0077, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 174, Step num: 13845, Learning rate: 0.00007512, Avg batch loss: 0.0040, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 175, Step num: 13846, Learning rate: 0.00007512, Avg batch loss: 0.0046, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 176, Step num: 13847, Learning rate: 0.00007511, Avg batch loss: 0.0051, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 177, Step num: 13848, Learning rate: 0.00007511, Avg batch loss: 0.0067, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 178, Step num: 13849, Learning rate: 0.00007511, Avg batch loss: 0.0046, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 179, Step num: 13850, Learning rate: 0.00007511, Avg batch loss: 0.0049, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 180, Step num: 13851, Learning rate: 0.00007510, Avg batch loss: 0.0040, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 181, Step num: 13852, Learning rate: 0.00007510, Avg batch loss: 0.0041, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 182, Step num: 13853, Learning rate: 0.00007510, Avg batch loss: 0.0069, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 183, Step num: 13854, Learning rate: 0.00007509, Avg batch loss: 0.0075, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 184, Step num: 13855, Learning rate: 0.00007509, Avg batch loss: 0.0060, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 185, Step num: 13856, Learning rate: 0.00007509, Avg batch loss: 0.0049, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 186, Step num: 13857, Learning rate: 0.00007509, Avg batch loss: 0.0067, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 187, Step num: 13858, Learning rate: 0.00007508, Avg batch loss: 0.0075, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 188, Step num: 13859, Learning rate: 0.00007508, Avg batch loss: 0.0059, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 189, Step num: 13860, Learning rate: 0.00007508, Avg batch loss: 0.0054, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 190, Step num: 13861, Learning rate: 0.00007508, Avg batch loss: 0.0047, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 191, Step num: 13862, Learning rate: 0.00007507, Avg batch loss: 0.0066, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 192, Step num: 13863, Learning rate: 0.00007507, Avg batch loss: 0.0073, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 193, Step num: 13864, Learning rate: 0.00007507, Avg batch loss: 0.0054, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 194, Step num: 13865, Learning rate: 0.00007506, Avg batch loss: 0.0060, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 195, Step num: 13866, Learning rate: 0.00007506, Avg batch loss: 0.0041, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 196, Step num: 13867, Learning rate: 0.00007506, Avg batch loss: 0.0054, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 197, Step num: 13868, Learning rate: 0.00007506, Avg batch loss: 0.0055, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 198, Step num: 13869, Learning rate: 0.00007505, Avg batch loss: 0.0050, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 199, Step num: 13870, Learning rate: 0.00007505, Avg batch loss: 0.0070, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 200, Step num: 13871, Learning rate: 0.00007505, Avg batch loss: 0.0041, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 201, Step num: 13872, Learning rate: 0.00007505, Avg batch loss: 0.0055, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 202, Step num: 13873, Learning rate: 0.00007504, Avg batch loss: 0.0073, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 203, Step num: 13874, Learning rate: 0.00007504, Avg batch loss: 0.0059, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 204, Step num: 13875, Learning rate: 0.00007504, Avg batch loss: 0.0046, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 205, Step num: 13876, Learning rate: 0.00007503, Avg batch loss: 0.0066, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 206, Step num: 13877, Learning rate: 0.00007503, Avg batch loss: 0.0064, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 207, Step num: 13878, Learning rate: 0.00007503, Avg batch loss: 0.0070, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 208, Step num: 13879, Learning rate: 0.00007503, Avg batch loss: 0.0046, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 209, Step num: 13880, Learning rate: 0.00007502, Avg batch loss: 0.0065, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 210, Step num: 13881, Learning rate: 0.00007502, Avg batch loss: 0.0053, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 211, Step num: 13882, Learning rate: 0.00007502, Avg batch loss: 0.0066, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 212, Step num: 13883, Learning rate: 0.00007502, Avg batch loss: 0.0068, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 213, Step num: 13884, Learning rate: 0.00007501, Avg batch loss: 0.0069, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 214, Step num: 13885, Learning rate: 0.00007501, Avg batch loss: 0.0068, Avg batch acc: 0.9909
Train, Epoch: 10, Batch: 215, Step num: 13886, Learning rate: 0.00007501, Avg batch loss: 0.0066, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 216, Step num: 13887, Learning rate: 0.00007501, Avg batch loss: 0.0064, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 217, Step num: 13888, Learning rate: 0.00007500, Avg batch loss: 0.0055, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 218, Step num: 13889, Learning rate: 0.00007500, Avg batch loss: 0.0063, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 219, Step num: 13890, Learning rate: 0.00007500, Avg batch loss: 0.0075, Avg batch acc: 0.9912
Train, Epoch: 10, Batch: 220, Step num: 13891, Learning rate: 0.00007499, Avg batch loss: 0.0075, Avg batch acc: 0.9916
Train, Epoch: 10, Batch: 221, Step num: 13892, Learning rate: 0.00007499, Avg batch loss: 0.0062, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 222, Step num: 13893, Learning rate: 0.00007499, Avg batch loss: 0.0076, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 223, Step num: 13894, Learning rate: 0.00007499, Avg batch loss: 0.0061, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 224, Step num: 13895, Learning rate: 0.00007498, Avg batch loss: 0.0062, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 225, Step num: 13896, Learning rate: 0.00007498, Avg batch loss: 0.0067, Avg batch acc: 0.9918
Train, Epoch: 10, Batch: 226, Step num: 13897, Learning rate: 0.00007498, Avg batch loss: 0.0066, Avg batch acc: 0.9917
Train, Epoch: 10, Batch: 227, Step num: 13898, Learning rate: 0.00007498, Avg batch loss: 0.0042, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 228, Step num: 13899, Learning rate: 0.00007497, Avg batch loss: 0.0048, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 229, Step num: 13900, Learning rate: 0.00007497, Avg batch loss: 0.0058, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 230, Step num: 13901, Learning rate: 0.00007497, Avg batch loss: 0.0107, Avg batch acc: 0.9904
Train, Epoch: 10, Batch: 231, Step num: 13902, Learning rate: 0.00007496, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 232, Step num: 13903, Learning rate: 0.00007496, Avg batch loss: 0.0064, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 233, Step num: 13904, Learning rate: 0.00007496, Avg batch loss: 0.0059, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 234, Step num: 13905, Learning rate: 0.00007496, Avg batch loss: 0.0058, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 235, Step num: 13906, Learning rate: 0.00007495, Avg batch loss: 0.0061, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 236, Step num: 13907, Learning rate: 0.00007495, Avg batch loss: 0.0053, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 237, Step num: 13908, Learning rate: 0.00007495, Avg batch loss: 0.0049, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 238, Step num: 13909, Learning rate: 0.00007495, Avg batch loss: 0.0050, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 239, Step num: 13910, Learning rate: 0.00007494, Avg batch loss: 0.0074, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 240, Step num: 13911, Learning rate: 0.00007494, Avg batch loss: 0.0081, Avg batch acc: 0.9917
Train, Epoch: 10, Batch: 241, Step num: 13912, Learning rate: 0.00007494, Avg batch loss: 0.0054, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 242, Step num: 13913, Learning rate: 0.00007493, Avg batch loss: 0.0080, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 243, Step num: 13914, Learning rate: 0.00007493, Avg batch loss: 0.0062, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 244, Step num: 13915, Learning rate: 0.00007493, Avg batch loss: 0.0057, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 245, Step num: 13916, Learning rate: 0.00007493, Avg batch loss: 0.0059, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 246, Step num: 13917, Learning rate: 0.00007492, Avg batch loss: 0.0057, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 247, Step num: 13918, Learning rate: 0.00007492, Avg batch loss: 0.0065, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 248, Step num: 13919, Learning rate: 0.00007492, Avg batch loss: 0.0086, Avg batch acc: 0.9905
Train, Epoch: 10, Batch: 249, Step num: 13920, Learning rate: 0.00007492, Avg batch loss: 0.0061, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 250, Step num: 13921, Learning rate: 0.00007491, Avg batch loss: 0.0076, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 251, Step num: 13922, Learning rate: 0.00007491, Avg batch loss: 0.0057, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 252, Step num: 13923, Learning rate: 0.00007491, Avg batch loss: 0.0060, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 253, Step num: 13924, Learning rate: 0.00007491, Avg batch loss: 0.0037, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 254, Step num: 13925, Learning rate: 0.00007490, Avg batch loss: 0.0055, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 255, Step num: 13926, Learning rate: 0.00007490, Avg batch loss: 0.0052, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 256, Step num: 13927, Learning rate: 0.00007490, Avg batch loss: 0.0057, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 257, Step num: 13928, Learning rate: 0.00007489, Avg batch loss: 0.0059, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 258, Step num: 13929, Learning rate: 0.00007489, Avg batch loss: 0.0071, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 259, Step num: 13930, Learning rate: 0.00007489, Avg batch loss: 0.0073, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 260, Step num: 13931, Learning rate: 0.00007489, Avg batch loss: 0.0059, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 261, Step num: 13932, Learning rate: 0.00007488, Avg batch loss: 0.0067, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 262, Step num: 13933, Learning rate: 0.00007488, Avg batch loss: 0.0044, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 263, Step num: 13934, Learning rate: 0.00007488, Avg batch loss: 0.0072, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 264, Step num: 13935, Learning rate: 0.00007488, Avg batch loss: 0.0074, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 265, Step num: 13936, Learning rate: 0.00007487, Avg batch loss: 0.0068, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 266, Step num: 13937, Learning rate: 0.00007487, Avg batch loss: 0.0074, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 267, Step num: 13938, Learning rate: 0.00007487, Avg batch loss: 0.0076, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 268, Step num: 13939, Learning rate: 0.00007487, Avg batch loss: 0.0082, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 269, Step num: 13940, Learning rate: 0.00007486, Avg batch loss: 0.0060, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 270, Step num: 13941, Learning rate: 0.00007486, Avg batch loss: 0.0100, Avg batch acc: 0.9903
Train, Epoch: 10, Batch: 271, Step num: 13942, Learning rate: 0.00007486, Avg batch loss: 0.0058, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 272, Step num: 13943, Learning rate: 0.00007485, Avg batch loss: 0.0052, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 273, Step num: 13944, Learning rate: 0.00007485, Avg batch loss: 0.0067, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 274, Step num: 13945, Learning rate: 0.00007485, Avg batch loss: 0.0044, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 275, Step num: 13946, Learning rate: 0.00007485, Avg batch loss: 0.0059, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 276, Step num: 13947, Learning rate: 0.00007484, Avg batch loss: 0.0088, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 277, Step num: 13948, Learning rate: 0.00007484, Avg batch loss: 0.0062, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 278, Step num: 13949, Learning rate: 0.00007484, Avg batch loss: 0.0048, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 279, Step num: 13950, Learning rate: 0.00007484, Avg batch loss: 0.0059, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 280, Step num: 13951, Learning rate: 0.00007483, Avg batch loss: 0.0063, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 281, Step num: 13952, Learning rate: 0.00007483, Avg batch loss: 0.0068, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 282, Step num: 13953, Learning rate: 0.00007483, Avg batch loss: 0.0058, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 283, Step num: 13954, Learning rate: 0.00007482, Avg batch loss: 0.0059, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 284, Step num: 13955, Learning rate: 0.00007482, Avg batch loss: 0.0039, Avg batch acc: 0.9974
Train, Epoch: 10, Batch: 285, Step num: 13956, Learning rate: 0.00007482, Avg batch loss: 0.0067, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 286, Step num: 13957, Learning rate: 0.00007482, Avg batch loss: 0.0051, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 287, Step num: 13958, Learning rate: 0.00007481, Avg batch loss: 0.0054, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 288, Step num: 13959, Learning rate: 0.00007481, Avg batch loss: 0.0053, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 289, Step num: 13960, Learning rate: 0.00007481, Avg batch loss: 0.0071, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 290, Step num: 13961, Learning rate: 0.00007481, Avg batch loss: 0.0061, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 291, Step num: 13962, Learning rate: 0.00007480, Avg batch loss: 0.0089, Avg batch acc: 0.9904
Train, Epoch: 10, Batch: 292, Step num: 13963, Learning rate: 0.00007480, Avg batch loss: 0.0063, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 293, Step num: 13964, Learning rate: 0.00007480, Avg batch loss: 0.0085, Avg batch acc: 0.9895
Train, Epoch: 10, Batch: 294, Step num: 13965, Learning rate: 0.00007480, Avg batch loss: 0.0080, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 295, Step num: 13966, Learning rate: 0.00007479, Avg batch loss: 0.0062, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 296, Step num: 13967, Learning rate: 0.00007479, Avg batch loss: 0.0072, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 297, Step num: 13968, Learning rate: 0.00007479, Avg batch loss: 0.0063, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 298, Step num: 13969, Learning rate: 0.00007478, Avg batch loss: 0.0152, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 299, Step num: 13970, Learning rate: 0.00007478, Avg batch loss: 0.0071, Avg batch acc: 0.9893
Train, Epoch: 10, Batch: 300, Step num: 13971, Learning rate: 0.00007478, Avg batch loss: 0.0064, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 301, Step num: 13972, Learning rate: 0.00007478, Avg batch loss: 0.0048, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 302, Step num: 13973, Learning rate: 0.00007477, Avg batch loss: 0.0075, Avg batch acc: 0.9915
Train, Epoch: 10, Batch: 303, Step num: 13974, Learning rate: 0.00007477, Avg batch loss: 0.0070, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 304, Step num: 13975, Learning rate: 0.00007477, Avg batch loss: 0.0066, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 305, Step num: 13976, Learning rate: 0.00007477, Avg batch loss: 0.0049, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 306, Step num: 13977, Learning rate: 0.00007476, Avg batch loss: 0.0057, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 307, Step num: 13978, Learning rate: 0.00007476, Avg batch loss: 0.0047, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 308, Step num: 13979, Learning rate: 0.00007476, Avg batch loss: 0.0066, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 309, Step num: 13980, Learning rate: 0.00007476, Avg batch loss: 0.0049, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 310, Step num: 13981, Learning rate: 0.00007475, Avg batch loss: 0.0064, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 311, Step num: 13982, Learning rate: 0.00007475, Avg batch loss: 0.0061, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 312, Step num: 13983, Learning rate: 0.00007475, Avg batch loss: 0.0049, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 313, Step num: 13984, Learning rate: 0.00007474, Avg batch loss: 0.0052, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 314, Step num: 13985, Learning rate: 0.00007474, Avg batch loss: 0.0050, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 315, Step num: 13986, Learning rate: 0.00007474, Avg batch loss: 0.0066, Avg batch acc: 0.9904
Train, Epoch: 10, Batch: 316, Step num: 13987, Learning rate: 0.00007474, Avg batch loss: 0.0052, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 317, Step num: 13988, Learning rate: 0.00007473, Avg batch loss: 0.0044, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 318, Step num: 13989, Learning rate: 0.00007473, Avg batch loss: 0.0067, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 319, Step num: 13990, Learning rate: 0.00007473, Avg batch loss: 0.0046, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 320, Step num: 13991, Learning rate: 0.00007473, Avg batch loss: 0.0064, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 321, Step num: 13992, Learning rate: 0.00007472, Avg batch loss: 0.0057, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 322, Step num: 13993, Learning rate: 0.00007472, Avg batch loss: 0.0047, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 323, Step num: 13994, Learning rate: 0.00007472, Avg batch loss: 0.0064, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 324, Step num: 13995, Learning rate: 0.00007472, Avg batch loss: 0.0063, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 325, Step num: 13996, Learning rate: 0.00007471, Avg batch loss: 0.0061, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 326, Step num: 13997, Learning rate: 0.00007471, Avg batch loss: 0.0058, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 327, Step num: 13998, Learning rate: 0.00007471, Avg batch loss: 0.0050, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 328, Step num: 13999, Learning rate: 0.00007470, Avg batch loss: 0.0054, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 329, Step num: 14000, Learning rate: 0.00007470, Avg batch loss: 0.0069, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 330, Step num: 14001, Learning rate: 0.00007470, Avg batch loss: 0.0087, Avg batch acc: 0.9918
Train, Epoch: 10, Batch: 331, Step num: 14002, Learning rate: 0.00007470, Avg batch loss: 0.0061, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 332, Step num: 14003, Learning rate: 0.00007469, Avg batch loss: 0.0063, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 333, Step num: 14004, Learning rate: 0.00007469, Avg batch loss: 0.0057, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 334, Step num: 14005, Learning rate: 0.00007469, Avg batch loss: 0.0082, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 335, Step num: 14006, Learning rate: 0.00007469, Avg batch loss: 0.0053, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 336, Step num: 14007, Learning rate: 0.00007468, Avg batch loss: 0.0037, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 337, Step num: 14008, Learning rate: 0.00007468, Avg batch loss: 0.0064, Avg batch acc: 0.9906
Train, Epoch: 10, Batch: 338, Step num: 14009, Learning rate: 0.00007468, Avg batch loss: 0.0051, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 339, Step num: 14010, Learning rate: 0.00007468, Avg batch loss: 0.0037, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 340, Step num: 14011, Learning rate: 0.00007467, Avg batch loss: 0.0068, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 341, Step num: 14012, Learning rate: 0.00007467, Avg batch loss: 0.0060, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 342, Step num: 14013, Learning rate: 0.00007467, Avg batch loss: 0.0050, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 343, Step num: 14014, Learning rate: 0.00007466, Avg batch loss: 0.0076, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 344, Step num: 14015, Learning rate: 0.00007466, Avg batch loss: 0.0057, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 345, Step num: 14016, Learning rate: 0.00007466, Avg batch loss: 0.0075, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 346, Step num: 14017, Learning rate: 0.00007466, Avg batch loss: 0.0051, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 347, Step num: 14018, Learning rate: 0.00007465, Avg batch loss: 0.0066, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 348, Step num: 14019, Learning rate: 0.00007465, Avg batch loss: 0.0065, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 349, Step num: 14020, Learning rate: 0.00007465, Avg batch loss: 0.0054, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 350, Step num: 14021, Learning rate: 0.00007465, Avg batch loss: 0.0064, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 351, Step num: 14022, Learning rate: 0.00007464, Avg batch loss: 0.0041, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 352, Step num: 14023, Learning rate: 0.00007464, Avg batch loss: 0.0041, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 353, Step num: 14024, Learning rate: 0.00007464, Avg batch loss: 0.0051, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 354, Step num: 14025, Learning rate: 0.00007464, Avg batch loss: 0.0069, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 355, Step num: 14026, Learning rate: 0.00007463, Avg batch loss: 0.0050, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 356, Step num: 14027, Learning rate: 0.00007463, Avg batch loss: 0.0074, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 357, Step num: 14028, Learning rate: 0.00007463, Avg batch loss: 0.0048, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 358, Step num: 14029, Learning rate: 0.00007462, Avg batch loss: 0.0073, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 359, Step num: 14030, Learning rate: 0.00007462, Avg batch loss: 0.0051, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 360, Step num: 14031, Learning rate: 0.00007462, Avg batch loss: 0.0055, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 361, Step num: 14032, Learning rate: 0.00007462, Avg batch loss: 0.0049, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 362, Step num: 14033, Learning rate: 0.00007461, Avg batch loss: 0.0050, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 363, Step num: 14034, Learning rate: 0.00007461, Avg batch loss: 0.0073, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 364, Step num: 14035, Learning rate: 0.00007461, Avg batch loss: 0.0063, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 365, Step num: 14036, Learning rate: 0.00007461, Avg batch loss: 0.0046, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 366, Step num: 14037, Learning rate: 0.00007460, Avg batch loss: 0.0051, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 367, Step num: 14038, Learning rate: 0.00007460, Avg batch loss: 0.0054, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 368, Step num: 14039, Learning rate: 0.00007460, Avg batch loss: 0.0056, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 369, Step num: 14040, Learning rate: 0.00007460, Avg batch loss: 0.0061, Avg batch acc: 0.9908
Train, Epoch: 10, Batch: 370, Step num: 14041, Learning rate: 0.00007459, Avg batch loss: 0.0065, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 371, Step num: 14042, Learning rate: 0.00007459, Avg batch loss: 0.0086, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 372, Step num: 14043, Learning rate: 0.00007459, Avg batch loss: 0.0049, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 373, Step num: 14044, Learning rate: 0.00007458, Avg batch loss: 0.0056, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 374, Step num: 14045, Learning rate: 0.00007458, Avg batch loss: 0.0060, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 375, Step num: 14046, Learning rate: 0.00007458, Avg batch loss: 0.0053, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 376, Step num: 14047, Learning rate: 0.00007458, Avg batch loss: 0.0048, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 377, Step num: 14048, Learning rate: 0.00007457, Avg batch loss: 0.0099, Avg batch acc: 0.9903
Train, Epoch: 10, Batch: 378, Step num: 14049, Learning rate: 0.00007457, Avg batch loss: 0.0066, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 379, Step num: 14050, Learning rate: 0.00007457, Avg batch loss: 0.0073, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 380, Step num: 14051, Learning rate: 0.00007457, Avg batch loss: 0.0064, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 381, Step num: 14052, Learning rate: 0.00007456, Avg batch loss: 0.0046, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 382, Step num: 14053, Learning rate: 0.00007456, Avg batch loss: 0.0062, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 383, Step num: 14054, Learning rate: 0.00007456, Avg batch loss: 0.0053, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 384, Step num: 14055, Learning rate: 0.00007456, Avg batch loss: 0.0054, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 385, Step num: 14056, Learning rate: 0.00007455, Avg batch loss: 0.0061, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 386, Step num: 14057, Learning rate: 0.00007455, Avg batch loss: 0.0052, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 387, Step num: 14058, Learning rate: 0.00007455, Avg batch loss: 0.0066, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 388, Step num: 14059, Learning rate: 0.00007454, Avg batch loss: 0.0064, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 389, Step num: 14060, Learning rate: 0.00007454, Avg batch loss: 0.0094, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 390, Step num: 14061, Learning rate: 0.00007454, Avg batch loss: 0.0071, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 391, Step num: 14062, Learning rate: 0.00007454, Avg batch loss: 0.0074, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 392, Step num: 14063, Learning rate: 0.00007453, Avg batch loss: 0.0080, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 393, Step num: 14064, Learning rate: 0.00007453, Avg batch loss: 0.0047, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 394, Step num: 14065, Learning rate: 0.00007453, Avg batch loss: 0.0058, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 395, Step num: 14066, Learning rate: 0.00007453, Avg batch loss: 0.0059, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 396, Step num: 14067, Learning rate: 0.00007452, Avg batch loss: 0.0054, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 397, Step num: 14068, Learning rate: 0.00007452, Avg batch loss: 0.0094, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 398, Step num: 14069, Learning rate: 0.00007452, Avg batch loss: 0.0044, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 399, Step num: 14070, Learning rate: 0.00007452, Avg batch loss: 0.0066, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 400, Step num: 14071, Learning rate: 0.00007451, Avg batch loss: 0.0057, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 401, Step num: 14072, Learning rate: 0.00007451, Avg batch loss: 0.0050, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 402, Step num: 14073, Learning rate: 0.00007451, Avg batch loss: 0.0049, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 403, Step num: 14074, Learning rate: 0.00007451, Avg batch loss: 0.0074, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 404, Step num: 14075, Learning rate: 0.00007450, Avg batch loss: 0.0072, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 405, Step num: 14076, Learning rate: 0.00007450, Avg batch loss: 0.0074, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 406, Step num: 14077, Learning rate: 0.00007450, Avg batch loss: 0.0080, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 407, Step num: 14078, Learning rate: 0.00007449, Avg batch loss: 0.0054, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 408, Step num: 14079, Learning rate: 0.00007449, Avg batch loss: 0.0072, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 409, Step num: 14080, Learning rate: 0.00007449, Avg batch loss: 0.0055, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 410, Step num: 14081, Learning rate: 0.00007449, Avg batch loss: 0.0069, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 411, Step num: 14082, Learning rate: 0.00007448, Avg batch loss: 0.0044, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 412, Step num: 14083, Learning rate: 0.00007448, Avg batch loss: 0.0066, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 413, Step num: 14084, Learning rate: 0.00007448, Avg batch loss: 0.0066, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 414, Step num: 14085, Learning rate: 0.00007448, Avg batch loss: 0.0058, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 415, Step num: 14086, Learning rate: 0.00007447, Avg batch loss: 0.0073, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 416, Step num: 14087, Learning rate: 0.00007447, Avg batch loss: 0.0059, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 417, Step num: 14088, Learning rate: 0.00007447, Avg batch loss: 0.0063, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 418, Step num: 14089, Learning rate: 0.00007447, Avg batch loss: 0.0082, Avg batch acc: 0.9900
Train, Epoch: 10, Batch: 419, Step num: 14090, Learning rate: 0.00007446, Avg batch loss: 0.0060, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 420, Step num: 14091, Learning rate: 0.00007446, Avg batch loss: 0.0084, Avg batch acc: 0.9905
Train, Epoch: 10, Batch: 421, Step num: 14092, Learning rate: 0.00007446, Avg batch loss: 0.0051, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 422, Step num: 14093, Learning rate: 0.00007445, Avg batch loss: 0.0059, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 423, Step num: 14094, Learning rate: 0.00007445, Avg batch loss: 0.0046, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 424, Step num: 14095, Learning rate: 0.00007445, Avg batch loss: 0.0060, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 425, Step num: 14096, Learning rate: 0.00007445, Avg batch loss: 0.0040, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 426, Step num: 14097, Learning rate: 0.00007444, Avg batch loss: 0.0044, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 427, Step num: 14098, Learning rate: 0.00007444, Avg batch loss: 0.0067, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 428, Step num: 14099, Learning rate: 0.00007444, Avg batch loss: 0.0061, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 429, Step num: 14100, Learning rate: 0.00007444, Avg batch loss: 0.0070, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 430, Step num: 14101, Learning rate: 0.00007443, Avg batch loss: 0.0048, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 431, Step num: 14102, Learning rate: 0.00007443, Avg batch loss: 0.0058, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 432, Step num: 14103, Learning rate: 0.00007443, Avg batch loss: 0.0050, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 433, Step num: 14104, Learning rate: 0.00007443, Avg batch loss: 0.0060, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 434, Step num: 14105, Learning rate: 0.00007442, Avg batch loss: 0.0056, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 435, Step num: 14106, Learning rate: 0.00007442, Avg batch loss: 0.0047, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 436, Step num: 14107, Learning rate: 0.00007442, Avg batch loss: 0.0071, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 437, Step num: 14108, Learning rate: 0.00007442, Avg batch loss: 0.0049, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 438, Step num: 14109, Learning rate: 0.00007441, Avg batch loss: 0.0074, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 439, Step num: 14110, Learning rate: 0.00007441, Avg batch loss: 0.0048, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 440, Step num: 14111, Learning rate: 0.00007441, Avg batch loss: 0.0058, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 441, Step num: 14112, Learning rate: 0.00007440, Avg batch loss: 0.0073, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 442, Step num: 14113, Learning rate: 0.00007440, Avg batch loss: 0.0046, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 443, Step num: 14114, Learning rate: 0.00007440, Avg batch loss: 0.0056, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 444, Step num: 14115, Learning rate: 0.00007440, Avg batch loss: 0.0054, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 445, Step num: 14116, Learning rate: 0.00007439, Avg batch loss: 0.0047, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 446, Step num: 14117, Learning rate: 0.00007439, Avg batch loss: 0.0064, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 447, Step num: 14118, Learning rate: 0.00007439, Avg batch loss: 0.0060, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 448, Step num: 14119, Learning rate: 0.00007439, Avg batch loss: 0.0049, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 449, Step num: 14120, Learning rate: 0.00007438, Avg batch loss: 0.0055, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 450, Step num: 14121, Learning rate: 0.00007438, Avg batch loss: 0.0070, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 451, Step num: 14122, Learning rate: 0.00007438, Avg batch loss: 0.0065, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 452, Step num: 14123, Learning rate: 0.00007438, Avg batch loss: 0.0050, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 453, Step num: 14124, Learning rate: 0.00007437, Avg batch loss: 0.0083, Avg batch acc: 0.9898
Train, Epoch: 10, Batch: 454, Step num: 14125, Learning rate: 0.00007437, Avg batch loss: 0.0049, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 455, Step num: 14126, Learning rate: 0.00007437, Avg batch loss: 0.0050, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 456, Step num: 14127, Learning rate: 0.00007437, Avg batch loss: 0.0068, Avg batch acc: 0.9911
Train, Epoch: 10, Batch: 457, Step num: 14128, Learning rate: 0.00007436, Avg batch loss: 0.0075, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 458, Step num: 14129, Learning rate: 0.00007436, Avg batch loss: 0.0043, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 459, Step num: 14130, Learning rate: 0.00007436, Avg batch loss: 0.0034, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 460, Step num: 14131, Learning rate: 0.00007435, Avg batch loss: 0.0054, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 461, Step num: 14132, Learning rate: 0.00007435, Avg batch loss: 0.0055, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 462, Step num: 14133, Learning rate: 0.00007435, Avg batch loss: 0.0047, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 463, Step num: 14134, Learning rate: 0.00007435, Avg batch loss: 0.0064, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 464, Step num: 14135, Learning rate: 0.00007434, Avg batch loss: 0.0056, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 465, Step num: 14136, Learning rate: 0.00007434, Avg batch loss: 0.0048, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 466, Step num: 14137, Learning rate: 0.00007434, Avg batch loss: 0.0060, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 467, Step num: 14138, Learning rate: 0.00007434, Avg batch loss: 0.0057, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 468, Step num: 14139, Learning rate: 0.00007433, Avg batch loss: 0.0145, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 469, Step num: 14140, Learning rate: 0.00007433, Avg batch loss: 0.0058, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 470, Step num: 14141, Learning rate: 0.00007433, Avg batch loss: 0.0058, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 471, Step num: 14142, Learning rate: 0.00007433, Avg batch loss: 0.0059, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 472, Step num: 14143, Learning rate: 0.00007432, Avg batch loss: 0.0071, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 473, Step num: 14144, Learning rate: 0.00007432, Avg batch loss: 0.0127, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 474, Step num: 14145, Learning rate: 0.00007432, Avg batch loss: 0.0061, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 475, Step num: 14146, Learning rate: 0.00007432, Avg batch loss: 0.0057, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 476, Step num: 14147, Learning rate: 0.00007431, Avg batch loss: 0.0067, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 477, Step num: 14148, Learning rate: 0.00007431, Avg batch loss: 0.0049, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 478, Step num: 14149, Learning rate: 0.00007431, Avg batch loss: 0.0073, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 479, Step num: 14150, Learning rate: 0.00007430, Avg batch loss: 0.0066, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 480, Step num: 14151, Learning rate: 0.00007430, Avg batch loss: 0.0044, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 481, Step num: 14152, Learning rate: 0.00007430, Avg batch loss: 0.0053, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 482, Step num: 14153, Learning rate: 0.00007430, Avg batch loss: 0.0057, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 483, Step num: 14154, Learning rate: 0.00007429, Avg batch loss: 0.0079, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 484, Step num: 14155, Learning rate: 0.00007429, Avg batch loss: 0.0049, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 485, Step num: 14156, Learning rate: 0.00007429, Avg batch loss: 0.0049, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 486, Step num: 14157, Learning rate: 0.00007429, Avg batch loss: 0.0043, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 487, Step num: 14158, Learning rate: 0.00007428, Avg batch loss: 0.0071, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 488, Step num: 14159, Learning rate: 0.00007428, Avg batch loss: 0.0047, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 489, Step num: 14160, Learning rate: 0.00007428, Avg batch loss: 0.0063, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 490, Step num: 14161, Learning rate: 0.00007428, Avg batch loss: 0.0056, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 491, Step num: 14162, Learning rate: 0.00007427, Avg batch loss: 0.0061, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 492, Step num: 14163, Learning rate: 0.00007427, Avg batch loss: 0.0065, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 493, Step num: 14164, Learning rate: 0.00007427, Avg batch loss: 0.0051, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 494, Step num: 14165, Learning rate: 0.00007427, Avg batch loss: 0.0060, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 495, Step num: 14166, Learning rate: 0.00007426, Avg batch loss: 0.0034, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 496, Step num: 14167, Learning rate: 0.00007426, Avg batch loss: 0.0069, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 497, Step num: 14168, Learning rate: 0.00007426, Avg batch loss: 0.0053, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 498, Step num: 14169, Learning rate: 0.00007425, Avg batch loss: 0.0049, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 499, Step num: 14170, Learning rate: 0.00007425, Avg batch loss: 0.0063, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 500, Step num: 14171, Learning rate: 0.00007425, Avg batch loss: 0.0050, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 501, Step num: 14172, Learning rate: 0.00007425, Avg batch loss: 0.0045, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 502, Step num: 14173, Learning rate: 0.00007424, Avg batch loss: 0.0057, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 503, Step num: 14174, Learning rate: 0.00007424, Avg batch loss: 0.0049, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 504, Step num: 14175, Learning rate: 0.00007424, Avg batch loss: 0.0055, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 505, Step num: 14176, Learning rate: 0.00007424, Avg batch loss: 0.0070, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 506, Step num: 14177, Learning rate: 0.00007423, Avg batch loss: 0.0070, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 507, Step num: 14178, Learning rate: 0.00007423, Avg batch loss: 0.0057, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 508, Step num: 14179, Learning rate: 0.00007423, Avg batch loss: 0.0057, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 509, Step num: 14180, Learning rate: 0.00007423, Avg batch loss: 0.0050, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 510, Step num: 14181, Learning rate: 0.00007422, Avg batch loss: 0.0069, Avg batch acc: 0.9916
Train, Epoch: 10, Batch: 511, Step num: 14182, Learning rate: 0.00007422, Avg batch loss: 0.0050, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 512, Step num: 14183, Learning rate: 0.00007422, Avg batch loss: 0.0038, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 513, Step num: 14184, Learning rate: 0.00007422, Avg batch loss: 0.0051, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 514, Step num: 14185, Learning rate: 0.00007421, Avg batch loss: 0.0059, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 515, Step num: 14186, Learning rate: 0.00007421, Avg batch loss: 0.0048, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 516, Step num: 14187, Learning rate: 0.00007421, Avg batch loss: 0.0046, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 517, Step num: 14188, Learning rate: 0.00007421, Avg batch loss: 0.0087, Avg batch acc: 0.9895
Train, Epoch: 10, Batch: 518, Step num: 14189, Learning rate: 0.00007420, Avg batch loss: 0.0072, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 519, Step num: 14190, Learning rate: 0.00007420, Avg batch loss: 0.0051, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 520, Step num: 14191, Learning rate: 0.00007420, Avg batch loss: 0.0059, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 521, Step num: 14192, Learning rate: 0.00007419, Avg batch loss: 0.0069, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 522, Step num: 14193, Learning rate: 0.00007419, Avg batch loss: 0.0060, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 523, Step num: 14194, Learning rate: 0.00007419, Avg batch loss: 0.0062, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 524, Step num: 14195, Learning rate: 0.00007419, Avg batch loss: 0.0077, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 525, Step num: 14196, Learning rate: 0.00007418, Avg batch loss: 0.0047, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 526, Step num: 14197, Learning rate: 0.00007418, Avg batch loss: 0.0066, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 527, Step num: 14198, Learning rate: 0.00007418, Avg batch loss: 0.0063, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 528, Step num: 14199, Learning rate: 0.00007418, Avg batch loss: 0.0055, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 529, Step num: 14200, Learning rate: 0.00007417, Avg batch loss: 0.0069, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 530, Step num: 14201, Learning rate: 0.00007417, Avg batch loss: 0.0039, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 531, Step num: 14202, Learning rate: 0.00007417, Avg batch loss: 0.0057, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 532, Step num: 14203, Learning rate: 0.00007417, Avg batch loss: 0.0052, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 533, Step num: 14204, Learning rate: 0.00007416, Avg batch loss: 0.0050, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 534, Step num: 14205, Learning rate: 0.00007416, Avg batch loss: 0.0068, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 535, Step num: 14206, Learning rate: 0.00007416, Avg batch loss: 0.0072, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 536, Step num: 14207, Learning rate: 0.00007416, Avg batch loss: 0.0050, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 537, Step num: 14208, Learning rate: 0.00007415, Avg batch loss: 0.0082, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 538, Step num: 14209, Learning rate: 0.00007415, Avg batch loss: 0.0061, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 539, Step num: 14210, Learning rate: 0.00007415, Avg batch loss: 0.0071, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 540, Step num: 14211, Learning rate: 0.00007415, Avg batch loss: 0.0068, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 541, Step num: 14212, Learning rate: 0.00007414, Avg batch loss: 0.0051, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 542, Step num: 14213, Learning rate: 0.00007414, Avg batch loss: 0.0075, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 543, Step num: 14214, Learning rate: 0.00007414, Avg batch loss: 0.0057, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 544, Step num: 14215, Learning rate: 0.00007413, Avg batch loss: 0.0037, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 545, Step num: 14216, Learning rate: 0.00007413, Avg batch loss: 0.0078, Avg batch acc: 0.9916
Train, Epoch: 10, Batch: 546, Step num: 14217, Learning rate: 0.00007413, Avg batch loss: 0.0060, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 547, Step num: 14218, Learning rate: 0.00007413, Avg batch loss: 0.0063, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 548, Step num: 14219, Learning rate: 0.00007412, Avg batch loss: 0.0088, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 549, Step num: 14220, Learning rate: 0.00007412, Avg batch loss: 0.0068, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 550, Step num: 14221, Learning rate: 0.00007412, Avg batch loss: 0.0045, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 551, Step num: 14222, Learning rate: 0.00007412, Avg batch loss: 0.0064, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 552, Step num: 14223, Learning rate: 0.00007411, Avg batch loss: 0.0066, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 553, Step num: 14224, Learning rate: 0.00007411, Avg batch loss: 0.0072, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 554, Step num: 14225, Learning rate: 0.00007411, Avg batch loss: 0.0069, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 555, Step num: 14226, Learning rate: 0.00007411, Avg batch loss: 0.0060, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 556, Step num: 14227, Learning rate: 0.00007410, Avg batch loss: 0.0061, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 557, Step num: 14228, Learning rate: 0.00007410, Avg batch loss: 0.0059, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 558, Step num: 14229, Learning rate: 0.00007410, Avg batch loss: 0.0058, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 559, Step num: 14230, Learning rate: 0.00007410, Avg batch loss: 0.0057, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 560, Step num: 14231, Learning rate: 0.00007409, Avg batch loss: 0.0052, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 561, Step num: 14232, Learning rate: 0.00007409, Avg batch loss: 0.0065, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 562, Step num: 14233, Learning rate: 0.00007409, Avg batch loss: 0.0084, Avg batch acc: 0.9913
Train, Epoch: 10, Batch: 563, Step num: 14234, Learning rate: 0.00007409, Avg batch loss: 0.0044, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 564, Step num: 14235, Learning rate: 0.00007408, Avg batch loss: 0.0055, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 565, Step num: 14236, Learning rate: 0.00007408, Avg batch loss: 0.0068, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 566, Step num: 14237, Learning rate: 0.00007408, Avg batch loss: 0.0058, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 567, Step num: 14238, Learning rate: 0.00007407, Avg batch loss: 0.0074, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 568, Step num: 14239, Learning rate: 0.00007407, Avg batch loss: 0.0049, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 569, Step num: 14240, Learning rate: 0.00007407, Avg batch loss: 0.0057, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 570, Step num: 14241, Learning rate: 0.00007407, Avg batch loss: 0.0053, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 571, Step num: 14242, Learning rate: 0.00007406, Avg batch loss: 0.0100, Avg batch acc: 0.9892
Train, Epoch: 10, Batch: 572, Step num: 14243, Learning rate: 0.00007406, Avg batch loss: 0.0065, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 573, Step num: 14244, Learning rate: 0.00007406, Avg batch loss: 0.0073, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 574, Step num: 14245, Learning rate: 0.00007406, Avg batch loss: 0.0049, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 575, Step num: 14246, Learning rate: 0.00007405, Avg batch loss: 0.0050, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 576, Step num: 14247, Learning rate: 0.00007405, Avg batch loss: 0.0062, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 577, Step num: 14248, Learning rate: 0.00007405, Avg batch loss: 0.0053, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 578, Step num: 14249, Learning rate: 0.00007405, Avg batch loss: 0.0048, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 579, Step num: 14250, Learning rate: 0.00007404, Avg batch loss: 0.0072, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 580, Step num: 14251, Learning rate: 0.00007404, Avg batch loss: 0.0065, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 581, Step num: 14252, Learning rate: 0.00007404, Avg batch loss: 0.0055, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 582, Step num: 14253, Learning rate: 0.00007404, Avg batch loss: 0.0086, Avg batch acc: 0.9911
Train, Epoch: 10, Batch: 583, Step num: 14254, Learning rate: 0.00007403, Avg batch loss: 0.0054, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 584, Step num: 14255, Learning rate: 0.00007403, Avg batch loss: 0.0063, Avg batch acc: 0.9918
Train, Epoch: 10, Batch: 585, Step num: 14256, Learning rate: 0.00007403, Avg batch loss: 0.0059, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 586, Step num: 14257, Learning rate: 0.00007403, Avg batch loss: 0.0069, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 587, Step num: 14258, Learning rate: 0.00007402, Avg batch loss: 0.0071, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 588, Step num: 14259, Learning rate: 0.00007402, Avg batch loss: 0.0065, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 589, Step num: 14260, Learning rate: 0.00007402, Avg batch loss: 0.0048, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 590, Step num: 14261, Learning rate: 0.00007402, Avg batch loss: 0.0052, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 591, Step num: 14262, Learning rate: 0.00007401, Avg batch loss: 0.0056, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 592, Step num: 14263, Learning rate: 0.00007401, Avg batch loss: 0.0053, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 593, Step num: 14264, Learning rate: 0.00007401, Avg batch loss: 0.0092, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 594, Step num: 14265, Learning rate: 0.00007400, Avg batch loss: 0.0043, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 595, Step num: 14266, Learning rate: 0.00007400, Avg batch loss: 0.0053, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 596, Step num: 14267, Learning rate: 0.00007400, Avg batch loss: 0.0081, Avg batch acc: 0.9882
Train, Epoch: 10, Batch: 597, Step num: 14268, Learning rate: 0.00007400, Avg batch loss: 0.0034, Avg batch acc: 0.9979
Train, Epoch: 10, Batch: 598, Step num: 14269, Learning rate: 0.00007399, Avg batch loss: 0.0079, Avg batch acc: 0.9909
Train, Epoch: 10, Batch: 599, Step num: 14270, Learning rate: 0.00007399, Avg batch loss: 0.0046, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 600, Step num: 14271, Learning rate: 0.00007399, Avg batch loss: 0.0065, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 601, Step num: 14272, Learning rate: 0.00007399, Avg batch loss: 0.0042, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 602, Step num: 14273, Learning rate: 0.00007398, Avg batch loss: 0.0061, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 603, Step num: 14274, Learning rate: 0.00007398, Avg batch loss: 0.0060, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 604, Step num: 14275, Learning rate: 0.00007398, Avg batch loss: 0.0076, Avg batch acc: 0.9912
Train, Epoch: 10, Batch: 605, Step num: 14276, Learning rate: 0.00007398, Avg batch loss: 0.0062, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 606, Step num: 14277, Learning rate: 0.00007397, Avg batch loss: 0.0051, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 607, Step num: 14278, Learning rate: 0.00007397, Avg batch loss: 0.0075, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 608, Step num: 14279, Learning rate: 0.00007397, Avg batch loss: 0.0049, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 609, Step num: 14280, Learning rate: 0.00007397, Avg batch loss: 0.0056, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 610, Step num: 14281, Learning rate: 0.00007396, Avg batch loss: 0.0065, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 611, Step num: 14282, Learning rate: 0.00007396, Avg batch loss: 0.0057, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 612, Step num: 14283, Learning rate: 0.00007396, Avg batch loss: 0.0062, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 613, Step num: 14284, Learning rate: 0.00007396, Avg batch loss: 0.0061, Avg batch acc: 0.9915
Train, Epoch: 10, Batch: 614, Step num: 14285, Learning rate: 0.00007395, Avg batch loss: 0.0064, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 615, Step num: 14286, Learning rate: 0.00007395, Avg batch loss: 0.0059, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 616, Step num: 14287, Learning rate: 0.00007395, Avg batch loss: 0.0065, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 617, Step num: 14288, Learning rate: 0.00007395, Avg batch loss: 0.0044, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 618, Step num: 14289, Learning rate: 0.00007394, Avg batch loss: 0.0073, Avg batch acc: 0.9918
Train, Epoch: 10, Batch: 619, Step num: 14290, Learning rate: 0.00007394, Avg batch loss: 0.0044, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 620, Step num: 14291, Learning rate: 0.00007394, Avg batch loss: 0.0050, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 621, Step num: 14292, Learning rate: 0.00007393, Avg batch loss: 0.0064, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 622, Step num: 14293, Learning rate: 0.00007393, Avg batch loss: 0.0057, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 623, Step num: 14294, Learning rate: 0.00007393, Avg batch loss: 0.0056, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 624, Step num: 14295, Learning rate: 0.00007393, Avg batch loss: 0.0054, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 625, Step num: 14296, Learning rate: 0.00007392, Avg batch loss: 0.0066, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 626, Step num: 14297, Learning rate: 0.00007392, Avg batch loss: 0.0079, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 627, Step num: 14298, Learning rate: 0.00007392, Avg batch loss: 0.0068, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 628, Step num: 14299, Learning rate: 0.00007392, Avg batch loss: 0.0058, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 629, Step num: 14300, Learning rate: 0.00007391, Avg batch loss: 0.0058, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 630, Step num: 14301, Learning rate: 0.00007391, Avg batch loss: 0.0074, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 631, Step num: 14302, Learning rate: 0.00007391, Avg batch loss: 0.0060, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 632, Step num: 14303, Learning rate: 0.00007391, Avg batch loss: 0.0027, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 633, Step num: 14304, Learning rate: 0.00007390, Avg batch loss: 0.0041, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 634, Step num: 14305, Learning rate: 0.00007390, Avg batch loss: 0.0058, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 635, Step num: 14306, Learning rate: 0.00007390, Avg batch loss: 0.0038, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 636, Step num: 14307, Learning rate: 0.00007390, Avg batch loss: 0.0041, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 637, Step num: 14308, Learning rate: 0.00007389, Avg batch loss: 0.0055, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 638, Step num: 14309, Learning rate: 0.00007389, Avg batch loss: 0.0061, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 639, Step num: 14310, Learning rate: 0.00007389, Avg batch loss: 0.0053, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 640, Step num: 14311, Learning rate: 0.00007389, Avg batch loss: 0.0066, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 641, Step num: 14312, Learning rate: 0.00007388, Avg batch loss: 0.0055, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 642, Step num: 14313, Learning rate: 0.00007388, Avg batch loss: 0.0040, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 643, Step num: 14314, Learning rate: 0.00007388, Avg batch loss: 0.0055, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 644, Step num: 14315, Learning rate: 0.00007388, Avg batch loss: 0.0070, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 645, Step num: 14316, Learning rate: 0.00007387, Avg batch loss: 0.0053, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 646, Step num: 14317, Learning rate: 0.00007387, Avg batch loss: 0.0054, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 647, Step num: 14318, Learning rate: 0.00007387, Avg batch loss: 0.0049, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 648, Step num: 14319, Learning rate: 0.00007386, Avg batch loss: 0.0061, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 649, Step num: 14320, Learning rate: 0.00007386, Avg batch loss: 0.0037, Avg batch acc: 0.9982
Train, Epoch: 10, Batch: 650, Step num: 14321, Learning rate: 0.00007386, Avg batch loss: 0.0048, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 651, Step num: 14322, Learning rate: 0.00007386, Avg batch loss: 0.0055, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 652, Step num: 14323, Learning rate: 0.00007385, Avg batch loss: 0.0049, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 653, Step num: 14324, Learning rate: 0.00007385, Avg batch loss: 0.0057, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 654, Step num: 14325, Learning rate: 0.00007385, Avg batch loss: 0.0071, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 655, Step num: 14326, Learning rate: 0.00007385, Avg batch loss: 0.0062, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 656, Step num: 14327, Learning rate: 0.00007384, Avg batch loss: 0.0066, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 657, Step num: 14328, Learning rate: 0.00007384, Avg batch loss: 0.0057, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 658, Step num: 14329, Learning rate: 0.00007384, Avg batch loss: 0.0058, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 659, Step num: 14330, Learning rate: 0.00007384, Avg batch loss: 0.0060, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 660, Step num: 14331, Learning rate: 0.00007383, Avg batch loss: 0.0054, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 661, Step num: 14332, Learning rate: 0.00007383, Avg batch loss: 0.0047, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 662, Step num: 14333, Learning rate: 0.00007383, Avg batch loss: 0.0072, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 663, Step num: 14334, Learning rate: 0.00007383, Avg batch loss: 0.0053, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 664, Step num: 14335, Learning rate: 0.00007382, Avg batch loss: 0.0061, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 665, Step num: 14336, Learning rate: 0.00007382, Avg batch loss: 0.0047, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 666, Step num: 14337, Learning rate: 0.00007382, Avg batch loss: 0.0056, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 667, Step num: 14338, Learning rate: 0.00007382, Avg batch loss: 0.0063, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 668, Step num: 14339, Learning rate: 0.00007381, Avg batch loss: 0.0061, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 669, Step num: 14340, Learning rate: 0.00007381, Avg batch loss: 0.0046, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 670, Step num: 14341, Learning rate: 0.00007381, Avg batch loss: 0.0057, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 671, Step num: 14342, Learning rate: 0.00007381, Avg batch loss: 0.0050, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 672, Step num: 14343, Learning rate: 0.00007380, Avg batch loss: 0.0049, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 673, Step num: 14344, Learning rate: 0.00007380, Avg batch loss: 0.0033, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 674, Step num: 14345, Learning rate: 0.00007380, Avg batch loss: 0.0073, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 675, Step num: 14346, Learning rate: 0.00007380, Avg batch loss: 0.0040, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 676, Step num: 14347, Learning rate: 0.00007379, Avg batch loss: 0.0077, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 677, Step num: 14348, Learning rate: 0.00007379, Avg batch loss: 0.0048, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 678, Step num: 14349, Learning rate: 0.00007379, Avg batch loss: 0.0047, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 679, Step num: 14350, Learning rate: 0.00007379, Avg batch loss: 0.0054, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 680, Step num: 14351, Learning rate: 0.00007378, Avg batch loss: 0.0061, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 681, Step num: 14352, Learning rate: 0.00007378, Avg batch loss: 0.0087, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 682, Step num: 14353, Learning rate: 0.00007378, Avg batch loss: 0.0071, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 683, Step num: 14354, Learning rate: 0.00007377, Avg batch loss: 0.0053, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 684, Step num: 14355, Learning rate: 0.00007377, Avg batch loss: 0.0047, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 685, Step num: 14356, Learning rate: 0.00007377, Avg batch loss: 0.0042, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 686, Step num: 14357, Learning rate: 0.00007377, Avg batch loss: 0.0045, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 687, Step num: 14358, Learning rate: 0.00007376, Avg batch loss: 0.0157, Avg batch acc: 0.9908
Train, Epoch: 10, Batch: 688, Step num: 14359, Learning rate: 0.00007376, Avg batch loss: 0.0060, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 689, Step num: 14360, Learning rate: 0.00007376, Avg batch loss: 0.0058, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 690, Step num: 14361, Learning rate: 0.00007376, Avg batch loss: 0.0041, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 691, Step num: 14362, Learning rate: 0.00007375, Avg batch loss: 0.0078, Avg batch acc: 0.9909
Train, Epoch: 10, Batch: 692, Step num: 14363, Learning rate: 0.00007375, Avg batch loss: 0.0054, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 693, Step num: 14364, Learning rate: 0.00007375, Avg batch loss: 0.0045, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 694, Step num: 14365, Learning rate: 0.00007375, Avg batch loss: 0.0042, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 695, Step num: 14366, Learning rate: 0.00007374, Avg batch loss: 0.0038, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 696, Step num: 14367, Learning rate: 0.00007374, Avg batch loss: 0.0050, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 697, Step num: 14368, Learning rate: 0.00007374, Avg batch loss: 0.0077, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 698, Step num: 14369, Learning rate: 0.00007374, Avg batch loss: 0.0069, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 699, Step num: 14370, Learning rate: 0.00007373, Avg batch loss: 0.0067, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 700, Step num: 14371, Learning rate: 0.00007373, Avg batch loss: 0.0041, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 701, Step num: 14372, Learning rate: 0.00007373, Avg batch loss: 0.0053, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 702, Step num: 14373, Learning rate: 0.00007373, Avg batch loss: 0.0076, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 703, Step num: 14374, Learning rate: 0.00007372, Avg batch loss: 0.0058, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 704, Step num: 14375, Learning rate: 0.00007372, Avg batch loss: 0.0044, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 705, Step num: 14376, Learning rate: 0.00007372, Avg batch loss: 0.0060, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 706, Step num: 14377, Learning rate: 0.00007372, Avg batch loss: 0.0099, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 707, Step num: 14378, Learning rate: 0.00007371, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 708, Step num: 14379, Learning rate: 0.00007371, Avg batch loss: 0.0103, Avg batch acc: 0.9865
Train, Epoch: 10, Batch: 709, Step num: 14380, Learning rate: 0.00007371, Avg batch loss: 0.0079, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 710, Step num: 14381, Learning rate: 0.00007371, Avg batch loss: 0.0069, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 711, Step num: 14382, Learning rate: 0.00007370, Avg batch loss: 0.0055, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 712, Step num: 14383, Learning rate: 0.00007370, Avg batch loss: 0.0066, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 713, Step num: 14384, Learning rate: 0.00007370, Avg batch loss: 0.0076, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 714, Step num: 14385, Learning rate: 0.00007370, Avg batch loss: 0.0059, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 715, Step num: 14386, Learning rate: 0.00007369, Avg batch loss: 0.0052, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 716, Step num: 14387, Learning rate: 0.00007369, Avg batch loss: 0.0064, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 717, Step num: 14388, Learning rate: 0.00007369, Avg batch loss: 0.0076, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 718, Step num: 14389, Learning rate: 0.00007369, Avg batch loss: 0.0075, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 719, Step num: 14390, Learning rate: 0.00007368, Avg batch loss: 0.0045, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 720, Step num: 14391, Learning rate: 0.00007368, Avg batch loss: 0.0054, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 721, Step num: 14392, Learning rate: 0.00007368, Avg batch loss: 0.0051, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 722, Step num: 14393, Learning rate: 0.00007367, Avg batch loss: 0.0076, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 723, Step num: 14394, Learning rate: 0.00007367, Avg batch loss: 0.0029, Avg batch acc: 0.9982
Train, Epoch: 10, Batch: 724, Step num: 14395, Learning rate: 0.00007367, Avg batch loss: 0.0063, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 725, Step num: 14396, Learning rate: 0.00007367, Avg batch loss: 0.0059, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 726, Step num: 14397, Learning rate: 0.00007366, Avg batch loss: 0.0073, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 727, Step num: 14398, Learning rate: 0.00007366, Avg batch loss: 0.0061, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 728, Step num: 14399, Learning rate: 0.00007366, Avg batch loss: 0.0061, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 729, Step num: 14400, Learning rate: 0.00007366, Avg batch loss: 0.0049, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 730, Step num: 14401, Learning rate: 0.00007365, Avg batch loss: 0.0078, Avg batch acc: 0.9908
Train, Epoch: 10, Batch: 731, Step num: 14402, Learning rate: 0.00007365, Avg batch loss: 0.0033, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 732, Step num: 14403, Learning rate: 0.00007365, Avg batch loss: 0.0061, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 733, Step num: 14404, Learning rate: 0.00007365, Avg batch loss: 0.0056, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 734, Step num: 14405, Learning rate: 0.00007364, Avg batch loss: 0.0072, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 735, Step num: 14406, Learning rate: 0.00007364, Avg batch loss: 0.0047, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 736, Step num: 14407, Learning rate: 0.00007364, Avg batch loss: 0.0043, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 737, Step num: 14408, Learning rate: 0.00007364, Avg batch loss: 0.0047, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 738, Step num: 14409, Learning rate: 0.00007363, Avg batch loss: 0.0099, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 739, Step num: 14410, Learning rate: 0.00007363, Avg batch loss: 0.0045, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 740, Step num: 14411, Learning rate: 0.00007363, Avg batch loss: 0.0076, Avg batch acc: 0.9911
Train, Epoch: 10, Batch: 741, Step num: 14412, Learning rate: 0.00007363, Avg batch loss: 0.0038, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 742, Step num: 14413, Learning rate: 0.00007362, Avg batch loss: 0.0056, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 743, Step num: 14414, Learning rate: 0.00007362, Avg batch loss: 0.0041, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 744, Step num: 14415, Learning rate: 0.00007362, Avg batch loss: 0.0053, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 745, Step num: 14416, Learning rate: 0.00007362, Avg batch loss: 0.0050, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 746, Step num: 14417, Learning rate: 0.00007361, Avg batch loss: 0.0075, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 747, Step num: 14418, Learning rate: 0.00007361, Avg batch loss: 0.0087, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 748, Step num: 14419, Learning rate: 0.00007361, Avg batch loss: 0.0054, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 749, Step num: 14420, Learning rate: 0.00007361, Avg batch loss: 0.0062, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 750, Step num: 14421, Learning rate: 0.00007360, Avg batch loss: 0.0055, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 751, Step num: 14422, Learning rate: 0.00007360, Avg batch loss: 0.0088, Avg batch acc: 0.9911
Train, Epoch: 10, Batch: 752, Step num: 14423, Learning rate: 0.00007360, Avg batch loss: 0.0081, Avg batch acc: 0.9913
Train, Epoch: 10, Batch: 753, Step num: 14424, Learning rate: 0.00007360, Avg batch loss: 0.0086, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 754, Step num: 14425, Learning rate: 0.00007359, Avg batch loss: 0.0054, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 755, Step num: 14426, Learning rate: 0.00007359, Avg batch loss: 0.0078, Avg batch acc: 0.9913
Train, Epoch: 10, Batch: 756, Step num: 14427, Learning rate: 0.00007359, Avg batch loss: 0.0080, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 757, Step num: 14428, Learning rate: 0.00007359, Avg batch loss: 0.0192, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 758, Step num: 14429, Learning rate: 0.00007358, Avg batch loss: 0.0067, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 759, Step num: 14430, Learning rate: 0.00007358, Avg batch loss: 0.0212, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 760, Step num: 14431, Learning rate: 0.00007358, Avg batch loss: 0.0205, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 761, Step num: 14432, Learning rate: 0.00007358, Avg batch loss: 0.0041, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 762, Step num: 14433, Learning rate: 0.00007357, Avg batch loss: 0.0043, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 763, Step num: 14434, Learning rate: 0.00007357, Avg batch loss: 0.0043, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 764, Step num: 14435, Learning rate: 0.00007357, Avg batch loss: 0.0050, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 765, Step num: 14436, Learning rate: 0.00007357, Avg batch loss: 0.0075, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 766, Step num: 14437, Learning rate: 0.00007356, Avg batch loss: 0.0066, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 767, Step num: 14438, Learning rate: 0.00007356, Avg batch loss: 0.0152, Avg batch acc: 0.9886
Train, Epoch: 10, Batch: 768, Step num: 14439, Learning rate: 0.00007356, Avg batch loss: 0.0409, Avg batch acc: 0.9859
Train, Epoch: 10, Batch: 769, Step num: 14440, Learning rate: 0.00007355, Avg batch loss: 0.0076, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 770, Step num: 14441, Learning rate: 0.00007355, Avg batch loss: 0.0071, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 771, Step num: 14442, Learning rate: 0.00007355, Avg batch loss: 0.0066, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 772, Step num: 14443, Learning rate: 0.00007355, Avg batch loss: 0.0059, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 773, Step num: 14444, Learning rate: 0.00007354, Avg batch loss: 0.0051, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 774, Step num: 14445, Learning rate: 0.00007354, Avg batch loss: 0.0086, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 775, Step num: 14446, Learning rate: 0.00007354, Avg batch loss: 0.0062, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 776, Step num: 14447, Learning rate: 0.00007354, Avg batch loss: 0.0095, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 777, Step num: 14448, Learning rate: 0.00007353, Avg batch loss: 0.0054, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 778, Step num: 14449, Learning rate: 0.00007353, Avg batch loss: 0.0076, Avg batch acc: 0.9904
Train, Epoch: 10, Batch: 779, Step num: 14450, Learning rate: 0.00007353, Avg batch loss: 0.0056, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 780, Step num: 14451, Learning rate: 0.00007353, Avg batch loss: 0.0066, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 781, Step num: 14452, Learning rate: 0.00007352, Avg batch loss: 0.0100, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 782, Step num: 14453, Learning rate: 0.00007352, Avg batch loss: 0.0062, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 783, Step num: 14454, Learning rate: 0.00007352, Avg batch loss: 0.0050, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 784, Step num: 14455, Learning rate: 0.00007352, Avg batch loss: 0.0122, Avg batch acc: 0.9906
Train, Epoch: 10, Batch: 785, Step num: 14456, Learning rate: 0.00007351, Avg batch loss: 0.0067, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 786, Step num: 14457, Learning rate: 0.00007351, Avg batch loss: 0.0058, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 787, Step num: 14458, Learning rate: 0.00007351, Avg batch loss: 0.0076, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 788, Step num: 14459, Learning rate: 0.00007351, Avg batch loss: 0.0072, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 789, Step num: 14460, Learning rate: 0.00007350, Avg batch loss: 0.0069, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 790, Step num: 14461, Learning rate: 0.00007350, Avg batch loss: 0.0071, Avg batch acc: 0.9909
Train, Epoch: 10, Batch: 791, Step num: 14462, Learning rate: 0.00007350, Avg batch loss: 0.0060, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 792, Step num: 14463, Learning rate: 0.00007350, Avg batch loss: 0.0058, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 793, Step num: 14464, Learning rate: 0.00007349, Avg batch loss: 0.0054, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 794, Step num: 14465, Learning rate: 0.00007349, Avg batch loss: 0.0054, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 795, Step num: 14466, Learning rate: 0.00007349, Avg batch loss: 0.0035, Avg batch acc: 0.9974
Train, Epoch: 10, Batch: 796, Step num: 14467, Learning rate: 0.00007349, Avg batch loss: 0.0060, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 797, Step num: 14468, Learning rate: 0.00007348, Avg batch loss: 0.0064, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 798, Step num: 14469, Learning rate: 0.00007348, Avg batch loss: 0.0069, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 799, Step num: 14470, Learning rate: 0.00007348, Avg batch loss: 0.0059, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 800, Step num: 14471, Learning rate: 0.00007348, Avg batch loss: 0.0066, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 801, Step num: 14472, Learning rate: 0.00007347, Avg batch loss: 0.0047, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 802, Step num: 14473, Learning rate: 0.00007347, Avg batch loss: 0.0059, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 803, Step num: 14474, Learning rate: 0.00007347, Avg batch loss: 0.0065, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 804, Step num: 14475, Learning rate: 0.00007347, Avg batch loss: 0.0037, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 805, Step num: 14476, Learning rate: 0.00007346, Avg batch loss: 0.0060, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 806, Step num: 14477, Learning rate: 0.00007346, Avg batch loss: 0.0073, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 807, Step num: 14478, Learning rate: 0.00007346, Avg batch loss: 0.0067, Avg batch acc: 0.9898
Train, Epoch: 10, Batch: 808, Step num: 14479, Learning rate: 0.00007346, Avg batch loss: 0.0069, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 809, Step num: 14480, Learning rate: 0.00007345, Avg batch loss: 0.0089, Avg batch acc: 0.9907
Train, Epoch: 10, Batch: 810, Step num: 14481, Learning rate: 0.00007345, Avg batch loss: 0.0046, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 811, Step num: 14482, Learning rate: 0.00007345, Avg batch loss: 0.0057, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 812, Step num: 14483, Learning rate: 0.00007345, Avg batch loss: 0.0070, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 813, Step num: 14484, Learning rate: 0.00007344, Avg batch loss: 0.0072, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 814, Step num: 14485, Learning rate: 0.00007344, Avg batch loss: 0.0052, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 815, Step num: 14486, Learning rate: 0.00007344, Avg batch loss: 0.0051, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 816, Step num: 14487, Learning rate: 0.00007344, Avg batch loss: 0.0067, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 817, Step num: 14488, Learning rate: 0.00007343, Avg batch loss: 0.0054, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 818, Step num: 14489, Learning rate: 0.00007343, Avg batch loss: 0.0029, Avg batch acc: 0.9973
Train, Epoch: 10, Batch: 819, Step num: 14490, Learning rate: 0.00007343, Avg batch loss: 0.0048, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 820, Step num: 14491, Learning rate: 0.00007343, Avg batch loss: 0.0040, Avg batch acc: 0.9974
Train, Epoch: 10, Batch: 821, Step num: 14492, Learning rate: 0.00007342, Avg batch loss: 0.0055, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 822, Step num: 14493, Learning rate: 0.00007342, Avg batch loss: 0.0056, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 823, Step num: 14494, Learning rate: 0.00007342, Avg batch loss: 0.0067, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 824, Step num: 14495, Learning rate: 0.00007342, Avg batch loss: 0.0057, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 825, Step num: 14496, Learning rate: 0.00007341, Avg batch loss: 0.0043, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 826, Step num: 14497, Learning rate: 0.00007341, Avg batch loss: 0.0067, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 827, Step num: 14498, Learning rate: 0.00007341, Avg batch loss: 0.0040, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 828, Step num: 14499, Learning rate: 0.00007341, Avg batch loss: 0.0064, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 829, Step num: 14500, Learning rate: 0.00007340, Avg batch loss: 0.0062, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 830, Step num: 14501, Learning rate: 0.00007340, Avg batch loss: 0.0046, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 831, Step num: 14502, Learning rate: 0.00007340, Avg batch loss: 0.0046, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 832, Step num: 14503, Learning rate: 0.00007339, Avg batch loss: 0.0047, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 833, Step num: 14504, Learning rate: 0.00007339, Avg batch loss: 0.0060, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 834, Step num: 14505, Learning rate: 0.00007339, Avg batch loss: 0.0063, Avg batch acc: 0.9916
Train, Epoch: 10, Batch: 835, Step num: 14506, Learning rate: 0.00007339, Avg batch loss: 0.0051, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 836, Step num: 14507, Learning rate: 0.00007338, Avg batch loss: 0.0054, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 837, Step num: 14508, Learning rate: 0.00007338, Avg batch loss: 0.0056, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 838, Step num: 14509, Learning rate: 0.00007338, Avg batch loss: 0.0061, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 839, Step num: 14510, Learning rate: 0.00007338, Avg batch loss: 0.0063, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 840, Step num: 14511, Learning rate: 0.00007337, Avg batch loss: 0.0045, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 841, Step num: 14512, Learning rate: 0.00007337, Avg batch loss: 0.0048, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 842, Step num: 14513, Learning rate: 0.00007337, Avg batch loss: 0.0074, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 843, Step num: 14514, Learning rate: 0.00007337, Avg batch loss: 0.0062, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 844, Step num: 14515, Learning rate: 0.00007336, Avg batch loss: 0.0051, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 845, Step num: 14516, Learning rate: 0.00007336, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 846, Step num: 14517, Learning rate: 0.00007336, Avg batch loss: 0.0046, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 847, Step num: 14518, Learning rate: 0.00007336, Avg batch loss: 0.0034, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 848, Step num: 14519, Learning rate: 0.00007335, Avg batch loss: 0.0052, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 849, Step num: 14520, Learning rate: 0.00007335, Avg batch loss: 0.0054, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 850, Step num: 14521, Learning rate: 0.00007335, Avg batch loss: 0.0052, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 851, Step num: 14522, Learning rate: 0.00007335, Avg batch loss: 0.0094, Avg batch acc: 0.9893
Train, Epoch: 10, Batch: 852, Step num: 14523, Learning rate: 0.00007334, Avg batch loss: 0.0071, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 853, Step num: 14524, Learning rate: 0.00007334, Avg batch loss: 0.0068, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 854, Step num: 14525, Learning rate: 0.00007334, Avg batch loss: 0.0039, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 855, Step num: 14526, Learning rate: 0.00007334, Avg batch loss: 0.0062, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 856, Step num: 14527, Learning rate: 0.00007333, Avg batch loss: 0.0072, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 857, Step num: 14528, Learning rate: 0.00007333, Avg batch loss: 0.0074, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 858, Step num: 14529, Learning rate: 0.00007333, Avg batch loss: 0.0042, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 859, Step num: 14530, Learning rate: 0.00007333, Avg batch loss: 0.0057, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 860, Step num: 14531, Learning rate: 0.00007332, Avg batch loss: 0.0065, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 861, Step num: 14532, Learning rate: 0.00007332, Avg batch loss: 0.0042, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 862, Step num: 14533, Learning rate: 0.00007332, Avg batch loss: 0.0069, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 863, Step num: 14534, Learning rate: 0.00007332, Avg batch loss: 0.0044, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 864, Step num: 14535, Learning rate: 0.00007331, Avg batch loss: 0.0045, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 865, Step num: 14536, Learning rate: 0.00007331, Avg batch loss: 0.0054, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 866, Step num: 14537, Learning rate: 0.00007331, Avg batch loss: 0.0071, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 867, Step num: 14538, Learning rate: 0.00007331, Avg batch loss: 0.0052, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 868, Step num: 14539, Learning rate: 0.00007330, Avg batch loss: 0.0060, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 869, Step num: 14540, Learning rate: 0.00007330, Avg batch loss: 0.0042, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 870, Step num: 14541, Learning rate: 0.00007330, Avg batch loss: 0.0049, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 871, Step num: 14542, Learning rate: 0.00007330, Avg batch loss: 0.0047, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 872, Step num: 14543, Learning rate: 0.00007329, Avg batch loss: 0.0055, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 873, Step num: 14544, Learning rate: 0.00007329, Avg batch loss: 0.0052, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 874, Step num: 14545, Learning rate: 0.00007329, Avg batch loss: 0.0062, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 875, Step num: 14546, Learning rate: 0.00007329, Avg batch loss: 0.0054, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 876, Step num: 14547, Learning rate: 0.00007328, Avg batch loss: 0.0052, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 877, Step num: 14548, Learning rate: 0.00007328, Avg batch loss: 0.0060, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 878, Step num: 14549, Learning rate: 0.00007328, Avg batch loss: 0.0055, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 879, Step num: 14550, Learning rate: 0.00007328, Avg batch loss: 0.0037, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 880, Step num: 14551, Learning rate: 0.00007327, Avg batch loss: 0.0071, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 881, Step num: 14552, Learning rate: 0.00007327, Avg batch loss: 0.0059, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 882, Step num: 14553, Learning rate: 0.00007327, Avg batch loss: 0.0053, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 883, Step num: 14554, Learning rate: 0.00007327, Avg batch loss: 0.0081, Avg batch acc: 0.9916
Train, Epoch: 10, Batch: 884, Step num: 14555, Learning rate: 0.00007326, Avg batch loss: 0.0063, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 885, Step num: 14556, Learning rate: 0.00007326, Avg batch loss: 0.0060, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 886, Step num: 14557, Learning rate: 0.00007326, Avg batch loss: 0.0060, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 887, Step num: 14558, Learning rate: 0.00007326, Avg batch loss: 0.0041, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 888, Step num: 14559, Learning rate: 0.00007325, Avg batch loss: 0.0063, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 889, Step num: 14560, Learning rate: 0.00007325, Avg batch loss: 0.0064, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 890, Step num: 14561, Learning rate: 0.00007325, Avg batch loss: 0.0054, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 891, Step num: 14562, Learning rate: 0.00007325, Avg batch loss: 0.0037, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 892, Step num: 14563, Learning rate: 0.00007324, Avg batch loss: 0.0039, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 893, Step num: 14564, Learning rate: 0.00007324, Avg batch loss: 0.0044, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 894, Step num: 14565, Learning rate: 0.00007324, Avg batch loss: 0.0061, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 895, Step num: 14566, Learning rate: 0.00007324, Avg batch loss: 0.0058, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 896, Step num: 14567, Learning rate: 0.00007323, Avg batch loss: 0.0042, Avg batch acc: 0.9974
Train, Epoch: 10, Batch: 897, Step num: 14568, Learning rate: 0.00007323, Avg batch loss: 0.0053, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 898, Step num: 14569, Learning rate: 0.00007323, Avg batch loss: 0.0055, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 899, Step num: 14570, Learning rate: 0.00007323, Avg batch loss: 0.0047, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 900, Step num: 14571, Learning rate: 0.00007322, Avg batch loss: 0.0041, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 901, Step num: 14572, Learning rate: 0.00007322, Avg batch loss: 0.0079, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 902, Step num: 14573, Learning rate: 0.00007322, Avg batch loss: 0.0075, Avg batch acc: 0.9917
Train, Epoch: 10, Batch: 903, Step num: 14574, Learning rate: 0.00007322, Avg batch loss: 0.0057, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 904, Step num: 14575, Learning rate: 0.00007321, Avg batch loss: 0.0062, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 905, Step num: 14576, Learning rate: 0.00007321, Avg batch loss: 0.0040, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 906, Step num: 14577, Learning rate: 0.00007321, Avg batch loss: 0.0045, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 907, Step num: 14578, Learning rate: 0.00007321, Avg batch loss: 0.0059, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 908, Step num: 14579, Learning rate: 0.00007320, Avg batch loss: 0.0073, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 909, Step num: 14580, Learning rate: 0.00007320, Avg batch loss: 0.0078, Avg batch acc: 0.9913
Train, Epoch: 10, Batch: 910, Step num: 14581, Learning rate: 0.00007320, Avg batch loss: 0.0047, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 911, Step num: 14582, Learning rate: 0.00007320, Avg batch loss: 0.0038, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 912, Step num: 14583, Learning rate: 0.00007319, Avg batch loss: 0.0048, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 913, Step num: 14584, Learning rate: 0.00007319, Avg batch loss: 0.0059, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 914, Step num: 14585, Learning rate: 0.00007319, Avg batch loss: 0.0041, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 915, Step num: 14586, Learning rate: 0.00007319, Avg batch loss: 0.0036, Avg batch acc: 0.9975
Train, Epoch: 10, Batch: 916, Step num: 14587, Learning rate: 0.00007318, Avg batch loss: 0.0064, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 917, Step num: 14588, Learning rate: 0.00007318, Avg batch loss: 0.0039, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 918, Step num: 14589, Learning rate: 0.00007318, Avg batch loss: 0.0038, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 919, Step num: 14590, Learning rate: 0.00007318, Avg batch loss: 0.0054, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 920, Step num: 14591, Learning rate: 0.00007317, Avg batch loss: 0.0051, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 921, Step num: 14592, Learning rate: 0.00007317, Avg batch loss: 0.0060, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 922, Step num: 14593, Learning rate: 0.00007317, Avg batch loss: 0.0044, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 923, Step num: 14594, Learning rate: 0.00007317, Avg batch loss: 0.0056, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 924, Step num: 14595, Learning rate: 0.00007316, Avg batch loss: 0.0067, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 925, Step num: 14596, Learning rate: 0.00007316, Avg batch loss: 0.0039, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 926, Step num: 14597, Learning rate: 0.00007316, Avg batch loss: 0.0061, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 927, Step num: 14598, Learning rate: 0.00007316, Avg batch loss: 0.0041, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 928, Step num: 14599, Learning rate: 0.00007315, Avg batch loss: 0.0061, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 929, Step num: 14600, Learning rate: 0.00007315, Avg batch loss: 0.0067, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 930, Step num: 14601, Learning rate: 0.00007315, Avg batch loss: 0.0067, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 931, Step num: 14602, Learning rate: 0.00007315, Avg batch loss: 0.0047, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 932, Step num: 14603, Learning rate: 0.00007314, Avg batch loss: 0.0047, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 933, Step num: 14604, Learning rate: 0.00007314, Avg batch loss: 0.0051, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 934, Step num: 14605, Learning rate: 0.00007314, Avg batch loss: 0.0040, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 935, Step num: 14606, Learning rate: 0.00007314, Avg batch loss: 0.0043, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 936, Step num: 14607, Learning rate: 0.00007313, Avg batch loss: 0.0044, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 937, Step num: 14608, Learning rate: 0.00007313, Avg batch loss: 0.0042, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 938, Step num: 14609, Learning rate: 0.00007313, Avg batch loss: 0.0046, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 939, Step num: 14610, Learning rate: 0.00007313, Avg batch loss: 0.0057, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 940, Step num: 14611, Learning rate: 0.00007312, Avg batch loss: 0.0055, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 941, Step num: 14612, Learning rate: 0.00007312, Avg batch loss: 0.0052, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 942, Step num: 14613, Learning rate: 0.00007312, Avg batch loss: 0.0067, Avg batch acc: 0.9894
Train, Epoch: 10, Batch: 943, Step num: 14614, Learning rate: 0.00007312, Avg batch loss: 0.0056, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 944, Step num: 14615, Learning rate: 0.00007311, Avg batch loss: 0.0048, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 945, Step num: 14616, Learning rate: 0.00007311, Avg batch loss: 0.0053, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 946, Step num: 14617, Learning rate: 0.00007311, Avg batch loss: 0.0068, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 947, Step num: 14618, Learning rate: 0.00007311, Avg batch loss: 0.0073, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 948, Step num: 14619, Learning rate: 0.00007310, Avg batch loss: 0.0046, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 949, Step num: 14620, Learning rate: 0.00007310, Avg batch loss: 0.0048, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 950, Step num: 14621, Learning rate: 0.00007310, Avg batch loss: 0.0066, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 951, Step num: 14622, Learning rate: 0.00007310, Avg batch loss: 0.0062, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 952, Step num: 14623, Learning rate: 0.00007309, Avg batch loss: 0.0084, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 953, Step num: 14624, Learning rate: 0.00007309, Avg batch loss: 0.0065, Avg batch acc: 0.9905
Train, Epoch: 10, Batch: 954, Step num: 14625, Learning rate: 0.00007309, Avg batch loss: 0.0048, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 955, Step num: 14626, Learning rate: 0.00007309, Avg batch loss: 0.0110, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 956, Step num: 14627, Learning rate: 0.00007308, Avg batch loss: 0.0033, Avg batch acc: 0.9978
Train, Epoch: 10, Batch: 957, Step num: 14628, Learning rate: 0.00007308, Avg batch loss: 0.0054, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 958, Step num: 14629, Learning rate: 0.00007308, Avg batch loss: 0.0054, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 959, Step num: 14630, Learning rate: 0.00007308, Avg batch loss: 0.0045, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 960, Step num: 14631, Learning rate: 0.00007307, Avg batch loss: 0.0067, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 961, Step num: 14632, Learning rate: 0.00007307, Avg batch loss: 0.0063, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 962, Step num: 14633, Learning rate: 0.00007307, Avg batch loss: 0.0052, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 963, Step num: 14634, Learning rate: 0.00007307, Avg batch loss: 0.0043, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 964, Step num: 14635, Learning rate: 0.00007306, Avg batch loss: 0.0050, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 965, Step num: 14636, Learning rate: 0.00007306, Avg batch loss: 0.0050, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 966, Step num: 14637, Learning rate: 0.00007306, Avg batch loss: 0.0042, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 967, Step num: 14638, Learning rate: 0.00007306, Avg batch loss: 0.0068, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 968, Step num: 14639, Learning rate: 0.00007305, Avg batch loss: 0.0066, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 969, Step num: 14640, Learning rate: 0.00007305, Avg batch loss: 0.0052, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 970, Step num: 14641, Learning rate: 0.00007305, Avg batch loss: 0.0043, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 971, Step num: 14642, Learning rate: 0.00007305, Avg batch loss: 0.0049, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 972, Step num: 14643, Learning rate: 0.00007304, Avg batch loss: 0.0077, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 973, Step num: 14644, Learning rate: 0.00007304, Avg batch loss: 0.0035, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 974, Step num: 14645, Learning rate: 0.00007304, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 975, Step num: 14646, Learning rate: 0.00007304, Avg batch loss: 0.0087, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 976, Step num: 14647, Learning rate: 0.00007303, Avg batch loss: 0.0052, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 977, Step num: 14648, Learning rate: 0.00007303, Avg batch loss: 0.0040, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 978, Step num: 14649, Learning rate: 0.00007303, Avg batch loss: 0.0050, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 979, Step num: 14650, Learning rate: 0.00007303, Avg batch loss: 0.0058, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 980, Step num: 14651, Learning rate: 0.00007302, Avg batch loss: 0.0064, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 981, Step num: 14652, Learning rate: 0.00007302, Avg batch loss: 0.0053, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 982, Step num: 14653, Learning rate: 0.00007302, Avg batch loss: 0.0050, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 983, Step num: 14654, Learning rate: 0.00007302, Avg batch loss: 0.0059, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 984, Step num: 14655, Learning rate: 0.00007301, Avg batch loss: 0.0055, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 985, Step num: 14656, Learning rate: 0.00007301, Avg batch loss: 0.0063, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 986, Step num: 14657, Learning rate: 0.00007301, Avg batch loss: 0.0042, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 987, Step num: 14658, Learning rate: 0.00007301, Avg batch loss: 0.0047, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 988, Step num: 14659, Learning rate: 0.00007300, Avg batch loss: 0.0054, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 989, Step num: 14660, Learning rate: 0.00007300, Avg batch loss: 0.0049, Avg batch acc: 0.9975
Train, Epoch: 10, Batch: 990, Step num: 14661, Learning rate: 0.00007300, Avg batch loss: 0.0047, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 991, Step num: 14662, Learning rate: 0.00007300, Avg batch loss: 0.0045, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 992, Step num: 14663, Learning rate: 0.00007299, Avg batch loss: 0.0047, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 993, Step num: 14664, Learning rate: 0.00007299, Avg batch loss: 0.0055, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 994, Step num: 14665, Learning rate: 0.00007299, Avg batch loss: 0.0054, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 995, Step num: 14666, Learning rate: 0.00007299, Avg batch loss: 0.0036, Avg batch acc: 0.9978
Train, Epoch: 10, Batch: 996, Step num: 14667, Learning rate: 0.00007298, Avg batch loss: 0.0055, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 997, Step num: 14668, Learning rate: 0.00007298, Avg batch loss: 0.0051, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 998, Step num: 14669, Learning rate: 0.00007298, Avg batch loss: 0.0043, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 999, Step num: 14670, Learning rate: 0.00007298, Avg batch loss: 0.0059, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 1000, Step num: 14671, Learning rate: 0.00007297, Avg batch loss: 0.0043, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1001, Step num: 14672, Learning rate: 0.00007297, Avg batch loss: 0.0054, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1002, Step num: 14673, Learning rate: 0.00007297, Avg batch loss: 0.0039, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1003, Step num: 14674, Learning rate: 0.00007297, Avg batch loss: 0.0043, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 1004, Step num: 14675, Learning rate: 0.00007296, Avg batch loss: 0.0039, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1005, Step num: 14676, Learning rate: 0.00007296, Avg batch loss: 0.0049, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1006, Step num: 14677, Learning rate: 0.00007296, Avg batch loss: 0.0056, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1007, Step num: 14678, Learning rate: 0.00007296, Avg batch loss: 0.0073, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 1008, Step num: 14679, Learning rate: 0.00007295, Avg batch loss: 0.0060, Avg batch acc: 0.9975
Train, Epoch: 10, Batch: 1009, Step num: 14680, Learning rate: 0.00007295, Avg batch loss: 0.0030, Avg batch acc: 0.9986
Train, Epoch: 10, Batch: 1010, Step num: 14681, Learning rate: 0.00007295, Avg batch loss: 0.0193, Avg batch acc: 0.9900
Train, Epoch: 10, Batch: 1011, Step num: 14682, Learning rate: 0.00007295, Avg batch loss: 0.0040, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 1012, Step num: 14683, Learning rate: 0.00007294, Avg batch loss: 0.0077, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 1013, Step num: 14684, Learning rate: 0.00007294, Avg batch loss: 0.0047, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1014, Step num: 14685, Learning rate: 0.00007294, Avg batch loss: 0.0057, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1015, Step num: 14686, Learning rate: 0.00007294, Avg batch loss: 0.0041, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 1016, Step num: 14687, Learning rate: 0.00007293, Avg batch loss: 0.0056, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 1017, Step num: 14688, Learning rate: 0.00007293, Avg batch loss: 0.0065, Avg batch acc: 0.9915
Train, Epoch: 10, Batch: 1018, Step num: 14689, Learning rate: 0.00007293, Avg batch loss: 0.0041, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1019, Step num: 14690, Learning rate: 0.00007293, Avg batch loss: 0.0079, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1020, Step num: 14691, Learning rate: 0.00007292, Avg batch loss: 0.0055, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 1021, Step num: 14692, Learning rate: 0.00007292, Avg batch loss: 0.0054, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 1022, Step num: 14693, Learning rate: 0.00007292, Avg batch loss: 0.0054, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1023, Step num: 14694, Learning rate: 0.00007292, Avg batch loss: 0.0071, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 1024, Step num: 14695, Learning rate: 0.00007291, Avg batch loss: 0.0061, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 1025, Step num: 14696, Learning rate: 0.00007291, Avg batch loss: 0.0044, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1026, Step num: 14697, Learning rate: 0.00007291, Avg batch loss: 0.0067, Avg batch acc: 0.9892
Train, Epoch: 10, Batch: 1027, Step num: 14698, Learning rate: 0.00007291, Avg batch loss: 0.0044, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1028, Step num: 14699, Learning rate: 0.00007290, Avg batch loss: 0.0036, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1029, Step num: 14700, Learning rate: 0.00007290, Avg batch loss: 0.0074, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 1030, Step num: 14701, Learning rate: 0.00007290, Avg batch loss: 0.0044, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 1031, Step num: 14702, Learning rate: 0.00007290, Avg batch loss: 0.0044, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1032, Step num: 14703, Learning rate: 0.00007289, Avg batch loss: 0.0050, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1033, Step num: 14704, Learning rate: 0.00007289, Avg batch loss: 0.0052, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1034, Step num: 14705, Learning rate: 0.00007289, Avg batch loss: 0.0048, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 1035, Step num: 14706, Learning rate: 0.00007289, Avg batch loss: 0.0052, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1036, Step num: 14707, Learning rate: 0.00007288, Avg batch loss: 0.0036, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1037, Step num: 14708, Learning rate: 0.00007288, Avg batch loss: 0.0065, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1038, Step num: 14709, Learning rate: 0.00007288, Avg batch loss: 0.0045, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1039, Step num: 14710, Learning rate: 0.00007288, Avg batch loss: 0.0055, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 1040, Step num: 14711, Learning rate: 0.00007287, Avg batch loss: 0.0065, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 1041, Step num: 14712, Learning rate: 0.00007287, Avg batch loss: 0.0042, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1042, Step num: 14713, Learning rate: 0.00007287, Avg batch loss: 0.0045, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1043, Step num: 14714, Learning rate: 0.00007287, Avg batch loss: 0.0030, Avg batch acc: 0.9979
Train, Epoch: 10, Batch: 1044, Step num: 14715, Learning rate: 0.00007286, Avg batch loss: 0.0065, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1045, Step num: 14716, Learning rate: 0.00007286, Avg batch loss: 0.0059, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 1046, Step num: 14717, Learning rate: 0.00007286, Avg batch loss: 0.0051, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1047, Step num: 14718, Learning rate: 0.00007286, Avg batch loss: 0.0071, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 1048, Step num: 14719, Learning rate: 0.00007285, Avg batch loss: 0.0052, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 1049, Step num: 14720, Learning rate: 0.00007285, Avg batch loss: 0.0059, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 1050, Step num: 14721, Learning rate: 0.00007285, Avg batch loss: 0.0051, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1051, Step num: 14722, Learning rate: 0.00007285, Avg batch loss: 0.0049, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1052, Step num: 14723, Learning rate: 0.00007284, Avg batch loss: 0.0046, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1053, Step num: 14724, Learning rate: 0.00007284, Avg batch loss: 0.0047, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1054, Step num: 14725, Learning rate: 0.00007284, Avg batch loss: 0.0052, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1055, Step num: 14726, Learning rate: 0.00007284, Avg batch loss: 0.0047, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 1056, Step num: 14727, Learning rate: 0.00007283, Avg batch loss: 0.0055, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1057, Step num: 14728, Learning rate: 0.00007283, Avg batch loss: 0.0057, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1058, Step num: 14729, Learning rate: 0.00007283, Avg batch loss: 0.0085, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 1059, Step num: 14730, Learning rate: 0.00007283, Avg batch loss: 0.0051, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1060, Step num: 14731, Learning rate: 0.00007282, Avg batch loss: 0.0056, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1061, Step num: 14732, Learning rate: 0.00007282, Avg batch loss: 0.0051, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1062, Step num: 14733, Learning rate: 0.00007282, Avg batch loss: 0.0044, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 1063, Step num: 14734, Learning rate: 0.00007282, Avg batch loss: 0.0085, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 1064, Step num: 14735, Learning rate: 0.00007281, Avg batch loss: 0.0046, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1065, Step num: 14736, Learning rate: 0.00007281, Avg batch loss: 0.0041, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1066, Step num: 14737, Learning rate: 0.00007281, Avg batch loss: 0.0039, Avg batch acc: 0.9974
Train, Epoch: 10, Batch: 1067, Step num: 14738, Learning rate: 0.00007281, Avg batch loss: 0.0061, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1068, Step num: 14739, Learning rate: 0.00007280, Avg batch loss: 0.0042, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 1069, Step num: 14740, Learning rate: 0.00007280, Avg batch loss: 0.0058, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1070, Step num: 14741, Learning rate: 0.00007280, Avg batch loss: 0.0041, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1071, Step num: 14742, Learning rate: 0.00007280, Avg batch loss: 0.0063, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 1072, Step num: 14743, Learning rate: 0.00007280, Avg batch loss: 0.0041, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 1073, Step num: 14744, Learning rate: 0.00007279, Avg batch loss: 0.0071, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 1074, Step num: 14745, Learning rate: 0.00007279, Avg batch loss: 0.0073, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 1075, Step num: 14746, Learning rate: 0.00007279, Avg batch loss: 0.0059, Avg batch acc: 0.9911
Train, Epoch: 10, Batch: 1076, Step num: 14747, Learning rate: 0.00007279, Avg batch loss: 0.0055, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1077, Step num: 14748, Learning rate: 0.00007278, Avg batch loss: 0.0068, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 1078, Step num: 14749, Learning rate: 0.00007278, Avg batch loss: 0.0052, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1079, Step num: 14750, Learning rate: 0.00007278, Avg batch loss: 0.0038, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1080, Step num: 14751, Learning rate: 0.00007278, Avg batch loss: 0.0054, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1081, Step num: 14752, Learning rate: 0.00007277, Avg batch loss: 0.0060, Avg batch acc: 0.9930
Train, Epoch: 10, Batch: 1082, Step num: 14753, Learning rate: 0.00007277, Avg batch loss: 0.0062, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1083, Step num: 14754, Learning rate: 0.00007277, Avg batch loss: 0.0056, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1084, Step num: 14755, Learning rate: 0.00007277, Avg batch loss: 0.0055, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1085, Step num: 14756, Learning rate: 0.00007276, Avg batch loss: 0.0063, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1086, Step num: 14757, Learning rate: 0.00007276, Avg batch loss: 0.0057, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1087, Step num: 14758, Learning rate: 0.00007276, Avg batch loss: 0.0065, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 1088, Step num: 14759, Learning rate: 0.00007276, Avg batch loss: 0.0055, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1089, Step num: 14760, Learning rate: 0.00007275, Avg batch loss: 0.0054, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1090, Step num: 14761, Learning rate: 0.00007275, Avg batch loss: 0.0043, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1091, Step num: 14762, Learning rate: 0.00007275, Avg batch loss: 0.0065, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1092, Step num: 14763, Learning rate: 0.00007275, Avg batch loss: 0.0047, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1093, Step num: 14764, Learning rate: 0.00007274, Avg batch loss: 0.0057, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1094, Step num: 14765, Learning rate: 0.00007274, Avg batch loss: 0.0041, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1095, Step num: 14766, Learning rate: 0.00007274, Avg batch loss: 0.0055, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1096, Step num: 14767, Learning rate: 0.00007274, Avg batch loss: 0.0063, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1097, Step num: 14768, Learning rate: 0.00007273, Avg batch loss: 0.0055, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 1098, Step num: 14769, Learning rate: 0.00007273, Avg batch loss: 0.0061, Avg batch acc: 0.9917
Train, Epoch: 10, Batch: 1099, Step num: 14770, Learning rate: 0.00007273, Avg batch loss: 0.0051, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1100, Step num: 14771, Learning rate: 0.00007273, Avg batch loss: 0.0048, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1101, Step num: 14772, Learning rate: 0.00007272, Avg batch loss: 0.0051, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1102, Step num: 14773, Learning rate: 0.00007272, Avg batch loss: 0.0050, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1103, Step num: 14774, Learning rate: 0.00007272, Avg batch loss: 0.0048, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1104, Step num: 14775, Learning rate: 0.00007272, Avg batch loss: 0.0037, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1105, Step num: 14776, Learning rate: 0.00007271, Avg batch loss: 0.0050, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 1106, Step num: 14777, Learning rate: 0.00007271, Avg batch loss: 0.0050, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1107, Step num: 14778, Learning rate: 0.00007271, Avg batch loss: 0.0036, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 1108, Step num: 14779, Learning rate: 0.00007271, Avg batch loss: 0.0067, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1109, Step num: 14780, Learning rate: 0.00007270, Avg batch loss: 0.0046, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1110, Step num: 14781, Learning rate: 0.00007270, Avg batch loss: 0.0051, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 1111, Step num: 14782, Learning rate: 0.00007270, Avg batch loss: 0.0076, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 1112, Step num: 14783, Learning rate: 0.00007270, Avg batch loss: 0.0037, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1113, Step num: 14784, Learning rate: 0.00007269, Avg batch loss: 0.0056, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1114, Step num: 14785, Learning rate: 0.00007269, Avg batch loss: 0.0060, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 1115, Step num: 14786, Learning rate: 0.00007269, Avg batch loss: 0.0048, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 1116, Step num: 14787, Learning rate: 0.00007269, Avg batch loss: 0.0121, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 1117, Step num: 14788, Learning rate: 0.00007268, Avg batch loss: 0.0055, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 1118, Step num: 14789, Learning rate: 0.00007268, Avg batch loss: 0.0471, Avg batch acc: 0.9879
Train, Epoch: 10, Batch: 1119, Step num: 14790, Learning rate: 0.00007268, Avg batch loss: 0.0113, Avg batch acc: 0.9913
Train, Epoch: 10, Batch: 1120, Step num: 14791, Learning rate: 0.00007268, Avg batch loss: 0.0048, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 1121, Step num: 14792, Learning rate: 0.00007267, Avg batch loss: 0.0073, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1122, Step num: 14793, Learning rate: 0.00007267, Avg batch loss: 0.0058, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1123, Step num: 14794, Learning rate: 0.00007267, Avg batch loss: 0.0038, Avg batch acc: 0.9974
Train, Epoch: 10, Batch: 1124, Step num: 14795, Learning rate: 0.00007267, Avg batch loss: 0.0064, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 1125, Step num: 14796, Learning rate: 0.00007266, Avg batch loss: 0.0057, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1126, Step num: 14797, Learning rate: 0.00007266, Avg batch loss: 0.0089, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1127, Step num: 14798, Learning rate: 0.00007266, Avg batch loss: 0.0041, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1128, Step num: 14799, Learning rate: 0.00007266, Avg batch loss: 0.0065, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 1129, Step num: 14800, Learning rate: 0.00007265, Avg batch loss: 0.0076, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1130, Step num: 14801, Learning rate: 0.00007265, Avg batch loss: 0.0091, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 1131, Step num: 14802, Learning rate: 0.00007265, Avg batch loss: 0.0061, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1132, Step num: 14803, Learning rate: 0.00007265, Avg batch loss: 0.0040, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1133, Step num: 14804, Learning rate: 0.00007264, Avg batch loss: 0.0055, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1134, Step num: 14805, Learning rate: 0.00007264, Avg batch loss: 0.0048, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1135, Step num: 14806, Learning rate: 0.00007264, Avg batch loss: 0.0043, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 1136, Step num: 14807, Learning rate: 0.00007264, Avg batch loss: 0.0057, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1137, Step num: 14808, Learning rate: 0.00007264, Avg batch loss: 0.0077, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 1138, Step num: 14809, Learning rate: 0.00007263, Avg batch loss: 0.0066, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 1139, Step num: 14810, Learning rate: 0.00007263, Avg batch loss: 0.0072, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1140, Step num: 14811, Learning rate: 0.00007263, Avg batch loss: 0.0040, Avg batch acc: 0.9973
Train, Epoch: 10, Batch: 1141, Step num: 14812, Learning rate: 0.00007263, Avg batch loss: 0.0037, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1142, Step num: 14813, Learning rate: 0.00007262, Avg batch loss: 0.0058, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1143, Step num: 14814, Learning rate: 0.00007262, Avg batch loss: 0.0060, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1144, Step num: 14815, Learning rate: 0.00007262, Avg batch loss: 0.0034, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 1145, Step num: 14816, Learning rate: 0.00007262, Avg batch loss: 0.0037, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1146, Step num: 14817, Learning rate: 0.00007261, Avg batch loss: 0.0044, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 1147, Step num: 14818, Learning rate: 0.00007261, Avg batch loss: 0.0083, Avg batch acc: 0.9916
Train, Epoch: 10, Batch: 1148, Step num: 14819, Learning rate: 0.00007261, Avg batch loss: 0.0062, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1149, Step num: 14820, Learning rate: 0.00007261, Avg batch loss: 0.0043, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 1150, Step num: 14821, Learning rate: 0.00007260, Avg batch loss: 0.0046, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1151, Step num: 14822, Learning rate: 0.00007260, Avg batch loss: 0.0046, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1152, Step num: 14823, Learning rate: 0.00007260, Avg batch loss: 0.0050, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1153, Step num: 14824, Learning rate: 0.00007260, Avg batch loss: 0.0045, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1154, Step num: 14825, Learning rate: 0.00007259, Avg batch loss: 0.0075, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 1155, Step num: 14826, Learning rate: 0.00007259, Avg batch loss: 0.0042, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1156, Step num: 14827, Learning rate: 0.00007259, Avg batch loss: 0.0049, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 1157, Step num: 14828, Learning rate: 0.00007259, Avg batch loss: 0.0043, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1158, Step num: 14829, Learning rate: 0.00007258, Avg batch loss: 0.0056, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1159, Step num: 14830, Learning rate: 0.00007258, Avg batch loss: 0.0044, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 1160, Step num: 14831, Learning rate: 0.00007258, Avg batch loss: 0.0054, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1161, Step num: 14832, Learning rate: 0.00007258, Avg batch loss: 0.0068, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 1162, Step num: 14833, Learning rate: 0.00007257, Avg batch loss: 0.0033, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 1163, Step num: 14834, Learning rate: 0.00007257, Avg batch loss: 0.0051, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1164, Step num: 14835, Learning rate: 0.00007257, Avg batch loss: 0.0037, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1165, Step num: 14836, Learning rate: 0.00007257, Avg batch loss: 0.0057, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 1166, Step num: 14837, Learning rate: 0.00007256, Avg batch loss: 0.0048, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1167, Step num: 14838, Learning rate: 0.00007256, Avg batch loss: 0.0059, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1168, Step num: 14839, Learning rate: 0.00007256, Avg batch loss: 0.0051, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1169, Step num: 14840, Learning rate: 0.00007256, Avg batch loss: 0.0058, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 1170, Step num: 14841, Learning rate: 0.00007255, Avg batch loss: 0.0042, Avg batch acc: 0.9974
Train, Epoch: 10, Batch: 1171, Step num: 14842, Learning rate: 0.00007255, Avg batch loss: 0.0043, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1172, Step num: 14843, Learning rate: 0.00007255, Avg batch loss: 0.0048, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 1173, Step num: 14844, Learning rate: 0.00007255, Avg batch loss: 0.0064, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1174, Step num: 14845, Learning rate: 0.00007254, Avg batch loss: 0.0042, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 1175, Step num: 14846, Learning rate: 0.00007254, Avg batch loss: 0.0038, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 1176, Step num: 14847, Learning rate: 0.00007254, Avg batch loss: 0.0044, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1177, Step num: 14848, Learning rate: 0.00007254, Avg batch loss: 0.0043, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1178, Step num: 14849, Learning rate: 0.00007253, Avg batch loss: 0.0059, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 1179, Step num: 14850, Learning rate: 0.00007253, Avg batch loss: 0.0030, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1180, Step num: 14851, Learning rate: 0.00007253, Avg batch loss: 0.0049, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1181, Step num: 14852, Learning rate: 0.00007253, Avg batch loss: 0.0051, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1182, Step num: 14853, Learning rate: 0.00007253, Avg batch loss: 0.0063, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1183, Step num: 14854, Learning rate: 0.00007252, Avg batch loss: 0.0037, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1184, Step num: 14855, Learning rate: 0.00007252, Avg batch loss: 0.0055, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 1185, Step num: 14856, Learning rate: 0.00007252, Avg batch loss: 0.0041, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1186, Step num: 14857, Learning rate: 0.00007252, Avg batch loss: 0.0051, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1187, Step num: 14858, Learning rate: 0.00007251, Avg batch loss: 0.0052, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1188, Step num: 14859, Learning rate: 0.00007251, Avg batch loss: 0.0070, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 1189, Step num: 14860, Learning rate: 0.00007251, Avg batch loss: 0.0052, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1190, Step num: 14861, Learning rate: 0.00007251, Avg batch loss: 0.0056, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 1191, Step num: 14862, Learning rate: 0.00007250, Avg batch loss: 0.0068, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1192, Step num: 14863, Learning rate: 0.00007250, Avg batch loss: 0.0050, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1193, Step num: 14864, Learning rate: 0.00007250, Avg batch loss: 0.0093, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 1194, Step num: 14865, Learning rate: 0.00007250, Avg batch loss: 0.0049, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1195, Step num: 14866, Learning rate: 0.00007249, Avg batch loss: 0.0044, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1196, Step num: 14867, Learning rate: 0.00007249, Avg batch loss: 0.0063, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1197, Step num: 14868, Learning rate: 0.00007249, Avg batch loss: 0.0261, Avg batch acc: 0.9897
Train, Epoch: 10, Batch: 1198, Step num: 14869, Learning rate: 0.00007249, Avg batch loss: 0.0048, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1199, Step num: 14870, Learning rate: 0.00007248, Avg batch loss: 0.0082, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 1200, Step num: 14871, Learning rate: 0.00007248, Avg batch loss: 0.0051, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1201, Step num: 14872, Learning rate: 0.00007248, Avg batch loss: 0.0053, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1202, Step num: 14873, Learning rate: 0.00007248, Avg batch loss: 0.0044, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1203, Step num: 14874, Learning rate: 0.00007247, Avg batch loss: 0.0065, Avg batch acc: 0.9932
Train, Epoch: 10, Batch: 1204, Step num: 14875, Learning rate: 0.00007247, Avg batch loss: 0.0085, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 1205, Step num: 14876, Learning rate: 0.00007247, Avg batch loss: 0.0041, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 1206, Step num: 14877, Learning rate: 0.00007247, Avg batch loss: 0.0053, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1207, Step num: 14878, Learning rate: 0.00007246, Avg batch loss: 0.0037, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 1208, Step num: 14879, Learning rate: 0.00007246, Avg batch loss: 0.0078, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 1209, Step num: 14880, Learning rate: 0.00007246, Avg batch loss: 0.0113, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 1210, Step num: 14881, Learning rate: 0.00007246, Avg batch loss: 0.0091, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 1211, Step num: 14882, Learning rate: 0.00007245, Avg batch loss: 0.0051, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1212, Step num: 14883, Learning rate: 0.00007245, Avg batch loss: 0.0057, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1213, Step num: 14884, Learning rate: 0.00007245, Avg batch loss: 0.0070, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 1214, Step num: 14885, Learning rate: 0.00007245, Avg batch loss: 0.0040, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1215, Step num: 14886, Learning rate: 0.00007244, Avg batch loss: 0.0049, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1216, Step num: 14887, Learning rate: 0.00007244, Avg batch loss: 0.0042, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 1217, Step num: 14888, Learning rate: 0.00007244, Avg batch loss: 0.0049, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1218, Step num: 14889, Learning rate: 0.00007244, Avg batch loss: 0.0054, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1219, Step num: 14890, Learning rate: 0.00007243, Avg batch loss: 0.0064, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 1220, Step num: 14891, Learning rate: 0.00007243, Avg batch loss: 0.0057, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 1221, Step num: 14892, Learning rate: 0.00007243, Avg batch loss: 0.0056, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1222, Step num: 14893, Learning rate: 0.00007243, Avg batch loss: 0.0040, Avg batch acc: 0.9978
Train, Epoch: 10, Batch: 1223, Step num: 14894, Learning rate: 0.00007243, Avg batch loss: 0.0068, Avg batch acc: 0.9912
Train, Epoch: 10, Batch: 1224, Step num: 14895, Learning rate: 0.00007242, Avg batch loss: 0.0064, Avg batch acc: 0.9917
Train, Epoch: 10, Batch: 1225, Step num: 14896, Learning rate: 0.00007242, Avg batch loss: 0.0055, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1226, Step num: 14897, Learning rate: 0.00007242, Avg batch loss: 0.0033, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1227, Step num: 14898, Learning rate: 0.00007242, Avg batch loss: 0.0063, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1228, Step num: 14899, Learning rate: 0.00007241, Avg batch loss: 0.0054, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1229, Step num: 14900, Learning rate: 0.00007241, Avg batch loss: 0.0041, Avg batch acc: 0.9974
Train, Epoch: 10, Batch: 1230, Step num: 14901, Learning rate: 0.00007241, Avg batch loss: 0.0047, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1231, Step num: 14902, Learning rate: 0.00007241, Avg batch loss: 0.0036, Avg batch acc: 0.9979
Train, Epoch: 10, Batch: 1232, Step num: 14903, Learning rate: 0.00007240, Avg batch loss: 0.0069, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1233, Step num: 14904, Learning rate: 0.00007240, Avg batch loss: 0.0055, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1234, Step num: 14905, Learning rate: 0.00007240, Avg batch loss: 0.0045, Avg batch acc: 0.9901
Train, Epoch: 10, Batch: 1235, Step num: 14906, Learning rate: 0.00007240, Avg batch loss: 0.0049, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1236, Step num: 14907, Learning rate: 0.00007239, Avg batch loss: 0.0038, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1237, Step num: 14908, Learning rate: 0.00007239, Avg batch loss: 0.0047, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1238, Step num: 14909, Learning rate: 0.00007239, Avg batch loss: 0.0037, Avg batch acc: 0.9975
Train, Epoch: 10, Batch: 1239, Step num: 14910, Learning rate: 0.00007239, Avg batch loss: 0.0060, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 1240, Step num: 14911, Learning rate: 0.00007238, Avg batch loss: 0.0061, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1241, Step num: 14912, Learning rate: 0.00007238, Avg batch loss: 0.0042, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 1242, Step num: 14913, Learning rate: 0.00007238, Avg batch loss: 0.0060, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1243, Step num: 14914, Learning rate: 0.00007238, Avg batch loss: 0.0056, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 1244, Step num: 14915, Learning rate: 0.00007237, Avg batch loss: 0.0052, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1245, Step num: 14916, Learning rate: 0.00007237, Avg batch loss: 0.0044, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1246, Step num: 14917, Learning rate: 0.00007237, Avg batch loss: 0.0041, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1247, Step num: 14918, Learning rate: 0.00007237, Avg batch loss: 0.0051, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1248, Step num: 14919, Learning rate: 0.00007236, Avg batch loss: 0.0036, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 1249, Step num: 14920, Learning rate: 0.00007236, Avg batch loss: 0.0038, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1250, Step num: 14921, Learning rate: 0.00007236, Avg batch loss: 0.0042, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1251, Step num: 14922, Learning rate: 0.00007236, Avg batch loss: 0.0043, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1252, Step num: 14923, Learning rate: 0.00007235, Avg batch loss: 0.0061, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 1253, Step num: 14924, Learning rate: 0.00007235, Avg batch loss: 0.0048, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1254, Step num: 14925, Learning rate: 0.00007235, Avg batch loss: 0.0064, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 1255, Step num: 14926, Learning rate: 0.00007235, Avg batch loss: 0.0058, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 1256, Step num: 14927, Learning rate: 0.00007235, Avg batch loss: 0.0052, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1257, Step num: 14928, Learning rate: 0.00007234, Avg batch loss: 0.0048, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1258, Step num: 14929, Learning rate: 0.00007234, Avg batch loss: 0.0051, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1259, Step num: 14930, Learning rate: 0.00007234, Avg batch loss: 0.0045, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1260, Step num: 14931, Learning rate: 0.00007234, Avg batch loss: 0.0060, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1261, Step num: 14932, Learning rate: 0.00007233, Avg batch loss: 0.0039, Avg batch acc: 0.9975
Train, Epoch: 10, Batch: 1262, Step num: 14933, Learning rate: 0.00007233, Avg batch loss: 0.0044, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1263, Step num: 14934, Learning rate: 0.00007233, Avg batch loss: 0.0059, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1264, Step num: 14935, Learning rate: 0.00007233, Avg batch loss: 0.0035, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1265, Step num: 14936, Learning rate: 0.00007232, Avg batch loss: 0.0036, Avg batch acc: 0.9973
Train, Epoch: 10, Batch: 1266, Step num: 14937, Learning rate: 0.00007232, Avg batch loss: 0.0050, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1267, Step num: 14938, Learning rate: 0.00007232, Avg batch loss: 0.0050, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1268, Step num: 14939, Learning rate: 0.00007232, Avg batch loss: 0.0047, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1269, Step num: 14940, Learning rate: 0.00007231, Avg batch loss: 0.0037, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 1270, Step num: 14941, Learning rate: 0.00007231, Avg batch loss: 0.0064, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 1271, Step num: 14942, Learning rate: 0.00007231, Avg batch loss: 0.0041, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1272, Step num: 14943, Learning rate: 0.00007231, Avg batch loss: 0.0047, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1273, Step num: 14944, Learning rate: 0.00007230, Avg batch loss: 0.0036, Avg batch acc: 0.9975
Train, Epoch: 10, Batch: 1274, Step num: 14945, Learning rate: 0.00007230, Avg batch loss: 0.0044, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1275, Step num: 14946, Learning rate: 0.00007230, Avg batch loss: 0.0044, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1276, Step num: 14947, Learning rate: 0.00007230, Avg batch loss: 0.0067, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1277, Step num: 14948, Learning rate: 0.00007229, Avg batch loss: 0.0049, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1278, Step num: 14949, Learning rate: 0.00007229, Avg batch loss: 0.0083, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1279, Step num: 14950, Learning rate: 0.00007229, Avg batch loss: 0.0046, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1280, Step num: 14951, Learning rate: 0.00007229, Avg batch loss: 0.0043, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1281, Step num: 14952, Learning rate: 0.00007228, Avg batch loss: 0.0044, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 1282, Step num: 14953, Learning rate: 0.00007228, Avg batch loss: 0.0054, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1283, Step num: 14954, Learning rate: 0.00007228, Avg batch loss: 0.0067, Avg batch acc: 0.9931
Train, Epoch: 10, Batch: 1284, Step num: 14955, Learning rate: 0.00007228, Avg batch loss: 0.0061, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1285, Step num: 14956, Learning rate: 0.00007227, Avg batch loss: 0.0043, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1286, Step num: 14957, Learning rate: 0.00007227, Avg batch loss: 0.0063, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 1287, Step num: 14958, Learning rate: 0.00007227, Avg batch loss: 0.0053, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1288, Step num: 14959, Learning rate: 0.00007227, Avg batch loss: 0.0073, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 1289, Step num: 14960, Learning rate: 0.00007227, Avg batch loss: 0.0054, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1290, Step num: 14961, Learning rate: 0.00007226, Avg batch loss: 0.0061, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 1291, Step num: 14962, Learning rate: 0.00007226, Avg batch loss: 0.0073, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 1292, Step num: 14963, Learning rate: 0.00007226, Avg batch loss: 0.0050, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1293, Step num: 14964, Learning rate: 0.00007226, Avg batch loss: 0.0052, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1294, Step num: 14965, Learning rate: 0.00007225, Avg batch loss: 0.0051, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1295, Step num: 14966, Learning rate: 0.00007225, Avg batch loss: 0.0073, Avg batch acc: 0.9897
Train, Epoch: 10, Batch: 1296, Step num: 14967, Learning rate: 0.00007225, Avg batch loss: 0.0055, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 1297, Step num: 14968, Learning rate: 0.00007225, Avg batch loss: 0.0042, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1298, Step num: 14969, Learning rate: 0.00007224, Avg batch loss: 0.0040, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 1299, Step num: 14970, Learning rate: 0.00007224, Avg batch loss: 0.0053, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1300, Step num: 14971, Learning rate: 0.00007224, Avg batch loss: 0.0047, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1301, Step num: 14972, Learning rate: 0.00007224, Avg batch loss: 0.0055, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1302, Step num: 14973, Learning rate: 0.00007223, Avg batch loss: 0.0061, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 1303, Step num: 14974, Learning rate: 0.00007223, Avg batch loss: 0.0066, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 1304, Step num: 14975, Learning rate: 0.00007223, Avg batch loss: 0.0040, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1305, Step num: 14976, Learning rate: 0.00007223, Avg batch loss: 0.0058, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1306, Step num: 14977, Learning rate: 0.00007222, Avg batch loss: 0.0065, Avg batch acc: 0.9915
Train, Epoch: 10, Batch: 1307, Step num: 14978, Learning rate: 0.00007222, Avg batch loss: 0.0028, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1308, Step num: 14979, Learning rate: 0.00007222, Avg batch loss: 0.0050, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1309, Step num: 14980, Learning rate: 0.00007222, Avg batch loss: 0.0066, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 1310, Step num: 14981, Learning rate: 0.00007221, Avg batch loss: 0.0058, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 1311, Step num: 14982, Learning rate: 0.00007221, Avg batch loss: 0.0053, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1312, Step num: 14983, Learning rate: 0.00007221, Avg batch loss: 0.0051, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1313, Step num: 14984, Learning rate: 0.00007221, Avg batch loss: 0.0061, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1314, Step num: 14985, Learning rate: 0.00007220, Avg batch loss: 0.0067, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1315, Step num: 14986, Learning rate: 0.00007220, Avg batch loss: 0.0053, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1316, Step num: 14987, Learning rate: 0.00007220, Avg batch loss: 0.0054, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1317, Step num: 14988, Learning rate: 0.00007220, Avg batch loss: 0.0051, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1318, Step num: 14989, Learning rate: 0.00007220, Avg batch loss: 0.0040, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1319, Step num: 14990, Learning rate: 0.00007219, Avg batch loss: 0.0053, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1320, Step num: 14991, Learning rate: 0.00007219, Avg batch loss: 0.0055, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 1321, Step num: 14992, Learning rate: 0.00007219, Avg batch loss: 0.0040, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1322, Step num: 14993, Learning rate: 0.00007219, Avg batch loss: 0.0056, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 1323, Step num: 14994, Learning rate: 0.00007218, Avg batch loss: 0.0057, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 1324, Step num: 14995, Learning rate: 0.00007218, Avg batch loss: 0.0055, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1325, Step num: 14996, Learning rate: 0.00007218, Avg batch loss: 0.0041, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1326, Step num: 14997, Learning rate: 0.00007218, Avg batch loss: 0.0060, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1327, Step num: 14998, Learning rate: 0.00007217, Avg batch loss: 0.0053, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1328, Step num: 14999, Learning rate: 0.00007217, Avg batch loss: 0.0049, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1329, Step num: 15000, Learning rate: 0.00007217, Avg batch loss: 0.0050, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1330, Step num: 15001, Learning rate: 0.00007217, Avg batch loss: 0.0074, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 1331, Step num: 15002, Learning rate: 0.00007216, Avg batch loss: 0.0049, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1332, Step num: 15003, Learning rate: 0.00007216, Avg batch loss: 0.0032, Avg batch acc: 0.9973
Train, Epoch: 10, Batch: 1333, Step num: 15004, Learning rate: 0.00007216, Avg batch loss: 0.0057, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1334, Step num: 15005, Learning rate: 0.00007216, Avg batch loss: 0.0052, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1335, Step num: 15006, Learning rate: 0.00007215, Avg batch loss: 0.0048, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1336, Step num: 15007, Learning rate: 0.00007215, Avg batch loss: 0.0054, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 1337, Step num: 15008, Learning rate: 0.00007215, Avg batch loss: 0.0075, Avg batch acc: 0.9928
Train, Epoch: 10, Batch: 1338, Step num: 15009, Learning rate: 0.00007215, Avg batch loss: 0.0042, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 1339, Step num: 15010, Learning rate: 0.00007214, Avg batch loss: 0.0051, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1340, Step num: 15011, Learning rate: 0.00007214, Avg batch loss: 0.0063, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1341, Step num: 15012, Learning rate: 0.00007214, Avg batch loss: 0.0043, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 1342, Step num: 15013, Learning rate: 0.00007214, Avg batch loss: 0.0035, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 1343, Step num: 15014, Learning rate: 0.00007214, Avg batch loss: 0.0044, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1344, Step num: 15015, Learning rate: 0.00007213, Avg batch loss: 0.0063, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 1345, Step num: 15016, Learning rate: 0.00007213, Avg batch loss: 0.0062, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 1346, Step num: 15017, Learning rate: 0.00007213, Avg batch loss: 0.0043, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1347, Step num: 15018, Learning rate: 0.00007213, Avg batch loss: 0.0053, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1348, Step num: 15019, Learning rate: 0.00007212, Avg batch loss: 0.0052, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1349, Step num: 15020, Learning rate: 0.00007212, Avg batch loss: 0.0057, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1350, Step num: 15021, Learning rate: 0.00007212, Avg batch loss: 0.0053, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 1351, Step num: 15022, Learning rate: 0.00007212, Avg batch loss: 0.0085, Avg batch acc: 0.9889
Train, Epoch: 10, Batch: 1352, Step num: 15023, Learning rate: 0.00007211, Avg batch loss: 0.0055, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 1353, Step num: 15024, Learning rate: 0.00007211, Avg batch loss: 0.0037, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1354, Step num: 15025, Learning rate: 0.00007211, Avg batch loss: 0.0057, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1355, Step num: 15026, Learning rate: 0.00007211, Avg batch loss: 0.0048, Avg batch acc: 0.9971
Train, Epoch: 10, Batch: 1356, Step num: 15027, Learning rate: 0.00007210, Avg batch loss: 0.0044, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 1357, Step num: 15028, Learning rate: 0.00007210, Avg batch loss: 0.0047, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 1358, Step num: 15029, Learning rate: 0.00007210, Avg batch loss: 0.0046, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1359, Step num: 15030, Learning rate: 0.00007210, Avg batch loss: 0.0082, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1360, Step num: 15031, Learning rate: 0.00007209, Avg batch loss: 0.0055, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 1361, Step num: 15032, Learning rate: 0.00007209, Avg batch loss: 0.0066, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1362, Step num: 15033, Learning rate: 0.00007209, Avg batch loss: 0.0050, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1363, Step num: 15034, Learning rate: 0.00007209, Avg batch loss: 0.0065, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1364, Step num: 15035, Learning rate: 0.00007208, Avg batch loss: 0.0044, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1365, Step num: 15036, Learning rate: 0.00007208, Avg batch loss: 0.0035, Avg batch acc: 0.9960
Train, Epoch: 10, Batch: 1366, Step num: 15037, Learning rate: 0.00007208, Avg batch loss: 0.0030, Avg batch acc: 0.9972
Train, Epoch: 10, Batch: 1367, Step num: 15038, Learning rate: 0.00007208, Avg batch loss: 0.0025, Avg batch acc: 0.9983
Train, Epoch: 10, Batch: 1368, Step num: 15039, Learning rate: 0.00007208, Avg batch loss: 0.0061, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 1369, Step num: 15040, Learning rate: 0.00007207, Avg batch loss: 0.0041, Avg batch acc: 0.9962
Train, Epoch: 10, Batch: 1370, Step num: 15041, Learning rate: 0.00007207, Avg batch loss: 0.0051, Avg batch acc: 0.9939
Train, Epoch: 10, Batch: 1371, Step num: 15042, Learning rate: 0.00007207, Avg batch loss: 0.0056, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1372, Step num: 15043, Learning rate: 0.00007207, Avg batch loss: 0.0053, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1373, Step num: 15044, Learning rate: 0.00007206, Avg batch loss: 0.0050, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1374, Step num: 15045, Learning rate: 0.00007206, Avg batch loss: 0.0046, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1375, Step num: 15046, Learning rate: 0.00007206, Avg batch loss: 0.0037, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1376, Step num: 15047, Learning rate: 0.00007206, Avg batch loss: 0.0062, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 1377, Step num: 15048, Learning rate: 0.00007205, Avg batch loss: 0.0069, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 1378, Step num: 15049, Learning rate: 0.00007205, Avg batch loss: 0.0064, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 1379, Step num: 15050, Learning rate: 0.00007205, Avg batch loss: 0.0056, Avg batch acc: 0.9923
Train, Epoch: 10, Batch: 1380, Step num: 15051, Learning rate: 0.00007205, Avg batch loss: 0.0039, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1381, Step num: 15052, Learning rate: 0.00007204, Avg batch loss: 0.0058, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 1382, Step num: 15053, Learning rate: 0.00007204, Avg batch loss: 0.0044, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1383, Step num: 15054, Learning rate: 0.00007204, Avg batch loss: 0.0063, Avg batch acc: 0.9927
Train, Epoch: 10, Batch: 1384, Step num: 15055, Learning rate: 0.00007204, Avg batch loss: 0.0045, Avg batch acc: 0.9961
Train, Epoch: 10, Batch: 1385, Step num: 15056, Learning rate: 0.00007203, Avg batch loss: 0.0052, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1386, Step num: 15057, Learning rate: 0.00007203, Avg batch loss: 0.0066, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1387, Step num: 15058, Learning rate: 0.00007203, Avg batch loss: 0.0034, Avg batch acc: 0.9982
Train, Epoch: 10, Batch: 1388, Step num: 15059, Learning rate: 0.00007203, Avg batch loss: 0.0051, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1389, Step num: 15060, Learning rate: 0.00007202, Avg batch loss: 0.0045, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 1390, Step num: 15061, Learning rate: 0.00007202, Avg batch loss: 0.0065, Avg batch acc: 0.9919
Train, Epoch: 10, Batch: 1391, Step num: 15062, Learning rate: 0.00007202, Avg batch loss: 0.0042, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 1392, Step num: 15063, Learning rate: 0.00007202, Avg batch loss: 0.0051, Avg batch acc: 0.9922
Train, Epoch: 10, Batch: 1393, Step num: 15064, Learning rate: 0.00007202, Avg batch loss: 0.0054, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 1394, Step num: 15065, Learning rate: 0.00007201, Avg batch loss: 0.0055, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 1395, Step num: 15066, Learning rate: 0.00007201, Avg batch loss: 0.0043, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1396, Step num: 15067, Learning rate: 0.00007201, Avg batch loss: 0.0041, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1397, Step num: 15068, Learning rate: 0.00007201, Avg batch loss: 0.0052, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1398, Step num: 15069, Learning rate: 0.00007200, Avg batch loss: 0.0059, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1399, Step num: 15070, Learning rate: 0.00007200, Avg batch loss: 0.0047, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1400, Step num: 15071, Learning rate: 0.00007200, Avg batch loss: 0.0061, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1401, Step num: 15072, Learning rate: 0.00007200, Avg batch loss: 0.0049, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1402, Step num: 15073, Learning rate: 0.00007199, Avg batch loss: 0.0039, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1403, Step num: 15074, Learning rate: 0.00007199, Avg batch loss: 0.0057, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 1404, Step num: 15075, Learning rate: 0.00007199, Avg batch loss: 0.0031, Avg batch acc: 0.9982
Train, Epoch: 10, Batch: 1405, Step num: 15076, Learning rate: 0.00007199, Avg batch loss: 0.0051, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1406, Step num: 15077, Learning rate: 0.00007198, Avg batch loss: 0.0055, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1407, Step num: 15078, Learning rate: 0.00007198, Avg batch loss: 0.0042, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1408, Step num: 15079, Learning rate: 0.00007198, Avg batch loss: 0.0053, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 1409, Step num: 15080, Learning rate: 0.00007198, Avg batch loss: 0.0039, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 1410, Step num: 15081, Learning rate: 0.00007197, Avg batch loss: 0.0044, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 1411, Step num: 15082, Learning rate: 0.00007197, Avg batch loss: 0.0055, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1412, Step num: 15083, Learning rate: 0.00007197, Avg batch loss: 0.0053, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1413, Step num: 15084, Learning rate: 0.00007197, Avg batch loss: 0.0042, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1414, Step num: 15085, Learning rate: 0.00007197, Avg batch loss: 0.0038, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1415, Step num: 15086, Learning rate: 0.00007196, Avg batch loss: 0.0040, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 1416, Step num: 15087, Learning rate: 0.00007196, Avg batch loss: 0.0040, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1417, Step num: 15088, Learning rate: 0.00007196, Avg batch loss: 0.0034, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 1418, Step num: 15089, Learning rate: 0.00007196, Avg batch loss: 0.0063, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1419, Step num: 15090, Learning rate: 0.00007195, Avg batch loss: 0.0057, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1420, Step num: 15091, Learning rate: 0.00007195, Avg batch loss: 0.0056, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1421, Step num: 15092, Learning rate: 0.00007195, Avg batch loss: 0.0045, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1422, Step num: 15093, Learning rate: 0.00007195, Avg batch loss: 0.0040, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1423, Step num: 15094, Learning rate: 0.00007194, Avg batch loss: 0.0036, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 1424, Step num: 15095, Learning rate: 0.00007194, Avg batch loss: 0.0048, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1425, Step num: 15096, Learning rate: 0.00007194, Avg batch loss: 0.0059, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1426, Step num: 15097, Learning rate: 0.00007194, Avg batch loss: 0.0060, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 1427, Step num: 15098, Learning rate: 0.00007193, Avg batch loss: 0.0062, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1428, Step num: 15099, Learning rate: 0.00007193, Avg batch loss: 0.0043, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1429, Step num: 15100, Learning rate: 0.00007193, Avg batch loss: 0.0032, Avg batch acc: 0.9969
Train, Epoch: 10, Batch: 1430, Step num: 15101, Learning rate: 0.00007193, Avg batch loss: 0.0042, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1431, Step num: 15102, Learning rate: 0.00007192, Avg batch loss: 0.0037, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1432, Step num: 15103, Learning rate: 0.00007192, Avg batch loss: 0.0035, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1433, Step num: 15104, Learning rate: 0.00007192, Avg batch loss: 0.0044, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1434, Step num: 15105, Learning rate: 0.00007192, Avg batch loss: 0.0068, Avg batch acc: 0.9912
Train, Epoch: 10, Batch: 1435, Step num: 15106, Learning rate: 0.00007192, Avg batch loss: 0.0053, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1436, Step num: 15107, Learning rate: 0.00007191, Avg batch loss: 0.0058, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1437, Step num: 15108, Learning rate: 0.00007191, Avg batch loss: 0.0057, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 1438, Step num: 15109, Learning rate: 0.00007191, Avg batch loss: 0.0066, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1439, Step num: 15110, Learning rate: 0.00007191, Avg batch loss: 0.0068, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 1440, Step num: 15111, Learning rate: 0.00007190, Avg batch loss: 0.0050, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1441, Step num: 15112, Learning rate: 0.00007190, Avg batch loss: 0.0069, Avg batch acc: 0.9914
Train, Epoch: 10, Batch: 1442, Step num: 15113, Learning rate: 0.00007190, Avg batch loss: 0.0066, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 1443, Step num: 15114, Learning rate: 0.00007190, Avg batch loss: 0.0044, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1444, Step num: 15115, Learning rate: 0.00007189, Avg batch loss: 0.0054, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 1445, Step num: 15116, Learning rate: 0.00007189, Avg batch loss: 0.0058, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1446, Step num: 15117, Learning rate: 0.00007189, Avg batch loss: 0.0047, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 1447, Step num: 15118, Learning rate: 0.00007189, Avg batch loss: 0.0056, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1448, Step num: 15119, Learning rate: 0.00007188, Avg batch loss: 0.0046, Avg batch acc: 0.9970
Train, Epoch: 10, Batch: 1449, Step num: 15120, Learning rate: 0.00007188, Avg batch loss: 0.0039, Avg batch acc: 0.9968
Train, Epoch: 10, Batch: 1450, Step num: 15121, Learning rate: 0.00007188, Avg batch loss: 0.0043, Avg batch acc: 0.9975
Train, Epoch: 10, Batch: 1451, Step num: 15122, Learning rate: 0.00007188, Avg batch loss: 0.0057, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1452, Step num: 15123, Learning rate: 0.00007187, Avg batch loss: 0.0057, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1453, Step num: 15124, Learning rate: 0.00007187, Avg batch loss: 0.0064, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1454, Step num: 15125, Learning rate: 0.00007187, Avg batch loss: 0.0200, Avg batch acc: 0.9924
Train, Epoch: 10, Batch: 1455, Step num: 15126, Learning rate: 0.00007187, Avg batch loss: 0.0056, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1456, Step num: 15127, Learning rate: 0.00007187, Avg batch loss: 0.0049, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1457, Step num: 15128, Learning rate: 0.00007186, Avg batch loss: 0.0058, Avg batch acc: 0.9942
Train, Epoch: 10, Batch: 1458, Step num: 15129, Learning rate: 0.00007186, Avg batch loss: 0.0075, Avg batch acc: 0.9933
Train, Epoch: 10, Batch: 1459, Step num: 15130, Learning rate: 0.00007186, Avg batch loss: 0.0047, Avg batch acc: 0.9950
Train, Epoch: 10, Batch: 1460, Step num: 15131, Learning rate: 0.00007186, Avg batch loss: 0.0052, Avg batch acc: 0.9967
Train, Epoch: 10, Batch: 1461, Step num: 15132, Learning rate: 0.00007185, Avg batch loss: 0.0053, Avg batch acc: 0.9946
Train, Epoch: 10, Batch: 1462, Step num: 15133, Learning rate: 0.00007185, Avg batch loss: 0.0061, Avg batch acc: 0.9920
Train, Epoch: 10, Batch: 1463, Step num: 15134, Learning rate: 0.00007185, Avg batch loss: 0.0045, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1464, Step num: 15135, Learning rate: 0.00007185, Avg batch loss: 0.0040, Avg batch acc: 0.9964
Train, Epoch: 10, Batch: 1465, Step num: 15136, Learning rate: 0.00007184, Avg batch loss: 0.0052, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1466, Step num: 15137, Learning rate: 0.00007184, Avg batch loss: 0.0062, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1467, Step num: 15138, Learning rate: 0.00007184, Avg batch loss: 0.0040, Avg batch acc: 0.9955
Train, Epoch: 10, Batch: 1468, Step num: 15139, Learning rate: 0.00007184, Avg batch loss: 0.0052, Avg batch acc: 0.9956
Train, Epoch: 10, Batch: 1469, Step num: 15140, Learning rate: 0.00007183, Avg batch loss: 0.0053, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1470, Step num: 15141, Learning rate: 0.00007183, Avg batch loss: 0.0069, Avg batch acc: 0.9948
Train, Epoch: 10, Batch: 1471, Step num: 15142, Learning rate: 0.00007183, Avg batch loss: 0.0046, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1472, Step num: 15143, Learning rate: 0.00007183, Avg batch loss: 0.0062, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1473, Step num: 15144, Learning rate: 0.00007182, Avg batch loss: 0.0037, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1474, Step num: 15145, Learning rate: 0.00007182, Avg batch loss: 0.0044, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 1475, Step num: 15146, Learning rate: 0.00007182, Avg batch loss: 0.0049, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 1476, Step num: 15147, Learning rate: 0.00007182, Avg batch loss: 0.0049, Avg batch acc: 0.9936
Train, Epoch: 10, Batch: 1477, Step num: 15148, Learning rate: 0.00007182, Avg batch loss: 0.0059, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1478, Step num: 15149, Learning rate: 0.00007181, Avg batch loss: 0.0044, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 1479, Step num: 15150, Learning rate: 0.00007181, Avg batch loss: 0.0086, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 1480, Step num: 15151, Learning rate: 0.00007181, Avg batch loss: 0.0055, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1481, Step num: 15152, Learning rate: 0.00007181, Avg batch loss: 0.0042, Avg batch acc: 0.9963
Train, Epoch: 10, Batch: 1482, Step num: 15153, Learning rate: 0.00007180, Avg batch loss: 0.0051, Avg batch acc: 0.9929
Train, Epoch: 10, Batch: 1483, Step num: 15154, Learning rate: 0.00007180, Avg batch loss: 0.0050, Avg batch acc: 0.9966
Train, Epoch: 10, Batch: 1484, Step num: 15155, Learning rate: 0.00007180, Avg batch loss: 0.0068, Avg batch acc: 0.9951
Train, Epoch: 10, Batch: 1485, Step num: 15156, Learning rate: 0.00007180, Avg batch loss: 0.0032, Avg batch acc: 0.9975
Train, Epoch: 10, Batch: 1486, Step num: 15157, Learning rate: 0.00007179, Avg batch loss: 0.0042, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1487, Step num: 15158, Learning rate: 0.00007179, Avg batch loss: 0.0080, Avg batch acc: 0.9909
Train, Epoch: 10, Batch: 1488, Step num: 15159, Learning rate: 0.00007179, Avg batch loss: 0.0101, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1489, Step num: 15160, Learning rate: 0.00007179, Avg batch loss: 0.0061, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1490, Step num: 15161, Learning rate: 0.00007178, Avg batch loss: 0.0048, Avg batch acc: 0.9952
Train, Epoch: 10, Batch: 1491, Step num: 15162, Learning rate: 0.00007178, Avg batch loss: 0.0050, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1492, Step num: 15163, Learning rate: 0.00007178, Avg batch loss: 0.0046, Avg batch acc: 0.9943
Train, Epoch: 10, Batch: 1493, Step num: 15164, Learning rate: 0.00007178, Avg batch loss: 0.0059, Avg batch acc: 0.9941
Train, Epoch: 10, Batch: 1494, Step num: 15165, Learning rate: 0.00007178, Avg batch loss: 0.0058, Avg batch acc: 0.9947
Train, Epoch: 10, Batch: 1495, Step num: 15166, Learning rate: 0.00007177, Avg batch loss: 0.0052, Avg batch acc: 0.9958
Train, Epoch: 10, Batch: 1496, Step num: 15167, Learning rate: 0.00007177, Avg batch loss: 0.0036, Avg batch acc: 0.9965
Train, Epoch: 10, Batch: 1497, Step num: 15168, Learning rate: 0.00007177, Avg batch loss: 0.0071, Avg batch acc: 0.9926
Train, Epoch: 10, Batch: 1498, Step num: 15169, Learning rate: 0.00007177, Avg batch loss: 0.0091, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 1499, Step num: 15170, Learning rate: 0.00007176, Avg batch loss: 0.0196, Avg batch acc: 0.9901
Train, Epoch: 10, Batch: 1500, Step num: 15171, Learning rate: 0.00007176, Avg batch loss: 0.0045, Avg batch acc: 0.9957
Train, Epoch: 10, Batch: 1501, Step num: 15172, Learning rate: 0.00007176, Avg batch loss: 0.0053, Avg batch acc: 0.9940
Train, Epoch: 10, Batch: 1502, Step num: 15173, Learning rate: 0.00007176, Avg batch loss: 0.0163, Avg batch acc: 0.9925
Train, Epoch: 10, Batch: 1503, Step num: 15174, Learning rate: 0.00007175, Avg batch loss: 0.0088, Avg batch acc: 0.9893
Train, Epoch: 10, Batch: 1504, Step num: 15175, Learning rate: 0.00007175, Avg batch loss: 0.0065, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 1505, Step num: 15176, Learning rate: 0.00007175, Avg batch loss: 0.0055, Avg batch acc: 0.9953
Train, Epoch: 10, Batch: 1506, Step num: 15177, Learning rate: 0.00007175, Avg batch loss: 0.0047, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1507, Step num: 15178, Learning rate: 0.00007174, Avg batch loss: 0.0055, Avg batch acc: 0.9938
Train, Epoch: 10, Batch: 1508, Step num: 15179, Learning rate: 0.00007174, Avg batch loss: 0.0062, Avg batch acc: 0.9935
Train, Epoch: 10, Batch: 1509, Step num: 15180, Learning rate: 0.00007174, Avg batch loss: 0.0076, Avg batch acc: 0.9921
Train, Epoch: 10, Batch: 1510, Step num: 15181, Learning rate: 0.00007174, Avg batch loss: 0.0076, Avg batch acc: 0.9937
Train, Epoch: 10, Batch: 1511, Step num: 15182, Learning rate: 0.00007173, Avg batch loss: 0.0064, Avg batch acc: 0.9934
Train, Epoch: 10, Batch: 1512, Step num: 15183, Learning rate: 0.00007173, Avg batch loss: 0.0059, Avg batch acc: 0.9945
Train, Epoch: 10, Batch: 1513, Step num: 15184, Learning rate: 0.00007173, Avg batch loss: 0.0067, Avg batch acc: 0.9954
Train, Epoch: 10, Batch: 1514, Step num: 15185, Learning rate: 0.00007173, Avg batch loss: 0.0044, Avg batch acc: 0.9959
Train, Epoch: 10, Batch: 1515, Step num: 15186, Learning rate: 0.00007173, Avg batch loss: 0.0051, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1516, Step num: 15187, Learning rate: 0.00007172, Avg batch loss: 0.0036, Avg batch acc: 0.9982
Train, Epoch: 10, Batch: 1517, Step num: 15188, Learning rate: 0.00007172, Avg batch loss: 0.0066, Avg batch acc: 0.9949
Train, Epoch: 10, Batch: 1518, Step num: 15189, Learning rate: 0.00007172, Avg batch loss: 0.0065, Avg batch acc: 0.9944
Train, Epoch: 10, Batch: 1519, Step num: 15190, Learning rate: 0.00007172, Avg batch loss: 0.0059, Avg batch acc: 0.9949
Train, Epoch: 10, Avg epoch loss: 0.0060, Avg epoch acc: 0.9943, Overall time: 959.7 s, Speed: 4535.6 tokens/s on cuda:1

Validate, Epoch: 10, Batch: 1, Avg batch loss: 0.0049, Avg batch acc: 0.9928
Validate, Epoch: 10, Batch: 2, Avg batch loss: 0.0058, Avg batch acc: 0.9947
Validate, Epoch: 10, Batch: 3, Avg batch loss: 0.0046, Avg batch acc: 0.9951
Validate, Epoch: 10, Batch: 4, Avg batch loss: 0.0051, Avg batch acc: 0.9954
Validate, Epoch: 10, Batch: 5, Avg batch loss: 0.0056, Avg batch acc: 0.9956
Validate, Epoch: 10, Batch: 6, Avg batch loss: 0.0069, Avg batch acc: 0.9952
Validate, Epoch: 10, Batch: 7, Avg batch loss: 0.0046, Avg batch acc: 0.9943
Validate, Epoch: 10, Batch: 8, Avg batch loss: 0.0066, Avg batch acc: 0.9938
Validate, Epoch: 10, Batch: 9, Avg batch loss: 0.0061, Avg batch acc: 0.9942
Validate, Epoch: 10, Batch: 10, Avg batch loss: 0.0072, Avg batch acc: 0.9933
Validate, Epoch: 10, Batch: 11, Avg batch loss: 0.0055, Avg batch acc: 0.9933
Validate, Epoch: 10, Batch: 12, Avg batch loss: 0.0045, Avg batch acc: 0.9958
Validate, Epoch: 10, Batch: 13, Avg batch loss: 0.0044, Avg batch acc: 0.9974
Validate, Epoch: 10, Batch: 14, Avg batch loss: 0.0051, Avg batch acc: 0.9958
Validate, Epoch: 10, Batch: 15, Avg batch loss: 0.0041, Avg batch acc: 0.9971
Validate, Epoch: 10, Batch: 16, Avg batch loss: 0.0087, Avg batch acc: 0.9945
Validate, Epoch: 10, Batch: 17, Avg batch loss: 0.0046, Avg batch acc: 0.9957
Validate, Epoch: 10, Batch: 18, Avg batch loss: 0.0037, Avg batch acc: 0.9978
Validate, Epoch: 10, Batch: 19, Avg batch loss: 0.0060, Avg batch acc: 0.9934
Validate, Epoch: 10, Batch: 20, Avg batch loss: 0.0051, Avg batch acc: 0.9948
Validate, Epoch: 10, Batch: 21, Avg batch loss: 0.0184, Avg batch acc: 0.9928
Validate, Epoch: 10, Batch: 22, Avg batch loss: 0.0033, Avg batch acc: 0.9969
Validate, Epoch: 10, Batch: 23, Avg batch loss: 0.0073, Avg batch acc: 0.9947
Validate, Epoch: 10, Batch: 24, Avg batch loss: 0.0072, Avg batch acc: 0.9937
Validate, Epoch: 10, Batch: 25, Avg batch loss: 0.0116, Avg batch acc: 0.9944
Validate, Epoch: 10, Batch: 26, Avg batch loss: 0.0053, Avg batch acc: 0.9954
Validate, Epoch: 10, Batch: 27, Avg batch loss: 0.0065, Avg batch acc: 0.9939
Validate, Epoch: 10, Batch: 28, Avg batch loss: 0.0055, Avg batch acc: 0.9946
Validate, Epoch: 10, Batch: 29, Avg batch loss: 0.0057, Avg batch acc: 0.9935
Validate, Epoch: 10, Batch: 30, Avg batch loss: 0.0051, Avg batch acc: 0.9961
Validate, Epoch: 10, Batch: 31, Avg batch loss: 0.0042, Avg batch acc: 0.9965
Validate, Epoch: 10, Batch: 32, Avg batch loss: 0.0038, Avg batch acc: 0.9954
Validate, Epoch: 10, Batch: 33, Avg batch loss: 0.0052, Avg batch acc: 0.9956
Validate, Epoch: 10, Batch: 34, Avg batch loss: 0.0063, Avg batch acc: 0.9951
Validate, Epoch: 10, Batch: 35, Avg batch loss: 0.0047, Avg batch acc: 0.9955
Validate, Epoch: 10, Batch: 36, Avg batch loss: 0.0049, Avg batch acc: 0.9950
Validate, Epoch: 10, Batch: 37, Avg batch loss: 0.0049, Avg batch acc: 0.9965
Validate, Epoch: 10, Batch: 38, Avg batch loss: 0.0045, Avg batch acc: 0.9970
Validate, Epoch: 10, Batch: 39, Avg batch loss: 0.0047, Avg batch acc: 0.9957
Validate, Epoch: 10, Batch: 40, Avg batch loss: 0.0060, Avg batch acc: 0.9927
Validate, Epoch: 10, Batch: 41, Avg batch loss: 0.0058, Avg batch acc: 0.9950
Validate, Epoch: 10, Batch: 42, Avg batch loss: 0.0041, Avg batch acc: 0.9966
Validate, Epoch: 10, Batch: 43, Avg batch loss: 0.0050, Avg batch acc: 0.9953
Validate, Epoch: 10, Batch: 44, Avg batch loss: 0.0056, Avg batch acc: 0.9947
Validate, Epoch: 10, Batch: 45, Avg batch loss: 0.0041, Avg batch acc: 0.9966
Validate, Epoch: 10, Batch: 46, Avg batch loss: 0.0051, Avg batch acc: 0.9946
Validate, Epoch: 10, Batch: 47, Avg batch loss: 0.0057, Avg batch acc: 0.9946
Validate, Epoch: 10, Batch: 48, Avg batch loss: 0.0052, Avg batch acc: 0.9941
Validate, Epoch: 10, Batch: 49, Avg batch loss: 0.0068, Avg batch acc: 0.9954
Validate, Epoch: 10, Batch: 50, Avg batch loss: 0.0045, Avg batch acc: 0.9955
Validate, Epoch: 10, Batch: 51, Avg batch loss: 0.0047, Avg batch acc: 0.9962
Validate, Epoch: 10, Batch: 52, Avg batch loss: 0.0045, Avg batch acc: 0.9957
Validate, Epoch: 10, Batch: 53, Avg batch loss: 0.0060, Avg batch acc: 0.9945
Validate, Epoch: 10, Batch: 54, Avg batch loss: 0.0036, Avg batch acc: 0.9961
Validate, Epoch: 10, Batch: 55, Avg batch loss: 0.0077, Avg batch acc: 0.9929
Validate, Epoch: 10, Batch: 56, Avg batch loss: 0.0049, Avg batch acc: 0.9958
Validate, Epoch: 10, Batch: 57, Avg batch loss: 0.0068, Avg batch acc: 0.9918
Validate, Epoch: 10, Batch: 58, Avg batch loss: 0.0060, Avg batch acc: 0.9942
Validate, Epoch: 10, Batch: 59, Avg batch loss: 0.0051, Avg batch acc: 0.9953
Validate, Epoch: 10, Batch: 60, Avg batch loss: 0.0052, Avg batch acc: 0.9951
Validate, Epoch: 10, Batch: 61, Avg batch loss: 0.0044, Avg batch acc: 0.9965
Validate, Epoch: 10, Batch: 62, Avg batch loss: 0.0045, Avg batch acc: 0.9962
Validate, Epoch: 10, Batch: 63, Avg batch loss: 0.0031, Avg batch acc: 0.9952
Validate, Epoch: 10, Batch: 64, Avg batch loss: 0.0036, Avg batch acc: 0.9972
Validate, Epoch: 10, Batch: 65, Avg batch loss: 0.0053, Avg batch acc: 0.9953
Validate, Epoch: 10, Batch: 66, Avg batch loss: 0.0044, Avg batch acc: 0.9957
Validate, Epoch: 10, Batch: 67, Avg batch loss: 0.0047, Avg batch acc: 0.9966
Validate, Epoch: 10, Batch: 68, Avg batch loss: 0.0048, Avg batch acc: 0.9944
Validate, Epoch: 10, Batch: 69, Avg batch loss: 0.0056, Avg batch acc: 0.9951
Validate, Epoch: 10, Batch: 70, Avg batch loss: 0.0056, Avg batch acc: 0.9943
Validate, Epoch: 10, Batch: 71, Avg batch loss: 0.0041, Avg batch acc: 0.9963
Validate, Epoch: 10, Batch: 72, Avg batch loss: 0.0058, Avg batch acc: 0.9954
Validate, Epoch: 10, Batch: 73, Avg batch loss: 0.0073, Avg batch acc: 0.9954
Validate, Epoch: 10, Batch: 74, Avg batch loss: 0.0048, Avg batch acc: 0.9948
Validate, Epoch: 10, Batch: 75, Avg batch loss: 0.0060, Avg batch acc: 0.9946
Validate, Epoch: 10, Batch: 76, Avg batch loss: 0.0042, Avg batch acc: 0.9957
Validate, Epoch: 10, Batch: 77, Avg batch loss: 0.0056, Avg batch acc: 0.9931
Validate, Epoch: 10, Batch: 78, Avg batch loss: 0.0079, Avg batch acc: 0.9928
Validate, Epoch: 10, Batch: 79, Avg batch loss: 0.0055, Avg batch acc: 0.9932
Validate, Epoch: 10, Batch: 80, Avg batch loss: 0.0043, Avg batch acc: 0.9956
Validate, Epoch: 10, Batch: 81, Avg batch loss: 0.0065, Avg batch acc: 0.9942
Validate, Epoch: 10, Batch: 82, Avg batch loss: 0.0073, Avg batch acc: 0.9927
Validate, Epoch: 10, Batch: 83, Avg batch loss: 0.0050, Avg batch acc: 0.9927
Validate, Epoch: 10, Batch: 84, Avg batch loss: 0.0068, Avg batch acc: 0.9922
Validate, Epoch: 10, Batch: 85, Avg batch loss: 0.0102, Avg batch acc: 0.9914
Validate, Epoch: 10, Batch: 86, Avg batch loss: 0.0042, Avg batch acc: 0.9939
Validate, Epoch: 10, Batch: 87, Avg batch loss: 0.0055, Avg batch acc: 0.9922
Validate, Epoch: 10, Batch: 88, Avg batch loss: 0.0044, Avg batch acc: 0.9954
Validate, Epoch: 10, Batch: 89, Avg batch loss: 0.0040, Avg batch acc: 0.9973
Validate, Epoch: 10, Batch: 90, Avg batch loss: 0.0055, Avg batch acc: 0.9935
Validate, Epoch: 10, Batch: 91, Avg batch loss: 0.0045, Avg batch acc: 0.9945
Validate, Epoch: 10, Batch: 92, Avg batch loss: 0.0045, Avg batch acc: 0.9960
Validate, Epoch: 10, Batch: 93, Avg batch loss: 0.0056, Avg batch acc: 0.9947
Validate, Epoch: 10, Batch: 94, Avg batch loss: 0.0049, Avg batch acc: 0.9953
Validate, Epoch: 10, Batch: 95, Avg batch loss: 0.0053, Avg batch acc: 0.9939
Validate, Epoch: 10, Batch: 96, Avg batch loss: 0.0049, Avg batch acc: 0.9942
Validate, Epoch: 10, Batch: 97, Avg batch loss: 0.0076, Avg batch acc: 0.9942
Validate, Epoch: 10, Batch: 98, Avg batch loss: 0.0054, Avg batch acc: 0.9967
Validate, Epoch: 10, Batch: 99, Avg batch loss: 0.0058, Avg batch acc: 0.9956
Validate, Epoch: 10, Batch: 100, Avg batch loss: 0.0049, Avg batch acc: 0.9956
Validate, Epoch: 10, Batch: 101, Avg batch loss: 0.0080, Avg batch acc: 0.9939
Validate, Epoch: 10, Batch: 102, Avg batch loss: 0.0084, Avg batch acc: 0.9922
Validate, Epoch: 10, Batch: 103, Avg batch loss: 0.0046, Avg batch acc: 0.9958
Validate, Epoch: 10, Batch: 104, Avg batch loss: 0.0034, Avg batch acc: 0.9965
Validate, Epoch: 10, Batch: 105, Avg batch loss: 0.0047, Avg batch acc: 0.9954
Validate, Epoch: 10, Batch: 106, Avg batch loss: 0.0076, Avg batch acc: 0.9940
Validate, Epoch: 10, Batch: 107, Avg batch loss: 0.0064, Avg batch acc: 0.9950
Validate, Epoch: 10, Batch: 108, Avg batch loss: 0.0066, Avg batch acc: 0.9903
Validate, Epoch: 10, Batch: 109, Avg batch loss: 0.0092, Avg batch acc: 0.9939
Validate, Epoch: 10, Batch: 110, Avg batch loss: 0.0043, Avg batch acc: 0.9910
Validate, Epoch: 10, Batch: 111, Avg batch loss: 0.0079, Avg batch acc: 0.9935
Validate, Epoch: 10, Batch: 112, Avg batch loss: 0.0053, Avg batch acc: 0.9966
Validate, Epoch: 10, Batch: 113, Avg batch loss: 0.0057, Avg batch acc: 0.9953
Validate, Epoch: 10, Batch: 114, Avg batch loss: 0.0045, Avg batch acc: 0.9961
Validate, Epoch: 10, Batch: 115, Avg batch loss: 0.0048, Avg batch acc: 0.9966
Validate, Epoch: 10, Batch: 116, Avg batch loss: 0.0038, Avg batch acc: 0.9974
Validate, Epoch: 10, Batch: 117, Avg batch loss: 0.0038, Avg batch acc: 0.9960
Validate, Epoch: 10, Batch: 118, Avg batch loss: 0.0051, Avg batch acc: 0.9911
Validate, Epoch: 10, Batch: 119, Avg batch loss: 0.0050, Avg batch acc: 0.9941
Validate, Epoch: 10, Batch: 120, Avg batch loss: 0.0046, Avg batch acc: 0.9963
Validate, Epoch: 10, Batch: 121, Avg batch loss: 0.0059, Avg batch acc: 0.9928
Validate, Epoch: 10, Batch: 122, Avg batch loss: 0.0052, Avg batch acc: 0.9947
Validate, Epoch: 10, Batch: 123, Avg batch loss: 0.0039, Avg batch acc: 0.9961
Validate, Epoch: 10, Batch: 124, Avg batch loss: 0.0049, Avg batch acc: 0.9961
Validate, Epoch: 10, Batch: 125, Avg batch loss: 0.0074, Avg batch acc: 0.9917
Validate, Epoch: 10, Batch: 126, Avg batch loss: 0.0039, Avg batch acc: 0.9966
Validate, Epoch: 10, Batch: 127, Avg batch loss: 0.0085, Avg batch acc: 0.9912
Validate, Epoch: 10, Batch: 128, Avg batch loss: 0.0048, Avg batch acc: 0.9949
Validate, Epoch: 10, Batch: 129, Avg batch loss: 0.0078, Avg batch acc: 0.9931
Validate, Epoch: 10, Batch: 130, Avg batch loss: 0.0062, Avg batch acc: 0.9940
Validate, Epoch: 10, Batch: 131, Avg batch loss: 0.0050, Avg batch acc: 0.9950
Validate, Epoch: 10, Batch: 132, Avg batch loss: 0.0042, Avg batch acc: 0.9959
Validate, Epoch: 10, Batch: 133, Avg batch loss: 0.0074, Avg batch acc: 0.9936
Validate, Epoch: 10, Batch: 134, Avg batch loss: 0.0070, Avg batch acc: 0.9928
Validate, Epoch: 10, Batch: 135, Avg batch loss: 0.0167, Avg batch acc: 0.9917
Validate, Epoch: 10, Batch: 136, Avg batch loss: 0.0059, Avg batch acc: 0.9932
Validate, Epoch: 10, Batch: 137, Avg batch loss: 0.0042, Avg batch acc: 0.9963
Validate, Epoch: 10, Batch: 138, Avg batch loss: 0.0037, Avg batch acc: 0.9973
Validate, Epoch: 10, Batch: 139, Avg batch loss: 0.0074, Avg batch acc: 0.9899
Validate, Epoch: 10, Batch: 140, Avg batch loss: 0.0056, Avg batch acc: 0.9955
Validate, Epoch: 10, Batch: 141, Avg batch loss: 0.0043, Avg batch acc: 0.9981
Validate, Epoch: 10, Batch: 142, Avg batch loss: 0.0056, Avg batch acc: 0.9944
Validate, Epoch: 10, Batch: 143, Avg batch loss: 0.0053, Avg batch acc: 0.9948
Validate, Epoch: 10, Batch: 144, Avg batch loss: 0.0049, Avg batch acc: 0.9938
Validate, Epoch: 10, Batch: 145, Avg batch loss: 0.0029, Avg batch acc: 0.9972
Validate, Epoch: 10, Batch: 146, Avg batch loss: 0.0064, Avg batch acc: 0.9957
Validate, Epoch: 10, Batch: 147, Avg batch loss: 0.0058, Avg batch acc: 0.9946
Validate, Epoch: 10, Batch: 148, Avg batch loss: 0.0054, Avg batch acc: 0.9950
Validate, Epoch: 10, Batch: 149, Avg batch loss: 0.0041, Avg batch acc: 0.9958
Validate, Epoch: 10, Batch: 150, Avg batch loss: 0.0065, Avg batch acc: 0.9920
Validate, Epoch: 10, Batch: 151, Avg batch loss: 0.0053, Avg batch acc: 0.9944
Validate, Epoch: 10, Batch: 152, Avg batch loss: 0.0070, Avg batch acc: 0.9936
Validate, Epoch: 10, Batch: 153, Avg batch loss: 0.0051, Avg batch acc: 0.9929
Validate, Epoch: 10, Batch: 154, Avg batch loss: 0.0067, Avg batch acc: 0.9915
Validate, Epoch: 10, Batch: 155, Avg batch loss: 0.0054, Avg batch acc: 0.9959
Validate, Epoch: 10, Batch: 156, Avg batch loss: 0.0070, Avg batch acc: 0.9923
Validate, Epoch: 10, Batch: 157, Avg batch loss: 0.0047, Avg batch acc: 0.9948
Validate, Epoch: 10, Batch: 158, Avg batch loss: 0.0082, Avg batch acc: 0.9934
Validate, Epoch: 10, Batch: 159, Avg batch loss: 0.0061, Avg batch acc: 0.9926
Validate, Epoch: 10, Batch: 160, Avg batch loss: 0.0048, Avg batch acc: 0.9939
Validate, Epoch: 10, Batch: 161, Avg batch loss: 0.0104, Avg batch acc: 0.9928
Validate, Epoch: 10, Batch: 162, Avg batch loss: 0.0075, Avg batch acc: 0.9928
Validate, Epoch: 10, Batch: 163, Avg batch loss: 0.0056, Avg batch acc: 0.9938
Validate, Epoch: 10, Batch: 164, Avg batch loss: 0.0057, Avg batch acc: 0.9952
Validate, Epoch: 10, Batch: 165, Avg batch loss: 0.0034, Avg batch acc: 0.9954
Validate, Epoch: 10, Batch: 166, Avg batch loss: 0.0079, Avg batch acc: 0.9947
Validate, Epoch: 10, Batch: 167, Avg batch loss: 0.0038, Avg batch acc: 0.9959
Validate, Epoch: 10, Batch: 168, Avg batch loss: 0.0045, Avg batch acc: 0.9956
Validate, Epoch: 10, Batch: 169, Avg batch loss: 0.0059, Avg batch acc: 0.9961
Validate, Epoch: 10, Avg epoch loss: 0.0057, Avg epoch acc: 0.9947, Overall time: 37.1 s, Speed: 13004.1 tokens/s on cuda:1


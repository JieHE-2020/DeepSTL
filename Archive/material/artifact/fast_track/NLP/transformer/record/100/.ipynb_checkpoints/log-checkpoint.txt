Train, Epoch: 1, Batch: 1, Step num: 1, Learning rate: 0.00000070, Avg batch loss: 1.7199, Avg batch acc: 0.0002
Train, Epoch: 1, Batch: 2, Step num: 2, Learning rate: 0.00000140, Avg batch loss: 1.6533, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 3, Step num: 3, Learning rate: 0.00000210, Avg batch loss: 1.5945, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 4, Step num: 4, Learning rate: 0.00000280, Avg batch loss: 1.7165, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 5, Step num: 5, Learning rate: 0.00000349, Avg batch loss: 1.8423, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 6, Step num: 6, Learning rate: 0.00000419, Avg batch loss: 1.6559, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 7, Step num: 7, Learning rate: 0.00000489, Avg batch loss: 1.6569, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 8, Step num: 8, Learning rate: 0.00000559, Avg batch loss: 1.6528, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 9, Step num: 9, Learning rate: 0.00000629, Avg batch loss: 1.6820, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 10, Step num: 10, Learning rate: 0.00000699, Avg batch loss: 1.6279, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 11, Step num: 11, Learning rate: 0.00000769, Avg batch loss: 1.6103, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 12, Step num: 12, Learning rate: 0.00000839, Avg batch loss: 1.6873, Avg batch acc: 0.0002
Train, Epoch: 1, Batch: 13, Step num: 13, Learning rate: 0.00000908, Avg batch loss: 1.7042, Avg batch acc: 0.0003
Train, Epoch: 1, Batch: 14, Step num: 14, Learning rate: 0.00000978, Avg batch loss: 1.6638, Avg batch acc: 0.0018
Train, Epoch: 1, Batch: 15, Step num: 15, Learning rate: 0.00001048, Avg batch loss: 1.6820, Avg batch acc: 0.0003
Train, Epoch: 1, Batch: 16, Step num: 16, Learning rate: 0.00001118, Avg batch loss: 1.6182, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 17, Step num: 17, Learning rate: 0.00001188, Avg batch loss: 1.7580, Avg batch acc: 0.0019
Train, Epoch: 1, Batch: 18, Step num: 18, Learning rate: 0.00001258, Avg batch loss: 1.5889, Avg batch acc: 0.0034
Train, Epoch: 1, Batch: 19, Step num: 19, Learning rate: 0.00001328, Avg batch loss: 1.6068, Avg batch acc: 0.0034
Train, Epoch: 1, Batch: 20, Step num: 20, Learning rate: 0.00001398, Avg batch loss: 1.6512, Avg batch acc: 0.0027
Train, Epoch: 1, Batch: 21, Step num: 21, Learning rate: 0.00001467, Avg batch loss: 1.6198, Avg batch acc: 0.0042
Train, Epoch: 1, Batch: 22, Step num: 22, Learning rate: 0.00001537, Avg batch loss: 1.5656, Avg batch acc: 0.0094
Train, Epoch: 1, Batch: 23, Step num: 23, Learning rate: 0.00001607, Avg batch loss: 1.7786, Avg batch acc: 0.0119
Train, Epoch: 1, Batch: 24, Step num: 24, Learning rate: 0.00001677, Avg batch loss: 1.6464, Avg batch acc: 0.0142
Train, Epoch: 1, Batch: 25, Step num: 25, Learning rate: 0.00001747, Avg batch loss: 1.6043, Avg batch acc: 0.0247
Train, Epoch: 1, Batch: 26, Step num: 26, Learning rate: 0.00001817, Avg batch loss: 1.4336, Avg batch acc: 0.0297
Train, Epoch: 1, Batch: 27, Step num: 27, Learning rate: 0.00001887, Avg batch loss: 1.6901, Avg batch acc: 0.0295
Train, Epoch: 1, Batch: 28, Step num: 28, Learning rate: 0.00001957, Avg batch loss: 1.6780, Avg batch acc: 0.0345
Train, Epoch: 1, Batch: 29, Step num: 29, Learning rate: 0.00002026, Avg batch loss: 1.6379, Avg batch acc: 0.0397
Train, Epoch: 1, Batch: 30, Step num: 30, Learning rate: 0.00002096, Avg batch loss: 1.4515, Avg batch acc: 0.0439
Train, Epoch: 1, Batch: 31, Step num: 31, Learning rate: 0.00002166, Avg batch loss: 1.4860, Avg batch acc: 0.0412
Train, Epoch: 1, Batch: 32, Step num: 32, Learning rate: 0.00002236, Avg batch loss: 1.5235, Avg batch acc: 0.0497
Train, Epoch: 1, Batch: 33, Step num: 33, Learning rate: 0.00002306, Avg batch loss: 1.5961, Avg batch acc: 0.0553
Train, Epoch: 1, Batch: 34, Step num: 34, Learning rate: 0.00002376, Avg batch loss: 1.6332, Avg batch acc: 0.0517
Train, Epoch: 1, Batch: 35, Step num: 35, Learning rate: 0.00002446, Avg batch loss: 1.7048, Avg batch acc: 0.0507
Train, Epoch: 1, Batch: 36, Step num: 36, Learning rate: 0.00002516, Avg batch loss: 1.4538, Avg batch acc: 0.0484
Train, Epoch: 1, Batch: 37, Step num: 37, Learning rate: 0.00002585, Avg batch loss: 1.5784, Avg batch acc: 0.0531
Train, Epoch: 1, Batch: 38, Step num: 38, Learning rate: 0.00002655, Avg batch loss: 1.5809, Avg batch acc: 0.0581
Train, Epoch: 1, Batch: 39, Step num: 39, Learning rate: 0.00002725, Avg batch loss: 1.6048, Avg batch acc: 0.0554
Train, Epoch: 1, Batch: 40, Step num: 40, Learning rate: 0.00002795, Avg batch loss: 1.4545, Avg batch acc: 0.0581
Train, Epoch: 1, Batch: 41, Step num: 41, Learning rate: 0.00002865, Avg batch loss: 1.4410, Avg batch acc: 0.0609
Train, Epoch: 1, Batch: 42, Step num: 42, Learning rate: 0.00002935, Avg batch loss: 1.5664, Avg batch acc: 0.0530
Train, Epoch: 1, Batch: 43, Step num: 43, Learning rate: 0.00003005, Avg batch loss: 1.6431, Avg batch acc: 0.0581
Train, Epoch: 1, Batch: 44, Step num: 44, Learning rate: 0.00003075, Avg batch loss: 1.4138, Avg batch acc: 0.0564
Train, Epoch: 1, Batch: 45, Step num: 45, Learning rate: 0.00003144, Avg batch loss: 1.5532, Avg batch acc: 0.0594
Train, Epoch: 1, Batch: 46, Step num: 46, Learning rate: 0.00003214, Avg batch loss: 1.5148, Avg batch acc: 0.0594
Train, Epoch: 1, Batch: 47, Step num: 47, Learning rate: 0.00003284, Avg batch loss: 1.5538, Avg batch acc: 0.0575
Train, Epoch: 1, Batch: 48, Step num: 48, Learning rate: 0.00003354, Avg batch loss: 1.6147, Avg batch acc: 0.0570
Train, Epoch: 1, Batch: 49, Step num: 49, Learning rate: 0.00003424, Avg batch loss: 1.5442, Avg batch acc: 0.0618
Train, Epoch: 1, Batch: 50, Step num: 50, Learning rate: 0.00003494, Avg batch loss: 1.5480, Avg batch acc: 0.0558
Train, Epoch: 1, Batch: 51, Step num: 51, Learning rate: 0.00003564, Avg batch loss: 1.6055, Avg batch acc: 0.0669
Train, Epoch: 1, Batch: 52, Step num: 52, Learning rate: 0.00003634, Avg batch loss: 1.4596, Avg batch acc: 0.0581
Train, Epoch: 1, Batch: 53, Step num: 53, Learning rate: 0.00003703, Avg batch loss: 1.5348, Avg batch acc: 0.0607
Train, Epoch: 1, Batch: 54, Step num: 54, Learning rate: 0.00003773, Avg batch loss: 1.3844, Avg batch acc: 0.0668
Train, Epoch: 1, Batch: 55, Step num: 55, Learning rate: 0.00003843, Avg batch loss: 1.4347, Avg batch acc: 0.0618
Train, Epoch: 1, Batch: 56, Step num: 56, Learning rate: 0.00003913, Avg batch loss: 1.4251, Avg batch acc: 0.0614
Train, Epoch: 1, Batch: 57, Step num: 57, Learning rate: 0.00003983, Avg batch loss: 1.5257, Avg batch acc: 0.0650
Train, Epoch: 1, Batch: 58, Step num: 58, Learning rate: 0.00004053, Avg batch loss: 1.5378, Avg batch acc: 0.0633
Train, Epoch: 1, Batch: 59, Step num: 59, Learning rate: 0.00004123, Avg batch loss: 1.4129, Avg batch acc: 0.0808
Train, Epoch: 1, Batch: 60, Step num: 60, Learning rate: 0.00004193, Avg batch loss: 1.5196, Avg batch acc: 0.0659
Train, Epoch: 1, Batch: 61, Step num: 61, Learning rate: 0.00004263, Avg batch loss: 1.3415, Avg batch acc: 0.0682
Train, Epoch: 1, Batch: 62, Step num: 62, Learning rate: 0.00004332, Avg batch loss: 1.3875, Avg batch acc: 0.0633
Train, Epoch: 1, Batch: 63, Step num: 63, Learning rate: 0.00004402, Avg batch loss: 1.4581, Avg batch acc: 0.0746
Train, Epoch: 1, Batch: 64, Step num: 64, Learning rate: 0.00004472, Avg batch loss: 1.4115, Avg batch acc: 0.0673
Train, Epoch: 1, Batch: 65, Step num: 65, Learning rate: 0.00004542, Avg batch loss: 1.5163, Avg batch acc: 0.0658
Train, Epoch: 1, Batch: 66, Step num: 66, Learning rate: 0.00004612, Avg batch loss: 1.5509, Avg batch acc: 0.0591
Train, Epoch: 1, Batch: 67, Step num: 67, Learning rate: 0.00004682, Avg batch loss: 1.4938, Avg batch acc: 0.0741
Train, Epoch: 1, Batch: 68, Step num: 68, Learning rate: 0.00004752, Avg batch loss: 1.4782, Avg batch acc: 0.0681
Train, Epoch: 1, Batch: 69, Step num: 69, Learning rate: 0.00004822, Avg batch loss: 1.5240, Avg batch acc: 0.0692
Train, Epoch: 1, Batch: 70, Step num: 70, Learning rate: 0.00004891, Avg batch loss: 1.3248, Avg batch acc: 0.0669
Train, Epoch: 1, Batch: 71, Step num: 71, Learning rate: 0.00004961, Avg batch loss: 1.3987, Avg batch acc: 0.0697
Train, Epoch: 1, Batch: 72, Step num: 72, Learning rate: 0.00005031, Avg batch loss: 1.6273, Avg batch acc: 0.0660
Train, Epoch: 1, Batch: 73, Step num: 73, Learning rate: 0.00005101, Avg batch loss: 1.5347, Avg batch acc: 0.0671
Train, Epoch: 1, Batch: 74, Step num: 74, Learning rate: 0.00005171, Avg batch loss: 1.4234, Avg batch acc: 0.0631
Train, Epoch: 1, Batch: 75, Step num: 75, Learning rate: 0.00005241, Avg batch loss: 1.4461, Avg batch acc: 0.0631
Train, Epoch: 1, Batch: 76, Step num: 76, Learning rate: 0.00005311, Avg batch loss: 1.5256, Avg batch acc: 0.0783
Train, Epoch: 1, Batch: 77, Step num: 77, Learning rate: 0.00005381, Avg batch loss: 1.3339, Avg batch acc: 0.0693
Train, Epoch: 1, Batch: 78, Step num: 78, Learning rate: 0.00005450, Avg batch loss: 1.3974, Avg batch acc: 0.0658
Train, Epoch: 1, Batch: 79, Step num: 79, Learning rate: 0.00005520, Avg batch loss: 1.4391, Avg batch acc: 0.0752
Train, Epoch: 1, Batch: 80, Step num: 80, Learning rate: 0.00005590, Avg batch loss: 1.4945, Avg batch acc: 0.0738
Train, Epoch: 1, Batch: 81, Step num: 81, Learning rate: 0.00005660, Avg batch loss: 1.5022, Avg batch acc: 0.0699
Train, Epoch: 1, Batch: 82, Step num: 82, Learning rate: 0.00005730, Avg batch loss: 1.4758, Avg batch acc: 0.0749
Train, Epoch: 1, Batch: 83, Step num: 83, Learning rate: 0.00005800, Avg batch loss: 1.4515, Avg batch acc: 0.0803
Train, Epoch: 1, Batch: 84, Step num: 84, Learning rate: 0.00005870, Avg batch loss: 1.2614, Avg batch acc: 0.0854
Train, Epoch: 1, Batch: 85, Step num: 85, Learning rate: 0.00005940, Avg batch loss: 1.4960, Avg batch acc: 0.0723
Train, Epoch: 1, Batch: 86, Step num: 86, Learning rate: 0.00006009, Avg batch loss: 1.4150, Avg batch acc: 0.0824
Train, Epoch: 1, Batch: 87, Step num: 87, Learning rate: 0.00006079, Avg batch loss: 1.3881, Avg batch acc: 0.0865
Train, Epoch: 1, Batch: 88, Step num: 88, Learning rate: 0.00006149, Avg batch loss: 1.4365, Avg batch acc: 0.0807
Train, Epoch: 1, Batch: 89, Step num: 89, Learning rate: 0.00006219, Avg batch loss: 1.4110, Avg batch acc: 0.0841
Train, Epoch: 1, Batch: 90, Step num: 90, Learning rate: 0.00006289, Avg batch loss: 1.3797, Avg batch acc: 0.0868
Train, Epoch: 1, Batch: 91, Step num: 91, Learning rate: 0.00006359, Avg batch loss: 1.5165, Avg batch acc: 0.0855
Train, Epoch: 1, Batch: 92, Step num: 92, Learning rate: 0.00006429, Avg batch loss: 1.5388, Avg batch acc: 0.0841
Train, Epoch: 1, Batch: 93, Step num: 93, Learning rate: 0.00006499, Avg batch loss: 1.3366, Avg batch acc: 0.0906
Train, Epoch: 1, Batch: 94, Step num: 94, Learning rate: 0.00006568, Avg batch loss: 1.4081, Avg batch acc: 0.0893
Train, Epoch: 1, Batch: 95, Step num: 95, Learning rate: 0.00006638, Avg batch loss: 1.3418, Avg batch acc: 0.0909
Train, Epoch: 1, Batch: 96, Step num: 96, Learning rate: 0.00006708, Avg batch loss: 1.5432, Avg batch acc: 0.0965
Train, Epoch: 1, Batch: 97, Step num: 97, Learning rate: 0.00006778, Avg batch loss: 1.4039, Avg batch acc: 0.1043
Train, Epoch: 1, Batch: 98, Step num: 98, Learning rate: 0.00006848, Avg batch loss: 1.3976, Avg batch acc: 0.0921
Train, Epoch: 1, Batch: 99, Step num: 99, Learning rate: 0.00006918, Avg batch loss: 1.3591, Avg batch acc: 0.1019
Train, Epoch: 1, Batch: 100, Step num: 100, Learning rate: 0.00006988, Avg batch loss: 1.4105, Avg batch acc: 0.0975
Train, Epoch: 1, Batch: 101, Step num: 101, Learning rate: 0.00007058, Avg batch loss: 1.4082, Avg batch acc: 0.1192
Train, Epoch: 1, Batch: 102, Step num: 102, Learning rate: 0.00007127, Avg batch loss: 1.2447, Avg batch acc: 0.1152
Train, Epoch: 1, Batch: 103, Step num: 103, Learning rate: 0.00007197, Avg batch loss: 1.3264, Avg batch acc: 0.1133
Train, Epoch: 1, Batch: 104, Step num: 104, Learning rate: 0.00007267, Avg batch loss: 1.3864, Avg batch acc: 0.1009
Train, Epoch: 1, Batch: 105, Step num: 105, Learning rate: 0.00007337, Avg batch loss: 1.3297, Avg batch acc: 0.1045
Train, Epoch: 1, Batch: 106, Step num: 106, Learning rate: 0.00007407, Avg batch loss: 1.3512, Avg batch acc: 0.0994
Train, Epoch: 1, Batch: 107, Step num: 107, Learning rate: 0.00007477, Avg batch loss: 1.3876, Avg batch acc: 0.1098
Train, Epoch: 1, Batch: 108, Step num: 108, Learning rate: 0.00007547, Avg batch loss: 1.3076, Avg batch acc: 0.1183
Train, Epoch: 1, Batch: 109, Step num: 109, Learning rate: 0.00007617, Avg batch loss: 1.4080, Avg batch acc: 0.1132
Train, Epoch: 1, Batch: 110, Step num: 110, Learning rate: 0.00007686, Avg batch loss: 1.3321, Avg batch acc: 0.1288
Train, Epoch: 1, Batch: 111, Step num: 111, Learning rate: 0.00007756, Avg batch loss: 1.2795, Avg batch acc: 0.1249
Train, Epoch: 1, Batch: 112, Step num: 112, Learning rate: 0.00007826, Avg batch loss: 1.3564, Avg batch acc: 0.1189
Train, Epoch: 1, Batch: 113, Step num: 113, Learning rate: 0.00007896, Avg batch loss: 1.2567, Avg batch acc: 0.1383
Train, Epoch: 1, Batch: 114, Step num: 114, Learning rate: 0.00007966, Avg batch loss: 1.4412, Avg batch acc: 0.1167
Train, Epoch: 1, Batch: 115, Step num: 115, Learning rate: 0.00008036, Avg batch loss: 1.3358, Avg batch acc: 0.1249
Train, Epoch: 1, Batch: 116, Step num: 116, Learning rate: 0.00008106, Avg batch loss: 1.3768, Avg batch acc: 0.1240
Train, Epoch: 1, Batch: 117, Step num: 117, Learning rate: 0.00008176, Avg batch loss: 1.2230, Avg batch acc: 0.1405
Train, Epoch: 1, Batch: 118, Step num: 118, Learning rate: 0.00008246, Avg batch loss: 1.2825, Avg batch acc: 0.1301
Train, Epoch: 1, Batch: 119, Step num: 119, Learning rate: 0.00008315, Avg batch loss: 1.1911, Avg batch acc: 0.1250
Train, Epoch: 1, Batch: 120, Step num: 120, Learning rate: 0.00008385, Avg batch loss: 1.2914, Avg batch acc: 0.1321
Train, Epoch: 1, Batch: 121, Step num: 121, Learning rate: 0.00008455, Avg batch loss: 1.3109, Avg batch acc: 0.1248
Train, Epoch: 1, Batch: 122, Step num: 122, Learning rate: 0.00008525, Avg batch loss: 1.2173, Avg batch acc: 0.1424
Train, Epoch: 1, Batch: 123, Step num: 123, Learning rate: 0.00008595, Avg batch loss: 1.2513, Avg batch acc: 0.1340
Train, Epoch: 1, Batch: 124, Step num: 124, Learning rate: 0.00008665, Avg batch loss: 1.2608, Avg batch acc: 0.1395
Train, Epoch: 1, Batch: 125, Step num: 125, Learning rate: 0.00008735, Avg batch loss: 1.1986, Avg batch acc: 0.1391
Train, Epoch: 1, Batch: 126, Step num: 126, Learning rate: 0.00008805, Avg batch loss: 1.2379, Avg batch acc: 0.1276
Train, Epoch: 1, Batch: 127, Step num: 127, Learning rate: 0.00008874, Avg batch loss: 1.1169, Avg batch acc: 0.1393
Train, Epoch: 1, Batch: 128, Step num: 128, Learning rate: 0.00008944, Avg batch loss: 1.2117, Avg batch acc: 0.1363
Train, Epoch: 1, Batch: 129, Step num: 129, Learning rate: 0.00009014, Avg batch loss: 1.3368, Avg batch acc: 0.1322
Train, Epoch: 1, Batch: 130, Step num: 130, Learning rate: 0.00009084, Avg batch loss: 1.2200, Avg batch acc: 0.1447
Train, Epoch: 1, Batch: 131, Step num: 131, Learning rate: 0.00009154, Avg batch loss: 1.2563, Avg batch acc: 0.1397
Train, Epoch: 1, Batch: 132, Step num: 132, Learning rate: 0.00009224, Avg batch loss: 1.2022, Avg batch acc: 0.1503
Train, Epoch: 1, Batch: 133, Step num: 133, Learning rate: 0.00009294, Avg batch loss: 1.1926, Avg batch acc: 0.1623
Train, Epoch: 1, Batch: 134, Step num: 134, Learning rate: 0.00009364, Avg batch loss: 1.2360, Avg batch acc: 0.1556
Train, Epoch: 1, Batch: 135, Step num: 135, Learning rate: 0.00009433, Avg batch loss: 1.2480, Avg batch acc: 0.1553
Train, Epoch: 1, Batch: 136, Step num: 136, Learning rate: 0.00009503, Avg batch loss: 1.2800, Avg batch acc: 0.1562
Train, Epoch: 1, Batch: 137, Step num: 137, Learning rate: 0.00009573, Avg batch loss: 1.3160, Avg batch acc: 0.1628
Train, Epoch: 1, Batch: 138, Step num: 138, Learning rate: 0.00009643, Avg batch loss: 1.1986, Avg batch acc: 0.1693
Train, Epoch: 1, Batch: 139, Step num: 139, Learning rate: 0.00009713, Avg batch loss: 1.2137, Avg batch acc: 0.1707
Train, Epoch: 1, Batch: 140, Step num: 140, Learning rate: 0.00009783, Avg batch loss: 1.1574, Avg batch acc: 0.1700
Train, Epoch: 1, Batch: 141, Step num: 141, Learning rate: 0.00009853, Avg batch loss: 1.2827, Avg batch acc: 0.1700
Train, Epoch: 1, Batch: 142, Step num: 142, Learning rate: 0.00009923, Avg batch loss: 1.2132, Avg batch acc: 0.1749
Train, Epoch: 1, Batch: 143, Step num: 143, Learning rate: 0.00009992, Avg batch loss: 1.1768, Avg batch acc: 0.1880
Train, Epoch: 1, Batch: 144, Step num: 144, Learning rate: 0.00010062, Avg batch loss: 1.1986, Avg batch acc: 0.1806
Train, Epoch: 1, Batch: 145, Step num: 145, Learning rate: 0.00010132, Avg batch loss: 1.1083, Avg batch acc: 0.1903
Train, Epoch: 1, Batch: 146, Step num: 146, Learning rate: 0.00010202, Avg batch loss: 1.2157, Avg batch acc: 0.1698
Train, Epoch: 1, Batch: 147, Step num: 147, Learning rate: 0.00010272, Avg batch loss: 1.1551, Avg batch acc: 0.1873
Train, Epoch: 1, Batch: 148, Step num: 148, Learning rate: 0.00010342, Avg batch loss: 1.1839, Avg batch acc: 0.1683
Train, Epoch: 1, Batch: 149, Step num: 149, Learning rate: 0.00010412, Avg batch loss: 1.2185, Avg batch acc: 0.1917
Train, Epoch: 1, Batch: 150, Step num: 150, Learning rate: 0.00010482, Avg batch loss: 1.2124, Avg batch acc: 0.1839
Train, Epoch: 1, Batch: 151, Step num: 151, Learning rate: 0.00010551, Avg batch loss: 1.1812, Avg batch acc: 0.2005
Train, Epoch: 1, Batch: 152, Step num: 152, Learning rate: 0.00010621, Avg batch loss: 1.1762, Avg batch acc: 0.1928
Train, Epoch: 1, Batch: 153, Step num: 153, Learning rate: 0.00010691, Avg batch loss: 1.1172, Avg batch acc: 0.1919
Train, Epoch: 1, Batch: 154, Step num: 154, Learning rate: 0.00010761, Avg batch loss: 1.1937, Avg batch acc: 0.1845
Train, Epoch: 1, Batch: 155, Step num: 155, Learning rate: 0.00010831, Avg batch loss: 1.2600, Avg batch acc: 0.1806
Train, Epoch: 1, Batch: 156, Step num: 156, Learning rate: 0.00010901, Avg batch loss: 1.1089, Avg batch acc: 0.1842
Train, Epoch: 1, Batch: 157, Step num: 157, Learning rate: 0.00010971, Avg batch loss: 1.1120, Avg batch acc: 0.2060
Train, Epoch: 1, Batch: 158, Step num: 158, Learning rate: 0.00011041, Avg batch loss: 1.1363, Avg batch acc: 0.2028
Train, Epoch: 1, Batch: 159, Step num: 159, Learning rate: 0.00011110, Avg batch loss: 1.2157, Avg batch acc: 0.1908
Train, Epoch: 1, Batch: 160, Step num: 160, Learning rate: 0.00011180, Avg batch loss: 1.0900, Avg batch acc: 0.1948
Train, Epoch: 1, Batch: 161, Step num: 161, Learning rate: 0.00011250, Avg batch loss: 1.1857, Avg batch acc: 0.2050
Train, Epoch: 1, Batch: 162, Step num: 162, Learning rate: 0.00011320, Avg batch loss: 1.1693, Avg batch acc: 0.2052
Train, Epoch: 1, Batch: 163, Step num: 163, Learning rate: 0.00011390, Avg batch loss: 1.0526, Avg batch acc: 0.2072
Train, Epoch: 1, Batch: 164, Step num: 164, Learning rate: 0.00011460, Avg batch loss: 1.0341, Avg batch acc: 0.2213
Train, Epoch: 1, Batch: 165, Step num: 165, Learning rate: 0.00011530, Avg batch loss: 1.0748, Avg batch acc: 0.2194
Train, Epoch: 1, Batch: 166, Step num: 166, Learning rate: 0.00011600, Avg batch loss: 1.0894, Avg batch acc: 0.2339
Train, Epoch: 1, Batch: 167, Step num: 167, Learning rate: 0.00011669, Avg batch loss: 1.0968, Avg batch acc: 0.2301
Train, Epoch: 1, Batch: 168, Step num: 168, Learning rate: 0.00011739, Avg batch loss: 1.0420, Avg batch acc: 0.2104
Train, Epoch: 1, Batch: 169, Step num: 169, Learning rate: 0.00011809, Avg batch loss: 1.1043, Avg batch acc: 0.2060
Train, Epoch: 1, Batch: 170, Step num: 170, Learning rate: 0.00011879, Avg batch loss: 1.0955, Avg batch acc: 0.2213
Train, Epoch: 1, Batch: 171, Step num: 171, Learning rate: 0.00011949, Avg batch loss: 1.0368, Avg batch acc: 0.2252
Train, Epoch: 1, Batch: 172, Step num: 172, Learning rate: 0.00012019, Avg batch loss: 1.0643, Avg batch acc: 0.2305
Train, Epoch: 1, Batch: 173, Step num: 173, Learning rate: 0.00012089, Avg batch loss: 1.0258, Avg batch acc: 0.2235
Train, Epoch: 1, Batch: 174, Step num: 174, Learning rate: 0.00012159, Avg batch loss: 1.1109, Avg batch acc: 0.2329
Train, Epoch: 1, Batch: 175, Step num: 175, Learning rate: 0.00012228, Avg batch loss: 1.1268, Avg batch acc: 0.2340
Train, Epoch: 1, Batch: 176, Step num: 176, Learning rate: 0.00012298, Avg batch loss: 0.9951, Avg batch acc: 0.2239
Train, Epoch: 1, Batch: 177, Step num: 177, Learning rate: 0.00012368, Avg batch loss: 1.1349, Avg batch acc: 0.2307
Train, Epoch: 1, Batch: 178, Step num: 178, Learning rate: 0.00012438, Avg batch loss: 1.0650, Avg batch acc: 0.2350
Train, Epoch: 1, Batch: 179, Step num: 179, Learning rate: 0.00012508, Avg batch loss: 1.0215, Avg batch acc: 0.2387
Train, Epoch: 1, Batch: 180, Step num: 180, Learning rate: 0.00012578, Avg batch loss: 1.0668, Avg batch acc: 0.2256
Train, Epoch: 1, Batch: 181, Step num: 181, Learning rate: 0.00012648, Avg batch loss: 0.9559, Avg batch acc: 0.2394
Train, Epoch: 1, Batch: 182, Step num: 182, Learning rate: 0.00012718, Avg batch loss: 1.0152, Avg batch acc: 0.2329
Train, Epoch: 1, Batch: 183, Step num: 183, Learning rate: 0.00012788, Avg batch loss: 1.0524, Avg batch acc: 0.2383
Train, Epoch: 1, Batch: 184, Step num: 184, Learning rate: 0.00012857, Avg batch loss: 1.0602, Avg batch acc: 0.2484
Train, Epoch: 1, Batch: 185, Step num: 185, Learning rate: 0.00012927, Avg batch loss: 1.0532, Avg batch acc: 0.2381
Train, Epoch: 1, Batch: 186, Step num: 186, Learning rate: 0.00012997, Avg batch loss: 1.0183, Avg batch acc: 0.2340
Train, Epoch: 1, Batch: 187, Step num: 187, Learning rate: 0.00013067, Avg batch loss: 1.0433, Avg batch acc: 0.2398
Train, Epoch: 1, Batch: 188, Step num: 188, Learning rate: 0.00013137, Avg batch loss: 0.9820, Avg batch acc: 0.2449
Train, Epoch: 1, Batch: 189, Step num: 189, Learning rate: 0.00013207, Avg batch loss: 0.9805, Avg batch acc: 0.2475
Train, Epoch: 1, Batch: 190, Step num: 190, Learning rate: 0.00013277, Avg batch loss: 1.0364, Avg batch acc: 0.2479
Train, Epoch: 1, Batch: 191, Step num: 191, Learning rate: 0.00013347, Avg batch loss: 1.1038, Avg batch acc: 0.2567
Train, Epoch: 1, Batch: 192, Step num: 192, Learning rate: 0.00013416, Avg batch loss: 0.9805, Avg batch acc: 0.2457
Train, Epoch: 1, Batch: 193, Step num: 193, Learning rate: 0.00013486, Avg batch loss: 0.9826, Avg batch acc: 0.2619
Train, Epoch: 1, Batch: 194, Step num: 194, Learning rate: 0.00013556, Avg batch loss: 0.9698, Avg batch acc: 0.2524
Train, Epoch: 1, Batch: 195, Step num: 195, Learning rate: 0.00013626, Avg batch loss: 0.9301, Avg batch acc: 0.2486
Train, Epoch: 1, Batch: 196, Step num: 196, Learning rate: 0.00013696, Avg batch loss: 1.0353, Avg batch acc: 0.2454
Train, Epoch: 1, Batch: 197, Step num: 197, Learning rate: 0.00013766, Avg batch loss: 1.0612, Avg batch acc: 0.2642
Train, Epoch: 1, Batch: 198, Step num: 198, Learning rate: 0.00013836, Avg batch loss: 1.0392, Avg batch acc: 0.2352
Train, Epoch: 1, Batch: 199, Step num: 199, Learning rate: 0.00013906, Avg batch loss: 0.9433, Avg batch acc: 0.2420
Train, Epoch: 1, Batch: 200, Step num: 200, Learning rate: 0.00013975, Avg batch loss: 1.0964, Avg batch acc: 0.2450
Train, Epoch: 1, Batch: 201, Step num: 201, Learning rate: 0.00014045, Avg batch loss: 1.0001, Avg batch acc: 0.2499
Train, Epoch: 1, Batch: 202, Step num: 202, Learning rate: 0.00014115, Avg batch loss: 0.9400, Avg batch acc: 0.2519
Train, Epoch: 1, Batch: 203, Step num: 203, Learning rate: 0.00014185, Avg batch loss: 0.9983, Avg batch acc: 0.2705
Train, Epoch: 1, Batch: 204, Step num: 204, Learning rate: 0.00014255, Avg batch loss: 0.9092, Avg batch acc: 0.2713
Train, Epoch: 1, Batch: 205, Step num: 205, Learning rate: 0.00014325, Avg batch loss: 0.9632, Avg batch acc: 0.2629
Train, Epoch: 1, Batch: 206, Step num: 206, Learning rate: 0.00014395, Avg batch loss: 0.9032, Avg batch acc: 0.2666
Train, Epoch: 1, Batch: 207, Step num: 207, Learning rate: 0.00014465, Avg batch loss: 0.9567, Avg batch acc: 0.2584
Train, Epoch: 1, Batch: 208, Step num: 208, Learning rate: 0.00014534, Avg batch loss: 0.9314, Avg batch acc: 0.2702
Train, Epoch: 1, Batch: 209, Step num: 209, Learning rate: 0.00014604, Avg batch loss: 0.9644, Avg batch acc: 0.2621
Train, Epoch: 1, Batch: 210, Step num: 210, Learning rate: 0.00014674, Avg batch loss: 0.9154, Avg batch acc: 0.2677
Train, Epoch: 1, Batch: 211, Step num: 211, Learning rate: 0.00014744, Avg batch loss: 0.8974, Avg batch acc: 0.2706
Train, Epoch: 1, Batch: 212, Step num: 212, Learning rate: 0.00014814, Avg batch loss: 1.0175, Avg batch acc: 0.2655
Train, Epoch: 1, Batch: 213, Step num: 213, Learning rate: 0.00014884, Avg batch loss: 1.0078, Avg batch acc: 0.2842
Train, Epoch: 1, Batch: 214, Step num: 214, Learning rate: 0.00014954, Avg batch loss: 0.9844, Avg batch acc: 0.2540
Train, Epoch: 1, Batch: 215, Step num: 215, Learning rate: 0.00015024, Avg batch loss: 0.9308, Avg batch acc: 0.2613
Train, Epoch: 1, Batch: 216, Step num: 216, Learning rate: 0.00015093, Avg batch loss: 0.8995, Avg batch acc: 0.2637
Train, Epoch: 1, Batch: 217, Step num: 217, Learning rate: 0.00015163, Avg batch loss: 1.0147, Avg batch acc: 0.2651
Train, Epoch: 1, Batch: 218, Step num: 218, Learning rate: 0.00015233, Avg batch loss: 0.8959, Avg batch acc: 0.2703
Train, Epoch: 1, Batch: 219, Step num: 219, Learning rate: 0.00015303, Avg batch loss: 0.9787, Avg batch acc: 0.2583
Train, Epoch: 1, Batch: 220, Step num: 220, Learning rate: 0.00015373, Avg batch loss: 0.9209, Avg batch acc: 0.2708
Train, Epoch: 1, Batch: 221, Step num: 221, Learning rate: 0.00015443, Avg batch loss: 1.0045, Avg batch acc: 0.2602
Train, Epoch: 1, Batch: 222, Step num: 222, Learning rate: 0.00015513, Avg batch loss: 0.9807, Avg batch acc: 0.2775
Train, Epoch: 1, Batch: 223, Step num: 223, Learning rate: 0.00015583, Avg batch loss: 0.9977, Avg batch acc: 0.2486
Train, Epoch: 1, Batch: 224, Step num: 224, Learning rate: 0.00015652, Avg batch loss: 0.9889, Avg batch acc: 0.2787
Train, Epoch: 1, Batch: 225, Step num: 225, Learning rate: 0.00015722, Avg batch loss: 1.0068, Avg batch acc: 0.2835
Train, Epoch: 1, Batch: 226, Step num: 226, Learning rate: 0.00015792, Avg batch loss: 0.8924, Avg batch acc: 0.2921
Train, Epoch: 1, Batch: 227, Step num: 227, Learning rate: 0.00015862, Avg batch loss: 0.9146, Avg batch acc: 0.2652
Train, Epoch: 1, Batch: 228, Step num: 228, Learning rate: 0.00015932, Avg batch loss: 0.8954, Avg batch acc: 0.2747
Train, Epoch: 1, Batch: 229, Step num: 229, Learning rate: 0.00016002, Avg batch loss: 0.9697, Avg batch acc: 0.2621
Train, Epoch: 1, Batch: 230, Step num: 230, Learning rate: 0.00016072, Avg batch loss: 0.9138, Avg batch acc: 0.2652
Train, Epoch: 1, Batch: 231, Step num: 231, Learning rate: 0.00016142, Avg batch loss: 0.9034, Avg batch acc: 0.2658
Train, Epoch: 1, Batch: 232, Step num: 232, Learning rate: 0.00016211, Avg batch loss: 0.9075, Avg batch acc: 0.2817
Train, Epoch: 1, Batch: 233, Step num: 233, Learning rate: 0.00016281, Avg batch loss: 0.9275, Avg batch acc: 0.2672
Train, Epoch: 1, Batch: 234, Step num: 234, Learning rate: 0.00016351, Avg batch loss: 0.9176, Avg batch acc: 0.2652
Train, Epoch: 1, Batch: 235, Step num: 235, Learning rate: 0.00016421, Avg batch loss: 0.9129, Avg batch acc: 0.2766
Train, Epoch: 1, Batch: 236, Step num: 236, Learning rate: 0.00016491, Avg batch loss: 0.8785, Avg batch acc: 0.2695
Train, Epoch: 1, Batch: 237, Step num: 237, Learning rate: 0.00016561, Avg batch loss: 0.9552, Avg batch acc: 0.2814
Train, Epoch: 1, Batch: 238, Step num: 238, Learning rate: 0.00016631, Avg batch loss: 0.9499, Avg batch acc: 0.2730
Train, Epoch: 1, Batch: 239, Step num: 239, Learning rate: 0.00016701, Avg batch loss: 0.8728, Avg batch acc: 0.2941
Train, Epoch: 1, Batch: 240, Step num: 240, Learning rate: 0.00016771, Avg batch loss: 0.8505, Avg batch acc: 0.2768
Train, Epoch: 1, Batch: 241, Step num: 241, Learning rate: 0.00016840, Avg batch loss: 0.8557, Avg batch acc: 0.2956
Train, Epoch: 1, Batch: 242, Step num: 242, Learning rate: 0.00016910, Avg batch loss: 0.8756, Avg batch acc: 0.2802
Train, Epoch: 1, Batch: 243, Step num: 243, Learning rate: 0.00016980, Avg batch loss: 0.8244, Avg batch acc: 0.2827
Train, Epoch: 1, Batch: 244, Step num: 244, Learning rate: 0.00017050, Avg batch loss: 0.8120, Avg batch acc: 0.3111
Train, Epoch: 1, Batch: 245, Step num: 245, Learning rate: 0.00017120, Avg batch loss: 0.8743, Avg batch acc: 0.3096
Train, Epoch: 1, Batch: 246, Step num: 246, Learning rate: 0.00017190, Avg batch loss: 0.8401, Avg batch acc: 0.2936
Train, Epoch: 1, Batch: 247, Step num: 247, Learning rate: 0.00017260, Avg batch loss: 0.8710, Avg batch acc: 0.2997
Train, Epoch: 1, Batch: 248, Step num: 248, Learning rate: 0.00017330, Avg batch loss: 0.8559, Avg batch acc: 0.2862
Train, Epoch: 1, Batch: 249, Step num: 249, Learning rate: 0.00017399, Avg batch loss: 0.8300, Avg batch acc: 0.2894
Train, Epoch: 1, Batch: 250, Step num: 250, Learning rate: 0.00017469, Avg batch loss: 0.8059, Avg batch acc: 0.2958
Train, Epoch: 1, Batch: 251, Step num: 251, Learning rate: 0.00017539, Avg batch loss: 0.8483, Avg batch acc: 0.2845
Train, Epoch: 1, Batch: 252, Step num: 252, Learning rate: 0.00017609, Avg batch loss: 0.9140, Avg batch acc: 0.2659
Train, Epoch: 1, Batch: 253, Step num: 253, Learning rate: 0.00017679, Avg batch loss: 0.9224, Avg batch acc: 0.2903
Train, Epoch: 1, Batch: 254, Step num: 254, Learning rate: 0.00017749, Avg batch loss: 0.9033, Avg batch acc: 0.2645
Train, Epoch: 1, Batch: 255, Step num: 255, Learning rate: 0.00017819, Avg batch loss: 0.8603, Avg batch acc: 0.2771
Train, Epoch: 1, Batch: 256, Step num: 256, Learning rate: 0.00017889, Avg batch loss: 0.8764, Avg batch acc: 0.2935
Train, Epoch: 1, Batch: 257, Step num: 257, Learning rate: 0.00017958, Avg batch loss: 0.8389, Avg batch acc: 0.3068
Train, Epoch: 1, Batch: 258, Step num: 258, Learning rate: 0.00018028, Avg batch loss: 0.8140, Avg batch acc: 0.3083
Train, Epoch: 1, Batch: 259, Step num: 259, Learning rate: 0.00018098, Avg batch loss: 0.8757, Avg batch acc: 0.2815
Train, Epoch: 1, Batch: 260, Step num: 260, Learning rate: 0.00018168, Avg batch loss: 0.8419, Avg batch acc: 0.2875
Train, Epoch: 1, Batch: 261, Step num: 261, Learning rate: 0.00018238, Avg batch loss: 0.8219, Avg batch acc: 0.2836
Train, Epoch: 1, Batch: 262, Step num: 262, Learning rate: 0.00018308, Avg batch loss: 0.8195, Avg batch acc: 0.3073
Train, Epoch: 1, Batch: 263, Step num: 263, Learning rate: 0.00018378, Avg batch loss: 0.8343, Avg batch acc: 0.2685
Train, Epoch: 1, Batch: 264, Step num: 264, Learning rate: 0.00018448, Avg batch loss: 0.8787, Avg batch acc: 0.2852
Train, Epoch: 1, Batch: 265, Step num: 265, Learning rate: 0.00018517, Avg batch loss: 0.8351, Avg batch acc: 0.2829
Train, Epoch: 1, Batch: 266, Step num: 266, Learning rate: 0.00018587, Avg batch loss: 0.8708, Avg batch acc: 0.2852
Train, Epoch: 1, Batch: 267, Step num: 267, Learning rate: 0.00018657, Avg batch loss: 0.9183, Avg batch acc: 0.2870
Train, Epoch: 1, Batch: 268, Step num: 268, Learning rate: 0.00018727, Avg batch loss: 0.9300, Avg batch acc: 0.2910
Train, Epoch: 1, Batch: 269, Step num: 269, Learning rate: 0.00018797, Avg batch loss: 0.8964, Avg batch acc: 0.2893
Train, Epoch: 1, Batch: 270, Step num: 270, Learning rate: 0.00018867, Avg batch loss: 0.8815, Avg batch acc: 0.2622
Train, Epoch: 1, Batch: 271, Step num: 271, Learning rate: 0.00018937, Avg batch loss: 0.9145, Avg batch acc: 0.2983
Train, Epoch: 1, Batch: 272, Step num: 272, Learning rate: 0.00019007, Avg batch loss: 0.8422, Avg batch acc: 0.3032
Train, Epoch: 1, Batch: 273, Step num: 273, Learning rate: 0.00019076, Avg batch loss: 0.8557, Avg batch acc: 0.2769
Train, Epoch: 1, Batch: 274, Step num: 274, Learning rate: 0.00019146, Avg batch loss: 0.7919, Avg batch acc: 0.2959
Train, Epoch: 1, Batch: 275, Step num: 275, Learning rate: 0.00019216, Avg batch loss: 0.9147, Avg batch acc: 0.2727
Train, Epoch: 1, Batch: 276, Step num: 276, Learning rate: 0.00019286, Avg batch loss: 0.8496, Avg batch acc: 0.2944
Train, Epoch: 1, Batch: 277, Step num: 277, Learning rate: 0.00019356, Avg batch loss: 0.8840, Avg batch acc: 0.2913
Train, Epoch: 1, Batch: 278, Step num: 278, Learning rate: 0.00019426, Avg batch loss: 0.8049, Avg batch acc: 0.2888
Train, Epoch: 1, Batch: 279, Step num: 279, Learning rate: 0.00019496, Avg batch loss: 0.8223, Avg batch acc: 0.2910
Train, Epoch: 1, Batch: 280, Step num: 280, Learning rate: 0.00019566, Avg batch loss: 0.8728, Avg batch acc: 0.3035
Train, Epoch: 1, Batch: 281, Step num: 281, Learning rate: 0.00019635, Avg batch loss: 0.8464, Avg batch acc: 0.2891
Train, Epoch: 1, Batch: 282, Step num: 282, Learning rate: 0.00019705, Avg batch loss: 0.7956, Avg batch acc: 0.3031
Train, Epoch: 1, Batch: 283, Step num: 283, Learning rate: 0.00019775, Avg batch loss: 0.7577, Avg batch acc: 0.3048
Train, Epoch: 1, Batch: 284, Step num: 284, Learning rate: 0.00019845, Avg batch loss: 0.8023, Avg batch acc: 0.3033
Train, Epoch: 1, Batch: 285, Step num: 285, Learning rate: 0.00019915, Avg batch loss: 0.8609, Avg batch acc: 0.3003
Train, Epoch: 1, Batch: 286, Step num: 286, Learning rate: 0.00019985, Avg batch loss: 0.8686, Avg batch acc: 0.3065
Train, Epoch: 1, Batch: 287, Step num: 287, Learning rate: 0.00020055, Avg batch loss: 0.8326, Avg batch acc: 0.2856
Train, Epoch: 1, Batch: 288, Step num: 288, Learning rate: 0.00020125, Avg batch loss: 0.8199, Avg batch acc: 0.3059
Train, Epoch: 1, Batch: 289, Step num: 289, Learning rate: 0.00020194, Avg batch loss: 0.8586, Avg batch acc: 0.2895
Train, Epoch: 1, Batch: 290, Step num: 290, Learning rate: 0.00020264, Avg batch loss: 0.8003, Avg batch acc: 0.3151
Train, Epoch: 1, Batch: 291, Step num: 291, Learning rate: 0.00020334, Avg batch loss: 0.8126, Avg batch acc: 0.3183
Train, Epoch: 1, Batch: 292, Step num: 292, Learning rate: 0.00020404, Avg batch loss: 0.7890, Avg batch acc: 0.3157
Train, Epoch: 1, Batch: 293, Step num: 293, Learning rate: 0.00020474, Avg batch loss: 0.7757, Avg batch acc: 0.3118
Train, Epoch: 1, Batch: 294, Step num: 294, Learning rate: 0.00020544, Avg batch loss: 0.8481, Avg batch acc: 0.2886
Train, Epoch: 1, Batch: 295, Step num: 295, Learning rate: 0.00020614, Avg batch loss: 0.9032, Avg batch acc: 0.2803
Train, Epoch: 1, Batch: 296, Step num: 296, Learning rate: 0.00020684, Avg batch loss: 0.7400, Avg batch acc: 0.3049
Train, Epoch: 1, Batch: 297, Step num: 297, Learning rate: 0.00020754, Avg batch loss: 0.8113, Avg batch acc: 0.3145
Train, Epoch: 1, Batch: 298, Step num: 298, Learning rate: 0.00020823, Avg batch loss: 0.8204, Avg batch acc: 0.3117
Train, Epoch: 1, Batch: 299, Step num: 299, Learning rate: 0.00020893, Avg batch loss: 0.7978, Avg batch acc: 0.3116
Train, Epoch: 1, Batch: 300, Step num: 300, Learning rate: 0.00020963, Avg batch loss: 0.8307, Avg batch acc: 0.3212
Train, Epoch: 1, Batch: 301, Step num: 301, Learning rate: 0.00021033, Avg batch loss: 0.8401, Avg batch acc: 0.3092
Train, Epoch: 1, Batch: 302, Step num: 302, Learning rate: 0.00021103, Avg batch loss: 0.7634, Avg batch acc: 0.3090
Train, Epoch: 1, Batch: 303, Step num: 303, Learning rate: 0.00021173, Avg batch loss: 0.7708, Avg batch acc: 0.3210
Train, Epoch: 1, Batch: 304, Step num: 304, Learning rate: 0.00021243, Avg batch loss: 0.8719, Avg batch acc: 0.2867
Train, Epoch: 1, Batch: 305, Step num: 305, Learning rate: 0.00021313, Avg batch loss: 0.8152, Avg batch acc: 0.3066
Train, Epoch: 1, Batch: 306, Step num: 306, Learning rate: 0.00021382, Avg batch loss: 0.7976, Avg batch acc: 0.3125
Train, Epoch: 1, Batch: 307, Step num: 307, Learning rate: 0.00021452, Avg batch loss: 0.8337, Avg batch acc: 0.3074
Train, Epoch: 1, Batch: 308, Step num: 308, Learning rate: 0.00021522, Avg batch loss: 0.7812, Avg batch acc: 0.2957
Train, Epoch: 1, Batch: 309, Step num: 309, Learning rate: 0.00021592, Avg batch loss: 0.8100, Avg batch acc: 0.3186
Train, Epoch: 1, Batch: 310, Step num: 310, Learning rate: 0.00021662, Avg batch loss: 0.8262, Avg batch acc: 0.2947
Train, Epoch: 1, Batch: 311, Step num: 311, Learning rate: 0.00021732, Avg batch loss: 0.8056, Avg batch acc: 0.2980
Train, Epoch: 1, Batch: 312, Step num: 312, Learning rate: 0.00021802, Avg batch loss: 0.8153, Avg batch acc: 0.3087
Train, Epoch: 1, Batch: 313, Step num: 313, Learning rate: 0.00021872, Avg batch loss: 0.7671, Avg batch acc: 0.3199
Train, Epoch: 1, Batch: 314, Step num: 314, Learning rate: 0.00021941, Avg batch loss: 0.7900, Avg batch acc: 0.2959
Train, Epoch: 1, Batch: 315, Step num: 315, Learning rate: 0.00022011, Avg batch loss: 0.7921, Avg batch acc: 0.3144
Train, Epoch: 1, Batch: 316, Step num: 316, Learning rate: 0.00022081, Avg batch loss: 0.8443, Avg batch acc: 0.3200
Train, Epoch: 1, Batch: 317, Step num: 317, Learning rate: 0.00022151, Avg batch loss: 0.7152, Avg batch acc: 0.3255
Train, Epoch: 1, Batch: 318, Step num: 318, Learning rate: 0.00022221, Avg batch loss: 0.8220, Avg batch acc: 0.3036
Train, Epoch: 1, Batch: 319, Step num: 319, Learning rate: 0.00022291, Avg batch loss: 0.8066, Avg batch acc: 0.3101
Train, Epoch: 1, Batch: 320, Step num: 320, Learning rate: 0.00022361, Avg batch loss: 0.8063, Avg batch acc: 0.2911
Train, Epoch: 1, Batch: 321, Step num: 321, Learning rate: 0.00022431, Avg batch loss: 0.8368, Avg batch acc: 0.3209
Train, Epoch: 1, Batch: 322, Step num: 322, Learning rate: 0.00022500, Avg batch loss: 0.7716, Avg batch acc: 0.3134
Train, Epoch: 1, Batch: 323, Step num: 323, Learning rate: 0.00022570, Avg batch loss: 0.7484, Avg batch acc: 0.3111
Train, Epoch: 1, Batch: 324, Step num: 324, Learning rate: 0.00022640, Avg batch loss: 0.7972, Avg batch acc: 0.3089
Train, Epoch: 1, Batch: 325, Step num: 325, Learning rate: 0.00022710, Avg batch loss: 0.7993, Avg batch acc: 0.3136
Train, Epoch: 1, Batch: 326, Step num: 326, Learning rate: 0.00022780, Avg batch loss: 0.7695, Avg batch acc: 0.2972
Train, Epoch: 1, Batch: 327, Step num: 327, Learning rate: 0.00022850, Avg batch loss: 0.7528, Avg batch acc: 0.3107
Train, Epoch: 1, Batch: 328, Step num: 328, Learning rate: 0.00022920, Avg batch loss: 0.8197, Avg batch acc: 0.2969
Train, Epoch: 1, Batch: 329, Step num: 329, Learning rate: 0.00022990, Avg batch loss: 0.8015, Avg batch acc: 0.3115
Train, Epoch: 1, Batch: 330, Step num: 330, Learning rate: 0.00023059, Avg batch loss: 0.7638, Avg batch acc: 0.3433
Train, Epoch: 1, Batch: 331, Step num: 331, Learning rate: 0.00023129, Avg batch loss: 0.7298, Avg batch acc: 0.3128
Train, Epoch: 1, Batch: 332, Step num: 332, Learning rate: 0.00023199, Avg batch loss: 0.7096, Avg batch acc: 0.3434
Train, Epoch: 1, Batch: 333, Step num: 333, Learning rate: 0.00023269, Avg batch loss: 0.7153, Avg batch acc: 0.3194
Train, Epoch: 1, Batch: 334, Step num: 334, Learning rate: 0.00023339, Avg batch loss: 0.7817, Avg batch acc: 0.3293
Train, Epoch: 1, Batch: 335, Step num: 335, Learning rate: 0.00023409, Avg batch loss: 0.7938, Avg batch acc: 0.3187
Train, Epoch: 1, Batch: 336, Step num: 336, Learning rate: 0.00023479, Avg batch loss: 0.7275, Avg batch acc: 0.3255
Train, Epoch: 1, Batch: 337, Step num: 337, Learning rate: 0.00023549, Avg batch loss: 0.7340, Avg batch acc: 0.3290
Train, Epoch: 1, Batch: 338, Step num: 338, Learning rate: 0.00023618, Avg batch loss: 0.8042, Avg batch acc: 0.3099
Train, Epoch: 1, Batch: 339, Step num: 339, Learning rate: 0.00023688, Avg batch loss: 0.7530, Avg batch acc: 0.3344
Train, Epoch: 1, Batch: 340, Step num: 340, Learning rate: 0.00023758, Avg batch loss: 0.7522, Avg batch acc: 0.3325
Train, Epoch: 1, Batch: 341, Step num: 341, Learning rate: 0.00023828, Avg batch loss: 0.7069, Avg batch acc: 0.3277
Train, Epoch: 1, Batch: 342, Step num: 342, Learning rate: 0.00023898, Avg batch loss: 0.7573, Avg batch acc: 0.3211
Train, Epoch: 1, Batch: 343, Step num: 343, Learning rate: 0.00023968, Avg batch loss: 0.7550, Avg batch acc: 0.3294
Train, Epoch: 1, Batch: 344, Step num: 344, Learning rate: 0.00024038, Avg batch loss: 0.8011, Avg batch acc: 0.3125
Train, Epoch: 1, Batch: 345, Step num: 345, Learning rate: 0.00024108, Avg batch loss: 0.7074, Avg batch acc: 0.3194
Train, Epoch: 1, Batch: 346, Step num: 346, Learning rate: 0.00024177, Avg batch loss: 0.7610, Avg batch acc: 0.3330
Train, Epoch: 1, Batch: 347, Step num: 347, Learning rate: 0.00024247, Avg batch loss: 0.7211, Avg batch acc: 0.3127
Train, Epoch: 1, Batch: 348, Step num: 348, Learning rate: 0.00024317, Avg batch loss: 0.7217, Avg batch acc: 0.3449
Train, Epoch: 1, Batch: 349, Step num: 349, Learning rate: 0.00024387, Avg batch loss: 0.7771, Avg batch acc: 0.3123
Train, Epoch: 1, Batch: 350, Step num: 350, Learning rate: 0.00024457, Avg batch loss: 0.7512, Avg batch acc: 0.2984
Train, Epoch: 1, Batch: 351, Step num: 351, Learning rate: 0.00024527, Avg batch loss: 0.7645, Avg batch acc: 0.3452
Train, Epoch: 1, Batch: 352, Step num: 352, Learning rate: 0.00024597, Avg batch loss: 0.7277, Avg batch acc: 0.3337
Train, Epoch: 1, Batch: 353, Step num: 353, Learning rate: 0.00024667, Avg batch loss: 0.7463, Avg batch acc: 0.3465
Train, Epoch: 1, Batch: 354, Step num: 354, Learning rate: 0.00024737, Avg batch loss: 0.8453, Avg batch acc: 0.3020
Train, Epoch: 1, Batch: 355, Step num: 355, Learning rate: 0.00024806, Avg batch loss: 0.7256, Avg batch acc: 0.3158
Train, Epoch: 1, Batch: 356, Step num: 356, Learning rate: 0.00024876, Avg batch loss: 0.7136, Avg batch acc: 0.3336
Train, Epoch: 1, Batch: 357, Step num: 357, Learning rate: 0.00024946, Avg batch loss: 0.7235, Avg batch acc: 0.3427
Train, Epoch: 1, Batch: 358, Step num: 358, Learning rate: 0.00025016, Avg batch loss: 0.6408, Avg batch acc: 0.3486
Train, Epoch: 1, Batch: 359, Step num: 359, Learning rate: 0.00025086, Avg batch loss: 0.7276, Avg batch acc: 0.3528
Train, Epoch: 1, Batch: 360, Step num: 360, Learning rate: 0.00025156, Avg batch loss: 0.7647, Avg batch acc: 0.3255
Train, Epoch: 1, Batch: 361, Step num: 361, Learning rate: 0.00025226, Avg batch loss: 0.7362, Avg batch acc: 0.3182
Train, Epoch: 1, Batch: 362, Step num: 362, Learning rate: 0.00025296, Avg batch loss: 0.8058, Avg batch acc: 0.3289
Train, Epoch: 1, Batch: 363, Step num: 363, Learning rate: 0.00025365, Avg batch loss: 0.7333, Avg batch acc: 0.3117
Train, Epoch: 1, Batch: 364, Step num: 364, Learning rate: 0.00025435, Avg batch loss: 0.7150, Avg batch acc: 0.3311
Train, Epoch: 1, Batch: 365, Step num: 365, Learning rate: 0.00025505, Avg batch loss: 0.7785, Avg batch acc: 0.3233
Train, Epoch: 1, Batch: 366, Step num: 366, Learning rate: 0.00025575, Avg batch loss: 0.7859, Avg batch acc: 0.3325
Train, Epoch: 1, Batch: 367, Step num: 367, Learning rate: 0.00025645, Avg batch loss: 0.6914, Avg batch acc: 0.3311
Train, Epoch: 1, Batch: 368, Step num: 368, Learning rate: 0.00025715, Avg batch loss: 0.7154, Avg batch acc: 0.3304
Train, Epoch: 1, Batch: 369, Step num: 369, Learning rate: 0.00025785, Avg batch loss: 0.7817, Avg batch acc: 0.3183
Train, Epoch: 1, Batch: 370, Step num: 370, Learning rate: 0.00025855, Avg batch loss: 0.7201, Avg batch acc: 0.3267
Train, Epoch: 1, Batch: 371, Step num: 371, Learning rate: 0.00025924, Avg batch loss: 0.7337, Avg batch acc: 0.3329
Train, Epoch: 1, Batch: 372, Step num: 372, Learning rate: 0.00025994, Avg batch loss: 0.7179, Avg batch acc: 0.3254
Train, Epoch: 1, Batch: 373, Step num: 373, Learning rate: 0.00026064, Avg batch loss: 0.7892, Avg batch acc: 0.3145
Train, Epoch: 1, Batch: 374, Step num: 374, Learning rate: 0.00026134, Avg batch loss: 0.7742, Avg batch acc: 0.3160
Train, Epoch: 1, Batch: 375, Step num: 375, Learning rate: 0.00026204, Avg batch loss: 0.7496, Avg batch acc: 0.3248
Train, Epoch: 1, Batch: 376, Step num: 376, Learning rate: 0.00026274, Avg batch loss: 0.7686, Avg batch acc: 0.3284
Train, Epoch: 1, Batch: 377, Step num: 377, Learning rate: 0.00026344, Avg batch loss: 0.7721, Avg batch acc: 0.3327
Train, Epoch: 1, Batch: 378, Step num: 378, Learning rate: 0.00026414, Avg batch loss: 0.7606, Avg batch acc: 0.3358
Train, Epoch: 1, Batch: 379, Step num: 379, Learning rate: 0.00026483, Avg batch loss: 0.7305, Avg batch acc: 0.3519
Train, Epoch: 1, Batch: 380, Step num: 380, Learning rate: 0.00026553, Avg batch loss: 0.7465, Avg batch acc: 0.3416
Train, Epoch: 1, Batch: 381, Step num: 381, Learning rate: 0.00026623, Avg batch loss: 0.7114, Avg batch acc: 0.3403
Train, Epoch: 1, Batch: 382, Step num: 382, Learning rate: 0.00026693, Avg batch loss: 0.7088, Avg batch acc: 0.3483
Train, Epoch: 1, Batch: 383, Step num: 383, Learning rate: 0.00026763, Avg batch loss: 0.8004, Avg batch acc: 0.3079
Train, Epoch: 1, Batch: 384, Step num: 384, Learning rate: 0.00026833, Avg batch loss: 0.7923, Avg batch acc: 0.3323
Train, Epoch: 1, Batch: 385, Step num: 385, Learning rate: 0.00026903, Avg batch loss: 0.6659, Avg batch acc: 0.3609
Train, Epoch: 1, Batch: 386, Step num: 386, Learning rate: 0.00026973, Avg batch loss: 0.7331, Avg batch acc: 0.3282
Train, Epoch: 1, Batch: 387, Step num: 387, Learning rate: 0.00027042, Avg batch loss: 0.6784, Avg batch acc: 0.3396
Train, Epoch: 1, Batch: 388, Step num: 388, Learning rate: 0.00027112, Avg batch loss: 0.7416, Avg batch acc: 0.3346
Train, Epoch: 1, Batch: 389, Step num: 389, Learning rate: 0.00027182, Avg batch loss: 0.7021, Avg batch acc: 0.3403
Train, Epoch: 1, Batch: 390, Step num: 390, Learning rate: 0.00027252, Avg batch loss: 0.7854, Avg batch acc: 0.3150
Train, Epoch: 1, Batch: 391, Step num: 391, Learning rate: 0.00027322, Avg batch loss: 0.6903, Avg batch acc: 0.3404
Train, Epoch: 1, Batch: 392, Step num: 392, Learning rate: 0.00027392, Avg batch loss: 0.7640, Avg batch acc: 0.3345
Train, Epoch: 1, Batch: 393, Step num: 393, Learning rate: 0.00027462, Avg batch loss: 0.7716, Avg batch acc: 0.3052
Train, Epoch: 1, Batch: 394, Step num: 394, Learning rate: 0.00027532, Avg batch loss: 0.6966, Avg batch acc: 0.3331
Train, Epoch: 1, Batch: 395, Step num: 395, Learning rate: 0.00027601, Avg batch loss: 0.7164, Avg batch acc: 0.3325
Train, Epoch: 1, Batch: 396, Step num: 396, Learning rate: 0.00027671, Avg batch loss: 0.7685, Avg batch acc: 0.3179
Train, Epoch: 1, Batch: 397, Step num: 397, Learning rate: 0.00027741, Avg batch loss: 0.7136, Avg batch acc: 0.3417
Train, Epoch: 1, Batch: 398, Step num: 398, Learning rate: 0.00027811, Avg batch loss: 0.7495, Avg batch acc: 0.3084
Train, Epoch: 1, Batch: 399, Step num: 399, Learning rate: 0.00027881, Avg batch loss: 0.6974, Avg batch acc: 0.3437
Train, Epoch: 1, Batch: 400, Step num: 400, Learning rate: 0.00027951, Avg batch loss: 0.6908, Avg batch acc: 0.3414
Train, Epoch: 1, Batch: 401, Step num: 401, Learning rate: 0.00028021, Avg batch loss: 0.6641, Avg batch acc: 0.3467
Train, Epoch: 1, Batch: 402, Step num: 402, Learning rate: 0.00028091, Avg batch loss: 0.6984, Avg batch acc: 0.3338
Train, Epoch: 1, Batch: 403, Step num: 403, Learning rate: 0.00028160, Avg batch loss: 0.6875, Avg batch acc: 0.3391
Train, Epoch: 1, Batch: 404, Step num: 404, Learning rate: 0.00028230, Avg batch loss: 0.7141, Avg batch acc: 0.3305
Train, Epoch: 1, Batch: 405, Step num: 405, Learning rate: 0.00028300, Avg batch loss: 0.7555, Avg batch acc: 0.3311
Train, Epoch: 1, Batch: 406, Step num: 406, Learning rate: 0.00028370, Avg batch loss: 0.7059, Avg batch acc: 0.3339
Train, Epoch: 1, Batch: 407, Step num: 407, Learning rate: 0.00028440, Avg batch loss: 0.7070, Avg batch acc: 0.3395
Train, Epoch: 1, Batch: 408, Step num: 408, Learning rate: 0.00028510, Avg batch loss: 0.7489, Avg batch acc: 0.3447
Train, Epoch: 1, Batch: 409, Step num: 409, Learning rate: 0.00028580, Avg batch loss: 0.7825, Avg batch acc: 0.3273
Train, Epoch: 1, Batch: 410, Step num: 410, Learning rate: 0.00028650, Avg batch loss: 0.7030, Avg batch acc: 0.3314
Train, Epoch: 1, Batch: 411, Step num: 411, Learning rate: 0.00028719, Avg batch loss: 0.7566, Avg batch acc: 0.3388
Train, Epoch: 1, Batch: 412, Step num: 412, Learning rate: 0.00028789, Avg batch loss: 0.7148, Avg batch acc: 0.3282
Train, Epoch: 1, Batch: 413, Step num: 413, Learning rate: 0.00028859, Avg batch loss: 0.7757, Avg batch acc: 0.3303
Train, Epoch: 1, Batch: 414, Step num: 414, Learning rate: 0.00028929, Avg batch loss: 0.6963, Avg batch acc: 0.3636
Train, Epoch: 1, Batch: 415, Step num: 415, Learning rate: 0.00028999, Avg batch loss: 0.6827, Avg batch acc: 0.3284
Train, Epoch: 1, Batch: 416, Step num: 416, Learning rate: 0.00029069, Avg batch loss: 0.6667, Avg batch acc: 0.3725
Train, Epoch: 1, Batch: 417, Step num: 417, Learning rate: 0.00029139, Avg batch loss: 0.6956, Avg batch acc: 0.3594
Train, Epoch: 1, Batch: 418, Step num: 418, Learning rate: 0.00029209, Avg batch loss: 0.7194, Avg batch acc: 0.3373
Train, Epoch: 1, Batch: 419, Step num: 419, Learning rate: 0.00029279, Avg batch loss: 0.6553, Avg batch acc: 0.3361
Train, Epoch: 1, Batch: 420, Step num: 420, Learning rate: 0.00029348, Avg batch loss: 0.7489, Avg batch acc: 0.3369
Train, Epoch: 1, Batch: 421, Step num: 421, Learning rate: 0.00029418, Avg batch loss: 0.6976, Avg batch acc: 0.3607
Train, Epoch: 1, Batch: 422, Step num: 422, Learning rate: 0.00029488, Avg batch loss: 0.6738, Avg batch acc: 0.3471
Train, Epoch: 1, Batch: 423, Step num: 423, Learning rate: 0.00029558, Avg batch loss: 0.7026, Avg batch acc: 0.3436
Train, Epoch: 1, Batch: 424, Step num: 424, Learning rate: 0.00029628, Avg batch loss: 0.6703, Avg batch acc: 0.3536
Train, Epoch: 1, Batch: 425, Step num: 425, Learning rate: 0.00029698, Avg batch loss: 0.7169, Avg batch acc: 0.3332
Train, Epoch: 1, Batch: 426, Step num: 426, Learning rate: 0.00029768, Avg batch loss: 0.7394, Avg batch acc: 0.3577
Train, Epoch: 1, Batch: 427, Step num: 427, Learning rate: 0.00029838, Avg batch loss: 0.8174, Avg batch acc: 0.3368
Train, Epoch: 1, Batch: 428, Step num: 428, Learning rate: 0.00029907, Avg batch loss: 0.7166, Avg batch acc: 0.3431
Train, Epoch: 1, Batch: 429, Step num: 429, Learning rate: 0.00029977, Avg batch loss: 0.7627, Avg batch acc: 0.3514
Train, Epoch: 1, Batch: 430, Step num: 430, Learning rate: 0.00030047, Avg batch loss: 0.7452, Avg batch acc: 0.3452
Train, Epoch: 1, Batch: 431, Step num: 431, Learning rate: 0.00030117, Avg batch loss: 0.7446, Avg batch acc: 0.3486
Train, Epoch: 1, Batch: 432, Step num: 432, Learning rate: 0.00030187, Avg batch loss: 0.6433, Avg batch acc: 0.3614
Train, Epoch: 1, Batch: 433, Step num: 433, Learning rate: 0.00030257, Avg batch loss: 0.6641, Avg batch acc: 0.3440
Train, Epoch: 1, Batch: 434, Step num: 434, Learning rate: 0.00030327, Avg batch loss: 0.6148, Avg batch acc: 0.3466
Train, Epoch: 1, Batch: 435, Step num: 435, Learning rate: 0.00030397, Avg batch loss: 0.7284, Avg batch acc: 0.3431
Train, Epoch: 1, Batch: 436, Step num: 436, Learning rate: 0.00030466, Avg batch loss: 0.6978, Avg batch acc: 0.3554
Train, Epoch: 1, Batch: 437, Step num: 437, Learning rate: 0.00030536, Avg batch loss: 0.7763, Avg batch acc: 0.3302
Train, Epoch: 1, Batch: 438, Step num: 438, Learning rate: 0.00030606, Avg batch loss: 0.7480, Avg batch acc: 0.3268
Train, Epoch: 1, Batch: 439, Step num: 439, Learning rate: 0.00030676, Avg batch loss: 0.7761, Avg batch acc: 0.3310
Train, Epoch: 1, Batch: 440, Step num: 440, Learning rate: 0.00030746, Avg batch loss: 0.6919, Avg batch acc: 0.3509
Train, Epoch: 1, Batch: 441, Step num: 441, Learning rate: 0.00030816, Avg batch loss: 0.6059, Avg batch acc: 0.3760
Train, Epoch: 1, Batch: 442, Step num: 442, Learning rate: 0.00030886, Avg batch loss: 0.7349, Avg batch acc: 0.3432
Train, Epoch: 1, Batch: 443, Step num: 443, Learning rate: 0.00030956, Avg batch loss: 0.7102, Avg batch acc: 0.3574
Train, Epoch: 1, Batch: 444, Step num: 444, Learning rate: 0.00031025, Avg batch loss: 0.7745, Avg batch acc: 0.3545
Train, Epoch: 1, Batch: 445, Step num: 445, Learning rate: 0.00031095, Avg batch loss: 0.6983, Avg batch acc: 0.3873
Train, Epoch: 1, Batch: 446, Step num: 446, Learning rate: 0.00031165, Avg batch loss: 0.6817, Avg batch acc: 0.3705
Train, Epoch: 1, Batch: 447, Step num: 447, Learning rate: 0.00031235, Avg batch loss: 0.7135, Avg batch acc: 0.3402
Train, Epoch: 1, Batch: 448, Step num: 448, Learning rate: 0.00031305, Avg batch loss: 0.7350, Avg batch acc: 0.3365
Train, Epoch: 1, Batch: 449, Step num: 449, Learning rate: 0.00031375, Avg batch loss: 0.7129, Avg batch acc: 0.3501
Train, Epoch: 1, Batch: 450, Step num: 450, Learning rate: 0.00031445, Avg batch loss: 0.6746, Avg batch acc: 0.3593
Train, Epoch: 1, Batch: 451, Step num: 451, Learning rate: 0.00031515, Avg batch loss: 0.6441, Avg batch acc: 0.3449
Train, Epoch: 1, Batch: 452, Step num: 452, Learning rate: 0.00031584, Avg batch loss: 0.7141, Avg batch acc: 0.3473
Train, Epoch: 1, Batch: 453, Step num: 453, Learning rate: 0.00031654, Avg batch loss: 0.6818, Avg batch acc: 0.3671
Train, Epoch: 1, Batch: 454, Step num: 454, Learning rate: 0.00031724, Avg batch loss: 0.6967, Avg batch acc: 0.3528
Train, Epoch: 1, Batch: 455, Step num: 455, Learning rate: 0.00031794, Avg batch loss: 0.7770, Avg batch acc: 0.3588
Train, Epoch: 1, Batch: 456, Step num: 456, Learning rate: 0.00031864, Avg batch loss: 0.7210, Avg batch acc: 0.3466
Train, Epoch: 1, Batch: 457, Step num: 457, Learning rate: 0.00031934, Avg batch loss: 0.7305, Avg batch acc: 0.3441
Train, Epoch: 1, Batch: 458, Step num: 458, Learning rate: 0.00032004, Avg batch loss: 0.7330, Avg batch acc: 0.3461
Train, Epoch: 1, Batch: 459, Step num: 459, Learning rate: 0.00032074, Avg batch loss: 0.6954, Avg batch acc: 0.3614
Train, Epoch: 1, Batch: 460, Step num: 460, Learning rate: 0.00032143, Avg batch loss: 0.7178, Avg batch acc: 0.3554
Train, Epoch: 1, Batch: 461, Step num: 461, Learning rate: 0.00032213, Avg batch loss: 0.6633, Avg batch acc: 0.3604
Train, Epoch: 1, Batch: 462, Step num: 462, Learning rate: 0.00032283, Avg batch loss: 0.6649, Avg batch acc: 0.3805
Train, Epoch: 1, Batch: 463, Step num: 463, Learning rate: 0.00032353, Avg batch loss: 0.6909, Avg batch acc: 0.3430
Train, Epoch: 1, Batch: 464, Step num: 464, Learning rate: 0.00032423, Avg batch loss: 0.7357, Avg batch acc: 0.3343
Train, Epoch: 1, Batch: 465, Step num: 465, Learning rate: 0.00032493, Avg batch loss: 0.6355, Avg batch acc: 0.3588
Train, Epoch: 1, Batch: 466, Step num: 466, Learning rate: 0.00032563, Avg batch loss: 0.7011, Avg batch acc: 0.3603
Train, Epoch: 1, Batch: 467, Step num: 467, Learning rate: 0.00032633, Avg batch loss: 0.7309, Avg batch acc: 0.3617
Train, Epoch: 1, Batch: 468, Step num: 468, Learning rate: 0.00032702, Avg batch loss: 0.7903, Avg batch acc: 0.3316
Train, Epoch: 1, Batch: 469, Step num: 469, Learning rate: 0.00032772, Avg batch loss: 0.7330, Avg batch acc: 0.3465
Train, Epoch: 1, Batch: 470, Step num: 470, Learning rate: 0.00032842, Avg batch loss: 0.7673, Avg batch acc: 0.3313
Train, Epoch: 1, Batch: 471, Step num: 471, Learning rate: 0.00032912, Avg batch loss: 0.7317, Avg batch acc: 0.3583
Train, Epoch: 1, Batch: 472, Step num: 472, Learning rate: 0.00032982, Avg batch loss: 0.6862, Avg batch acc: 0.3642
Train, Epoch: 1, Batch: 473, Step num: 473, Learning rate: 0.00033052, Avg batch loss: 0.6648, Avg batch acc: 0.3491
Train, Epoch: 1, Batch: 474, Step num: 474, Learning rate: 0.00033122, Avg batch loss: 0.6983, Avg batch acc: 0.3567
Train, Epoch: 1, Batch: 475, Step num: 475, Learning rate: 0.00033192, Avg batch loss: 0.6354, Avg batch acc: 0.3968
Train, Epoch: 1, Batch: 476, Step num: 476, Learning rate: 0.00033262, Avg batch loss: 0.6700, Avg batch acc: 0.3686
Train, Epoch: 1, Batch: 477, Step num: 477, Learning rate: 0.00033331, Avg batch loss: 0.7059, Avg batch acc: 0.3543
Train, Epoch: 1, Batch: 478, Step num: 478, Learning rate: 0.00033401, Avg batch loss: 0.7707, Avg batch acc: 0.3322
Train, Epoch: 1, Batch: 479, Step num: 479, Learning rate: 0.00033471, Avg batch loss: 0.7023, Avg batch acc: 0.3509
Train, Epoch: 1, Batch: 480, Step num: 480, Learning rate: 0.00033541, Avg batch loss: 0.6947, Avg batch acc: 0.3530
Train, Epoch: 1, Batch: 481, Step num: 481, Learning rate: 0.00033611, Avg batch loss: 0.7166, Avg batch acc: 0.3451
Train, Epoch: 1, Batch: 482, Step num: 482, Learning rate: 0.00033681, Avg batch loss: 0.6856, Avg batch acc: 0.3465
Train, Epoch: 1, Batch: 483, Step num: 483, Learning rate: 0.00033751, Avg batch loss: 0.6948, Avg batch acc: 0.3393
Train, Epoch: 1, Batch: 484, Step num: 484, Learning rate: 0.00033821, Avg batch loss: 0.6502, Avg batch acc: 0.3668
Train, Epoch: 1, Batch: 485, Step num: 485, Learning rate: 0.00033890, Avg batch loss: 0.7161, Avg batch acc: 0.3411
Train, Epoch: 1, Batch: 486, Step num: 486, Learning rate: 0.00033960, Avg batch loss: 0.7065, Avg batch acc: 0.3551
Train, Epoch: 1, Batch: 487, Step num: 487, Learning rate: 0.00034030, Avg batch loss: 0.6824, Avg batch acc: 0.3659
Train, Epoch: 1, Batch: 488, Step num: 488, Learning rate: 0.00034100, Avg batch loss: 0.6913, Avg batch acc: 0.3648
Train, Epoch: 1, Batch: 489, Step num: 489, Learning rate: 0.00034170, Avg batch loss: 0.6918, Avg batch acc: 0.3572
Train, Epoch: 1, Batch: 490, Step num: 490, Learning rate: 0.00034240, Avg batch loss: 0.7117, Avg batch acc: 0.3442
Train, Epoch: 1, Batch: 491, Step num: 491, Learning rate: 0.00034310, Avg batch loss: 0.7644, Avg batch acc: 0.3622
Train, Epoch: 1, Batch: 492, Step num: 492, Learning rate: 0.00034380, Avg batch loss: 0.7381, Avg batch acc: 0.3419
Train, Epoch: 1, Batch: 493, Step num: 493, Learning rate: 0.00034449, Avg batch loss: 0.6183, Avg batch acc: 0.3733
Train, Epoch: 1, Batch: 494, Step num: 494, Learning rate: 0.00034519, Avg batch loss: 0.7163, Avg batch acc: 0.3424
Train, Epoch: 1, Batch: 495, Step num: 495, Learning rate: 0.00034589, Avg batch loss: 0.7028, Avg batch acc: 0.3595
Train, Epoch: 1, Batch: 496, Step num: 496, Learning rate: 0.00034659, Avg batch loss: 0.6998, Avg batch acc: 0.3541
Train, Epoch: 1, Batch: 497, Step num: 497, Learning rate: 0.00034729, Avg batch loss: 0.7309, Avg batch acc: 0.3645
Train, Epoch: 1, Batch: 498, Step num: 498, Learning rate: 0.00034799, Avg batch loss: 0.7279, Avg batch acc: 0.3623
Train, Epoch: 1, Batch: 499, Step num: 499, Learning rate: 0.00034869, Avg batch loss: 0.6619, Avg batch acc: 0.3593
Train, Epoch: 1, Batch: 500, Step num: 500, Learning rate: 0.00034939, Avg batch loss: 0.6668, Avg batch acc: 0.3716
Train, Epoch: 1, Batch: 501, Step num: 501, Learning rate: 0.00035008, Avg batch loss: 0.6292, Avg batch acc: 0.3631
Train, Epoch: 1, Batch: 502, Step num: 502, Learning rate: 0.00035078, Avg batch loss: 0.6454, Avg batch acc: 0.3753
Train, Epoch: 1, Batch: 503, Step num: 503, Learning rate: 0.00035148, Avg batch loss: 0.7686, Avg batch acc: 0.3666
Train, Epoch: 1, Batch: 504, Step num: 504, Learning rate: 0.00035218, Avg batch loss: 0.6717, Avg batch acc: 0.3647
Train, Epoch: 1, Batch: 505, Step num: 505, Learning rate: 0.00035288, Avg batch loss: 0.6114, Avg batch acc: 0.3645
Train, Epoch: 1, Batch: 506, Step num: 506, Learning rate: 0.00035358, Avg batch loss: 0.6622, Avg batch acc: 0.3638
Train, Epoch: 1, Batch: 507, Step num: 507, Learning rate: 0.00035428, Avg batch loss: 0.7011, Avg batch acc: 0.3548
Train, Epoch: 1, Batch: 508, Step num: 508, Learning rate: 0.00035498, Avg batch loss: 0.7272, Avg batch acc: 0.3572
Train, Epoch: 1, Batch: 509, Step num: 509, Learning rate: 0.00035567, Avg batch loss: 0.7488, Avg batch acc: 0.3354
Train, Epoch: 1, Batch: 510, Step num: 510, Learning rate: 0.00035637, Avg batch loss: 0.6730, Avg batch acc: 0.3582
Train, Epoch: 1, Batch: 511, Step num: 511, Learning rate: 0.00035707, Avg batch loss: 0.7037, Avg batch acc: 0.3721
Train, Epoch: 1, Batch: 512, Step num: 512, Learning rate: 0.00035777, Avg batch loss: 0.6794, Avg batch acc: 0.3408
Train, Epoch: 1, Batch: 513, Step num: 513, Learning rate: 0.00035847, Avg batch loss: 0.7008, Avg batch acc: 0.3690
Train, Epoch: 1, Batch: 514, Step num: 514, Learning rate: 0.00035917, Avg batch loss: 0.6616, Avg batch acc: 0.3718
Train, Epoch: 1, Batch: 515, Step num: 515, Learning rate: 0.00035987, Avg batch loss: 0.6224, Avg batch acc: 0.3558
Train, Epoch: 1, Batch: 516, Step num: 516, Learning rate: 0.00036057, Avg batch loss: 0.6653, Avg batch acc: 0.3837
Train, Epoch: 1, Batch: 517, Step num: 517, Learning rate: 0.00036126, Avg batch loss: 0.7020, Avg batch acc: 0.3782
Train, Epoch: 1, Batch: 518, Step num: 518, Learning rate: 0.00036196, Avg batch loss: 0.7379, Avg batch acc: 0.3560
Train, Epoch: 1, Batch: 519, Step num: 519, Learning rate: 0.00036266, Avg batch loss: 0.7558, Avg batch acc: 0.3429
Train, Epoch: 1, Batch: 520, Step num: 520, Learning rate: 0.00036336, Avg batch loss: 0.6353, Avg batch acc: 0.3784
Train, Epoch: 1, Batch: 521, Step num: 521, Learning rate: 0.00036406, Avg batch loss: 0.7028, Avg batch acc: 0.3661
Train, Epoch: 1, Batch: 522, Step num: 522, Learning rate: 0.00036476, Avg batch loss: 0.6567, Avg batch acc: 0.3560
Train, Epoch: 1, Batch: 523, Step num: 523, Learning rate: 0.00036546, Avg batch loss: 0.6958, Avg batch acc: 0.3629
Train, Epoch: 1, Batch: 524, Step num: 524, Learning rate: 0.00036616, Avg batch loss: 0.6405, Avg batch acc: 0.3645
Train, Epoch: 1, Batch: 525, Step num: 525, Learning rate: 0.00036685, Avg batch loss: 0.6606, Avg batch acc: 0.3579
Train, Epoch: 1, Batch: 526, Step num: 526, Learning rate: 0.00036755, Avg batch loss: 0.6456, Avg batch acc: 0.3631
Train, Epoch: 1, Batch: 527, Step num: 527, Learning rate: 0.00036825, Avg batch loss: 0.6326, Avg batch acc: 0.3891
Train, Epoch: 1, Batch: 528, Step num: 528, Learning rate: 0.00036895, Avg batch loss: 0.6663, Avg batch acc: 0.3655
Train, Epoch: 1, Batch: 529, Step num: 529, Learning rate: 0.00036965, Avg batch loss: 0.6676, Avg batch acc: 0.3596
Train, Epoch: 1, Batch: 530, Step num: 530, Learning rate: 0.00037035, Avg batch loss: 0.7097, Avg batch acc: 0.3514
Train, Epoch: 1, Batch: 531, Step num: 531, Learning rate: 0.00037105, Avg batch loss: 0.6154, Avg batch acc: 0.3707
Train, Epoch: 1, Batch: 532, Step num: 532, Learning rate: 0.00037175, Avg batch loss: 0.6721, Avg batch acc: 0.3604
Train, Epoch: 1, Batch: 533, Step num: 533, Learning rate: 0.00037245, Avg batch loss: 0.7097, Avg batch acc: 0.3645
Train, Epoch: 1, Batch: 534, Step num: 534, Learning rate: 0.00037314, Avg batch loss: 0.6436, Avg batch acc: 0.3676
Train, Epoch: 1, Batch: 535, Step num: 535, Learning rate: 0.00037384, Avg batch loss: 0.6662, Avg batch acc: 0.3573
Train, Epoch: 1, Batch: 536, Step num: 536, Learning rate: 0.00037454, Avg batch loss: 0.7144, Avg batch acc: 0.3591
Train, Epoch: 1, Batch: 537, Step num: 537, Learning rate: 0.00037524, Avg batch loss: 0.6972, Avg batch acc: 0.3674
Train, Epoch: 1, Batch: 538, Step num: 538, Learning rate: 0.00037594, Avg batch loss: 0.6398, Avg batch acc: 0.3527
Train, Epoch: 1, Batch: 539, Step num: 539, Learning rate: 0.00037664, Avg batch loss: 0.7023, Avg batch acc: 0.3489
Train, Epoch: 1, Batch: 540, Step num: 540, Learning rate: 0.00037734, Avg batch loss: 0.6564, Avg batch acc: 0.3709
Train, Epoch: 1, Batch: 541, Step num: 541, Learning rate: 0.00037804, Avg batch loss: 0.6953, Avg batch acc: 0.3635
Train, Epoch: 1, Batch: 542, Step num: 542, Learning rate: 0.00037873, Avg batch loss: 0.7294, Avg batch acc: 0.3530
Train, Epoch: 1, Batch: 543, Step num: 543, Learning rate: 0.00037943, Avg batch loss: 0.7020, Avg batch acc: 0.3656
Train, Epoch: 1, Batch: 544, Step num: 544, Learning rate: 0.00038013, Avg batch loss: 0.6629, Avg batch acc: 0.3590
Train, Epoch: 1, Batch: 545, Step num: 545, Learning rate: 0.00038083, Avg batch loss: 0.6225, Avg batch acc: 0.3661
Train, Epoch: 1, Batch: 546, Step num: 546, Learning rate: 0.00038153, Avg batch loss: 0.6918, Avg batch acc: 0.3769
Train, Epoch: 1, Batch: 547, Step num: 547, Learning rate: 0.00038223, Avg batch loss: 0.7273, Avg batch acc: 0.3439
Train, Epoch: 1, Batch: 548, Step num: 548, Learning rate: 0.00038293, Avg batch loss: 0.6618, Avg batch acc: 0.3572
Train, Epoch: 1, Batch: 549, Step num: 549, Learning rate: 0.00038363, Avg batch loss: 0.6535, Avg batch acc: 0.3794
Train, Epoch: 1, Batch: 550, Step num: 550, Learning rate: 0.00038432, Avg batch loss: 0.6189, Avg batch acc: 0.3555
Train, Epoch: 1, Batch: 551, Step num: 551, Learning rate: 0.00038502, Avg batch loss: 0.7203, Avg batch acc: 0.3537
Train, Epoch: 1, Batch: 552, Step num: 552, Learning rate: 0.00038572, Avg batch loss: 0.7294, Avg batch acc: 0.3501
Train, Epoch: 1, Batch: 553, Step num: 553, Learning rate: 0.00038642, Avg batch loss: 0.6713, Avg batch acc: 0.3672
Train, Epoch: 1, Batch: 554, Step num: 554, Learning rate: 0.00038712, Avg batch loss: 0.6826, Avg batch acc: 0.3709
Train, Epoch: 1, Batch: 555, Step num: 555, Learning rate: 0.00038782, Avg batch loss: 0.7043, Avg batch acc: 0.3609
Train, Epoch: 1, Batch: 556, Step num: 556, Learning rate: 0.00038852, Avg batch loss: 0.6165, Avg batch acc: 0.3790
Train, Epoch: 1, Batch: 557, Step num: 557, Learning rate: 0.00038922, Avg batch loss: 0.7446, Avg batch acc: 0.3494
Train, Epoch: 1, Batch: 558, Step num: 558, Learning rate: 0.00038991, Avg batch loss: 0.6398, Avg batch acc: 0.3686
Train, Epoch: 1, Batch: 559, Step num: 559, Learning rate: 0.00039061, Avg batch loss: 0.7518, Avg batch acc: 0.3378
Train, Epoch: 1, Batch: 560, Step num: 560, Learning rate: 0.00039131, Avg batch loss: 0.6480, Avg batch acc: 0.3931
Train, Epoch: 1, Batch: 561, Step num: 561, Learning rate: 0.00039201, Avg batch loss: 0.6903, Avg batch acc: 0.3844
Train, Epoch: 1, Batch: 562, Step num: 562, Learning rate: 0.00039271, Avg batch loss: 0.6578, Avg batch acc: 0.4002
Train, Epoch: 1, Batch: 563, Step num: 563, Learning rate: 0.00039341, Avg batch loss: 0.6959, Avg batch acc: 0.3661
Train, Epoch: 1, Batch: 564, Step num: 564, Learning rate: 0.00039411, Avg batch loss: 0.7133, Avg batch acc: 0.3590
Train, Epoch: 1, Batch: 565, Step num: 565, Learning rate: 0.00039481, Avg batch loss: 0.7658, Avg batch acc: 0.3473
Train, Epoch: 1, Batch: 566, Step num: 566, Learning rate: 0.00039550, Avg batch loss: 0.6730, Avg batch acc: 0.3653
Train, Epoch: 1, Batch: 567, Step num: 567, Learning rate: 0.00039620, Avg batch loss: 0.6864, Avg batch acc: 0.3719
Train, Epoch: 1, Batch: 568, Step num: 568, Learning rate: 0.00039690, Avg batch loss: 0.6913, Avg batch acc: 0.3565
Train, Epoch: 1, Batch: 569, Step num: 569, Learning rate: 0.00039760, Avg batch loss: 0.6990, Avg batch acc: 0.3527
Train, Epoch: 1, Batch: 570, Step num: 570, Learning rate: 0.00039830, Avg batch loss: 0.6337, Avg batch acc: 0.3684
Train, Epoch: 1, Batch: 571, Step num: 571, Learning rate: 0.00039900, Avg batch loss: 0.7023, Avg batch acc: 0.3572
Train, Epoch: 1, Batch: 572, Step num: 572, Learning rate: 0.00039970, Avg batch loss: 0.7132, Avg batch acc: 0.3539
Train, Epoch: 1, Batch: 573, Step num: 573, Learning rate: 0.00040040, Avg batch loss: 0.7357, Avg batch acc: 0.3588
Train, Epoch: 1, Batch: 574, Step num: 574, Learning rate: 0.00040109, Avg batch loss: 0.6713, Avg batch acc: 0.3851
Train, Epoch: 1, Batch: 575, Step num: 575, Learning rate: 0.00040179, Avg batch loss: 0.6211, Avg batch acc: 0.3745
Train, Epoch: 1, Batch: 576, Step num: 576, Learning rate: 0.00040249, Avg batch loss: 0.6574, Avg batch acc: 0.3725
Train, Epoch: 1, Batch: 577, Step num: 577, Learning rate: 0.00040319, Avg batch loss: 0.6362, Avg batch acc: 0.3659
Train, Epoch: 1, Batch: 578, Step num: 578, Learning rate: 0.00040389, Avg batch loss: 0.7244, Avg batch acc: 0.3618
Train, Epoch: 1, Batch: 579, Step num: 579, Learning rate: 0.00040459, Avg batch loss: 0.6072, Avg batch acc: 0.3880
Train, Epoch: 1, Batch: 580, Step num: 580, Learning rate: 0.00040529, Avg batch loss: 0.6872, Avg batch acc: 0.3714
Train, Epoch: 1, Batch: 581, Step num: 581, Learning rate: 0.00040599, Avg batch loss: 0.6635, Avg batch acc: 0.3698
Train, Epoch: 1, Batch: 582, Step num: 582, Learning rate: 0.00040668, Avg batch loss: 0.6567, Avg batch acc: 0.3666
Train, Epoch: 1, Batch: 583, Step num: 583, Learning rate: 0.00040738, Avg batch loss: 0.7242, Avg batch acc: 0.3612
Train, Epoch: 1, Batch: 584, Step num: 584, Learning rate: 0.00040808, Avg batch loss: 0.6815, Avg batch acc: 0.3665
Train, Epoch: 1, Batch: 585, Step num: 585, Learning rate: 0.00040878, Avg batch loss: 0.6745, Avg batch acc: 0.3761
Train, Epoch: 1, Batch: 586, Step num: 586, Learning rate: 0.00040948, Avg batch loss: 0.6292, Avg batch acc: 0.3769
Train, Epoch: 1, Batch: 587, Step num: 587, Learning rate: 0.00041018, Avg batch loss: 0.6974, Avg batch acc: 0.3591
Train, Epoch: 1, Batch: 588, Step num: 588, Learning rate: 0.00041088, Avg batch loss: 0.6498, Avg batch acc: 0.3674
Train, Epoch: 1, Batch: 589, Step num: 589, Learning rate: 0.00041158, Avg batch loss: 0.6868, Avg batch acc: 0.3578
Train, Epoch: 1, Batch: 590, Step num: 590, Learning rate: 0.00041228, Avg batch loss: 0.6026, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 591, Step num: 591, Learning rate: 0.00041297, Avg batch loss: 0.6617, Avg batch acc: 0.3652
Train, Epoch: 1, Batch: 592, Step num: 592, Learning rate: 0.00041367, Avg batch loss: 0.6569, Avg batch acc: 0.3769
Train, Epoch: 1, Batch: 593, Step num: 593, Learning rate: 0.00041437, Avg batch loss: 0.6414, Avg batch acc: 0.3795
Train, Epoch: 1, Batch: 594, Step num: 594, Learning rate: 0.00041507, Avg batch loss: 0.6424, Avg batch acc: 0.3731
Train, Epoch: 1, Batch: 595, Step num: 595, Learning rate: 0.00041577, Avg batch loss: 0.7094, Avg batch acc: 0.3657
Train, Epoch: 1, Batch: 596, Step num: 596, Learning rate: 0.00041647, Avg batch loss: 0.6427, Avg batch acc: 0.3591
Train, Epoch: 1, Batch: 597, Step num: 597, Learning rate: 0.00041717, Avg batch loss: 0.6956, Avg batch acc: 0.3541
Train, Epoch: 1, Batch: 598, Step num: 598, Learning rate: 0.00041787, Avg batch loss: 0.6279, Avg batch acc: 0.3691
Train, Epoch: 1, Batch: 599, Step num: 599, Learning rate: 0.00041856, Avg batch loss: 0.6683, Avg batch acc: 0.3637
Train, Epoch: 1, Batch: 600, Step num: 600, Learning rate: 0.00041926, Avg batch loss: 0.6356, Avg batch acc: 0.3946
Train, Epoch: 1, Batch: 601, Step num: 601, Learning rate: 0.00041996, Avg batch loss: 0.7004, Avg batch acc: 0.3708
Train, Epoch: 1, Batch: 602, Step num: 602, Learning rate: 0.00042066, Avg batch loss: 0.6200, Avg batch acc: 0.3630
Train, Epoch: 1, Batch: 603, Step num: 603, Learning rate: 0.00042136, Avg batch loss: 0.6856, Avg batch acc: 0.3696
Train, Epoch: 1, Batch: 604, Step num: 604, Learning rate: 0.00042206, Avg batch loss: 0.6248, Avg batch acc: 0.3907
Train, Epoch: 1, Batch: 605, Step num: 605, Learning rate: 0.00042276, Avg batch loss: 0.6620, Avg batch acc: 0.3776
Train, Epoch: 1, Batch: 606, Step num: 606, Learning rate: 0.00042346, Avg batch loss: 0.6814, Avg batch acc: 0.3716
Train, Epoch: 1, Batch: 607, Step num: 607, Learning rate: 0.00042415, Avg batch loss: 0.7199, Avg batch acc: 0.3590
Train, Epoch: 1, Batch: 608, Step num: 608, Learning rate: 0.00042485, Avg batch loss: 0.6224, Avg batch acc: 0.3553
Train, Epoch: 1, Batch: 609, Step num: 609, Learning rate: 0.00042555, Avg batch loss: 0.6243, Avg batch acc: 0.3905
Train, Epoch: 1, Batch: 610, Step num: 610, Learning rate: 0.00042625, Avg batch loss: 0.6627, Avg batch acc: 0.3860
Train, Epoch: 1, Batch: 611, Step num: 611, Learning rate: 0.00042695, Avg batch loss: 0.7028, Avg batch acc: 0.3559
Train, Epoch: 1, Batch: 612, Step num: 612, Learning rate: 0.00042765, Avg batch loss: 0.6612, Avg batch acc: 0.3687
Train, Epoch: 1, Batch: 613, Step num: 613, Learning rate: 0.00042835, Avg batch loss: 0.6831, Avg batch acc: 0.3729
Train, Epoch: 1, Batch: 614, Step num: 614, Learning rate: 0.00042905, Avg batch loss: 0.6847, Avg batch acc: 0.3725
Train, Epoch: 1, Batch: 615, Step num: 615, Learning rate: 0.00042974, Avg batch loss: 0.6625, Avg batch acc: 0.3727
Train, Epoch: 1, Batch: 616, Step num: 616, Learning rate: 0.00043044, Avg batch loss: 0.6430, Avg batch acc: 0.3658
Train, Epoch: 1, Batch: 617, Step num: 617, Learning rate: 0.00043114, Avg batch loss: 0.6430, Avg batch acc: 0.3771
Train, Epoch: 1, Batch: 618, Step num: 618, Learning rate: 0.00043184, Avg batch loss: 0.6344, Avg batch acc: 0.3578
Train, Epoch: 1, Batch: 619, Step num: 619, Learning rate: 0.00043254, Avg batch loss: 0.6503, Avg batch acc: 0.3775
Train, Epoch: 1, Batch: 620, Step num: 620, Learning rate: 0.00043324, Avg batch loss: 0.6272, Avg batch acc: 0.3606
Train, Epoch: 1, Batch: 621, Step num: 621, Learning rate: 0.00043394, Avg batch loss: 0.7254, Avg batch acc: 0.3522
Train, Epoch: 1, Batch: 622, Step num: 622, Learning rate: 0.00043464, Avg batch loss: 0.6752, Avg batch acc: 0.3763
Train, Epoch: 1, Batch: 623, Step num: 623, Learning rate: 0.00043533, Avg batch loss: 0.6326, Avg batch acc: 0.3575
Train, Epoch: 1, Batch: 624, Step num: 624, Learning rate: 0.00043603, Avg batch loss: 0.6464, Avg batch acc: 0.3725
Train, Epoch: 1, Batch: 625, Step num: 625, Learning rate: 0.00043673, Avg batch loss: 0.6371, Avg batch acc: 0.3580
Train, Epoch: 1, Batch: 626, Step num: 626, Learning rate: 0.00043743, Avg batch loss: 0.6897, Avg batch acc: 0.3722
Train, Epoch: 1, Batch: 627, Step num: 627, Learning rate: 0.00043813, Avg batch loss: 0.6387, Avg batch acc: 0.3660
Train, Epoch: 1, Batch: 628, Step num: 628, Learning rate: 0.00043883, Avg batch loss: 0.6966, Avg batch acc: 0.3552
Train, Epoch: 1, Batch: 629, Step num: 629, Learning rate: 0.00043953, Avg batch loss: 0.6708, Avg batch acc: 0.3965
Train, Epoch: 1, Batch: 630, Step num: 630, Learning rate: 0.00044023, Avg batch loss: 0.6301, Avg batch acc: 0.3873
Train, Epoch: 1, Batch: 631, Step num: 631, Learning rate: 0.00044092, Avg batch loss: 0.6666, Avg batch acc: 0.3843
Train, Epoch: 1, Batch: 632, Step num: 632, Learning rate: 0.00044162, Avg batch loss: 0.6651, Avg batch acc: 0.3731
Train, Epoch: 1, Batch: 633, Step num: 633, Learning rate: 0.00044232, Avg batch loss: 0.6274, Avg batch acc: 0.3972
Train, Epoch: 1, Batch: 634, Step num: 634, Learning rate: 0.00044302, Avg batch loss: 0.6087, Avg batch acc: 0.3778
Train, Epoch: 1, Batch: 635, Step num: 635, Learning rate: 0.00044372, Avg batch loss: 0.6829, Avg batch acc: 0.3731
Train, Epoch: 1, Batch: 636, Step num: 636, Learning rate: 0.00044442, Avg batch loss: 0.6903, Avg batch acc: 0.3566
Train, Epoch: 1, Batch: 637, Step num: 637, Learning rate: 0.00044512, Avg batch loss: 0.6909, Avg batch acc: 0.3567
Train, Epoch: 1, Batch: 638, Step num: 638, Learning rate: 0.00044582, Avg batch loss: 0.6310, Avg batch acc: 0.3691
Train, Epoch: 1, Batch: 639, Step num: 639, Learning rate: 0.00044651, Avg batch loss: 0.6253, Avg batch acc: 0.3955
Train, Epoch: 1, Batch: 640, Step num: 640, Learning rate: 0.00044721, Avg batch loss: 0.7162, Avg batch acc: 0.3792
Train, Epoch: 1, Batch: 641, Step num: 641, Learning rate: 0.00044791, Avg batch loss: 0.6092, Avg batch acc: 0.3750
Train, Epoch: 1, Batch: 642, Step num: 642, Learning rate: 0.00044861, Avg batch loss: 0.7417, Avg batch acc: 0.3427
Train, Epoch: 1, Batch: 643, Step num: 643, Learning rate: 0.00044931, Avg batch loss: 0.6807, Avg batch acc: 0.3807
Train, Epoch: 1, Batch: 644, Step num: 644, Learning rate: 0.00045001, Avg batch loss: 0.6475, Avg batch acc: 0.3754
Train, Epoch: 1, Batch: 645, Step num: 645, Learning rate: 0.00045071, Avg batch loss: 0.6679, Avg batch acc: 0.3787
Train, Epoch: 1, Batch: 646, Step num: 646, Learning rate: 0.00045141, Avg batch loss: 0.6365, Avg batch acc: 0.3728
Train, Epoch: 1, Batch: 647, Step num: 647, Learning rate: 0.00045210, Avg batch loss: 0.6071, Avg batch acc: 0.3592
Train, Epoch: 1, Batch: 648, Step num: 648, Learning rate: 0.00045280, Avg batch loss: 0.6477, Avg batch acc: 0.3569
Train, Epoch: 1, Batch: 649, Step num: 649, Learning rate: 0.00045350, Avg batch loss: 0.6647, Avg batch acc: 0.3598
Train, Epoch: 1, Batch: 650, Step num: 650, Learning rate: 0.00045420, Avg batch loss: 0.6016, Avg batch acc: 0.3691
Train, Epoch: 1, Batch: 651, Step num: 651, Learning rate: 0.00045490, Avg batch loss: 0.7177, Avg batch acc: 0.3730
Train, Epoch: 1, Batch: 652, Step num: 652, Learning rate: 0.00045560, Avg batch loss: 0.6996, Avg batch acc: 0.3701
Train, Epoch: 1, Batch: 653, Step num: 653, Learning rate: 0.00045630, Avg batch loss: 0.6665, Avg batch acc: 0.3825
Train, Epoch: 1, Batch: 654, Step num: 654, Learning rate: 0.00045700, Avg batch loss: 0.6378, Avg batch acc: 0.3701
Train, Epoch: 1, Batch: 655, Step num: 655, Learning rate: 0.00045770, Avg batch loss: 0.6823, Avg batch acc: 0.3793
Train, Epoch: 1, Batch: 656, Step num: 656, Learning rate: 0.00045839, Avg batch loss: 0.6594, Avg batch acc: 0.3881
Train, Epoch: 1, Batch: 657, Step num: 657, Learning rate: 0.00045909, Avg batch loss: 0.6189, Avg batch acc: 0.4027
Train, Epoch: 1, Batch: 658, Step num: 658, Learning rate: 0.00045979, Avg batch loss: 0.6794, Avg batch acc: 0.3886
Train, Epoch: 1, Batch: 659, Step num: 659, Learning rate: 0.00046049, Avg batch loss: 0.6472, Avg batch acc: 0.3766
Train, Epoch: 1, Batch: 660, Step num: 660, Learning rate: 0.00046119, Avg batch loss: 0.6476, Avg batch acc: 0.3832
Train, Epoch: 1, Batch: 661, Step num: 661, Learning rate: 0.00046189, Avg batch loss: 0.5881, Avg batch acc: 0.3852
Train, Epoch: 1, Batch: 662, Step num: 662, Learning rate: 0.00046259, Avg batch loss: 0.6456, Avg batch acc: 0.3901
Train, Epoch: 1, Batch: 663, Step num: 663, Learning rate: 0.00046329, Avg batch loss: 0.5974, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 664, Step num: 664, Learning rate: 0.00046398, Avg batch loss: 0.6734, Avg batch acc: 0.3572
Train, Epoch: 1, Batch: 665, Step num: 665, Learning rate: 0.00046468, Avg batch loss: 0.6567, Avg batch acc: 0.3876
Train, Epoch: 1, Batch: 666, Step num: 666, Learning rate: 0.00046538, Avg batch loss: 0.6060, Avg batch acc: 0.3799
Train, Epoch: 1, Batch: 667, Step num: 667, Learning rate: 0.00046608, Avg batch loss: 0.6100, Avg batch acc: 0.4018
Train, Epoch: 1, Batch: 668, Step num: 668, Learning rate: 0.00046678, Avg batch loss: 0.5854, Avg batch acc: 0.4137
Train, Epoch: 1, Batch: 669, Step num: 669, Learning rate: 0.00046748, Avg batch loss: 0.6486, Avg batch acc: 0.3736
Train, Epoch: 1, Batch: 670, Step num: 670, Learning rate: 0.00046818, Avg batch loss: 0.6912, Avg batch acc: 0.3696
Train, Epoch: 1, Batch: 671, Step num: 671, Learning rate: 0.00046888, Avg batch loss: 0.6693, Avg batch acc: 0.3763
Train, Epoch: 1, Batch: 672, Step num: 672, Learning rate: 0.00046957, Avg batch loss: 0.6534, Avg batch acc: 0.3962
Train, Epoch: 1, Batch: 673, Step num: 673, Learning rate: 0.00047027, Avg batch loss: 0.7065, Avg batch acc: 0.3737
Train, Epoch: 1, Batch: 674, Step num: 674, Learning rate: 0.00047097, Avg batch loss: 0.6286, Avg batch acc: 0.3743
Train, Epoch: 1, Batch: 675, Step num: 675, Learning rate: 0.00047167, Avg batch loss: 0.6792, Avg batch acc: 0.3724
Train, Epoch: 1, Batch: 676, Step num: 676, Learning rate: 0.00047237, Avg batch loss: 0.6184, Avg batch acc: 0.3919
Train, Epoch: 1, Batch: 677, Step num: 677, Learning rate: 0.00047307, Avg batch loss: 0.6875, Avg batch acc: 0.3671
Train, Epoch: 1, Batch: 678, Step num: 678, Learning rate: 0.00047377, Avg batch loss: 0.6571, Avg batch acc: 0.3641
Train, Epoch: 1, Batch: 679, Step num: 679, Learning rate: 0.00047447, Avg batch loss: 0.6381, Avg batch acc: 0.3807
Train, Epoch: 1, Batch: 680, Step num: 680, Learning rate: 0.00047516, Avg batch loss: 0.6558, Avg batch acc: 0.3984
Train, Epoch: 1, Batch: 681, Step num: 681, Learning rate: 0.00047586, Avg batch loss: 0.6641, Avg batch acc: 0.3521
Train, Epoch: 1, Batch: 682, Step num: 682, Learning rate: 0.00047656, Avg batch loss: 0.6320, Avg batch acc: 0.3786
Train, Epoch: 1, Batch: 683, Step num: 683, Learning rate: 0.00047726, Avg batch loss: 0.6355, Avg batch acc: 0.3747
Train, Epoch: 1, Batch: 684, Step num: 684, Learning rate: 0.00047796, Avg batch loss: 0.5966, Avg batch acc: 0.4006
Train, Epoch: 1, Batch: 685, Step num: 685, Learning rate: 0.00047866, Avg batch loss: 0.6043, Avg batch acc: 0.4093
Train, Epoch: 1, Batch: 686, Step num: 686, Learning rate: 0.00047936, Avg batch loss: 0.5847, Avg batch acc: 0.4022
Train, Epoch: 1, Batch: 687, Step num: 687, Learning rate: 0.00048006, Avg batch loss: 0.6203, Avg batch acc: 0.3545
Train, Epoch: 1, Batch: 688, Step num: 688, Learning rate: 0.00048075, Avg batch loss: 0.5875, Avg batch acc: 0.3804
Train, Epoch: 1, Batch: 689, Step num: 689, Learning rate: 0.00048145, Avg batch loss: 0.6465, Avg batch acc: 0.3962
Train, Epoch: 1, Batch: 690, Step num: 690, Learning rate: 0.00048215, Avg batch loss: 0.7274, Avg batch acc: 0.3687
Train, Epoch: 1, Batch: 691, Step num: 691, Learning rate: 0.00048285, Avg batch loss: 0.6431, Avg batch acc: 0.4029
Train, Epoch: 1, Batch: 692, Step num: 692, Learning rate: 0.00048355, Avg batch loss: 0.6365, Avg batch acc: 0.3799
Train, Epoch: 1, Batch: 693, Step num: 693, Learning rate: 0.00048425, Avg batch loss: 0.7064, Avg batch acc: 0.3722
Train, Epoch: 1, Batch: 694, Step num: 694, Learning rate: 0.00048495, Avg batch loss: 0.6386, Avg batch acc: 0.3853
Train, Epoch: 1, Batch: 695, Step num: 695, Learning rate: 0.00048565, Avg batch loss: 0.7012, Avg batch acc: 0.3695
Train, Epoch: 1, Batch: 696, Step num: 696, Learning rate: 0.00048634, Avg batch loss: 0.6386, Avg batch acc: 0.3925
Train, Epoch: 1, Batch: 697, Step num: 697, Learning rate: 0.00048704, Avg batch loss: 0.6753, Avg batch acc: 0.3759
Train, Epoch: 1, Batch: 698, Step num: 698, Learning rate: 0.00048774, Avg batch loss: 0.6164, Avg batch acc: 0.3990
Train, Epoch: 1, Batch: 699, Step num: 699, Learning rate: 0.00048844, Avg batch loss: 0.6414, Avg batch acc: 0.3801
Train, Epoch: 1, Batch: 700, Step num: 700, Learning rate: 0.00048914, Avg batch loss: 0.6093, Avg batch acc: 0.3743
Train, Epoch: 1, Batch: 701, Step num: 701, Learning rate: 0.00048984, Avg batch loss: 0.6723, Avg batch acc: 0.3710
Train, Epoch: 1, Batch: 702, Step num: 702, Learning rate: 0.00049054, Avg batch loss: 0.6842, Avg batch acc: 0.3502
Train, Epoch: 1, Batch: 703, Step num: 703, Learning rate: 0.00049124, Avg batch loss: 0.6349, Avg batch acc: 0.3800
Train, Epoch: 1, Batch: 704, Step num: 704, Learning rate: 0.00049193, Avg batch loss: 0.6837, Avg batch acc: 0.3810
Train, Epoch: 1, Batch: 705, Step num: 705, Learning rate: 0.00049263, Avg batch loss: 0.7023, Avg batch acc: 0.3637
Train, Epoch: 1, Batch: 706, Step num: 706, Learning rate: 0.00049333, Avg batch loss: 0.7067, Avg batch acc: 0.3730
Train, Epoch: 1, Batch: 707, Step num: 707, Learning rate: 0.00049403, Avg batch loss: 0.7102, Avg batch acc: 0.3828
Train, Epoch: 1, Batch: 708, Step num: 708, Learning rate: 0.00049473, Avg batch loss: 0.7043, Avg batch acc: 0.3953
Train, Epoch: 1, Batch: 709, Step num: 709, Learning rate: 0.00049543, Avg batch loss: 0.6636, Avg batch acc: 0.3810
Train, Epoch: 1, Batch: 710, Step num: 710, Learning rate: 0.00049613, Avg batch loss: 0.6096, Avg batch acc: 0.3797
Train, Epoch: 1, Batch: 711, Step num: 711, Learning rate: 0.00049683, Avg batch loss: 0.6725, Avg batch acc: 0.3754
Train, Epoch: 1, Batch: 712, Step num: 712, Learning rate: 0.00049753, Avg batch loss: 0.6353, Avg batch acc: 0.4071
Train, Epoch: 1, Batch: 713, Step num: 713, Learning rate: 0.00049822, Avg batch loss: 0.6756, Avg batch acc: 0.3740
Train, Epoch: 1, Batch: 714, Step num: 714, Learning rate: 0.00049892, Avg batch loss: 0.5914, Avg batch acc: 0.3973
Train, Epoch: 1, Batch: 715, Step num: 715, Learning rate: 0.00049962, Avg batch loss: 0.6740, Avg batch acc: 0.3741
Train, Epoch: 1, Batch: 716, Step num: 716, Learning rate: 0.00050032, Avg batch loss: 0.6086, Avg batch acc: 0.3617
Train, Epoch: 1, Batch: 717, Step num: 717, Learning rate: 0.00050102, Avg batch loss: 0.7032, Avg batch acc: 0.3621
Train, Epoch: 1, Batch: 718, Step num: 718, Learning rate: 0.00050172, Avg batch loss: 0.7021, Avg batch acc: 0.3746
Train, Epoch: 1, Batch: 719, Step num: 719, Learning rate: 0.00050242, Avg batch loss: 0.6031, Avg batch acc: 0.3897
Train, Epoch: 1, Batch: 720, Step num: 720, Learning rate: 0.00050312, Avg batch loss: 0.6713, Avg batch acc: 0.3763
Train, Epoch: 1, Batch: 721, Step num: 721, Learning rate: 0.00050381, Avg batch loss: 0.6291, Avg batch acc: 0.3806
Train, Epoch: 1, Batch: 722, Step num: 722, Learning rate: 0.00050451, Avg batch loss: 0.6359, Avg batch acc: 0.3720
Train, Epoch: 1, Batch: 723, Step num: 723, Learning rate: 0.00050521, Avg batch loss: 0.6205, Avg batch acc: 0.3868
Train, Epoch: 1, Batch: 724, Step num: 724, Learning rate: 0.00050591, Avg batch loss: 0.6899, Avg batch acc: 0.3696
Train, Epoch: 1, Batch: 725, Step num: 725, Learning rate: 0.00050661, Avg batch loss: 0.5983, Avg batch acc: 0.4118
Train, Epoch: 1, Batch: 726, Step num: 726, Learning rate: 0.00050731, Avg batch loss: 0.6476, Avg batch acc: 0.3803
Train, Epoch: 1, Batch: 727, Step num: 727, Learning rate: 0.00050801, Avg batch loss: 0.6584, Avg batch acc: 0.3673
Train, Epoch: 1, Batch: 728, Step num: 728, Learning rate: 0.00050871, Avg batch loss: 0.6172, Avg batch acc: 0.3889
Train, Epoch: 1, Batch: 729, Step num: 729, Learning rate: 0.00050940, Avg batch loss: 0.6042, Avg batch acc: 0.3786
Train, Epoch: 1, Batch: 730, Step num: 730, Learning rate: 0.00051010, Avg batch loss: 0.6483, Avg batch acc: 0.3977
Train, Epoch: 1, Batch: 731, Step num: 731, Learning rate: 0.00051080, Avg batch loss: 0.7259, Avg batch acc: 0.3755
Train, Epoch: 1, Batch: 732, Step num: 732, Learning rate: 0.00051150, Avg batch loss: 0.6333, Avg batch acc: 0.3917
Train, Epoch: 1, Batch: 733, Step num: 733, Learning rate: 0.00051220, Avg batch loss: 0.6275, Avg batch acc: 0.3860
Train, Epoch: 1, Batch: 734, Step num: 734, Learning rate: 0.00051290, Avg batch loss: 0.6146, Avg batch acc: 0.3868
Train, Epoch: 1, Batch: 735, Step num: 735, Learning rate: 0.00051360, Avg batch loss: 0.6469, Avg batch acc: 0.4110
Train, Epoch: 1, Batch: 736, Step num: 736, Learning rate: 0.00051430, Avg batch loss: 0.6206, Avg batch acc: 0.3835
Train, Epoch: 1, Batch: 737, Step num: 737, Learning rate: 0.00051499, Avg batch loss: 0.6650, Avg batch acc: 0.3896
Train, Epoch: 1, Batch: 738, Step num: 738, Learning rate: 0.00051569, Avg batch loss: 0.6005, Avg batch acc: 0.3709
Train, Epoch: 1, Batch: 739, Step num: 739, Learning rate: 0.00051639, Avg batch loss: 0.6098, Avg batch acc: 0.3818
Train, Epoch: 1, Batch: 740, Step num: 740, Learning rate: 0.00051709, Avg batch loss: 0.6936, Avg batch acc: 0.3872
Train, Epoch: 1, Batch: 741, Step num: 741, Learning rate: 0.00051779, Avg batch loss: 0.6290, Avg batch acc: 0.3855
Train, Epoch: 1, Batch: 742, Step num: 742, Learning rate: 0.00051849, Avg batch loss: 0.6197, Avg batch acc: 0.3744
Train, Epoch: 1, Batch: 743, Step num: 743, Learning rate: 0.00051919, Avg batch loss: 0.7041, Avg batch acc: 0.3768
Train, Epoch: 1, Batch: 744, Step num: 744, Learning rate: 0.00051989, Avg batch loss: 0.6399, Avg batch acc: 0.3852
Train, Epoch: 1, Batch: 745, Step num: 745, Learning rate: 0.00052058, Avg batch loss: 0.6063, Avg batch acc: 0.3995
Train, Epoch: 1, Batch: 746, Step num: 746, Learning rate: 0.00052128, Avg batch loss: 0.6645, Avg batch acc: 0.3888
Train, Epoch: 1, Batch: 747, Step num: 747, Learning rate: 0.00052198, Avg batch loss: 0.6710, Avg batch acc: 0.3636
Train, Epoch: 1, Batch: 748, Step num: 748, Learning rate: 0.00052268, Avg batch loss: 0.6494, Avg batch acc: 0.3821
Train, Epoch: 1, Batch: 749, Step num: 749, Learning rate: 0.00052338, Avg batch loss: 0.5691, Avg batch acc: 0.4077
Train, Epoch: 1, Batch: 750, Step num: 750, Learning rate: 0.00052408, Avg batch loss: 0.6227, Avg batch acc: 0.3909
Train, Epoch: 1, Batch: 751, Step num: 751, Learning rate: 0.00052478, Avg batch loss: 0.5679, Avg batch acc: 0.4038
Train, Epoch: 1, Batch: 752, Step num: 752, Learning rate: 0.00052548, Avg batch loss: 0.6227, Avg batch acc: 0.3519
Train, Epoch: 1, Batch: 753, Step num: 753, Learning rate: 0.00052617, Avg batch loss: 0.6540, Avg batch acc: 0.3688
Train, Epoch: 1, Batch: 754, Step num: 754, Learning rate: 0.00052687, Avg batch loss: 0.6110, Avg batch acc: 0.3662
Train, Epoch: 1, Batch: 755, Step num: 755, Learning rate: 0.00052757, Avg batch loss: 0.6549, Avg batch acc: 0.3716
Train, Epoch: 1, Batch: 756, Step num: 756, Learning rate: 0.00052827, Avg batch loss: 0.6277, Avg batch acc: 0.3857
Train, Epoch: 1, Batch: 757, Step num: 757, Learning rate: 0.00052897, Avg batch loss: 0.6090, Avg batch acc: 0.3572
Train, Epoch: 1, Batch: 758, Step num: 758, Learning rate: 0.00052967, Avg batch loss: 0.6143, Avg batch acc: 0.3712
Train, Epoch: 1, Batch: 759, Step num: 759, Learning rate: 0.00053037, Avg batch loss: 0.6713, Avg batch acc: 0.3881
Train, Epoch: 1, Batch: 760, Step num: 760, Learning rate: 0.00053107, Avg batch loss: 0.7241, Avg batch acc: 0.3530
Train, Epoch: 1, Batch: 761, Step num: 761, Learning rate: 0.00053176, Avg batch loss: 0.5763, Avg batch acc: 0.4120
Train, Epoch: 1, Batch: 762, Step num: 762, Learning rate: 0.00053246, Avg batch loss: 0.6246, Avg batch acc: 0.3690
Train, Epoch: 1, Batch: 763, Step num: 763, Learning rate: 0.00053316, Avg batch loss: 0.6845, Avg batch acc: 0.3727
Train, Epoch: 1, Batch: 764, Step num: 764, Learning rate: 0.00053386, Avg batch loss: 0.6437, Avg batch acc: 0.3886
Train, Epoch: 1, Batch: 765, Step num: 765, Learning rate: 0.00053456, Avg batch loss: 0.6689, Avg batch acc: 0.3791
Train, Epoch: 1, Batch: 766, Step num: 766, Learning rate: 0.00053526, Avg batch loss: 0.6356, Avg batch acc: 0.3869
Train, Epoch: 1, Batch: 767, Step num: 767, Learning rate: 0.00053596, Avg batch loss: 0.5991, Avg batch acc: 0.3912
Train, Epoch: 1, Batch: 768, Step num: 768, Learning rate: 0.00053666, Avg batch loss: 0.6669, Avg batch acc: 0.3860
Train, Epoch: 1, Batch: 769, Step num: 769, Learning rate: 0.00053736, Avg batch loss: 0.6127, Avg batch acc: 0.3776
Train, Epoch: 1, Batch: 770, Step num: 770, Learning rate: 0.00053805, Avg batch loss: 0.5993, Avg batch acc: 0.4073
Train, Epoch: 1, Batch: 771, Step num: 771, Learning rate: 0.00053875, Avg batch loss: 0.6480, Avg batch acc: 0.3670
Train, Epoch: 1, Batch: 772, Step num: 772, Learning rate: 0.00053945, Avg batch loss: 0.6899, Avg batch acc: 0.3916
Train, Epoch: 1, Batch: 773, Step num: 773, Learning rate: 0.00054015, Avg batch loss: 0.5902, Avg batch acc: 0.3797
Train, Epoch: 1, Batch: 774, Step num: 774, Learning rate: 0.00054085, Avg batch loss: 0.5568, Avg batch acc: 0.3920
Train, Epoch: 1, Batch: 775, Step num: 775, Learning rate: 0.00054155, Avg batch loss: 0.6158, Avg batch acc: 0.3897
Train, Epoch: 1, Batch: 776, Step num: 776, Learning rate: 0.00054225, Avg batch loss: 0.6084, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 777, Step num: 777, Learning rate: 0.00054295, Avg batch loss: 0.6244, Avg batch acc: 0.4097
Train, Epoch: 1, Batch: 778, Step num: 778, Learning rate: 0.00054364, Avg batch loss: 0.6420, Avg batch acc: 0.3916
Train, Epoch: 1, Batch: 779, Step num: 779, Learning rate: 0.00054434, Avg batch loss: 0.6004, Avg batch acc: 0.3813
Train, Epoch: 1, Batch: 780, Step num: 780, Learning rate: 0.00054504, Avg batch loss: 0.6193, Avg batch acc: 0.4026
Train, Epoch: 1, Batch: 781, Step num: 781, Learning rate: 0.00054574, Avg batch loss: 0.6291, Avg batch acc: 0.3684
Train, Epoch: 1, Batch: 782, Step num: 782, Learning rate: 0.00054644, Avg batch loss: 0.6941, Avg batch acc: 0.3832
Train, Epoch: 1, Batch: 783, Step num: 783, Learning rate: 0.00054714, Avg batch loss: 0.6666, Avg batch acc: 0.3712
Train, Epoch: 1, Batch: 784, Step num: 784, Learning rate: 0.00054784, Avg batch loss: 0.5627, Avg batch acc: 0.3902
Train, Epoch: 1, Batch: 785, Step num: 785, Learning rate: 0.00054854, Avg batch loss: 0.6252, Avg batch acc: 0.3860
Train, Epoch: 1, Batch: 786, Step num: 786, Learning rate: 0.00054923, Avg batch loss: 0.6410, Avg batch acc: 0.3940
Train, Epoch: 1, Batch: 787, Step num: 787, Learning rate: 0.00054993, Avg batch loss: 0.6502, Avg batch acc: 0.4020
Train, Epoch: 1, Batch: 788, Step num: 788, Learning rate: 0.00055063, Avg batch loss: 0.5414, Avg batch acc: 0.4089
Train, Epoch: 1, Batch: 789, Step num: 789, Learning rate: 0.00055133, Avg batch loss: 0.6527, Avg batch acc: 0.3820
Train, Epoch: 1, Batch: 790, Step num: 790, Learning rate: 0.00055203, Avg batch loss: 0.6597, Avg batch acc: 0.3810
Train, Epoch: 1, Batch: 791, Step num: 791, Learning rate: 0.00055273, Avg batch loss: 0.5970, Avg batch acc: 0.3945
Train, Epoch: 1, Batch: 792, Step num: 792, Learning rate: 0.00055343, Avg batch loss: 0.6393, Avg batch acc: 0.3982
Train, Epoch: 1, Batch: 793, Step num: 793, Learning rate: 0.00055413, Avg batch loss: 0.6306, Avg batch acc: 0.3640
Train, Epoch: 1, Batch: 794, Step num: 794, Learning rate: 0.00055482, Avg batch loss: 0.6188, Avg batch acc: 0.3969
Train, Epoch: 1, Batch: 795, Step num: 795, Learning rate: 0.00055552, Avg batch loss: 0.5702, Avg batch acc: 0.3936
Train, Epoch: 1, Batch: 796, Step num: 796, Learning rate: 0.00055622, Avg batch loss: 0.6163, Avg batch acc: 0.4047
Train, Epoch: 1, Batch: 797, Step num: 797, Learning rate: 0.00055692, Avg batch loss: 0.5583, Avg batch acc: 0.4231
Train, Epoch: 1, Batch: 798, Step num: 798, Learning rate: 0.00055762, Avg batch loss: 0.5720, Avg batch acc: 0.3973
Train, Epoch: 1, Batch: 799, Step num: 799, Learning rate: 0.00055832, Avg batch loss: 0.6853, Avg batch acc: 0.3775
Train, Epoch: 1, Batch: 800, Step num: 800, Learning rate: 0.00055902, Avg batch loss: 0.6316, Avg batch acc: 0.3936
Train, Epoch: 1, Batch: 801, Step num: 801, Learning rate: 0.00055972, Avg batch loss: 0.5853, Avg batch acc: 0.4083
Train, Epoch: 1, Batch: 802, Step num: 802, Learning rate: 0.00056041, Avg batch loss: 0.6065, Avg batch acc: 0.3906
Train, Epoch: 1, Batch: 803, Step num: 803, Learning rate: 0.00056111, Avg batch loss: 0.7025, Avg batch acc: 0.3668
Train, Epoch: 1, Batch: 804, Step num: 804, Learning rate: 0.00056181, Avg batch loss: 0.6513, Avg batch acc: 0.3955
Train, Epoch: 1, Batch: 805, Step num: 805, Learning rate: 0.00056251, Avg batch loss: 0.6151, Avg batch acc: 0.3918
Train, Epoch: 1, Batch: 806, Step num: 806, Learning rate: 0.00056321, Avg batch loss: 0.5598, Avg batch acc: 0.4181
Train, Epoch: 1, Batch: 807, Step num: 807, Learning rate: 0.00056391, Avg batch loss: 0.6233, Avg batch acc: 0.3907
Train, Epoch: 1, Batch: 808, Step num: 808, Learning rate: 0.00056461, Avg batch loss: 0.5957, Avg batch acc: 0.3846
Train, Epoch: 1, Batch: 809, Step num: 809, Learning rate: 0.00056531, Avg batch loss: 0.5942, Avg batch acc: 0.3888
Train, Epoch: 1, Batch: 810, Step num: 810, Learning rate: 0.00056600, Avg batch loss: 0.6313, Avg batch acc: 0.3800
Train, Epoch: 1, Batch: 811, Step num: 811, Learning rate: 0.00056670, Avg batch loss: 0.6599, Avg batch acc: 0.3892
Train, Epoch: 1, Batch: 812, Step num: 812, Learning rate: 0.00056740, Avg batch loss: 0.6339, Avg batch acc: 0.3871
Train, Epoch: 1, Batch: 813, Step num: 813, Learning rate: 0.00056810, Avg batch loss: 0.6333, Avg batch acc: 0.3715
Train, Epoch: 1, Batch: 814, Step num: 814, Learning rate: 0.00056880, Avg batch loss: 0.6042, Avg batch acc: 0.3852
Train, Epoch: 1, Batch: 815, Step num: 815, Learning rate: 0.00056950, Avg batch loss: 0.6654, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 816, Step num: 816, Learning rate: 0.00057020, Avg batch loss: 0.6218, Avg batch acc: 0.4031
Train, Epoch: 1, Batch: 817, Step num: 817, Learning rate: 0.00057090, Avg batch loss: 0.6073, Avg batch acc: 0.4136
Train, Epoch: 1, Batch: 818, Step num: 818, Learning rate: 0.00057159, Avg batch loss: 0.5982, Avg batch acc: 0.3848
Train, Epoch: 1, Batch: 819, Step num: 819, Learning rate: 0.00057229, Avg batch loss: 0.5810, Avg batch acc: 0.3900
Train, Epoch: 1, Batch: 820, Step num: 820, Learning rate: 0.00057299, Avg batch loss: 0.6056, Avg batch acc: 0.3919
Train, Epoch: 1, Batch: 821, Step num: 821, Learning rate: 0.00057369, Avg batch loss: 0.6260, Avg batch acc: 0.3874
Train, Epoch: 1, Batch: 822, Step num: 822, Learning rate: 0.00057439, Avg batch loss: 0.6250, Avg batch acc: 0.3790
Train, Epoch: 1, Batch: 823, Step num: 823, Learning rate: 0.00057509, Avg batch loss: 0.6583, Avg batch acc: 0.3753
Train, Epoch: 1, Batch: 824, Step num: 824, Learning rate: 0.00057579, Avg batch loss: 0.6174, Avg batch acc: 0.3709
Train, Epoch: 1, Batch: 825, Step num: 825, Learning rate: 0.00057649, Avg batch loss: 0.5807, Avg batch acc: 0.4282
Train, Epoch: 1, Batch: 826, Step num: 826, Learning rate: 0.00057719, Avg batch loss: 0.5939, Avg batch acc: 0.3893
Train, Epoch: 1, Batch: 827, Step num: 827, Learning rate: 0.00057788, Avg batch loss: 0.5816, Avg batch acc: 0.4034
Train, Epoch: 1, Batch: 828, Step num: 828, Learning rate: 0.00057858, Avg batch loss: 0.5823, Avg batch acc: 0.3904
Train, Epoch: 1, Batch: 829, Step num: 829, Learning rate: 0.00057928, Avg batch loss: 0.6191, Avg batch acc: 0.3968
Train, Epoch: 1, Batch: 830, Step num: 830, Learning rate: 0.00057998, Avg batch loss: 0.5974, Avg batch acc: 0.4098
Train, Epoch: 1, Batch: 831, Step num: 831, Learning rate: 0.00058068, Avg batch loss: 0.5502, Avg batch acc: 0.4208
Train, Epoch: 1, Batch: 832, Step num: 832, Learning rate: 0.00058138, Avg batch loss: 0.6340, Avg batch acc: 0.4039
Train, Epoch: 1, Batch: 833, Step num: 833, Learning rate: 0.00058208, Avg batch loss: 0.6390, Avg batch acc: 0.3889
Train, Epoch: 1, Batch: 834, Step num: 834, Learning rate: 0.00058278, Avg batch loss: 0.6189, Avg batch acc: 0.3880
Train, Epoch: 1, Batch: 835, Step num: 835, Learning rate: 0.00058347, Avg batch loss: 0.5996, Avg batch acc: 0.4031
Train, Epoch: 1, Batch: 836, Step num: 836, Learning rate: 0.00058417, Avg batch loss: 0.6024, Avg batch acc: 0.3736
Train, Epoch: 1, Batch: 837, Step num: 837, Learning rate: 0.00058487, Avg batch loss: 0.6496, Avg batch acc: 0.3930
Train, Epoch: 1, Batch: 838, Step num: 838, Learning rate: 0.00058557, Avg batch loss: 0.6098, Avg batch acc: 0.3916
Train, Epoch: 1, Batch: 839, Step num: 839, Learning rate: 0.00058627, Avg batch loss: 0.5741, Avg batch acc: 0.3714
Train, Epoch: 1, Batch: 840, Step num: 840, Learning rate: 0.00058697, Avg batch loss: 0.6495, Avg batch acc: 0.3954
Train, Epoch: 1, Batch: 841, Step num: 841, Learning rate: 0.00058767, Avg batch loss: 0.6890, Avg batch acc: 0.3536
Train, Epoch: 1, Batch: 842, Step num: 842, Learning rate: 0.00058837, Avg batch loss: 0.6595, Avg batch acc: 0.4020
Train, Epoch: 1, Batch: 843, Step num: 843, Learning rate: 0.00058906, Avg batch loss: 0.6632, Avg batch acc: 0.3967
Train, Epoch: 1, Batch: 844, Step num: 844, Learning rate: 0.00058976, Avg batch loss: 0.6072, Avg batch acc: 0.4077
Train, Epoch: 1, Batch: 845, Step num: 845, Learning rate: 0.00059046, Avg batch loss: 0.6702, Avg batch acc: 0.4009
Train, Epoch: 1, Batch: 846, Step num: 846, Learning rate: 0.00059116, Avg batch loss: 0.6525, Avg batch acc: 0.3708
Train, Epoch: 1, Batch: 847, Step num: 847, Learning rate: 0.00059186, Avg batch loss: 0.5906, Avg batch acc: 0.3685
Train, Epoch: 1, Batch: 848, Step num: 848, Learning rate: 0.00059256, Avg batch loss: 0.6389, Avg batch acc: 0.3945
Train, Epoch: 1, Batch: 849, Step num: 849, Learning rate: 0.00059326, Avg batch loss: 0.6750, Avg batch acc: 0.3709
Train, Epoch: 1, Batch: 850, Step num: 850, Learning rate: 0.00059396, Avg batch loss: 0.5795, Avg batch acc: 0.3998
Train, Epoch: 1, Batch: 851, Step num: 851, Learning rate: 0.00059465, Avg batch loss: 0.5920, Avg batch acc: 0.4131
Train, Epoch: 1, Batch: 852, Step num: 852, Learning rate: 0.00059535, Avg batch loss: 0.6071, Avg batch acc: 0.3987
Train, Epoch: 1, Batch: 853, Step num: 853, Learning rate: 0.00059605, Avg batch loss: 0.6167, Avg batch acc: 0.3980
Train, Epoch: 1, Batch: 854, Step num: 854, Learning rate: 0.00059675, Avg batch loss: 0.6491, Avg batch acc: 0.3954
Train, Epoch: 1, Batch: 855, Step num: 855, Learning rate: 0.00059745, Avg batch loss: 0.5823, Avg batch acc: 0.3836
Train, Epoch: 1, Batch: 856, Step num: 856, Learning rate: 0.00059815, Avg batch loss: 0.6489, Avg batch acc: 0.3909
Train, Epoch: 1, Batch: 857, Step num: 857, Learning rate: 0.00059885, Avg batch loss: 0.6473, Avg batch acc: 0.4012
Train, Epoch: 1, Batch: 858, Step num: 858, Learning rate: 0.00059955, Avg batch loss: 0.5849, Avg batch acc: 0.3814
Train, Epoch: 1, Batch: 859, Step num: 859, Learning rate: 0.00060024, Avg batch loss: 0.6738, Avg batch acc: 0.3845
Train, Epoch: 1, Batch: 860, Step num: 860, Learning rate: 0.00060094, Avg batch loss: 0.6307, Avg batch acc: 0.3933
Train, Epoch: 1, Batch: 861, Step num: 861, Learning rate: 0.00060164, Avg batch loss: 0.5771, Avg batch acc: 0.4046
Train, Epoch: 1, Batch: 862, Step num: 862, Learning rate: 0.00060234, Avg batch loss: 0.6910, Avg batch acc: 0.3964
Train, Epoch: 1, Batch: 863, Step num: 863, Learning rate: 0.00060304, Avg batch loss: 0.5635, Avg batch acc: 0.4020
Train, Epoch: 1, Batch: 864, Step num: 864, Learning rate: 0.00060374, Avg batch loss: 0.5963, Avg batch acc: 0.3773
Train, Epoch: 1, Batch: 865, Step num: 865, Learning rate: 0.00060444, Avg batch loss: 0.5697, Avg batch acc: 0.3996
Train, Epoch: 1, Batch: 866, Step num: 866, Learning rate: 0.00060514, Avg batch loss: 0.6306, Avg batch acc: 0.3969
Train, Epoch: 1, Batch: 867, Step num: 867, Learning rate: 0.00060583, Avg batch loss: 0.6318, Avg batch acc: 0.4003
Train, Epoch: 1, Batch: 868, Step num: 868, Learning rate: 0.00060653, Avg batch loss: 0.6159, Avg batch acc: 0.4091
Train, Epoch: 1, Batch: 869, Step num: 869, Learning rate: 0.00060723, Avg batch loss: 0.6245, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 870, Step num: 870, Learning rate: 0.00060793, Avg batch loss: 0.6427, Avg batch acc: 0.3836
Train, Epoch: 1, Batch: 871, Step num: 871, Learning rate: 0.00060863, Avg batch loss: 0.6339, Avg batch acc: 0.3741
Train, Epoch: 1, Batch: 872, Step num: 872, Learning rate: 0.00060933, Avg batch loss: 0.6004, Avg batch acc: 0.3922
Train, Epoch: 1, Batch: 873, Step num: 873, Learning rate: 0.00061003, Avg batch loss: 0.6284, Avg batch acc: 0.3802
Train, Epoch: 1, Batch: 874, Step num: 874, Learning rate: 0.00061073, Avg batch loss: 0.6769, Avg batch acc: 0.3883
Train, Epoch: 1, Batch: 875, Step num: 875, Learning rate: 0.00061142, Avg batch loss: 0.5868, Avg batch acc: 0.3901
Train, Epoch: 1, Batch: 876, Step num: 876, Learning rate: 0.00061212, Avg batch loss: 0.6049, Avg batch acc: 0.3979
Train, Epoch: 1, Batch: 877, Step num: 877, Learning rate: 0.00061282, Avg batch loss: 0.6042, Avg batch acc: 0.4031
Train, Epoch: 1, Batch: 878, Step num: 878, Learning rate: 0.00061352, Avg batch loss: 0.6150, Avg batch acc: 0.4145
Train, Epoch: 1, Batch: 879, Step num: 879, Learning rate: 0.00061422, Avg batch loss: 0.6099, Avg batch acc: 0.4094
Train, Epoch: 1, Batch: 880, Step num: 880, Learning rate: 0.00061492, Avg batch loss: 0.6209, Avg batch acc: 0.3969
Train, Epoch: 1, Batch: 881, Step num: 881, Learning rate: 0.00061562, Avg batch loss: 0.6222, Avg batch acc: 0.3891
Train, Epoch: 1, Batch: 882, Step num: 882, Learning rate: 0.00061632, Avg batch loss: 0.5694, Avg batch acc: 0.4054
Train, Epoch: 1, Batch: 883, Step num: 883, Learning rate: 0.00061702, Avg batch loss: 0.5852, Avg batch acc: 0.4144
Train, Epoch: 1, Batch: 884, Step num: 884, Learning rate: 0.00061771, Avg batch loss: 0.5976, Avg batch acc: 0.3981
Train, Epoch: 1, Batch: 885, Step num: 885, Learning rate: 0.00061841, Avg batch loss: 0.6052, Avg batch acc: 0.4135
Train, Epoch: 1, Batch: 886, Step num: 886, Learning rate: 0.00061911, Avg batch loss: 0.6057, Avg batch acc: 0.4178
Train, Epoch: 1, Batch: 887, Step num: 887, Learning rate: 0.00061981, Avg batch loss: 0.5994, Avg batch acc: 0.4136
Train, Epoch: 1, Batch: 888, Step num: 888, Learning rate: 0.00062051, Avg batch loss: 0.6386, Avg batch acc: 0.3704
Train, Epoch: 1, Batch: 889, Step num: 889, Learning rate: 0.00062121, Avg batch loss: 0.5949, Avg batch acc: 0.3967
Train, Epoch: 1, Batch: 890, Step num: 890, Learning rate: 0.00062191, Avg batch loss: 0.6020, Avg batch acc: 0.4252
Train, Epoch: 1, Batch: 891, Step num: 891, Learning rate: 0.00062261, Avg batch loss: 0.6212, Avg batch acc: 0.3764
Train, Epoch: 1, Batch: 892, Step num: 892, Learning rate: 0.00062330, Avg batch loss: 0.5951, Avg batch acc: 0.4016
Train, Epoch: 1, Batch: 893, Step num: 893, Learning rate: 0.00062400, Avg batch loss: 0.6047, Avg batch acc: 0.4165
Train, Epoch: 1, Batch: 894, Step num: 894, Learning rate: 0.00062470, Avg batch loss: 0.5916, Avg batch acc: 0.3963
Train, Epoch: 1, Batch: 895, Step num: 895, Learning rate: 0.00062540, Avg batch loss: 0.6093, Avg batch acc: 0.3908
Train, Epoch: 1, Batch: 896, Step num: 896, Learning rate: 0.00062610, Avg batch loss: 0.5644, Avg batch acc: 0.4123
Train, Epoch: 1, Batch: 897, Step num: 897, Learning rate: 0.00062680, Avg batch loss: 0.5851, Avg batch acc: 0.4027
Train, Epoch: 1, Batch: 898, Step num: 898, Learning rate: 0.00062750, Avg batch loss: 0.5741, Avg batch acc: 0.4028
Train, Epoch: 1, Batch: 899, Step num: 899, Learning rate: 0.00062820, Avg batch loss: 0.6251, Avg batch acc: 0.3753
Train, Epoch: 1, Batch: 900, Step num: 900, Learning rate: 0.00062889, Avg batch loss: 0.6649, Avg batch acc: 0.3609
Train, Epoch: 1, Batch: 901, Step num: 901, Learning rate: 0.00062959, Avg batch loss: 0.5767, Avg batch acc: 0.4188
Train, Epoch: 1, Batch: 902, Step num: 902, Learning rate: 0.00063029, Avg batch loss: 0.5465, Avg batch acc: 0.4085
Train, Epoch: 1, Batch: 903, Step num: 903, Learning rate: 0.00063099, Avg batch loss: 0.6226, Avg batch acc: 0.3812
Train, Epoch: 1, Batch: 904, Step num: 904, Learning rate: 0.00063169, Avg batch loss: 0.5686, Avg batch acc: 0.3924
Train, Epoch: 1, Batch: 905, Step num: 905, Learning rate: 0.00063239, Avg batch loss: 0.5660, Avg batch acc: 0.4112
Train, Epoch: 1, Batch: 906, Step num: 906, Learning rate: 0.00063309, Avg batch loss: 0.5940, Avg batch acc: 0.4164
Train, Epoch: 1, Batch: 907, Step num: 907, Learning rate: 0.00063379, Avg batch loss: 0.6216, Avg batch acc: 0.4076
Train, Epoch: 1, Batch: 908, Step num: 908, Learning rate: 0.00063448, Avg batch loss: 0.5734, Avg batch acc: 0.4152
Train, Epoch: 1, Batch: 909, Step num: 909, Learning rate: 0.00063518, Avg batch loss: 0.6557, Avg batch acc: 0.3846
Train, Epoch: 1, Batch: 910, Step num: 910, Learning rate: 0.00063588, Avg batch loss: 0.6289, Avg batch acc: 0.3783
Train, Epoch: 1, Batch: 911, Step num: 911, Learning rate: 0.00063658, Avg batch loss: 0.6024, Avg batch acc: 0.3671
Train, Epoch: 1, Batch: 912, Step num: 912, Learning rate: 0.00063728, Avg batch loss: 0.6408, Avg batch acc: 0.3944
Train, Epoch: 1, Batch: 913, Step num: 913, Learning rate: 0.00063798, Avg batch loss: 0.6047, Avg batch acc: 0.4109
Train, Epoch: 1, Batch: 914, Step num: 914, Learning rate: 0.00063868, Avg batch loss: 0.6193, Avg batch acc: 0.3941
Train, Epoch: 1, Batch: 915, Step num: 915, Learning rate: 0.00063938, Avg batch loss: 0.5942, Avg batch acc: 0.3914
Train, Epoch: 1, Batch: 916, Step num: 916, Learning rate: 0.00064007, Avg batch loss: 0.6003, Avg batch acc: 0.3925
Train, Epoch: 1, Batch: 917, Step num: 917, Learning rate: 0.00064077, Avg batch loss: 0.5461, Avg batch acc: 0.3802
Train, Epoch: 1, Batch: 918, Step num: 918, Learning rate: 0.00064147, Avg batch loss: 0.6452, Avg batch acc: 0.3896
Train, Epoch: 1, Batch: 919, Step num: 919, Learning rate: 0.00064217, Avg batch loss: 0.6033, Avg batch acc: 0.4043
Train, Epoch: 1, Batch: 920, Step num: 920, Learning rate: 0.00064287, Avg batch loss: 0.6370, Avg batch acc: 0.3852
Train, Epoch: 1, Batch: 921, Step num: 921, Learning rate: 0.00064357, Avg batch loss: 0.6215, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 922, Step num: 922, Learning rate: 0.00064427, Avg batch loss: 0.6379, Avg batch acc: 0.4083
Train, Epoch: 1, Batch: 923, Step num: 923, Learning rate: 0.00064497, Avg batch loss: 0.5734, Avg batch acc: 0.4132
Train, Epoch: 1, Batch: 924, Step num: 924, Learning rate: 0.00064566, Avg batch loss: 0.6142, Avg batch acc: 0.4009
Train, Epoch: 1, Batch: 925, Step num: 925, Learning rate: 0.00064636, Avg batch loss: 0.6009, Avg batch acc: 0.4056
Train, Epoch: 1, Batch: 926, Step num: 926, Learning rate: 0.00064706, Avg batch loss: 0.6022, Avg batch acc: 0.4122
Train, Epoch: 1, Batch: 927, Step num: 927, Learning rate: 0.00064776, Avg batch loss: 0.6038, Avg batch acc: 0.3923
Train, Epoch: 1, Batch: 928, Step num: 928, Learning rate: 0.00064846, Avg batch loss: 0.6474, Avg batch acc: 0.3878
Train, Epoch: 1, Batch: 929, Step num: 929, Learning rate: 0.00064916, Avg batch loss: 0.5261, Avg batch acc: 0.4027
Train, Epoch: 1, Batch: 930, Step num: 930, Learning rate: 0.00064986, Avg batch loss: 0.6069, Avg batch acc: 0.4067
Train, Epoch: 1, Batch: 931, Step num: 931, Learning rate: 0.00065056, Avg batch loss: 0.6106, Avg batch acc: 0.4075
Train, Epoch: 1, Batch: 932, Step num: 932, Learning rate: 0.00065125, Avg batch loss: 0.6637, Avg batch acc: 0.3912
Train, Epoch: 1, Batch: 933, Step num: 933, Learning rate: 0.00065195, Avg batch loss: 0.6399, Avg batch acc: 0.3775
Train, Epoch: 1, Batch: 934, Step num: 934, Learning rate: 0.00065265, Avg batch loss: 0.5907, Avg batch acc: 0.4071
Train, Epoch: 1, Batch: 935, Step num: 935, Learning rate: 0.00065335, Avg batch loss: 0.6012, Avg batch acc: 0.4121
Train, Epoch: 1, Batch: 936, Step num: 936, Learning rate: 0.00065405, Avg batch loss: 0.5844, Avg batch acc: 0.3983
Train, Epoch: 1, Batch: 937, Step num: 937, Learning rate: 0.00065475, Avg batch loss: 0.5939, Avg batch acc: 0.4012
Train, Epoch: 1, Batch: 938, Step num: 938, Learning rate: 0.00065545, Avg batch loss: 0.5592, Avg batch acc: 0.4077
Train, Epoch: 1, Batch: 939, Step num: 939, Learning rate: 0.00065615, Avg batch loss: 0.5844, Avg batch acc: 0.4194
Train, Epoch: 1, Batch: 940, Step num: 940, Learning rate: 0.00065684, Avg batch loss: 0.6071, Avg batch acc: 0.3911
Train, Epoch: 1, Batch: 941, Step num: 941, Learning rate: 0.00065754, Avg batch loss: 0.6080, Avg batch acc: 0.4112
Train, Epoch: 1, Batch: 942, Step num: 942, Learning rate: 0.00065824, Avg batch loss: 0.5752, Avg batch acc: 0.3903
Train, Epoch: 1, Batch: 943, Step num: 943, Learning rate: 0.00065894, Avg batch loss: 0.6092, Avg batch acc: 0.3993
Train, Epoch: 1, Batch: 944, Step num: 944, Learning rate: 0.00065964, Avg batch loss: 0.6357, Avg batch acc: 0.4055
Train, Epoch: 1, Batch: 945, Step num: 945, Learning rate: 0.00066034, Avg batch loss: 0.5847, Avg batch acc: 0.4029
Train, Epoch: 1, Batch: 946, Step num: 946, Learning rate: 0.00066104, Avg batch loss: 0.6290, Avg batch acc: 0.3907
Train, Epoch: 1, Batch: 947, Step num: 947, Learning rate: 0.00066174, Avg batch loss: 0.5823, Avg batch acc: 0.4114
Train, Epoch: 1, Batch: 948, Step num: 948, Learning rate: 0.00066244, Avg batch loss: 0.6045, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 949, Step num: 949, Learning rate: 0.00066313, Avg batch loss: 0.5634, Avg batch acc: 0.4133
Train, Epoch: 1, Batch: 950, Step num: 950, Learning rate: 0.00066383, Avg batch loss: 0.6661, Avg batch acc: 0.3826
Train, Epoch: 1, Batch: 951, Step num: 951, Learning rate: 0.00066453, Avg batch loss: 0.5866, Avg batch acc: 0.4128
Train, Epoch: 1, Batch: 952, Step num: 952, Learning rate: 0.00066523, Avg batch loss: 0.5903, Avg batch acc: 0.3997
Train, Epoch: 1, Batch: 953, Step num: 953, Learning rate: 0.00066593, Avg batch loss: 0.6008, Avg batch acc: 0.4170
Train, Epoch: 1, Batch: 954, Step num: 954, Learning rate: 0.00066663, Avg batch loss: 0.6439, Avg batch acc: 0.3897
Train, Epoch: 1, Batch: 955, Step num: 955, Learning rate: 0.00066733, Avg batch loss: 0.5631, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 956, Step num: 956, Learning rate: 0.00066803, Avg batch loss: 0.5669, Avg batch acc: 0.4272
Train, Epoch: 1, Batch: 957, Step num: 957, Learning rate: 0.00066872, Avg batch loss: 0.5227, Avg batch acc: 0.4059
Train, Epoch: 1, Batch: 958, Step num: 958, Learning rate: 0.00066942, Avg batch loss: 0.5894, Avg batch acc: 0.4190
Train, Epoch: 1, Batch: 959, Step num: 959, Learning rate: 0.00067012, Avg batch loss: 0.5605, Avg batch acc: 0.3995
Train, Epoch: 1, Batch: 960, Step num: 960, Learning rate: 0.00067082, Avg batch loss: 0.6221, Avg batch acc: 0.3987
Train, Epoch: 1, Batch: 961, Step num: 961, Learning rate: 0.00067152, Avg batch loss: 0.6347, Avg batch acc: 0.3993
Train, Epoch: 1, Batch: 962, Step num: 962, Learning rate: 0.00067222, Avg batch loss: 0.6331, Avg batch acc: 0.3903
Train, Epoch: 1, Batch: 963, Step num: 963, Learning rate: 0.00067292, Avg batch loss: 0.5529, Avg batch acc: 0.4102
Train, Epoch: 1, Batch: 964, Step num: 964, Learning rate: 0.00067362, Avg batch loss: 0.5456, Avg batch acc: 0.3939
Train, Epoch: 1, Batch: 965, Step num: 965, Learning rate: 0.00067431, Avg batch loss: 0.6394, Avg batch acc: 0.3839
Train, Epoch: 1, Batch: 966, Step num: 966, Learning rate: 0.00067501, Avg batch loss: 0.5713, Avg batch acc: 0.4224
Train, Epoch: 1, Batch: 967, Step num: 967, Learning rate: 0.00067571, Avg batch loss: 0.5867, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 968, Step num: 968, Learning rate: 0.00067641, Avg batch loss: 0.5522, Avg batch acc: 0.4103
Train, Epoch: 1, Batch: 969, Step num: 969, Learning rate: 0.00067711, Avg batch loss: 0.5643, Avg batch acc: 0.4015
Train, Epoch: 1, Batch: 970, Step num: 970, Learning rate: 0.00067781, Avg batch loss: 0.6344, Avg batch acc: 0.3791
Train, Epoch: 1, Batch: 971, Step num: 971, Learning rate: 0.00067851, Avg batch loss: 0.5891, Avg batch acc: 0.4079
Train, Epoch: 1, Batch: 972, Step num: 972, Learning rate: 0.00067921, Avg batch loss: 0.6072, Avg batch acc: 0.3970
Train, Epoch: 1, Batch: 973, Step num: 973, Learning rate: 0.00067990, Avg batch loss: 0.5632, Avg batch acc: 0.4065
Train, Epoch: 1, Batch: 974, Step num: 974, Learning rate: 0.00068060, Avg batch loss: 0.5763, Avg batch acc: 0.4035
Train, Epoch: 1, Batch: 975, Step num: 975, Learning rate: 0.00068130, Avg batch loss: 0.6332, Avg batch acc: 0.4137
Train, Epoch: 1, Batch: 976, Step num: 976, Learning rate: 0.00068200, Avg batch loss: 0.6068, Avg batch acc: 0.4249
Train, Epoch: 1, Batch: 977, Step num: 977, Learning rate: 0.00068270, Avg batch loss: 0.6342, Avg batch acc: 0.3932
Train, Epoch: 1, Batch: 978, Step num: 978, Learning rate: 0.00068340, Avg batch loss: 0.6011, Avg batch acc: 0.3968
Train, Epoch: 1, Batch: 979, Step num: 979, Learning rate: 0.00068410, Avg batch loss: 0.6260, Avg batch acc: 0.3891
Train, Epoch: 1, Batch: 980, Step num: 980, Learning rate: 0.00068480, Avg batch loss: 0.6231, Avg batch acc: 0.4053
Train, Epoch: 1, Batch: 981, Step num: 981, Learning rate: 0.00068549, Avg batch loss: 0.5964, Avg batch acc: 0.4092
Train, Epoch: 1, Batch: 982, Step num: 982, Learning rate: 0.00068619, Avg batch loss: 0.5491, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 983, Step num: 983, Learning rate: 0.00068689, Avg batch loss: 0.5991, Avg batch acc: 0.3907
Train, Epoch: 1, Batch: 984, Step num: 984, Learning rate: 0.00068759, Avg batch loss: 0.5738, Avg batch acc: 0.3982
Train, Epoch: 1, Batch: 985, Step num: 985, Learning rate: 0.00068829, Avg batch loss: 0.5550, Avg batch acc: 0.4089
Train, Epoch: 1, Batch: 986, Step num: 986, Learning rate: 0.00068899, Avg batch loss: 0.5495, Avg batch acc: 0.4206
Train, Epoch: 1, Batch: 987, Step num: 987, Learning rate: 0.00068969, Avg batch loss: 0.5812, Avg batch acc: 0.4226
Train, Epoch: 1, Batch: 988, Step num: 988, Learning rate: 0.00069039, Avg batch loss: 0.6291, Avg batch acc: 0.3928
Train, Epoch: 1, Batch: 989, Step num: 989, Learning rate: 0.00069108, Avg batch loss: 0.6254, Avg batch acc: 0.3832
Train, Epoch: 1, Batch: 990, Step num: 990, Learning rate: 0.00069178, Avg batch loss: 0.6279, Avg batch acc: 0.4095
Train, Epoch: 1, Batch: 991, Step num: 991, Learning rate: 0.00069248, Avg batch loss: 0.5871, Avg batch acc: 0.4137
Train, Epoch: 1, Batch: 992, Step num: 992, Learning rate: 0.00069318, Avg batch loss: 0.6263, Avg batch acc: 0.3998
Train, Epoch: 1, Batch: 993, Step num: 993, Learning rate: 0.00069388, Avg batch loss: 0.6097, Avg batch acc: 0.4171
Train, Epoch: 1, Batch: 994, Step num: 994, Learning rate: 0.00069458, Avg batch loss: 0.5368, Avg batch acc: 0.4190
Train, Epoch: 1, Batch: 995, Step num: 995, Learning rate: 0.00069528, Avg batch loss: 0.5981, Avg batch acc: 0.3853
Train, Epoch: 1, Batch: 996, Step num: 996, Learning rate: 0.00069598, Avg batch loss: 0.5586, Avg batch acc: 0.4196
Train, Epoch: 1, Batch: 997, Step num: 997, Learning rate: 0.00069667, Avg batch loss: 0.5938, Avg batch acc: 0.3992
Train, Epoch: 1, Batch: 998, Step num: 998, Learning rate: 0.00069737, Avg batch loss: 0.6398, Avg batch acc: 0.3884
Train, Epoch: 1, Batch: 999, Step num: 999, Learning rate: 0.00069807, Avg batch loss: 0.5691, Avg batch acc: 0.4231
Train, Epoch: 1, Batch: 1000, Step num: 1000, Learning rate: 0.00069877, Avg batch loss: 0.5564, Avg batch acc: 0.4112
Train, Epoch: 1, Batch: 1001, Step num: 1001, Learning rate: 0.00069947, Avg batch loss: 0.6381, Avg batch acc: 0.3836
Train, Epoch: 1, Batch: 1002, Step num: 1002, Learning rate: 0.00070017, Avg batch loss: 0.5803, Avg batch acc: 0.4131
Train, Epoch: 1, Batch: 1003, Step num: 1003, Learning rate: 0.00070087, Avg batch loss: 0.5630, Avg batch acc: 0.4019
Train, Epoch: 1, Batch: 1004, Step num: 1004, Learning rate: 0.00070157, Avg batch loss: 0.6269, Avg batch acc: 0.4021
Train, Epoch: 1, Batch: 1005, Step num: 1005, Learning rate: 0.00070227, Avg batch loss: 0.5729, Avg batch acc: 0.3996
Train, Epoch: 1, Batch: 1006, Step num: 1006, Learning rate: 0.00070296, Avg batch loss: 0.6303, Avg batch acc: 0.3995
Train, Epoch: 1, Batch: 1007, Step num: 1007, Learning rate: 0.00070366, Avg batch loss: 0.5770, Avg batch acc: 0.3925
Train, Epoch: 1, Batch: 1008, Step num: 1008, Learning rate: 0.00070436, Avg batch loss: 0.6113, Avg batch acc: 0.3965
Train, Epoch: 1, Batch: 1009, Step num: 1009, Learning rate: 0.00070506, Avg batch loss: 0.5988, Avg batch acc: 0.4165
Train, Epoch: 1, Batch: 1010, Step num: 1010, Learning rate: 0.00070576, Avg batch loss: 0.6452, Avg batch acc: 0.3815
Train, Epoch: 1, Batch: 1011, Step num: 1011, Learning rate: 0.00070646, Avg batch loss: 0.5391, Avg batch acc: 0.4391
Train, Epoch: 1, Batch: 1012, Step num: 1012, Learning rate: 0.00070716, Avg batch loss: 0.5939, Avg batch acc: 0.4091
Train, Epoch: 1, Batch: 1013, Step num: 1013, Learning rate: 0.00070786, Avg batch loss: 0.6415, Avg batch acc: 0.3911
Train, Epoch: 1, Batch: 1014, Step num: 1014, Learning rate: 0.00070855, Avg batch loss: 0.5407, Avg batch acc: 0.4082
Train, Epoch: 1, Batch: 1015, Step num: 1015, Learning rate: 0.00070925, Avg batch loss: 0.5600, Avg batch acc: 0.3992
Train, Epoch: 1, Batch: 1016, Step num: 1016, Learning rate: 0.00070995, Avg batch loss: 0.5312, Avg batch acc: 0.3990
Train, Epoch: 1, Batch: 1017, Step num: 1017, Learning rate: 0.00071065, Avg batch loss: 0.6442, Avg batch acc: 0.4052
Train, Epoch: 1, Batch: 1018, Step num: 1018, Learning rate: 0.00071135, Avg batch loss: 0.5525, Avg batch acc: 0.4172
Train, Epoch: 1, Batch: 1019, Step num: 1019, Learning rate: 0.00071205, Avg batch loss: 0.6070, Avg batch acc: 0.4051
Train, Epoch: 1, Batch: 1020, Step num: 1020, Learning rate: 0.00071275, Avg batch loss: 0.5695, Avg batch acc: 0.4045
Train, Epoch: 1, Batch: 1021, Step num: 1021, Learning rate: 0.00071345, Avg batch loss: 0.5672, Avg batch acc: 0.4015
Train, Epoch: 1, Batch: 1022, Step num: 1022, Learning rate: 0.00071414, Avg batch loss: 0.5889, Avg batch acc: 0.4055
Train, Epoch: 1, Batch: 1023, Step num: 1023, Learning rate: 0.00071484, Avg batch loss: 0.5939, Avg batch acc: 0.3967
Train, Epoch: 1, Batch: 1024, Step num: 1024, Learning rate: 0.00071554, Avg batch loss: 0.6701, Avg batch acc: 0.3877
Train, Epoch: 1, Batch: 1025, Step num: 1025, Learning rate: 0.00071624, Avg batch loss: 0.6475, Avg batch acc: 0.4107
Train, Epoch: 1, Batch: 1026, Step num: 1026, Learning rate: 0.00071694, Avg batch loss: 0.5750, Avg batch acc: 0.4057
Train, Epoch: 1, Batch: 1027, Step num: 1027, Learning rate: 0.00071764, Avg batch loss: 0.5454, Avg batch acc: 0.4223
Train, Epoch: 1, Batch: 1028, Step num: 1028, Learning rate: 0.00071834, Avg batch loss: 0.6220, Avg batch acc: 0.3928
Train, Epoch: 1, Batch: 1029, Step num: 1029, Learning rate: 0.00071904, Avg batch loss: 0.5698, Avg batch acc: 0.3977
Train, Epoch: 1, Batch: 1030, Step num: 1030, Learning rate: 0.00071973, Avg batch loss: 0.6022, Avg batch acc: 0.3727
Train, Epoch: 1, Batch: 1031, Step num: 1031, Learning rate: 0.00072043, Avg batch loss: 0.5489, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 1032, Step num: 1032, Learning rate: 0.00072113, Avg batch loss: 0.5313, Avg batch acc: 0.3953
Train, Epoch: 1, Batch: 1033, Step num: 1033, Learning rate: 0.00072183, Avg batch loss: 0.5778, Avg batch acc: 0.4137
Train, Epoch: 1, Batch: 1034, Step num: 1034, Learning rate: 0.00072253, Avg batch loss: 0.5931, Avg batch acc: 0.3940
Train, Epoch: 1, Batch: 1035, Step num: 1035, Learning rate: 0.00072323, Avg batch loss: 0.6826, Avg batch acc: 0.3789
Train, Epoch: 1, Batch: 1036, Step num: 1036, Learning rate: 0.00072393, Avg batch loss: 0.5557, Avg batch acc: 0.4016
Train, Epoch: 1, Batch: 1037, Step num: 1037, Learning rate: 0.00072463, Avg batch loss: 0.6256, Avg batch acc: 0.3900
Train, Epoch: 1, Batch: 1038, Step num: 1038, Learning rate: 0.00072532, Avg batch loss: 0.5810, Avg batch acc: 0.4365
Train, Epoch: 1, Batch: 1039, Step num: 1039, Learning rate: 0.00072602, Avg batch loss: 0.6003, Avg batch acc: 0.4061
Train, Epoch: 1, Batch: 1040, Step num: 1040, Learning rate: 0.00072672, Avg batch loss: 0.5810, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 1041, Step num: 1041, Learning rate: 0.00072742, Avg batch loss: 0.5819, Avg batch acc: 0.4061
Train, Epoch: 1, Batch: 1042, Step num: 1042, Learning rate: 0.00072812, Avg batch loss: 0.6163, Avg batch acc: 0.4028
Train, Epoch: 1, Batch: 1043, Step num: 1043, Learning rate: 0.00072882, Avg batch loss: 0.6486, Avg batch acc: 0.4020
Train, Epoch: 1, Batch: 1044, Step num: 1044, Learning rate: 0.00072952, Avg batch loss: 0.6391, Avg batch acc: 0.4047
Train, Epoch: 1, Batch: 1045, Step num: 1045, Learning rate: 0.00073022, Avg batch loss: 0.6596, Avg batch acc: 0.3983
Train, Epoch: 1, Batch: 1046, Step num: 1046, Learning rate: 0.00073091, Avg batch loss: 0.5660, Avg batch acc: 0.4305
Train, Epoch: 1, Batch: 1047, Step num: 1047, Learning rate: 0.00073161, Avg batch loss: 0.5925, Avg batch acc: 0.4154
Train, Epoch: 1, Batch: 1048, Step num: 1048, Learning rate: 0.00073231, Avg batch loss: 0.5948, Avg batch acc: 0.4122
Train, Epoch: 1, Batch: 1049, Step num: 1049, Learning rate: 0.00073301, Avg batch loss: 0.6437, Avg batch acc: 0.3783
Train, Epoch: 1, Batch: 1050, Step num: 1050, Learning rate: 0.00073371, Avg batch loss: 0.5950, Avg batch acc: 0.3727
Train, Epoch: 1, Batch: 1051, Step num: 1051, Learning rate: 0.00073441, Avg batch loss: 0.6031, Avg batch acc: 0.3956
Train, Epoch: 1, Batch: 1052, Step num: 1052, Learning rate: 0.00073511, Avg batch loss: 0.5524, Avg batch acc: 0.4161
Train, Epoch: 1, Batch: 1053, Step num: 1053, Learning rate: 0.00073581, Avg batch loss: 0.5020, Avg batch acc: 0.4155
Train, Epoch: 1, Batch: 1054, Step num: 1054, Learning rate: 0.00073650, Avg batch loss: 0.5995, Avg batch acc: 0.4105
Train, Epoch: 1, Batch: 1055, Step num: 1055, Learning rate: 0.00073720, Avg batch loss: 0.5955, Avg batch acc: 0.3992
Train, Epoch: 1, Batch: 1056, Step num: 1056, Learning rate: 0.00073790, Avg batch loss: 0.6394, Avg batch acc: 0.3882
Train, Epoch: 1, Batch: 1057, Step num: 1057, Learning rate: 0.00073860, Avg batch loss: 0.5938, Avg batch acc: 0.3996
Train, Epoch: 1, Batch: 1058, Step num: 1058, Learning rate: 0.00073930, Avg batch loss: 0.6480, Avg batch acc: 0.3912
Train, Epoch: 1, Batch: 1059, Step num: 1059, Learning rate: 0.00074000, Avg batch loss: 0.5664, Avg batch acc: 0.4085
Train, Epoch: 1, Batch: 1060, Step num: 1060, Learning rate: 0.00074070, Avg batch loss: 0.5639, Avg batch acc: 0.4063
Train, Epoch: 1, Batch: 1061, Step num: 1061, Learning rate: 0.00074140, Avg batch loss: 0.5076, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1062, Step num: 1062, Learning rate: 0.00074210, Avg batch loss: 0.5967, Avg batch acc: 0.4212
Train, Epoch: 1, Batch: 1063, Step num: 1063, Learning rate: 0.00074279, Avg batch loss: 0.6149, Avg batch acc: 0.4092
Train, Epoch: 1, Batch: 1064, Step num: 1064, Learning rate: 0.00074349, Avg batch loss: 0.5427, Avg batch acc: 0.4188
Train, Epoch: 1, Batch: 1065, Step num: 1065, Learning rate: 0.00074419, Avg batch loss: 0.5868, Avg batch acc: 0.3902
Train, Epoch: 1, Batch: 1066, Step num: 1066, Learning rate: 0.00074489, Avg batch loss: 0.4849, Avg batch acc: 0.4226
Train, Epoch: 1, Batch: 1067, Step num: 1067, Learning rate: 0.00074559, Avg batch loss: 0.5677, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 1068, Step num: 1068, Learning rate: 0.00074629, Avg batch loss: 0.5645, Avg batch acc: 0.4138
Train, Epoch: 1, Batch: 1069, Step num: 1069, Learning rate: 0.00074699, Avg batch loss: 0.5671, Avg batch acc: 0.4110
Train, Epoch: 1, Batch: 1070, Step num: 1070, Learning rate: 0.00074769, Avg batch loss: 0.6051, Avg batch acc: 0.4067
Train, Epoch: 1, Batch: 1071, Step num: 1071, Learning rate: 0.00074838, Avg batch loss: 0.5792, Avg batch acc: 0.4164
Train, Epoch: 1, Batch: 1072, Step num: 1072, Learning rate: 0.00074908, Avg batch loss: 0.6081, Avg batch acc: 0.4140
Train, Epoch: 1, Batch: 1073, Step num: 1073, Learning rate: 0.00074978, Avg batch loss: 0.6095, Avg batch acc: 0.4135
Train, Epoch: 1, Batch: 1074, Step num: 1074, Learning rate: 0.00075048, Avg batch loss: 0.5588, Avg batch acc: 0.4075
Train, Epoch: 1, Batch: 1075, Step num: 1075, Learning rate: 0.00075118, Avg batch loss: 0.5744, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 1076, Step num: 1076, Learning rate: 0.00075188, Avg batch loss: 0.6204, Avg batch acc: 0.3825
Train, Epoch: 1, Batch: 1077, Step num: 1077, Learning rate: 0.00075258, Avg batch loss: 0.5748, Avg batch acc: 0.4036
Train, Epoch: 1, Batch: 1078, Step num: 1078, Learning rate: 0.00075328, Avg batch loss: 0.5815, Avg batch acc: 0.4128
Train, Epoch: 1, Batch: 1079, Step num: 1079, Learning rate: 0.00075397, Avg batch loss: 0.5691, Avg batch acc: 0.4095
Train, Epoch: 1, Batch: 1080, Step num: 1080, Learning rate: 0.00075467, Avg batch loss: 0.6646, Avg batch acc: 0.3974
Train, Epoch: 1, Batch: 1081, Step num: 1081, Learning rate: 0.00075537, Avg batch loss: 0.5383, Avg batch acc: 0.3954
Train, Epoch: 1, Batch: 1082, Step num: 1082, Learning rate: 0.00075607, Avg batch loss: 0.5139, Avg batch acc: 0.4205
Train, Epoch: 1, Batch: 1083, Step num: 1083, Learning rate: 0.00075677, Avg batch loss: 0.5662, Avg batch acc: 0.4146
Train, Epoch: 1, Batch: 1084, Step num: 1084, Learning rate: 0.00075747, Avg batch loss: 0.6114, Avg batch acc: 0.4018
Train, Epoch: 1, Batch: 1085, Step num: 1085, Learning rate: 0.00075817, Avg batch loss: 0.6217, Avg batch acc: 0.3934
Train, Epoch: 1, Batch: 1086, Step num: 1086, Learning rate: 0.00075887, Avg batch loss: 0.5606, Avg batch acc: 0.4135
Train, Epoch: 1, Batch: 1087, Step num: 1087, Learning rate: 0.00075956, Avg batch loss: 0.5855, Avg batch acc: 0.4129
Train, Epoch: 1, Batch: 1088, Step num: 1088, Learning rate: 0.00076026, Avg batch loss: 0.5642, Avg batch acc: 0.4264
Train, Epoch: 1, Batch: 1089, Step num: 1089, Learning rate: 0.00076096, Avg batch loss: 0.6064, Avg batch acc: 0.4237
Train, Epoch: 1, Batch: 1090, Step num: 1090, Learning rate: 0.00076166, Avg batch loss: 0.5732, Avg batch acc: 0.3949
Train, Epoch: 1, Batch: 1091, Step num: 1091, Learning rate: 0.00076236, Avg batch loss: 0.5860, Avg batch acc: 0.4186
Train, Epoch: 1, Batch: 1092, Step num: 1092, Learning rate: 0.00076306, Avg batch loss: 0.5955, Avg batch acc: 0.4093
Train, Epoch: 1, Batch: 1093, Step num: 1093, Learning rate: 0.00076376, Avg batch loss: 0.6150, Avg batch acc: 0.4239
Train, Epoch: 1, Batch: 1094, Step num: 1094, Learning rate: 0.00076446, Avg batch loss: 0.5719, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 1095, Step num: 1095, Learning rate: 0.00076515, Avg batch loss: 0.5982, Avg batch acc: 0.4138
Train, Epoch: 1, Batch: 1096, Step num: 1096, Learning rate: 0.00076585, Avg batch loss: 0.5944, Avg batch acc: 0.4223
Train, Epoch: 1, Batch: 1097, Step num: 1097, Learning rate: 0.00076655, Avg batch loss: 0.6696, Avg batch acc: 0.3963
Train, Epoch: 1, Batch: 1098, Step num: 1098, Learning rate: 0.00076725, Avg batch loss: 0.5750, Avg batch acc: 0.4073
Train, Epoch: 1, Batch: 1099, Step num: 1099, Learning rate: 0.00076795, Avg batch loss: 0.6190, Avg batch acc: 0.4109
Train, Epoch: 1, Batch: 1100, Step num: 1100, Learning rate: 0.00076865, Avg batch loss: 0.6124, Avg batch acc: 0.4179
Train, Epoch: 1, Batch: 1101, Step num: 1101, Learning rate: 0.00076935, Avg batch loss: 0.5602, Avg batch acc: 0.4104
Train, Epoch: 1, Batch: 1102, Step num: 1102, Learning rate: 0.00077005, Avg batch loss: 0.5559, Avg batch acc: 0.4352
Train, Epoch: 1, Batch: 1103, Step num: 1103, Learning rate: 0.00077074, Avg batch loss: 0.6300, Avg batch acc: 0.3929
Train, Epoch: 1, Batch: 1104, Step num: 1104, Learning rate: 0.00077144, Avg batch loss: 0.5736, Avg batch acc: 0.3986
Train, Epoch: 1, Batch: 1105, Step num: 1105, Learning rate: 0.00077214, Avg batch loss: 0.6275, Avg batch acc: 0.3956
Train, Epoch: 1, Batch: 1106, Step num: 1106, Learning rate: 0.00077284, Avg batch loss: 0.5903, Avg batch acc: 0.3881
Train, Epoch: 1, Batch: 1107, Step num: 1107, Learning rate: 0.00077354, Avg batch loss: 0.5794, Avg batch acc: 0.4115
Train, Epoch: 1, Batch: 1108, Step num: 1108, Learning rate: 0.00077424, Avg batch loss: 0.5991, Avg batch acc: 0.4168
Train, Epoch: 1, Batch: 1109, Step num: 1109, Learning rate: 0.00077494, Avg batch loss: 0.5524, Avg batch acc: 0.4226
Train, Epoch: 1, Batch: 1110, Step num: 1110, Learning rate: 0.00077564, Avg batch loss: 0.5670, Avg batch acc: 0.4091
Train, Epoch: 1, Batch: 1111, Step num: 1111, Learning rate: 0.00077633, Avg batch loss: 0.5878, Avg batch acc: 0.4151
Train, Epoch: 1, Batch: 1112, Step num: 1112, Learning rate: 0.00077703, Avg batch loss: 0.5949, Avg batch acc: 0.3874
Train, Epoch: 1, Batch: 1113, Step num: 1113, Learning rate: 0.00077773, Avg batch loss: 0.5582, Avg batch acc: 0.4203
Train, Epoch: 1, Batch: 1114, Step num: 1114, Learning rate: 0.00077843, Avg batch loss: 0.5959, Avg batch acc: 0.4190
Train, Epoch: 1, Batch: 1115, Step num: 1115, Learning rate: 0.00077913, Avg batch loss: 0.5600, Avg batch acc: 0.4236
Train, Epoch: 1, Batch: 1116, Step num: 1116, Learning rate: 0.00077983, Avg batch loss: 0.5822, Avg batch acc: 0.4184
Train, Epoch: 1, Batch: 1117, Step num: 1117, Learning rate: 0.00078053, Avg batch loss: 0.5373, Avg batch acc: 0.4253
Train, Epoch: 1, Batch: 1118, Step num: 1118, Learning rate: 0.00078123, Avg batch loss: 0.6418, Avg batch acc: 0.3928
Train, Epoch: 1, Batch: 1119, Step num: 1119, Learning rate: 0.00078193, Avg batch loss: 0.5489, Avg batch acc: 0.4173
Train, Epoch: 1, Batch: 1120, Step num: 1120, Learning rate: 0.00078262, Avg batch loss: 0.5712, Avg batch acc: 0.4132
Train, Epoch: 1, Batch: 1121, Step num: 1121, Learning rate: 0.00078332, Avg batch loss: 0.5602, Avg batch acc: 0.4171
Train, Epoch: 1, Batch: 1122, Step num: 1122, Learning rate: 0.00078402, Avg batch loss: 0.5385, Avg batch acc: 0.4152
Train, Epoch: 1, Batch: 1123, Step num: 1123, Learning rate: 0.00078472, Avg batch loss: 0.6316, Avg batch acc: 0.4172
Train, Epoch: 1, Batch: 1124, Step num: 1124, Learning rate: 0.00078542, Avg batch loss: 0.5868, Avg batch acc: 0.4153
Train, Epoch: 1, Batch: 1125, Step num: 1125, Learning rate: 0.00078612, Avg batch loss: 0.6575, Avg batch acc: 0.3915
Train, Epoch: 1, Batch: 1126, Step num: 1126, Learning rate: 0.00078682, Avg batch loss: 0.5435, Avg batch acc: 0.4243
Train, Epoch: 1, Batch: 1127, Step num: 1127, Learning rate: 0.00078752, Avg batch loss: 0.5283, Avg batch acc: 0.4343
Train, Epoch: 1, Batch: 1128, Step num: 1128, Learning rate: 0.00078821, Avg batch loss: 0.5367, Avg batch acc: 0.4176
Train, Epoch: 1, Batch: 1129, Step num: 1129, Learning rate: 0.00078891, Avg batch loss: 0.5976, Avg batch acc: 0.3939
Train, Epoch: 1, Batch: 1130, Step num: 1130, Learning rate: 0.00078961, Avg batch loss: 0.5616, Avg batch acc: 0.4283
Train, Epoch: 1, Batch: 1131, Step num: 1131, Learning rate: 0.00079031, Avg batch loss: 0.5956, Avg batch acc: 0.3851
Train, Epoch: 1, Batch: 1132, Step num: 1132, Learning rate: 0.00079101, Avg batch loss: 0.5994, Avg batch acc: 0.4109
Train, Epoch: 1, Batch: 1133, Step num: 1133, Learning rate: 0.00079171, Avg batch loss: 0.5640, Avg batch acc: 0.4120
Train, Epoch: 1, Batch: 1134, Step num: 1134, Learning rate: 0.00079241, Avg batch loss: 0.6208, Avg batch acc: 0.3853
Train, Epoch: 1, Batch: 1135, Step num: 1135, Learning rate: 0.00079311, Avg batch loss: 0.4820, Avg batch acc: 0.4237
Train, Epoch: 1, Batch: 1136, Step num: 1136, Learning rate: 0.00079380, Avg batch loss: 0.5759, Avg batch acc: 0.3962
Train, Epoch: 1, Batch: 1137, Step num: 1137, Learning rate: 0.00079450, Avg batch loss: 0.5468, Avg batch acc: 0.4232
Train, Epoch: 1, Batch: 1138, Step num: 1138, Learning rate: 0.00079520, Avg batch loss: 0.5903, Avg batch acc: 0.4003
Train, Epoch: 1, Batch: 1139, Step num: 1139, Learning rate: 0.00079590, Avg batch loss: 0.5762, Avg batch acc: 0.4086
Train, Epoch: 1, Batch: 1140, Step num: 1140, Learning rate: 0.00079660, Avg batch loss: 0.5607, Avg batch acc: 0.4231
Train, Epoch: 1, Batch: 1141, Step num: 1141, Learning rate: 0.00079730, Avg batch loss: 0.5833, Avg batch acc: 0.4191
Train, Epoch: 1, Batch: 1142, Step num: 1142, Learning rate: 0.00079800, Avg batch loss: 0.6031, Avg batch acc: 0.4047
Train, Epoch: 1, Batch: 1143, Step num: 1143, Learning rate: 0.00079870, Avg batch loss: 0.5712, Avg batch acc: 0.4086
Train, Epoch: 1, Batch: 1144, Step num: 1144, Learning rate: 0.00079939, Avg batch loss: 0.5492, Avg batch acc: 0.4348
Train, Epoch: 1, Batch: 1145, Step num: 1145, Learning rate: 0.00080009, Avg batch loss: 0.4724, Avg batch acc: 0.4419
Train, Epoch: 1, Batch: 1146, Step num: 1146, Learning rate: 0.00080079, Avg batch loss: 0.6085, Avg batch acc: 0.3904
Train, Epoch: 1, Batch: 1147, Step num: 1147, Learning rate: 0.00080149, Avg batch loss: 0.5639, Avg batch acc: 0.4057
Train, Epoch: 1, Batch: 1148, Step num: 1148, Learning rate: 0.00080219, Avg batch loss: 0.5584, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 1149, Step num: 1149, Learning rate: 0.00080289, Avg batch loss: 0.6172, Avg batch acc: 0.3996
Train, Epoch: 1, Batch: 1150, Step num: 1150, Learning rate: 0.00080359, Avg batch loss: 0.5348, Avg batch acc: 0.4054
Train, Epoch: 1, Batch: 1151, Step num: 1151, Learning rate: 0.00080429, Avg batch loss: 0.5848, Avg batch acc: 0.4153
Train, Epoch: 1, Batch: 1152, Step num: 1152, Learning rate: 0.00080498, Avg batch loss: 0.6140, Avg batch acc: 0.3933
Train, Epoch: 1, Batch: 1153, Step num: 1153, Learning rate: 0.00080568, Avg batch loss: 0.5595, Avg batch acc: 0.4253
Train, Epoch: 1, Batch: 1154, Step num: 1154, Learning rate: 0.00080638, Avg batch loss: 0.5625, Avg batch acc: 0.4252
Train, Epoch: 1, Batch: 1155, Step num: 1155, Learning rate: 0.00080708, Avg batch loss: 0.5870, Avg batch acc: 0.4322
Train, Epoch: 1, Batch: 1156, Step num: 1156, Learning rate: 0.00080778, Avg batch loss: 0.5729, Avg batch acc: 0.4192
Train, Epoch: 1, Batch: 1157, Step num: 1157, Learning rate: 0.00080848, Avg batch loss: 0.5697, Avg batch acc: 0.4115
Train, Epoch: 1, Batch: 1158, Step num: 1158, Learning rate: 0.00080918, Avg batch loss: 0.5845, Avg batch acc: 0.4096
Train, Epoch: 1, Batch: 1159, Step num: 1159, Learning rate: 0.00080988, Avg batch loss: 0.5255, Avg batch acc: 0.4257
Train, Epoch: 1, Batch: 1160, Step num: 1160, Learning rate: 0.00081057, Avg batch loss: 0.5445, Avg batch acc: 0.4045
Train, Epoch: 1, Batch: 1161, Step num: 1161, Learning rate: 0.00081127, Avg batch loss: 0.5347, Avg batch acc: 0.4053
Train, Epoch: 1, Batch: 1162, Step num: 1162, Learning rate: 0.00081197, Avg batch loss: 0.5702, Avg batch acc: 0.3805
Train, Epoch: 1, Batch: 1163, Step num: 1163, Learning rate: 0.00081267, Avg batch loss: 0.5728, Avg batch acc: 0.3974
Train, Epoch: 1, Batch: 1164, Step num: 1164, Learning rate: 0.00081337, Avg batch loss: 0.6458, Avg batch acc: 0.3972
Train, Epoch: 1, Batch: 1165, Step num: 1165, Learning rate: 0.00081407, Avg batch loss: 0.6073, Avg batch acc: 0.4027
Train, Epoch: 1, Batch: 1166, Step num: 1166, Learning rate: 0.00081477, Avg batch loss: 0.5278, Avg batch acc: 0.4199
Train, Epoch: 1, Batch: 1167, Step num: 1167, Learning rate: 0.00081547, Avg batch loss: 0.5829, Avg batch acc: 0.4191
Train, Epoch: 1, Batch: 1168, Step num: 1168, Learning rate: 0.00081616, Avg batch loss: 0.5451, Avg batch acc: 0.4090
Train, Epoch: 1, Batch: 1169, Step num: 1169, Learning rate: 0.00081686, Avg batch loss: 0.5511, Avg batch acc: 0.4222
Train, Epoch: 1, Batch: 1170, Step num: 1170, Learning rate: 0.00081756, Avg batch loss: 0.6022, Avg batch acc: 0.4042
Train, Epoch: 1, Batch: 1171, Step num: 1171, Learning rate: 0.00081826, Avg batch loss: 0.5537, Avg batch acc: 0.4239
Train, Epoch: 1, Batch: 1172, Step num: 1172, Learning rate: 0.00081896, Avg batch loss: 0.5592, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1173, Step num: 1173, Learning rate: 0.00081966, Avg batch loss: 0.6017, Avg batch acc: 0.3983
Train, Epoch: 1, Batch: 1174, Step num: 1174, Learning rate: 0.00082036, Avg batch loss: 0.5675, Avg batch acc: 0.4089
Train, Epoch: 1, Batch: 1175, Step num: 1175, Learning rate: 0.00082106, Avg batch loss: 0.5646, Avg batch acc: 0.4102
Train, Epoch: 1, Batch: 1176, Step num: 1176, Learning rate: 0.00082175, Avg batch loss: 0.5696, Avg batch acc: 0.3893
Train, Epoch: 1, Batch: 1177, Step num: 1177, Learning rate: 0.00082245, Avg batch loss: 0.5859, Avg batch acc: 0.3936
Train, Epoch: 1, Batch: 1178, Step num: 1178, Learning rate: 0.00082315, Avg batch loss: 0.5813, Avg batch acc: 0.4282
Train, Epoch: 1, Batch: 1179, Step num: 1179, Learning rate: 0.00082385, Avg batch loss: 0.5549, Avg batch acc: 0.4212
Train, Epoch: 1, Batch: 1180, Step num: 1180, Learning rate: 0.00082455, Avg batch loss: 0.6007, Avg batch acc: 0.4089
Train, Epoch: 1, Batch: 1181, Step num: 1181, Learning rate: 0.00082525, Avg batch loss: 0.5306, Avg batch acc: 0.4441
Train, Epoch: 1, Batch: 1182, Step num: 1182, Learning rate: 0.00082595, Avg batch loss: 0.5761, Avg batch acc: 0.4164
Train, Epoch: 1, Batch: 1183, Step num: 1183, Learning rate: 0.00082665, Avg batch loss: 0.5723, Avg batch acc: 0.4328
Train, Epoch: 1, Batch: 1184, Step num: 1184, Learning rate: 0.00082735, Avg batch loss: 0.5581, Avg batch acc: 0.4061
Train, Epoch: 1, Batch: 1185, Step num: 1185, Learning rate: 0.00082804, Avg batch loss: 0.5985, Avg batch acc: 0.4006
Train, Epoch: 1, Batch: 1186, Step num: 1186, Learning rate: 0.00082874, Avg batch loss: 0.5404, Avg batch acc: 0.4235
Train, Epoch: 1, Batch: 1187, Step num: 1187, Learning rate: 0.00082944, Avg batch loss: 0.5686, Avg batch acc: 0.4271
Train, Epoch: 1, Batch: 1188, Step num: 1188, Learning rate: 0.00083014, Avg batch loss: 0.5289, Avg batch acc: 0.4119
Train, Epoch: 1, Batch: 1189, Step num: 1189, Learning rate: 0.00083084, Avg batch loss: 0.5418, Avg batch acc: 0.4050
Train, Epoch: 1, Batch: 1190, Step num: 1190, Learning rate: 0.00083154, Avg batch loss: 0.5038, Avg batch acc: 0.4208
Train, Epoch: 1, Batch: 1191, Step num: 1191, Learning rate: 0.00083224, Avg batch loss: 0.5417, Avg batch acc: 0.4223
Train, Epoch: 1, Batch: 1192, Step num: 1192, Learning rate: 0.00083294, Avg batch loss: 0.5711, Avg batch acc: 0.4201
Train, Epoch: 1, Batch: 1193, Step num: 1193, Learning rate: 0.00083363, Avg batch loss: 0.5731, Avg batch acc: 0.4102
Train, Epoch: 1, Batch: 1194, Step num: 1194, Learning rate: 0.00083433, Avg batch loss: 0.5953, Avg batch acc: 0.4136
Train, Epoch: 1, Batch: 1195, Step num: 1195, Learning rate: 0.00083503, Avg batch loss: 0.5862, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 1196, Step num: 1196, Learning rate: 0.00083573, Avg batch loss: 0.5818, Avg batch acc: 0.4278
Train, Epoch: 1, Batch: 1197, Step num: 1197, Learning rate: 0.00083643, Avg batch loss: 0.5297, Avg batch acc: 0.4088
Train, Epoch: 1, Batch: 1198, Step num: 1198, Learning rate: 0.00083713, Avg batch loss: 0.5961, Avg batch acc: 0.4259
Train, Epoch: 1, Batch: 1199, Step num: 1199, Learning rate: 0.00083783, Avg batch loss: 0.5459, Avg batch acc: 0.4140
Train, Epoch: 1, Batch: 1200, Step num: 1200, Learning rate: 0.00083853, Avg batch loss: 0.5396, Avg batch acc: 0.4188
Train, Epoch: 1, Batch: 1201, Step num: 1201, Learning rate: 0.00083922, Avg batch loss: 0.5014, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 1202, Step num: 1202, Learning rate: 0.00083992, Avg batch loss: 0.5149, Avg batch acc: 0.4342
Train, Epoch: 1, Batch: 1203, Step num: 1203, Learning rate: 0.00084062, Avg batch loss: 0.5600, Avg batch acc: 0.4079
Train, Epoch: 1, Batch: 1204, Step num: 1204, Learning rate: 0.00084132, Avg batch loss: 0.5488, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1205, Step num: 1205, Learning rate: 0.00084202, Avg batch loss: 0.5246, Avg batch acc: 0.4341
Train, Epoch: 1, Batch: 1206, Step num: 1206, Learning rate: 0.00084272, Avg batch loss: 0.5402, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 1207, Step num: 1207, Learning rate: 0.00084342, Avg batch loss: 0.4851, Avg batch acc: 0.4418
Train, Epoch: 1, Batch: 1208, Step num: 1208, Learning rate: 0.00084412, Avg batch loss: 0.5877, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1209, Step num: 1209, Learning rate: 0.00084481, Avg batch loss: 0.5651, Avg batch acc: 0.4162
Train, Epoch: 1, Batch: 1210, Step num: 1210, Learning rate: 0.00084551, Avg batch loss: 0.5799, Avg batch acc: 0.4041
Train, Epoch: 1, Batch: 1211, Step num: 1211, Learning rate: 0.00084621, Avg batch loss: 0.5693, Avg batch acc: 0.4312
Train, Epoch: 1, Batch: 1212, Step num: 1212, Learning rate: 0.00084691, Avg batch loss: 0.5393, Avg batch acc: 0.4496
Train, Epoch: 1, Batch: 1213, Step num: 1213, Learning rate: 0.00084761, Avg batch loss: 0.5536, Avg batch acc: 0.4122
Train, Epoch: 1, Batch: 1214, Step num: 1214, Learning rate: 0.00084831, Avg batch loss: 0.5529, Avg batch acc: 0.4142
Train, Epoch: 1, Batch: 1215, Step num: 1215, Learning rate: 0.00084901, Avg batch loss: 0.5330, Avg batch acc: 0.4203
Train, Epoch: 1, Batch: 1216, Step num: 1216, Learning rate: 0.00084971, Avg batch loss: 0.5749, Avg batch acc: 0.4313
Train, Epoch: 1, Batch: 1217, Step num: 1217, Learning rate: 0.00085040, Avg batch loss: 0.4878, Avg batch acc: 0.4401
Train, Epoch: 1, Batch: 1218, Step num: 1218, Learning rate: 0.00085110, Avg batch loss: 0.5528, Avg batch acc: 0.4530
Train, Epoch: 1, Batch: 1219, Step num: 1219, Learning rate: 0.00085180, Avg batch loss: 0.5189, Avg batch acc: 0.4059
Train, Epoch: 1, Batch: 1220, Step num: 1220, Learning rate: 0.00085250, Avg batch loss: 0.5600, Avg batch acc: 0.4254
Train, Epoch: 1, Batch: 1221, Step num: 1221, Learning rate: 0.00085320, Avg batch loss: 0.5043, Avg batch acc: 0.4341
Train, Epoch: 1, Batch: 1222, Step num: 1222, Learning rate: 0.00085390, Avg batch loss: 0.5596, Avg batch acc: 0.4111
Train, Epoch: 1, Batch: 1223, Step num: 1223, Learning rate: 0.00085460, Avg batch loss: 0.5848, Avg batch acc: 0.4115
Train, Epoch: 1, Batch: 1224, Step num: 1224, Learning rate: 0.00085530, Avg batch loss: 0.5752, Avg batch acc: 0.4066
Train, Epoch: 1, Batch: 1225, Step num: 1225, Learning rate: 0.00085599, Avg batch loss: 0.5172, Avg batch acc: 0.4171
Train, Epoch: 1, Batch: 1226, Step num: 1226, Learning rate: 0.00085669, Avg batch loss: 0.5341, Avg batch acc: 0.4288
Train, Epoch: 1, Batch: 1227, Step num: 1227, Learning rate: 0.00085739, Avg batch loss: 0.5939, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 1228, Step num: 1228, Learning rate: 0.00085809, Avg batch loss: 0.5078, Avg batch acc: 0.4234
Train, Epoch: 1, Batch: 1229, Step num: 1229, Learning rate: 0.00085879, Avg batch loss: 0.5393, Avg batch acc: 0.4212
Train, Epoch: 1, Batch: 1230, Step num: 1230, Learning rate: 0.00085949, Avg batch loss: 0.6146, Avg batch acc: 0.4213
Train, Epoch: 1, Batch: 1231, Step num: 1231, Learning rate: 0.00086019, Avg batch loss: 0.5135, Avg batch acc: 0.4156
Train, Epoch: 1, Batch: 1232, Step num: 1232, Learning rate: 0.00086089, Avg batch loss: 0.6158, Avg batch acc: 0.4031
Train, Epoch: 1, Batch: 1233, Step num: 1233, Learning rate: 0.00086158, Avg batch loss: 0.5870, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1234, Step num: 1234, Learning rate: 0.00086228, Avg batch loss: 0.5874, Avg batch acc: 0.4170
Train, Epoch: 1, Batch: 1235, Step num: 1235, Learning rate: 0.00086298, Avg batch loss: 0.4920, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1236, Step num: 1236, Learning rate: 0.00086368, Avg batch loss: 0.5481, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 1237, Step num: 1237, Learning rate: 0.00086438, Avg batch loss: 0.5696, Avg batch acc: 0.4110
Train, Epoch: 1, Batch: 1238, Step num: 1238, Learning rate: 0.00086508, Avg batch loss: 0.5565, Avg batch acc: 0.4249
Train, Epoch: 1, Batch: 1239, Step num: 1239, Learning rate: 0.00086578, Avg batch loss: 0.5435, Avg batch acc: 0.3946
Train, Epoch: 1, Batch: 1240, Step num: 1240, Learning rate: 0.00086648, Avg batch loss: 0.5172, Avg batch acc: 0.4272
Train, Epoch: 1, Batch: 1241, Step num: 1241, Learning rate: 0.00086718, Avg batch loss: 0.6221, Avg batch acc: 0.4057
Train, Epoch: 1, Batch: 1242, Step num: 1242, Learning rate: 0.00086787, Avg batch loss: 0.5510, Avg batch acc: 0.4153
Train, Epoch: 1, Batch: 1243, Step num: 1243, Learning rate: 0.00086857, Avg batch loss: 0.5914, Avg batch acc: 0.4094
Train, Epoch: 1, Batch: 1244, Step num: 1244, Learning rate: 0.00086927, Avg batch loss: 0.4761, Avg batch acc: 0.4262
Train, Epoch: 1, Batch: 1245, Step num: 1245, Learning rate: 0.00086997, Avg batch loss: 0.5411, Avg batch acc: 0.4090
Train, Epoch: 1, Batch: 1246, Step num: 1246, Learning rate: 0.00087067, Avg batch loss: 0.5120, Avg batch acc: 0.4313
Train, Epoch: 1, Batch: 1247, Step num: 1247, Learning rate: 0.00087137, Avg batch loss: 0.6082, Avg batch acc: 0.4067
Train, Epoch: 1, Batch: 1248, Step num: 1248, Learning rate: 0.00087207, Avg batch loss: 0.5588, Avg batch acc: 0.4132
Train, Epoch: 1, Batch: 1249, Step num: 1249, Learning rate: 0.00087277, Avg batch loss: 0.5938, Avg batch acc: 0.4055
Train, Epoch: 1, Batch: 1250, Step num: 1250, Learning rate: 0.00087346, Avg batch loss: 0.5263, Avg batch acc: 0.4149
Train, Epoch: 1, Batch: 1251, Step num: 1251, Learning rate: 0.00087416, Avg batch loss: 0.5663, Avg batch acc: 0.4166
Train, Epoch: 1, Batch: 1252, Step num: 1252, Learning rate: 0.00087486, Avg batch loss: 0.5336, Avg batch acc: 0.4172
Train, Epoch: 1, Batch: 1253, Step num: 1253, Learning rate: 0.00087556, Avg batch loss: 0.5070, Avg batch acc: 0.3873
Train, Epoch: 1, Batch: 1254, Step num: 1254, Learning rate: 0.00087626, Avg batch loss: 0.5926, Avg batch acc: 0.3912
Train, Epoch: 1, Batch: 1255, Step num: 1255, Learning rate: 0.00087696, Avg batch loss: 0.5089, Avg batch acc: 0.4241
Train, Epoch: 1, Batch: 1256, Step num: 1256, Learning rate: 0.00087766, Avg batch loss: 0.5367, Avg batch acc: 0.4290
Train, Epoch: 1, Batch: 1257, Step num: 1257, Learning rate: 0.00087836, Avg batch loss: 0.6431, Avg batch acc: 0.4036
Train, Epoch: 1, Batch: 1258, Step num: 1258, Learning rate: 0.00087905, Avg batch loss: 0.5753, Avg batch acc: 0.4327
Train, Epoch: 1, Batch: 1259, Step num: 1259, Learning rate: 0.00087975, Avg batch loss: 0.4844, Avg batch acc: 0.4572
Train, Epoch: 1, Batch: 1260, Step num: 1260, Learning rate: 0.00088045, Avg batch loss: 0.5622, Avg batch acc: 0.4104
Train, Epoch: 1, Batch: 1261, Step num: 1261, Learning rate: 0.00088115, Avg batch loss: 0.6113, Avg batch acc: 0.4093
Train, Epoch: 1, Batch: 1262, Step num: 1262, Learning rate: 0.00088185, Avg batch loss: 0.5192, Avg batch acc: 0.4252
Train, Epoch: 1, Batch: 1263, Step num: 1263, Learning rate: 0.00088255, Avg batch loss: 0.5772, Avg batch acc: 0.3928
Train, Epoch: 1, Batch: 1264, Step num: 1264, Learning rate: 0.00088325, Avg batch loss: 0.5475, Avg batch acc: 0.4100
Train, Epoch: 1, Batch: 1265, Step num: 1265, Learning rate: 0.00088395, Avg batch loss: 0.5104, Avg batch acc: 0.4419
Train, Epoch: 1, Batch: 1266, Step num: 1266, Learning rate: 0.00088464, Avg batch loss: 0.5500, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1267, Step num: 1267, Learning rate: 0.00088534, Avg batch loss: 0.5426, Avg batch acc: 0.4164
Train, Epoch: 1, Batch: 1268, Step num: 1268, Learning rate: 0.00088604, Avg batch loss: 0.5515, Avg batch acc: 0.4190
Train, Epoch: 1, Batch: 1269, Step num: 1269, Learning rate: 0.00088674, Avg batch loss: 0.5472, Avg batch acc: 0.4257
Train, Epoch: 1, Batch: 1270, Step num: 1270, Learning rate: 0.00088744, Avg batch loss: 0.5745, Avg batch acc: 0.4129
Train, Epoch: 1, Batch: 1271, Step num: 1271, Learning rate: 0.00088814, Avg batch loss: 0.6146, Avg batch acc: 0.3908
Train, Epoch: 1, Batch: 1272, Step num: 1272, Learning rate: 0.00088884, Avg batch loss: 0.5629, Avg batch acc: 0.4190
Train, Epoch: 1, Batch: 1273, Step num: 1273, Learning rate: 0.00088954, Avg batch loss: 0.5476, Avg batch acc: 0.3793
Train, Epoch: 1, Batch: 1274, Step num: 1274, Learning rate: 0.00089023, Avg batch loss: 0.5569, Avg batch acc: 0.4313
Train, Epoch: 1, Batch: 1275, Step num: 1275, Learning rate: 0.00089093, Avg batch loss: 0.6042, Avg batch acc: 0.3975
Train, Epoch: 1, Batch: 1276, Step num: 1276, Learning rate: 0.00089163, Avg batch loss: 0.5001, Avg batch acc: 0.4173
Train, Epoch: 1, Batch: 1277, Step num: 1277, Learning rate: 0.00089233, Avg batch loss: 0.6192, Avg batch acc: 0.4035
Train, Epoch: 1, Batch: 1278, Step num: 1278, Learning rate: 0.00089303, Avg batch loss: 0.6004, Avg batch acc: 0.4086
Train, Epoch: 1, Batch: 1279, Step num: 1279, Learning rate: 0.00089373, Avg batch loss: 0.5135, Avg batch acc: 0.4384
Train, Epoch: 1, Batch: 1280, Step num: 1280, Learning rate: 0.00089443, Avg batch loss: 0.5443, Avg batch acc: 0.4332
Train, Epoch: 1, Batch: 1281, Step num: 1281, Learning rate: 0.00089513, Avg batch loss: 0.6041, Avg batch acc: 0.4424
Train, Epoch: 1, Batch: 1282, Step num: 1282, Learning rate: 0.00089582, Avg batch loss: 0.5771, Avg batch acc: 0.4249
Train, Epoch: 1, Batch: 1283, Step num: 1283, Learning rate: 0.00089652, Avg batch loss: 0.5560, Avg batch acc: 0.4329
Train, Epoch: 1, Batch: 1284, Step num: 1284, Learning rate: 0.00089722, Avg batch loss: 0.5362, Avg batch acc: 0.4091
Train, Epoch: 1, Batch: 1285, Step num: 1285, Learning rate: 0.00089792, Avg batch loss: 0.5781, Avg batch acc: 0.3998
Train, Epoch: 1, Batch: 1286, Step num: 1286, Learning rate: 0.00089862, Avg batch loss: 0.5271, Avg batch acc: 0.4386
Train, Epoch: 1, Batch: 1287, Step num: 1287, Learning rate: 0.00089932, Avg batch loss: 0.5468, Avg batch acc: 0.4304
Train, Epoch: 1, Batch: 1288, Step num: 1288, Learning rate: 0.00090002, Avg batch loss: 0.5195, Avg batch acc: 0.4339
Train, Epoch: 1, Batch: 1289, Step num: 1289, Learning rate: 0.00090072, Avg batch loss: 0.5864, Avg batch acc: 0.4047
Train, Epoch: 1, Batch: 1290, Step num: 1290, Learning rate: 0.00090141, Avg batch loss: 0.5466, Avg batch acc: 0.3967
Train, Epoch: 1, Batch: 1291, Step num: 1291, Learning rate: 0.00090211, Avg batch loss: 0.5682, Avg batch acc: 0.4013
Train, Epoch: 1, Batch: 1292, Step num: 1292, Learning rate: 0.00090281, Avg batch loss: 0.5856, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 1293, Step num: 1293, Learning rate: 0.00090351, Avg batch loss: 0.5613, Avg batch acc: 0.4174
Train, Epoch: 1, Batch: 1294, Step num: 1294, Learning rate: 0.00090421, Avg batch loss: 0.4789, Avg batch acc: 0.4401
Train, Epoch: 1, Batch: 1295, Step num: 1295, Learning rate: 0.00090491, Avg batch loss: 0.5589, Avg batch acc: 0.4112
Train, Epoch: 1, Batch: 1296, Step num: 1296, Learning rate: 0.00090561, Avg batch loss: 0.5194, Avg batch acc: 0.4308
Train, Epoch: 1, Batch: 1297, Step num: 1297, Learning rate: 0.00090631, Avg batch loss: 0.5732, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1298, Step num: 1298, Learning rate: 0.00090701, Avg batch loss: 0.5600, Avg batch acc: 0.4034
Train, Epoch: 1, Batch: 1299, Step num: 1299, Learning rate: 0.00090770, Avg batch loss: 0.5229, Avg batch acc: 0.4238
Train, Epoch: 1, Batch: 1300, Step num: 1300, Learning rate: 0.00090840, Avg batch loss: 0.6223, Avg batch acc: 0.4081
Train, Epoch: 1, Batch: 1301, Step num: 1301, Learning rate: 0.00090910, Avg batch loss: 0.5674, Avg batch acc: 0.4140
Train, Epoch: 1, Batch: 1302, Step num: 1302, Learning rate: 0.00090980, Avg batch loss: 0.5273, Avg batch acc: 0.4059
Train, Epoch: 1, Batch: 1303, Step num: 1303, Learning rate: 0.00091050, Avg batch loss: 0.5751, Avg batch acc: 0.4236
Train, Epoch: 1, Batch: 1304, Step num: 1304, Learning rate: 0.00091120, Avg batch loss: 0.5461, Avg batch acc: 0.4179
Train, Epoch: 1, Batch: 1305, Step num: 1305, Learning rate: 0.00091190, Avg batch loss: 0.5796, Avg batch acc: 0.4229
Train, Epoch: 1, Batch: 1306, Step num: 1306, Learning rate: 0.00091260, Avg batch loss: 0.5774, Avg batch acc: 0.4271
Train, Epoch: 1, Batch: 1307, Step num: 1307, Learning rate: 0.00091329, Avg batch loss: 0.5464, Avg batch acc: 0.4264
Train, Epoch: 1, Batch: 1308, Step num: 1308, Learning rate: 0.00091399, Avg batch loss: 0.4933, Avg batch acc: 0.4198
Train, Epoch: 1, Batch: 1309, Step num: 1309, Learning rate: 0.00091469, Avg batch loss: 0.5393, Avg batch acc: 0.4251
Train, Epoch: 1, Batch: 1310, Step num: 1310, Learning rate: 0.00091539, Avg batch loss: 0.5854, Avg batch acc: 0.4195
Train, Epoch: 1, Batch: 1311, Step num: 1311, Learning rate: 0.00091609, Avg batch loss: 0.5593, Avg batch acc: 0.4175
Train, Epoch: 1, Batch: 1312, Step num: 1312, Learning rate: 0.00091679, Avg batch loss: 0.4800, Avg batch acc: 0.4339
Train, Epoch: 1, Batch: 1313, Step num: 1313, Learning rate: 0.00091749, Avg batch loss: 0.5763, Avg batch acc: 0.4192
Train, Epoch: 1, Batch: 1314, Step num: 1314, Learning rate: 0.00091819, Avg batch loss: 0.4849, Avg batch acc: 0.4434
Train, Epoch: 1, Batch: 1315, Step num: 1315, Learning rate: 0.00091888, Avg batch loss: 0.5171, Avg batch acc: 0.4325
Train, Epoch: 1, Batch: 1316, Step num: 1316, Learning rate: 0.00091958, Avg batch loss: 0.5482, Avg batch acc: 0.4022
Train, Epoch: 1, Batch: 1317, Step num: 1317, Learning rate: 0.00092028, Avg batch loss: 0.5765, Avg batch acc: 0.3979
Train, Epoch: 1, Batch: 1318, Step num: 1318, Learning rate: 0.00092098, Avg batch loss: 0.5020, Avg batch acc: 0.4333
Train, Epoch: 1, Batch: 1319, Step num: 1319, Learning rate: 0.00092168, Avg batch loss: 0.5456, Avg batch acc: 0.4250
Train, Epoch: 1, Batch: 1320, Step num: 1320, Learning rate: 0.00092238, Avg batch loss: 0.5561, Avg batch acc: 0.4244
Train, Epoch: 1, Batch: 1321, Step num: 1321, Learning rate: 0.00092308, Avg batch loss: 0.5341, Avg batch acc: 0.4513
Train, Epoch: 1, Batch: 1322, Step num: 1322, Learning rate: 0.00092378, Avg batch loss: 0.5595, Avg batch acc: 0.3934
Train, Epoch: 1, Batch: 1323, Step num: 1323, Learning rate: 0.00092447, Avg batch loss: 0.5528, Avg batch acc: 0.4243
Train, Epoch: 1, Batch: 1324, Step num: 1324, Learning rate: 0.00092517, Avg batch loss: 0.5998, Avg batch acc: 0.4018
Train, Epoch: 1, Batch: 1325, Step num: 1325, Learning rate: 0.00092587, Avg batch loss: 0.5358, Avg batch acc: 0.4185
Train, Epoch: 1, Batch: 1326, Step num: 1326, Learning rate: 0.00092657, Avg batch loss: 0.5551, Avg batch acc: 0.4225
Train, Epoch: 1, Batch: 1327, Step num: 1327, Learning rate: 0.00092727, Avg batch loss: 0.5663, Avg batch acc: 0.4121
Train, Epoch: 1, Batch: 1328, Step num: 1328, Learning rate: 0.00092797, Avg batch loss: 0.5151, Avg batch acc: 0.4529
Train, Epoch: 1, Batch: 1329, Step num: 1329, Learning rate: 0.00092867, Avg batch loss: 0.5350, Avg batch acc: 0.4240
Train, Epoch: 1, Batch: 1330, Step num: 1330, Learning rate: 0.00092937, Avg batch loss: 0.5676, Avg batch acc: 0.3979
Train, Epoch: 1, Batch: 1331, Step num: 1331, Learning rate: 0.00093006, Avg batch loss: 0.5235, Avg batch acc: 0.4151
Train, Epoch: 1, Batch: 1332, Step num: 1332, Learning rate: 0.00093076, Avg batch loss: 0.6306, Avg batch acc: 0.4020
Train, Epoch: 1, Batch: 1333, Step num: 1333, Learning rate: 0.00093146, Avg batch loss: 0.5670, Avg batch acc: 0.4075
Train, Epoch: 1, Batch: 1334, Step num: 1334, Learning rate: 0.00093216, Avg batch loss: 0.5057, Avg batch acc: 0.4360
Train, Epoch: 1, Batch: 1335, Step num: 1335, Learning rate: 0.00093286, Avg batch loss: 0.4987, Avg batch acc: 0.4350
Train, Epoch: 1, Batch: 1336, Step num: 1336, Learning rate: 0.00093356, Avg batch loss: 0.4837, Avg batch acc: 0.4574
Train, Epoch: 1, Batch: 1337, Step num: 1337, Learning rate: 0.00093426, Avg batch loss: 0.5071, Avg batch acc: 0.4439
Train, Epoch: 1, Batch: 1338, Step num: 1338, Learning rate: 0.00093496, Avg batch loss: 0.5272, Avg batch acc: 0.4253
Train, Epoch: 1, Batch: 1339, Step num: 1339, Learning rate: 0.00093565, Avg batch loss: 0.5688, Avg batch acc: 0.4148
Train, Epoch: 1, Batch: 1340, Step num: 1340, Learning rate: 0.00093635, Avg batch loss: 0.5954, Avg batch acc: 0.3942
Train, Epoch: 1, Batch: 1341, Step num: 1341, Learning rate: 0.00093705, Avg batch loss: 0.5635, Avg batch acc: 0.4216
Train, Epoch: 1, Batch: 1342, Step num: 1342, Learning rate: 0.00093775, Avg batch loss: 0.5349, Avg batch acc: 0.4316
Train, Epoch: 1, Batch: 1343, Step num: 1343, Learning rate: 0.00093845, Avg batch loss: 0.5190, Avg batch acc: 0.4070
Train, Epoch: 1, Batch: 1344, Step num: 1344, Learning rate: 0.00093915, Avg batch loss: 0.5530, Avg batch acc: 0.4139
Train, Epoch: 1, Batch: 1345, Step num: 1345, Learning rate: 0.00093985, Avg batch loss: 0.5148, Avg batch acc: 0.4194
Train, Epoch: 1, Batch: 1346, Step num: 1346, Learning rate: 0.00094055, Avg batch loss: 0.5334, Avg batch acc: 0.4240
Train, Epoch: 1, Batch: 1347, Step num: 1347, Learning rate: 0.00094124, Avg batch loss: 0.5092, Avg batch acc: 0.4334
Train, Epoch: 1, Batch: 1348, Step num: 1348, Learning rate: 0.00094194, Avg batch loss: 0.5367, Avg batch acc: 0.4345
Train, Epoch: 1, Batch: 1349, Step num: 1349, Learning rate: 0.00094264, Avg batch loss: 0.5296, Avg batch acc: 0.4187
Train, Epoch: 1, Batch: 1350, Step num: 1350, Learning rate: 0.00094334, Avg batch loss: 0.5431, Avg batch acc: 0.4239
Train, Epoch: 1, Batch: 1351, Step num: 1351, Learning rate: 0.00094404, Avg batch loss: 0.5291, Avg batch acc: 0.4204
Train, Epoch: 1, Batch: 1352, Step num: 1352, Learning rate: 0.00094474, Avg batch loss: 0.5619, Avg batch acc: 0.4284
Train, Epoch: 1, Batch: 1353, Step num: 1353, Learning rate: 0.00094544, Avg batch loss: 0.5817, Avg batch acc: 0.4111
Train, Epoch: 1, Batch: 1354, Step num: 1354, Learning rate: 0.00094614, Avg batch loss: 0.4816, Avg batch acc: 0.4155
Train, Epoch: 1, Batch: 1355, Step num: 1355, Learning rate: 0.00094684, Avg batch loss: 0.5603, Avg batch acc: 0.4119
Train, Epoch: 1, Batch: 1356, Step num: 1356, Learning rate: 0.00094753, Avg batch loss: 0.5329, Avg batch acc: 0.4156
Train, Epoch: 1, Batch: 1357, Step num: 1357, Learning rate: 0.00094823, Avg batch loss: 0.5323, Avg batch acc: 0.4255
Train, Epoch: 1, Batch: 1358, Step num: 1358, Learning rate: 0.00094893, Avg batch loss: 0.5166, Avg batch acc: 0.4306
Train, Epoch: 1, Batch: 1359, Step num: 1359, Learning rate: 0.00094963, Avg batch loss: 0.5110, Avg batch acc: 0.4215
Train, Epoch: 1, Batch: 1360, Step num: 1360, Learning rate: 0.00095033, Avg batch loss: 0.5135, Avg batch acc: 0.4294
Train, Epoch: 1, Batch: 1361, Step num: 1361, Learning rate: 0.00095103, Avg batch loss: 0.4754, Avg batch acc: 0.4517
Train, Epoch: 1, Batch: 1362, Step num: 1362, Learning rate: 0.00095173, Avg batch loss: 0.5048, Avg batch acc: 0.4223
Train, Epoch: 1, Batch: 1363, Step num: 1363, Learning rate: 0.00095243, Avg batch loss: 0.5324, Avg batch acc: 0.4144
Train, Epoch: 1, Batch: 1364, Step num: 1364, Learning rate: 0.00095312, Avg batch loss: 0.5265, Avg batch acc: 0.4178
Train, Epoch: 1, Batch: 1365, Step num: 1365, Learning rate: 0.00095382, Avg batch loss: 0.5245, Avg batch acc: 0.4418
Train, Epoch: 1, Batch: 1366, Step num: 1366, Learning rate: 0.00095452, Avg batch loss: 0.5317, Avg batch acc: 0.4373
Train, Epoch: 1, Batch: 1367, Step num: 1367, Learning rate: 0.00095522, Avg batch loss: 0.5150, Avg batch acc: 0.4369
Train, Epoch: 1, Batch: 1368, Step num: 1368, Learning rate: 0.00095592, Avg batch loss: 0.4951, Avg batch acc: 0.4495
Train, Epoch: 1, Batch: 1369, Step num: 1369, Learning rate: 0.00095662, Avg batch loss: 0.5061, Avg batch acc: 0.4418
Train, Epoch: 1, Batch: 1370, Step num: 1370, Learning rate: 0.00095732, Avg batch loss: 0.5125, Avg batch acc: 0.4280
Train, Epoch: 1, Batch: 1371, Step num: 1371, Learning rate: 0.00095802, Avg batch loss: 0.4934, Avg batch acc: 0.4390
Train, Epoch: 1, Batch: 1372, Step num: 1372, Learning rate: 0.00095871, Avg batch loss: 0.4827, Avg batch acc: 0.4341
Train, Epoch: 1, Batch: 1373, Step num: 1373, Learning rate: 0.00095941, Avg batch loss: 0.5167, Avg batch acc: 0.4250
Train, Epoch: 1, Batch: 1374, Step num: 1374, Learning rate: 0.00096011, Avg batch loss: 0.5077, Avg batch acc: 0.4261
Train, Epoch: 1, Batch: 1375, Step num: 1375, Learning rate: 0.00096081, Avg batch loss: 0.5580, Avg batch acc: 0.4078
Train, Epoch: 1, Batch: 1376, Step num: 1376, Learning rate: 0.00096151, Avg batch loss: 0.5768, Avg batch acc: 0.4412
Train, Epoch: 1, Batch: 1377, Step num: 1377, Learning rate: 0.00096221, Avg batch loss: 0.5519, Avg batch acc: 0.4225
Train, Epoch: 1, Batch: 1378, Step num: 1378, Learning rate: 0.00096291, Avg batch loss: 0.5324, Avg batch acc: 0.4322
Train, Epoch: 1, Batch: 1379, Step num: 1379, Learning rate: 0.00096361, Avg batch loss: 0.5540, Avg batch acc: 0.4268
Train, Epoch: 1, Batch: 1380, Step num: 1380, Learning rate: 0.00096430, Avg batch loss: 0.5673, Avg batch acc: 0.4165
Train, Epoch: 1, Batch: 1381, Step num: 1381, Learning rate: 0.00096500, Avg batch loss: 0.5480, Avg batch acc: 0.4386
Train, Epoch: 1, Batch: 1382, Step num: 1382, Learning rate: 0.00096570, Avg batch loss: 0.5918, Avg batch acc: 0.4033
Train, Epoch: 1, Batch: 1383, Step num: 1383, Learning rate: 0.00096640, Avg batch loss: 0.5024, Avg batch acc: 0.4304
Train, Epoch: 1, Batch: 1384, Step num: 1384, Learning rate: 0.00096710, Avg batch loss: 0.5545, Avg batch acc: 0.4312
Train, Epoch: 1, Batch: 1385, Step num: 1385, Learning rate: 0.00096780, Avg batch loss: 0.4925, Avg batch acc: 0.4249
Train, Epoch: 1, Batch: 1386, Step num: 1386, Learning rate: 0.00096850, Avg batch loss: 0.5348, Avg batch acc: 0.4390
Train, Epoch: 1, Batch: 1387, Step num: 1387, Learning rate: 0.00096920, Avg batch loss: 0.5089, Avg batch acc: 0.4587
Train, Epoch: 1, Batch: 1388, Step num: 1388, Learning rate: 0.00096989, Avg batch loss: 0.5288, Avg batch acc: 0.4256
Train, Epoch: 1, Batch: 1389, Step num: 1389, Learning rate: 0.00097059, Avg batch loss: 0.5158, Avg batch acc: 0.4340
Train, Epoch: 1, Batch: 1390, Step num: 1390, Learning rate: 0.00097129, Avg batch loss: 0.5107, Avg batch acc: 0.4321
Train, Epoch: 1, Batch: 1391, Step num: 1391, Learning rate: 0.00097199, Avg batch loss: 0.5018, Avg batch acc: 0.4122
Train, Epoch: 1, Batch: 1392, Step num: 1392, Learning rate: 0.00097269, Avg batch loss: 0.5094, Avg batch acc: 0.4402
Train, Epoch: 1, Batch: 1393, Step num: 1393, Learning rate: 0.00097339, Avg batch loss: 0.5470, Avg batch acc: 0.4291
Train, Epoch: 1, Batch: 1394, Step num: 1394, Learning rate: 0.00097409, Avg batch loss: 0.5096, Avg batch acc: 0.4432
Train, Epoch: 1, Batch: 1395, Step num: 1395, Learning rate: 0.00097479, Avg batch loss: 0.5315, Avg batch acc: 0.4356
Train, Epoch: 1, Batch: 1396, Step num: 1396, Learning rate: 0.00097548, Avg batch loss: 0.5301, Avg batch acc: 0.4333
Train, Epoch: 1, Batch: 1397, Step num: 1397, Learning rate: 0.00097618, Avg batch loss: 0.5108, Avg batch acc: 0.4092
Train, Epoch: 1, Batch: 1398, Step num: 1398, Learning rate: 0.00097688, Avg batch loss: 0.5218, Avg batch acc: 0.4431
Train, Epoch: 1, Batch: 1399, Step num: 1399, Learning rate: 0.00097758, Avg batch loss: 0.5364, Avg batch acc: 0.4223
Train, Epoch: 1, Batch: 1400, Step num: 1400, Learning rate: 0.00097828, Avg batch loss: 0.5643, Avg batch acc: 0.4233
Train, Epoch: 1, Batch: 1401, Step num: 1401, Learning rate: 0.00097898, Avg batch loss: 0.5838, Avg batch acc: 0.4081
Train, Epoch: 1, Batch: 1402, Step num: 1402, Learning rate: 0.00097968, Avg batch loss: 0.5203, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 1403, Step num: 1403, Learning rate: 0.00098038, Avg batch loss: 0.5303, Avg batch acc: 0.4392
Train, Epoch: 1, Batch: 1404, Step num: 1404, Learning rate: 0.00098107, Avg batch loss: 0.4923, Avg batch acc: 0.4374
Train, Epoch: 1, Batch: 1405, Step num: 1405, Learning rate: 0.00098177, Avg batch loss: 0.5316, Avg batch acc: 0.4109
Train, Epoch: 1, Batch: 1406, Step num: 1406, Learning rate: 0.00098247, Avg batch loss: 0.5486, Avg batch acc: 0.4405
Train, Epoch: 1, Batch: 1407, Step num: 1407, Learning rate: 0.00098317, Avg batch loss: 0.4879, Avg batch acc: 0.4311
Train, Epoch: 1, Batch: 1408, Step num: 1408, Learning rate: 0.00098387, Avg batch loss: 0.4678, Avg batch acc: 0.4403
Train, Epoch: 1, Batch: 1409, Step num: 1409, Learning rate: 0.00098457, Avg batch loss: 0.5303, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 1410, Step num: 1410, Learning rate: 0.00098527, Avg batch loss: 0.5461, Avg batch acc: 0.4248
Train, Epoch: 1, Batch: 1411, Step num: 1411, Learning rate: 0.00098597, Avg batch loss: 0.5118, Avg batch acc: 0.4245
Train, Epoch: 1, Batch: 1412, Step num: 1412, Learning rate: 0.00098666, Avg batch loss: 0.5543, Avg batch acc: 0.4196
Train, Epoch: 1, Batch: 1413, Step num: 1413, Learning rate: 0.00098736, Avg batch loss: 0.4935, Avg batch acc: 0.4318
Train, Epoch: 1, Batch: 1414, Step num: 1414, Learning rate: 0.00098806, Avg batch loss: 0.5922, Avg batch acc: 0.4393
Train, Epoch: 1, Batch: 1415, Step num: 1415, Learning rate: 0.00098876, Avg batch loss: 0.5357, Avg batch acc: 0.4311
Train, Epoch: 1, Batch: 1416, Step num: 1416, Learning rate: 0.00098946, Avg batch loss: 0.5251, Avg batch acc: 0.4252
Train, Epoch: 1, Batch: 1417, Step num: 1417, Learning rate: 0.00099016, Avg batch loss: 0.5121, Avg batch acc: 0.4310
Train, Epoch: 1, Batch: 1418, Step num: 1418, Learning rate: 0.00099086, Avg batch loss: 0.5566, Avg batch acc: 0.4333
Train, Epoch: 1, Batch: 1419, Step num: 1419, Learning rate: 0.00099156, Avg batch loss: 0.5067, Avg batch acc: 0.4092
Train, Epoch: 1, Batch: 1420, Step num: 1420, Learning rate: 0.00099226, Avg batch loss: 0.5321, Avg batch acc: 0.4340
Train, Epoch: 1, Batch: 1421, Step num: 1421, Learning rate: 0.00099295, Avg batch loss: 0.5126, Avg batch acc: 0.4435
Train, Epoch: 1, Batch: 1422, Step num: 1422, Learning rate: 0.00099365, Avg batch loss: 0.4951, Avg batch acc: 0.4154
Train, Epoch: 1, Batch: 1423, Step num: 1423, Learning rate: 0.00099435, Avg batch loss: 0.5414, Avg batch acc: 0.4192
Train, Epoch: 1, Batch: 1424, Step num: 1424, Learning rate: 0.00099505, Avg batch loss: 0.5727, Avg batch acc: 0.4138
Train, Epoch: 1, Batch: 1425, Step num: 1425, Learning rate: 0.00099575, Avg batch loss: 0.5360, Avg batch acc: 0.4000
Train, Epoch: 1, Batch: 1426, Step num: 1426, Learning rate: 0.00099645, Avg batch loss: 0.5134, Avg batch acc: 0.4390
Train, Epoch: 1, Batch: 1427, Step num: 1427, Learning rate: 0.00099715, Avg batch loss: 0.5438, Avg batch acc: 0.4317
Train, Epoch: 1, Batch: 1428, Step num: 1428, Learning rate: 0.00099785, Avg batch loss: 0.5139, Avg batch acc: 0.4294
Train, Epoch: 1, Batch: 1429, Step num: 1429, Learning rate: 0.00099854, Avg batch loss: 0.5307, Avg batch acc: 0.4411
Train, Epoch: 1, Batch: 1430, Step num: 1430, Learning rate: 0.00099924, Avg batch loss: 0.5777, Avg batch acc: 0.3995
Train, Epoch: 1, Batch: 1431, Step num: 1431, Learning rate: 0.00099994, Avg batch loss: 0.4809, Avg batch acc: 0.4326
Train, Epoch: 1, Batch: 1432, Step num: 1432, Learning rate: 0.00100064, Avg batch loss: 0.5343, Avg batch acc: 0.4324
Train, Epoch: 1, Batch: 1433, Step num: 1433, Learning rate: 0.00100134, Avg batch loss: 0.5269, Avg batch acc: 0.4260
Train, Epoch: 1, Batch: 1434, Step num: 1434, Learning rate: 0.00100204, Avg batch loss: 0.5239, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 1435, Step num: 1435, Learning rate: 0.00100274, Avg batch loss: 0.5561, Avg batch acc: 0.4281
Train, Epoch: 1, Batch: 1436, Step num: 1436, Learning rate: 0.00100344, Avg batch loss: 0.4975, Avg batch acc: 0.4439
Train, Epoch: 1, Batch: 1437, Step num: 1437, Learning rate: 0.00100413, Avg batch loss: 0.5125, Avg batch acc: 0.4397
Train, Epoch: 1, Batch: 1438, Step num: 1438, Learning rate: 0.00100483, Avg batch loss: 0.4869, Avg batch acc: 0.4397
Train, Epoch: 1, Batch: 1439, Step num: 1439, Learning rate: 0.00100553, Avg batch loss: 0.5295, Avg batch acc: 0.4210
Train, Epoch: 1, Batch: 1440, Step num: 1440, Learning rate: 0.00100623, Avg batch loss: 0.5771, Avg batch acc: 0.4255
Train, Epoch: 1, Batch: 1441, Step num: 1441, Learning rate: 0.00100693, Avg batch loss: 0.5467, Avg batch acc: 0.4395
Train, Epoch: 1, Batch: 1442, Step num: 1442, Learning rate: 0.00100763, Avg batch loss: 0.5736, Avg batch acc: 0.4069
Train, Epoch: 1, Batch: 1443, Step num: 1443, Learning rate: 0.00100833, Avg batch loss: 0.5568, Avg batch acc: 0.4123
Train, Epoch: 1, Batch: 1444, Step num: 1444, Learning rate: 0.00100903, Avg batch loss: 0.5239, Avg batch acc: 0.4283
Train, Epoch: 1, Batch: 1445, Step num: 1445, Learning rate: 0.00100972, Avg batch loss: 0.5679, Avg batch acc: 0.4435
Train, Epoch: 1, Batch: 1446, Step num: 1446, Learning rate: 0.00101042, Avg batch loss: 0.5223, Avg batch acc: 0.4323
Train, Epoch: 1, Batch: 1447, Step num: 1447, Learning rate: 0.00101112, Avg batch loss: 0.5503, Avg batch acc: 0.4422
Train, Epoch: 1, Batch: 1448, Step num: 1448, Learning rate: 0.00101182, Avg batch loss: 0.5017, Avg batch acc: 0.4535
Train, Epoch: 1, Batch: 1449, Step num: 1449, Learning rate: 0.00101252, Avg batch loss: 0.5090, Avg batch acc: 0.4247
Train, Epoch: 1, Batch: 1450, Step num: 1450, Learning rate: 0.00101322, Avg batch loss: 0.5480, Avg batch acc: 0.4213
Train, Epoch: 1, Batch: 1451, Step num: 1451, Learning rate: 0.00101392, Avg batch loss: 0.6199, Avg batch acc: 0.4222
Train, Epoch: 1, Batch: 1452, Step num: 1452, Learning rate: 0.00101462, Avg batch loss: 0.4923, Avg batch acc: 0.4579
Train, Epoch: 1, Batch: 1453, Step num: 1453, Learning rate: 0.00101531, Avg batch loss: 0.5349, Avg batch acc: 0.4254
Train, Epoch: 1, Batch: 1454, Step num: 1454, Learning rate: 0.00101601, Avg batch loss: 0.5133, Avg batch acc: 0.4148
Train, Epoch: 1, Batch: 1455, Step num: 1455, Learning rate: 0.00101671, Avg batch loss: 0.4986, Avg batch acc: 0.4160
Train, Epoch: 1, Batch: 1456, Step num: 1456, Learning rate: 0.00101741, Avg batch loss: 0.4617, Avg batch acc: 0.4477
Train, Epoch: 1, Batch: 1457, Step num: 1457, Learning rate: 0.00101811, Avg batch loss: 0.5117, Avg batch acc: 0.4384
Train, Epoch: 1, Batch: 1458, Step num: 1458, Learning rate: 0.00101881, Avg batch loss: 0.5381, Avg batch acc: 0.4138
Train, Epoch: 1, Batch: 1459, Step num: 1459, Learning rate: 0.00101951, Avg batch loss: 0.4919, Avg batch acc: 0.4240
Train, Epoch: 1, Batch: 1460, Step num: 1460, Learning rate: 0.00102021, Avg batch loss: 0.5762, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 1461, Step num: 1461, Learning rate: 0.00102090, Avg batch loss: 0.5670, Avg batch acc: 0.4319
Train, Epoch: 1, Batch: 1462, Step num: 1462, Learning rate: 0.00102160, Avg batch loss: 0.5017, Avg batch acc: 0.4460
Train, Epoch: 1, Batch: 1463, Step num: 1463, Learning rate: 0.00102230, Avg batch loss: 0.4700, Avg batch acc: 0.4496
Train, Epoch: 1, Batch: 1464, Step num: 1464, Learning rate: 0.00102300, Avg batch loss: 0.4906, Avg batch acc: 0.4300
Train, Epoch: 1, Batch: 1465, Step num: 1465, Learning rate: 0.00102370, Avg batch loss: 0.5426, Avg batch acc: 0.4238
Train, Epoch: 1, Batch: 1466, Step num: 1466, Learning rate: 0.00102440, Avg batch loss: 0.4926, Avg batch acc: 0.4407
Train, Epoch: 1, Batch: 1467, Step num: 1467, Learning rate: 0.00102510, Avg batch loss: 0.5396, Avg batch acc: 0.4153
Train, Epoch: 1, Batch: 1468, Step num: 1468, Learning rate: 0.00102580, Avg batch loss: 0.5910, Avg batch acc: 0.4308
Train, Epoch: 1, Batch: 1469, Step num: 1469, Learning rate: 0.00102649, Avg batch loss: 0.5184, Avg batch acc: 0.4413
Train, Epoch: 1, Batch: 1470, Step num: 1470, Learning rate: 0.00102719, Avg batch loss: 0.5427, Avg batch acc: 0.4104
Train, Epoch: 1, Batch: 1471, Step num: 1471, Learning rate: 0.00102789, Avg batch loss: 0.4972, Avg batch acc: 0.4380
Train, Epoch: 1, Batch: 1472, Step num: 1472, Learning rate: 0.00102859, Avg batch loss: 0.5672, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1473, Step num: 1473, Learning rate: 0.00102929, Avg batch loss: 0.4944, Avg batch acc: 0.4434
Train, Epoch: 1, Batch: 1474, Step num: 1474, Learning rate: 0.00102999, Avg batch loss: 0.4973, Avg batch acc: 0.4268
Train, Epoch: 1, Batch: 1475, Step num: 1475, Learning rate: 0.00103069, Avg batch loss: 0.5508, Avg batch acc: 0.4293
Train, Epoch: 1, Batch: 1476, Step num: 1476, Learning rate: 0.00103139, Avg batch loss: 0.4957, Avg batch acc: 0.4505
Train, Epoch: 1, Batch: 1477, Step num: 1477, Learning rate: 0.00103209, Avg batch loss: 0.5560, Avg batch acc: 0.4500
Train, Epoch: 1, Batch: 1478, Step num: 1478, Learning rate: 0.00103278, Avg batch loss: 0.5507, Avg batch acc: 0.4100
Train, Epoch: 1, Batch: 1479, Step num: 1479, Learning rate: 0.00103348, Avg batch loss: 0.5793, Avg batch acc: 0.4231
Train, Epoch: 1, Batch: 1480, Step num: 1480, Learning rate: 0.00103418, Avg batch loss: 0.5962, Avg batch acc: 0.4311
Train, Epoch: 1, Batch: 1481, Step num: 1481, Learning rate: 0.00103488, Avg batch loss: 0.5282, Avg batch acc: 0.4303
Train, Epoch: 1, Batch: 1482, Step num: 1482, Learning rate: 0.00103558, Avg batch loss: 0.5148, Avg batch acc: 0.4269
Train, Epoch: 1, Batch: 1483, Step num: 1483, Learning rate: 0.00103628, Avg batch loss: 0.5112, Avg batch acc: 0.4331
Train, Epoch: 1, Batch: 1484, Step num: 1484, Learning rate: 0.00103698, Avg batch loss: 0.5387, Avg batch acc: 0.4280
Train, Epoch: 1, Batch: 1485, Step num: 1485, Learning rate: 0.00103768, Avg batch loss: 0.4834, Avg batch acc: 0.4544
Train, Epoch: 1, Batch: 1486, Step num: 1486, Learning rate: 0.00103837, Avg batch loss: 0.5555, Avg batch acc: 0.4481
Train, Epoch: 1, Batch: 1487, Step num: 1487, Learning rate: 0.00103907, Avg batch loss: 0.5195, Avg batch acc: 0.4465
Train, Epoch: 1, Batch: 1488, Step num: 1488, Learning rate: 0.00103977, Avg batch loss: 0.5249, Avg batch acc: 0.4441
Train, Epoch: 1, Batch: 1489, Step num: 1489, Learning rate: 0.00104047, Avg batch loss: 0.5834, Avg batch acc: 0.4271
Train, Epoch: 1, Batch: 1490, Step num: 1490, Learning rate: 0.00104117, Avg batch loss: 0.4631, Avg batch acc: 0.4512
Train, Epoch: 1, Batch: 1491, Step num: 1491, Learning rate: 0.00104187, Avg batch loss: 0.5412, Avg batch acc: 0.4326
Train, Epoch: 1, Batch: 1492, Step num: 1492, Learning rate: 0.00104257, Avg batch loss: 0.5839, Avg batch acc: 0.4127
Train, Epoch: 1, Batch: 1493, Step num: 1493, Learning rate: 0.00104327, Avg batch loss: 0.5175, Avg batch acc: 0.4570
Train, Epoch: 1, Batch: 1494, Step num: 1494, Learning rate: 0.00104396, Avg batch loss: 0.4824, Avg batch acc: 0.4580
Train, Epoch: 1, Batch: 1495, Step num: 1495, Learning rate: 0.00104466, Avg batch loss: 0.5393, Avg batch acc: 0.4350
Train, Epoch: 1, Batch: 1496, Step num: 1496, Learning rate: 0.00104536, Avg batch loss: 0.5439, Avg batch acc: 0.4372
Train, Epoch: 1, Batch: 1497, Step num: 1497, Learning rate: 0.00104606, Avg batch loss: 0.4812, Avg batch acc: 0.4503
Train, Epoch: 1, Batch: 1498, Step num: 1498, Learning rate: 0.00104676, Avg batch loss: 0.5427, Avg batch acc: 0.4075
Train, Epoch: 1, Batch: 1499, Step num: 1499, Learning rate: 0.00104746, Avg batch loss: 0.4874, Avg batch acc: 0.4501
Train, Epoch: 1, Batch: 1500, Step num: 1500, Learning rate: 0.00104816, Avg batch loss: 0.5326, Avg batch acc: 0.4545
Train, Epoch: 1, Batch: 1501, Step num: 1501, Learning rate: 0.00104886, Avg batch loss: 0.5025, Avg batch acc: 0.4334
Train, Epoch: 1, Batch: 1502, Step num: 1502, Learning rate: 0.00104955, Avg batch loss: 0.5017, Avg batch acc: 0.4359
Train, Epoch: 1, Batch: 1503, Step num: 1503, Learning rate: 0.00105025, Avg batch loss: 0.5412, Avg batch acc: 0.4202
Train, Epoch: 1, Batch: 1504, Step num: 1504, Learning rate: 0.00105095, Avg batch loss: 0.5160, Avg batch acc: 0.4372
Train, Epoch: 1, Batch: 1505, Step num: 1505, Learning rate: 0.00105165, Avg batch loss: 0.5297, Avg batch acc: 0.4388
Train, Epoch: 1, Batch: 1506, Step num: 1506, Learning rate: 0.00105235, Avg batch loss: 0.5797, Avg batch acc: 0.4177
Train, Epoch: 1, Batch: 1507, Step num: 1507, Learning rate: 0.00105305, Avg batch loss: 0.5205, Avg batch acc: 0.4389
Train, Epoch: 1, Batch: 1508, Step num: 1508, Learning rate: 0.00105375, Avg batch loss: 0.5222, Avg batch acc: 0.4434
Train, Epoch: 1, Batch: 1509, Step num: 1509, Learning rate: 0.00105445, Avg batch loss: 0.5377, Avg batch acc: 0.4363
Train, Epoch: 1, Batch: 1510, Step num: 1510, Learning rate: 0.00105514, Avg batch loss: 0.5160, Avg batch acc: 0.4377
Train, Epoch: 1, Batch: 1511, Step num: 1511, Learning rate: 0.00105584, Avg batch loss: 0.5245, Avg batch acc: 0.4432
Train, Epoch: 1, Batch: 1512, Step num: 1512, Learning rate: 0.00105654, Avg batch loss: 0.5028, Avg batch acc: 0.4478
Train, Epoch: 1, Batch: 1513, Step num: 1513, Learning rate: 0.00105724, Avg batch loss: 0.5136, Avg batch acc: 0.4036
Train, Epoch: 1, Batch: 1514, Step num: 1514, Learning rate: 0.00105794, Avg batch loss: 0.5495, Avg batch acc: 0.4334
Train, Epoch: 1, Batch: 1515, Step num: 1515, Learning rate: 0.00105864, Avg batch loss: 0.4907, Avg batch acc: 0.4494
Train, Epoch: 1, Batch: 1516, Step num: 1516, Learning rate: 0.00105934, Avg batch loss: 0.5226, Avg batch acc: 0.4295
Train, Epoch: 1, Batch: 1517, Step num: 1517, Learning rate: 0.00106004, Avg batch loss: 0.5999, Avg batch acc: 0.4008
Train, Epoch: 1, Batch: 1518, Step num: 1518, Learning rate: 0.00106073, Avg batch loss: 0.5607, Avg batch acc: 0.4380
Train, Epoch: 1, Batch: 1519, Step num: 1519, Learning rate: 0.00106143, Avg batch loss: 0.5443, Avg batch acc: 0.4405
Train, Epoch: 1, Avg epoch loss: 0.7312, Avg epoch acc: 0.3481, Overall time: 420.7 s, Speed: 10345.2 tokens/s on cuda:0

Validate, Epoch: 1, Batch: 1, Avg batch loss: 0.5354, Avg batch acc: 0.4240
Validate, Epoch: 1, Batch: 2, Avg batch loss: 0.5670, Avg batch acc: 0.4058
Validate, Epoch: 1, Batch: 3, Avg batch loss: 0.4927, Avg batch acc: 0.4351
Validate, Epoch: 1, Batch: 4, Avg batch loss: 0.5231, Avg batch acc: 0.4244
Validate, Epoch: 1, Batch: 5, Avg batch loss: 0.4778, Avg batch acc: 0.4361
Validate, Epoch: 1, Batch: 6, Avg batch loss: 0.5211, Avg batch acc: 0.4281
Validate, Epoch: 1, Batch: 7, Avg batch loss: 0.5184, Avg batch acc: 0.4226
Validate, Epoch: 1, Batch: 8, Avg batch loss: 0.5490, Avg batch acc: 0.4290
Validate, Epoch: 1, Batch: 9, Avg batch loss: 0.5210, Avg batch acc: 0.4155
Validate, Epoch: 1, Batch: 10, Avg batch loss: 0.5049, Avg batch acc: 0.4257
Validate, Epoch: 1, Batch: 11, Avg batch loss: 0.5465, Avg batch acc: 0.4222
Validate, Epoch: 1, Batch: 12, Avg batch loss: 0.4418, Avg batch acc: 0.4466
Validate, Epoch: 1, Batch: 13, Avg batch loss: 0.5543, Avg batch acc: 0.4000
Validate, Epoch: 1, Batch: 14, Avg batch loss: 0.4856, Avg batch acc: 0.4403
Validate, Epoch: 1, Batch: 15, Avg batch loss: 0.5624, Avg batch acc: 0.4303
Validate, Epoch: 1, Batch: 16, Avg batch loss: 0.4639, Avg batch acc: 0.4614
Validate, Epoch: 1, Batch: 17, Avg batch loss: 0.5647, Avg batch acc: 0.4031
Validate, Epoch: 1, Batch: 18, Avg batch loss: 0.4500, Avg batch acc: 0.4395
Validate, Epoch: 1, Batch: 19, Avg batch loss: 0.5133, Avg batch acc: 0.4244
Validate, Epoch: 1, Batch: 20, Avg batch loss: 0.4810, Avg batch acc: 0.4430
Validate, Epoch: 1, Batch: 21, Avg batch loss: 0.5072, Avg batch acc: 0.4031
Validate, Epoch: 1, Batch: 22, Avg batch loss: 0.5350, Avg batch acc: 0.4283
Validate, Epoch: 1, Batch: 23, Avg batch loss: 0.5234, Avg batch acc: 0.4105
Validate, Epoch: 1, Batch: 24, Avg batch loss: 0.5374, Avg batch acc: 0.4100
Validate, Epoch: 1, Batch: 25, Avg batch loss: 0.4995, Avg batch acc: 0.4328
Validate, Epoch: 1, Batch: 26, Avg batch loss: 0.5648, Avg batch acc: 0.4277
Validate, Epoch: 1, Batch: 27, Avg batch loss: 0.5336, Avg batch acc: 0.4282
Validate, Epoch: 1, Batch: 28, Avg batch loss: 0.5797, Avg batch acc: 0.4188
Validate, Epoch: 1, Batch: 29, Avg batch loss: 0.5209, Avg batch acc: 0.4465
Validate, Epoch: 1, Batch: 30, Avg batch loss: 0.4979, Avg batch acc: 0.4376
Validate, Epoch: 1, Batch: 31, Avg batch loss: 0.4989, Avg batch acc: 0.4522
Validate, Epoch: 1, Batch: 32, Avg batch loss: 0.5488, Avg batch acc: 0.4272
Validate, Epoch: 1, Batch: 33, Avg batch loss: 0.5486, Avg batch acc: 0.4128
Validate, Epoch: 1, Batch: 34, Avg batch loss: 0.5468, Avg batch acc: 0.4209
Validate, Epoch: 1, Batch: 35, Avg batch loss: 0.4897, Avg batch acc: 0.4369
Validate, Epoch: 1, Batch: 36, Avg batch loss: 0.5561, Avg batch acc: 0.4224
Validate, Epoch: 1, Batch: 37, Avg batch loss: 0.5939, Avg batch acc: 0.4144
Validate, Epoch: 1, Batch: 38, Avg batch loss: 0.5536, Avg batch acc: 0.3984
Validate, Epoch: 1, Batch: 39, Avg batch loss: 0.4960, Avg batch acc: 0.4329
Validate, Epoch: 1, Batch: 40, Avg batch loss: 0.4920, Avg batch acc: 0.4191
Validate, Epoch: 1, Batch: 41, Avg batch loss: 0.5178, Avg batch acc: 0.4405
Validate, Epoch: 1, Batch: 42, Avg batch loss: 0.5324, Avg batch acc: 0.4376
Validate, Epoch: 1, Batch: 43, Avg batch loss: 0.6320, Avg batch acc: 0.3880
Validate, Epoch: 1, Batch: 44, Avg batch loss: 0.4974, Avg batch acc: 0.4105
Validate, Epoch: 1, Batch: 45, Avg batch loss: 0.4856, Avg batch acc: 0.4418
Validate, Epoch: 1, Batch: 46, Avg batch loss: 0.5583, Avg batch acc: 0.4378
Validate, Epoch: 1, Batch: 47, Avg batch loss: 0.4884, Avg batch acc: 0.4187
Validate, Epoch: 1, Batch: 48, Avg batch loss: 0.5705, Avg batch acc: 0.4197
Validate, Epoch: 1, Batch: 49, Avg batch loss: 0.5111, Avg batch acc: 0.4133
Validate, Epoch: 1, Batch: 50, Avg batch loss: 0.4772, Avg batch acc: 0.4398
Validate, Epoch: 1, Batch: 51, Avg batch loss: 0.5909, Avg batch acc: 0.4162
Validate, Epoch: 1, Batch: 52, Avg batch loss: 0.4853, Avg batch acc: 0.4505
Validate, Epoch: 1, Batch: 53, Avg batch loss: 0.5391, Avg batch acc: 0.4069
Validate, Epoch: 1, Batch: 54, Avg batch loss: 0.5110, Avg batch acc: 0.4508
Validate, Epoch: 1, Batch: 55, Avg batch loss: 0.4969, Avg batch acc: 0.4309
Validate, Epoch: 1, Batch: 56, Avg batch loss: 0.4939, Avg batch acc: 0.4180
Validate, Epoch: 1, Batch: 57, Avg batch loss: 0.5497, Avg batch acc: 0.4123
Validate, Epoch: 1, Batch: 58, Avg batch loss: 0.4934, Avg batch acc: 0.4292
Validate, Epoch: 1, Batch: 59, Avg batch loss: 0.5578, Avg batch acc: 0.4374
Validate, Epoch: 1, Batch: 60, Avg batch loss: 0.4790, Avg batch acc: 0.4383
Validate, Epoch: 1, Batch: 61, Avg batch loss: 0.5242, Avg batch acc: 0.4419
Validate, Epoch: 1, Batch: 62, Avg batch loss: 0.5555, Avg batch acc: 0.4102
Validate, Epoch: 1, Batch: 63, Avg batch loss: 0.5015, Avg batch acc: 0.4431
Validate, Epoch: 1, Batch: 64, Avg batch loss: 0.5625, Avg batch acc: 0.4190
Validate, Epoch: 1, Batch: 65, Avg batch loss: 0.5133, Avg batch acc: 0.4390
Validate, Epoch: 1, Batch: 66, Avg batch loss: 0.5072, Avg batch acc: 0.4288
Validate, Epoch: 1, Batch: 67, Avg batch loss: 0.5378, Avg batch acc: 0.4108
Validate, Epoch: 1, Batch: 68, Avg batch loss: 0.5203, Avg batch acc: 0.4441
Validate, Epoch: 1, Batch: 69, Avg batch loss: 0.5160, Avg batch acc: 0.4175
Validate, Epoch: 1, Batch: 70, Avg batch loss: 0.5570, Avg batch acc: 0.4340
Validate, Epoch: 1, Batch: 71, Avg batch loss: 0.5335, Avg batch acc: 0.4242
Validate, Epoch: 1, Batch: 72, Avg batch loss: 0.4832, Avg batch acc: 0.4376
Validate, Epoch: 1, Batch: 73, Avg batch loss: 0.4901, Avg batch acc: 0.4360
Validate, Epoch: 1, Batch: 74, Avg batch loss: 0.5675, Avg batch acc: 0.4241
Validate, Epoch: 1, Batch: 75, Avg batch loss: 0.4841, Avg batch acc: 0.4619
Validate, Epoch: 1, Batch: 76, Avg batch loss: 0.5200, Avg batch acc: 0.4205
Validate, Epoch: 1, Batch: 77, Avg batch loss: 0.5281, Avg batch acc: 0.4220
Validate, Epoch: 1, Batch: 78, Avg batch loss: 0.5285, Avg batch acc: 0.4359
Validate, Epoch: 1, Batch: 79, Avg batch loss: 0.5185, Avg batch acc: 0.4298
Validate, Epoch: 1, Batch: 80, Avg batch loss: 0.5811, Avg batch acc: 0.3973
Validate, Epoch: 1, Batch: 81, Avg batch loss: 0.5516, Avg batch acc: 0.4159
Validate, Epoch: 1, Batch: 82, Avg batch loss: 0.5156, Avg batch acc: 0.4390
Validate, Epoch: 1, Batch: 83, Avg batch loss: 0.5362, Avg batch acc: 0.4421
Validate, Epoch: 1, Batch: 84, Avg batch loss: 0.5042, Avg batch acc: 0.4548
Validate, Epoch: 1, Batch: 85, Avg batch loss: 0.4958, Avg batch acc: 0.4363
Validate, Epoch: 1, Batch: 86, Avg batch loss: 0.5179, Avg batch acc: 0.4264
Validate, Epoch: 1, Batch: 87, Avg batch loss: 0.5608, Avg batch acc: 0.4331
Validate, Epoch: 1, Batch: 88, Avg batch loss: 0.5458, Avg batch acc: 0.4308
Validate, Epoch: 1, Batch: 89, Avg batch loss: 0.5506, Avg batch acc: 0.4320
Validate, Epoch: 1, Batch: 90, Avg batch loss: 0.5108, Avg batch acc: 0.4324
Validate, Epoch: 1, Batch: 91, Avg batch loss: 0.5268, Avg batch acc: 0.4262
Validate, Epoch: 1, Batch: 92, Avg batch loss: 0.5020, Avg batch acc: 0.4555
Validate, Epoch: 1, Batch: 93, Avg batch loss: 0.5372, Avg batch acc: 0.4185
Validate, Epoch: 1, Batch: 94, Avg batch loss: 0.5418, Avg batch acc: 0.4127
Validate, Epoch: 1, Batch: 95, Avg batch loss: 0.6119, Avg batch acc: 0.4000
Validate, Epoch: 1, Batch: 96, Avg batch loss: 0.5299, Avg batch acc: 0.4339
Validate, Epoch: 1, Batch: 97, Avg batch loss: 0.5274, Avg batch acc: 0.4390
Validate, Epoch: 1, Batch: 98, Avg batch loss: 0.5143, Avg batch acc: 0.4261
Validate, Epoch: 1, Batch: 99, Avg batch loss: 0.5391, Avg batch acc: 0.4165
Validate, Epoch: 1, Batch: 100, Avg batch loss: 0.4587, Avg batch acc: 0.4335
Validate, Epoch: 1, Batch: 101, Avg batch loss: 0.5142, Avg batch acc: 0.4381
Validate, Epoch: 1, Batch: 102, Avg batch loss: 0.5036, Avg batch acc: 0.4385
Validate, Epoch: 1, Batch: 103, Avg batch loss: 0.4419, Avg batch acc: 0.4478
Validate, Epoch: 1, Batch: 104, Avg batch loss: 0.5312, Avg batch acc: 0.4231
Validate, Epoch: 1, Batch: 105, Avg batch loss: 0.5882, Avg batch acc: 0.4259
Validate, Epoch: 1, Batch: 106, Avg batch loss: 0.4783, Avg batch acc: 0.4425
Validate, Epoch: 1, Batch: 107, Avg batch loss: 0.5625, Avg batch acc: 0.4018
Validate, Epoch: 1, Batch: 108, Avg batch loss: 0.5178, Avg batch acc: 0.4148
Validate, Epoch: 1, Batch: 109, Avg batch loss: 0.4996, Avg batch acc: 0.4102
Validate, Epoch: 1, Batch: 110, Avg batch loss: 0.5185, Avg batch acc: 0.4198
Validate, Epoch: 1, Batch: 111, Avg batch loss: 0.5400, Avg batch acc: 0.4279
Validate, Epoch: 1, Batch: 112, Avg batch loss: 0.4969, Avg batch acc: 0.4204
Validate, Epoch: 1, Batch: 113, Avg batch loss: 0.5486, Avg batch acc: 0.4151
Validate, Epoch: 1, Batch: 114, Avg batch loss: 0.5089, Avg batch acc: 0.4296
Validate, Epoch: 1, Batch: 115, Avg batch loss: 0.5757, Avg batch acc: 0.4155
Validate, Epoch: 1, Batch: 116, Avg batch loss: 0.5325, Avg batch acc: 0.4199
Validate, Epoch: 1, Batch: 117, Avg batch loss: 0.4993, Avg batch acc: 0.4392
Validate, Epoch: 1, Batch: 118, Avg batch loss: 0.5354, Avg batch acc: 0.4011
Validate, Epoch: 1, Batch: 119, Avg batch loss: 0.5155, Avg batch acc: 0.4305
Validate, Epoch: 1, Batch: 120, Avg batch loss: 0.5228, Avg batch acc: 0.4400
Validate, Epoch: 1, Batch: 121, Avg batch loss: 0.5687, Avg batch acc: 0.4206
Validate, Epoch: 1, Batch: 122, Avg batch loss: 0.5024, Avg batch acc: 0.4236
Validate, Epoch: 1, Batch: 123, Avg batch loss: 0.5913, Avg batch acc: 0.4060
Validate, Epoch: 1, Batch: 124, Avg batch loss: 0.5025, Avg batch acc: 0.4289
Validate, Epoch: 1, Batch: 125, Avg batch loss: 0.5172, Avg batch acc: 0.4246
Validate, Epoch: 1, Batch: 126, Avg batch loss: 0.4849, Avg batch acc: 0.4237
Validate, Epoch: 1, Batch: 127, Avg batch loss: 0.5223, Avg batch acc: 0.4251
Validate, Epoch: 1, Batch: 128, Avg batch loss: 0.5110, Avg batch acc: 0.4359
Validate, Epoch: 1, Batch: 129, Avg batch loss: 0.5051, Avg batch acc: 0.4408
Validate, Epoch: 1, Batch: 130, Avg batch loss: 0.5020, Avg batch acc: 0.4433
Validate, Epoch: 1, Batch: 131, Avg batch loss: 0.4919, Avg batch acc: 0.4426
Validate, Epoch: 1, Batch: 132, Avg batch loss: 0.5796, Avg batch acc: 0.4120
Validate, Epoch: 1, Batch: 133, Avg batch loss: 0.5327, Avg batch acc: 0.4101
Validate, Epoch: 1, Batch: 134, Avg batch loss: 0.5023, Avg batch acc: 0.4223
Validate, Epoch: 1, Batch: 135, Avg batch loss: 0.5382, Avg batch acc: 0.4204
Validate, Epoch: 1, Batch: 136, Avg batch loss: 0.5322, Avg batch acc: 0.4322
Validate, Epoch: 1, Batch: 137, Avg batch loss: 0.4491, Avg batch acc: 0.4358
Validate, Epoch: 1, Batch: 138, Avg batch loss: 0.5459, Avg batch acc: 0.4097
Validate, Epoch: 1, Batch: 139, Avg batch loss: 0.5414, Avg batch acc: 0.4087
Validate, Epoch: 1, Batch: 140, Avg batch loss: 0.5263, Avg batch acc: 0.4456
Validate, Epoch: 1, Batch: 141, Avg batch loss: 0.5016, Avg batch acc: 0.4355
Validate, Epoch: 1, Batch: 142, Avg batch loss: 0.4630, Avg batch acc: 0.4561
Validate, Epoch: 1, Batch: 143, Avg batch loss: 0.5156, Avg batch acc: 0.4357
Validate, Epoch: 1, Batch: 144, Avg batch loss: 0.5197, Avg batch acc: 0.4440
Validate, Epoch: 1, Batch: 145, Avg batch loss: 0.5318, Avg batch acc: 0.4402
Validate, Epoch: 1, Batch: 146, Avg batch loss: 0.4998, Avg batch acc: 0.4301
Validate, Epoch: 1, Batch: 147, Avg batch loss: 0.6016, Avg batch acc: 0.4098
Validate, Epoch: 1, Batch: 148, Avg batch loss: 0.5064, Avg batch acc: 0.4434
Validate, Epoch: 1, Batch: 149, Avg batch loss: 0.5364, Avg batch acc: 0.4162
Validate, Epoch: 1, Batch: 150, Avg batch loss: 0.4891, Avg batch acc: 0.4310
Validate, Epoch: 1, Batch: 151, Avg batch loss: 0.5013, Avg batch acc: 0.4381
Validate, Epoch: 1, Batch: 152, Avg batch loss: 0.4916, Avg batch acc: 0.4348
Validate, Epoch: 1, Batch: 153, Avg batch loss: 0.5256, Avg batch acc: 0.4313
Validate, Epoch: 1, Batch: 154, Avg batch loss: 0.5041, Avg batch acc: 0.4338
Validate, Epoch: 1, Batch: 155, Avg batch loss: 0.5341, Avg batch acc: 0.4415
Validate, Epoch: 1, Batch: 156, Avg batch loss: 0.5602, Avg batch acc: 0.4299
Validate, Epoch: 1, Batch: 157, Avg batch loss: 0.5329, Avg batch acc: 0.4400
Validate, Epoch: 1, Batch: 158, Avg batch loss: 0.5006, Avg batch acc: 0.4356
Validate, Epoch: 1, Batch: 159, Avg batch loss: 0.4927, Avg batch acc: 0.4365
Validate, Epoch: 1, Batch: 160, Avg batch loss: 0.5225, Avg batch acc: 0.4193
Validate, Epoch: 1, Batch: 161, Avg batch loss: 0.5337, Avg batch acc: 0.4238
Validate, Epoch: 1, Batch: 162, Avg batch loss: 0.5406, Avg batch acc: 0.4364
Validate, Epoch: 1, Batch: 163, Avg batch loss: 0.5121, Avg batch acc: 0.4265
Validate, Epoch: 1, Batch: 164, Avg batch loss: 0.5475, Avg batch acc: 0.4401
Validate, Epoch: 1, Batch: 165, Avg batch loss: 0.5214, Avg batch acc: 0.4335
Validate, Epoch: 1, Batch: 166, Avg batch loss: 0.5547, Avg batch acc: 0.4161
Validate, Epoch: 1, Batch: 167, Avg batch loss: 0.4983, Avg batch acc: 0.4228
Validate, Epoch: 1, Batch: 168, Avg batch loss: 0.5455, Avg batch acc: 0.4072
Validate, Epoch: 1, Batch: 169, Avg batch loss: 0.5108, Avg batch acc: 0.4520
Validate, Epoch: 1, Avg epoch loss: 0.5234, Avg epoch acc: 0.4279, Overall time: 18.2 s, Speed: 26554.4 tokens/s on cuda:0

Train, Epoch: 2, Batch: 1, Step num: 1520, Learning rate: 0.00106213, Avg batch loss: 0.4990, Avg batch acc: 0.4427
Train, Epoch: 2, Batch: 2, Step num: 1521, Learning rate: 0.00106283, Avg batch loss: 0.5491, Avg batch acc: 0.4229
Train, Epoch: 2, Batch: 3, Step num: 1522, Learning rate: 0.00106353, Avg batch loss: 0.5371, Avg batch acc: 0.4520
Train, Epoch: 2, Batch: 4, Step num: 1523, Learning rate: 0.00106423, Avg batch loss: 0.4916, Avg batch acc: 0.4266
Train, Epoch: 2, Batch: 5, Step num: 1524, Learning rate: 0.00106493, Avg batch loss: 0.4904, Avg batch acc: 0.4356
Train, Epoch: 2, Batch: 6, Step num: 1525, Learning rate: 0.00106563, Avg batch loss: 0.5394, Avg batch acc: 0.4489
Train, Epoch: 2, Batch: 7, Step num: 1526, Learning rate: 0.00106632, Avg batch loss: 0.5232, Avg batch acc: 0.4168
Train, Epoch: 2, Batch: 8, Step num: 1527, Learning rate: 0.00106702, Avg batch loss: 0.5349, Avg batch acc: 0.4347
Train, Epoch: 2, Batch: 9, Step num: 1528, Learning rate: 0.00106772, Avg batch loss: 0.5101, Avg batch acc: 0.4146
Train, Epoch: 2, Batch: 10, Step num: 1529, Learning rate: 0.00106842, Avg batch loss: 0.5077, Avg batch acc: 0.4506
Train, Epoch: 2, Batch: 11, Step num: 1530, Learning rate: 0.00106912, Avg batch loss: 0.5269, Avg batch acc: 0.4231
Train, Epoch: 2, Batch: 12, Step num: 1531, Learning rate: 0.00106982, Avg batch loss: 0.5017, Avg batch acc: 0.4471
Train, Epoch: 2, Batch: 13, Step num: 1532, Learning rate: 0.00107052, Avg batch loss: 0.5586, Avg batch acc: 0.4151
Train, Epoch: 2, Batch: 14, Step num: 1533, Learning rate: 0.00107122, Avg batch loss: 0.5226, Avg batch acc: 0.4280
Train, Epoch: 2, Batch: 15, Step num: 1534, Learning rate: 0.00107192, Avg batch loss: 0.5576, Avg batch acc: 0.4201
Train, Epoch: 2, Batch: 16, Step num: 1535, Learning rate: 0.00107261, Avg batch loss: 0.5009, Avg batch acc: 0.4403
Train, Epoch: 2, Batch: 17, Step num: 1536, Learning rate: 0.00107331, Avg batch loss: 0.5121, Avg batch acc: 0.4118
Train, Epoch: 2, Batch: 18, Step num: 1537, Learning rate: 0.00107401, Avg batch loss: 0.5237, Avg batch acc: 0.4214
Train, Epoch: 2, Batch: 19, Step num: 1538, Learning rate: 0.00107471, Avg batch loss: 0.4922, Avg batch acc: 0.4469
Train, Epoch: 2, Batch: 20, Step num: 1539, Learning rate: 0.00107541, Avg batch loss: 0.5339, Avg batch acc: 0.4259
Train, Epoch: 2, Batch: 21, Step num: 1540, Learning rate: 0.00107611, Avg batch loss: 0.5278, Avg batch acc: 0.4339
Train, Epoch: 2, Batch: 22, Step num: 1541, Learning rate: 0.00107681, Avg batch loss: 0.4825, Avg batch acc: 0.4561
Train, Epoch: 2, Batch: 23, Step num: 1542, Learning rate: 0.00107751, Avg batch loss: 0.5278, Avg batch acc: 0.4242
Train, Epoch: 2, Batch: 24, Step num: 1543, Learning rate: 0.00107820, Avg batch loss: 0.4846, Avg batch acc: 0.4674
Train, Epoch: 2, Batch: 25, Step num: 1544, Learning rate: 0.00107890, Avg batch loss: 0.5452, Avg batch acc: 0.4261
Train, Epoch: 2, Batch: 26, Step num: 1545, Learning rate: 0.00107960, Avg batch loss: 0.5294, Avg batch acc: 0.4386
Train, Epoch: 2, Batch: 27, Step num: 1546, Learning rate: 0.00108030, Avg batch loss: 0.5556, Avg batch acc: 0.4298
Train, Epoch: 2, Batch: 28, Step num: 1547, Learning rate: 0.00108100, Avg batch loss: 0.5147, Avg batch acc: 0.4334
Train, Epoch: 2, Batch: 29, Step num: 1548, Learning rate: 0.00108170, Avg batch loss: 0.5509, Avg batch acc: 0.4531
Train, Epoch: 2, Batch: 30, Step num: 1549, Learning rate: 0.00108240, Avg batch loss: 0.5192, Avg batch acc: 0.4351
Train, Epoch: 2, Batch: 31, Step num: 1550, Learning rate: 0.00108310, Avg batch loss: 0.5661, Avg batch acc: 0.4353
Train, Epoch: 2, Batch: 32, Step num: 1551, Learning rate: 0.00108379, Avg batch loss: 0.4696, Avg batch acc: 0.4617
Train, Epoch: 2, Batch: 33, Step num: 1552, Learning rate: 0.00108449, Avg batch loss: 0.4646, Avg batch acc: 0.4593
Train, Epoch: 2, Batch: 34, Step num: 1553, Learning rate: 0.00108519, Avg batch loss: 0.5608, Avg batch acc: 0.4051
Train, Epoch: 2, Batch: 35, Step num: 1554, Learning rate: 0.00108589, Avg batch loss: 0.4913, Avg batch acc: 0.4481
Train, Epoch: 2, Batch: 36, Step num: 1555, Learning rate: 0.00108659, Avg batch loss: 0.5282, Avg batch acc: 0.4408
Train, Epoch: 2, Batch: 37, Step num: 1556, Learning rate: 0.00108729, Avg batch loss: 0.5148, Avg batch acc: 0.4560
Train, Epoch: 2, Batch: 38, Step num: 1557, Learning rate: 0.00108799, Avg batch loss: 0.5465, Avg batch acc: 0.4226
Train, Epoch: 2, Batch: 39, Step num: 1558, Learning rate: 0.00108869, Avg batch loss: 0.5632, Avg batch acc: 0.4427
Train, Epoch: 2, Batch: 40, Step num: 1559, Learning rate: 0.00108938, Avg batch loss: 0.4998, Avg batch acc: 0.4392
Train, Epoch: 2, Batch: 41, Step num: 1560, Learning rate: 0.00109008, Avg batch loss: 0.5755, Avg batch acc: 0.4178
Train, Epoch: 2, Batch: 42, Step num: 1561, Learning rate: 0.00109078, Avg batch loss: 0.5111, Avg batch acc: 0.4470
Train, Epoch: 2, Batch: 43, Step num: 1562, Learning rate: 0.00109148, Avg batch loss: 0.5372, Avg batch acc: 0.4417
Train, Epoch: 2, Batch: 44, Step num: 1563, Learning rate: 0.00109218, Avg batch loss: 0.5594, Avg batch acc: 0.4303
Train, Epoch: 2, Batch: 45, Step num: 1564, Learning rate: 0.00109288, Avg batch loss: 0.4908, Avg batch acc: 0.4295
Train, Epoch: 2, Batch: 46, Step num: 1565, Learning rate: 0.00109358, Avg batch loss: 0.4465, Avg batch acc: 0.4363
Train, Epoch: 2, Batch: 47, Step num: 1566, Learning rate: 0.00109428, Avg batch loss: 0.5409, Avg batch acc: 0.4283
Train, Epoch: 2, Batch: 48, Step num: 1567, Learning rate: 0.00109497, Avg batch loss: 0.5022, Avg batch acc: 0.4476
Train, Epoch: 2, Batch: 49, Step num: 1568, Learning rate: 0.00109567, Avg batch loss: 0.4831, Avg batch acc: 0.4415
Train, Epoch: 2, Batch: 50, Step num: 1569, Learning rate: 0.00109637, Avg batch loss: 0.5479, Avg batch acc: 0.4091
Train, Epoch: 2, Batch: 51, Step num: 1570, Learning rate: 0.00109707, Avg batch loss: 0.5507, Avg batch acc: 0.4023
Train, Epoch: 2, Batch: 52, Step num: 1571, Learning rate: 0.00109777, Avg batch loss: 0.5285, Avg batch acc: 0.4307
Train, Epoch: 2, Batch: 53, Step num: 1572, Learning rate: 0.00109847, Avg batch loss: 0.4804, Avg batch acc: 0.4061
Train, Epoch: 2, Batch: 54, Step num: 1573, Learning rate: 0.00109917, Avg batch loss: 0.5282, Avg batch acc: 0.4234
Train, Epoch: 2, Batch: 55, Step num: 1574, Learning rate: 0.00109987, Avg batch loss: 0.4766, Avg batch acc: 0.4562
Train, Epoch: 2, Batch: 56, Step num: 1575, Learning rate: 0.00110056, Avg batch loss: 0.5343, Avg batch acc: 0.4628
Train, Epoch: 2, Batch: 57, Step num: 1576, Learning rate: 0.00110126, Avg batch loss: 0.5917, Avg batch acc: 0.4235
Train, Epoch: 2, Batch: 58, Step num: 1577, Learning rate: 0.00110196, Avg batch loss: 0.5150, Avg batch acc: 0.4199
Train, Epoch: 2, Batch: 59, Step num: 1578, Learning rate: 0.00110266, Avg batch loss: 0.4862, Avg batch acc: 0.4279
Train, Epoch: 2, Batch: 60, Step num: 1579, Learning rate: 0.00110336, Avg batch loss: 0.5200, Avg batch acc: 0.4097
Train, Epoch: 2, Batch: 61, Step num: 1580, Learning rate: 0.00110406, Avg batch loss: 0.5712, Avg batch acc: 0.4339
Train, Epoch: 2, Batch: 62, Step num: 1581, Learning rate: 0.00110476, Avg batch loss: 0.5090, Avg batch acc: 0.4454
Train, Epoch: 2, Batch: 63, Step num: 1582, Learning rate: 0.00110546, Avg batch loss: 0.5082, Avg batch acc: 0.4442
Train, Epoch: 2, Batch: 64, Step num: 1583, Learning rate: 0.00110615, Avg batch loss: 0.5576, Avg batch acc: 0.4381

Train, Epoch: 1, Batch: 1, Step num: 1, Learning rate: 0.00000070, Avg batch loss: 1.6797, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 2, Step num: 2, Learning rate: 0.00000140, Avg batch loss: 1.6388, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 3, Step num: 3, Learning rate: 0.00000210, Avg batch loss: 1.8171, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 4, Step num: 4, Learning rate: 0.00000280, Avg batch loss: 1.7208, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 5, Step num: 5, Learning rate: 0.00000349, Avg batch loss: 1.6878, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 6, Step num: 6, Learning rate: 0.00000419, Avg batch loss: 1.5458, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 7, Step num: 7, Learning rate: 0.00000489, Avg batch loss: 1.7514, Avg batch acc: 0.0007
Train, Epoch: 1, Batch: 8, Step num: 8, Learning rate: 0.00000559, Avg batch loss: 1.7947, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 9, Step num: 9, Learning rate: 0.00000629, Avg batch loss: 1.6577, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 10, Step num: 10, Learning rate: 0.00000699, Avg batch loss: 1.6594, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 11, Step num: 11, Learning rate: 0.00000769, Avg batch loss: 1.6778, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 12, Step num: 12, Learning rate: 0.00000839, Avg batch loss: 1.7395, Avg batch acc: 0.0011
Train, Epoch: 1, Batch: 13, Step num: 13, Learning rate: 0.00000908, Avg batch loss: 1.7136, Avg batch acc: 0.0037
Train, Epoch: 1, Batch: 14, Step num: 14, Learning rate: 0.00000978, Avg batch loss: 1.7159, Avg batch acc: 0.0014
Train, Epoch: 1, Batch: 15, Step num: 15, Learning rate: 0.00001048, Avg batch loss: 1.7739, Avg batch acc: 0.0017
Train, Epoch: 1, Batch: 16, Step num: 16, Learning rate: 0.00001118, Avg batch loss: 1.7410, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 17, Step num: 17, Learning rate: 0.00001188, Avg batch loss: 1.6001, Avg batch acc: 0.0024
Train, Epoch: 1, Batch: 18, Step num: 18, Learning rate: 0.00001258, Avg batch loss: 1.5924, Avg batch acc: 0.0015
Train, Epoch: 1, Batch: 19, Step num: 19, Learning rate: 0.00001328, Avg batch loss: 1.8353, Avg batch acc: 0.0015
Train, Epoch: 1, Batch: 20, Step num: 20, Learning rate: 0.00001398, Avg batch loss: 1.7338, Avg batch acc: 0.0009
Train, Epoch: 1, Batch: 21, Step num: 21, Learning rate: 0.00001467, Avg batch loss: 1.5979, Avg batch acc: 0.0036
Train, Epoch: 1, Batch: 22, Step num: 22, Learning rate: 0.00001537, Avg batch loss: 1.8300, Avg batch acc: 0.0038
Train, Epoch: 1, Batch: 23, Step num: 23, Learning rate: 0.00001607, Avg batch loss: 1.6271, Avg batch acc: 0.0046
Train, Epoch: 1, Batch: 24, Step num: 24, Learning rate: 0.00001677, Avg batch loss: 1.6400, Avg batch acc: 0.0042
Train, Epoch: 1, Batch: 25, Step num: 25, Learning rate: 0.00001747, Avg batch loss: 1.6331, Avg batch acc: 0.0029
Train, Epoch: 1, Batch: 26, Step num: 26, Learning rate: 0.00001817, Avg batch loss: 1.6240, Avg batch acc: 0.0019
Train, Epoch: 1, Batch: 27, Step num: 27, Learning rate: 0.00001887, Avg batch loss: 1.5854, Avg batch acc: 0.0026
Train, Epoch: 1, Batch: 28, Step num: 28, Learning rate: 0.00001957, Avg batch loss: 1.6811, Avg batch acc: 0.0025
Train, Epoch: 1, Batch: 29, Step num: 29, Learning rate: 0.00002026, Avg batch loss: 1.5692, Avg batch acc: 0.0045
Train, Epoch: 1, Batch: 30, Step num: 30, Learning rate: 0.00002096, Avg batch loss: 1.6776, Avg batch acc: 0.0042
Train, Epoch: 1, Batch: 31, Step num: 31, Learning rate: 0.00002166, Avg batch loss: 1.5413, Avg batch acc: 0.0049
Train, Epoch: 1, Batch: 32, Step num: 32, Learning rate: 0.00002236, Avg batch loss: 1.5546, Avg batch acc: 0.0127
Train, Epoch: 1, Batch: 33, Step num: 33, Learning rate: 0.00002306, Avg batch loss: 1.5507, Avg batch acc: 0.0160
Train, Epoch: 1, Batch: 34, Step num: 34, Learning rate: 0.00002376, Avg batch loss: 1.5596, Avg batch acc: 0.0267
Train, Epoch: 1, Batch: 35, Step num: 35, Learning rate: 0.00002446, Avg batch loss: 1.5475, Avg batch acc: 0.0288
Train, Epoch: 1, Batch: 36, Step num: 36, Learning rate: 0.00002516, Avg batch loss: 1.6031, Avg batch acc: 0.0366
Train, Epoch: 1, Batch: 37, Step num: 37, Learning rate: 0.00002585, Avg batch loss: 1.6052, Avg batch acc: 0.0465
Train, Epoch: 1, Batch: 38, Step num: 38, Learning rate: 0.00002655, Avg batch loss: 1.5141, Avg batch acc: 0.0392
Train, Epoch: 1, Batch: 39, Step num: 39, Learning rate: 0.00002725, Avg batch loss: 1.6372, Avg batch acc: 0.0652
Train, Epoch: 1, Batch: 40, Step num: 40, Learning rate: 0.00002795, Avg batch loss: 1.3482, Avg batch acc: 0.0648
Train, Epoch: 1, Batch: 41, Step num: 41, Learning rate: 0.00002865, Avg batch loss: 1.4885, Avg batch acc: 0.0633
Train, Epoch: 1, Batch: 42, Step num: 42, Learning rate: 0.00002935, Avg batch loss: 1.4349, Avg batch acc: 0.0698
Train, Epoch: 1, Batch: 43, Step num: 43, Learning rate: 0.00003005, Avg batch loss: 1.6059, Avg batch acc: 0.0666
Train, Epoch: 1, Batch: 44, Step num: 44, Learning rate: 0.00003075, Avg batch loss: 1.4440, Avg batch acc: 0.0636
Train, Epoch: 1, Batch: 45, Step num: 45, Learning rate: 0.00003144, Avg batch loss: 1.4151, Avg batch acc: 0.0669
Train, Epoch: 1, Batch: 46, Step num: 46, Learning rate: 0.00003214, Avg batch loss: 1.4979, Avg batch acc: 0.0712
Train, Epoch: 1, Batch: 47, Step num: 47, Learning rate: 0.00003284, Avg batch loss: 1.5348, Avg batch acc: 0.0728
Train, Epoch: 1, Batch: 48, Step num: 48, Learning rate: 0.00003354, Avg batch loss: 1.6022, Avg batch acc: 0.0672
Train, Epoch: 1, Batch: 49, Step num: 49, Learning rate: 0.00003424, Avg batch loss: 1.4707, Avg batch acc: 0.0715
Train, Epoch: 1, Batch: 50, Step num: 50, Learning rate: 0.00003494, Avg batch loss: 1.5185, Avg batch acc: 0.0693
Train, Epoch: 1, Batch: 51, Step num: 51, Learning rate: 0.00003564, Avg batch loss: 1.5211, Avg batch acc: 0.0688
Train, Epoch: 1, Batch: 52, Step num: 52, Learning rate: 0.00003634, Avg batch loss: 1.5393, Avg batch acc: 0.0618
Train, Epoch: 1, Batch: 53, Step num: 53, Learning rate: 0.00003703, Avg batch loss: 1.6079, Avg batch acc: 0.0604
Train, Epoch: 1, Batch: 54, Step num: 54, Learning rate: 0.00003773, Avg batch loss: 1.5665, Avg batch acc: 0.0684
Train, Epoch: 1, Batch: 55, Step num: 55, Learning rate: 0.00003843, Avg batch loss: 1.4937, Avg batch acc: 0.0602
Train, Epoch: 1, Batch: 56, Step num: 56, Learning rate: 0.00003913, Avg batch loss: 1.5014, Avg batch acc: 0.0623
Train, Epoch: 1, Batch: 57, Step num: 57, Learning rate: 0.00003983, Avg batch loss: 1.5167, Avg batch acc: 0.0599
Train, Epoch: 1, Batch: 58, Step num: 58, Learning rate: 0.00004053, Avg batch loss: 1.5203, Avg batch acc: 0.0674
Train, Epoch: 1, Batch: 59, Step num: 59, Learning rate: 0.00004123, Avg batch loss: 1.4995, Avg batch acc: 0.0632
Train, Epoch: 1, Batch: 60, Step num: 60, Learning rate: 0.00004193, Avg batch loss: 1.4342, Avg batch acc: 0.0705
Train, Epoch: 1, Batch: 61, Step num: 61, Learning rate: 0.00004263, Avg batch loss: 1.5068, Avg batch acc: 0.0648
Train, Epoch: 1, Batch: 62, Step num: 62, Learning rate: 0.00004332, Avg batch loss: 1.4108, Avg batch acc: 0.0728
Train, Epoch: 1, Batch: 63, Step num: 63, Learning rate: 0.00004402, Avg batch loss: 1.4905, Avg batch acc: 0.0684
Train, Epoch: 1, Batch: 64, Step num: 64, Learning rate: 0.00004472, Avg batch loss: 1.4569, Avg batch acc: 0.0675
Train, Epoch: 1, Batch: 65, Step num: 65, Learning rate: 0.00004542, Avg batch loss: 1.3709, Avg batch acc: 0.0696
Train, Epoch: 1, Batch: 66, Step num: 66, Learning rate: 0.00004612, Avg batch loss: 1.4803, Avg batch acc: 0.0647
Train, Epoch: 1, Batch: 67, Step num: 67, Learning rate: 0.00004682, Avg batch loss: 1.4554, Avg batch acc: 0.0737
Train, Epoch: 1, Batch: 68, Step num: 68, Learning rate: 0.00004752, Avg batch loss: 1.5175, Avg batch acc: 0.0766
Train, Epoch: 1, Batch: 69, Step num: 69, Learning rate: 0.00004822, Avg batch loss: 1.4102, Avg batch acc: 0.0693
Train, Epoch: 1, Batch: 70, Step num: 70, Learning rate: 0.00004891, Avg batch loss: 1.4185, Avg batch acc: 0.0687
Train, Epoch: 1, Batch: 71, Step num: 71, Learning rate: 0.00004961, Avg batch loss: 1.4599, Avg batch acc: 0.0736
Train, Epoch: 1, Batch: 72, Step num: 72, Learning rate: 0.00005031, Avg batch loss: 1.3254, Avg batch acc: 0.0747
Train, Epoch: 1, Batch: 73, Step num: 73, Learning rate: 0.00005101, Avg batch loss: 1.3485, Avg batch acc: 0.0775
Train, Epoch: 1, Batch: 74, Step num: 74, Learning rate: 0.00005171, Avg batch loss: 1.5113, Avg batch acc: 0.0761
Train, Epoch: 1, Batch: 75, Step num: 75, Learning rate: 0.00005241, Avg batch loss: 1.5021, Avg batch acc: 0.0810
Train, Epoch: 1, Batch: 76, Step num: 76, Learning rate: 0.00005311, Avg batch loss: 1.4760, Avg batch acc: 0.0867
Train, Epoch: 1, Batch: 77, Step num: 77, Learning rate: 0.00005381, Avg batch loss: 1.4366, Avg batch acc: 0.0827
Train, Epoch: 1, Batch: 78, Step num: 78, Learning rate: 0.00005450, Avg batch loss: 1.3464, Avg batch acc: 0.0674
Train, Epoch: 1, Batch: 79, Step num: 79, Learning rate: 0.00005520, Avg batch loss: 1.4448, Avg batch acc: 0.0808
Train, Epoch: 1, Batch: 80, Step num: 80, Learning rate: 0.00005590, Avg batch loss: 1.5314, Avg batch acc: 0.0799
Train, Epoch: 1, Batch: 81, Step num: 81, Learning rate: 0.00005660, Avg batch loss: 1.4765, Avg batch acc: 0.0838
Train, Epoch: 1, Batch: 82, Step num: 82, Learning rate: 0.00005730, Avg batch loss: 1.4457, Avg batch acc: 0.0851
Train, Epoch: 1, Batch: 83, Step num: 83, Learning rate: 0.00005800, Avg batch loss: 1.4738, Avg batch acc: 0.0829
Train, Epoch: 1, Batch: 84, Step num: 84, Learning rate: 0.00005870, Avg batch loss: 1.4847, Avg batch acc: 0.0801
Train, Epoch: 1, Batch: 85, Step num: 85, Learning rate: 0.00005940, Avg batch loss: 1.3942, Avg batch acc: 0.0797
Train, Epoch: 1, Batch: 86, Step num: 86, Learning rate: 0.00006009, Avg batch loss: 1.4446, Avg batch acc: 0.0869
Train, Epoch: 1, Batch: 87, Step num: 87, Learning rate: 0.00006079, Avg batch loss: 1.4432, Avg batch acc: 0.0827
Train, Epoch: 1, Batch: 88, Step num: 88, Learning rate: 0.00006149, Avg batch loss: 1.4695, Avg batch acc: 0.0911
Train, Epoch: 1, Batch: 89, Step num: 89, Learning rate: 0.00006219, Avg batch loss: 1.3852, Avg batch acc: 0.0852
Train, Epoch: 1, Batch: 90, Step num: 90, Learning rate: 0.00006289, Avg batch loss: 1.3519, Avg batch acc: 0.0808
Train, Epoch: 1, Batch: 91, Step num: 91, Learning rate: 0.00006359, Avg batch loss: 1.4523, Avg batch acc: 0.0853
Train, Epoch: 1, Batch: 92, Step num: 92, Learning rate: 0.00006429, Avg batch loss: 1.4816, Avg batch acc: 0.0977
Train, Epoch: 1, Batch: 93, Step num: 93, Learning rate: 0.00006499, Avg batch loss: 1.4968, Avg batch acc: 0.0996
Train, Epoch: 1, Batch: 94, Step num: 94, Learning rate: 0.00006568, Avg batch loss: 1.4109, Avg batch acc: 0.1008
Train, Epoch: 1, Batch: 95, Step num: 95, Learning rate: 0.00006638, Avg batch loss: 1.4002, Avg batch acc: 0.0926
Train, Epoch: 1, Batch: 96, Step num: 96, Learning rate: 0.00006708, Avg batch loss: 1.5138, Avg batch acc: 0.1078
Train, Epoch: 1, Batch: 97, Step num: 97, Learning rate: 0.00006778, Avg batch loss: 1.4141, Avg batch acc: 0.0927
Train, Epoch: 1, Batch: 98, Step num: 98, Learning rate: 0.00006848, Avg batch loss: 1.4823, Avg batch acc: 0.0945
Train, Epoch: 1, Batch: 99, Step num: 99, Learning rate: 0.00006918, Avg batch loss: 1.4651, Avg batch acc: 0.1013
Train, Epoch: 1, Batch: 100, Step num: 100, Learning rate: 0.00006988, Avg batch loss: 1.4386, Avg batch acc: 0.1004
Train, Epoch: 1, Batch: 101, Step num: 101, Learning rate: 0.00007058, Avg batch loss: 1.3021, Avg batch acc: 0.1064
Train, Epoch: 1, Batch: 102, Step num: 102, Learning rate: 0.00007127, Avg batch loss: 1.2182, Avg batch acc: 0.1118
Train, Epoch: 1, Batch: 103, Step num: 103, Learning rate: 0.00007197, Avg batch loss: 1.3014, Avg batch acc: 0.1095
Train, Epoch: 1, Batch: 104, Step num: 104, Learning rate: 0.00007267, Avg batch loss: 1.2990, Avg batch acc: 0.1161
Train, Epoch: 1, Batch: 105, Step num: 105, Learning rate: 0.00007337, Avg batch loss: 1.4197, Avg batch acc: 0.1088
Train, Epoch: 1, Batch: 106, Step num: 106, Learning rate: 0.00007407, Avg batch loss: 1.4510, Avg batch acc: 0.1142
Train, Epoch: 1, Batch: 107, Step num: 107, Learning rate: 0.00007477, Avg batch loss: 1.4033, Avg batch acc: 0.1218
Train, Epoch: 1, Batch: 108, Step num: 108, Learning rate: 0.00007547, Avg batch loss: 1.4531, Avg batch acc: 0.1203
Train, Epoch: 1, Batch: 109, Step num: 109, Learning rate: 0.00007617, Avg batch loss: 1.3676, Avg batch acc: 0.1225
Train, Epoch: 1, Batch: 110, Step num: 110, Learning rate: 0.00007686, Avg batch loss: 1.2441, Avg batch acc: 0.1161
Train, Epoch: 1, Batch: 111, Step num: 111, Learning rate: 0.00007756, Avg batch loss: 1.3794, Avg batch acc: 0.1136
Train, Epoch: 1, Batch: 112, Step num: 112, Learning rate: 0.00007826, Avg batch loss: 1.3352, Avg batch acc: 0.1140
Train, Epoch: 1, Batch: 113, Step num: 113, Learning rate: 0.00007896, Avg batch loss: 1.4078, Avg batch acc: 0.1134
Train, Epoch: 1, Batch: 114, Step num: 114, Learning rate: 0.00007966, Avg batch loss: 1.2571, Avg batch acc: 0.1192
Train, Epoch: 1, Batch: 115, Step num: 115, Learning rate: 0.00008036, Avg batch loss: 1.2934, Avg batch acc: 0.1311
Train, Epoch: 1, Batch: 116, Step num: 116, Learning rate: 0.00008106, Avg batch loss: 1.3170, Avg batch acc: 0.1294
Train, Epoch: 1, Batch: 117, Step num: 117, Learning rate: 0.00008176, Avg batch loss: 1.2266, Avg batch acc: 0.1296
Train, Epoch: 1, Batch: 118, Step num: 118, Learning rate: 0.00008246, Avg batch loss: 1.3418, Avg batch acc: 0.1238
Train, Epoch: 1, Batch: 119, Step num: 119, Learning rate: 0.00008315, Avg batch loss: 1.3504, Avg batch acc: 0.1211
Train, Epoch: 1, Batch: 120, Step num: 120, Learning rate: 0.00008385, Avg batch loss: 1.3090, Avg batch acc: 0.1191
Train, Epoch: 1, Batch: 121, Step num: 121, Learning rate: 0.00008455, Avg batch loss: 1.4142, Avg batch acc: 0.1271
Train, Epoch: 1, Batch: 122, Step num: 122, Learning rate: 0.00008525, Avg batch loss: 1.2246, Avg batch acc: 0.1199
Train, Epoch: 1, Batch: 123, Step num: 123, Learning rate: 0.00008595, Avg batch loss: 1.2987, Avg batch acc: 0.1131
Train, Epoch: 1, Batch: 124, Step num: 124, Learning rate: 0.00008665, Avg batch loss: 1.2941, Avg batch acc: 0.1234
Train, Epoch: 1, Batch: 125, Step num: 125, Learning rate: 0.00008735, Avg batch loss: 1.2499, Avg batch acc: 0.1367
Train, Epoch: 1, Batch: 126, Step num: 126, Learning rate: 0.00008805, Avg batch loss: 1.2176, Avg batch acc: 0.1281
Train, Epoch: 1, Batch: 127, Step num: 127, Learning rate: 0.00008874, Avg batch loss: 1.3157, Avg batch acc: 0.1233
Train, Epoch: 1, Batch: 128, Step num: 128, Learning rate: 0.00008944, Avg batch loss: 1.2113, Avg batch acc: 0.1274
Train, Epoch: 1, Batch: 129, Step num: 129, Learning rate: 0.00009014, Avg batch loss: 1.2855, Avg batch acc: 0.1290
Train, Epoch: 1, Batch: 130, Step num: 130, Learning rate: 0.00009084, Avg batch loss: 1.2953, Avg batch acc: 0.1288
Train, Epoch: 1, Batch: 131, Step num: 131, Learning rate: 0.00009154, Avg batch loss: 1.2173, Avg batch acc: 0.1221
Train, Epoch: 1, Batch: 132, Step num: 132, Learning rate: 0.00009224, Avg batch loss: 1.3311, Avg batch acc: 0.1341
Train, Epoch: 1, Batch: 133, Step num: 133, Learning rate: 0.00009294, Avg batch loss: 1.2312, Avg batch acc: 0.1269
Train, Epoch: 1, Batch: 134, Step num: 134, Learning rate: 0.00009364, Avg batch loss: 1.2026, Avg batch acc: 0.1412
Train, Epoch: 1, Batch: 135, Step num: 135, Learning rate: 0.00009433, Avg batch loss: 1.3392, Avg batch acc: 0.1334
Train, Epoch: 1, Batch: 136, Step num: 136, Learning rate: 0.00009503, Avg batch loss: 1.1506, Avg batch acc: 0.1395
Train, Epoch: 1, Batch: 137, Step num: 137, Learning rate: 0.00009573, Avg batch loss: 1.2794, Avg batch acc: 0.1285
Train, Epoch: 1, Batch: 138, Step num: 138, Learning rate: 0.00009643, Avg batch loss: 1.2300, Avg batch acc: 0.1389
Train, Epoch: 1, Batch: 139, Step num: 139, Learning rate: 0.00009713, Avg batch loss: 1.3044, Avg batch acc: 0.1316
Train, Epoch: 1, Batch: 140, Step num: 140, Learning rate: 0.00009783, Avg batch loss: 1.2562, Avg batch acc: 0.1519
Train, Epoch: 1, Batch: 141, Step num: 141, Learning rate: 0.00009853, Avg batch loss: 1.2053, Avg batch acc: 0.1410
Train, Epoch: 1, Batch: 142, Step num: 142, Learning rate: 0.00009923, Avg batch loss: 1.2188, Avg batch acc: 0.1442
Train, Epoch: 1, Batch: 143, Step num: 143, Learning rate: 0.00009992, Avg batch loss: 1.2277, Avg batch acc: 0.1433
Train, Epoch: 1, Batch: 144, Step num: 144, Learning rate: 0.00010062, Avg batch loss: 1.2788, Avg batch acc: 0.1363
Train, Epoch: 1, Batch: 145, Step num: 145, Learning rate: 0.00010132, Avg batch loss: 1.2108, Avg batch acc: 0.1494
Train, Epoch: 1, Batch: 146, Step num: 146, Learning rate: 0.00010202, Avg batch loss: 1.2071, Avg batch acc: 0.1621
Train, Epoch: 1, Batch: 147, Step num: 147, Learning rate: 0.00010272, Avg batch loss: 1.2463, Avg batch acc: 0.1500
Train, Epoch: 1, Batch: 148, Step num: 148, Learning rate: 0.00010342, Avg batch loss: 1.0744, Avg batch acc: 0.1699
Train, Epoch: 1, Batch: 149, Step num: 149, Learning rate: 0.00010412, Avg batch loss: 1.2821, Avg batch acc: 0.1472
Train, Epoch: 1, Batch: 150, Step num: 150, Learning rate: 0.00010482, Avg batch loss: 1.1446, Avg batch acc: 0.1612
Train, Epoch: 1, Batch: 151, Step num: 151, Learning rate: 0.00010551, Avg batch loss: 1.1773, Avg batch acc: 0.1637
Train, Epoch: 1, Batch: 152, Step num: 152, Learning rate: 0.00010621, Avg batch loss: 1.1237, Avg batch acc: 0.1840
Train, Epoch: 1, Batch: 153, Step num: 153, Learning rate: 0.00010691, Avg batch loss: 1.3390, Avg batch acc: 0.1733
Train, Epoch: 1, Batch: 154, Step num: 154, Learning rate: 0.00010761, Avg batch loss: 1.1129, Avg batch acc: 0.1852
Train, Epoch: 1, Batch: 155, Step num: 155, Learning rate: 0.00010831, Avg batch loss: 1.2828, Avg batch acc: 0.1662
Train, Epoch: 1, Batch: 156, Step num: 156, Learning rate: 0.00010901, Avg batch loss: 1.2700, Avg batch acc: 0.1771
Train, Epoch: 1, Batch: 157, Step num: 157, Learning rate: 0.00010971, Avg batch loss: 1.1918, Avg batch acc: 0.1845
Train, Epoch: 1, Batch: 158, Step num: 158, Learning rate: 0.00011041, Avg batch loss: 1.1034, Avg batch acc: 0.1926
Train, Epoch: 1, Batch: 159, Step num: 159, Learning rate: 0.00011110, Avg batch loss: 1.2608, Avg batch acc: 0.1892
Train, Epoch: 1, Batch: 160, Step num: 160, Learning rate: 0.00011180, Avg batch loss: 1.0922, Avg batch acc: 0.1934
Train, Epoch: 1, Batch: 161, Step num: 161, Learning rate: 0.00011250, Avg batch loss: 1.1431, Avg batch acc: 0.2058
Train, Epoch: 1, Batch: 162, Step num: 162, Learning rate: 0.00011320, Avg batch loss: 1.1493, Avg batch acc: 0.1873
Train, Epoch: 1, Batch: 163, Step num: 163, Learning rate: 0.00011390, Avg batch loss: 1.0813, Avg batch acc: 0.2107
Train, Epoch: 1, Batch: 164, Step num: 164, Learning rate: 0.00011460, Avg batch loss: 1.1287, Avg batch acc: 0.2120
Train, Epoch: 1, Batch: 165, Step num: 165, Learning rate: 0.00011530, Avg batch loss: 1.0720, Avg batch acc: 0.2019
Train, Epoch: 1, Batch: 166, Step num: 166, Learning rate: 0.00011600, Avg batch loss: 1.0973, Avg batch acc: 0.2121
Train, Epoch: 1, Batch: 167, Step num: 167, Learning rate: 0.00011669, Avg batch loss: 1.2074, Avg batch acc: 0.2018
Train, Epoch: 1, Batch: 168, Step num: 168, Learning rate: 0.00011739, Avg batch loss: 1.1279, Avg batch acc: 0.2067
Train, Epoch: 1, Batch: 169, Step num: 169, Learning rate: 0.00011809, Avg batch loss: 1.1525, Avg batch acc: 0.2064
Train, Epoch: 1, Batch: 170, Step num: 170, Learning rate: 0.00011879, Avg batch loss: 1.1061, Avg batch acc: 0.2132
Train, Epoch: 1, Batch: 171, Step num: 171, Learning rate: 0.00011949, Avg batch loss: 1.1820, Avg batch acc: 0.2009
Train, Epoch: 1, Batch: 172, Step num: 172, Learning rate: 0.00012019, Avg batch loss: 1.0846, Avg batch acc: 0.2160
Train, Epoch: 1, Batch: 173, Step num: 173, Learning rate: 0.00012089, Avg batch loss: 1.0839, Avg batch acc: 0.2170
Train, Epoch: 1, Batch: 174, Step num: 174, Learning rate: 0.00012159, Avg batch loss: 1.2495, Avg batch acc: 0.2110
Train, Epoch: 1, Batch: 175, Step num: 175, Learning rate: 0.00012228, Avg batch loss: 1.1463, Avg batch acc: 0.2191
Train, Epoch: 1, Batch: 176, Step num: 176, Learning rate: 0.00012298, Avg batch loss: 1.0966, Avg batch acc: 0.2211
Train, Epoch: 1, Batch: 177, Step num: 177, Learning rate: 0.00012368, Avg batch loss: 1.0907, Avg batch acc: 0.2183
Train, Epoch: 1, Batch: 178, Step num: 178, Learning rate: 0.00012438, Avg batch loss: 1.0684, Avg batch acc: 0.2260
Train, Epoch: 1, Batch: 179, Step num: 179, Learning rate: 0.00012508, Avg batch loss: 1.1272, Avg batch acc: 0.2351
Train, Epoch: 1, Batch: 180, Step num: 180, Learning rate: 0.00012578, Avg batch loss: 1.0137, Avg batch acc: 0.2253
Train, Epoch: 1, Batch: 181, Step num: 181, Learning rate: 0.00012648, Avg batch loss: 1.1032, Avg batch acc: 0.2284
Train, Epoch: 1, Batch: 182, Step num: 182, Learning rate: 0.00012718, Avg batch loss: 1.0872, Avg batch acc: 0.2209
Train, Epoch: 1, Batch: 183, Step num: 183, Learning rate: 0.00012788, Avg batch loss: 1.0128, Avg batch acc: 0.2269
Train, Epoch: 1, Batch: 184, Step num: 184, Learning rate: 0.00012857, Avg batch loss: 1.0004, Avg batch acc: 0.2375
Train, Epoch: 1, Batch: 185, Step num: 185, Learning rate: 0.00012927, Avg batch loss: 1.0560, Avg batch acc: 0.2310
Train, Epoch: 1, Batch: 186, Step num: 186, Learning rate: 0.00012997, Avg batch loss: 1.0401, Avg batch acc: 0.2292
Train, Epoch: 1, Batch: 187, Step num: 187, Learning rate: 0.00013067, Avg batch loss: 0.9125, Avg batch acc: 0.2287
Train, Epoch: 1, Batch: 188, Step num: 188, Learning rate: 0.00013137, Avg batch loss: 1.0216, Avg batch acc: 0.2354
Train, Epoch: 1, Batch: 189, Step num: 189, Learning rate: 0.00013207, Avg batch loss: 1.0659, Avg batch acc: 0.2250
Train, Epoch: 1, Batch: 190, Step num: 190, Learning rate: 0.00013277, Avg batch loss: 1.0491, Avg batch acc: 0.2413
Train, Epoch: 1, Batch: 191, Step num: 191, Learning rate: 0.00013347, Avg batch loss: 1.0066, Avg batch acc: 0.2284
Train, Epoch: 1, Batch: 192, Step num: 192, Learning rate: 0.00013416, Avg batch loss: 0.9920, Avg batch acc: 0.2236
Train, Epoch: 1, Batch: 193, Step num: 193, Learning rate: 0.00013486, Avg batch loss: 1.0500, Avg batch acc: 0.2322
Train, Epoch: 1, Batch: 194, Step num: 194, Learning rate: 0.00013556, Avg batch loss: 1.0777, Avg batch acc: 0.2239
Train, Epoch: 1, Batch: 195, Step num: 195, Learning rate: 0.00013626, Avg batch loss: 1.0216, Avg batch acc: 0.2533
Train, Epoch: 1, Batch: 196, Step num: 196, Learning rate: 0.00013696, Avg batch loss: 0.9778, Avg batch acc: 0.2393
Train, Epoch: 1, Batch: 197, Step num: 197, Learning rate: 0.00013766, Avg batch loss: 0.9817, Avg batch acc: 0.2493
Train, Epoch: 1, Batch: 198, Step num: 198, Learning rate: 0.00013836, Avg batch loss: 0.9443, Avg batch acc: 0.2503
Train, Epoch: 1, Batch: 199, Step num: 199, Learning rate: 0.00013906, Avg batch loss: 1.0219, Avg batch acc: 0.2472
Train, Epoch: 1, Batch: 200, Step num: 200, Learning rate: 0.00013975, Avg batch loss: 1.0678, Avg batch acc: 0.2406
Train, Epoch: 1, Batch: 201, Step num: 201, Learning rate: 0.00014045, Avg batch loss: 0.9276, Avg batch acc: 0.2553
Train, Epoch: 1, Batch: 202, Step num: 202, Learning rate: 0.00014115, Avg batch loss: 0.9593, Avg batch acc: 0.2516
Train, Epoch: 1, Batch: 203, Step num: 203, Learning rate: 0.00014185, Avg batch loss: 0.9341, Avg batch acc: 0.2558
Train, Epoch: 1, Batch: 204, Step num: 204, Learning rate: 0.00014255, Avg batch loss: 0.9752, Avg batch acc: 0.2457
Train, Epoch: 1, Batch: 205, Step num: 205, Learning rate: 0.00014325, Avg batch loss: 1.0013, Avg batch acc: 0.2364
Train, Epoch: 1, Batch: 206, Step num: 206, Learning rate: 0.00014395, Avg batch loss: 1.0684, Avg batch acc: 0.2494
Train, Epoch: 1, Batch: 207, Step num: 207, Learning rate: 0.00014465, Avg batch loss: 0.9564, Avg batch acc: 0.2531
Train, Epoch: 1, Batch: 208, Step num: 208, Learning rate: 0.00014534, Avg batch loss: 0.9432, Avg batch acc: 0.2390
Train, Epoch: 1, Batch: 209, Step num: 209, Learning rate: 0.00014604, Avg batch loss: 0.8754, Avg batch acc: 0.2403
Train, Epoch: 1, Batch: 210, Step num: 210, Learning rate: 0.00014674, Avg batch loss: 1.0165, Avg batch acc: 0.2604
Train, Epoch: 1, Batch: 211, Step num: 211, Learning rate: 0.00014744, Avg batch loss: 1.0457, Avg batch acc: 0.2438
Train, Epoch: 1, Batch: 212, Step num: 212, Learning rate: 0.00014814, Avg batch loss: 1.0732, Avg batch acc: 0.2361
Train, Epoch: 1, Batch: 213, Step num: 213, Learning rate: 0.00014884, Avg batch loss: 0.9187, Avg batch acc: 0.2641
Train, Epoch: 1, Batch: 214, Step num: 214, Learning rate: 0.00014954, Avg batch loss: 0.9257, Avg batch acc: 0.2619
Train, Epoch: 1, Batch: 215, Step num: 215, Learning rate: 0.00015024, Avg batch loss: 0.9574, Avg batch acc: 0.2448
Train, Epoch: 1, Batch: 216, Step num: 216, Learning rate: 0.00015093, Avg batch loss: 1.0203, Avg batch acc: 0.2485
Train, Epoch: 1, Batch: 217, Step num: 217, Learning rate: 0.00015163, Avg batch loss: 1.0658, Avg batch acc: 0.2562
Train, Epoch: 1, Batch: 218, Step num: 218, Learning rate: 0.00015233, Avg batch loss: 1.0340, Avg batch acc: 0.2482
Train, Epoch: 1, Batch: 219, Step num: 219, Learning rate: 0.00015303, Avg batch loss: 0.9574, Avg batch acc: 0.2478
Train, Epoch: 1, Batch: 220, Step num: 220, Learning rate: 0.00015373, Avg batch loss: 0.9609, Avg batch acc: 0.2350
Train, Epoch: 1, Batch: 221, Step num: 221, Learning rate: 0.00015443, Avg batch loss: 0.9309, Avg batch acc: 0.2425
Train, Epoch: 1, Batch: 222, Step num: 222, Learning rate: 0.00015513, Avg batch loss: 0.9466, Avg batch acc: 0.2490
Train, Epoch: 1, Batch: 223, Step num: 223, Learning rate: 0.00015583, Avg batch loss: 1.0103, Avg batch acc: 0.2613
Train, Epoch: 1, Batch: 224, Step num: 224, Learning rate: 0.00015652, Avg batch loss: 0.9430, Avg batch acc: 0.2541
Train, Epoch: 1, Batch: 225, Step num: 225, Learning rate: 0.00015722, Avg batch loss: 0.9817, Avg batch acc: 0.2448
Train, Epoch: 1, Batch: 226, Step num: 226, Learning rate: 0.00015792, Avg batch loss: 0.9100, Avg batch acc: 0.2657
Train, Epoch: 1, Batch: 227, Step num: 227, Learning rate: 0.00015862, Avg batch loss: 0.8554, Avg batch acc: 0.2486
Train, Epoch: 1, Batch: 228, Step num: 228, Learning rate: 0.00015932, Avg batch loss: 0.9442, Avg batch acc: 0.2550
Train, Epoch: 1, Batch: 229, Step num: 229, Learning rate: 0.00016002, Avg batch loss: 0.8738, Avg batch acc: 0.2663
Train, Epoch: 1, Batch: 230, Step num: 230, Learning rate: 0.00016072, Avg batch loss: 0.9341, Avg batch acc: 0.2761
Train, Epoch: 1, Batch: 231, Step num: 231, Learning rate: 0.00016142, Avg batch loss: 0.9327, Avg batch acc: 0.2628
Train, Epoch: 1, Batch: 232, Step num: 232, Learning rate: 0.00016211, Avg batch loss: 0.9665, Avg batch acc: 0.2553
Train, Epoch: 1, Batch: 233, Step num: 233, Learning rate: 0.00016281, Avg batch loss: 0.8971, Avg batch acc: 0.2530
Train, Epoch: 1, Batch: 234, Step num: 234, Learning rate: 0.00016351, Avg batch loss: 0.8698, Avg batch acc: 0.2687
Train, Epoch: 1, Batch: 235, Step num: 235, Learning rate: 0.00016421, Avg batch loss: 0.8465, Avg batch acc: 0.2666
Train, Epoch: 1, Batch: 236, Step num: 236, Learning rate: 0.00016491, Avg batch loss: 0.9802, Avg batch acc: 0.2394
Train, Epoch: 1, Batch: 237, Step num: 237, Learning rate: 0.00016561, Avg batch loss: 0.8950, Avg batch acc: 0.2658
Train, Epoch: 1, Batch: 238, Step num: 238, Learning rate: 0.00016631, Avg batch loss: 0.9161, Avg batch acc: 0.2616
Train, Epoch: 1, Batch: 239, Step num: 239, Learning rate: 0.00016701, Avg batch loss: 0.8991, Avg batch acc: 0.2592
Train, Epoch: 1, Batch: 240, Step num: 240, Learning rate: 0.00016771, Avg batch loss: 0.8789, Avg batch acc: 0.2762
Train, Epoch: 1, Batch: 241, Step num: 241, Learning rate: 0.00016840, Avg batch loss: 0.8529, Avg batch acc: 0.2710
Train, Epoch: 1, Batch: 242, Step num: 242, Learning rate: 0.00016910, Avg batch loss: 0.9209, Avg batch acc: 0.2706
Train, Epoch: 1, Batch: 243, Step num: 243, Learning rate: 0.00016980, Avg batch loss: 0.8664, Avg batch acc: 0.2560
Train, Epoch: 1, Batch: 244, Step num: 244, Learning rate: 0.00017050, Avg batch loss: 0.9074, Avg batch acc: 0.2749
Train, Epoch: 1, Batch: 245, Step num: 245, Learning rate: 0.00017120, Avg batch loss: 0.9133, Avg batch acc: 0.2687
Train, Epoch: 1, Batch: 246, Step num: 246, Learning rate: 0.00017190, Avg batch loss: 0.8724, Avg batch acc: 0.2763
Train, Epoch: 1, Batch: 247, Step num: 247, Learning rate: 0.00017260, Avg batch loss: 0.8853, Avg batch acc: 0.2564
Train, Epoch: 1, Batch: 248, Step num: 248, Learning rate: 0.00017330, Avg batch loss: 0.8917, Avg batch acc: 0.2603
Train, Epoch: 1, Batch: 249, Step num: 249, Learning rate: 0.00017399, Avg batch loss: 1.0329, Avg batch acc: 0.2580
Train, Epoch: 1, Batch: 250, Step num: 250, Learning rate: 0.00017469, Avg batch loss: 0.8440, Avg batch acc: 0.2857
Train, Epoch: 1, Batch: 251, Step num: 251, Learning rate: 0.00017539, Avg batch loss: 0.9376, Avg batch acc: 0.2751
Train, Epoch: 1, Batch: 252, Step num: 252, Learning rate: 0.00017609, Avg batch loss: 0.8609, Avg batch acc: 0.2680
Train, Epoch: 1, Batch: 253, Step num: 253, Learning rate: 0.00017679, Avg batch loss: 1.0007, Avg batch acc: 0.2831
Train, Epoch: 1, Batch: 254, Step num: 254, Learning rate: 0.00017749, Avg batch loss: 0.7978, Avg batch acc: 0.3165
Train, Epoch: 1, Batch: 255, Step num: 255, Learning rate: 0.00017819, Avg batch loss: 0.8348, Avg batch acc: 0.2884
Train, Epoch: 1, Batch: 256, Step num: 256, Learning rate: 0.00017889, Avg batch loss: 0.8632, Avg batch acc: 0.2823
Train, Epoch: 1, Batch: 257, Step num: 257, Learning rate: 0.00017958, Avg batch loss: 0.9297, Avg batch acc: 0.2782
Train, Epoch: 1, Batch: 258, Step num: 258, Learning rate: 0.00018028, Avg batch loss: 0.8104, Avg batch acc: 0.2822
Train, Epoch: 1, Batch: 259, Step num: 259, Learning rate: 0.00018098, Avg batch loss: 0.8615, Avg batch acc: 0.2819
Train, Epoch: 1, Batch: 260, Step num: 260, Learning rate: 0.00018168, Avg batch loss: 0.9049, Avg batch acc: 0.2836
Train, Epoch: 1, Batch: 261, Step num: 261, Learning rate: 0.00018238, Avg batch loss: 0.9022, Avg batch acc: 0.3073
Train, Epoch: 1, Batch: 262, Step num: 262, Learning rate: 0.00018308, Avg batch loss: 0.8502, Avg batch acc: 0.2948
Train, Epoch: 1, Batch: 263, Step num: 263, Learning rate: 0.00018378, Avg batch loss: 0.8904, Avg batch acc: 0.2777
Train, Epoch: 1, Batch: 264, Step num: 264, Learning rate: 0.00018448, Avg batch loss: 0.9145, Avg batch acc: 0.2960
Train, Epoch: 1, Batch: 265, Step num: 265, Learning rate: 0.00018517, Avg batch loss: 0.8722, Avg batch acc: 0.2829
Train, Epoch: 1, Batch: 266, Step num: 266, Learning rate: 0.00018587, Avg batch loss: 0.7769, Avg batch acc: 0.2986
Train, Epoch: 1, Batch: 267, Step num: 267, Learning rate: 0.00018657, Avg batch loss: 0.8719, Avg batch acc: 0.2859
Train, Epoch: 1, Batch: 268, Step num: 268, Learning rate: 0.00018727, Avg batch loss: 0.8330, Avg batch acc: 0.2841
Train, Epoch: 1, Batch: 269, Step num: 269, Learning rate: 0.00018797, Avg batch loss: 0.8692, Avg batch acc: 0.2909
Train, Epoch: 1, Batch: 270, Step num: 270, Learning rate: 0.00018867, Avg batch loss: 0.8105, Avg batch acc: 0.2910
Train, Epoch: 1, Batch: 271, Step num: 271, Learning rate: 0.00018937, Avg batch loss: 0.8510, Avg batch acc: 0.2888
Train, Epoch: 1, Batch: 272, Step num: 272, Learning rate: 0.00019007, Avg batch loss: 0.8568, Avg batch acc: 0.2850
Train, Epoch: 1, Batch: 273, Step num: 273, Learning rate: 0.00019076, Avg batch loss: 0.8852, Avg batch acc: 0.3077
Train, Epoch: 1, Batch: 274, Step num: 274, Learning rate: 0.00019146, Avg batch loss: 0.9344, Avg batch acc: 0.2737
Train, Epoch: 1, Batch: 275, Step num: 275, Learning rate: 0.00019216, Avg batch loss: 0.8331, Avg batch acc: 0.2861
Train, Epoch: 1, Batch: 276, Step num: 276, Learning rate: 0.00019286, Avg batch loss: 0.8475, Avg batch acc: 0.3051
Train, Epoch: 1, Batch: 277, Step num: 277, Learning rate: 0.00019356, Avg batch loss: 0.8462, Avg batch acc: 0.3056
Train, Epoch: 1, Batch: 278, Step num: 278, Learning rate: 0.00019426, Avg batch loss: 0.8038, Avg batch acc: 0.2981
Train, Epoch: 1, Batch: 279, Step num: 279, Learning rate: 0.00019496, Avg batch loss: 0.8100, Avg batch acc: 0.2950
Train, Epoch: 1, Batch: 280, Step num: 280, Learning rate: 0.00019566, Avg batch loss: 0.7615, Avg batch acc: 0.3132
Train, Epoch: 1, Batch: 281, Step num: 281, Learning rate: 0.00019635, Avg batch loss: 0.8425, Avg batch acc: 0.3042
Train, Epoch: 1, Batch: 282, Step num: 282, Learning rate: 0.00019705, Avg batch loss: 0.8995, Avg batch acc: 0.2978
Train, Epoch: 1, Batch: 283, Step num: 283, Learning rate: 0.00019775, Avg batch loss: 0.8970, Avg batch acc: 0.2875
Train, Epoch: 1, Batch: 284, Step num: 284, Learning rate: 0.00019845, Avg batch loss: 0.8078, Avg batch acc: 0.3088
Train, Epoch: 1, Batch: 285, Step num: 285, Learning rate: 0.00019915, Avg batch loss: 0.8008, Avg batch acc: 0.2837
Train, Epoch: 1, Batch: 286, Step num: 286, Learning rate: 0.00019985, Avg batch loss: 0.8571, Avg batch acc: 0.3199
Train, Epoch: 1, Batch: 287, Step num: 287, Learning rate: 0.00020055, Avg batch loss: 0.8660, Avg batch acc: 0.2994
Train, Epoch: 1, Batch: 288, Step num: 288, Learning rate: 0.00020125, Avg batch loss: 0.8151, Avg batch acc: 0.2933
Train, Epoch: 1, Batch: 289, Step num: 289, Learning rate: 0.00020194, Avg batch loss: 0.7905, Avg batch acc: 0.3127
Train, Epoch: 1, Batch: 290, Step num: 290, Learning rate: 0.00020264, Avg batch loss: 0.8159, Avg batch acc: 0.3140
Train, Epoch: 1, Batch: 291, Step num: 291, Learning rate: 0.00020334, Avg batch loss: 0.8426, Avg batch acc: 0.2918
Train, Epoch: 1, Batch: 292, Step num: 292, Learning rate: 0.00020404, Avg batch loss: 0.7181, Avg batch acc: 0.3253
Train, Epoch: 1, Batch: 293, Step num: 293, Learning rate: 0.00020474, Avg batch loss: 0.8101, Avg batch acc: 0.3170
Train, Epoch: 1, Batch: 294, Step num: 294, Learning rate: 0.00020544, Avg batch loss: 0.8010, Avg batch acc: 0.2948
Train, Epoch: 1, Batch: 295, Step num: 295, Learning rate: 0.00020614, Avg batch loss: 0.7650, Avg batch acc: 0.3151
Train, Epoch: 1, Batch: 296, Step num: 296, Learning rate: 0.00020684, Avg batch loss: 0.9420, Avg batch acc: 0.2993
Train, Epoch: 1, Batch: 297, Step num: 297, Learning rate: 0.00020754, Avg batch loss: 0.8491, Avg batch acc: 0.3067
Train, Epoch: 1, Batch: 298, Step num: 298, Learning rate: 0.00020823, Avg batch loss: 0.7357, Avg batch acc: 0.3096
Train, Epoch: 1, Batch: 299, Step num: 299, Learning rate: 0.00020893, Avg batch loss: 0.8760, Avg batch acc: 0.3080
Train, Epoch: 1, Batch: 300, Step num: 300, Learning rate: 0.00020963, Avg batch loss: 0.7894, Avg batch acc: 0.3045
Train, Epoch: 1, Batch: 301, Step num: 301, Learning rate: 0.00021033, Avg batch loss: 0.8564, Avg batch acc: 0.2848
Train, Epoch: 1, Batch: 302, Step num: 302, Learning rate: 0.00021103, Avg batch loss: 0.8184, Avg batch acc: 0.3057
Train, Epoch: 1, Batch: 303, Step num: 303, Learning rate: 0.00021173, Avg batch loss: 0.7947, Avg batch acc: 0.3070
Train, Epoch: 1, Batch: 304, Step num: 304, Learning rate: 0.00021243, Avg batch loss: 0.7519, Avg batch acc: 0.3060
Train, Epoch: 1, Batch: 305, Step num: 305, Learning rate: 0.00021313, Avg batch loss: 0.8495, Avg batch acc: 0.3052
Train, Epoch: 1, Batch: 306, Step num: 306, Learning rate: 0.00021382, Avg batch loss: 0.8428, Avg batch acc: 0.2925
Train, Epoch: 1, Batch: 307, Step num: 307, Learning rate: 0.00021452, Avg batch loss: 0.8227, Avg batch acc: 0.3084
Train, Epoch: 1, Batch: 308, Step num: 308, Learning rate: 0.00021522, Avg batch loss: 0.8431, Avg batch acc: 0.2956
Train, Epoch: 1, Batch: 309, Step num: 309, Learning rate: 0.00021592, Avg batch loss: 0.8088, Avg batch acc: 0.3172
Train, Epoch: 1, Batch: 310, Step num: 310, Learning rate: 0.00021662, Avg batch loss: 0.8047, Avg batch acc: 0.3050
Train, Epoch: 1, Batch: 311, Step num: 311, Learning rate: 0.00021732, Avg batch loss: 0.8491, Avg batch acc: 0.3268
Train, Epoch: 1, Batch: 312, Step num: 312, Learning rate: 0.00021802, Avg batch loss: 0.7646, Avg batch acc: 0.3104
Train, Epoch: 1, Batch: 313, Step num: 313, Learning rate: 0.00021872, Avg batch loss: 0.8944, Avg batch acc: 0.3012
Train, Epoch: 1, Batch: 314, Step num: 314, Learning rate: 0.00021941, Avg batch loss: 0.8172, Avg batch acc: 0.2848
Train, Epoch: 1, Batch: 315, Step num: 315, Learning rate: 0.00022011, Avg batch loss: 0.7402, Avg batch acc: 0.3374
Train, Epoch: 1, Batch: 316, Step num: 316, Learning rate: 0.00022081, Avg batch loss: 0.8133, Avg batch acc: 0.3130
Train, Epoch: 1, Batch: 317, Step num: 317, Learning rate: 0.00022151, Avg batch loss: 0.8056, Avg batch acc: 0.2971
Train, Epoch: 1, Batch: 318, Step num: 318, Learning rate: 0.00022221, Avg batch loss: 0.8208, Avg batch acc: 0.3234
Train, Epoch: 1, Batch: 319, Step num: 319, Learning rate: 0.00022291, Avg batch loss: 0.8253, Avg batch acc: 0.3015
Train, Epoch: 1, Batch: 320, Step num: 320, Learning rate: 0.00022361, Avg batch loss: 0.8523, Avg batch acc: 0.3016
Train, Epoch: 1, Batch: 321, Step num: 321, Learning rate: 0.00022431, Avg batch loss: 0.7937, Avg batch acc: 0.2932
Train, Epoch: 1, Batch: 322, Step num: 322, Learning rate: 0.00022500, Avg batch loss: 0.7986, Avg batch acc: 0.3078
Train, Epoch: 1, Batch: 323, Step num: 323, Learning rate: 0.00022570, Avg batch loss: 0.7495, Avg batch acc: 0.3287
Train, Epoch: 1, Batch: 324, Step num: 324, Learning rate: 0.00022640, Avg batch loss: 0.8309, Avg batch acc: 0.3176
Train, Epoch: 1, Batch: 325, Step num: 325, Learning rate: 0.00022710, Avg batch loss: 0.7966, Avg batch acc: 0.3151
Train, Epoch: 1, Batch: 326, Step num: 326, Learning rate: 0.00022780, Avg batch loss: 0.7242, Avg batch acc: 0.3322
Train, Epoch: 1, Batch: 327, Step num: 327, Learning rate: 0.00022850, Avg batch loss: 0.8377, Avg batch acc: 0.3279
Train, Epoch: 1, Batch: 328, Step num: 328, Learning rate: 0.00022920, Avg batch loss: 0.7377, Avg batch acc: 0.3266
Train, Epoch: 1, Batch: 329, Step num: 329, Learning rate: 0.00022990, Avg batch loss: 0.8461, Avg batch acc: 0.3048
Train, Epoch: 1, Batch: 330, Step num: 330, Learning rate: 0.00023059, Avg batch loss: 0.7862, Avg batch acc: 0.3042
Train, Epoch: 1, Batch: 331, Step num: 331, Learning rate: 0.00023129, Avg batch loss: 0.8826, Avg batch acc: 0.2944
Train, Epoch: 1, Batch: 332, Step num: 332, Learning rate: 0.00023199, Avg batch loss: 0.7796, Avg batch acc: 0.3326
Train, Epoch: 1, Batch: 333, Step num: 333, Learning rate: 0.00023269, Avg batch loss: 0.8124, Avg batch acc: 0.3278
Train, Epoch: 1, Batch: 334, Step num: 334, Learning rate: 0.00023339, Avg batch loss: 0.7970, Avg batch acc: 0.2982
Train, Epoch: 1, Batch: 335, Step num: 335, Learning rate: 0.00023409, Avg batch loss: 0.7328, Avg batch acc: 0.3207
Train, Epoch: 1, Batch: 336, Step num: 336, Learning rate: 0.00023479, Avg batch loss: 0.7377, Avg batch acc: 0.3044
Train, Epoch: 1, Batch: 337, Step num: 337, Learning rate: 0.00023549, Avg batch loss: 0.7969, Avg batch acc: 0.3168
Train, Epoch: 1, Batch: 338, Step num: 338, Learning rate: 0.00023618, Avg batch loss: 0.7729, Avg batch acc: 0.3202
Train, Epoch: 1, Batch: 339, Step num: 339, Learning rate: 0.00023688, Avg batch loss: 0.7060, Avg batch acc: 0.3337
Train, Epoch: 1, Batch: 340, Step num: 340, Learning rate: 0.00023758, Avg batch loss: 0.7267, Avg batch acc: 0.3095
Train, Epoch: 1, Batch: 341, Step num: 341, Learning rate: 0.00023828, Avg batch loss: 0.7697, Avg batch acc: 0.3119
Train, Epoch: 1, Batch: 342, Step num: 342, Learning rate: 0.00023898, Avg batch loss: 0.7400, Avg batch acc: 0.3325
Train, Epoch: 1, Batch: 343, Step num: 343, Learning rate: 0.00023968, Avg batch loss: 0.8370, Avg batch acc: 0.3349
Train, Epoch: 1, Batch: 344, Step num: 344, Learning rate: 0.00024038, Avg batch loss: 0.6703, Avg batch acc: 0.3414
Train, Epoch: 1, Batch: 345, Step num: 345, Learning rate: 0.00024108, Avg batch loss: 0.8302, Avg batch acc: 0.3176
Train, Epoch: 1, Batch: 346, Step num: 346, Learning rate: 0.00024177, Avg batch loss: 0.7893, Avg batch acc: 0.3103
Train, Epoch: 1, Batch: 347, Step num: 347, Learning rate: 0.00024247, Avg batch loss: 0.7217, Avg batch acc: 0.3355
Train, Epoch: 1, Batch: 348, Step num: 348, Learning rate: 0.00024317, Avg batch loss: 0.7944, Avg batch acc: 0.3070
Train, Epoch: 1, Batch: 349, Step num: 349, Learning rate: 0.00024387, Avg batch loss: 0.8025, Avg batch acc: 0.3223
Train, Epoch: 1, Batch: 350, Step num: 350, Learning rate: 0.00024457, Avg batch loss: 0.7364, Avg batch acc: 0.3297
Train, Epoch: 1, Batch: 351, Step num: 351, Learning rate: 0.00024527, Avg batch loss: 0.7700, Avg batch acc: 0.3226
Train, Epoch: 1, Batch: 352, Step num: 352, Learning rate: 0.00024597, Avg batch loss: 0.7963, Avg batch acc: 0.3056
Train, Epoch: 1, Batch: 353, Step num: 353, Learning rate: 0.00024667, Avg batch loss: 0.7829, Avg batch acc: 0.3204
Train, Epoch: 1, Batch: 354, Step num: 354, Learning rate: 0.00024737, Avg batch loss: 0.7647, Avg batch acc: 0.3058
Train, Epoch: 1, Batch: 355, Step num: 355, Learning rate: 0.00024806, Avg batch loss: 0.7396, Avg batch acc: 0.3310
Train, Epoch: 1, Batch: 356, Step num: 356, Learning rate: 0.00024876, Avg batch loss: 0.6957, Avg batch acc: 0.3401
Train, Epoch: 1, Batch: 357, Step num: 357, Learning rate: 0.00024946, Avg batch loss: 0.7898, Avg batch acc: 0.3226
Train, Epoch: 1, Batch: 358, Step num: 358, Learning rate: 0.00025016, Avg batch loss: 0.7408, Avg batch acc: 0.3408
Train, Epoch: 1, Batch: 359, Step num: 359, Learning rate: 0.00025086, Avg batch loss: 0.7676, Avg batch acc: 0.3191
Train, Epoch: 1, Batch: 360, Step num: 360, Learning rate: 0.00025156, Avg batch loss: 0.7427, Avg batch acc: 0.3136
Train, Epoch: 1, Batch: 361, Step num: 361, Learning rate: 0.00025226, Avg batch loss: 0.6781, Avg batch acc: 0.3396
Train, Epoch: 1, Batch: 362, Step num: 362, Learning rate: 0.00025296, Avg batch loss: 0.7714, Avg batch acc: 0.3362
Train, Epoch: 1, Batch: 363, Step num: 363, Learning rate: 0.00025365, Avg batch loss: 0.8359, Avg batch acc: 0.3311
Train, Epoch: 1, Batch: 364, Step num: 364, Learning rate: 0.00025435, Avg batch loss: 0.7218, Avg batch acc: 0.3151
Train, Epoch: 1, Batch: 365, Step num: 365, Learning rate: 0.00025505, Avg batch loss: 0.7803, Avg batch acc: 0.3326
Train, Epoch: 1, Batch: 366, Step num: 366, Learning rate: 0.00025575, Avg batch loss: 0.8023, Avg batch acc: 0.2965
Train, Epoch: 1, Batch: 367, Step num: 367, Learning rate: 0.00025645, Avg batch loss: 0.6994, Avg batch acc: 0.3213
Train, Epoch: 1, Batch: 368, Step num: 368, Learning rate: 0.00025715, Avg batch loss: 0.7435, Avg batch acc: 0.3375
Train, Epoch: 1, Batch: 369, Step num: 369, Learning rate: 0.00025785, Avg batch loss: 0.7343, Avg batch acc: 0.3434
Train, Epoch: 1, Batch: 370, Step num: 370, Learning rate: 0.00025855, Avg batch loss: 0.7602, Avg batch acc: 0.3286
Train, Epoch: 1, Batch: 371, Step num: 371, Learning rate: 0.00025924, Avg batch loss: 0.7796, Avg batch acc: 0.3159
Train, Epoch: 1, Batch: 372, Step num: 372, Learning rate: 0.00025994, Avg batch loss: 0.7465, Avg batch acc: 0.3346
Train, Epoch: 1, Batch: 373, Step num: 373, Learning rate: 0.00026064, Avg batch loss: 0.7183, Avg batch acc: 0.3420
Train, Epoch: 1, Batch: 374, Step num: 374, Learning rate: 0.00026134, Avg batch loss: 0.6463, Avg batch acc: 0.3373
Train, Epoch: 1, Batch: 375, Step num: 375, Learning rate: 0.00026204, Avg batch loss: 0.7235, Avg batch acc: 0.3518
Train, Epoch: 1, Batch: 376, Step num: 376, Learning rate: 0.00026274, Avg batch loss: 0.7256, Avg batch acc: 0.2970
Train, Epoch: 1, Batch: 377, Step num: 377, Learning rate: 0.00026344, Avg batch loss: 0.7242, Avg batch acc: 0.3505
Train, Epoch: 1, Batch: 378, Step num: 378, Learning rate: 0.00026414, Avg batch loss: 0.7155, Avg batch acc: 0.3159
Train, Epoch: 1, Batch: 379, Step num: 379, Learning rate: 0.00026483, Avg batch loss: 0.7460, Avg batch acc: 0.3344
Train, Epoch: 1, Batch: 380, Step num: 380, Learning rate: 0.00026553, Avg batch loss: 0.7957, Avg batch acc: 0.3282
Train, Epoch: 1, Batch: 381, Step num: 381, Learning rate: 0.00026623, Avg batch loss: 0.6961, Avg batch acc: 0.3320
Train, Epoch: 1, Batch: 382, Step num: 382, Learning rate: 0.00026693, Avg batch loss: 0.6989, Avg batch acc: 0.3182
Train, Epoch: 1, Batch: 383, Step num: 383, Learning rate: 0.00026763, Avg batch loss: 0.6880, Avg batch acc: 0.3257
Train, Epoch: 1, Batch: 384, Step num: 384, Learning rate: 0.00026833, Avg batch loss: 0.7575, Avg batch acc: 0.3219
Train, Epoch: 1, Batch: 385, Step num: 385, Learning rate: 0.00026903, Avg batch loss: 0.7590, Avg batch acc: 0.3224
Train, Epoch: 1, Batch: 386, Step num: 386, Learning rate: 0.00026973, Avg batch loss: 0.7529, Avg batch acc: 0.3494
Train, Epoch: 1, Batch: 387, Step num: 387, Learning rate: 0.00027042, Avg batch loss: 0.7058, Avg batch acc: 0.3324
Train, Epoch: 1, Batch: 388, Step num: 388, Learning rate: 0.00027112, Avg batch loss: 0.7530, Avg batch acc: 0.3093
Train, Epoch: 1, Batch: 389, Step num: 389, Learning rate: 0.00027182, Avg batch loss: 0.7657, Avg batch acc: 0.3347
Train, Epoch: 1, Batch: 390, Step num: 390, Learning rate: 0.00027252, Avg batch loss: 0.7538, Avg batch acc: 0.3336
Train, Epoch: 1, Batch: 391, Step num: 391, Learning rate: 0.00027322, Avg batch loss: 0.7744, Avg batch acc: 0.3073
Train, Epoch: 1, Batch: 392, Step num: 392, Learning rate: 0.00027392, Avg batch loss: 0.7517, Avg batch acc: 0.3327
Train, Epoch: 1, Batch: 393, Step num: 393, Learning rate: 0.00027462, Avg batch loss: 0.7274, Avg batch acc: 0.3501
Train, Epoch: 1, Batch: 394, Step num: 394, Learning rate: 0.00027532, Avg batch loss: 0.6807, Avg batch acc: 0.3272
Train, Epoch: 1, Batch: 395, Step num: 395, Learning rate: 0.00027601, Avg batch loss: 0.7290, Avg batch acc: 0.3547
Train, Epoch: 1, Batch: 396, Step num: 396, Learning rate: 0.00027671, Avg batch loss: 0.7165, Avg batch acc: 0.3477
Train, Epoch: 1, Batch: 397, Step num: 397, Learning rate: 0.00027741, Avg batch loss: 0.7912, Avg batch acc: 0.3380
Train, Epoch: 1, Batch: 398, Step num: 398, Learning rate: 0.00027811, Avg batch loss: 0.6930, Avg batch acc: 0.3458
Train, Epoch: 1, Batch: 399, Step num: 399, Learning rate: 0.00027881, Avg batch loss: 0.7794, Avg batch acc: 0.2975
Train, Epoch: 1, Batch: 400, Step num: 400, Learning rate: 0.00027951, Avg batch loss: 0.7707, Avg batch acc: 0.3183
Train, Epoch: 1, Batch: 401, Step num: 401, Learning rate: 0.00028021, Avg batch loss: 0.7379, Avg batch acc: 0.3319
Train, Epoch: 1, Batch: 402, Step num: 402, Learning rate: 0.00028091, Avg batch loss: 0.7288, Avg batch acc: 0.3432
Train, Epoch: 1, Batch: 403, Step num: 403, Learning rate: 0.00028160, Avg batch loss: 0.7577, Avg batch acc: 0.3554
Train, Epoch: 1, Batch: 404, Step num: 404, Learning rate: 0.00028230, Avg batch loss: 0.7480, Avg batch acc: 0.3257
Train, Epoch: 1, Batch: 405, Step num: 405, Learning rate: 0.00028300, Avg batch loss: 0.7211, Avg batch acc: 0.3341
Train, Epoch: 1, Batch: 406, Step num: 406, Learning rate: 0.00028370, Avg batch loss: 0.7418, Avg batch acc: 0.3608
Train, Epoch: 1, Batch: 407, Step num: 407, Learning rate: 0.00028440, Avg batch loss: 0.6859, Avg batch acc: 0.3147
Train, Epoch: 1, Batch: 408, Step num: 408, Learning rate: 0.00028510, Avg batch loss: 0.7374, Avg batch acc: 0.3447
Train, Epoch: 1, Batch: 409, Step num: 409, Learning rate: 0.00028580, Avg batch loss: 0.7382, Avg batch acc: 0.3380
Train, Epoch: 1, Batch: 410, Step num: 410, Learning rate: 0.00028650, Avg batch loss: 0.6544, Avg batch acc: 0.3347
Train, Epoch: 1, Batch: 411, Step num: 411, Learning rate: 0.00028719, Avg batch loss: 0.7974, Avg batch acc: 0.3234
Train, Epoch: 1, Batch: 412, Step num: 412, Learning rate: 0.00028789, Avg batch loss: 0.7140, Avg batch acc: 0.3528
Train, Epoch: 1, Batch: 413, Step num: 413, Learning rate: 0.00028859, Avg batch loss: 0.7076, Avg batch acc: 0.3333
Train, Epoch: 1, Batch: 414, Step num: 414, Learning rate: 0.00028929, Avg batch loss: 0.6899, Avg batch acc: 0.3493
Train, Epoch: 1, Batch: 415, Step num: 415, Learning rate: 0.00028999, Avg batch loss: 0.7197, Avg batch acc: 0.3294
Train, Epoch: 1, Batch: 416, Step num: 416, Learning rate: 0.00029069, Avg batch loss: 0.8004, Avg batch acc: 0.3559
Train, Epoch: 1, Batch: 417, Step num: 417, Learning rate: 0.00029139, Avg batch loss: 0.6757, Avg batch acc: 0.3398
Train, Epoch: 1, Batch: 418, Step num: 418, Learning rate: 0.00029209, Avg batch loss: 0.6878, Avg batch acc: 0.3391
Train, Epoch: 1, Batch: 419, Step num: 419, Learning rate: 0.00029279, Avg batch loss: 0.7271, Avg batch acc: 0.3365
Train, Epoch: 1, Batch: 420, Step num: 420, Learning rate: 0.00029348, Avg batch loss: 0.6876, Avg batch acc: 0.3470
Train, Epoch: 1, Batch: 421, Step num: 421, Learning rate: 0.00029418, Avg batch loss: 0.6908, Avg batch acc: 0.3476
Train, Epoch: 1, Batch: 422, Step num: 422, Learning rate: 0.00029488, Avg batch loss: 0.7215, Avg batch acc: 0.3432
Train, Epoch: 1, Batch: 423, Step num: 423, Learning rate: 0.00029558, Avg batch loss: 0.6550, Avg batch acc: 0.3390
Train, Epoch: 1, Batch: 424, Step num: 424, Learning rate: 0.00029628, Avg batch loss: 0.6840, Avg batch acc: 0.3532
Train, Epoch: 1, Batch: 425, Step num: 425, Learning rate: 0.00029698, Avg batch loss: 0.7241, Avg batch acc: 0.3403
Train, Epoch: 1, Batch: 426, Step num: 426, Learning rate: 0.00029768, Avg batch loss: 0.6807, Avg batch acc: 0.3438
Train, Epoch: 1, Batch: 427, Step num: 427, Learning rate: 0.00029838, Avg batch loss: 0.7004, Avg batch acc: 0.3391
Train, Epoch: 1, Batch: 428, Step num: 428, Learning rate: 0.00029907, Avg batch loss: 0.7512, Avg batch acc: 0.3494
Train, Epoch: 1, Batch: 429, Step num: 429, Learning rate: 0.00029977, Avg batch loss: 0.6281, Avg batch acc: 0.3566
Train, Epoch: 1, Batch: 430, Step num: 430, Learning rate: 0.00030047, Avg batch loss: 0.7570, Avg batch acc: 0.3098
Train, Epoch: 1, Batch: 431, Step num: 431, Learning rate: 0.00030117, Avg batch loss: 0.7274, Avg batch acc: 0.3691
Train, Epoch: 1, Batch: 432, Step num: 432, Learning rate: 0.00030187, Avg batch loss: 0.7171, Avg batch acc: 0.3340
Train, Epoch: 1, Batch: 433, Step num: 433, Learning rate: 0.00030257, Avg batch loss: 0.7008, Avg batch acc: 0.3301
Train, Epoch: 1, Batch: 434, Step num: 434, Learning rate: 0.00030327, Avg batch loss: 0.7148, Avg batch acc: 0.3286
Train, Epoch: 1, Batch: 435, Step num: 435, Learning rate: 0.00030397, Avg batch loss: 0.7183, Avg batch acc: 0.3518
Train, Epoch: 1, Batch: 436, Step num: 436, Learning rate: 0.00030466, Avg batch loss: 0.6777, Avg batch acc: 0.3377
Train, Epoch: 1, Batch: 437, Step num: 437, Learning rate: 0.00030536, Avg batch loss: 0.7307, Avg batch acc: 0.3623
Train, Epoch: 1, Batch: 438, Step num: 438, Learning rate: 0.00030606, Avg batch loss: 0.6999, Avg batch acc: 0.3642
Train, Epoch: 1, Batch: 439, Step num: 439, Learning rate: 0.00030676, Avg batch loss: 0.7327, Avg batch acc: 0.3634
Train, Epoch: 1, Batch: 440, Step num: 440, Learning rate: 0.00030746, Avg batch loss: 0.6699, Avg batch acc: 0.3721
Train, Epoch: 1, Batch: 441, Step num: 441, Learning rate: 0.00030816, Avg batch loss: 0.7178, Avg batch acc: 0.3425
Train, Epoch: 1, Batch: 442, Step num: 442, Learning rate: 0.00030886, Avg batch loss: 0.7004, Avg batch acc: 0.3618
Train, Epoch: 1, Batch: 443, Step num: 443, Learning rate: 0.00030956, Avg batch loss: 0.7419, Avg batch acc: 0.3241
Train, Epoch: 1, Batch: 444, Step num: 444, Learning rate: 0.00031025, Avg batch loss: 0.7427, Avg batch acc: 0.3450
Train, Epoch: 1, Batch: 445, Step num: 445, Learning rate: 0.00031095, Avg batch loss: 0.6639, Avg batch acc: 0.3779
Train, Epoch: 1, Batch: 446, Step num: 446, Learning rate: 0.00031165, Avg batch loss: 0.7459, Avg batch acc: 0.3337
Train, Epoch: 1, Batch: 447, Step num: 447, Learning rate: 0.00031235, Avg batch loss: 0.6326, Avg batch acc: 0.3539
Train, Epoch: 1, Batch: 448, Step num: 448, Learning rate: 0.00031305, Avg batch loss: 0.7042, Avg batch acc: 0.3343
Train, Epoch: 1, Batch: 449, Step num: 449, Learning rate: 0.00031375, Avg batch loss: 0.6889, Avg batch acc: 0.3374
Train, Epoch: 1, Batch: 450, Step num: 450, Learning rate: 0.00031445, Avg batch loss: 0.7177, Avg batch acc: 0.3479
Train, Epoch: 1, Batch: 451, Step num: 451, Learning rate: 0.00031515, Avg batch loss: 0.6889, Avg batch acc: 0.3398
Train, Epoch: 1, Batch: 452, Step num: 452, Learning rate: 0.00031584, Avg batch loss: 0.7609, Avg batch acc: 0.3391
Train, Epoch: 1, Batch: 453, Step num: 453, Learning rate: 0.00031654, Avg batch loss: 0.6804, Avg batch acc: 0.3404
Train, Epoch: 1, Batch: 454, Step num: 454, Learning rate: 0.00031724, Avg batch loss: 0.6646, Avg batch acc: 0.3467
Train, Epoch: 1, Batch: 455, Step num: 455, Learning rate: 0.00031794, Avg batch loss: 0.7028, Avg batch acc: 0.3670
Train, Epoch: 1, Batch: 456, Step num: 456, Learning rate: 0.00031864, Avg batch loss: 0.7267, Avg batch acc: 0.3467
Train, Epoch: 1, Batch: 457, Step num: 457, Learning rate: 0.00031934, Avg batch loss: 0.6180, Avg batch acc: 0.3771
Train, Epoch: 1, Batch: 458, Step num: 458, Learning rate: 0.00032004, Avg batch loss: 0.6871, Avg batch acc: 0.3564
Train, Epoch: 1, Batch: 459, Step num: 459, Learning rate: 0.00032074, Avg batch loss: 0.6869, Avg batch acc: 0.3398
Train, Epoch: 1, Batch: 460, Step num: 460, Learning rate: 0.00032143, Avg batch loss: 0.6749, Avg batch acc: 0.3411
Train, Epoch: 1, Batch: 461, Step num: 461, Learning rate: 0.00032213, Avg batch loss: 0.7627, Avg batch acc: 0.3239
Train, Epoch: 1, Batch: 462, Step num: 462, Learning rate: 0.00032283, Avg batch loss: 0.7061, Avg batch acc: 0.3509
Train, Epoch: 1, Batch: 463, Step num: 463, Learning rate: 0.00032353, Avg batch loss: 0.6745, Avg batch acc: 0.3420
Train, Epoch: 1, Batch: 464, Step num: 464, Learning rate: 0.00032423, Avg batch loss: 0.6877, Avg batch acc: 0.3539
Train, Epoch: 1, Batch: 465, Step num: 465, Learning rate: 0.00032493, Avg batch loss: 0.6974, Avg batch acc: 0.3423
Train, Epoch: 1, Batch: 466, Step num: 466, Learning rate: 0.00032563, Avg batch loss: 0.6918, Avg batch acc: 0.3671
Train, Epoch: 1, Batch: 467, Step num: 467, Learning rate: 0.00032633, Avg batch loss: 0.7262, Avg batch acc: 0.3300
Train, Epoch: 1, Batch: 468, Step num: 468, Learning rate: 0.00032702, Avg batch loss: 0.6892, Avg batch acc: 0.3630
Train, Epoch: 1, Batch: 469, Step num: 469, Learning rate: 0.00032772, Avg batch loss: 0.7373, Avg batch acc: 0.3625
Train, Epoch: 1, Batch: 470, Step num: 470, Learning rate: 0.00032842, Avg batch loss: 0.7239, Avg batch acc: 0.3477
Train, Epoch: 1, Batch: 471, Step num: 471, Learning rate: 0.00032912, Avg batch loss: 0.6615, Avg batch acc: 0.3563
Train, Epoch: 1, Batch: 472, Step num: 472, Learning rate: 0.00032982, Avg batch loss: 0.6620, Avg batch acc: 0.3571
Train, Epoch: 1, Batch: 473, Step num: 473, Learning rate: 0.00033052, Avg batch loss: 0.7206, Avg batch acc: 0.3552
Train, Epoch: 1, Batch: 474, Step num: 474, Learning rate: 0.00033122, Avg batch loss: 0.7136, Avg batch acc: 0.3448
Train, Epoch: 1, Batch: 475, Step num: 475, Learning rate: 0.00033192, Avg batch loss: 0.7035, Avg batch acc: 0.3586
Train, Epoch: 1, Batch: 476, Step num: 476, Learning rate: 0.00033262, Avg batch loss: 0.7086, Avg batch acc: 0.3463
Train, Epoch: 1, Batch: 477, Step num: 477, Learning rate: 0.00033331, Avg batch loss: 0.6834, Avg batch acc: 0.3603
Train, Epoch: 1, Batch: 478, Step num: 478, Learning rate: 0.00033401, Avg batch loss: 0.7788, Avg batch acc: 0.3385
Train, Epoch: 1, Batch: 479, Step num: 479, Learning rate: 0.00033471, Avg batch loss: 0.7125, Avg batch acc: 0.3332
Train, Epoch: 1, Batch: 480, Step num: 480, Learning rate: 0.00033541, Avg batch loss: 0.7659, Avg batch acc: 0.3525
Train, Epoch: 1, Batch: 481, Step num: 481, Learning rate: 0.00033611, Avg batch loss: 0.7430, Avg batch acc: 0.3563
Train, Epoch: 1, Batch: 482, Step num: 482, Learning rate: 0.00033681, Avg batch loss: 0.6292, Avg batch acc: 0.3634
Train, Epoch: 1, Batch: 483, Step num: 483, Learning rate: 0.00033751, Avg batch loss: 0.6685, Avg batch acc: 0.3532
Train, Epoch: 1, Batch: 484, Step num: 484, Learning rate: 0.00033821, Avg batch loss: 0.6982, Avg batch acc: 0.3638
Train, Epoch: 1, Batch: 485, Step num: 485, Learning rate: 0.00033890, Avg batch loss: 0.6238, Avg batch acc: 0.3718
Train, Epoch: 1, Batch: 486, Step num: 486, Learning rate: 0.00033960, Avg batch loss: 0.6653, Avg batch acc: 0.3562
Train, Epoch: 1, Batch: 487, Step num: 487, Learning rate: 0.00034030, Avg batch loss: 0.6656, Avg batch acc: 0.3557
Train, Epoch: 1, Batch: 488, Step num: 488, Learning rate: 0.00034100, Avg batch loss: 0.7132, Avg batch acc: 0.3747
Train, Epoch: 1, Batch: 489, Step num: 489, Learning rate: 0.00034170, Avg batch loss: 0.6955, Avg batch acc: 0.3364
Train, Epoch: 1, Batch: 490, Step num: 490, Learning rate: 0.00034240, Avg batch loss: 0.6572, Avg batch acc: 0.3546
Train, Epoch: 1, Batch: 491, Step num: 491, Learning rate: 0.00034310, Avg batch loss: 0.6825, Avg batch acc: 0.3668
Train, Epoch: 1, Batch: 492, Step num: 492, Learning rate: 0.00034380, Avg batch loss: 0.7119, Avg batch acc: 0.3755
Train, Epoch: 1, Batch: 493, Step num: 493, Learning rate: 0.00034449, Avg batch loss: 0.6204, Avg batch acc: 0.3464
Train, Epoch: 1, Batch: 494, Step num: 494, Learning rate: 0.00034519, Avg batch loss: 0.6728, Avg batch acc: 0.3601
Train, Epoch: 1, Batch: 495, Step num: 495, Learning rate: 0.00034589, Avg batch loss: 0.7084, Avg batch acc: 0.3463
Train, Epoch: 1, Batch: 496, Step num: 496, Learning rate: 0.00034659, Avg batch loss: 0.7461, Avg batch acc: 0.3377
Train, Epoch: 1, Batch: 497, Step num: 497, Learning rate: 0.00034729, Avg batch loss: 0.7638, Avg batch acc: 0.3309
Train, Epoch: 1, Batch: 498, Step num: 498, Learning rate: 0.00034799, Avg batch loss: 0.6618, Avg batch acc: 0.3492
Train, Epoch: 1, Batch: 499, Step num: 499, Learning rate: 0.00034869, Avg batch loss: 0.7566, Avg batch acc: 0.3438
Train, Epoch: 1, Batch: 500, Step num: 500, Learning rate: 0.00034939, Avg batch loss: 0.6409, Avg batch acc: 0.3535
Train, Epoch: 1, Batch: 501, Step num: 501, Learning rate: 0.00035008, Avg batch loss: 0.6349, Avg batch acc: 0.3557
Train, Epoch: 1, Batch: 502, Step num: 502, Learning rate: 0.00035078, Avg batch loss: 0.6521, Avg batch acc: 0.3682
Train, Epoch: 1, Batch: 503, Step num: 503, Learning rate: 0.00035148, Avg batch loss: 0.6788, Avg batch acc: 0.3454
Train, Epoch: 1, Batch: 504, Step num: 504, Learning rate: 0.00035218, Avg batch loss: 0.6329, Avg batch acc: 0.3805
Train, Epoch: 1, Batch: 505, Step num: 505, Learning rate: 0.00035288, Avg batch loss: 0.6109, Avg batch acc: 0.3632
Train, Epoch: 1, Batch: 506, Step num: 506, Learning rate: 0.00035358, Avg batch loss: 0.7212, Avg batch acc: 0.3315
Train, Epoch: 1, Batch: 507, Step num: 507, Learning rate: 0.00035428, Avg batch loss: 0.6949, Avg batch acc: 0.3519
Train, Epoch: 1, Batch: 508, Step num: 508, Learning rate: 0.00035498, Avg batch loss: 0.7161, Avg batch acc: 0.3481
Train, Epoch: 1, Batch: 509, Step num: 509, Learning rate: 0.00035567, Avg batch loss: 0.7202, Avg batch acc: 0.3535
Train, Epoch: 1, Batch: 510, Step num: 510, Learning rate: 0.00035637, Avg batch loss: 0.6551, Avg batch acc: 0.3543
Train, Epoch: 1, Batch: 511, Step num: 511, Learning rate: 0.00035707, Avg batch loss: 0.7084, Avg batch acc: 0.3323
Train, Epoch: 1, Batch: 512, Step num: 512, Learning rate: 0.00035777, Avg batch loss: 0.7748, Avg batch acc: 0.3552
Train, Epoch: 1, Batch: 513, Step num: 513, Learning rate: 0.00035847, Avg batch loss: 0.7261, Avg batch acc: 0.3456
Train, Epoch: 1, Batch: 514, Step num: 514, Learning rate: 0.00035917, Avg batch loss: 0.7163, Avg batch acc: 0.3505
Train, Epoch: 1, Batch: 515, Step num: 515, Learning rate: 0.00035987, Avg batch loss: 0.6207, Avg batch acc: 0.3763
Train, Epoch: 1, Batch: 516, Step num: 516, Learning rate: 0.00036057, Avg batch loss: 0.7294, Avg batch acc: 0.3516
Train, Epoch: 1, Batch: 517, Step num: 517, Learning rate: 0.00036126, Avg batch loss: 0.6291, Avg batch acc: 0.3878
Train, Epoch: 1, Batch: 518, Step num: 518, Learning rate: 0.00036196, Avg batch loss: 0.6689, Avg batch acc: 0.3527
Train, Epoch: 1, Batch: 519, Step num: 519, Learning rate: 0.00036266, Avg batch loss: 0.6426, Avg batch acc: 0.3716
Train, Epoch: 1, Batch: 520, Step num: 520, Learning rate: 0.00036336, Avg batch loss: 0.7192, Avg batch acc: 0.3688
Train, Epoch: 1, Batch: 521, Step num: 521, Learning rate: 0.00036406, Avg batch loss: 0.7434, Avg batch acc: 0.3616
Train, Epoch: 1, Batch: 522, Step num: 522, Learning rate: 0.00036476, Avg batch loss: 0.7305, Avg batch acc: 0.3499
Train, Epoch: 1, Batch: 523, Step num: 523, Learning rate: 0.00036546, Avg batch loss: 0.7553, Avg batch acc: 0.3655
Train, Epoch: 1, Batch: 524, Step num: 524, Learning rate: 0.00036616, Avg batch loss: 0.7529, Avg batch acc: 0.3443
Train, Epoch: 1, Batch: 525, Step num: 525, Learning rate: 0.00036685, Avg batch loss: 0.7110, Avg batch acc: 0.3523
Train, Epoch: 1, Batch: 526, Step num: 526, Learning rate: 0.00036755, Avg batch loss: 0.6930, Avg batch acc: 0.3644
Train, Epoch: 1, Batch: 527, Step num: 527, Learning rate: 0.00036825, Avg batch loss: 0.6769, Avg batch acc: 0.3471
Train, Epoch: 1, Batch: 528, Step num: 528, Learning rate: 0.00036895, Avg batch loss: 0.6643, Avg batch acc: 0.3681
Train, Epoch: 1, Batch: 529, Step num: 529, Learning rate: 0.00036965, Avg batch loss: 0.7353, Avg batch acc: 0.3479
Train, Epoch: 1, Batch: 530, Step num: 530, Learning rate: 0.00037035, Avg batch loss: 0.6834, Avg batch acc: 0.3633
Train, Epoch: 1, Batch: 531, Step num: 531, Learning rate: 0.00037105, Avg batch loss: 0.6257, Avg batch acc: 0.3635
Train, Epoch: 1, Batch: 532, Step num: 532, Learning rate: 0.00037175, Avg batch loss: 0.6984, Avg batch acc: 0.3528
Train, Epoch: 1, Batch: 533, Step num: 533, Learning rate: 0.00037245, Avg batch loss: 0.6639, Avg batch acc: 0.3561
Train, Epoch: 1, Batch: 534, Step num: 534, Learning rate: 0.00037314, Avg batch loss: 0.6290, Avg batch acc: 0.3588
Train, Epoch: 1, Batch: 535, Step num: 535, Learning rate: 0.00037384, Avg batch loss: 0.7333, Avg batch acc: 0.3358
Train, Epoch: 1, Batch: 536, Step num: 536, Learning rate: 0.00037454, Avg batch loss: 0.6962, Avg batch acc: 0.3562
Train, Epoch: 1, Batch: 537, Step num: 537, Learning rate: 0.00037524, Avg batch loss: 0.6939, Avg batch acc: 0.3574
Train, Epoch: 1, Batch: 538, Step num: 538, Learning rate: 0.00037594, Avg batch loss: 0.6823, Avg batch acc: 0.3511
Train, Epoch: 1, Batch: 539, Step num: 539, Learning rate: 0.00037664, Avg batch loss: 0.6488, Avg batch acc: 0.3623
Train, Epoch: 1, Batch: 540, Step num: 540, Learning rate: 0.00037734, Avg batch loss: 0.6918, Avg batch acc: 0.3680
Train, Epoch: 1, Batch: 541, Step num: 541, Learning rate: 0.00037804, Avg batch loss: 0.6553, Avg batch acc: 0.3709
Train, Epoch: 1, Batch: 542, Step num: 542, Learning rate: 0.00037873, Avg batch loss: 0.6451, Avg batch acc: 0.3790
Train, Epoch: 1, Batch: 543, Step num: 543, Learning rate: 0.00037943, Avg batch loss: 0.7115, Avg batch acc: 0.3597
Train, Epoch: 1, Batch: 544, Step num: 544, Learning rate: 0.00038013, Avg batch loss: 0.6982, Avg batch acc: 0.3738
Train, Epoch: 1, Batch: 545, Step num: 545, Learning rate: 0.00038083, Avg batch loss: 0.6501, Avg batch acc: 0.3724
Train, Epoch: 1, Batch: 546, Step num: 546, Learning rate: 0.00038153, Avg batch loss: 0.6184, Avg batch acc: 0.3938
Train, Epoch: 1, Batch: 547, Step num: 547, Learning rate: 0.00038223, Avg batch loss: 0.7235, Avg batch acc: 0.3695
Train, Epoch: 1, Batch: 548, Step num: 548, Learning rate: 0.00038293, Avg batch loss: 0.6892, Avg batch acc: 0.3804
Train, Epoch: 1, Batch: 549, Step num: 549, Learning rate: 0.00038363, Avg batch loss: 0.6541, Avg batch acc: 0.3637
Train, Epoch: 1, Batch: 550, Step num: 550, Learning rate: 0.00038432, Avg batch loss: 0.7029, Avg batch acc: 0.3357
Train, Epoch: 1, Batch: 551, Step num: 551, Learning rate: 0.00038502, Avg batch loss: 0.6958, Avg batch acc: 0.3630
Train, Epoch: 1, Batch: 552, Step num: 552, Learning rate: 0.00038572, Avg batch loss: 0.6871, Avg batch acc: 0.3697
Train, Epoch: 1, Batch: 553, Step num: 553, Learning rate: 0.00038642, Avg batch loss: 0.6998, Avg batch acc: 0.3841
Train, Epoch: 1, Batch: 554, Step num: 554, Learning rate: 0.00038712, Avg batch loss: 0.7093, Avg batch acc: 0.3554
Train, Epoch: 1, Batch: 555, Step num: 555, Learning rate: 0.00038782, Avg batch loss: 0.6552, Avg batch acc: 0.3718
Train, Epoch: 1, Batch: 556, Step num: 556, Learning rate: 0.00038852, Avg batch loss: 0.6595, Avg batch acc: 0.3697
Train, Epoch: 1, Batch: 557, Step num: 557, Learning rate: 0.00038922, Avg batch loss: 0.6689, Avg batch acc: 0.3816
Train, Epoch: 1, Batch: 558, Step num: 558, Learning rate: 0.00038991, Avg batch loss: 0.6555, Avg batch acc: 0.3697
Train, Epoch: 1, Batch: 559, Step num: 559, Learning rate: 0.00039061, Avg batch loss: 0.6427, Avg batch acc: 0.3667
Train, Epoch: 1, Batch: 560, Step num: 560, Learning rate: 0.00039131, Avg batch loss: 0.6775, Avg batch acc: 0.3771
Train, Epoch: 1, Batch: 561, Step num: 561, Learning rate: 0.00039201, Avg batch loss: 0.7173, Avg batch acc: 0.3526
Train, Epoch: 1, Batch: 562, Step num: 562, Learning rate: 0.00039271, Avg batch loss: 0.6784, Avg batch acc: 0.3538
Train, Epoch: 1, Batch: 563, Step num: 563, Learning rate: 0.00039341, Avg batch loss: 0.6842, Avg batch acc: 0.3909
Train, Epoch: 1, Batch: 564, Step num: 564, Learning rate: 0.00039411, Avg batch loss: 0.5963, Avg batch acc: 0.3690
Train, Epoch: 1, Batch: 565, Step num: 565, Learning rate: 0.00039481, Avg batch loss: 0.6558, Avg batch acc: 0.3524
Train, Epoch: 1, Batch: 566, Step num: 566, Learning rate: 0.00039550, Avg batch loss: 0.6807, Avg batch acc: 0.3859
Train, Epoch: 1, Batch: 567, Step num: 567, Learning rate: 0.00039620, Avg batch loss: 0.7377, Avg batch acc: 0.3585
Train, Epoch: 1, Batch: 568, Step num: 568, Learning rate: 0.00039690, Avg batch loss: 0.7062, Avg batch acc: 0.3720
Train, Epoch: 1, Batch: 569, Step num: 569, Learning rate: 0.00039760, Avg batch loss: 0.6854, Avg batch acc: 0.3405
Train, Epoch: 1, Batch: 570, Step num: 570, Learning rate: 0.00039830, Avg batch loss: 0.6895, Avg batch acc: 0.3504
Train, Epoch: 1, Batch: 571, Step num: 571, Learning rate: 0.00039900, Avg batch loss: 0.6988, Avg batch acc: 0.3482
Train, Epoch: 1, Batch: 572, Step num: 572, Learning rate: 0.00039970, Avg batch loss: 0.7553, Avg batch acc: 0.3503
Train, Epoch: 1, Batch: 573, Step num: 573, Learning rate: 0.00040040, Avg batch loss: 0.7025, Avg batch acc: 0.3799
Train, Epoch: 1, Batch: 574, Step num: 574, Learning rate: 0.00040109, Avg batch loss: 0.7132, Avg batch acc: 0.3581
Train, Epoch: 1, Batch: 575, Step num: 575, Learning rate: 0.00040179, Avg batch loss: 0.6525, Avg batch acc: 0.3719
Train, Epoch: 1, Batch: 576, Step num: 576, Learning rate: 0.00040249, Avg batch loss: 0.7157, Avg batch acc: 0.3615
Train, Epoch: 1, Batch: 577, Step num: 577, Learning rate: 0.00040319, Avg batch loss: 0.6953, Avg batch acc: 0.3775
Train, Epoch: 1, Batch: 578, Step num: 578, Learning rate: 0.00040389, Avg batch loss: 0.6790, Avg batch acc: 0.3687
Train, Epoch: 1, Batch: 579, Step num: 579, Learning rate: 0.00040459, Avg batch loss: 0.7149, Avg batch acc: 0.3552
Train, Epoch: 1, Batch: 580, Step num: 580, Learning rate: 0.00040529, Avg batch loss: 0.6455, Avg batch acc: 0.3596
Train, Epoch: 1, Batch: 581, Step num: 581, Learning rate: 0.00040599, Avg batch loss: 0.6790, Avg batch acc: 0.3590
Train, Epoch: 1, Batch: 582, Step num: 582, Learning rate: 0.00040668, Avg batch loss: 0.6939, Avg batch acc: 0.3568
Train, Epoch: 1, Batch: 583, Step num: 583, Learning rate: 0.00040738, Avg batch loss: 0.6948, Avg batch acc: 0.3657
Train, Epoch: 1, Batch: 584, Step num: 584, Learning rate: 0.00040808, Avg batch loss: 0.6966, Avg batch acc: 0.3696
Train, Epoch: 1, Batch: 585, Step num: 585, Learning rate: 0.00040878, Avg batch loss: 0.6548, Avg batch acc: 0.3764
Train, Epoch: 1, Batch: 586, Step num: 586, Learning rate: 0.00040948, Avg batch loss: 0.6586, Avg batch acc: 0.3713
Train, Epoch: 1, Batch: 587, Step num: 587, Learning rate: 0.00041018, Avg batch loss: 0.6994, Avg batch acc: 0.3400
Train, Epoch: 1, Batch: 588, Step num: 588, Learning rate: 0.00041088, Avg batch loss: 0.6211, Avg batch acc: 0.3784
Train, Epoch: 1, Batch: 589, Step num: 589, Learning rate: 0.00041158, Avg batch loss: 0.6946, Avg batch acc: 0.3634
Train, Epoch: 1, Batch: 590, Step num: 590, Learning rate: 0.00041228, Avg batch loss: 0.6647, Avg batch acc: 0.3668
Train, Epoch: 1, Batch: 591, Step num: 591, Learning rate: 0.00041297, Avg batch loss: 0.6486, Avg batch acc: 0.3670
Train, Epoch: 1, Batch: 592, Step num: 592, Learning rate: 0.00041367, Avg batch loss: 0.5888, Avg batch acc: 0.3951
Train, Epoch: 1, Batch: 593, Step num: 593, Learning rate: 0.00041437, Avg batch loss: 0.7210, Avg batch acc: 0.3510
Train, Epoch: 1, Batch: 594, Step num: 594, Learning rate: 0.00041507, Avg batch loss: 0.6202, Avg batch acc: 0.3766
Train, Epoch: 1, Batch: 595, Step num: 595, Learning rate: 0.00041577, Avg batch loss: 0.6602, Avg batch acc: 0.3658
Train, Epoch: 1, Batch: 596, Step num: 596, Learning rate: 0.00041647, Avg batch loss: 0.6974, Avg batch acc: 0.3675
Train, Epoch: 1, Batch: 597, Step num: 597, Learning rate: 0.00041717, Avg batch loss: 0.6483, Avg batch acc: 0.3900
Train, Epoch: 1, Batch: 598, Step num: 598, Learning rate: 0.00041787, Avg batch loss: 0.6883, Avg batch acc: 0.3790
Train, Epoch: 1, Batch: 599, Step num: 599, Learning rate: 0.00041856, Avg batch loss: 0.6354, Avg batch acc: 0.3628
Train, Epoch: 1, Batch: 600, Step num: 600, Learning rate: 0.00041926, Avg batch loss: 0.6764, Avg batch acc: 0.3629
Train, Epoch: 1, Batch: 601, Step num: 601, Learning rate: 0.00041996, Avg batch loss: 0.5663, Avg batch acc: 0.4001
Train, Epoch: 1, Batch: 602, Step num: 602, Learning rate: 0.00042066, Avg batch loss: 0.6176, Avg batch acc: 0.3762
Train, Epoch: 1, Batch: 603, Step num: 603, Learning rate: 0.00042136, Avg batch loss: 0.6260, Avg batch acc: 0.3925
Train, Epoch: 1, Batch: 604, Step num: 604, Learning rate: 0.00042206, Avg batch loss: 0.6777, Avg batch acc: 0.3765
Train, Epoch: 1, Batch: 605, Step num: 605, Learning rate: 0.00042276, Avg batch loss: 0.6923, Avg batch acc: 0.3755
Train, Epoch: 1, Batch: 606, Step num: 606, Learning rate: 0.00042346, Avg batch loss: 0.6117, Avg batch acc: 0.3764
Train, Epoch: 1, Batch: 607, Step num: 607, Learning rate: 0.00042415, Avg batch loss: 0.6443, Avg batch acc: 0.3651
Train, Epoch: 1, Batch: 608, Step num: 608, Learning rate: 0.00042485, Avg batch loss: 0.6876, Avg batch acc: 0.3672
Train, Epoch: 1, Batch: 609, Step num: 609, Learning rate: 0.00042555, Avg batch loss: 0.6035, Avg batch acc: 0.3637
Train, Epoch: 1, Batch: 610, Step num: 610, Learning rate: 0.00042625, Avg batch loss: 0.6645, Avg batch acc: 0.3765
Train, Epoch: 1, Batch: 611, Step num: 611, Learning rate: 0.00042695, Avg batch loss: 0.6803, Avg batch acc: 0.3704
Train, Epoch: 1, Batch: 612, Step num: 612, Learning rate: 0.00042765, Avg batch loss: 0.7044, Avg batch acc: 0.3522
Train, Epoch: 1, Batch: 613, Step num: 613, Learning rate: 0.00042835, Avg batch loss: 0.6074, Avg batch acc: 0.3934
Train, Epoch: 1, Batch: 614, Step num: 614, Learning rate: 0.00042905, Avg batch loss: 0.6803, Avg batch acc: 0.3801
Train, Epoch: 1, Batch: 615, Step num: 615, Learning rate: 0.00042974, Avg batch loss: 0.7043, Avg batch acc: 0.3598
Train, Epoch: 1, Batch: 616, Step num: 616, Learning rate: 0.00043044, Avg batch loss: 0.6363, Avg batch acc: 0.3659
Train, Epoch: 1, Batch: 617, Step num: 617, Learning rate: 0.00043114, Avg batch loss: 0.6259, Avg batch acc: 0.3836
Train, Epoch: 1, Batch: 618, Step num: 618, Learning rate: 0.00043184, Avg batch loss: 0.7176, Avg batch acc: 0.3610
Train, Epoch: 1, Batch: 619, Step num: 619, Learning rate: 0.00043254, Avg batch loss: 0.6665, Avg batch acc: 0.3900
Train, Epoch: 1, Batch: 620, Step num: 620, Learning rate: 0.00043324, Avg batch loss: 0.6860, Avg batch acc: 0.3634
Train, Epoch: 1, Batch: 621, Step num: 621, Learning rate: 0.00043394, Avg batch loss: 0.6871, Avg batch acc: 0.3811
Train, Epoch: 1, Batch: 622, Step num: 622, Learning rate: 0.00043464, Avg batch loss: 0.6453, Avg batch acc: 0.3707
Train, Epoch: 1, Batch: 623, Step num: 623, Learning rate: 0.00043533, Avg batch loss: 0.6284, Avg batch acc: 0.3779
Train, Epoch: 1, Batch: 624, Step num: 624, Learning rate: 0.00043603, Avg batch loss: 0.6753, Avg batch acc: 0.3681
Train, Epoch: 1, Batch: 625, Step num: 625, Learning rate: 0.00043673, Avg batch loss: 0.6555, Avg batch acc: 0.3722
Train, Epoch: 1, Batch: 626, Step num: 626, Learning rate: 0.00043743, Avg batch loss: 0.6566, Avg batch acc: 0.3735
Train, Epoch: 1, Batch: 627, Step num: 627, Learning rate: 0.00043813, Avg batch loss: 0.6600, Avg batch acc: 0.3723
Train, Epoch: 1, Batch: 628, Step num: 628, Learning rate: 0.00043883, Avg batch loss: 0.6674, Avg batch acc: 0.3712
Train, Epoch: 1, Batch: 629, Step num: 629, Learning rate: 0.00043953, Avg batch loss: 0.6912, Avg batch acc: 0.3761
Train, Epoch: 1, Batch: 630, Step num: 630, Learning rate: 0.00044023, Avg batch loss: 0.6669, Avg batch acc: 0.3733
Train, Epoch: 1, Batch: 631, Step num: 631, Learning rate: 0.00044092, Avg batch loss: 0.6680, Avg batch acc: 0.3765
Train, Epoch: 1, Batch: 632, Step num: 632, Learning rate: 0.00044162, Avg batch loss: 0.6437, Avg batch acc: 0.3784
Train, Epoch: 1, Batch: 633, Step num: 633, Learning rate: 0.00044232, Avg batch loss: 0.6239, Avg batch acc: 0.3837
Train, Epoch: 1, Batch: 634, Step num: 634, Learning rate: 0.00044302, Avg batch loss: 0.6554, Avg batch acc: 0.3573
Train, Epoch: 1, Batch: 635, Step num: 635, Learning rate: 0.00044372, Avg batch loss: 0.6150, Avg batch acc: 0.3645
Train, Epoch: 1, Batch: 636, Step num: 636, Learning rate: 0.00044442, Avg batch loss: 0.6616, Avg batch acc: 0.3887
Train, Epoch: 1, Batch: 637, Step num: 637, Learning rate: 0.00044512, Avg batch loss: 0.6711, Avg batch acc: 0.3558
Train, Epoch: 1, Batch: 638, Step num: 638, Learning rate: 0.00044582, Avg batch loss: 0.5802, Avg batch acc: 0.3837
Train, Epoch: 1, Batch: 639, Step num: 639, Learning rate: 0.00044651, Avg batch loss: 0.7056, Avg batch acc: 0.3713
Train, Epoch: 1, Batch: 640, Step num: 640, Learning rate: 0.00044721, Avg batch loss: 0.6460, Avg batch acc: 0.3485
Train, Epoch: 1, Batch: 641, Step num: 641, Learning rate: 0.00044791, Avg batch loss: 0.6987, Avg batch acc: 0.3687
Train, Epoch: 1, Batch: 642, Step num: 642, Learning rate: 0.00044861, Avg batch loss: 0.6508, Avg batch acc: 0.3719
Train, Epoch: 1, Batch: 643, Step num: 643, Learning rate: 0.00044931, Avg batch loss: 0.6920, Avg batch acc: 0.3801
Train, Epoch: 1, Batch: 644, Step num: 644, Learning rate: 0.00045001, Avg batch loss: 0.6872, Avg batch acc: 0.3634
Train, Epoch: 1, Batch: 645, Step num: 645, Learning rate: 0.00045071, Avg batch loss: 0.6285, Avg batch acc: 0.3637
Train, Epoch: 1, Batch: 646, Step num: 646, Learning rate: 0.00045141, Avg batch loss: 0.6155, Avg batch acc: 0.3851
Train, Epoch: 1, Batch: 647, Step num: 647, Learning rate: 0.00045210, Avg batch loss: 0.6312, Avg batch acc: 0.3781
Train, Epoch: 1, Batch: 648, Step num: 648, Learning rate: 0.00045280, Avg batch loss: 0.6878, Avg batch acc: 0.3715
Train, Epoch: 1, Batch: 649, Step num: 649, Learning rate: 0.00045350, Avg batch loss: 0.6452, Avg batch acc: 0.3623
Train, Epoch: 1, Batch: 650, Step num: 650, Learning rate: 0.00045420, Avg batch loss: 0.6568, Avg batch acc: 0.3845
Train, Epoch: 1, Batch: 651, Step num: 651, Learning rate: 0.00045490, Avg batch loss: 0.6290, Avg batch acc: 0.3677
Train, Epoch: 1, Batch: 652, Step num: 652, Learning rate: 0.00045560, Avg batch loss: 0.6645, Avg batch acc: 0.3739
Train, Epoch: 1, Batch: 653, Step num: 653, Learning rate: 0.00045630, Avg batch loss: 0.6235, Avg batch acc: 0.3792
Train, Epoch: 1, Batch: 654, Step num: 654, Learning rate: 0.00045700, Avg batch loss: 0.6226, Avg batch acc: 0.3727
Train, Epoch: 1, Batch: 655, Step num: 655, Learning rate: 0.00045770, Avg batch loss: 0.6605, Avg batch acc: 0.3882
Train, Epoch: 1, Batch: 656, Step num: 656, Learning rate: 0.00045839, Avg batch loss: 0.6628, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 657, Step num: 657, Learning rate: 0.00045909, Avg batch loss: 0.7079, Avg batch acc: 0.3789
Train, Epoch: 1, Batch: 658, Step num: 658, Learning rate: 0.00045979, Avg batch loss: 0.7060, Avg batch acc: 0.3473
Train, Epoch: 1, Batch: 659, Step num: 659, Learning rate: 0.00046049, Avg batch loss: 0.6175, Avg batch acc: 0.3792
Train, Epoch: 1, Batch: 660, Step num: 660, Learning rate: 0.00046119, Avg batch loss: 0.6641, Avg batch acc: 0.3660
Train, Epoch: 1, Batch: 661, Step num: 661, Learning rate: 0.00046189, Avg batch loss: 0.6753, Avg batch acc: 0.3785
Train, Epoch: 1, Batch: 662, Step num: 662, Learning rate: 0.00046259, Avg batch loss: 0.5961, Avg batch acc: 0.3922
Train, Epoch: 1, Batch: 663, Step num: 663, Learning rate: 0.00046329, Avg batch loss: 0.6312, Avg batch acc: 0.3870
Train, Epoch: 1, Batch: 664, Step num: 664, Learning rate: 0.00046398, Avg batch loss: 0.6441, Avg batch acc: 0.3574
Train, Epoch: 1, Batch: 665, Step num: 665, Learning rate: 0.00046468, Avg batch loss: 0.6199, Avg batch acc: 0.3747
Train, Epoch: 1, Batch: 666, Step num: 666, Learning rate: 0.00046538, Avg batch loss: 0.6875, Avg batch acc: 0.3704
Train, Epoch: 1, Batch: 667, Step num: 667, Learning rate: 0.00046608, Avg batch loss: 0.6964, Avg batch acc: 0.3743
Train, Epoch: 1, Batch: 668, Step num: 668, Learning rate: 0.00046678, Avg batch loss: 0.7161, Avg batch acc: 0.3684
Train, Epoch: 1, Batch: 669, Step num: 669, Learning rate: 0.00046748, Avg batch loss: 0.6423, Avg batch acc: 0.3910
Train, Epoch: 1, Batch: 670, Step num: 670, Learning rate: 0.00046818, Avg batch loss: 0.7002, Avg batch acc: 0.3698
Train, Epoch: 1, Batch: 671, Step num: 671, Learning rate: 0.00046888, Avg batch loss: 0.6112, Avg batch acc: 0.3678
Train, Epoch: 1, Batch: 672, Step num: 672, Learning rate: 0.00046957, Avg batch loss: 0.6841, Avg batch acc: 0.3674
Train, Epoch: 1, Batch: 673, Step num: 673, Learning rate: 0.00047027, Avg batch loss: 0.6479, Avg batch acc: 0.3673
Train, Epoch: 1, Batch: 674, Step num: 674, Learning rate: 0.00047097, Avg batch loss: 0.6667, Avg batch acc: 0.3745
Train, Epoch: 1, Batch: 675, Step num: 675, Learning rate: 0.00047167, Avg batch loss: 0.5947, Avg batch acc: 0.4016
Train, Epoch: 1, Batch: 676, Step num: 676, Learning rate: 0.00047237, Avg batch loss: 0.6869, Avg batch acc: 0.3686
Train, Epoch: 1, Batch: 677, Step num: 677, Learning rate: 0.00047307, Avg batch loss: 0.6884, Avg batch acc: 0.3762
Train, Epoch: 1, Batch: 678, Step num: 678, Learning rate: 0.00047377, Avg batch loss: 0.6695, Avg batch acc: 0.3753
Train, Epoch: 1, Batch: 679, Step num: 679, Learning rate: 0.00047447, Avg batch loss: 0.6684, Avg batch acc: 0.3638
Train, Epoch: 1, Batch: 680, Step num: 680, Learning rate: 0.00047516, Avg batch loss: 0.6390, Avg batch acc: 0.3813
Train, Epoch: 1, Batch: 681, Step num: 681, Learning rate: 0.00047586, Avg batch loss: 0.5999, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 682, Step num: 682, Learning rate: 0.00047656, Avg batch loss: 0.6555, Avg batch acc: 0.3785
Train, Epoch: 1, Batch: 683, Step num: 683, Learning rate: 0.00047726, Avg batch loss: 0.6459, Avg batch acc: 0.3690
Train, Epoch: 1, Batch: 684, Step num: 684, Learning rate: 0.00047796, Avg batch loss: 0.6699, Avg batch acc: 0.3835
Train, Epoch: 1, Batch: 685, Step num: 685, Learning rate: 0.00047866, Avg batch loss: 0.6897, Avg batch acc: 0.3531
Train, Epoch: 1, Batch: 686, Step num: 686, Learning rate: 0.00047936, Avg batch loss: 0.5443, Avg batch acc: 0.4047
Train, Epoch: 1, Batch: 687, Step num: 687, Learning rate: 0.00048006, Avg batch loss: 0.6286, Avg batch acc: 0.3832
Train, Epoch: 1, Batch: 688, Step num: 688, Learning rate: 0.00048075, Avg batch loss: 0.5863, Avg batch acc: 0.4025
Train, Epoch: 1, Batch: 689, Step num: 689, Learning rate: 0.00048145, Avg batch loss: 0.6338, Avg batch acc: 0.3919
Train, Epoch: 1, Batch: 690, Step num: 690, Learning rate: 0.00048215, Avg batch loss: 0.5706, Avg batch acc: 0.4018
Train, Epoch: 1, Batch: 691, Step num: 691, Learning rate: 0.00048285, Avg batch loss: 0.6887, Avg batch acc: 0.3715
Train, Epoch: 1, Batch: 692, Step num: 692, Learning rate: 0.00048355, Avg batch loss: 0.6515, Avg batch acc: 0.3795
Train, Epoch: 1, Batch: 693, Step num: 693, Learning rate: 0.00048425, Avg batch loss: 0.6471, Avg batch acc: 0.3731
Train, Epoch: 1, Batch: 694, Step num: 694, Learning rate: 0.00048495, Avg batch loss: 0.6806, Avg batch acc: 0.3556
Train, Epoch: 1, Batch: 695, Step num: 695, Learning rate: 0.00048565, Avg batch loss: 0.6142, Avg batch acc: 0.3936
Train, Epoch: 1, Batch: 696, Step num: 696, Learning rate: 0.00048634, Avg batch loss: 0.6071, Avg batch acc: 0.3831
Train, Epoch: 1, Batch: 697, Step num: 697, Learning rate: 0.00048704, Avg batch loss: 0.6595, Avg batch acc: 0.3761
Train, Epoch: 1, Batch: 698, Step num: 698, Learning rate: 0.00048774, Avg batch loss: 0.6742, Avg batch acc: 0.3664
Train, Epoch: 1, Batch: 699, Step num: 699, Learning rate: 0.00048844, Avg batch loss: 0.6937, Avg batch acc: 0.3831
Train, Epoch: 1, Batch: 700, Step num: 700, Learning rate: 0.00048914, Avg batch loss: 0.6829, Avg batch acc: 0.3506
Train, Epoch: 1, Batch: 701, Step num: 701, Learning rate: 0.00048984, Avg batch loss: 0.6079, Avg batch acc: 0.3858
Train, Epoch: 1, Batch: 702, Step num: 702, Learning rate: 0.00049054, Avg batch loss: 0.6205, Avg batch acc: 0.3701
Train, Epoch: 1, Batch: 703, Step num: 703, Learning rate: 0.00049124, Avg batch loss: 0.6701, Avg batch acc: 0.3670
Train, Epoch: 1, Batch: 704, Step num: 704, Learning rate: 0.00049193, Avg batch loss: 0.6715, Avg batch acc: 0.3823
Train, Epoch: 1, Batch: 705, Step num: 705, Learning rate: 0.00049263, Avg batch loss: 0.6055, Avg batch acc: 0.3879
Train, Epoch: 1, Batch: 706, Step num: 706, Learning rate: 0.00049333, Avg batch loss: 0.5659, Avg batch acc: 0.3989
Train, Epoch: 1, Batch: 707, Step num: 707, Learning rate: 0.00049403, Avg batch loss: 0.6689, Avg batch acc: 0.3919
Train, Epoch: 1, Batch: 708, Step num: 708, Learning rate: 0.00049473, Avg batch loss: 0.6615, Avg batch acc: 0.3827
Train, Epoch: 1, Batch: 709, Step num: 709, Learning rate: 0.00049543, Avg batch loss: 0.6643, Avg batch acc: 0.3825
Train, Epoch: 1, Batch: 710, Step num: 710, Learning rate: 0.00049613, Avg batch loss: 0.6487, Avg batch acc: 0.3987
Train, Epoch: 1, Batch: 711, Step num: 711, Learning rate: 0.00049683, Avg batch loss: 0.6119, Avg batch acc: 0.3941
Train, Epoch: 1, Batch: 712, Step num: 712, Learning rate: 0.00049753, Avg batch loss: 0.6489, Avg batch acc: 0.3898
Train, Epoch: 1, Batch: 713, Step num: 713, Learning rate: 0.00049822, Avg batch loss: 0.5971, Avg batch acc: 0.4021
Train, Epoch: 1, Batch: 714, Step num: 714, Learning rate: 0.00049892, Avg batch loss: 0.6046, Avg batch acc: 0.3984
Train, Epoch: 1, Batch: 715, Step num: 715, Learning rate: 0.00049962, Avg batch loss: 0.6359, Avg batch acc: 0.3852
Train, Epoch: 1, Batch: 716, Step num: 716, Learning rate: 0.00050032, Avg batch loss: 0.6094, Avg batch acc: 0.3986
Train, Epoch: 1, Batch: 717, Step num: 717, Learning rate: 0.00050102, Avg batch loss: 0.6495, Avg batch acc: 0.3815
Train, Epoch: 1, Batch: 718, Step num: 718, Learning rate: 0.00050172, Avg batch loss: 0.6411, Avg batch acc: 0.3771
Train, Epoch: 1, Batch: 719, Step num: 719, Learning rate: 0.00050242, Avg batch loss: 0.6401, Avg batch acc: 0.3859
Train, Epoch: 1, Batch: 720, Step num: 720, Learning rate: 0.00050312, Avg batch loss: 0.6315, Avg batch acc: 0.3790
Train, Epoch: 1, Batch: 721, Step num: 721, Learning rate: 0.00050381, Avg batch loss: 0.6261, Avg batch acc: 0.3927
Train, Epoch: 1, Batch: 722, Step num: 722, Learning rate: 0.00050451, Avg batch loss: 0.6148, Avg batch acc: 0.3818
Train, Epoch: 1, Batch: 723, Step num: 723, Learning rate: 0.00050521, Avg batch loss: 0.6210, Avg batch acc: 0.3878
Train, Epoch: 1, Batch: 724, Step num: 724, Learning rate: 0.00050591, Avg batch loss: 0.6978, Avg batch acc: 0.3726
Train, Epoch: 1, Batch: 725, Step num: 725, Learning rate: 0.00050661, Avg batch loss: 0.5903, Avg batch acc: 0.3852
Train, Epoch: 1, Batch: 726, Step num: 726, Learning rate: 0.00050731, Avg batch loss: 0.6979, Avg batch acc: 0.3683
Train, Epoch: 1, Batch: 727, Step num: 727, Learning rate: 0.00050801, Avg batch loss: 0.7021, Avg batch acc: 0.3658
Train, Epoch: 1, Batch: 728, Step num: 728, Learning rate: 0.00050871, Avg batch loss: 0.6269, Avg batch acc: 0.3877
Train, Epoch: 1, Batch: 729, Step num: 729, Learning rate: 0.00050940, Avg batch loss: 0.6694, Avg batch acc: 0.4009
Train, Epoch: 1, Batch: 730, Step num: 730, Learning rate: 0.00051010, Avg batch loss: 0.6519, Avg batch acc: 0.3880
Train, Epoch: 1, Batch: 731, Step num: 731, Learning rate: 0.00051080, Avg batch loss: 0.6140, Avg batch acc: 0.3784
Train, Epoch: 1, Batch: 732, Step num: 732, Learning rate: 0.00051150, Avg batch loss: 0.5933, Avg batch acc: 0.3901
Train, Epoch: 1, Batch: 733, Step num: 733, Learning rate: 0.00051220, Avg batch loss: 0.5636, Avg batch acc: 0.4049
Train, Epoch: 1, Batch: 734, Step num: 734, Learning rate: 0.00051290, Avg batch loss: 0.6251, Avg batch acc: 0.4037
Train, Epoch: 1, Batch: 735, Step num: 735, Learning rate: 0.00051360, Avg batch loss: 0.6078, Avg batch acc: 0.3958
Train, Epoch: 1, Batch: 736, Step num: 736, Learning rate: 0.00051430, Avg batch loss: 0.5905, Avg batch acc: 0.3849
Train, Epoch: 1, Batch: 737, Step num: 737, Learning rate: 0.00051499, Avg batch loss: 0.5982, Avg batch acc: 0.3791
Train, Epoch: 1, Batch: 738, Step num: 738, Learning rate: 0.00051569, Avg batch loss: 0.6342, Avg batch acc: 0.3971
Train, Epoch: 1, Batch: 739, Step num: 739, Learning rate: 0.00051639, Avg batch loss: 0.6704, Avg batch acc: 0.3817
Train, Epoch: 1, Batch: 740, Step num: 740, Learning rate: 0.00051709, Avg batch loss: 0.6313, Avg batch acc: 0.3962
Train, Epoch: 1, Batch: 741, Step num: 741, Learning rate: 0.00051779, Avg batch loss: 0.6789, Avg batch acc: 0.3652
Train, Epoch: 1, Batch: 742, Step num: 742, Learning rate: 0.00051849, Avg batch loss: 0.5956, Avg batch acc: 0.3834
Train, Epoch: 1, Batch: 743, Step num: 743, Learning rate: 0.00051919, Avg batch loss: 0.5742, Avg batch acc: 0.3984
Train, Epoch: 1, Batch: 744, Step num: 744, Learning rate: 0.00051989, Avg batch loss: 0.6920, Avg batch acc: 0.3699
Train, Epoch: 1, Batch: 745, Step num: 745, Learning rate: 0.00052058, Avg batch loss: 0.5807, Avg batch acc: 0.3947
Train, Epoch: 1, Batch: 746, Step num: 746, Learning rate: 0.00052128, Avg batch loss: 0.6961, Avg batch acc: 0.3855
Train, Epoch: 1, Batch: 747, Step num: 747, Learning rate: 0.00052198, Avg batch loss: 0.6208, Avg batch acc: 0.3741
Train, Epoch: 1, Batch: 748, Step num: 748, Learning rate: 0.00052268, Avg batch loss: 0.6000, Avg batch acc: 0.3997
Train, Epoch: 1, Batch: 749, Step num: 749, Learning rate: 0.00052338, Avg batch loss: 0.5919, Avg batch acc: 0.4056
Train, Epoch: 1, Batch: 750, Step num: 750, Learning rate: 0.00052408, Avg batch loss: 0.5398, Avg batch acc: 0.3961
Train, Epoch: 1, Batch: 751, Step num: 751, Learning rate: 0.00052478, Avg batch loss: 0.6185, Avg batch acc: 0.4026
Train, Epoch: 1, Batch: 752, Step num: 752, Learning rate: 0.00052548, Avg batch loss: 0.5736, Avg batch acc: 0.3989
Train, Epoch: 1, Batch: 753, Step num: 753, Learning rate: 0.00052617, Avg batch loss: 0.6462, Avg batch acc: 0.3820
Train, Epoch: 1, Batch: 754, Step num: 754, Learning rate: 0.00052687, Avg batch loss: 0.6506, Avg batch acc: 0.3818
Train, Epoch: 1, Batch: 755, Step num: 755, Learning rate: 0.00052757, Avg batch loss: 0.6162, Avg batch acc: 0.3929
Train, Epoch: 1, Batch: 756, Step num: 756, Learning rate: 0.00052827, Avg batch loss: 0.6967, Avg batch acc: 0.3756
Train, Epoch: 1, Batch: 757, Step num: 757, Learning rate: 0.00052897, Avg batch loss: 0.6377, Avg batch acc: 0.3882
Train, Epoch: 1, Batch: 758, Step num: 758, Learning rate: 0.00052967, Avg batch loss: 0.6867, Avg batch acc: 0.3656
Train, Epoch: 1, Batch: 759, Step num: 759, Learning rate: 0.00053037, Avg batch loss: 0.7294, Avg batch acc: 0.3548
Train, Epoch: 1, Batch: 760, Step num: 760, Learning rate: 0.00053107, Avg batch loss: 0.6469, Avg batch acc: 0.3901
Train, Epoch: 1, Batch: 761, Step num: 761, Learning rate: 0.00053176, Avg batch loss: 0.6419, Avg batch acc: 0.3854
Train, Epoch: 1, Batch: 762, Step num: 762, Learning rate: 0.00053246, Avg batch loss: 0.6020, Avg batch acc: 0.3810
Train, Epoch: 1, Batch: 763, Step num: 763, Learning rate: 0.00053316, Avg batch loss: 0.6870, Avg batch acc: 0.3652
Train, Epoch: 1, Batch: 764, Step num: 764, Learning rate: 0.00053386, Avg batch loss: 0.6606, Avg batch acc: 0.3779
Train, Epoch: 1, Batch: 765, Step num: 765, Learning rate: 0.00053456, Avg batch loss: 0.6672, Avg batch acc: 0.3782
Train, Epoch: 1, Batch: 766, Step num: 766, Learning rate: 0.00053526, Avg batch loss: 0.6314, Avg batch acc: 0.3871
Train, Epoch: 1, Batch: 767, Step num: 767, Learning rate: 0.00053596, Avg batch loss: 0.6678, Avg batch acc: 0.3645
Train, Epoch: 1, Batch: 768, Step num: 768, Learning rate: 0.00053666, Avg batch loss: 0.6225, Avg batch acc: 0.3900
Train, Epoch: 1, Batch: 769, Step num: 769, Learning rate: 0.00053736, Avg batch loss: 0.5714, Avg batch acc: 0.3754
Train, Epoch: 1, Batch: 770, Step num: 770, Learning rate: 0.00053805, Avg batch loss: 0.6404, Avg batch acc: 0.3876
Train, Epoch: 1, Batch: 771, Step num: 771, Learning rate: 0.00053875, Avg batch loss: 0.5742, Avg batch acc: 0.3998
Train, Epoch: 1, Batch: 772, Step num: 772, Learning rate: 0.00053945, Avg batch loss: 0.6155, Avg batch acc: 0.3923
Train, Epoch: 1, Batch: 773, Step num: 773, Learning rate: 0.00054015, Avg batch loss: 0.5971, Avg batch acc: 0.3948
Train, Epoch: 1, Batch: 774, Step num: 774, Learning rate: 0.00054085, Avg batch loss: 0.6185, Avg batch acc: 0.3930
Train, Epoch: 1, Batch: 775, Step num: 775, Learning rate: 0.00054155, Avg batch loss: 0.6042, Avg batch acc: 0.3854
Train, Epoch: 1, Batch: 776, Step num: 776, Learning rate: 0.00054225, Avg batch loss: 0.6640, Avg batch acc: 0.4013
Train, Epoch: 1, Batch: 777, Step num: 777, Learning rate: 0.00054295, Avg batch loss: 0.6469, Avg batch acc: 0.3921
Train, Epoch: 1, Batch: 778, Step num: 778, Learning rate: 0.00054364, Avg batch loss: 0.6965, Avg batch acc: 0.3811
Train, Epoch: 1, Batch: 779, Step num: 779, Learning rate: 0.00054434, Avg batch loss: 0.6291, Avg batch acc: 0.4050
Train, Epoch: 1, Batch: 780, Step num: 780, Learning rate: 0.00054504, Avg batch loss: 0.6700, Avg batch acc: 0.3827
Train, Epoch: 1, Batch: 781, Step num: 781, Learning rate: 0.00054574, Avg batch loss: 0.6271, Avg batch acc: 0.3804
Train, Epoch: 1, Batch: 782, Step num: 782, Learning rate: 0.00054644, Avg batch loss: 0.6248, Avg batch acc: 0.4102
Train, Epoch: 1, Batch: 783, Step num: 783, Learning rate: 0.00054714, Avg batch loss: 0.6122, Avg batch acc: 0.3944
Train, Epoch: 1, Batch: 784, Step num: 784, Learning rate: 0.00054784, Avg batch loss: 0.6221, Avg batch acc: 0.3870
Train, Epoch: 1, Batch: 785, Step num: 785, Learning rate: 0.00054854, Avg batch loss: 0.5702, Avg batch acc: 0.3949
Train, Epoch: 1, Batch: 786, Step num: 786, Learning rate: 0.00054923, Avg batch loss: 0.6278, Avg batch acc: 0.3928
Train, Epoch: 1, Batch: 787, Step num: 787, Learning rate: 0.00054993, Avg batch loss: 0.6948, Avg batch acc: 0.3741
Train, Epoch: 1, Batch: 788, Step num: 788, Learning rate: 0.00055063, Avg batch loss: 0.6390, Avg batch acc: 0.3718
Train, Epoch: 1, Batch: 789, Step num: 789, Learning rate: 0.00055133, Avg batch loss: 0.6172, Avg batch acc: 0.3952
Train, Epoch: 1, Batch: 790, Step num: 790, Learning rate: 0.00055203, Avg batch loss: 0.6644, Avg batch acc: 0.3742
Train, Epoch: 1, Batch: 791, Step num: 791, Learning rate: 0.00055273, Avg batch loss: 0.6334, Avg batch acc: 0.3767
Train, Epoch: 1, Batch: 792, Step num: 792, Learning rate: 0.00055343, Avg batch loss: 0.5987, Avg batch acc: 0.4082
Train, Epoch: 1, Batch: 793, Step num: 793, Learning rate: 0.00055413, Avg batch loss: 0.5992, Avg batch acc: 0.4091
Train, Epoch: 1, Batch: 794, Step num: 794, Learning rate: 0.00055482, Avg batch loss: 0.6950, Avg batch acc: 0.3928
Train, Epoch: 1, Batch: 795, Step num: 795, Learning rate: 0.00055552, Avg batch loss: 0.5955, Avg batch acc: 0.4088
Train, Epoch: 1, Batch: 796, Step num: 796, Learning rate: 0.00055622, Avg batch loss: 0.5539, Avg batch acc: 0.4051
Train, Epoch: 1, Batch: 797, Step num: 797, Learning rate: 0.00055692, Avg batch loss: 0.6983, Avg batch acc: 0.3671
Train, Epoch: 1, Batch: 798, Step num: 798, Learning rate: 0.00055762, Avg batch loss: 0.6244, Avg batch acc: 0.4066
Train, Epoch: 1, Batch: 799, Step num: 799, Learning rate: 0.00055832, Avg batch loss: 0.6381, Avg batch acc: 0.3914
Train, Epoch: 1, Batch: 800, Step num: 800, Learning rate: 0.00055902, Avg batch loss: 0.6245, Avg batch acc: 0.4002
Train, Epoch: 1, Batch: 801, Step num: 801, Learning rate: 0.00055972, Avg batch loss: 0.6652, Avg batch acc: 0.4040
Train, Epoch: 1, Batch: 802, Step num: 802, Learning rate: 0.00056041, Avg batch loss: 0.6589, Avg batch acc: 0.3709
Train, Epoch: 1, Batch: 803, Step num: 803, Learning rate: 0.00056111, Avg batch loss: 0.6112, Avg batch acc: 0.3881
Train, Epoch: 1, Batch: 804, Step num: 804, Learning rate: 0.00056181, Avg batch loss: 0.6578, Avg batch acc: 0.3880
Train, Epoch: 1, Batch: 805, Step num: 805, Learning rate: 0.00056251, Avg batch loss: 0.5901, Avg batch acc: 0.3979
Train, Epoch: 1, Batch: 806, Step num: 806, Learning rate: 0.00056321, Avg batch loss: 0.5929, Avg batch acc: 0.4136
Train, Epoch: 1, Batch: 807, Step num: 807, Learning rate: 0.00056391, Avg batch loss: 0.6649, Avg batch acc: 0.3872
Train, Epoch: 1, Batch: 808, Step num: 808, Learning rate: 0.00056461, Avg batch loss: 0.6604, Avg batch acc: 0.3889
Train, Epoch: 1, Batch: 809, Step num: 809, Learning rate: 0.00056531, Avg batch loss: 0.6807, Avg batch acc: 0.3926
Train, Epoch: 1, Batch: 810, Step num: 810, Learning rate: 0.00056600, Avg batch loss: 0.5893, Avg batch acc: 0.3889
Train, Epoch: 1, Batch: 811, Step num: 811, Learning rate: 0.00056670, Avg batch loss: 0.5925, Avg batch acc: 0.3999
Train, Epoch: 1, Batch: 812, Step num: 812, Learning rate: 0.00056740, Avg batch loss: 0.6089, Avg batch acc: 0.3856
Train, Epoch: 1, Batch: 813, Step num: 813, Learning rate: 0.00056810, Avg batch loss: 0.5839, Avg batch acc: 0.3822
Train, Epoch: 1, Batch: 814, Step num: 814, Learning rate: 0.00056880, Avg batch loss: 0.6301, Avg batch acc: 0.3977
Train, Epoch: 1, Batch: 815, Step num: 815, Learning rate: 0.00056950, Avg batch loss: 0.6428, Avg batch acc: 0.3805
Train, Epoch: 1, Batch: 816, Step num: 816, Learning rate: 0.00057020, Avg batch loss: 0.6882, Avg batch acc: 0.3669
Train, Epoch: 1, Batch: 817, Step num: 817, Learning rate: 0.00057090, Avg batch loss: 0.6145, Avg batch acc: 0.3929
Train, Epoch: 1, Batch: 818, Step num: 818, Learning rate: 0.00057159, Avg batch loss: 0.5738, Avg batch acc: 0.4095
Train, Epoch: 1, Batch: 819, Step num: 819, Learning rate: 0.00057229, Avg batch loss: 0.5919, Avg batch acc: 0.4281
Train, Epoch: 1, Batch: 820, Step num: 820, Learning rate: 0.00057299, Avg batch loss: 0.5743, Avg batch acc: 0.3930
Train, Epoch: 1, Batch: 821, Step num: 821, Learning rate: 0.00057369, Avg batch loss: 0.5857, Avg batch acc: 0.4104
Train, Epoch: 1, Batch: 822, Step num: 822, Learning rate: 0.00057439, Avg batch loss: 0.6280, Avg batch acc: 0.3824
Train, Epoch: 1, Batch: 823, Step num: 823, Learning rate: 0.00057509, Avg batch loss: 0.5693, Avg batch acc: 0.4060
Train, Epoch: 1, Batch: 824, Step num: 824, Learning rate: 0.00057579, Avg batch loss: 0.6039, Avg batch acc: 0.3996
Train, Epoch: 1, Batch: 825, Step num: 825, Learning rate: 0.00057649, Avg batch loss: 0.6086, Avg batch acc: 0.3871
Train, Epoch: 1, Batch: 826, Step num: 826, Learning rate: 0.00057719, Avg batch loss: 0.6399, Avg batch acc: 0.3894
Train, Epoch: 1, Batch: 827, Step num: 827, Learning rate: 0.00057788, Avg batch loss: 0.6029, Avg batch acc: 0.3937
Train, Epoch: 1, Batch: 828, Step num: 828, Learning rate: 0.00057858, Avg batch loss: 0.6137, Avg batch acc: 0.4042
Train, Epoch: 1, Batch: 829, Step num: 829, Learning rate: 0.00057928, Avg batch loss: 0.6267, Avg batch acc: 0.3816
Train, Epoch: 1, Batch: 830, Step num: 830, Learning rate: 0.00057998, Avg batch loss: 0.6054, Avg batch acc: 0.3964
Train, Epoch: 1, Batch: 831, Step num: 831, Learning rate: 0.00058068, Avg batch loss: 0.5957, Avg batch acc: 0.4176
Train, Epoch: 1, Batch: 832, Step num: 832, Learning rate: 0.00058138, Avg batch loss: 0.6023, Avg batch acc: 0.4030
Train, Epoch: 1, Batch: 833, Step num: 833, Learning rate: 0.00058208, Avg batch loss: 0.6031, Avg batch acc: 0.3999
Train, Epoch: 1, Batch: 834, Step num: 834, Learning rate: 0.00058278, Avg batch loss: 0.6406, Avg batch acc: 0.4025
Train, Epoch: 1, Batch: 835, Step num: 835, Learning rate: 0.00058347, Avg batch loss: 0.6121, Avg batch acc: 0.4028
Train, Epoch: 1, Batch: 836, Step num: 836, Learning rate: 0.00058417, Avg batch loss: 0.6605, Avg batch acc: 0.3825
Train, Epoch: 1, Batch: 837, Step num: 837, Learning rate: 0.00058487, Avg batch loss: 0.6163, Avg batch acc: 0.4102
Train, Epoch: 1, Batch: 838, Step num: 838, Learning rate: 0.00058557, Avg batch loss: 0.6053, Avg batch acc: 0.3873
Train, Epoch: 1, Batch: 839, Step num: 839, Learning rate: 0.00058627, Avg batch loss: 0.6206, Avg batch acc: 0.3978
Train, Epoch: 1, Batch: 840, Step num: 840, Learning rate: 0.00058697, Avg batch loss: 0.6838, Avg batch acc: 0.3803
Train, Epoch: 1, Batch: 841, Step num: 841, Learning rate: 0.00058767, Avg batch loss: 0.6354, Avg batch acc: 0.3999
Train, Epoch: 1, Batch: 842, Step num: 842, Learning rate: 0.00058837, Avg batch loss: 0.6175, Avg batch acc: 0.4071
Train, Epoch: 1, Batch: 843, Step num: 843, Learning rate: 0.00058906, Avg batch loss: 0.5828, Avg batch acc: 0.4044
Train, Epoch: 1, Batch: 844, Step num: 844, Learning rate: 0.00058976, Avg batch loss: 0.5903, Avg batch acc: 0.4123
Train, Epoch: 1, Batch: 845, Step num: 845, Learning rate: 0.00059046, Avg batch loss: 0.6491, Avg batch acc: 0.3836
Train, Epoch: 1, Batch: 846, Step num: 846, Learning rate: 0.00059116, Avg batch loss: 0.5972, Avg batch acc: 0.4058
Train, Epoch: 1, Batch: 847, Step num: 847, Learning rate: 0.00059186, Avg batch loss: 0.6622, Avg batch acc: 0.3729
Train, Epoch: 1, Batch: 848, Step num: 848, Learning rate: 0.00059256, Avg batch loss: 0.6439, Avg batch acc: 0.3878
Train, Epoch: 1, Batch: 849, Step num: 849, Learning rate: 0.00059326, Avg batch loss: 0.6219, Avg batch acc: 0.3900
Train, Epoch: 1, Batch: 850, Step num: 850, Learning rate: 0.00059396, Avg batch loss: 0.5725, Avg batch acc: 0.3905
Train, Epoch: 1, Batch: 851, Step num: 851, Learning rate: 0.00059465, Avg batch loss: 0.5990, Avg batch acc: 0.3938
Train, Epoch: 1, Batch: 852, Step num: 852, Learning rate: 0.00059535, Avg batch loss: 0.6437, Avg batch acc: 0.4040
Train, Epoch: 1, Batch: 853, Step num: 853, Learning rate: 0.00059605, Avg batch loss: 0.6514, Avg batch acc: 0.3781
Train, Epoch: 1, Batch: 854, Step num: 854, Learning rate: 0.00059675, Avg batch loss: 0.5862, Avg batch acc: 0.3958
Train, Epoch: 1, Batch: 855, Step num: 855, Learning rate: 0.00059745, Avg batch loss: 0.6179, Avg batch acc: 0.4091
Train, Epoch: 1, Batch: 856, Step num: 856, Learning rate: 0.00059815, Avg batch loss: 0.6271, Avg batch acc: 0.4005
Train, Epoch: 1, Batch: 857, Step num: 857, Learning rate: 0.00059885, Avg batch loss: 0.6331, Avg batch acc: 0.3783
Train, Epoch: 1, Batch: 858, Step num: 858, Learning rate: 0.00059955, Avg batch loss: 0.6486, Avg batch acc: 0.3848
Train, Epoch: 1, Batch: 859, Step num: 859, Learning rate: 0.00060024, Avg batch loss: 0.5880, Avg batch acc: 0.3934
Train, Epoch: 1, Batch: 860, Step num: 860, Learning rate: 0.00060094, Avg batch loss: 0.6520, Avg batch acc: 0.4060
Train, Epoch: 1, Batch: 861, Step num: 861, Learning rate: 0.00060164, Avg batch loss: 0.5718, Avg batch acc: 0.4055
Train, Epoch: 1, Batch: 862, Step num: 862, Learning rate: 0.00060234, Avg batch loss: 0.5932, Avg batch acc: 0.4089
Train, Epoch: 1, Batch: 863, Step num: 863, Learning rate: 0.00060304, Avg batch loss: 0.5733, Avg batch acc: 0.4060
Train, Epoch: 1, Batch: 864, Step num: 864, Learning rate: 0.00060374, Avg batch loss: 0.6405, Avg batch acc: 0.3910
Train, Epoch: 1, Batch: 865, Step num: 865, Learning rate: 0.00060444, Avg batch loss: 0.5929, Avg batch acc: 0.3839
Train, Epoch: 1, Batch: 866, Step num: 866, Learning rate: 0.00060514, Avg batch loss: 0.5784, Avg batch acc: 0.4046
Train, Epoch: 1, Batch: 867, Step num: 867, Learning rate: 0.00060583, Avg batch loss: 0.6289, Avg batch acc: 0.4118
Train, Epoch: 1, Batch: 868, Step num: 868, Learning rate: 0.00060653, Avg batch loss: 0.6005, Avg batch acc: 0.4145
Train, Epoch: 1, Batch: 869, Step num: 869, Learning rate: 0.00060723, Avg batch loss: 0.6484, Avg batch acc: 0.3839
Train, Epoch: 1, Batch: 870, Step num: 870, Learning rate: 0.00060793, Avg batch loss: 0.6039, Avg batch acc: 0.3878
Train, Epoch: 1, Batch: 871, Step num: 871, Learning rate: 0.00060863, Avg batch loss: 0.5741, Avg batch acc: 0.4112
Train, Epoch: 1, Batch: 872, Step num: 872, Learning rate: 0.00060933, Avg batch loss: 0.5704, Avg batch acc: 0.3997
Train, Epoch: 1, Batch: 873, Step num: 873, Learning rate: 0.00061003, Avg batch loss: 0.6385, Avg batch acc: 0.4041
Train, Epoch: 1, Batch: 874, Step num: 874, Learning rate: 0.00061073, Avg batch loss: 0.5811, Avg batch acc: 0.4155
Train, Epoch: 1, Batch: 875, Step num: 875, Learning rate: 0.00061142, Avg batch loss: 0.6500, Avg batch acc: 0.3805
Train, Epoch: 1, Batch: 876, Step num: 876, Learning rate: 0.00061212, Avg batch loss: 0.6134, Avg batch acc: 0.3764
Train, Epoch: 1, Batch: 877, Step num: 877, Learning rate: 0.00061282, Avg batch loss: 0.5951, Avg batch acc: 0.4218
Train, Epoch: 1, Batch: 878, Step num: 878, Learning rate: 0.00061352, Avg batch loss: 0.5664, Avg batch acc: 0.4193
Train, Epoch: 1, Batch: 879, Step num: 879, Learning rate: 0.00061422, Avg batch loss: 0.6566, Avg batch acc: 0.3829
Train, Epoch: 1, Batch: 880, Step num: 880, Learning rate: 0.00061492, Avg batch loss: 0.6099, Avg batch acc: 0.4111
Train, Epoch: 1, Batch: 881, Step num: 881, Learning rate: 0.00061562, Avg batch loss: 0.5889, Avg batch acc: 0.3901
Train, Epoch: 1, Batch: 882, Step num: 882, Learning rate: 0.00061632, Avg batch loss: 0.5598, Avg batch acc: 0.4052
Train, Epoch: 1, Batch: 883, Step num: 883, Learning rate: 0.00061702, Avg batch loss: 0.6087, Avg batch acc: 0.4166
Train, Epoch: 1, Batch: 884, Step num: 884, Learning rate: 0.00061771, Avg batch loss: 0.6753, Avg batch acc: 0.3923
Train, Epoch: 1, Batch: 885, Step num: 885, Learning rate: 0.00061841, Avg batch loss: 0.6219, Avg batch acc: 0.4075
Train, Epoch: 1, Batch: 886, Step num: 886, Learning rate: 0.00061911, Avg batch loss: 0.6317, Avg batch acc: 0.4171
Train, Epoch: 1, Batch: 887, Step num: 887, Learning rate: 0.00061981, Avg batch loss: 0.6154, Avg batch acc: 0.4124
Train, Epoch: 1, Batch: 888, Step num: 888, Learning rate: 0.00062051, Avg batch loss: 0.6096, Avg batch acc: 0.4154
Train, Epoch: 1, Batch: 889, Step num: 889, Learning rate: 0.00062121, Avg batch loss: 0.6197, Avg batch acc: 0.3872
Train, Epoch: 1, Batch: 890, Step num: 890, Learning rate: 0.00062191, Avg batch loss: 0.5534, Avg batch acc: 0.4056
Train, Epoch: 1, Batch: 891, Step num: 891, Learning rate: 0.00062261, Avg batch loss: 0.6197, Avg batch acc: 0.3849
Train, Epoch: 1, Batch: 892, Step num: 892, Learning rate: 0.00062330, Avg batch loss: 0.5878, Avg batch acc: 0.4014
Train, Epoch: 1, Batch: 893, Step num: 893, Learning rate: 0.00062400, Avg batch loss: 0.6213, Avg batch acc: 0.4058
Train, Epoch: 1, Batch: 894, Step num: 894, Learning rate: 0.00062470, Avg batch loss: 0.6266, Avg batch acc: 0.3808
Train, Epoch: 1, Batch: 895, Step num: 895, Learning rate: 0.00062540, Avg batch loss: 0.6432, Avg batch acc: 0.3863
Train, Epoch: 1, Batch: 896, Step num: 896, Learning rate: 0.00062610, Avg batch loss: 0.6279, Avg batch acc: 0.4081
Train, Epoch: 1, Batch: 897, Step num: 897, Learning rate: 0.00062680, Avg batch loss: 0.6426, Avg batch acc: 0.3941
Train, Epoch: 1, Batch: 898, Step num: 898, Learning rate: 0.00062750, Avg batch loss: 0.5622, Avg batch acc: 0.4209
Train, Epoch: 1, Batch: 899, Step num: 899, Learning rate: 0.00062820, Avg batch loss: 0.5409, Avg batch acc: 0.4050
Train, Epoch: 1, Batch: 900, Step num: 900, Learning rate: 0.00062889, Avg batch loss: 0.5992, Avg batch acc: 0.3978
Train, Epoch: 1, Batch: 901, Step num: 901, Learning rate: 0.00062959, Avg batch loss: 0.6041, Avg batch acc: 0.4021
Train, Epoch: 1, Batch: 902, Step num: 902, Learning rate: 0.00063029, Avg batch loss: 0.6422, Avg batch acc: 0.3987
Train, Epoch: 1, Batch: 903, Step num: 903, Learning rate: 0.00063099, Avg batch loss: 0.5929, Avg batch acc: 0.4070
Train, Epoch: 1, Batch: 904, Step num: 904, Learning rate: 0.00063169, Avg batch loss: 0.6484, Avg batch acc: 0.3976
Train, Epoch: 1, Batch: 905, Step num: 905, Learning rate: 0.00063239, Avg batch loss: 0.5573, Avg batch acc: 0.4022
Train, Epoch: 1, Batch: 906, Step num: 906, Learning rate: 0.00063309, Avg batch loss: 0.6187, Avg batch acc: 0.3892
Train, Epoch: 1, Batch: 907, Step num: 907, Learning rate: 0.00063379, Avg batch loss: 0.6644, Avg batch acc: 0.4060
Train, Epoch: 1, Batch: 908, Step num: 908, Learning rate: 0.00063448, Avg batch loss: 0.6078, Avg batch acc: 0.4092
Train, Epoch: 1, Batch: 909, Step num: 909, Learning rate: 0.00063518, Avg batch loss: 0.6164, Avg batch acc: 0.4149
Train, Epoch: 1, Batch: 910, Step num: 910, Learning rate: 0.00063588, Avg batch loss: 0.5604, Avg batch acc: 0.4157
Train, Epoch: 1, Batch: 911, Step num: 911, Learning rate: 0.00063658, Avg batch loss: 0.6325, Avg batch acc: 0.4082
Train, Epoch: 1, Batch: 912, Step num: 912, Learning rate: 0.00063728, Avg batch loss: 0.5819, Avg batch acc: 0.3944
Train, Epoch: 1, Batch: 913, Step num: 913, Learning rate: 0.00063798, Avg batch loss: 0.5855, Avg batch acc: 0.3948
Train, Epoch: 1, Batch: 914, Step num: 914, Learning rate: 0.00063868, Avg batch loss: 0.5985, Avg batch acc: 0.4127
Train, Epoch: 1, Batch: 915, Step num: 915, Learning rate: 0.00063938, Avg batch loss: 0.6398, Avg batch acc: 0.4016
Train, Epoch: 1, Batch: 916, Step num: 916, Learning rate: 0.00064007, Avg batch loss: 0.5932, Avg batch acc: 0.4108
Train, Epoch: 1, Batch: 917, Step num: 917, Learning rate: 0.00064077, Avg batch loss: 0.5270, Avg batch acc: 0.3860
Train, Epoch: 1, Batch: 918, Step num: 918, Learning rate: 0.00064147, Avg batch loss: 0.5365, Avg batch acc: 0.4168
Train, Epoch: 1, Batch: 919, Step num: 919, Learning rate: 0.00064217, Avg batch loss: 0.5826, Avg batch acc: 0.4054
Train, Epoch: 1, Batch: 920, Step num: 920, Learning rate: 0.00064287, Avg batch loss: 0.6172, Avg batch acc: 0.3898
Train, Epoch: 1, Batch: 921, Step num: 921, Learning rate: 0.00064357, Avg batch loss: 0.6370, Avg batch acc: 0.3915
Train, Epoch: 1, Batch: 922, Step num: 922, Learning rate: 0.00064427, Avg batch loss: 0.5667, Avg batch acc: 0.3985
Train, Epoch: 1, Batch: 923, Step num: 923, Learning rate: 0.00064497, Avg batch loss: 0.5591, Avg batch acc: 0.4070
Train, Epoch: 1, Batch: 924, Step num: 924, Learning rate: 0.00064566, Avg batch loss: 0.5703, Avg batch acc: 0.4048
Train, Epoch: 1, Batch: 925, Step num: 925, Learning rate: 0.00064636, Avg batch loss: 0.6027, Avg batch acc: 0.3826
Train, Epoch: 1, Batch: 926, Step num: 926, Learning rate: 0.00064706, Avg batch loss: 0.6380, Avg batch acc: 0.3937
Train, Epoch: 1, Batch: 927, Step num: 927, Learning rate: 0.00064776, Avg batch loss: 0.5454, Avg batch acc: 0.4220
Train, Epoch: 1, Batch: 928, Step num: 928, Learning rate: 0.00064846, Avg batch loss: 0.5440, Avg batch acc: 0.3999
Train, Epoch: 1, Batch: 929, Step num: 929, Learning rate: 0.00064916, Avg batch loss: 0.6306, Avg batch acc: 0.4156
Train, Epoch: 1, Batch: 930, Step num: 930, Learning rate: 0.00064986, Avg batch loss: 0.5998, Avg batch acc: 0.3898
Train, Epoch: 1, Batch: 931, Step num: 931, Learning rate: 0.00065056, Avg batch loss: 0.5974, Avg batch acc: 0.4100
Train, Epoch: 1, Batch: 932, Step num: 932, Learning rate: 0.00065125, Avg batch loss: 0.6507, Avg batch acc: 0.4082
Train, Epoch: 1, Batch: 933, Step num: 933, Learning rate: 0.00065195, Avg batch loss: 0.5993, Avg batch acc: 0.3984
Train, Epoch: 1, Batch: 934, Step num: 934, Learning rate: 0.00065265, Avg batch loss: 0.5779, Avg batch acc: 0.4394
Train, Epoch: 1, Batch: 935, Step num: 935, Learning rate: 0.00065335, Avg batch loss: 0.6150, Avg batch acc: 0.3983
Train, Epoch: 1, Batch: 936, Step num: 936, Learning rate: 0.00065405, Avg batch loss: 0.6555, Avg batch acc: 0.4021
Train, Epoch: 1, Batch: 937, Step num: 937, Learning rate: 0.00065475, Avg batch loss: 0.6728, Avg batch acc: 0.3917
Train, Epoch: 1, Batch: 938, Step num: 938, Learning rate: 0.00065545, Avg batch loss: 0.6062, Avg batch acc: 0.4087
Train, Epoch: 1, Batch: 939, Step num: 939, Learning rate: 0.00065615, Avg batch loss: 0.5613, Avg batch acc: 0.4355
Train, Epoch: 1, Batch: 940, Step num: 940, Learning rate: 0.00065684, Avg batch loss: 0.5796, Avg batch acc: 0.4069
Train, Epoch: 1, Batch: 941, Step num: 941, Learning rate: 0.00065754, Avg batch loss: 0.5734, Avg batch acc: 0.4378
Train, Epoch: 1, Batch: 942, Step num: 942, Learning rate: 0.00065824, Avg batch loss: 0.5967, Avg batch acc: 0.4141
Train, Epoch: 1, Batch: 943, Step num: 943, Learning rate: 0.00065894, Avg batch loss: 0.5925, Avg batch acc: 0.4141
Train, Epoch: 1, Batch: 944, Step num: 944, Learning rate: 0.00065964, Avg batch loss: 0.5970, Avg batch acc: 0.4053
Train, Epoch: 1, Batch: 945, Step num: 945, Learning rate: 0.00066034, Avg batch loss: 0.5638, Avg batch acc: 0.4098
Train, Epoch: 1, Batch: 946, Step num: 946, Learning rate: 0.00066104, Avg batch loss: 0.6274, Avg batch acc: 0.4028
Train, Epoch: 1, Batch: 947, Step num: 947, Learning rate: 0.00066174, Avg batch loss: 0.6353, Avg batch acc: 0.4098
Train, Epoch: 1, Batch: 948, Step num: 948, Learning rate: 0.00066244, Avg batch loss: 0.6224, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 949, Step num: 949, Learning rate: 0.00066313, Avg batch loss: 0.6299, Avg batch acc: 0.3987
Train, Epoch: 1, Batch: 950, Step num: 950, Learning rate: 0.00066383, Avg batch loss: 0.5635, Avg batch acc: 0.3950
Train, Epoch: 1, Batch: 951, Step num: 951, Learning rate: 0.00066453, Avg batch loss: 0.5853, Avg batch acc: 0.4041
Train, Epoch: 1, Batch: 952, Step num: 952, Learning rate: 0.00066523, Avg batch loss: 0.5683, Avg batch acc: 0.4169
Train, Epoch: 1, Batch: 953, Step num: 953, Learning rate: 0.00066593, Avg batch loss: 0.5812, Avg batch acc: 0.4192
Train, Epoch: 1, Batch: 954, Step num: 954, Learning rate: 0.00066663, Avg batch loss: 0.6053, Avg batch acc: 0.4002
Train, Epoch: 1, Batch: 955, Step num: 955, Learning rate: 0.00066733, Avg batch loss: 0.6020, Avg batch acc: 0.3864
Train, Epoch: 1, Batch: 956, Step num: 956, Learning rate: 0.00066803, Avg batch loss: 0.5676, Avg batch acc: 0.4377
Train, Epoch: 1, Batch: 957, Step num: 957, Learning rate: 0.00066872, Avg batch loss: 0.5638, Avg batch acc: 0.4165
Train, Epoch: 1, Batch: 958, Step num: 958, Learning rate: 0.00066942, Avg batch loss: 0.5940, Avg batch acc: 0.4125
Train, Epoch: 1, Batch: 959, Step num: 959, Learning rate: 0.00067012, Avg batch loss: 0.5482, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 960, Step num: 960, Learning rate: 0.00067082, Avg batch loss: 0.5799, Avg batch acc: 0.4182
Train, Epoch: 1, Batch: 961, Step num: 961, Learning rate: 0.00067152, Avg batch loss: 0.6198, Avg batch acc: 0.4057
Train, Epoch: 1, Batch: 962, Step num: 962, Learning rate: 0.00067222, Avg batch loss: 0.6119, Avg batch acc: 0.3948
Train, Epoch: 1, Batch: 963, Step num: 963, Learning rate: 0.00067292, Avg batch loss: 0.5242, Avg batch acc: 0.4175
Train, Epoch: 1, Batch: 964, Step num: 964, Learning rate: 0.00067362, Avg batch loss: 0.5974, Avg batch acc: 0.4049
Train, Epoch: 1, Batch: 965, Step num: 965, Learning rate: 0.00067431, Avg batch loss: 0.5857, Avg batch acc: 0.4093
Train, Epoch: 1, Batch: 966, Step num: 966, Learning rate: 0.00067501, Avg batch loss: 0.5733, Avg batch acc: 0.4008
Train, Epoch: 1, Batch: 967, Step num: 967, Learning rate: 0.00067571, Avg batch loss: 0.5982, Avg batch acc: 0.4030
Train, Epoch: 1, Batch: 968, Step num: 968, Learning rate: 0.00067641, Avg batch loss: 0.5499, Avg batch acc: 0.4100
Train, Epoch: 1, Batch: 969, Step num: 969, Learning rate: 0.00067711, Avg batch loss: 0.5994, Avg batch acc: 0.4070
Train, Epoch: 1, Batch: 970, Step num: 970, Learning rate: 0.00067781, Avg batch loss: 0.5689, Avg batch acc: 0.3926
Train, Epoch: 1, Batch: 971, Step num: 971, Learning rate: 0.00067851, Avg batch loss: 0.5548, Avg batch acc: 0.4159
Train, Epoch: 1, Batch: 972, Step num: 972, Learning rate: 0.00067921, Avg batch loss: 0.5522, Avg batch acc: 0.3880
Train, Epoch: 1, Batch: 973, Step num: 973, Learning rate: 0.00067990, Avg batch loss: 0.5526, Avg batch acc: 0.4230
Train, Epoch: 1, Batch: 974, Step num: 974, Learning rate: 0.00068060, Avg batch loss: 0.6106, Avg batch acc: 0.4092
Train, Epoch: 1, Batch: 975, Step num: 975, Learning rate: 0.00068130, Avg batch loss: 0.5997, Avg batch acc: 0.4301
Train, Epoch: 1, Batch: 976, Step num: 976, Learning rate: 0.00068200, Avg batch loss: 0.6276, Avg batch acc: 0.4056
Train, Epoch: 1, Batch: 977, Step num: 977, Learning rate: 0.00068270, Avg batch loss: 0.6266, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 978, Step num: 978, Learning rate: 0.00068340, Avg batch loss: 0.6270, Avg batch acc: 0.4086
Train, Epoch: 1, Batch: 979, Step num: 979, Learning rate: 0.00068410, Avg batch loss: 0.6217, Avg batch acc: 0.4108
Train, Epoch: 1, Batch: 980, Step num: 980, Learning rate: 0.00068480, Avg batch loss: 0.6170, Avg batch acc: 0.4116
Train, Epoch: 1, Batch: 981, Step num: 981, Learning rate: 0.00068549, Avg batch loss: 0.6000, Avg batch acc: 0.4154
Train, Epoch: 1, Batch: 982, Step num: 982, Learning rate: 0.00068619, Avg batch loss: 0.5949, Avg batch acc: 0.3868
Train, Epoch: 1, Batch: 983, Step num: 983, Learning rate: 0.00068689, Avg batch loss: 0.5826, Avg batch acc: 0.4259
Train, Epoch: 1, Batch: 984, Step num: 984, Learning rate: 0.00068759, Avg batch loss: 0.5953, Avg batch acc: 0.4158
Train, Epoch: 1, Batch: 985, Step num: 985, Learning rate: 0.00068829, Avg batch loss: 0.6295, Avg batch acc: 0.3898
Train, Epoch: 1, Batch: 986, Step num: 986, Learning rate: 0.00068899, Avg batch loss: 0.6046, Avg batch acc: 0.4003
Train, Epoch: 1, Batch: 987, Step num: 987, Learning rate: 0.00068969, Avg batch loss: 0.6023, Avg batch acc: 0.4075
Train, Epoch: 1, Batch: 988, Step num: 988, Learning rate: 0.00069039, Avg batch loss: 0.5909, Avg batch acc: 0.4061
Train, Epoch: 1, Batch: 989, Step num: 989, Learning rate: 0.00069108, Avg batch loss: 0.5606, Avg batch acc: 0.4177
Train, Epoch: 1, Batch: 990, Step num: 990, Learning rate: 0.00069178, Avg batch loss: 0.6253, Avg batch acc: 0.3939
Train, Epoch: 1, Batch: 991, Step num: 991, Learning rate: 0.00069248, Avg batch loss: 0.5618, Avg batch acc: 0.3773
Train, Epoch: 1, Batch: 992, Step num: 992, Learning rate: 0.00069318, Avg batch loss: 0.5780, Avg batch acc: 0.4164
Train, Epoch: 1, Batch: 993, Step num: 993, Learning rate: 0.00069388, Avg batch loss: 0.6171, Avg batch acc: 0.3703
Train, Epoch: 1, Batch: 994, Step num: 994, Learning rate: 0.00069458, Avg batch loss: 0.6088, Avg batch acc: 0.4216
Train, Epoch: 1, Batch: 995, Step num: 995, Learning rate: 0.00069528, Avg batch loss: 0.6359, Avg batch acc: 0.4061
Train, Epoch: 1, Batch: 996, Step num: 996, Learning rate: 0.00069598, Avg batch loss: 0.5873, Avg batch acc: 0.4043
Train, Epoch: 1, Batch: 997, Step num: 997, Learning rate: 0.00069667, Avg batch loss: 0.5564, Avg batch acc: 0.4258
Train, Epoch: 1, Batch: 998, Step num: 998, Learning rate: 0.00069737, Avg batch loss: 0.5845, Avg batch acc: 0.4038
Train, Epoch: 1, Batch: 999, Step num: 999, Learning rate: 0.00069807, Avg batch loss: 0.5932, Avg batch acc: 0.4089
Train, Epoch: 1, Batch: 1000, Step num: 1000, Learning rate: 0.00069877, Avg batch loss: 0.5810, Avg batch acc: 0.3979
Train, Epoch: 1, Batch: 1001, Step num: 1001, Learning rate: 0.00069947, Avg batch loss: 0.5864, Avg batch acc: 0.4213
Train, Epoch: 1, Batch: 1002, Step num: 1002, Learning rate: 0.00070017, Avg batch loss: 0.5622, Avg batch acc: 0.4035
Train, Epoch: 1, Batch: 1003, Step num: 1003, Learning rate: 0.00070087, Avg batch loss: 0.6149, Avg batch acc: 0.3974
Train, Epoch: 1, Batch: 1004, Step num: 1004, Learning rate: 0.00070157, Avg batch loss: 0.5977, Avg batch acc: 0.3810
Train, Epoch: 1, Batch: 1005, Step num: 1005, Learning rate: 0.00070227, Avg batch loss: 0.5670, Avg batch acc: 0.4166
Train, Epoch: 1, Batch: 1006, Step num: 1006, Learning rate: 0.00070296, Avg batch loss: 0.6531, Avg batch acc: 0.3984
Train, Epoch: 1, Batch: 1007, Step num: 1007, Learning rate: 0.00070366, Avg batch loss: 0.5635, Avg batch acc: 0.4258
Train, Epoch: 1, Batch: 1008, Step num: 1008, Learning rate: 0.00070436, Avg batch loss: 0.6259, Avg batch acc: 0.4061
Train, Epoch: 1, Batch: 1009, Step num: 1009, Learning rate: 0.00070506, Avg batch loss: 0.5951, Avg batch acc: 0.4050
Train, Epoch: 1, Batch: 1010, Step num: 1010, Learning rate: 0.00070576, Avg batch loss: 0.6038, Avg batch acc: 0.4044
Train, Epoch: 1, Batch: 1011, Step num: 1011, Learning rate: 0.00070646, Avg batch loss: 0.6095, Avg batch acc: 0.3913
Train, Epoch: 1, Batch: 1012, Step num: 1012, Learning rate: 0.00070716, Avg batch loss: 0.5999, Avg batch acc: 0.4115
Train, Epoch: 1, Batch: 1013, Step num: 1013, Learning rate: 0.00070786, Avg batch loss: 0.6558, Avg batch acc: 0.3915
Train, Epoch: 1, Batch: 1014, Step num: 1014, Learning rate: 0.00070855, Avg batch loss: 0.5736, Avg batch acc: 0.4078
Train, Epoch: 1, Batch: 1015, Step num: 1015, Learning rate: 0.00070925, Avg batch loss: 0.5938, Avg batch acc: 0.4051
Train, Epoch: 1, Batch: 1016, Step num: 1016, Learning rate: 0.00070995, Avg batch loss: 0.6130, Avg batch acc: 0.3860
Train, Epoch: 1, Batch: 1017, Step num: 1017, Learning rate: 0.00071065, Avg batch loss: 0.4996, Avg batch acc: 0.4244
Train, Epoch: 1, Batch: 1018, Step num: 1018, Learning rate: 0.00071135, Avg batch loss: 0.5742, Avg batch acc: 0.4122
Train, Epoch: 1, Batch: 1019, Step num: 1019, Learning rate: 0.00071205, Avg batch loss: 0.4936, Avg batch acc: 0.4402
Train, Epoch: 1, Batch: 1020, Step num: 1020, Learning rate: 0.00071275, Avg batch loss: 0.5457, Avg batch acc: 0.4063
Train, Epoch: 1, Batch: 1021, Step num: 1021, Learning rate: 0.00071345, Avg batch loss: 0.5553, Avg batch acc: 0.3974
Train, Epoch: 1, Batch: 1022, Step num: 1022, Learning rate: 0.00071414, Avg batch loss: 0.5338, Avg batch acc: 0.4333
Train, Epoch: 1, Batch: 1023, Step num: 1023, Learning rate: 0.00071484, Avg batch loss: 0.6023, Avg batch acc: 0.4265
Train, Epoch: 1, Batch: 1024, Step num: 1024, Learning rate: 0.00071554, Avg batch loss: 0.6085, Avg batch acc: 0.4013
Train, Epoch: 1, Batch: 1025, Step num: 1025, Learning rate: 0.00071624, Avg batch loss: 0.6011, Avg batch acc: 0.4046
Train, Epoch: 1, Batch: 1026, Step num: 1026, Learning rate: 0.00071694, Avg batch loss: 0.5958, Avg batch acc: 0.4111
Train, Epoch: 1, Batch: 1027, Step num: 1027, Learning rate: 0.00071764, Avg batch loss: 0.5619, Avg batch acc: 0.4009
Train, Epoch: 1, Batch: 1028, Step num: 1028, Learning rate: 0.00071834, Avg batch loss: 0.5902, Avg batch acc: 0.4192
Train, Epoch: 1, Batch: 1029, Step num: 1029, Learning rate: 0.00071904, Avg batch loss: 0.6090, Avg batch acc: 0.4004
Train, Epoch: 1, Batch: 1030, Step num: 1030, Learning rate: 0.00071973, Avg batch loss: 0.5484, Avg batch acc: 0.4038
Train, Epoch: 1, Batch: 1031, Step num: 1031, Learning rate: 0.00072043, Avg batch loss: 0.6121, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1032, Step num: 1032, Learning rate: 0.00072113, Avg batch loss: 0.5893, Avg batch acc: 0.4036
Train, Epoch: 1, Batch: 1033, Step num: 1033, Learning rate: 0.00072183, Avg batch loss: 0.6093, Avg batch acc: 0.4189
Train, Epoch: 1, Batch: 1034, Step num: 1034, Learning rate: 0.00072253, Avg batch loss: 0.5303, Avg batch acc: 0.4385
Train, Epoch: 1, Batch: 1035, Step num: 1035, Learning rate: 0.00072323, Avg batch loss: 0.5296, Avg batch acc: 0.4450
Train, Epoch: 1, Batch: 1036, Step num: 1036, Learning rate: 0.00072393, Avg batch loss: 0.5551, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 1037, Step num: 1037, Learning rate: 0.00072463, Avg batch loss: 0.6332, Avg batch acc: 0.4087
Train, Epoch: 1, Batch: 1038, Step num: 1038, Learning rate: 0.00072532, Avg batch loss: 0.5050, Avg batch acc: 0.4070
Train, Epoch: 1, Batch: 1039, Step num: 1039, Learning rate: 0.00072602, Avg batch loss: 0.6161, Avg batch acc: 0.3956
Train, Epoch: 1, Batch: 1040, Step num: 1040, Learning rate: 0.00072672, Avg batch loss: 0.5478, Avg batch acc: 0.4139
Train, Epoch: 1, Batch: 1041, Step num: 1041, Learning rate: 0.00072742, Avg batch loss: 0.5859, Avg batch acc: 0.3945
Train, Epoch: 1, Batch: 1042, Step num: 1042, Learning rate: 0.00072812, Avg batch loss: 0.5339, Avg batch acc: 0.4302
Train, Epoch: 1, Batch: 1043, Step num: 1043, Learning rate: 0.00072882, Avg batch loss: 0.6184, Avg batch acc: 0.3867
Train, Epoch: 1, Batch: 1044, Step num: 1044, Learning rate: 0.00072952, Avg batch loss: 0.6182, Avg batch acc: 0.4071
Train, Epoch: 1, Batch: 1045, Step num: 1045, Learning rate: 0.00073022, Avg batch loss: 0.5557, Avg batch acc: 0.4195
Train, Epoch: 1, Batch: 1046, Step num: 1046, Learning rate: 0.00073091, Avg batch loss: 0.6100, Avg batch acc: 0.3999
Train, Epoch: 1, Batch: 1047, Step num: 1047, Learning rate: 0.00073161, Avg batch loss: 0.6118, Avg batch acc: 0.4081
Train, Epoch: 1, Batch: 1048, Step num: 1048, Learning rate: 0.00073231, Avg batch loss: 0.5418, Avg batch acc: 0.4065
Train, Epoch: 1, Batch: 1049, Step num: 1049, Learning rate: 0.00073301, Avg batch loss: 0.6107, Avg batch acc: 0.4008
Train, Epoch: 1, Batch: 1050, Step num: 1050, Learning rate: 0.00073371, Avg batch loss: 0.5859, Avg batch acc: 0.4169
Train, Epoch: 1, Batch: 1051, Step num: 1051, Learning rate: 0.00073441, Avg batch loss: 0.5892, Avg batch acc: 0.4209
Train, Epoch: 1, Batch: 1052, Step num: 1052, Learning rate: 0.00073511, Avg batch loss: 0.5745, Avg batch acc: 0.4065
Train, Epoch: 1, Batch: 1053, Step num: 1053, Learning rate: 0.00073581, Avg batch loss: 0.5045, Avg batch acc: 0.4264
Train, Epoch: 1, Batch: 1054, Step num: 1054, Learning rate: 0.00073650, Avg batch loss: 0.5700, Avg batch acc: 0.4246
Train, Epoch: 1, Batch: 1055, Step num: 1055, Learning rate: 0.00073720, Avg batch loss: 0.5514, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 1056, Step num: 1056, Learning rate: 0.00073790, Avg batch loss: 0.5278, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 1057, Step num: 1057, Learning rate: 0.00073860, Avg batch loss: 0.5540, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1058, Step num: 1058, Learning rate: 0.00073930, Avg batch loss: 0.6630, Avg batch acc: 0.3929
Train, Epoch: 1, Batch: 1059, Step num: 1059, Learning rate: 0.00074000, Avg batch loss: 0.5868, Avg batch acc: 0.3836
Train, Epoch: 1, Batch: 1060, Step num: 1060, Learning rate: 0.00074070, Avg batch loss: 0.5906, Avg batch acc: 0.4097
Train, Epoch: 1, Batch: 1061, Step num: 1061, Learning rate: 0.00074140, Avg batch loss: 0.5762, Avg batch acc: 0.3980
Train, Epoch: 1, Batch: 1062, Step num: 1062, Learning rate: 0.00074210, Avg batch loss: 0.6204, Avg batch acc: 0.3920
Train, Epoch: 1, Batch: 1063, Step num: 1063, Learning rate: 0.00074279, Avg batch loss: 0.5647, Avg batch acc: 0.4025
Train, Epoch: 1, Batch: 1064, Step num: 1064, Learning rate: 0.00074349, Avg batch loss: 0.5397, Avg batch acc: 0.4337
Train, Epoch: 1, Batch: 1065, Step num: 1065, Learning rate: 0.00074419, Avg batch loss: 0.6673, Avg batch acc: 0.3887
Train, Epoch: 1, Batch: 1066, Step num: 1066, Learning rate: 0.00074489, Avg batch loss: 0.5627, Avg batch acc: 0.4140
Train, Epoch: 1, Batch: 1067, Step num: 1067, Learning rate: 0.00074559, Avg batch loss: 0.5771, Avg batch acc: 0.3897
Train, Epoch: 1, Batch: 1068, Step num: 1068, Learning rate: 0.00074629, Avg batch loss: 0.5452, Avg batch acc: 0.4140
Train, Epoch: 1, Batch: 1069, Step num: 1069, Learning rate: 0.00074699, Avg batch loss: 0.5873, Avg batch acc: 0.4283
Train, Epoch: 1, Batch: 1070, Step num: 1070, Learning rate: 0.00074769, Avg batch loss: 0.6038, Avg batch acc: 0.4074
Train, Epoch: 1, Batch: 1071, Step num: 1071, Learning rate: 0.00074838, Avg batch loss: 0.5626, Avg batch acc: 0.4170
Train, Epoch: 1, Batch: 1072, Step num: 1072, Learning rate: 0.00074908, Avg batch loss: 0.5763, Avg batch acc: 0.4198
Train, Epoch: 1, Batch: 1073, Step num: 1073, Learning rate: 0.00074978, Avg batch loss: 0.6523, Avg batch acc: 0.4058
Train, Epoch: 1, Batch: 1074, Step num: 1074, Learning rate: 0.00075048, Avg batch loss: 0.6219, Avg batch acc: 0.3942
Train, Epoch: 1, Batch: 1075, Step num: 1075, Learning rate: 0.00075118, Avg batch loss: 0.5639, Avg batch acc: 0.4133
Train, Epoch: 1, Batch: 1076, Step num: 1076, Learning rate: 0.00075188, Avg batch loss: 0.6579, Avg batch acc: 0.3844
Train, Epoch: 1, Batch: 1077, Step num: 1077, Learning rate: 0.00075258, Avg batch loss: 0.5406, Avg batch acc: 0.4169
Train, Epoch: 1, Batch: 1078, Step num: 1078, Learning rate: 0.00075328, Avg batch loss: 0.5910, Avg batch acc: 0.4173
Train, Epoch: 1, Batch: 1079, Step num: 1079, Learning rate: 0.00075397, Avg batch loss: 0.5422, Avg batch acc: 0.4017
Train, Epoch: 1, Batch: 1080, Step num: 1080, Learning rate: 0.00075467, Avg batch loss: 0.5252, Avg batch acc: 0.4208
Train, Epoch: 1, Batch: 1081, Step num: 1081, Learning rate: 0.00075537, Avg batch loss: 0.5974, Avg batch acc: 0.4063
Train, Epoch: 1, Batch: 1082, Step num: 1082, Learning rate: 0.00075607, Avg batch loss: 0.6048, Avg batch acc: 0.4015
Train, Epoch: 1, Batch: 1083, Step num: 1083, Learning rate: 0.00075677, Avg batch loss: 0.5547, Avg batch acc: 0.4263
Train, Epoch: 1, Batch: 1084, Step num: 1084, Learning rate: 0.00075747, Avg batch loss: 0.5477, Avg batch acc: 0.4217
Train, Epoch: 1, Batch: 1085, Step num: 1085, Learning rate: 0.00075817, Avg batch loss: 0.5709, Avg batch acc: 0.4185
Train, Epoch: 1, Batch: 1086, Step num: 1086, Learning rate: 0.00075887, Avg batch loss: 0.5725, Avg batch acc: 0.4025
Train, Epoch: 1, Batch: 1087, Step num: 1087, Learning rate: 0.00075956, Avg batch loss: 0.5337, Avg batch acc: 0.4155
Train, Epoch: 1, Batch: 1088, Step num: 1088, Learning rate: 0.00076026, Avg batch loss: 0.6109, Avg batch acc: 0.3883
Train, Epoch: 1, Batch: 1089, Step num: 1089, Learning rate: 0.00076096, Avg batch loss: 0.4838, Avg batch acc: 0.4304
Train, Epoch: 1, Batch: 1090, Step num: 1090, Learning rate: 0.00076166, Avg batch loss: 0.5640, Avg batch acc: 0.4096
Train, Epoch: 1, Batch: 1091, Step num: 1091, Learning rate: 0.00076236, Avg batch loss: 0.5253, Avg batch acc: 0.4227
Train, Epoch: 1, Batch: 1092, Step num: 1092, Learning rate: 0.00076306, Avg batch loss: 0.5245, Avg batch acc: 0.4428
Train, Epoch: 1, Batch: 1093, Step num: 1093, Learning rate: 0.00076376, Avg batch loss: 0.5716, Avg batch acc: 0.4041
Train, Epoch: 1, Batch: 1094, Step num: 1094, Learning rate: 0.00076446, Avg batch loss: 0.6289, Avg batch acc: 0.3882
Train, Epoch: 1, Batch: 1095, Step num: 1095, Learning rate: 0.00076515, Avg batch loss: 0.6047, Avg batch acc: 0.4180
Train, Epoch: 1, Batch: 1096, Step num: 1096, Learning rate: 0.00076585, Avg batch loss: 0.6234, Avg batch acc: 0.4191
Train, Epoch: 1, Batch: 1097, Step num: 1097, Learning rate: 0.00076655, Avg batch loss: 0.5684, Avg batch acc: 0.4161
Train, Epoch: 1, Batch: 1098, Step num: 1098, Learning rate: 0.00076725, Avg batch loss: 0.6158, Avg batch acc: 0.4103
Train, Epoch: 1, Batch: 1099, Step num: 1099, Learning rate: 0.00076795, Avg batch loss: 0.5260, Avg batch acc: 0.4486
Train, Epoch: 1, Batch: 1100, Step num: 1100, Learning rate: 0.00076865, Avg batch loss: 0.5740, Avg batch acc: 0.4194
Train, Epoch: 1, Batch: 1101, Step num: 1101, Learning rate: 0.00076935, Avg batch loss: 0.5968, Avg batch acc: 0.4038
Train, Epoch: 1, Batch: 1102, Step num: 1102, Learning rate: 0.00077005, Avg batch loss: 0.6142, Avg batch acc: 0.3989
Train, Epoch: 1, Batch: 1103, Step num: 1103, Learning rate: 0.00077074, Avg batch loss: 0.6282, Avg batch acc: 0.3994
Train, Epoch: 1, Batch: 1104, Step num: 1104, Learning rate: 0.00077144, Avg batch loss: 0.5846, Avg batch acc: 0.4219
Train, Epoch: 1, Batch: 1105, Step num: 1105, Learning rate: 0.00077214, Avg batch loss: 0.5302, Avg batch acc: 0.4157
Train, Epoch: 1, Batch: 1106, Step num: 1106, Learning rate: 0.00077284, Avg batch loss: 0.5804, Avg batch acc: 0.4036
Train, Epoch: 1, Batch: 1107, Step num: 1107, Learning rate: 0.00077354, Avg batch loss: 0.5151, Avg batch acc: 0.4023
Train, Epoch: 1, Batch: 1108, Step num: 1108, Learning rate: 0.00077424, Avg batch loss: 0.5831, Avg batch acc: 0.4184
Train, Epoch: 1, Batch: 1109, Step num: 1109, Learning rate: 0.00077494, Avg batch loss: 0.5436, Avg batch acc: 0.4263
Train, Epoch: 1, Batch: 1110, Step num: 1110, Learning rate: 0.00077564, Avg batch loss: 0.6353, Avg batch acc: 0.3861
Train, Epoch: 1, Batch: 1111, Step num: 1111, Learning rate: 0.00077633, Avg batch loss: 0.5217, Avg batch acc: 0.4267
Train, Epoch: 1, Batch: 1112, Step num: 1112, Learning rate: 0.00077703, Avg batch loss: 0.6099, Avg batch acc: 0.4249
Train, Epoch: 1, Batch: 1113, Step num: 1113, Learning rate: 0.00077773, Avg batch loss: 0.5756, Avg batch acc: 0.4114
Train, Epoch: 1, Batch: 1114, Step num: 1114, Learning rate: 0.00077843, Avg batch loss: 0.5694, Avg batch acc: 0.4231
Train, Epoch: 1, Batch: 1115, Step num: 1115, Learning rate: 0.00077913, Avg batch loss: 0.6337, Avg batch acc: 0.3865
Train, Epoch: 1, Batch: 1116, Step num: 1116, Learning rate: 0.00077983, Avg batch loss: 0.5828, Avg batch acc: 0.4071
Train, Epoch: 1, Batch: 1117, Step num: 1117, Learning rate: 0.00078053, Avg batch loss: 0.6183, Avg batch acc: 0.4282
Train, Epoch: 1, Batch: 1118, Step num: 1118, Learning rate: 0.00078123, Avg batch loss: 0.5742, Avg batch acc: 0.4172
Train, Epoch: 1, Batch: 1119, Step num: 1119, Learning rate: 0.00078193, Avg batch loss: 0.6307, Avg batch acc: 0.3793
Train, Epoch: 1, Batch: 1120, Step num: 1120, Learning rate: 0.00078262, Avg batch loss: 0.5456, Avg batch acc: 0.4332
Train, Epoch: 1, Batch: 1121, Step num: 1121, Learning rate: 0.00078332, Avg batch loss: 0.6064, Avg batch acc: 0.4023
Train, Epoch: 1, Batch: 1122, Step num: 1122, Learning rate: 0.00078402, Avg batch loss: 0.5670, Avg batch acc: 0.4076
Train, Epoch: 1, Batch: 1123, Step num: 1123, Learning rate: 0.00078472, Avg batch loss: 0.5157, Avg batch acc: 0.4326
Train, Epoch: 1, Batch: 1124, Step num: 1124, Learning rate: 0.00078542, Avg batch loss: 0.5902, Avg batch acc: 0.4014
Train, Epoch: 1, Batch: 1125, Step num: 1125, Learning rate: 0.00078612, Avg batch loss: 0.5601, Avg batch acc: 0.4102
Train, Epoch: 1, Batch: 1126, Step num: 1126, Learning rate: 0.00078682, Avg batch loss: 0.5788, Avg batch acc: 0.4213
Train, Epoch: 1, Batch: 1127, Step num: 1127, Learning rate: 0.00078752, Avg batch loss: 0.5546, Avg batch acc: 0.4169
Train, Epoch: 1, Batch: 1128, Step num: 1128, Learning rate: 0.00078821, Avg batch loss: 0.5113, Avg batch acc: 0.4289
Train, Epoch: 1, Batch: 1129, Step num: 1129, Learning rate: 0.00078891, Avg batch loss: 0.5638, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1130, Step num: 1130, Learning rate: 0.00078961, Avg batch loss: 0.6004, Avg batch acc: 0.4187
Train, Epoch: 1, Batch: 1131, Step num: 1131, Learning rate: 0.00079031, Avg batch loss: 0.5726, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 1132, Step num: 1132, Learning rate: 0.00079101, Avg batch loss: 0.5837, Avg batch acc: 0.4151
Train, Epoch: 1, Batch: 1133, Step num: 1133, Learning rate: 0.00079171, Avg batch loss: 0.5697, Avg batch acc: 0.4266
Train, Epoch: 1, Batch: 1134, Step num: 1134, Learning rate: 0.00079241, Avg batch loss: 0.5785, Avg batch acc: 0.4153
Train, Epoch: 1, Batch: 1135, Step num: 1135, Learning rate: 0.00079311, Avg batch loss: 0.5666, Avg batch acc: 0.4296
Train, Epoch: 1, Batch: 1136, Step num: 1136, Learning rate: 0.00079380, Avg batch loss: 0.5264, Avg batch acc: 0.4328
Train, Epoch: 1, Batch: 1137, Step num: 1137, Learning rate: 0.00079450, Avg batch loss: 0.5670, Avg batch acc: 0.4166
Train, Epoch: 1, Batch: 1138, Step num: 1138, Learning rate: 0.00079520, Avg batch loss: 0.5709, Avg batch acc: 0.4273
Train, Epoch: 1, Batch: 1139, Step num: 1139, Learning rate: 0.00079590, Avg batch loss: 0.5634, Avg batch acc: 0.4156
Train, Epoch: 1, Batch: 1140, Step num: 1140, Learning rate: 0.00079660, Avg batch loss: 0.5526, Avg batch acc: 0.4236
Train, Epoch: 1, Batch: 1141, Step num: 1141, Learning rate: 0.00079730, Avg batch loss: 0.5541, Avg batch acc: 0.4261
Train, Epoch: 1, Batch: 1142, Step num: 1142, Learning rate: 0.00079800, Avg batch loss: 0.5251, Avg batch acc: 0.4373
Train, Epoch: 1, Batch: 1143, Step num: 1143, Learning rate: 0.00079870, Avg batch loss: 0.5647, Avg batch acc: 0.4241
Train, Epoch: 1, Batch: 1144, Step num: 1144, Learning rate: 0.00079939, Avg batch loss: 0.5994, Avg batch acc: 0.4077
Train, Epoch: 1, Batch: 1145, Step num: 1145, Learning rate: 0.00080009, Avg batch loss: 0.5815, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 1146, Step num: 1146, Learning rate: 0.00080079, Avg batch loss: 0.5619, Avg batch acc: 0.4019
Train, Epoch: 1, Batch: 1147, Step num: 1147, Learning rate: 0.00080149, Avg batch loss: 0.5268, Avg batch acc: 0.4435
Train, Epoch: 1, Batch: 1148, Step num: 1148, Learning rate: 0.00080219, Avg batch loss: 0.5471, Avg batch acc: 0.4262
Train, Epoch: 1, Batch: 1149, Step num: 1149, Learning rate: 0.00080289, Avg batch loss: 0.5661, Avg batch acc: 0.4072
Train, Epoch: 1, Batch: 1150, Step num: 1150, Learning rate: 0.00080359, Avg batch loss: 0.5837, Avg batch acc: 0.4122
Train, Epoch: 1, Batch: 1151, Step num: 1151, Learning rate: 0.00080429, Avg batch loss: 0.5548, Avg batch acc: 0.4248
Train, Epoch: 1, Batch: 1152, Step num: 1152, Learning rate: 0.00080498, Avg batch loss: 0.5273, Avg batch acc: 0.4299
Train, Epoch: 1, Batch: 1153, Step num: 1153, Learning rate: 0.00080568, Avg batch loss: 0.5587, Avg batch acc: 0.4216
Train, Epoch: 1, Batch: 1154, Step num: 1154, Learning rate: 0.00080638, Avg batch loss: 0.5341, Avg batch acc: 0.4114
Train, Epoch: 1, Batch: 1155, Step num: 1155, Learning rate: 0.00080708, Avg batch loss: 0.6126, Avg batch acc: 0.3936
Train, Epoch: 1, Batch: 1156, Step num: 1156, Learning rate: 0.00080778, Avg batch loss: 0.5824, Avg batch acc: 0.4276
Train, Epoch: 1, Batch: 1157, Step num: 1157, Learning rate: 0.00080848, Avg batch loss: 0.5740, Avg batch acc: 0.3931
Train, Epoch: 1, Batch: 1158, Step num: 1158, Learning rate: 0.00080918, Avg batch loss: 0.5659, Avg batch acc: 0.4074
Train, Epoch: 1, Batch: 1159, Step num: 1159, Learning rate: 0.00080988, Avg batch loss: 0.5455, Avg batch acc: 0.4234
Train, Epoch: 1, Batch: 1160, Step num: 1160, Learning rate: 0.00081057, Avg batch loss: 0.5753, Avg batch acc: 0.4129
Train, Epoch: 1, Batch: 1161, Step num: 1161, Learning rate: 0.00081127, Avg batch loss: 0.5615, Avg batch acc: 0.4264
Train, Epoch: 1, Batch: 1162, Step num: 1162, Learning rate: 0.00081197, Avg batch loss: 0.5808, Avg batch acc: 0.4116
Train, Epoch: 1, Batch: 1163, Step num: 1163, Learning rate: 0.00081267, Avg batch loss: 0.5446, Avg batch acc: 0.4090
Train, Epoch: 1, Batch: 1164, Step num: 1164, Learning rate: 0.00081337, Avg batch loss: 0.5424, Avg batch acc: 0.4320
Train, Epoch: 1, Batch: 1165, Step num: 1165, Learning rate: 0.00081407, Avg batch loss: 0.5822, Avg batch acc: 0.4207
Train, Epoch: 1, Batch: 1166, Step num: 1166, Learning rate: 0.00081477, Avg batch loss: 0.6339, Avg batch acc: 0.4263
Train, Epoch: 1, Batch: 1167, Step num: 1167, Learning rate: 0.00081547, Avg batch loss: 0.5533, Avg batch acc: 0.4210
Train, Epoch: 1, Batch: 1168, Step num: 1168, Learning rate: 0.00081616, Avg batch loss: 0.5626, Avg batch acc: 0.4083
Train, Epoch: 1, Batch: 1169, Step num: 1169, Learning rate: 0.00081686, Avg batch loss: 0.5276, Avg batch acc: 0.4286
Train, Epoch: 1, Batch: 1170, Step num: 1170, Learning rate: 0.00081756, Avg batch loss: 0.5650, Avg batch acc: 0.4239
Train, Epoch: 1, Batch: 1171, Step num: 1171, Learning rate: 0.00081826, Avg batch loss: 0.5486, Avg batch acc: 0.4157
Train, Epoch: 1, Batch: 1172, Step num: 1172, Learning rate: 0.00081896, Avg batch loss: 0.5576, Avg batch acc: 0.3893
Train, Epoch: 1, Batch: 1173, Step num: 1173, Learning rate: 0.00081966, Avg batch loss: 0.5684, Avg batch acc: 0.4069
Train, Epoch: 1, Batch: 1174, Step num: 1174, Learning rate: 0.00082036, Avg batch loss: 0.5386, Avg batch acc: 0.4367
Train, Epoch: 1, Batch: 1175, Step num: 1175, Learning rate: 0.00082106, Avg batch loss: 0.5240, Avg batch acc: 0.4307
Train, Epoch: 1, Batch: 1176, Step num: 1176, Learning rate: 0.00082175, Avg batch loss: 0.5452, Avg batch acc: 0.4402
Train, Epoch: 1, Batch: 1177, Step num: 1177, Learning rate: 0.00082245, Avg batch loss: 0.6217, Avg batch acc: 0.4220
Train, Epoch: 1, Batch: 1178, Step num: 1178, Learning rate: 0.00082315, Avg batch loss: 0.5509, Avg batch acc: 0.4053
Train, Epoch: 1, Batch: 1179, Step num: 1179, Learning rate: 0.00082385, Avg batch loss: 0.5860, Avg batch acc: 0.4209
Train, Epoch: 1, Batch: 1180, Step num: 1180, Learning rate: 0.00082455, Avg batch loss: 0.5618, Avg batch acc: 0.4329
Train, Epoch: 1, Batch: 1181, Step num: 1181, Learning rate: 0.00082525, Avg batch loss: 0.5876, Avg batch acc: 0.4223
Train, Epoch: 1, Batch: 1182, Step num: 1182, Learning rate: 0.00082595, Avg batch loss: 0.5508, Avg batch acc: 0.4085
Train, Epoch: 1, Batch: 1183, Step num: 1183, Learning rate: 0.00082665, Avg batch loss: 0.5358, Avg batch acc: 0.4094
Train, Epoch: 1, Batch: 1184, Step num: 1184, Learning rate: 0.00082735, Avg batch loss: 0.5549, Avg batch acc: 0.4015
Train, Epoch: 1, Batch: 1185, Step num: 1185, Learning rate: 0.00082804, Avg batch loss: 0.5806, Avg batch acc: 0.4193
Train, Epoch: 1, Batch: 1186, Step num: 1186, Learning rate: 0.00082874, Avg batch loss: 0.5281, Avg batch acc: 0.4317
Train, Epoch: 1, Batch: 1187, Step num: 1187, Learning rate: 0.00082944, Avg batch loss: 0.5014, Avg batch acc: 0.4252
Train, Epoch: 1, Batch: 1188, Step num: 1188, Learning rate: 0.00083014, Avg batch loss: 0.5942, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1189, Step num: 1189, Learning rate: 0.00083084, Avg batch loss: 0.5511, Avg batch acc: 0.4465
Train, Epoch: 1, Batch: 1190, Step num: 1190, Learning rate: 0.00083154, Avg batch loss: 0.5363, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1191, Step num: 1191, Learning rate: 0.00083224, Avg batch loss: 0.5562, Avg batch acc: 0.4325
Train, Epoch: 1, Batch: 1192, Step num: 1192, Learning rate: 0.00083294, Avg batch loss: 0.5503, Avg batch acc: 0.4384
Train, Epoch: 1, Batch: 1193, Step num: 1193, Learning rate: 0.00083363, Avg batch loss: 0.5391, Avg batch acc: 0.4267
Train, Epoch: 1, Batch: 1194, Step num: 1194, Learning rate: 0.00083433, Avg batch loss: 0.5715, Avg batch acc: 0.4092
Train, Epoch: 1, Batch: 1195, Step num: 1195, Learning rate: 0.00083503, Avg batch loss: 0.5611, Avg batch acc: 0.4352
Train, Epoch: 1, Batch: 1196, Step num: 1196, Learning rate: 0.00083573, Avg batch loss: 0.5585, Avg batch acc: 0.4429
Train, Epoch: 1, Batch: 1197, Step num: 1197, Learning rate: 0.00083643, Avg batch loss: 0.5792, Avg batch acc: 0.4116
Train, Epoch: 1, Batch: 1198, Step num: 1198, Learning rate: 0.00083713, Avg batch loss: 0.5802, Avg batch acc: 0.4018
Train, Epoch: 1, Batch: 1199, Step num: 1199, Learning rate: 0.00083783, Avg batch loss: 0.5538, Avg batch acc: 0.4312
Train, Epoch: 1, Batch: 1200, Step num: 1200, Learning rate: 0.00083853, Avg batch loss: 0.4903, Avg batch acc: 0.4381
Train, Epoch: 1, Batch: 1201, Step num: 1201, Learning rate: 0.00083922, Avg batch loss: 0.5132, Avg batch acc: 0.4342
Train, Epoch: 1, Batch: 1202, Step num: 1202, Learning rate: 0.00083992, Avg batch loss: 0.5127, Avg batch acc: 0.4398
Train, Epoch: 1, Batch: 1203, Step num: 1203, Learning rate: 0.00084062, Avg batch loss: 0.4991, Avg batch acc: 0.4458
Train, Epoch: 1, Batch: 1204, Step num: 1204, Learning rate: 0.00084132, Avg batch loss: 0.4740, Avg batch acc: 0.4504
Train, Epoch: 1, Batch: 1205, Step num: 1205, Learning rate: 0.00084202, Avg batch loss: 0.5271, Avg batch acc: 0.4079
Train, Epoch: 1, Batch: 1206, Step num: 1206, Learning rate: 0.00084272, Avg batch loss: 0.5374, Avg batch acc: 0.4306
Train, Epoch: 1, Batch: 1207, Step num: 1207, Learning rate: 0.00084342, Avg batch loss: 0.4957, Avg batch acc: 0.4130
Train, Epoch: 1, Batch: 1208, Step num: 1208, Learning rate: 0.00084412, Avg batch loss: 0.5795, Avg batch acc: 0.4192
Train, Epoch: 1, Batch: 1209, Step num: 1209, Learning rate: 0.00084481, Avg batch loss: 0.4929, Avg batch acc: 0.4475
Train, Epoch: 1, Batch: 1210, Step num: 1210, Learning rate: 0.00084551, Avg batch loss: 0.5495, Avg batch acc: 0.4047
Train, Epoch: 1, Batch: 1211, Step num: 1211, Learning rate: 0.00084621, Avg batch loss: 0.4802, Avg batch acc: 0.4483
Train, Epoch: 1, Batch: 1212, Step num: 1212, Learning rate: 0.00084691, Avg batch loss: 0.5361, Avg batch acc: 0.4429
Train, Epoch: 1, Batch: 1213, Step num: 1213, Learning rate: 0.00084761, Avg batch loss: 0.5717, Avg batch acc: 0.4229
Train, Epoch: 1, Batch: 1214, Step num: 1214, Learning rate: 0.00084831, Avg batch loss: 0.5089, Avg batch acc: 0.4219
Train, Epoch: 1, Batch: 1215, Step num: 1215, Learning rate: 0.00084901, Avg batch loss: 0.6121, Avg batch acc: 0.3998
Train, Epoch: 1, Batch: 1216, Step num: 1216, Learning rate: 0.00084971, Avg batch loss: 0.5546, Avg batch acc: 0.4331
Train, Epoch: 1, Batch: 1217, Step num: 1217, Learning rate: 0.00085040, Avg batch loss: 0.6205, Avg batch acc: 0.4105
Train, Epoch: 1, Batch: 1218, Step num: 1218, Learning rate: 0.00085110, Avg batch loss: 0.5649, Avg batch acc: 0.4036
Train, Epoch: 1, Batch: 1219, Step num: 1219, Learning rate: 0.00085180, Avg batch loss: 0.5924, Avg batch acc: 0.3953
Train, Epoch: 1, Batch: 1220, Step num: 1220, Learning rate: 0.00085250, Avg batch loss: 0.5275, Avg batch acc: 0.4226
Train, Epoch: 1, Batch: 1221, Step num: 1221, Learning rate: 0.00085320, Avg batch loss: 0.5154, Avg batch acc: 0.4301
Train, Epoch: 1, Batch: 1222, Step num: 1222, Learning rate: 0.00085390, Avg batch loss: 0.5408, Avg batch acc: 0.4276
Train, Epoch: 1, Batch: 1223, Step num: 1223, Learning rate: 0.00085460, Avg batch loss: 0.5625, Avg batch acc: 0.4128
Train, Epoch: 1, Batch: 1224, Step num: 1224, Learning rate: 0.00085530, Avg batch loss: 0.4907, Avg batch acc: 0.4528
Train, Epoch: 1, Batch: 1225, Step num: 1225, Learning rate: 0.00085599, Avg batch loss: 0.5116, Avg batch acc: 0.4336
Train, Epoch: 1, Batch: 1226, Step num: 1226, Learning rate: 0.00085669, Avg batch loss: 0.5629, Avg batch acc: 0.4284
Train, Epoch: 1, Batch: 1227, Step num: 1227, Learning rate: 0.00085739, Avg batch loss: 0.5796, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1228, Step num: 1228, Learning rate: 0.00085809, Avg batch loss: 0.5578, Avg batch acc: 0.4342
Train, Epoch: 1, Batch: 1229, Step num: 1229, Learning rate: 0.00085879, Avg batch loss: 0.5571, Avg batch acc: 0.4139
Train, Epoch: 1, Batch: 1230, Step num: 1230, Learning rate: 0.00085949, Avg batch loss: 0.5439, Avg batch acc: 0.4421
Train, Epoch: 1, Batch: 1231, Step num: 1231, Learning rate: 0.00086019, Avg batch loss: 0.5133, Avg batch acc: 0.4152
Train, Epoch: 1, Batch: 1232, Step num: 1232, Learning rate: 0.00086089, Avg batch loss: 0.5723, Avg batch acc: 0.4072
Train, Epoch: 1, Batch: 1233, Step num: 1233, Learning rate: 0.00086158, Avg batch loss: 0.5523, Avg batch acc: 0.4445
Train, Epoch: 1, Batch: 1234, Step num: 1234, Learning rate: 0.00086228, Avg batch loss: 0.5349, Avg batch acc: 0.4118
Train, Epoch: 1, Batch: 1235, Step num: 1235, Learning rate: 0.00086298, Avg batch loss: 0.5724, Avg batch acc: 0.4165
Train, Epoch: 1, Batch: 1236, Step num: 1236, Learning rate: 0.00086368, Avg batch loss: 0.5278, Avg batch acc: 0.4281
Train, Epoch: 1, Batch: 1237, Step num: 1237, Learning rate: 0.00086438, Avg batch loss: 0.5681, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 1238, Step num: 1238, Learning rate: 0.00086508, Avg batch loss: 0.5426, Avg batch acc: 0.4295
Train, Epoch: 1, Batch: 1239, Step num: 1239, Learning rate: 0.00086578, Avg batch loss: 0.5301, Avg batch acc: 0.4407
Train, Epoch: 1, Batch: 1240, Step num: 1240, Learning rate: 0.00086648, Avg batch loss: 0.5167, Avg batch acc: 0.4128
Train, Epoch: 1, Batch: 1241, Step num: 1241, Learning rate: 0.00086718, Avg batch loss: 0.5324, Avg batch acc: 0.4194
Train, Epoch: 1, Batch: 1242, Step num: 1242, Learning rate: 0.00086787, Avg batch loss: 0.5762, Avg batch acc: 0.4175
Train, Epoch: 1, Batch: 1243, Step num: 1243, Learning rate: 0.00086857, Avg batch loss: 0.5568, Avg batch acc: 0.4241
Train, Epoch: 1, Batch: 1244, Step num: 1244, Learning rate: 0.00086927, Avg batch loss: 0.5659, Avg batch acc: 0.4164
Train, Epoch: 1, Batch: 1245, Step num: 1245, Learning rate: 0.00086997, Avg batch loss: 0.5326, Avg batch acc: 0.4176
Train, Epoch: 1, Batch: 1246, Step num: 1246, Learning rate: 0.00087067, Avg batch loss: 0.6164, Avg batch acc: 0.4130
Train, Epoch: 1, Batch: 1247, Step num: 1247, Learning rate: 0.00087137, Avg batch loss: 0.6399, Avg batch acc: 0.4129
Train, Epoch: 1, Batch: 1248, Step num: 1248, Learning rate: 0.00087207, Avg batch loss: 0.5781, Avg batch acc: 0.4004
Train, Epoch: 1, Batch: 1249, Step num: 1249, Learning rate: 0.00087277, Avg batch loss: 0.5377, Avg batch acc: 0.4238
Train, Epoch: 1, Batch: 1250, Step num: 1250, Learning rate: 0.00087346, Avg batch loss: 0.5065, Avg batch acc: 0.4376
Train, Epoch: 1, Batch: 1251, Step num: 1251, Learning rate: 0.00087416, Avg batch loss: 0.5401, Avg batch acc: 0.4179
Train, Epoch: 1, Batch: 1252, Step num: 1252, Learning rate: 0.00087486, Avg batch loss: 0.5774, Avg batch acc: 0.4189
Train, Epoch: 1, Batch: 1253, Step num: 1253, Learning rate: 0.00087556, Avg batch loss: 0.5818, Avg batch acc: 0.4210
Train, Epoch: 1, Batch: 1254, Step num: 1254, Learning rate: 0.00087626, Avg batch loss: 0.5674, Avg batch acc: 0.4056
Train, Epoch: 1, Batch: 1255, Step num: 1255, Learning rate: 0.00087696, Avg batch loss: 0.5805, Avg batch acc: 0.4026
Train, Epoch: 1, Batch: 1256, Step num: 1256, Learning rate: 0.00087766, Avg batch loss: 0.5396, Avg batch acc: 0.4270
Train, Epoch: 1, Batch: 1257, Step num: 1257, Learning rate: 0.00087836, Avg batch loss: 0.5428, Avg batch acc: 0.4328
Train, Epoch: 1, Batch: 1258, Step num: 1258, Learning rate: 0.00087905, Avg batch loss: 0.5365, Avg batch acc: 0.4367
Train, Epoch: 1, Batch: 1259, Step num: 1259, Learning rate: 0.00087975, Avg batch loss: 0.5414, Avg batch acc: 0.4127
Train, Epoch: 1, Batch: 1260, Step num: 1260, Learning rate: 0.00088045, Avg batch loss: 0.5092, Avg batch acc: 0.4358
Train, Epoch: 1, Batch: 1261, Step num: 1261, Learning rate: 0.00088115, Avg batch loss: 0.4989, Avg batch acc: 0.4158
Train, Epoch: 1, Batch: 1262, Step num: 1262, Learning rate: 0.00088185, Avg batch loss: 0.5609, Avg batch acc: 0.4008
Train, Epoch: 1, Batch: 1263, Step num: 1263, Learning rate: 0.00088255, Avg batch loss: 0.5529, Avg batch acc: 0.4142
Train, Epoch: 1, Batch: 1264, Step num: 1264, Learning rate: 0.00088325, Avg batch loss: 0.5730, Avg batch acc: 0.4183
Train, Epoch: 1, Batch: 1265, Step num: 1265, Learning rate: 0.00088395, Avg batch loss: 0.5768, Avg batch acc: 0.4122
Train, Epoch: 1, Batch: 1266, Step num: 1266, Learning rate: 0.00088464, Avg batch loss: 0.5787, Avg batch acc: 0.4402
Train, Epoch: 1, Batch: 1267, Step num: 1267, Learning rate: 0.00088534, Avg batch loss: 0.4982, Avg batch acc: 0.4169
Train, Epoch: 1, Batch: 1268, Step num: 1268, Learning rate: 0.00088604, Avg batch loss: 0.5231, Avg batch acc: 0.4404
Train, Epoch: 1, Batch: 1269, Step num: 1269, Learning rate: 0.00088674, Avg batch loss: 0.5045, Avg batch acc: 0.4085
Train, Epoch: 1, Batch: 1270, Step num: 1270, Learning rate: 0.00088744, Avg batch loss: 0.5833, Avg batch acc: 0.4254
Train, Epoch: 1, Batch: 1271, Step num: 1271, Learning rate: 0.00088814, Avg batch loss: 0.5981, Avg batch acc: 0.4346
Train, Epoch: 1, Batch: 1272, Step num: 1272, Learning rate: 0.00088884, Avg batch loss: 0.5262, Avg batch acc: 0.4283
Train, Epoch: 1, Batch: 1273, Step num: 1273, Learning rate: 0.00088954, Avg batch loss: 0.5556, Avg batch acc: 0.4162
Train, Epoch: 1, Batch: 1274, Step num: 1274, Learning rate: 0.00089023, Avg batch loss: 0.5297, Avg batch acc: 0.4155
Train, Epoch: 1, Batch: 1275, Step num: 1275, Learning rate: 0.00089093, Avg batch loss: 0.5173, Avg batch acc: 0.4373
Train, Epoch: 1, Batch: 1276, Step num: 1276, Learning rate: 0.00089163, Avg batch loss: 0.5315, Avg batch acc: 0.4336
Train, Epoch: 1, Batch: 1277, Step num: 1277, Learning rate: 0.00089233, Avg batch loss: 0.5370, Avg batch acc: 0.4271
Train, Epoch: 1, Batch: 1278, Step num: 1278, Learning rate: 0.00089303, Avg batch loss: 0.5143, Avg batch acc: 0.4305
Train, Epoch: 1, Batch: 1279, Step num: 1279, Learning rate: 0.00089373, Avg batch loss: 0.6012, Avg batch acc: 0.4351
Train, Epoch: 1, Batch: 1280, Step num: 1280, Learning rate: 0.00089443, Avg batch loss: 0.5691, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1281, Step num: 1281, Learning rate: 0.00089513, Avg batch loss: 0.5438, Avg batch acc: 0.4204
Train, Epoch: 1, Batch: 1282, Step num: 1282, Learning rate: 0.00089582, Avg batch loss: 0.5166, Avg batch acc: 0.4192
Train, Epoch: 1, Batch: 1283, Step num: 1283, Learning rate: 0.00089652, Avg batch loss: 0.4858, Avg batch acc: 0.4370
Train, Epoch: 1, Batch: 1284, Step num: 1284, Learning rate: 0.00089722, Avg batch loss: 0.5534, Avg batch acc: 0.4165
Train, Epoch: 1, Batch: 1285, Step num: 1285, Learning rate: 0.00089792, Avg batch loss: 0.5211, Avg batch acc: 0.4257
Train, Epoch: 1, Batch: 1286, Step num: 1286, Learning rate: 0.00089862, Avg batch loss: 0.5299, Avg batch acc: 0.4209
Train, Epoch: 1, Batch: 1287, Step num: 1287, Learning rate: 0.00089932, Avg batch loss: 0.5695, Avg batch acc: 0.4301
Train, Epoch: 1, Batch: 1288, Step num: 1288, Learning rate: 0.00090002, Avg batch loss: 0.5047, Avg batch acc: 0.4483
Train, Epoch: 1, Batch: 1289, Step num: 1289, Learning rate: 0.00090072, Avg batch loss: 0.5334, Avg batch acc: 0.4429
Train, Epoch: 1, Batch: 1290, Step num: 1290, Learning rate: 0.00090141, Avg batch loss: 0.5596, Avg batch acc: 0.4162
Train, Epoch: 1, Batch: 1291, Step num: 1291, Learning rate: 0.00090211, Avg batch loss: 0.5907, Avg batch acc: 0.4110
Train, Epoch: 1, Batch: 1292, Step num: 1292, Learning rate: 0.00090281, Avg batch loss: 0.4924, Avg batch acc: 0.4404
Train, Epoch: 1, Batch: 1293, Step num: 1293, Learning rate: 0.00090351, Avg batch loss: 0.5455, Avg batch acc: 0.4302
Train, Epoch: 1, Batch: 1294, Step num: 1294, Learning rate: 0.00090421, Avg batch loss: 0.5091, Avg batch acc: 0.4288
Train, Epoch: 1, Batch: 1295, Step num: 1295, Learning rate: 0.00090491, Avg batch loss: 0.5244, Avg batch acc: 0.4348
Train, Epoch: 1, Batch: 1296, Step num: 1296, Learning rate: 0.00090561, Avg batch loss: 0.5278, Avg batch acc: 0.4490
Train, Epoch: 1, Batch: 1297, Step num: 1297, Learning rate: 0.00090631, Avg batch loss: 0.4827, Avg batch acc: 0.4463
Train, Epoch: 1, Batch: 1298, Step num: 1298, Learning rate: 0.00090701, Avg batch loss: 0.5024, Avg batch acc: 0.4477
Train, Epoch: 1, Batch: 1299, Step num: 1299, Learning rate: 0.00090770, Avg batch loss: 0.5862, Avg batch acc: 0.4218
Train, Epoch: 1, Batch: 1300, Step num: 1300, Learning rate: 0.00090840, Avg batch loss: 0.5449, Avg batch acc: 0.4314
Train, Epoch: 1, Batch: 1301, Step num: 1301, Learning rate: 0.00090910, Avg batch loss: 0.5857, Avg batch acc: 0.4237
Train, Epoch: 1, Batch: 1302, Step num: 1302, Learning rate: 0.00090980, Avg batch loss: 0.5222, Avg batch acc: 0.4296
Train, Epoch: 1, Batch: 1303, Step num: 1303, Learning rate: 0.00091050, Avg batch loss: 0.5357, Avg batch acc: 0.4355
Train, Epoch: 1, Batch: 1304, Step num: 1304, Learning rate: 0.00091120, Avg batch loss: 0.5886, Avg batch acc: 0.4139
Train, Epoch: 1, Batch: 1305, Step num: 1305, Learning rate: 0.00091190, Avg batch loss: 0.5275, Avg batch acc: 0.4378
Train, Epoch: 1, Batch: 1306, Step num: 1306, Learning rate: 0.00091260, Avg batch loss: 0.5796, Avg batch acc: 0.4184
Train, Epoch: 1, Batch: 1307, Step num: 1307, Learning rate: 0.00091329, Avg batch loss: 0.5037, Avg batch acc: 0.4414
Train, Epoch: 1, Batch: 1308, Step num: 1308, Learning rate: 0.00091399, Avg batch loss: 0.5230, Avg batch acc: 0.4360
Train, Epoch: 1, Batch: 1309, Step num: 1309, Learning rate: 0.00091469, Avg batch loss: 0.4710, Avg batch acc: 0.4372
Train, Epoch: 1, Batch: 1310, Step num: 1310, Learning rate: 0.00091539, Avg batch loss: 0.5086, Avg batch acc: 0.4604
Train, Epoch: 1, Batch: 1311, Step num: 1311, Learning rate: 0.00091609, Avg batch loss: 0.4836, Avg batch acc: 0.4268
Train, Epoch: 1, Batch: 1312, Step num: 1312, Learning rate: 0.00091679, Avg batch loss: 0.5527, Avg batch acc: 0.4259
Train, Epoch: 1, Batch: 1313, Step num: 1313, Learning rate: 0.00091749, Avg batch loss: 0.5844, Avg batch acc: 0.3991
Train, Epoch: 1, Batch: 1314, Step num: 1314, Learning rate: 0.00091819, Avg batch loss: 0.5017, Avg batch acc: 0.4436
Train, Epoch: 1, Batch: 1315, Step num: 1315, Learning rate: 0.00091888, Avg batch loss: 0.5659, Avg batch acc: 0.4371
Train, Epoch: 1, Batch: 1316, Step num: 1316, Learning rate: 0.00091958, Avg batch loss: 0.5026, Avg batch acc: 0.4524
Train, Epoch: 1, Batch: 1317, Step num: 1317, Learning rate: 0.00092028, Avg batch loss: 0.4758, Avg batch acc: 0.4259
Train, Epoch: 1, Batch: 1318, Step num: 1318, Learning rate: 0.00092098, Avg batch loss: 0.5610, Avg batch acc: 0.4095
Train, Epoch: 1, Batch: 1319, Step num: 1319, Learning rate: 0.00092168, Avg batch loss: 0.5374, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1320, Step num: 1320, Learning rate: 0.00092238, Avg batch loss: 0.5391, Avg batch acc: 0.4464
Train, Epoch: 1, Batch: 1321, Step num: 1321, Learning rate: 0.00092308, Avg batch loss: 0.5256, Avg batch acc: 0.4116
Train, Epoch: 1, Batch: 1322, Step num: 1322, Learning rate: 0.00092378, Avg batch loss: 0.4988, Avg batch acc: 0.4121
Train, Epoch: 1, Batch: 1323, Step num: 1323, Learning rate: 0.00092447, Avg batch loss: 0.5618, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 1324, Step num: 1324, Learning rate: 0.00092517, Avg batch loss: 0.4662, Avg batch acc: 0.4478
Train, Epoch: 1, Batch: 1325, Step num: 1325, Learning rate: 0.00092587, Avg batch loss: 0.5332, Avg batch acc: 0.4358
Train, Epoch: 1, Batch: 1326, Step num: 1326, Learning rate: 0.00092657, Avg batch loss: 0.5338, Avg batch acc: 0.4249
Train, Epoch: 1, Batch: 1327, Step num: 1327, Learning rate: 0.00092727, Avg batch loss: 0.5248, Avg batch acc: 0.4447
Train, Epoch: 1, Batch: 1328, Step num: 1328, Learning rate: 0.00092797, Avg batch loss: 0.5444, Avg batch acc: 0.4388
Train, Epoch: 1, Batch: 1329, Step num: 1329, Learning rate: 0.00092867, Avg batch loss: 0.5221, Avg batch acc: 0.4282
Train, Epoch: 1, Batch: 1330, Step num: 1330, Learning rate: 0.00092937, Avg batch loss: 0.5761, Avg batch acc: 0.4257
Train, Epoch: 1, Batch: 1331, Step num: 1331, Learning rate: 0.00093006, Avg batch loss: 0.5424, Avg batch acc: 0.4115
Train, Epoch: 1, Batch: 1332, Step num: 1332, Learning rate: 0.00093076, Avg batch loss: 0.5891, Avg batch acc: 0.4285
Train, Epoch: 1, Batch: 1333, Step num: 1333, Learning rate: 0.00093146, Avg batch loss: 0.5278, Avg batch acc: 0.4205
Train, Epoch: 1, Batch: 1334, Step num: 1334, Learning rate: 0.00093216, Avg batch loss: 0.4724, Avg batch acc: 0.4506
Train, Epoch: 1, Batch: 1335, Step num: 1335, Learning rate: 0.00093286, Avg batch loss: 0.5636, Avg batch acc: 0.4180
Train, Epoch: 1, Batch: 1336, Step num: 1336, Learning rate: 0.00093356, Avg batch loss: 0.6082, Avg batch acc: 0.4108
Train, Epoch: 1, Batch: 1337, Step num: 1337, Learning rate: 0.00093426, Avg batch loss: 0.5404, Avg batch acc: 0.4154
Train, Epoch: 1, Batch: 1338, Step num: 1338, Learning rate: 0.00093496, Avg batch loss: 0.5726, Avg batch acc: 0.4019
Train, Epoch: 1, Batch: 1339, Step num: 1339, Learning rate: 0.00093565, Avg batch loss: 0.4962, Avg batch acc: 0.4443
Train, Epoch: 1, Batch: 1340, Step num: 1340, Learning rate: 0.00093635, Avg batch loss: 0.5177, Avg batch acc: 0.4241
Train, Epoch: 1, Batch: 1341, Step num: 1341, Learning rate: 0.00093705, Avg batch loss: 0.5396, Avg batch acc: 0.4253
Train, Epoch: 1, Batch: 1342, Step num: 1342, Learning rate: 0.00093775, Avg batch loss: 0.5399, Avg batch acc: 0.4196
Train, Epoch: 1, Batch: 1343, Step num: 1343, Learning rate: 0.00093845, Avg batch loss: 0.5253, Avg batch acc: 0.4415
Train, Epoch: 1, Batch: 1344, Step num: 1344, Learning rate: 0.00093915, Avg batch loss: 0.6628, Avg batch acc: 0.4024
Train, Epoch: 1, Batch: 1345, Step num: 1345, Learning rate: 0.00093985, Avg batch loss: 0.5464, Avg batch acc: 0.4330
Train, Epoch: 1, Batch: 1346, Step num: 1346, Learning rate: 0.00094055, Avg batch loss: 0.5441, Avg batch acc: 0.4317
Train, Epoch: 1, Batch: 1347, Step num: 1347, Learning rate: 0.00094124, Avg batch loss: 0.5328, Avg batch acc: 0.4287
Train, Epoch: 1, Batch: 1348, Step num: 1348, Learning rate: 0.00094194, Avg batch loss: 0.5284, Avg batch acc: 0.4578
Train, Epoch: 1, Batch: 1349, Step num: 1349, Learning rate: 0.00094264, Avg batch loss: 0.5298, Avg batch acc: 0.4185
Train, Epoch: 1, Batch: 1350, Step num: 1350, Learning rate: 0.00094334, Avg batch loss: 0.6067, Avg batch acc: 0.4114
Train, Epoch: 1, Batch: 1351, Step num: 1351, Learning rate: 0.00094404, Avg batch loss: 0.5445, Avg batch acc: 0.4548
Train, Epoch: 1, Batch: 1352, Step num: 1352, Learning rate: 0.00094474, Avg batch loss: 0.6140, Avg batch acc: 0.4102
Train, Epoch: 1, Batch: 1353, Step num: 1353, Learning rate: 0.00094544, Avg batch loss: 0.5522, Avg batch acc: 0.4284
Train, Epoch: 1, Batch: 1354, Step num: 1354, Learning rate: 0.00094614, Avg batch loss: 0.5096, Avg batch acc: 0.4338
Train, Epoch: 1, Batch: 1355, Step num: 1355, Learning rate: 0.00094684, Avg batch loss: 0.5507, Avg batch acc: 0.4330
Train, Epoch: 1, Batch: 1356, Step num: 1356, Learning rate: 0.00094753, Avg batch loss: 0.5734, Avg batch acc: 0.4094
Train, Epoch: 1, Batch: 1357, Step num: 1357, Learning rate: 0.00094823, Avg batch loss: 0.5104, Avg batch acc: 0.4138
Train, Epoch: 1, Batch: 1358, Step num: 1358, Learning rate: 0.00094893, Avg batch loss: 0.5450, Avg batch acc: 0.4336
Train, Epoch: 1, Batch: 1359, Step num: 1359, Learning rate: 0.00094963, Avg batch loss: 0.5099, Avg batch acc: 0.4237
Train, Epoch: 1, Batch: 1360, Step num: 1360, Learning rate: 0.00095033, Avg batch loss: 0.5910, Avg batch acc: 0.4202
Train, Epoch: 1, Batch: 1361, Step num: 1361, Learning rate: 0.00095103, Avg batch loss: 0.5664, Avg batch acc: 0.4242
Train, Epoch: 1, Batch: 1362, Step num: 1362, Learning rate: 0.00095173, Avg batch loss: 0.5737, Avg batch acc: 0.4121
Train, Epoch: 1, Batch: 1363, Step num: 1363, Learning rate: 0.00095243, Avg batch loss: 0.5769, Avg batch acc: 0.4231
Train, Epoch: 1, Batch: 1364, Step num: 1364, Learning rate: 0.00095312, Avg batch loss: 0.5749, Avg batch acc: 0.4143
Train, Epoch: 1, Batch: 1365, Step num: 1365, Learning rate: 0.00095382, Avg batch loss: 0.4981, Avg batch acc: 0.4286
Train, Epoch: 1, Batch: 1366, Step num: 1366, Learning rate: 0.00095452, Avg batch loss: 0.4831, Avg batch acc: 0.4407
Train, Epoch: 1, Batch: 1367, Step num: 1367, Learning rate: 0.00095522, Avg batch loss: 0.6464, Avg batch acc: 0.4141
Train, Epoch: 1, Batch: 1368, Step num: 1368, Learning rate: 0.00095592, Avg batch loss: 0.5517, Avg batch acc: 0.4209
Train, Epoch: 1, Batch: 1369, Step num: 1369, Learning rate: 0.00095662, Avg batch loss: 0.5370, Avg batch acc: 0.4386
Train, Epoch: 1, Batch: 1370, Step num: 1370, Learning rate: 0.00095732, Avg batch loss: 0.5114, Avg batch acc: 0.4551
Train, Epoch: 1, Batch: 1371, Step num: 1371, Learning rate: 0.00095802, Avg batch loss: 0.4649, Avg batch acc: 0.4292
Train, Epoch: 1, Batch: 1372, Step num: 1372, Learning rate: 0.00095871, Avg batch loss: 0.5252, Avg batch acc: 0.4330
Train, Epoch: 1, Batch: 1373, Step num: 1373, Learning rate: 0.00095941, Avg batch loss: 0.5431, Avg batch acc: 0.4278
Train, Epoch: 1, Batch: 1374, Step num: 1374, Learning rate: 0.00096011, Avg batch loss: 0.5033, Avg batch acc: 0.4221
Train, Epoch: 1, Batch: 1375, Step num: 1375, Learning rate: 0.00096081, Avg batch loss: 0.4956, Avg batch acc: 0.4503
Train, Epoch: 1, Batch: 1376, Step num: 1376, Learning rate: 0.00096151, Avg batch loss: 0.4731, Avg batch acc: 0.4484
Train, Epoch: 1, Batch: 1377, Step num: 1377, Learning rate: 0.00096221, Avg batch loss: 0.5433, Avg batch acc: 0.4069
Train, Epoch: 1, Batch: 1378, Step num: 1378, Learning rate: 0.00096291, Avg batch loss: 0.5346, Avg batch acc: 0.4241
Train, Epoch: 1, Batch: 1379, Step num: 1379, Learning rate: 0.00096361, Avg batch loss: 0.5137, Avg batch acc: 0.4329
Train, Epoch: 1, Batch: 1380, Step num: 1380, Learning rate: 0.00096430, Avg batch loss: 0.5186, Avg batch acc: 0.4476
Train, Epoch: 1, Batch: 1381, Step num: 1381, Learning rate: 0.00096500, Avg batch loss: 0.5703, Avg batch acc: 0.4119
Train, Epoch: 1, Batch: 1382, Step num: 1382, Learning rate: 0.00096570, Avg batch loss: 0.5650, Avg batch acc: 0.4098
Train, Epoch: 1, Batch: 1383, Step num: 1383, Learning rate: 0.00096640, Avg batch loss: 0.5221, Avg batch acc: 0.4207
Train, Epoch: 1, Batch: 1384, Step num: 1384, Learning rate: 0.00096710, Avg batch loss: 0.5534, Avg batch acc: 0.4444
Train, Epoch: 1, Batch: 1385, Step num: 1385, Learning rate: 0.00096780, Avg batch loss: 0.5245, Avg batch acc: 0.4094
Train, Epoch: 1, Batch: 1386, Step num: 1386, Learning rate: 0.00096850, Avg batch loss: 0.5152, Avg batch acc: 0.4376
Train, Epoch: 1, Batch: 1387, Step num: 1387, Learning rate: 0.00096920, Avg batch loss: 0.5228, Avg batch acc: 0.4294
Train, Epoch: 1, Batch: 1388, Step num: 1388, Learning rate: 0.00096989, Avg batch loss: 0.5183, Avg batch acc: 0.4308
Train, Epoch: 1, Batch: 1389, Step num: 1389, Learning rate: 0.00097059, Avg batch loss: 0.5239, Avg batch acc: 0.4336
Train, Epoch: 1, Batch: 1390, Step num: 1390, Learning rate: 0.00097129, Avg batch loss: 0.5354, Avg batch acc: 0.4245
Train, Epoch: 1, Batch: 1391, Step num: 1391, Learning rate: 0.00097199, Avg batch loss: 0.5447, Avg batch acc: 0.4345
Train, Epoch: 1, Batch: 1392, Step num: 1392, Learning rate: 0.00097269, Avg batch loss: 0.5352, Avg batch acc: 0.4224
Train, Epoch: 1, Batch: 1393, Step num: 1393, Learning rate: 0.00097339, Avg batch loss: 0.5262, Avg batch acc: 0.4341
Train, Epoch: 1, Batch: 1394, Step num: 1394, Learning rate: 0.00097409, Avg batch loss: 0.5996, Avg batch acc: 0.4166
Train, Epoch: 1, Batch: 1395, Step num: 1395, Learning rate: 0.00097479, Avg batch loss: 0.5459, Avg batch acc: 0.4405
Train, Epoch: 1, Batch: 1396, Step num: 1396, Learning rate: 0.00097548, Avg batch loss: 0.5655, Avg batch acc: 0.4220
Train, Epoch: 1, Batch: 1397, Step num: 1397, Learning rate: 0.00097618, Avg batch loss: 0.5251, Avg batch acc: 0.4299
Train, Epoch: 1, Batch: 1398, Step num: 1398, Learning rate: 0.00097688, Avg batch loss: 0.5328, Avg batch acc: 0.4209
Train, Epoch: 1, Batch: 1399, Step num: 1399, Learning rate: 0.00097758, Avg batch loss: 0.5045, Avg batch acc: 0.4285
Train, Epoch: 1, Batch: 1400, Step num: 1400, Learning rate: 0.00097828, Avg batch loss: 0.5277, Avg batch acc: 0.4260
Train, Epoch: 1, Batch: 1401, Step num: 1401, Learning rate: 0.00097898, Avg batch loss: 0.5270, Avg batch acc: 0.4423
Train, Epoch: 1, Batch: 1402, Step num: 1402, Learning rate: 0.00097968, Avg batch loss: 0.5625, Avg batch acc: 0.4152
Train, Epoch: 1, Batch: 1403, Step num: 1403, Learning rate: 0.00098038, Avg batch loss: 0.6008, Avg batch acc: 0.4031
Train, Epoch: 1, Batch: 1404, Step num: 1404, Learning rate: 0.00098107, Avg batch loss: 0.5161, Avg batch acc: 0.4237
Train, Epoch: 1, Batch: 1405, Step num: 1405, Learning rate: 0.00098177, Avg batch loss: 0.5074, Avg batch acc: 0.4473
Train, Epoch: 1, Batch: 1406, Step num: 1406, Learning rate: 0.00098247, Avg batch loss: 0.5735, Avg batch acc: 0.4202
Train, Epoch: 1, Batch: 1407, Step num: 1407, Learning rate: 0.00098317, Avg batch loss: 0.5233, Avg batch acc: 0.4317
Train, Epoch: 1, Batch: 1408, Step num: 1408, Learning rate: 0.00098387, Avg batch loss: 0.4897, Avg batch acc: 0.4412
Train, Epoch: 1, Batch: 1409, Step num: 1409, Learning rate: 0.00098457, Avg batch loss: 0.4818, Avg batch acc: 0.4448
Train, Epoch: 1, Batch: 1410, Step num: 1410, Learning rate: 0.00098527, Avg batch loss: 0.5129, Avg batch acc: 0.4254
Train, Epoch: 1, Batch: 1411, Step num: 1411, Learning rate: 0.00098597, Avg batch loss: 0.5555, Avg batch acc: 0.4320
Train, Epoch: 1, Batch: 1412, Step num: 1412, Learning rate: 0.00098666, Avg batch loss: 0.5098, Avg batch acc: 0.4222
Train, Epoch: 1, Batch: 1413, Step num: 1413, Learning rate: 0.00098736, Avg batch loss: 0.5058, Avg batch acc: 0.4210
Train, Epoch: 1, Batch: 1414, Step num: 1414, Learning rate: 0.00098806, Avg batch loss: 0.5228, Avg batch acc: 0.4352
Train, Epoch: 1, Batch: 1415, Step num: 1415, Learning rate: 0.00098876, Avg batch loss: 0.5374, Avg batch acc: 0.4253
Train, Epoch: 1, Batch: 1416, Step num: 1416, Learning rate: 0.00098946, Avg batch loss: 0.5499, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1417, Step num: 1417, Learning rate: 0.00099016, Avg batch loss: 0.5686, Avg batch acc: 0.4154
Train, Epoch: 1, Batch: 1418, Step num: 1418, Learning rate: 0.00099086, Avg batch loss: 0.5340, Avg batch acc: 0.4419
Train, Epoch: 1, Batch: 1419, Step num: 1419, Learning rate: 0.00099156, Avg batch loss: 0.5215, Avg batch acc: 0.4398
Train, Epoch: 1, Batch: 1420, Step num: 1420, Learning rate: 0.00099226, Avg batch loss: 0.5150, Avg batch acc: 0.4441
Train, Epoch: 1, Batch: 1421, Step num: 1421, Learning rate: 0.00099295, Avg batch loss: 0.4901, Avg batch acc: 0.4369
Train, Epoch: 1, Batch: 1422, Step num: 1422, Learning rate: 0.00099365, Avg batch loss: 0.5526, Avg batch acc: 0.4244
Train, Epoch: 1, Batch: 1423, Step num: 1423, Learning rate: 0.00099435, Avg batch loss: 0.5573, Avg batch acc: 0.4294
Train, Epoch: 1, Batch: 1424, Step num: 1424, Learning rate: 0.00099505, Avg batch loss: 0.5327, Avg batch acc: 0.4395
Train, Epoch: 1, Batch: 1425, Step num: 1425, Learning rate: 0.00099575, Avg batch loss: 0.5337, Avg batch acc: 0.4371
Train, Epoch: 1, Batch: 1426, Step num: 1426, Learning rate: 0.00099645, Avg batch loss: 0.5242, Avg batch acc: 0.4280
Train, Epoch: 1, Batch: 1427, Step num: 1427, Learning rate: 0.00099715, Avg batch loss: 0.5395, Avg batch acc: 0.4332
Train, Epoch: 1, Batch: 1428, Step num: 1428, Learning rate: 0.00099785, Avg batch loss: 0.5246, Avg batch acc: 0.4622
Train, Epoch: 1, Batch: 1429, Step num: 1429, Learning rate: 0.00099854, Avg batch loss: 0.5617, Avg batch acc: 0.4442
Train, Epoch: 1, Batch: 1430, Step num: 1430, Learning rate: 0.00099924, Avg batch loss: 0.5487, Avg batch acc: 0.4191
Train, Epoch: 1, Batch: 1431, Step num: 1431, Learning rate: 0.00099994, Avg batch loss: 0.5010, Avg batch acc: 0.4444
Train, Epoch: 1, Batch: 1432, Step num: 1432, Learning rate: 0.00100064, Avg batch loss: 0.5450, Avg batch acc: 0.4408
Train, Epoch: 1, Batch: 1433, Step num: 1433, Learning rate: 0.00100134, Avg batch loss: 0.5585, Avg batch acc: 0.4241
Train, Epoch: 1, Batch: 1434, Step num: 1434, Learning rate: 0.00100204, Avg batch loss: 0.5170, Avg batch acc: 0.4124
Train, Epoch: 1, Batch: 1435, Step num: 1435, Learning rate: 0.00100274, Avg batch loss: 0.4880, Avg batch acc: 0.4435
Train, Epoch: 1, Batch: 1436, Step num: 1436, Learning rate: 0.00100344, Avg batch loss: 0.5288, Avg batch acc: 0.4352
Train, Epoch: 1, Batch: 1437, Step num: 1437, Learning rate: 0.00100413, Avg batch loss: 0.5084, Avg batch acc: 0.4194
Train, Epoch: 1, Batch: 1438, Step num: 1438, Learning rate: 0.00100483, Avg batch loss: 0.5832, Avg batch acc: 0.4018
Train, Epoch: 1, Batch: 1439, Step num: 1439, Learning rate: 0.00100553, Avg batch loss: 0.5103, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1440, Step num: 1440, Learning rate: 0.00100623, Avg batch loss: 0.4735, Avg batch acc: 0.4288
Train, Epoch: 1, Batch: 1441, Step num: 1441, Learning rate: 0.00100693, Avg batch loss: 0.5418, Avg batch acc: 0.4333
Train, Epoch: 1, Batch: 1442, Step num: 1442, Learning rate: 0.00100763, Avg batch loss: 0.5175, Avg batch acc: 0.4283
Train, Epoch: 1, Batch: 1443, Step num: 1443, Learning rate: 0.00100833, Avg batch loss: 0.6147, Avg batch acc: 0.3930
Train, Epoch: 1, Batch: 1444, Step num: 1444, Learning rate: 0.00100903, Avg batch loss: 0.5316, Avg batch acc: 0.4418
Train, Epoch: 1, Batch: 1445, Step num: 1445, Learning rate: 0.00100972, Avg batch loss: 0.5981, Avg batch acc: 0.4308
Train, Epoch: 1, Batch: 1446, Step num: 1446, Learning rate: 0.00101042, Avg batch loss: 0.5261, Avg batch acc: 0.4204
Train, Epoch: 1, Batch: 1447, Step num: 1447, Learning rate: 0.00101112, Avg batch loss: 0.4969, Avg batch acc: 0.4345
Train, Epoch: 1, Batch: 1448, Step num: 1448, Learning rate: 0.00101182, Avg batch loss: 0.5597, Avg batch acc: 0.4374
Train, Epoch: 1, Batch: 1449, Step num: 1449, Learning rate: 0.00101252, Avg batch loss: 0.5391, Avg batch acc: 0.4382
Train, Epoch: 1, Batch: 1450, Step num: 1450, Learning rate: 0.00101322, Avg batch loss: 0.5293, Avg batch acc: 0.4188
Train, Epoch: 1, Batch: 1451, Step num: 1451, Learning rate: 0.00101392, Avg batch loss: 0.5726, Avg batch acc: 0.4043
Train, Epoch: 1, Batch: 1452, Step num: 1452, Learning rate: 0.00101462, Avg batch loss: 0.5158, Avg batch acc: 0.4402
Train, Epoch: 1, Batch: 1453, Step num: 1453, Learning rate: 0.00101531, Avg batch loss: 0.4740, Avg batch acc: 0.4529
Train, Epoch: 1, Batch: 1454, Step num: 1454, Learning rate: 0.00101601, Avg batch loss: 0.5229, Avg batch acc: 0.4398
Train, Epoch: 1, Batch: 1455, Step num: 1455, Learning rate: 0.00101671, Avg batch loss: 0.5306, Avg batch acc: 0.4321
Train, Epoch: 1, Batch: 1456, Step num: 1456, Learning rate: 0.00101741, Avg batch loss: 0.4793, Avg batch acc: 0.4588
Train, Epoch: 1, Batch: 1457, Step num: 1457, Learning rate: 0.00101811, Avg batch loss: 0.5082, Avg batch acc: 0.4475
Train, Epoch: 1, Batch: 1458, Step num: 1458, Learning rate: 0.00101881, Avg batch loss: 0.5385, Avg batch acc: 0.4197
Train, Epoch: 1, Batch: 1459, Step num: 1459, Learning rate: 0.00101951, Avg batch loss: 0.5252, Avg batch acc: 0.4310
Train, Epoch: 1, Batch: 1460, Step num: 1460, Learning rate: 0.00102021, Avg batch loss: 0.4987, Avg batch acc: 0.4439
Train, Epoch: 1, Batch: 1461, Step num: 1461, Learning rate: 0.00102090, Avg batch loss: 0.4874, Avg batch acc: 0.4587
Train, Epoch: 1, Batch: 1462, Step num: 1462, Learning rate: 0.00102160, Avg batch loss: 0.5387, Avg batch acc: 0.4304
Train, Epoch: 1, Batch: 1463, Step num: 1463, Learning rate: 0.00102230, Avg batch loss: 0.5083, Avg batch acc: 0.4413
Train, Epoch: 1, Batch: 1464, Step num: 1464, Learning rate: 0.00102300, Avg batch loss: 0.6149, Avg batch acc: 0.4130
Train, Epoch: 1, Batch: 1465, Step num: 1465, Learning rate: 0.00102370, Avg batch loss: 0.6103, Avg batch acc: 0.4178
Train, Epoch: 1, Batch: 1466, Step num: 1466, Learning rate: 0.00102440, Avg batch loss: 0.4953, Avg batch acc: 0.4582
Train, Epoch: 1, Batch: 1467, Step num: 1467, Learning rate: 0.00102510, Avg batch loss: 0.5761, Avg batch acc: 0.4277
Train, Epoch: 1, Batch: 1468, Step num: 1468, Learning rate: 0.00102580, Avg batch loss: 0.5438, Avg batch acc: 0.4177
Train, Epoch: 1, Batch: 1469, Step num: 1469, Learning rate: 0.00102649, Avg batch loss: 0.5497, Avg batch acc: 0.4181
Train, Epoch: 1, Batch: 1470, Step num: 1470, Learning rate: 0.00102719, Avg batch loss: 0.5415, Avg batch acc: 0.4190
Train, Epoch: 1, Batch: 1471, Step num: 1471, Learning rate: 0.00102789, Avg batch loss: 0.5117, Avg batch acc: 0.4349
Train, Epoch: 1, Batch: 1472, Step num: 1472, Learning rate: 0.00102859, Avg batch loss: 0.5431, Avg batch acc: 0.4451
Train, Epoch: 1, Batch: 1473, Step num: 1473, Learning rate: 0.00102929, Avg batch loss: 0.4886, Avg batch acc: 0.4355
Train, Epoch: 1, Batch: 1474, Step num: 1474, Learning rate: 0.00102999, Avg batch loss: 0.4669, Avg batch acc: 0.4435
Train, Epoch: 1, Batch: 1475, Step num: 1475, Learning rate: 0.00103069, Avg batch loss: 0.5480, Avg batch acc: 0.4247
Train, Epoch: 1, Batch: 1476, Step num: 1476, Learning rate: 0.00103139, Avg batch loss: 0.5428, Avg batch acc: 0.4230
Train, Epoch: 1, Batch: 1477, Step num: 1477, Learning rate: 0.00103209, Avg batch loss: 0.5501, Avg batch acc: 0.4191
Train, Epoch: 1, Batch: 1478, Step num: 1478, Learning rate: 0.00103278, Avg batch loss: 0.5770, Avg batch acc: 0.4347
Train, Epoch: 1, Batch: 1479, Step num: 1479, Learning rate: 0.00103348, Avg batch loss: 0.5803, Avg batch acc: 0.4118
Train, Epoch: 1, Batch: 1480, Step num: 1480, Learning rate: 0.00103418, Avg batch loss: 0.5558, Avg batch acc: 0.4274
Train, Epoch: 1, Batch: 1481, Step num: 1481, Learning rate: 0.00103488, Avg batch loss: 0.4408, Avg batch acc: 0.4401
Train, Epoch: 1, Batch: 1482, Step num: 1482, Learning rate: 0.00103558, Avg batch loss: 0.5409, Avg batch acc: 0.4379
Train, Epoch: 1, Batch: 1483, Step num: 1483, Learning rate: 0.00103628, Avg batch loss: 0.5696, Avg batch acc: 0.4205
Train, Epoch: 1, Batch: 1484, Step num: 1484, Learning rate: 0.00103698, Avg batch loss: 0.4977, Avg batch acc: 0.4278
Train, Epoch: 1, Batch: 1485, Step num: 1485, Learning rate: 0.00103768, Avg batch loss: 0.5211, Avg batch acc: 0.4237
Train, Epoch: 1, Batch: 1486, Step num: 1486, Learning rate: 0.00103837, Avg batch loss: 0.4506, Avg batch acc: 0.4474
Train, Epoch: 1, Batch: 1487, Step num: 1487, Learning rate: 0.00103907, Avg batch loss: 0.4601, Avg batch acc: 0.4583
Train, Epoch: 1, Batch: 1488, Step num: 1488, Learning rate: 0.00103977, Avg batch loss: 0.5391, Avg batch acc: 0.4308
Train, Epoch: 1, Batch: 1489, Step num: 1489, Learning rate: 0.00104047, Avg batch loss: 0.5396, Avg batch acc: 0.4232
Train, Epoch: 1, Batch: 1490, Step num: 1490, Learning rate: 0.00104117, Avg batch loss: 0.5106, Avg batch acc: 0.4247
Train, Epoch: 1, Batch: 1491, Step num: 1491, Learning rate: 0.00104187, Avg batch loss: 0.4761, Avg batch acc: 0.4418
Train, Epoch: 1, Batch: 1492, Step num: 1492, Learning rate: 0.00104257, Avg batch loss: 0.5189, Avg batch acc: 0.4383
Train, Epoch: 1, Batch: 1493, Step num: 1493, Learning rate: 0.00104327, Avg batch loss: 0.5589, Avg batch acc: 0.4139
Train, Epoch: 1, Batch: 1494, Step num: 1494, Learning rate: 0.00104396, Avg batch loss: 0.5348, Avg batch acc: 0.4463
Train, Epoch: 1, Batch: 1495, Step num: 1495, Learning rate: 0.00104466, Avg batch loss: 0.5264, Avg batch acc: 0.4382
Train, Epoch: 1, Batch: 1496, Step num: 1496, Learning rate: 0.00104536, Avg batch loss: 0.5114, Avg batch acc: 0.4383
Train, Epoch: 1, Batch: 1497, Step num: 1497, Learning rate: 0.00104606, Avg batch loss: 0.5201, Avg batch acc: 0.4416
Train, Epoch: 1, Batch: 1498, Step num: 1498, Learning rate: 0.00104676, Avg batch loss: 0.5214, Avg batch acc: 0.4316
Train, Epoch: 1, Batch: 1499, Step num: 1499, Learning rate: 0.00104746, Avg batch loss: 0.4891, Avg batch acc: 0.4414
Train, Epoch: 1, Batch: 1500, Step num: 1500, Learning rate: 0.00104816, Avg batch loss: 0.5062, Avg batch acc: 0.4378
Train, Epoch: 1, Batch: 1501, Step num: 1501, Learning rate: 0.00104886, Avg batch loss: 0.5216, Avg batch acc: 0.4438
Train, Epoch: 1, Batch: 1502, Step num: 1502, Learning rate: 0.00104955, Avg batch loss: 0.5199, Avg batch acc: 0.4304
Train, Epoch: 1, Batch: 1503, Step num: 1503, Learning rate: 0.00105025, Avg batch loss: 0.5288, Avg batch acc: 0.4326
Train, Epoch: 1, Batch: 1504, Step num: 1504, Learning rate: 0.00105095, Avg batch loss: 0.4860, Avg batch acc: 0.4390
Train, Epoch: 1, Batch: 1505, Step num: 1505, Learning rate: 0.00105165, Avg batch loss: 0.5073, Avg batch acc: 0.4458
Train, Epoch: 1, Batch: 1506, Step num: 1506, Learning rate: 0.00105235, Avg batch loss: 0.5683, Avg batch acc: 0.4220
Train, Epoch: 1, Batch: 1507, Step num: 1507, Learning rate: 0.00105305, Avg batch loss: 0.5185, Avg batch acc: 0.4368
Train, Epoch: 1, Batch: 1508, Step num: 1508, Learning rate: 0.00105375, Avg batch loss: 0.5698, Avg batch acc: 0.4245
Train, Epoch: 1, Batch: 1509, Step num: 1509, Learning rate: 0.00105445, Avg batch loss: 0.5219, Avg batch acc: 0.4534
Train, Epoch: 1, Batch: 1510, Step num: 1510, Learning rate: 0.00105514, Avg batch loss: 0.4706, Avg batch acc: 0.4377
Train, Epoch: 1, Batch: 1511, Step num: 1511, Learning rate: 0.00105584, Avg batch loss: 0.4963, Avg batch acc: 0.4337
Train, Epoch: 1, Batch: 1512, Step num: 1512, Learning rate: 0.00105654, Avg batch loss: 0.4978, Avg batch acc: 0.4365
Train, Epoch: 1, Batch: 1513, Step num: 1513, Learning rate: 0.00105724, Avg batch loss: 0.5226, Avg batch acc: 0.4295
Train, Epoch: 1, Batch: 1514, Step num: 1514, Learning rate: 0.00105794, Avg batch loss: 0.4768, Avg batch acc: 0.4329
Train, Epoch: 1, Batch: 1515, Step num: 1515, Learning rate: 0.00105864, Avg batch loss: 0.5311, Avg batch acc: 0.4442
Train, Epoch: 1, Batch: 1516, Step num: 1516, Learning rate: 0.00105934, Avg batch loss: 0.5077, Avg batch acc: 0.4251
Train, Epoch: 1, Batch: 1517, Step num: 1517, Learning rate: 0.00106004, Avg batch loss: 0.5828, Avg batch acc: 0.4089
Train, Epoch: 1, Batch: 1518, Step num: 1518, Learning rate: 0.00106073, Avg batch loss: 0.5258, Avg batch acc: 0.4360
Train, Epoch: 1, Batch: 1519, Step num: 1519, Learning rate: 0.00106143, Avg batch loss: 0.5313, Avg batch acc: 0.4363
Train, Epoch: 1, Avg epoch loss: 0.7326, Avg epoch acc: 0.3484, Overall time: 419.0 s, Speed: 10388.0 tokens/s on cuda:1

Validate, Epoch: 1, Batch: 1, Avg batch loss: 0.4862, Avg batch acc: 0.4387
Validate, Epoch: 1, Batch: 2, Avg batch loss: 0.5299, Avg batch acc: 0.4395
Validate, Epoch: 1, Batch: 3, Avg batch loss: 0.5146, Avg batch acc: 0.4212
Validate, Epoch: 1, Batch: 4, Avg batch loss: 0.5559, Avg batch acc: 0.4301
Validate, Epoch: 1, Batch: 5, Avg batch loss: 0.5141, Avg batch acc: 0.4566
Validate, Epoch: 1, Batch: 6, Avg batch loss: 0.5190, Avg batch acc: 0.4502
Validate, Epoch: 1, Batch: 7, Avg batch loss: 0.5505, Avg batch acc: 0.4303
Validate, Epoch: 1, Batch: 8, Avg batch loss: 0.4585, Avg batch acc: 0.4550
Validate, Epoch: 1, Batch: 9, Avg batch loss: 0.4957, Avg batch acc: 0.4379
Validate, Epoch: 1, Batch: 10, Avg batch loss: 0.5638, Avg batch acc: 0.4210
Validate, Epoch: 1, Batch: 11, Avg batch loss: 0.5262, Avg batch acc: 0.4523
Validate, Epoch: 1, Batch: 12, Avg batch loss: 0.4411, Avg batch acc: 0.4541
Validate, Epoch: 1, Batch: 13, Avg batch loss: 0.4375, Avg batch acc: 0.4763
Validate, Epoch: 1, Batch: 14, Avg batch loss: 0.5624, Avg batch acc: 0.4247
Validate, Epoch: 1, Batch: 15, Avg batch loss: 0.5191, Avg batch acc: 0.4219
Validate, Epoch: 1, Batch: 16, Avg batch loss: 0.4976, Avg batch acc: 0.4594
Validate, Epoch: 1, Batch: 17, Avg batch loss: 0.5353, Avg batch acc: 0.4339
Validate, Epoch: 1, Batch: 18, Avg batch loss: 0.5545, Avg batch acc: 0.4268
Validate, Epoch: 1, Batch: 19, Avg batch loss: 0.4984, Avg batch acc: 0.4437
Validate, Epoch: 1, Batch: 20, Avg batch loss: 0.4679, Avg batch acc: 0.4261
Validate, Epoch: 1, Batch: 21, Avg batch loss: 0.4995, Avg batch acc: 0.4352
Validate, Epoch: 1, Batch: 22, Avg batch loss: 0.5462, Avg batch acc: 0.4318
Validate, Epoch: 1, Batch: 23, Avg batch loss: 0.5370, Avg batch acc: 0.4345
Validate, Epoch: 1, Batch: 24, Avg batch loss: 0.4817, Avg batch acc: 0.4463
Validate, Epoch: 1, Batch: 25, Avg batch loss: 0.5530, Avg batch acc: 0.4262
Validate, Epoch: 1, Batch: 26, Avg batch loss: 0.5267, Avg batch acc: 0.4379
Validate, Epoch: 1, Batch: 27, Avg batch loss: 0.5711, Avg batch acc: 0.4160
Validate, Epoch: 1, Batch: 28, Avg batch loss: 0.4787, Avg batch acc: 0.4395
Validate, Epoch: 1, Batch: 29, Avg batch loss: 0.5531, Avg batch acc: 0.4271
Validate, Epoch: 1, Batch: 30, Avg batch loss: 0.5049, Avg batch acc: 0.4110
Validate, Epoch: 1, Batch: 31, Avg batch loss: 0.5048, Avg batch acc: 0.4341
Validate, Epoch: 1, Batch: 32, Avg batch loss: 0.5210, Avg batch acc: 0.4307
Validate, Epoch: 1, Batch: 33, Avg batch loss: 0.5120, Avg batch acc: 0.4358
Validate, Epoch: 1, Batch: 34, Avg batch loss: 0.5221, Avg batch acc: 0.4496
Validate, Epoch: 1, Batch: 35, Avg batch loss: 0.4964, Avg batch acc: 0.4468
Validate, Epoch: 1, Batch: 36, Avg batch loss: 0.4998, Avg batch acc: 0.4518
Validate, Epoch: 1, Batch: 37, Avg batch loss: 0.4862, Avg batch acc: 0.4321
Validate, Epoch: 1, Batch: 38, Avg batch loss: 0.5113, Avg batch acc: 0.4321
Validate, Epoch: 1, Batch: 39, Avg batch loss: 0.5195, Avg batch acc: 0.4234
Validate, Epoch: 1, Batch: 40, Avg batch loss: 0.6167, Avg batch acc: 0.4022
Validate, Epoch: 1, Batch: 41, Avg batch loss: 0.4685, Avg batch acc: 0.4236
Validate, Epoch: 1, Batch: 42, Avg batch loss: 0.5011, Avg batch acc: 0.4252
Validate, Epoch: 1, Batch: 43, Avg batch loss: 0.5302, Avg batch acc: 0.4408
Validate, Epoch: 1, Batch: 44, Avg batch loss: 0.5763, Avg batch acc: 0.4283
Validate, Epoch: 1, Batch: 45, Avg batch loss: 0.5088, Avg batch acc: 0.4531
Validate, Epoch: 1, Batch: 46, Avg batch loss: 0.4897, Avg batch acc: 0.4362
Validate, Epoch: 1, Batch: 47, Avg batch loss: 0.5631, Avg batch acc: 0.4328
Validate, Epoch: 1, Batch: 48, Avg batch loss: 0.6038, Avg batch acc: 0.4182
Validate, Epoch: 1, Batch: 49, Avg batch loss: 0.4996, Avg batch acc: 0.4300
Validate, Epoch: 1, Batch: 50, Avg batch loss: 0.5354, Avg batch acc: 0.4155
Validate, Epoch: 1, Batch: 51, Avg batch loss: 0.5324, Avg batch acc: 0.4255
Validate, Epoch: 1, Batch: 52, Avg batch loss: 0.5100, Avg batch acc: 0.4574
Validate, Epoch: 1, Batch: 53, Avg batch loss: 0.5326, Avg batch acc: 0.4174
Validate, Epoch: 1, Batch: 54, Avg batch loss: 0.5276, Avg batch acc: 0.4340
Validate, Epoch: 1, Batch: 55, Avg batch loss: 0.5445, Avg batch acc: 0.4062
Validate, Epoch: 1, Batch: 56, Avg batch loss: 0.5191, Avg batch acc: 0.4457
Validate, Epoch: 1, Batch: 57, Avg batch loss: 0.4840, Avg batch acc: 0.4544
Validate, Epoch: 1, Batch: 58, Avg batch loss: 0.4709, Avg batch acc: 0.4589
Validate, Epoch: 1, Batch: 59, Avg batch loss: 0.5187, Avg batch acc: 0.4193
Validate, Epoch: 1, Batch: 60, Avg batch loss: 0.5022, Avg batch acc: 0.4339
Validate, Epoch: 1, Batch: 61, Avg batch loss: 0.4811, Avg batch acc: 0.4508
Validate, Epoch: 1, Batch: 62, Avg batch loss: 0.4897, Avg batch acc: 0.4238
Validate, Epoch: 1, Batch: 63, Avg batch loss: 0.5262, Avg batch acc: 0.4226
Validate, Epoch: 1, Batch: 64, Avg batch loss: 0.5489, Avg batch acc: 0.4201
Validate, Epoch: 1, Batch: 65, Avg batch loss: 0.4835, Avg batch acc: 0.4625
Validate, Epoch: 1, Batch: 66, Avg batch loss: 0.5251, Avg batch acc: 0.4543
Validate, Epoch: 1, Batch: 67, Avg batch loss: 0.4963, Avg batch acc: 0.4448
Validate, Epoch: 1, Batch: 68, Avg batch loss: 0.5148, Avg batch acc: 0.4500
Validate, Epoch: 1, Batch: 69, Avg batch loss: 0.5332, Avg batch acc: 0.4108
Validate, Epoch: 1, Batch: 70, Avg batch loss: 0.5106, Avg batch acc: 0.4377
Validate, Epoch: 1, Batch: 71, Avg batch loss: 0.4852, Avg batch acc: 0.4511
Validate, Epoch: 1, Batch: 72, Avg batch loss: 0.4500, Avg batch acc: 0.4471
Validate, Epoch: 1, Batch: 73, Avg batch loss: 0.4793, Avg batch acc: 0.4496
Validate, Epoch: 1, Batch: 74, Avg batch loss: 0.5419, Avg batch acc: 0.4191
Validate, Epoch: 1, Batch: 75, Avg batch loss: 0.4643, Avg batch acc: 0.4577
Validate, Epoch: 1, Batch: 76, Avg batch loss: 0.5062, Avg batch acc: 0.4222
Validate, Epoch: 1, Batch: 77, Avg batch loss: 0.5553, Avg batch acc: 0.4467
Validate, Epoch: 1, Batch: 78, Avg batch loss: 0.5436, Avg batch acc: 0.4236
Validate, Epoch: 1, Batch: 79, Avg batch loss: 0.5236, Avg batch acc: 0.4350
Validate, Epoch: 1, Batch: 80, Avg batch loss: 0.5964, Avg batch acc: 0.4363
Validate, Epoch: 1, Batch: 81, Avg batch loss: 0.5063, Avg batch acc: 0.4362
Validate, Epoch: 1, Batch: 82, Avg batch loss: 0.4555, Avg batch acc: 0.4318
Validate, Epoch: 1, Batch: 83, Avg batch loss: 0.5266, Avg batch acc: 0.4337
Validate, Epoch: 1, Batch: 84, Avg batch loss: 0.5302, Avg batch acc: 0.4421
Validate, Epoch: 1, Batch: 85, Avg batch loss: 0.5149, Avg batch acc: 0.4446
Validate, Epoch: 1, Batch: 86, Avg batch loss: 0.5210, Avg batch acc: 0.4335
Validate, Epoch: 1, Batch: 87, Avg batch loss: 0.5438, Avg batch acc: 0.4585
Validate, Epoch: 1, Batch: 88, Avg batch loss: 0.5453, Avg batch acc: 0.4186
Validate, Epoch: 1, Batch: 89, Avg batch loss: 0.4902, Avg batch acc: 0.4358
Validate, Epoch: 1, Batch: 90, Avg batch loss: 0.5464, Avg batch acc: 0.4356
Validate, Epoch: 1, Batch: 91, Avg batch loss: 0.5720, Avg batch acc: 0.4209
Validate, Epoch: 1, Batch: 92, Avg batch loss: 0.4946, Avg batch acc: 0.4499
Validate, Epoch: 1, Batch: 93, Avg batch loss: 0.5264, Avg batch acc: 0.4269
Validate, Epoch: 1, Batch: 94, Avg batch loss: 0.5034, Avg batch acc: 0.4258
Validate, Epoch: 1, Batch: 95, Avg batch loss: 0.5195, Avg batch acc: 0.4385
Validate, Epoch: 1, Batch: 96, Avg batch loss: 0.5252, Avg batch acc: 0.4500
Validate, Epoch: 1, Batch: 97, Avg batch loss: 0.5736, Avg batch acc: 0.4125
Validate, Epoch: 1, Batch: 98, Avg batch loss: 0.5421, Avg batch acc: 0.4170
Validate, Epoch: 1, Batch: 99, Avg batch loss: 0.5176, Avg batch acc: 0.4446
Validate, Epoch: 1, Batch: 100, Avg batch loss: 0.4376, Avg batch acc: 0.4586
Validate, Epoch: 1, Batch: 101, Avg batch loss: 0.5436, Avg batch acc: 0.4249
Validate, Epoch: 1, Batch: 102, Avg batch loss: 0.5309, Avg batch acc: 0.4333
Validate, Epoch: 1, Batch: 103, Avg batch loss: 0.5275, Avg batch acc: 0.4150
Validate, Epoch: 1, Batch: 104, Avg batch loss: 0.5680, Avg batch acc: 0.4165
Validate, Epoch: 1, Batch: 105, Avg batch loss: 0.5247, Avg batch acc: 0.4458
Validate, Epoch: 1, Batch: 106, Avg batch loss: 0.5089, Avg batch acc: 0.4427
Validate, Epoch: 1, Batch: 107, Avg batch loss: 0.5109, Avg batch acc: 0.4231
Validate, Epoch: 1, Batch: 108, Avg batch loss: 0.5239, Avg batch acc: 0.4357
Validate, Epoch: 1, Batch: 109, Avg batch loss: 0.5915, Avg batch acc: 0.4076
Validate, Epoch: 1, Batch: 110, Avg batch loss: 0.5171, Avg batch acc: 0.4217
Validate, Epoch: 1, Batch: 111, Avg batch loss: 0.5304, Avg batch acc: 0.4361
Validate, Epoch: 1, Batch: 112, Avg batch loss: 0.4531, Avg batch acc: 0.4303
Validate, Epoch: 1, Batch: 113, Avg batch loss: 0.5008, Avg batch acc: 0.4452
Validate, Epoch: 1, Batch: 114, Avg batch loss: 0.4869, Avg batch acc: 0.4467
Validate, Epoch: 1, Batch: 115, Avg batch loss: 0.5548, Avg batch acc: 0.4215
Validate, Epoch: 1, Batch: 116, Avg batch loss: 0.5178, Avg batch acc: 0.4253
Validate, Epoch: 1, Batch: 117, Avg batch loss: 0.4696, Avg batch acc: 0.4520
Validate, Epoch: 1, Batch: 118, Avg batch loss: 0.5024, Avg batch acc: 0.4354
Validate, Epoch: 1, Batch: 119, Avg batch loss: 0.5573, Avg batch acc: 0.4336
Validate, Epoch: 1, Batch: 120, Avg batch loss: 0.5679, Avg batch acc: 0.4100
Validate, Epoch: 1, Batch: 121, Avg batch loss: 0.4896, Avg batch acc: 0.4296
Validate, Epoch: 1, Batch: 122, Avg batch loss: 0.4712, Avg batch acc: 0.4277
Validate, Epoch: 1, Batch: 123, Avg batch loss: 0.5678, Avg batch acc: 0.4297
Validate, Epoch: 1, Batch: 124, Avg batch loss: 0.5492, Avg batch acc: 0.4132
Validate, Epoch: 1, Batch: 125, Avg batch loss: 0.5537, Avg batch acc: 0.4435
Validate, Epoch: 1, Batch: 126, Avg batch loss: 0.5330, Avg batch acc: 0.4266
Validate, Epoch: 1, Batch: 127, Avg batch loss: 0.5235, Avg batch acc: 0.4408
Validate, Epoch: 1, Batch: 128, Avg batch loss: 0.5210, Avg batch acc: 0.4412
Validate, Epoch: 1, Batch: 129, Avg batch loss: 0.5483, Avg batch acc: 0.4141
Validate, Epoch: 1, Batch: 130, Avg batch loss: 0.5675, Avg batch acc: 0.4287
Validate, Epoch: 1, Batch: 131, Avg batch loss: 0.5427, Avg batch acc: 0.4469
Validate, Epoch: 1, Batch: 132, Avg batch loss: 0.5567, Avg batch acc: 0.4398
Validate, Epoch: 1, Batch: 133, Avg batch loss: 0.5055, Avg batch acc: 0.4515
Validate, Epoch: 1, Batch: 134, Avg batch loss: 0.4925, Avg batch acc: 0.4529
Validate, Epoch: 1, Batch: 135, Avg batch loss: 0.5239, Avg batch acc: 0.4402
Validate, Epoch: 1, Batch: 136, Avg batch loss: 0.4532, Avg batch acc: 0.4565
Validate, Epoch: 1, Batch: 137, Avg batch loss: 0.4785, Avg batch acc: 0.4403
Validate, Epoch: 1, Batch: 138, Avg batch loss: 0.5097, Avg batch acc: 0.4351
Validate, Epoch: 1, Batch: 139, Avg batch loss: 0.5604, Avg batch acc: 0.4184
Validate, Epoch: 1, Batch: 140, Avg batch loss: 0.5403, Avg batch acc: 0.4498
Validate, Epoch: 1, Batch: 141, Avg batch loss: 0.5146, Avg batch acc: 0.4370
Validate, Epoch: 1, Batch: 142, Avg batch loss: 0.5442, Avg batch acc: 0.4381
Validate, Epoch: 1, Batch: 143, Avg batch loss: 0.5277, Avg batch acc: 0.4525
Validate, Epoch: 1, Batch: 144, Avg batch loss: 0.5639, Avg batch acc: 0.4096
Validate, Epoch: 1, Batch: 145, Avg batch loss: 0.5428, Avg batch acc: 0.4432
Validate, Epoch: 1, Batch: 146, Avg batch loss: 0.5242, Avg batch acc: 0.4263
Validate, Epoch: 1, Batch: 147, Avg batch loss: 0.5781, Avg batch acc: 0.4279
Validate, Epoch: 1, Batch: 148, Avg batch loss: 0.4947, Avg batch acc: 0.4537
Validate, Epoch: 1, Batch: 149, Avg batch loss: 0.5324, Avg batch acc: 0.4302
Validate, Epoch: 1, Batch: 150, Avg batch loss: 0.4806, Avg batch acc: 0.4563
Validate, Epoch: 1, Batch: 151, Avg batch loss: 0.5127, Avg batch acc: 0.4298
Validate, Epoch: 1, Batch: 152, Avg batch loss: 0.5447, Avg batch acc: 0.4224
Validate, Epoch: 1, Batch: 153, Avg batch loss: 0.4971, Avg batch acc: 0.4591
Validate, Epoch: 1, Batch: 154, Avg batch loss: 0.5700, Avg batch acc: 0.4374
Validate, Epoch: 1, Batch: 155, Avg batch loss: 0.4702, Avg batch acc: 0.4502
Validate, Epoch: 1, Batch: 156, Avg batch loss: 0.4807, Avg batch acc: 0.4434
Validate, Epoch: 1, Batch: 157, Avg batch loss: 0.4679, Avg batch acc: 0.4252
Validate, Epoch: 1, Batch: 158, Avg batch loss: 0.4837, Avg batch acc: 0.4459
Validate, Epoch: 1, Batch: 159, Avg batch loss: 0.5245, Avg batch acc: 0.4187
Validate, Epoch: 1, Batch: 160, Avg batch loss: 0.5256, Avg batch acc: 0.4274
Validate, Epoch: 1, Batch: 161, Avg batch loss: 0.4929, Avg batch acc: 0.4505
Validate, Epoch: 1, Batch: 162, Avg batch loss: 0.5235, Avg batch acc: 0.4464
Validate, Epoch: 1, Batch: 163, Avg batch loss: 0.5123, Avg batch acc: 0.4425
Validate, Epoch: 1, Batch: 164, Avg batch loss: 0.5138, Avg batch acc: 0.4298
Validate, Epoch: 1, Batch: 165, Avg batch loss: 0.5014, Avg batch acc: 0.4312
Validate, Epoch: 1, Batch: 166, Avg batch loss: 0.5326, Avg batch acc: 0.4085
Validate, Epoch: 1, Batch: 167, Avg batch loss: 0.4549, Avg batch acc: 0.4501
Validate, Epoch: 1, Batch: 168, Avg batch loss: 0.4993, Avg batch acc: 0.4450
Validate, Epoch: 1, Batch: 169, Avg batch loss: 0.5140, Avg batch acc: 0.4397
Validate, Epoch: 1, Avg epoch loss: 0.5186, Avg epoch acc: 0.4354, Overall time: 18.0 s, Speed: 26742.8 tokens/s on cuda:1

Train, Epoch: 2, Batch: 1, Step num: 1520, Learning rate: 0.00106213, Avg batch loss: 0.5542, Avg batch acc: 0.4210
Train, Epoch: 2, Batch: 2, Step num: 1521, Learning rate: 0.00106283, Avg batch loss: 0.5145, Avg batch acc: 0.4545
Train, Epoch: 2, Batch: 3, Step num: 1522, Learning rate: 0.00106353, Avg batch loss: 0.5968, Avg batch acc: 0.4246
Train, Epoch: 2, Batch: 4, Step num: 1523, Learning rate: 0.00106423, Avg batch loss: 0.5681, Avg batch acc: 0.4457
Train, Epoch: 2, Batch: 5, Step num: 1524, Learning rate: 0.00106493, Avg batch loss: 0.4424, Avg batch acc: 0.4504
Train, Epoch: 2, Batch: 6, Step num: 1525, Learning rate: 0.00106563, Avg batch loss: 0.5274, Avg batch acc: 0.4228
Train, Epoch: 2, Batch: 7, Step num: 1526, Learning rate: 0.00106632, Avg batch loss: 0.5235, Avg batch acc: 0.4321
Train, Epoch: 2, Batch: 8, Step num: 1527, Learning rate: 0.00106702, Avg batch loss: 0.4619, Avg batch acc: 0.4581
Train, Epoch: 2, Batch: 9, Step num: 1528, Learning rate: 0.00106772, Avg batch loss: 0.4700, Avg batch acc: 0.4462
Train, Epoch: 2, Batch: 10, Step num: 1529, Learning rate: 0.00106842, Avg batch loss: 0.4950, Avg batch acc: 0.4422
Train, Epoch: 2, Batch: 11, Step num: 1530, Learning rate: 0.00106912, Avg batch loss: 0.5241, Avg batch acc: 0.4389
Train, Epoch: 2, Batch: 12, Step num: 1531, Learning rate: 0.00106982, Avg batch loss: 0.4933, Avg batch acc: 0.4389
Train, Epoch: 2, Batch: 13, Step num: 1532, Learning rate: 0.00107052, Avg batch loss: 0.4817, Avg batch acc: 0.4487
Train, Epoch: 2, Batch: 14, Step num: 1533, Learning rate: 0.00107122, Avg batch loss: 0.5196, Avg batch acc: 0.4550
Train, Epoch: 2, Batch: 15, Step num: 1534, Learning rate: 0.00107192, Avg batch loss: 0.5246, Avg batch acc: 0.4296
Train, Epoch: 2, Batch: 16, Step num: 1535, Learning rate: 0.00107261, Avg batch loss: 0.5242, Avg batch acc: 0.4188
Train, Epoch: 2, Batch: 17, Step num: 1536, Learning rate: 0.00107331, Avg batch loss: 0.5009, Avg batch acc: 0.4517
Train, Epoch: 2, Batch: 18, Step num: 1537, Learning rate: 0.00107401, Avg batch loss: 0.5257, Avg batch acc: 0.4389
Train, Epoch: 2, Batch: 19, Step num: 1538, Learning rate: 0.00107471, Avg batch loss: 0.4908, Avg batch acc: 0.4445
Train, Epoch: 2, Batch: 20, Step num: 1539, Learning rate: 0.00107541, Avg batch loss: 0.4925, Avg batch acc: 0.4536
Train, Epoch: 2, Batch: 21, Step num: 1540, Learning rate: 0.00107611, Avg batch loss: 0.5828, Avg batch acc: 0.4495
Train, Epoch: 2, Batch: 22, Step num: 1541, Learning rate: 0.00107681, Avg batch loss: 0.4688, Avg batch acc: 0.4484
Train, Epoch: 2, Batch: 23, Step num: 1542, Learning rate: 0.00107751, Avg batch loss: 0.4981, Avg batch acc: 0.4495
Train, Epoch: 2, Batch: 24, Step num: 1543, Learning rate: 0.00107820, Avg batch loss: 0.4795, Avg batch acc: 0.4649
Train, Epoch: 2, Batch: 25, Step num: 1544, Learning rate: 0.00107890, Avg batch loss: 0.5260, Avg batch acc: 0.4443
Train, Epoch: 2, Batch: 26, Step num: 1545, Learning rate: 0.00107960, Avg batch loss: 0.5365, Avg batch acc: 0.4358
Train, Epoch: 2, Batch: 27, Step num: 1546, Learning rate: 0.00108030, Avg batch loss: 0.4987, Avg batch acc: 0.4447
Train, Epoch: 2, Batch: 28, Step num: 1547, Learning rate: 0.00108100, Avg batch loss: 0.5174, Avg batch acc: 0.4504
Train, Epoch: 2, Batch: 29, Step num: 1548, Learning rate: 0.00108170, Avg batch loss: 0.4920, Avg batch acc: 0.4458
Train, Epoch: 2, Batch: 30, Step num: 1549, Learning rate: 0.00108240, Avg batch loss: 0.5722, Avg batch acc: 0.4223
Train, Epoch: 2, Batch: 31, Step num: 1550, Learning rate: 0.00108310, Avg batch loss: 0.5422, Avg batch acc: 0.4226
Train, Epoch: 2, Batch: 32, Step num: 1551, Learning rate: 0.00108379, Avg batch loss: 0.5585, Avg batch acc: 0.4337
Train, Epoch: 2, Batch: 33, Step num: 1552, Learning rate: 0.00108449, Avg batch loss: 0.4723, Avg batch acc: 0.4638
Train, Epoch: 2, Batch: 34, Step num: 1553, Learning rate: 0.00108519, Avg batch loss: 0.5786, Avg batch acc: 0.4123
Train, Epoch: 2, Batch: 35, Step num: 1554, Learning rate: 0.00108589, Avg batch loss: 0.5431, Avg batch acc: 0.4396
Train, Epoch: 2, Batch: 36, Step num: 1555, Learning rate: 0.00108659, Avg batch loss: 0.5548, Avg batch acc: 0.4279
Train, Epoch: 2, Batch: 37, Step num: 1556, Learning rate: 0.00108729, Avg batch loss: 0.5408, Avg batch acc: 0.4539
Train, Epoch: 2, Batch: 38, Step num: 1557, Learning rate: 0.00108799, Avg batch loss: 0.5349, Avg batch acc: 0.4323
Train, Epoch: 2, Batch: 39, Step num: 1558, Learning rate: 0.00108869, Avg batch loss: 0.5426, Avg batch acc: 0.4519
Train, Epoch: 2, Batch: 40, Step num: 1559, Learning rate: 0.00108938, Avg batch loss: 0.4787, Avg batch acc: 0.4390
Train, Epoch: 2, Batch: 41, Step num: 1560, Learning rate: 0.00109008, Avg batch loss: 0.5285, Avg batch acc: 0.4385
Train, Epoch: 2, Batch: 42, Step num: 1561, Learning rate: 0.00109078, Avg batch loss: 0.4534, Avg batch acc: 0.4511
Train, Epoch: 2, Batch: 43, Step num: 1562, Learning rate: 0.00109148, Avg batch loss: 0.5043, Avg batch acc: 0.4325
Train, Epoch: 2, Batch: 44, Step num: 1563, Learning rate: 0.00109218, Avg batch loss: 0.5536, Avg batch acc: 0.4443
Train, Epoch: 2, Batch: 45, Step num: 1564, Learning rate: 0.00109288, Avg batch loss: 0.5204, Avg batch acc: 0.4376
Train, Epoch: 2, Batch: 46, Step num: 1565, Learning rate: 0.00109358, Avg batch loss: 0.5502, Avg batch acc: 0.4112
Train, Epoch: 2, Batch: 47, Step num: 1566, Learning rate: 0.00109428, Avg batch loss: 0.4831, Avg batch acc: 0.4711
Train, Epoch: 2, Batch: 48, Step num: 1567, Learning rate: 0.00109497, Avg batch loss: 0.5298, Avg batch acc: 0.4647
Train, Epoch: 2, Batch: 49, Step num: 1568, Learning rate: 0.00109567, Avg batch loss: 0.5202, Avg batch acc: 0.4393
Train, Epoch: 2, Batch: 50, Step num: 1569, Learning rate: 0.00109637, Avg batch loss: 0.4901, Avg batch acc: 0.4377
Train, Epoch: 2, Batch: 51, Step num: 1570, Learning rate: 0.00109707, Avg batch loss: 0.5494, Avg batch acc: 0.4296
Train, Epoch: 2, Batch: 52, Step num: 1571, Learning rate: 0.00109777, Avg batch loss: 0.5490, Avg batch acc: 0.4363
Train, Epoch: 2, Batch: 53, Step num: 1572, Learning rate: 0.00109847, Avg batch loss: 0.5934, Avg batch acc: 0.4291
Train, Epoch: 2, Batch: 54, Step num: 1573, Learning rate: 0.00109917, Avg batch loss: 0.5554, Avg batch acc: 0.4239
Train, Epoch: 2, Batch: 55, Step num: 1574, Learning rate: 0.00109987, Avg batch loss: 0.5430, Avg batch acc: 0.4468
Train, Epoch: 2, Batch: 56, Step num: 1575, Learning rate: 0.00110056, Avg batch loss: 0.5362, Avg batch acc: 0.4388
Train, Epoch: 2, Batch: 57, Step num: 1576, Learning rate: 0.00110126, Avg batch loss: 0.5809, Avg batch acc: 0.4350
Train, Epoch: 2, Batch: 58, Step num: 1577, Learning rate: 0.00110196, Avg batch loss: 0.4845, Avg batch acc: 0.4392
Train, Epoch: 2, Batch: 59, Step num: 1578, Learning rate: 0.00110266, Avg batch loss: 0.5113, Avg batch acc: 0.4423
Train, Epoch: 2, Batch: 60, Step num: 1579, Learning rate: 0.00110336, Avg batch loss: 0.5833, Avg batch acc: 0.4399
Train, Epoch: 2, Batch: 61, Step num: 1580, Learning rate: 0.00110406, Avg batch loss: 0.5023, Avg batch acc: 0.4272
Train, Epoch: 2, Batch: 62, Step num: 1581, Learning rate: 0.00110476, Avg batch loss: 0.4943, Avg batch acc: 0.4417
Train, Epoch: 2, Batch: 63, Step num: 1582, Learning rate: 0.00110546, Avg batch loss: 0.5200, Avg batch acc: 0.4522
Train, Epoch: 2, Batch: 64, Step num: 1583, Learning rate: 0.00110615, Avg batch loss: 0.4602, Avg batch acc: 0.4448
Train, Epoch: 2, Batch: 65, Step num: 1584, Learning rate: 0.00110685, Avg batch loss: 0.5367, Avg batch acc: 0.4330
Train, Epoch: 2, Batch: 66, Step num: 1585, Learning rate: 0.00110755, Avg batch loss: 0.4765, Avg batch acc: 0.4567
Train, Epoch: 2, Batch: 67, Step num: 1586, Learning rate: 0.00110825, Avg batch loss: 0.5910, Avg batch acc: 0.4195
Train, Epoch: 2, Batch: 68, Step num: 1587, Learning rate: 0.00110895, Avg batch loss: 0.4168, Avg batch acc: 0.4568
Train, Epoch: 2, Batch: 69, Step num: 1588, Learning rate: 0.00110965, Avg batch loss: 0.5035, Avg batch acc: 0.4361
Train, Epoch: 2, Batch: 70, Step num: 1589, Learning rate: 0.00111035, Avg batch loss: 0.4877, Avg batch acc: 0.4323
Train, Epoch: 2, Batch: 71, Step num: 1590, Learning rate: 0.00111105, Avg batch loss: 0.5256, Avg batch acc: 0.4338
Train, Epoch: 2, Batch: 72, Step num: 1591, Learning rate: 0.00111175, Avg batch loss: 0.4756, Avg batch acc: 0.4436
Train, Epoch: 2, Batch: 73, Step num: 1592, Learning rate: 0.00111244, Avg batch loss: 0.4712, Avg batch acc: 0.4531
Train, Epoch: 2, Batch: 74, Step num: 1593, Learning rate: 0.00111314, Avg batch loss: 0.5215, Avg batch acc: 0.4505
Train, Epoch: 2, Batch: 75, Step num: 1594, Learning rate: 0.00111384, Avg batch loss: 0.5154, Avg batch acc: 0.4315
Train, Epoch: 2, Batch: 76, Step num: 1595, Learning rate: 0.00111454, Avg batch loss: 0.4464, Avg batch acc: 0.4742
Train, Epoch: 2, Batch: 77, Step num: 1596, Learning rate: 0.00111524, Avg batch loss: 0.4964, Avg batch acc: 0.4513
Train, Epoch: 2, Batch: 78, Step num: 1597, Learning rate: 0.00111594, Avg batch loss: 0.4922, Avg batch acc: 0.4478
Train, Epoch: 2, Batch: 79, Step num: 1598, Learning rate: 0.00111664, Avg batch loss: 0.5267, Avg batch acc: 0.4384
Train, Epoch: 2, Batch: 80, Step num: 1599, Learning rate: 0.00111734, Avg batch loss: 0.4811, Avg batch acc: 0.4508
Train, Epoch: 2, Batch: 81, Step num: 1600, Learning rate: 0.00111803, Avg batch loss: 0.4908, Avg batch acc: 0.4450
Train, Epoch: 2, Batch: 82, Step num: 1601, Learning rate: 0.00111873, Avg batch loss: 0.5046, Avg batch acc: 0.4426
Train, Epoch: 2, Batch: 83, Step num: 1602, Learning rate: 0.00111943, Avg batch loss: 0.5510, Avg batch acc: 0.4253
Train, Epoch: 2, Batch: 84, Step num: 1603, Learning rate: 0.00112013, Avg batch loss: 0.5497, Avg batch acc: 0.4233
Train, Epoch: 2, Batch: 85, Step num: 1604, Learning rate: 0.00112083, Avg batch loss: 0.5463, Avg batch acc: 0.4167
Train, Epoch: 2, Batch: 86, Step num: 1605, Learning rate: 0.00112153, Avg batch loss: 0.5452, Avg batch acc: 0.4130
Train, Epoch: 2, Batch: 87, Step num: 1606, Learning rate: 0.00112223, Avg batch loss: 0.5120, Avg batch acc: 0.4421
Train, Epoch: 2, Batch: 88, Step num: 1607, Learning rate: 0.00112293, Avg batch loss: 0.5548, Avg batch acc: 0.4322
Train, Epoch: 2, Batch: 89, Step num: 1608, Learning rate: 0.00112362, Avg batch loss: 0.4702, Avg batch acc: 0.4574
Train, Epoch: 2, Batch: 90, Step num: 1609, Learning rate: 0.00112432, Avg batch loss: 0.5215, Avg batch acc: 0.4268
Train, Epoch: 2, Batch: 91, Step num: 1610, Learning rate: 0.00112502, Avg batch loss: 0.5063, Avg batch acc: 0.4531
Train, Epoch: 2, Batch: 92, Step num: 1611, Learning rate: 0.00112572, Avg batch loss: 0.5416, Avg batch acc: 0.4458
Train, Epoch: 2, Batch: 93, Step num: 1612, Learning rate: 0.00112642, Avg batch loss: 0.5366, Avg batch acc: 0.4418
Train, Epoch: 2, Batch: 94, Step num: 1613, Learning rate: 0.00112712, Avg batch loss: 0.4695, Avg batch acc: 0.4650
Train, Epoch: 2, Batch: 95, Step num: 1614, Learning rate: 0.00112782, Avg batch loss: 0.4653, Avg batch acc: 0.4751
Train, Epoch: 2, Batch: 96, Step num: 1615, Learning rate: 0.00112852, Avg batch loss: 0.5564, Avg batch acc: 0.4214
Train, Epoch: 2, Batch: 97, Step num: 1616, Learning rate: 0.00112921, Avg batch loss: 0.5412, Avg batch acc: 0.4307
Train, Epoch: 2, Batch: 98, Step num: 1617, Learning rate: 0.00112991, Avg batch loss: 0.5217, Avg batch acc: 0.4287
Train, Epoch: 2, Batch: 99, Step num: 1618, Learning rate: 0.00113061, Avg batch loss: 0.5571, Avg batch acc: 0.4380
Train, Epoch: 2, Batch: 100, Step num: 1619, Learning rate: 0.00113131, Avg batch loss: 0.5378, Avg batch acc: 0.4412
Train, Epoch: 2, Batch: 101, Step num: 1620, Learning rate: 0.00113201, Avg batch loss: 0.5336, Avg batch acc: 0.4379
Train, Epoch: 2, Batch: 102, Step num: 1621, Learning rate: 0.00113271, Avg batch loss: 0.5141, Avg batch acc: 0.4244
Train, Epoch: 2, Batch: 103, Step num: 1622, Learning rate: 0.00113341, Avg batch loss: 0.4937, Avg batch acc: 0.4438
Train, Epoch: 2, Batch: 104, Step num: 1623, Learning rate: 0.00113411, Avg batch loss: 0.5554, Avg batch acc: 0.4338
Train, Epoch: 2, Batch: 105, Step num: 1624, Learning rate: 0.00113480, Avg batch loss: 0.5463, Avg batch acc: 0.4393
Train, Epoch: 2, Batch: 106, Step num: 1625, Learning rate: 0.00113550, Avg batch loss: 0.4936, Avg batch acc: 0.4246
Train, Epoch: 2, Batch: 107, Step num: 1626, Learning rate: 0.00113620, Avg batch loss: 0.5069, Avg batch acc: 0.4260
Train, Epoch: 2, Batch: 108, Step num: 1627, Learning rate: 0.00113690, Avg batch loss: 0.5053, Avg batch acc: 0.4330
Train, Epoch: 2, Batch: 109, Step num: 1628, Learning rate: 0.00113760, Avg batch loss: 0.5222, Avg batch acc: 0.4414
Train, Epoch: 2, Batch: 110, Step num: 1629, Learning rate: 0.00113830, Avg batch loss: 0.5139, Avg batch acc: 0.4361
Train, Epoch: 2, Batch: 111, Step num: 1630, Learning rate: 0.00113900, Avg batch loss: 0.4866, Avg batch acc: 0.4355
Train, Epoch: 2, Batch: 112, Step num: 1631, Learning rate: 0.00113970, Avg batch loss: 0.5074, Avg batch acc: 0.4583
Train, Epoch: 2, Batch: 113, Step num: 1632, Learning rate: 0.00114039, Avg batch loss: 0.4678, Avg batch acc: 0.4552
Train, Epoch: 2, Batch: 114, Step num: 1633, Learning rate: 0.00114109, Avg batch loss: 0.4525, Avg batch acc: 0.4565
Train, Epoch: 2, Batch: 115, Step num: 1634, Learning rate: 0.00114179, Avg batch loss: 0.4838, Avg batch acc: 0.4404
Train, Epoch: 2, Batch: 116, Step num: 1635, Learning rate: 0.00114249, Avg batch loss: 0.4799, Avg batch acc: 0.4660
Train, Epoch: 2, Batch: 117, Step num: 1636, Learning rate: 0.00114319, Avg batch loss: 0.5296, Avg batch acc: 0.4568
Train, Epoch: 2, Batch: 118, Step num: 1637, Learning rate: 0.00114389, Avg batch loss: 0.5544, Avg batch acc: 0.4335
Train, Epoch: 2, Batch: 119, Step num: 1638, Learning rate: 0.00114459, Avg batch loss: 0.4620, Avg batch acc: 0.4546
Train, Epoch: 2, Batch: 120, Step num: 1639, Learning rate: 0.00114529, Avg batch loss: 0.5087, Avg batch acc: 0.4780
Train, Epoch: 2, Batch: 121, Step num: 1640, Learning rate: 0.00114598, Avg batch loss: 0.5129, Avg batch acc: 0.4220
Train, Epoch: 2, Batch: 122, Step num: 1641, Learning rate: 0.00114668, Avg batch loss: 0.5539, Avg batch acc: 0.4580
Train, Epoch: 2, Batch: 123, Step num: 1642, Learning rate: 0.00114738, Avg batch loss: 0.4960, Avg batch acc: 0.4565
Train, Epoch: 2, Batch: 124, Step num: 1643, Learning rate: 0.00114808, Avg batch loss: 0.5171, Avg batch acc: 0.4233
Train, Epoch: 2, Batch: 125, Step num: 1644, Learning rate: 0.00114878, Avg batch loss: 0.5170, Avg batch acc: 0.4443
Train, Epoch: 2, Batch: 126, Step num: 1645, Learning rate: 0.00114948, Avg batch loss: 0.4520, Avg batch acc: 0.4608
Train, Epoch: 2, Batch: 127, Step num: 1646, Learning rate: 0.00115018, Avg batch loss: 0.4946, Avg batch acc: 0.4592
Train, Epoch: 2, Batch: 128, Step num: 1647, Learning rate: 0.00115088, Avg batch loss: 0.4758, Avg batch acc: 0.4561
Train, Epoch: 2, Batch: 129, Step num: 1648, Learning rate: 0.00115158, Avg batch loss: 0.5447, Avg batch acc: 0.4556
Train, Epoch: 2, Batch: 130, Step num: 1649, Learning rate: 0.00115227, Avg batch loss: 0.4614, Avg batch acc: 0.4578
Train, Epoch: 2, Batch: 131, Step num: 1650, Learning rate: 0.00115297, Avg batch loss: 0.5082, Avg batch acc: 0.4623
Train, Epoch: 2, Batch: 132, Step num: 1651, Learning rate: 0.00115367, Avg batch loss: 0.5020, Avg batch acc: 0.4633
Train, Epoch: 2, Batch: 133, Step num: 1652, Learning rate: 0.00115437, Avg batch loss: 0.4824, Avg batch acc: 0.4458
Train, Epoch: 2, Batch: 134, Step num: 1653, Learning rate: 0.00115507, Avg batch loss: 0.5274, Avg batch acc: 0.4570
Train, Epoch: 2, Batch: 135, Step num: 1654, Learning rate: 0.00115577, Avg batch loss: 0.5366, Avg batch acc: 0.4572
Train, Epoch: 2, Batch: 136, Step num: 1655, Learning rate: 0.00115647, Avg batch loss: 0.4952, Avg batch acc: 0.4635
Train, Epoch: 2, Batch: 137, Step num: 1656, Learning rate: 0.00115717, Avg batch loss: 0.5258, Avg batch acc: 0.4172
Train, Epoch: 2, Batch: 138, Step num: 1657, Learning rate: 0.00115786, Avg batch loss: 0.5345, Avg batch acc: 0.4325
Train, Epoch: 2, Batch: 139, Step num: 1658, Learning rate: 0.00115856, Avg batch loss: 0.5162, Avg batch acc: 0.4365
Train, Epoch: 2, Batch: 140, Step num: 1659, Learning rate: 0.00115926, Avg batch loss: 0.5041, Avg batch acc: 0.4389
Train, Epoch: 2, Batch: 141, Step num: 1660, Learning rate: 0.00115996, Avg batch loss: 0.4688, Avg batch acc: 0.4589
Train, Epoch: 2, Batch: 142, Step num: 1661, Learning rate: 0.00116066, Avg batch loss: 0.5276, Avg batch acc: 0.4389
Train, Epoch: 2, Batch: 143, Step num: 1662, Learning rate: 0.00116136, Avg batch loss: 0.4842, Avg batch acc: 0.4542
Train, Epoch: 2, Batch: 144, Step num: 1663, Learning rate: 0.00116206, Avg batch loss: 0.5160, Avg batch acc: 0.4484
Train, Epoch: 2, Batch: 145, Step num: 1664, Learning rate: 0.00116276, Avg batch loss: 0.4523, Avg batch acc: 0.4547
Train, Epoch: 2, Batch: 146, Step num: 1665, Learning rate: 0.00116345, Avg batch loss: 0.5004, Avg batch acc: 0.4432
Train, Epoch: 2, Batch: 147, Step num: 1666, Learning rate: 0.00116415, Avg batch loss: 0.4981, Avg batch acc: 0.4499
Train, Epoch: 2, Batch: 148, Step num: 1667, Learning rate: 0.00116485, Avg batch loss: 0.5687, Avg batch acc: 0.4231
Train, Epoch: 2, Batch: 149, Step num: 1668, Learning rate: 0.00116555, Avg batch loss: 0.4946, Avg batch acc: 0.4407
Train, Epoch: 2, Batch: 150, Step num: 1669, Learning rate: 0.00116625, Avg batch loss: 0.5100, Avg batch acc: 0.4595
Train, Epoch: 2, Batch: 151, Step num: 1670, Learning rate: 0.00116695, Avg batch loss: 0.5601, Avg batch acc: 0.4240
Train, Epoch: 2, Batch: 152, Step num: 1671, Learning rate: 0.00116765, Avg batch loss: 0.4766, Avg batch acc: 0.4406
Train, Epoch: 2, Batch: 153, Step num: 1672, Learning rate: 0.00116835, Avg batch loss: 0.5044, Avg batch acc: 0.4555
Train, Epoch: 2, Batch: 154, Step num: 1673, Learning rate: 0.00116904, Avg batch loss: 0.4530, Avg batch acc: 0.4488
Train, Epoch: 2, Batch: 155, Step num: 1674, Learning rate: 0.00116974, Avg batch loss: 0.5068, Avg batch acc: 0.4644
Train, Epoch: 2, Batch: 156, Step num: 1675, Learning rate: 0.00117044, Avg batch loss: 0.4856, Avg batch acc: 0.4595
Train, Epoch: 2, Batch: 157, Step num: 1676, Learning rate: 0.00117114, Avg batch loss: 0.5242, Avg batch acc: 0.4255
Train, Epoch: 2, Batch: 158, Step num: 1677, Learning rate: 0.00117184, Avg batch loss: 0.5746, Avg batch acc: 0.4133
Train, Epoch: 2, Batch: 159, Step num: 1678, Learning rate: 0.00117254, Avg batch loss: 0.5189, Avg batch acc: 0.4436
Train, Epoch: 2, Batch: 160, Step num: 1679, Learning rate: 0.00117324, Avg batch loss: 0.5271, Avg batch acc: 0.4366
Train, Epoch: 2, Batch: 161, Step num: 1680, Learning rate: 0.00117394, Avg batch loss: 0.5181, Avg batch acc: 0.4279
Train, Epoch: 2, Batch: 162, Step num: 1681, Learning rate: 0.00117463, Avg batch loss: 0.4793, Avg batch acc: 0.4371
Train, Epoch: 2, Batch: 163, Step num: 1682, Learning rate: 0.00117533, Avg batch loss: 0.5503, Avg batch acc: 0.4195
Train, Epoch: 2, Batch: 164, Step num: 1683, Learning rate: 0.00117603, Avg batch loss: 0.5114, Avg batch acc: 0.4647
Train, Epoch: 2, Batch: 165, Step num: 1684, Learning rate: 0.00117673, Avg batch loss: 0.5130, Avg batch acc: 0.4470
Train, Epoch: 2, Batch: 166, Step num: 1685, Learning rate: 0.00117743, Avg batch loss: 0.5292, Avg batch acc: 0.4374
Train, Epoch: 2, Batch: 167, Step num: 1686, Learning rate: 0.00117813, Avg batch loss: 0.4414, Avg batch acc: 0.4635
Train, Epoch: 2, Batch: 168, Step num: 1687, Learning rate: 0.00117883, Avg batch loss: 0.5009, Avg batch acc: 0.4477
Train, Epoch: 2, Batch: 169, Step num: 1688, Learning rate: 0.00117953, Avg batch loss: 0.5689, Avg batch acc: 0.4386
Train, Epoch: 2, Batch: 170, Step num: 1689, Learning rate: 0.00118022, Avg batch loss: 0.4834, Avg batch acc: 0.4426
Train, Epoch: 2, Batch: 171, Step num: 1690, Learning rate: 0.00118092, Avg batch loss: 0.5260, Avg batch acc: 0.4529
Train, Epoch: 2, Batch: 172, Step num: 1691, Learning rate: 0.00118162, Avg batch loss: 0.5516, Avg batch acc: 0.4319
Train, Epoch: 2, Batch: 173, Step num: 1692, Learning rate: 0.00118232, Avg batch loss: 0.5344, Avg batch acc: 0.4661
Train, Epoch: 2, Batch: 174, Step num: 1693, Learning rate: 0.00118302, Avg batch loss: 0.4734, Avg batch acc: 0.4678
Train, Epoch: 2, Batch: 175, Step num: 1694, Learning rate: 0.00118372, Avg batch loss: 0.4746, Avg batch acc: 0.4534
Train, Epoch: 2, Batch: 176, Step num: 1695, Learning rate: 0.00118442, Avg batch loss: 0.4772, Avg batch acc: 0.4606
Train, Epoch: 2, Batch: 177, Step num: 1696, Learning rate: 0.00118512, Avg batch loss: 0.4851, Avg batch acc: 0.4447
Train, Epoch: 2, Batch: 178, Step num: 1697, Learning rate: 0.00118581, Avg batch loss: 0.5178, Avg batch acc: 0.4391
Train, Epoch: 2, Batch: 179, Step num: 1698, Learning rate: 0.00118651, Avg batch loss: 0.5039, Avg batch acc: 0.4479
Train, Epoch: 2, Batch: 180, Step num: 1699, Learning rate: 0.00118721, Avg batch loss: 0.5025, Avg batch acc: 0.4657
Train, Epoch: 2, Batch: 181, Step num: 1700, Learning rate: 0.00118791, Avg batch loss: 0.5124, Avg batch acc: 0.4564
Train, Epoch: 2, Batch: 182, Step num: 1701, Learning rate: 0.00118861, Avg batch loss: 0.4884, Avg batch acc: 0.4538
Train, Epoch: 2, Batch: 183, Step num: 1702, Learning rate: 0.00118931, Avg batch loss: 0.4643, Avg batch acc: 0.4567
Train, Epoch: 2, Batch: 184, Step num: 1703, Learning rate: 0.00119001, Avg batch loss: 0.5021, Avg batch acc: 0.4555
Train, Epoch: 2, Batch: 185, Step num: 1704, Learning rate: 0.00119071, Avg batch loss: 0.5431, Avg batch acc: 0.4438
Train, Epoch: 2, Batch: 186, Step num: 1705, Learning rate: 0.00119140, Avg batch loss: 0.4904, Avg batch acc: 0.4485
Train, Epoch: 2, Batch: 187, Step num: 1706, Learning rate: 0.00119210, Avg batch loss: 0.5020, Avg batch acc: 0.4438
Train, Epoch: 2, Batch: 188, Step num: 1707, Learning rate: 0.00119280, Avg batch loss: 0.5038, Avg batch acc: 0.4511
Train, Epoch: 2, Batch: 189, Step num: 1708, Learning rate: 0.00119350, Avg batch loss: 0.4334, Avg batch acc: 0.4736
Train, Epoch: 2, Batch: 190, Step num: 1709, Learning rate: 0.00119420, Avg batch loss: 0.4996, Avg batch acc: 0.4657
Train, Epoch: 2, Batch: 191, Step num: 1710, Learning rate: 0.00119490, Avg batch loss: 0.5581, Avg batch acc: 0.4403
Train, Epoch: 2, Batch: 192, Step num: 1711, Learning rate: 0.00119560, Avg batch loss: 0.4365, Avg batch acc: 0.4567
Train, Epoch: 2, Batch: 193, Step num: 1712, Learning rate: 0.00119630, Avg batch loss: 0.5710, Avg batch acc: 0.4534
Train, Epoch: 2, Batch: 194, Step num: 1713, Learning rate: 0.00119700, Avg batch loss: 0.5071, Avg batch acc: 0.4480
Train, Epoch: 2, Batch: 195, Step num: 1714, Learning rate: 0.00119769, Avg batch loss: 0.4952, Avg batch acc: 0.4300
Train, Epoch: 2, Batch: 196, Step num: 1715, Learning rate: 0.00119839, Avg batch loss: 0.5002, Avg batch acc: 0.4569
Train, Epoch: 2, Batch: 197, Step num: 1716, Learning rate: 0.00119909, Avg batch loss: 0.5015, Avg batch acc: 0.4377
Train, Epoch: 2, Batch: 198, Step num: 1717, Learning rate: 0.00119979, Avg batch loss: 0.5126, Avg batch acc: 0.4362
Train, Epoch: 2, Batch: 199, Step num: 1718, Learning rate: 0.00120049, Avg batch loss: 0.5104, Avg batch acc: 0.4536
Train, Epoch: 2, Batch: 200, Step num: 1719, Learning rate: 0.00120119, Avg batch loss: 0.4919, Avg batch acc: 0.4480
Train, Epoch: 2, Batch: 201, Step num: 1720, Learning rate: 0.00120189, Avg batch loss: 0.5202, Avg batch acc: 0.4580
Train, Epoch: 2, Batch: 202, Step num: 1721, Learning rate: 0.00120259, Avg batch loss: 0.4726, Avg batch acc: 0.4506
Train, Epoch: 2, Batch: 203, Step num: 1722, Learning rate: 0.00120328, Avg batch loss: 0.5174, Avg batch acc: 0.4246
Train, Epoch: 2, Batch: 204, Step num: 1723, Learning rate: 0.00120398, Avg batch loss: 0.4911, Avg batch acc: 0.4440
Train, Epoch: 2, Batch: 205, Step num: 1724, Learning rate: 0.00120468, Avg batch loss: 0.5132, Avg batch acc: 0.4464
Train, Epoch: 2, Batch: 206, Step num: 1725, Learning rate: 0.00120538, Avg batch loss: 0.4980, Avg batch acc: 0.4453
Train, Epoch: 2, Batch: 207, Step num: 1726, Learning rate: 0.00120608, Avg batch loss: 0.5144, Avg batch acc: 0.4458
Train, Epoch: 2, Batch: 208, Step num: 1727, Learning rate: 0.00120678, Avg batch loss: 0.4913, Avg batch acc: 0.4496
Train, Epoch: 2, Batch: 209, Step num: 1728, Learning rate: 0.00120748, Avg batch loss: 0.5238, Avg batch acc: 0.4689
Train, Epoch: 2, Batch: 210, Step num: 1729, Learning rate: 0.00120818, Avg batch loss: 0.5438, Avg batch acc: 0.4305
Train, Epoch: 2, Batch: 211, Step num: 1730, Learning rate: 0.00120887, Avg batch loss: 0.4774, Avg batch acc: 0.4634
Train, Epoch: 2, Batch: 212, Step num: 1731, Learning rate: 0.00120957, Avg batch loss: 0.5013, Avg batch acc: 0.4372
Train, Epoch: 2, Batch: 213, Step num: 1732, Learning rate: 0.00121027, Avg batch loss: 0.5599, Avg batch acc: 0.4166
Train, Epoch: 2, Batch: 214, Step num: 1733, Learning rate: 0.00121097, Avg batch loss: 0.5597, Avg batch acc: 0.4456
Train, Epoch: 2, Batch: 215, Step num: 1734, Learning rate: 0.00121167, Avg batch loss: 0.5639, Avg batch acc: 0.4319
Train, Epoch: 2, Batch: 216, Step num: 1735, Learning rate: 0.00121237, Avg batch loss: 0.5968, Avg batch acc: 0.4134
Train, Epoch: 2, Batch: 217, Step num: 1736, Learning rate: 0.00121307, Avg batch loss: 0.5335, Avg batch acc: 0.4408
Train, Epoch: 2, Batch: 218, Step num: 1737, Learning rate: 0.00121377, Avg batch loss: 0.5023, Avg batch acc: 0.4368
Train, Epoch: 2, Batch: 219, Step num: 1738, Learning rate: 0.00121446, Avg batch loss: 0.5230, Avg batch acc: 0.4541
Train, Epoch: 2, Batch: 220, Step num: 1739, Learning rate: 0.00121516, Avg batch loss: 0.4560, Avg batch acc: 0.4742
Train, Epoch: 2, Batch: 221, Step num: 1740, Learning rate: 0.00121586, Avg batch loss: 0.4714, Avg batch acc: 0.4334
Train, Epoch: 2, Batch: 222, Step num: 1741, Learning rate: 0.00121656, Avg batch loss: 0.5499, Avg batch acc: 0.4439
Train, Epoch: 2, Batch: 223, Step num: 1742, Learning rate: 0.00121726, Avg batch loss: 0.5350, Avg batch acc: 0.4454
Train, Epoch: 2, Batch: 224, Step num: 1743, Learning rate: 0.00121796, Avg batch loss: 0.4714, Avg batch acc: 0.4464
Train, Epoch: 2, Batch: 225, Step num: 1744, Learning rate: 0.00121866, Avg batch loss: 0.5145, Avg batch acc: 0.4515
Train, Epoch: 2, Batch: 226, Step num: 1745, Learning rate: 0.00121936, Avg batch loss: 0.4979, Avg batch acc: 0.4494
Train, Epoch: 2, Batch: 227, Step num: 1746, Learning rate: 0.00122005, Avg batch loss: 0.5435, Avg batch acc: 0.4491
Train, Epoch: 2, Batch: 228, Step num: 1747, Learning rate: 0.00122075, Avg batch loss: 0.5612, Avg batch acc: 0.4391
Train, Epoch: 2, Batch: 229, Step num: 1748, Learning rate: 0.00122145, Avg batch loss: 0.5043, Avg batch acc: 0.4342
Train, Epoch: 2, Batch: 230, Step num: 1749, Learning rate: 0.00122215, Avg batch loss: 0.4425, Avg batch acc: 0.4719
Train, Epoch: 2, Batch: 231, Step num: 1750, Learning rate: 0.00122285, Avg batch loss: 0.4937, Avg batch acc: 0.4266
Train, Epoch: 2, Batch: 232, Step num: 1751, Learning rate: 0.00122355, Avg batch loss: 0.5027, Avg batch acc: 0.4557
Train, Epoch: 2, Batch: 233, Step num: 1752, Learning rate: 0.00122425, Avg batch loss: 0.5097, Avg batch acc: 0.4729
Train, Epoch: 2, Batch: 234, Step num: 1753, Learning rate: 0.00122495, Avg batch loss: 0.5058, Avg batch acc: 0.4308
Train, Epoch: 2, Batch: 235, Step num: 1754, Learning rate: 0.00122564, Avg batch loss: 0.5036, Avg batch acc: 0.4316
Train, Epoch: 2, Batch: 236, Step num: 1755, Learning rate: 0.00122634, Avg batch loss: 0.4570, Avg batch acc: 0.4566
Train, Epoch: 2, Batch: 237, Step num: 1756, Learning rate: 0.00122704, Avg batch loss: 0.4829, Avg batch acc: 0.4452
Train, Epoch: 2, Batch: 238, Step num: 1757, Learning rate: 0.00122774, Avg batch loss: 0.5288, Avg batch acc: 0.4446
Train, Epoch: 2, Batch: 239, Step num: 1758, Learning rate: 0.00122844, Avg batch loss: 0.4655, Avg batch acc: 0.4402
Train, Epoch: 2, Batch: 240, Step num: 1759, Learning rate: 0.00122914, Avg batch loss: 0.4766, Avg batch acc: 0.4658
Train, Epoch: 2, Batch: 241, Step num: 1760, Learning rate: 0.00122984, Avg batch loss: 0.4598, Avg batch acc: 0.4658
Train, Epoch: 2, Batch: 242, Step num: 1761, Learning rate: 0.00123054, Avg batch loss: 0.5406, Avg batch acc: 0.4346
Train, Epoch: 2, Batch: 243, Step num: 1762, Learning rate: 0.00123123, Avg batch loss: 0.5107, Avg batch acc: 0.4468
Train, Epoch: 2, Batch: 244, Step num: 1763, Learning rate: 0.00123193, Avg batch loss: 0.5222, Avg batch acc: 0.4480
Train, Epoch: 2, Batch: 245, Step num: 1764, Learning rate: 0.00123263, Avg batch loss: 0.4605, Avg batch acc: 0.4518
Train, Epoch: 2, Batch: 246, Step num: 1765, Learning rate: 0.00123333, Avg batch loss: 0.5125, Avg batch acc: 0.4281
Train, Epoch: 2, Batch: 247, Step num: 1766, Learning rate: 0.00123403, Avg batch loss: 0.5206, Avg batch acc: 0.4602
Train, Epoch: 2, Batch: 248, Step num: 1767, Learning rate: 0.00123473, Avg batch loss: 0.4800, Avg batch acc: 0.4622
Train, Epoch: 2, Batch: 249, Step num: 1768, Learning rate: 0.00123543, Avg batch loss: 0.5464, Avg batch acc: 0.4614
Train, Epoch: 2, Batch: 250, Step num: 1769, Learning rate: 0.00123613, Avg batch loss: 0.5141, Avg batch acc: 0.4243
Train, Epoch: 2, Batch: 251, Step num: 1770, Learning rate: 0.00123683, Avg batch loss: 0.5508, Avg batch acc: 0.4298
Train, Epoch: 2, Batch: 252, Step num: 1771, Learning rate: 0.00123752, Avg batch loss: 0.4628, Avg batch acc: 0.4423

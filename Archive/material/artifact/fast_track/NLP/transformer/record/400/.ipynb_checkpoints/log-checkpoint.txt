Train, Epoch: 1, Batch: 1, Step num: 1, Learning rate: 0.00000070, Avg batch loss: 1.7645, Avg batch acc: 0.0012
Train, Epoch: 1, Batch: 2, Step num: 2, Learning rate: 0.00000140, Avg batch loss: 1.7777, Avg batch acc: 0.0002
Train, Epoch: 1, Batch: 3, Step num: 3, Learning rate: 0.00000210, Avg batch loss: 1.9586, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 4, Step num: 4, Learning rate: 0.00000280, Avg batch loss: 1.7328, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 5, Step num: 5, Learning rate: 0.00000349, Avg batch loss: 1.6072, Avg batch acc: 0.0005
Train, Epoch: 1, Batch: 6, Step num: 6, Learning rate: 0.00000419, Avg batch loss: 1.6057, Avg batch acc: 0.0004
Train, Epoch: 1, Batch: 7, Step num: 7, Learning rate: 0.00000489, Avg batch loss: 1.7273, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 8, Step num: 8, Learning rate: 0.00000559, Avg batch loss: 1.7805, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 9, Step num: 9, Learning rate: 0.00000629, Avg batch loss: 1.7830, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 10, Step num: 10, Learning rate: 0.00000699, Avg batch loss: 1.6389, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 11, Step num: 11, Learning rate: 0.00000769, Avg batch loss: 1.6564, Avg batch acc: 0.0000
Train, Epoch: 1, Batch: 12, Step num: 12, Learning rate: 0.00000839, Avg batch loss: 1.9023, Avg batch acc: 0.0006
Train, Epoch: 1, Batch: 13, Step num: 13, Learning rate: 0.00000908, Avg batch loss: 1.6866, Avg batch acc: 0.0010
Train, Epoch: 1, Batch: 14, Step num: 14, Learning rate: 0.00000978, Avg batch loss: 1.6573, Avg batch acc: 0.0008
Train, Epoch: 1, Batch: 15, Step num: 15, Learning rate: 0.00001048, Avg batch loss: 1.6087, Avg batch acc: 0.0015
Train, Epoch: 1, Batch: 16, Step num: 16, Learning rate: 0.00001118, Avg batch loss: 1.5894, Avg batch acc: 0.0019
Train, Epoch: 1, Batch: 17, Step num: 17, Learning rate: 0.00001188, Avg batch loss: 1.7131, Avg batch acc: 0.0018
Train, Epoch: 1, Batch: 18, Step num: 18, Learning rate: 0.00001258, Avg batch loss: 1.6714, Avg batch acc: 0.0015
Train, Epoch: 1, Batch: 19, Step num: 19, Learning rate: 0.00001328, Avg batch loss: 1.6857, Avg batch acc: 0.0024
Train, Epoch: 1, Batch: 20, Step num: 20, Learning rate: 0.00001398, Avg batch loss: 1.7123, Avg batch acc: 0.0045
Train, Epoch: 1, Batch: 21, Step num: 21, Learning rate: 0.00001467, Avg batch loss: 1.6459, Avg batch acc: 0.0074
Train, Epoch: 1, Batch: 22, Step num: 22, Learning rate: 0.00001537, Avg batch loss: 1.7571, Avg batch acc: 0.0092
Train, Epoch: 1, Batch: 23, Step num: 23, Learning rate: 0.00001607, Avg batch loss: 1.7323, Avg batch acc: 0.0174
Train, Epoch: 1, Batch: 24, Step num: 24, Learning rate: 0.00001677, Avg batch loss: 1.4995, Avg batch acc: 0.0225
Train, Epoch: 1, Batch: 25, Step num: 25, Learning rate: 0.00001747, Avg batch loss: 1.7204, Avg batch acc: 0.0278
Train, Epoch: 1, Batch: 26, Step num: 26, Learning rate: 0.00001817, Avg batch loss: 1.4600, Avg batch acc: 0.0450
Train, Epoch: 1, Batch: 27, Step num: 27, Learning rate: 0.00001887, Avg batch loss: 1.7583, Avg batch acc: 0.0449
Train, Epoch: 1, Batch: 28, Step num: 28, Learning rate: 0.00001957, Avg batch loss: 1.5908, Avg batch acc: 0.0466
Train, Epoch: 1, Batch: 29, Step num: 29, Learning rate: 0.00002026, Avg batch loss: 1.4910, Avg batch acc: 0.0582
Train, Epoch: 1, Batch: 30, Step num: 30, Learning rate: 0.00002096, Avg batch loss: 1.6878, Avg batch acc: 0.0642
Train, Epoch: 1, Batch: 31, Step num: 31, Learning rate: 0.00002166, Avg batch loss: 1.4323, Avg batch acc: 0.0597
Train, Epoch: 1, Batch: 32, Step num: 32, Learning rate: 0.00002236, Avg batch loss: 1.6069, Avg batch acc: 0.0632
Train, Epoch: 1, Batch: 33, Step num: 33, Learning rate: 0.00002306, Avg batch loss: 1.5228, Avg batch acc: 0.0662
Train, Epoch: 1, Batch: 34, Step num: 34, Learning rate: 0.00002376, Avg batch loss: 1.4835, Avg batch acc: 0.0621
Train, Epoch: 1, Batch: 35, Step num: 35, Learning rate: 0.00002446, Avg batch loss: 1.5287, Avg batch acc: 0.0622
Train, Epoch: 1, Batch: 36, Step num: 36, Learning rate: 0.00002516, Avg batch loss: 1.6179, Avg batch acc: 0.0666
Train, Epoch: 1, Batch: 37, Step num: 37, Learning rate: 0.00002585, Avg batch loss: 1.6259, Avg batch acc: 0.0657
Train, Epoch: 1, Batch: 38, Step num: 38, Learning rate: 0.00002655, Avg batch loss: 1.5751, Avg batch acc: 0.0707
Train, Epoch: 1, Batch: 39, Step num: 39, Learning rate: 0.00002725, Avg batch loss: 1.4584, Avg batch acc: 0.0732
Train, Epoch: 1, Batch: 40, Step num: 40, Learning rate: 0.00002795, Avg batch loss: 1.5369, Avg batch acc: 0.0720
Train, Epoch: 1, Batch: 41, Step num: 41, Learning rate: 0.00002865, Avg batch loss: 1.5869, Avg batch acc: 0.0683
Train, Epoch: 1, Batch: 42, Step num: 42, Learning rate: 0.00002935, Avg batch loss: 1.6070, Avg batch acc: 0.0689
Train, Epoch: 1, Batch: 43, Step num: 43, Learning rate: 0.00003005, Avg batch loss: 1.6590, Avg batch acc: 0.0673
Train, Epoch: 1, Batch: 44, Step num: 44, Learning rate: 0.00003075, Avg batch loss: 1.5449, Avg batch acc: 0.0702
Train, Epoch: 1, Batch: 45, Step num: 45, Learning rate: 0.00003144, Avg batch loss: 1.4891, Avg batch acc: 0.0720
Train, Epoch: 1, Batch: 46, Step num: 46, Learning rate: 0.00003214, Avg batch loss: 1.5621, Avg batch acc: 0.0710
Train, Epoch: 1, Batch: 47, Step num: 47, Learning rate: 0.00003284, Avg batch loss: 1.5411, Avg batch acc: 0.0729
Train, Epoch: 1, Batch: 48, Step num: 48, Learning rate: 0.00003354, Avg batch loss: 1.5848, Avg batch acc: 0.0672
Train, Epoch: 1, Batch: 49, Step num: 49, Learning rate: 0.00003424, Avg batch loss: 1.6336, Avg batch acc: 0.0695
Train, Epoch: 1, Batch: 50, Step num: 50, Learning rate: 0.00003494, Avg batch loss: 1.4880, Avg batch acc: 0.0686
Train, Epoch: 1, Batch: 51, Step num: 51, Learning rate: 0.00003564, Avg batch loss: 1.5918, Avg batch acc: 0.0718
Train, Epoch: 1, Batch: 52, Step num: 52, Learning rate: 0.00003634, Avg batch loss: 1.4974, Avg batch acc: 0.0770
Train, Epoch: 1, Batch: 53, Step num: 53, Learning rate: 0.00003703, Avg batch loss: 1.3871, Avg batch acc: 0.0744
Train, Epoch: 1, Batch: 54, Step num: 54, Learning rate: 0.00003773, Avg batch loss: 1.4835, Avg batch acc: 0.0714
Train, Epoch: 1, Batch: 55, Step num: 55, Learning rate: 0.00003843, Avg batch loss: 1.5170, Avg batch acc: 0.0773
Train, Epoch: 1, Batch: 56, Step num: 56, Learning rate: 0.00003913, Avg batch loss: 1.4855, Avg batch acc: 0.0654
Train, Epoch: 1, Batch: 57, Step num: 57, Learning rate: 0.00003983, Avg batch loss: 1.5428, Avg batch acc: 0.0795
Train, Epoch: 1, Batch: 58, Step num: 58, Learning rate: 0.00004053, Avg batch loss: 1.4287, Avg batch acc: 0.0681
Train, Epoch: 1, Batch: 59, Step num: 59, Learning rate: 0.00004123, Avg batch loss: 1.3899, Avg batch acc: 0.0741
Train, Epoch: 1, Batch: 60, Step num: 60, Learning rate: 0.00004193, Avg batch loss: 1.4758, Avg batch acc: 0.0730
Train, Epoch: 1, Batch: 61, Step num: 61, Learning rate: 0.00004263, Avg batch loss: 1.5809, Avg batch acc: 0.0716
Train, Epoch: 1, Batch: 62, Step num: 62, Learning rate: 0.00004332, Avg batch loss: 1.4198, Avg batch acc: 0.0792
Train, Epoch: 1, Batch: 63, Step num: 63, Learning rate: 0.00004402, Avg batch loss: 1.4995, Avg batch acc: 0.0806
Train, Epoch: 1, Batch: 64, Step num: 64, Learning rate: 0.00004472, Avg batch loss: 1.5385, Avg batch acc: 0.0784
Train, Epoch: 1, Batch: 65, Step num: 65, Learning rate: 0.00004542, Avg batch loss: 1.5578, Avg batch acc: 0.0804
Train, Epoch: 1, Batch: 66, Step num: 66, Learning rate: 0.00004612, Avg batch loss: 1.4826, Avg batch acc: 0.0761
Train, Epoch: 1, Batch: 67, Step num: 67, Learning rate: 0.00004682, Avg batch loss: 1.5049, Avg batch acc: 0.0749
Train, Epoch: 1, Batch: 68, Step num: 68, Learning rate: 0.00004752, Avg batch loss: 1.4174, Avg batch acc: 0.0765
Train, Epoch: 1, Batch: 69, Step num: 69, Learning rate: 0.00004822, Avg batch loss: 1.4874, Avg batch acc: 0.0747
Train, Epoch: 1, Batch: 70, Step num: 70, Learning rate: 0.00004891, Avg batch loss: 1.4807, Avg batch acc: 0.0805
Train, Epoch: 1, Batch: 71, Step num: 71, Learning rate: 0.00004961, Avg batch loss: 1.5198, Avg batch acc: 0.0855
Train, Epoch: 1, Batch: 72, Step num: 72, Learning rate: 0.00005031, Avg batch loss: 1.5055, Avg batch acc: 0.0764
Train, Epoch: 1, Batch: 73, Step num: 73, Learning rate: 0.00005101, Avg batch loss: 1.5416, Avg batch acc: 0.0817
Train, Epoch: 1, Batch: 74, Step num: 74, Learning rate: 0.00005171, Avg batch loss: 1.4065, Avg batch acc: 0.0809
Train, Epoch: 1, Batch: 75, Step num: 75, Learning rate: 0.00005241, Avg batch loss: 1.4185, Avg batch acc: 0.0877
Train, Epoch: 1, Batch: 76, Step num: 76, Learning rate: 0.00005311, Avg batch loss: 1.4950, Avg batch acc: 0.0788
Train, Epoch: 1, Batch: 77, Step num: 77, Learning rate: 0.00005381, Avg batch loss: 1.5545, Avg batch acc: 0.0795
Train, Epoch: 1, Batch: 78, Step num: 78, Learning rate: 0.00005450, Avg batch loss: 1.4067, Avg batch acc: 0.0836
Train, Epoch: 1, Batch: 79, Step num: 79, Learning rate: 0.00005520, Avg batch loss: 1.5400, Avg batch acc: 0.0957
Train, Epoch: 1, Batch: 80, Step num: 80, Learning rate: 0.00005590, Avg batch loss: 1.3895, Avg batch acc: 0.0869
Train, Epoch: 1, Batch: 81, Step num: 81, Learning rate: 0.00005660, Avg batch loss: 1.4704, Avg batch acc: 0.0798
Train, Epoch: 1, Batch: 82, Step num: 82, Learning rate: 0.00005730, Avg batch loss: 1.4086, Avg batch acc: 0.0929
Train, Epoch: 1, Batch: 83, Step num: 83, Learning rate: 0.00005800, Avg batch loss: 1.4016, Avg batch acc: 0.0888
Train, Epoch: 1, Batch: 84, Step num: 84, Learning rate: 0.00005870, Avg batch loss: 1.3786, Avg batch acc: 0.0913
Train, Epoch: 1, Batch: 85, Step num: 85, Learning rate: 0.00005940, Avg batch loss: 1.4857, Avg batch acc: 0.0893
Train, Epoch: 1, Batch: 86, Step num: 86, Learning rate: 0.00006009, Avg batch loss: 1.3428, Avg batch acc: 0.1020
Train, Epoch: 1, Batch: 87, Step num: 87, Learning rate: 0.00006079, Avg batch loss: 1.3065, Avg batch acc: 0.0968
Train, Epoch: 1, Batch: 88, Step num: 88, Learning rate: 0.00006149, Avg batch loss: 1.4371, Avg batch acc: 0.0909
Train, Epoch: 1, Batch: 89, Step num: 89, Learning rate: 0.00006219, Avg batch loss: 1.3586, Avg batch acc: 0.0884
Train, Epoch: 1, Batch: 90, Step num: 90, Learning rate: 0.00006289, Avg batch loss: 1.3226, Avg batch acc: 0.0911
Train, Epoch: 1, Batch: 91, Step num: 91, Learning rate: 0.00006359, Avg batch loss: 1.4805, Avg batch acc: 0.0935
Train, Epoch: 1, Batch: 92, Step num: 92, Learning rate: 0.00006429, Avg batch loss: 1.4207, Avg batch acc: 0.1004
Train, Epoch: 1, Batch: 93, Step num: 93, Learning rate: 0.00006499, Avg batch loss: 1.3293, Avg batch acc: 0.0998
Train, Epoch: 1, Batch: 94, Step num: 94, Learning rate: 0.00006568, Avg batch loss: 1.3633, Avg batch acc: 0.0985
Train, Epoch: 1, Batch: 95, Step num: 95, Learning rate: 0.00006638, Avg batch loss: 1.4029, Avg batch acc: 0.0846
Train, Epoch: 1, Batch: 96, Step num: 96, Learning rate: 0.00006708, Avg batch loss: 1.2970, Avg batch acc: 0.1021
Train, Epoch: 1, Batch: 97, Step num: 97, Learning rate: 0.00006778, Avg batch loss: 1.3960, Avg batch acc: 0.0967
Train, Epoch: 1, Batch: 98, Step num: 98, Learning rate: 0.00006848, Avg batch loss: 1.3918, Avg batch acc: 0.1072
Train, Epoch: 1, Batch: 99, Step num: 99, Learning rate: 0.00006918, Avg batch loss: 1.4531, Avg batch acc: 0.1006
Train, Epoch: 1, Batch: 100, Step num: 100, Learning rate: 0.00006988, Avg batch loss: 1.3549, Avg batch acc: 0.0999
Train, Epoch: 1, Batch: 101, Step num: 101, Learning rate: 0.00007058, Avg batch loss: 1.4104, Avg batch acc: 0.0929
Train, Epoch: 1, Batch: 102, Step num: 102, Learning rate: 0.00007127, Avg batch loss: 1.4166, Avg batch acc: 0.1005
Train, Epoch: 1, Batch: 103, Step num: 103, Learning rate: 0.00007197, Avg batch loss: 1.4915, Avg batch acc: 0.1015
Train, Epoch: 1, Batch: 104, Step num: 104, Learning rate: 0.00007267, Avg batch loss: 1.3358, Avg batch acc: 0.1014
Train, Epoch: 1, Batch: 105, Step num: 105, Learning rate: 0.00007337, Avg batch loss: 1.4242, Avg batch acc: 0.1137
Train, Epoch: 1, Batch: 106, Step num: 106, Learning rate: 0.00007407, Avg batch loss: 1.4033, Avg batch acc: 0.1080
Train, Epoch: 1, Batch: 107, Step num: 107, Learning rate: 0.00007477, Avg batch loss: 1.2258, Avg batch acc: 0.1093
Train, Epoch: 1, Batch: 108, Step num: 108, Learning rate: 0.00007547, Avg batch loss: 1.2278, Avg batch acc: 0.1160
Train, Epoch: 1, Batch: 109, Step num: 109, Learning rate: 0.00007617, Avg batch loss: 1.3067, Avg batch acc: 0.1051
Train, Epoch: 1, Batch: 110, Step num: 110, Learning rate: 0.00007686, Avg batch loss: 1.3186, Avg batch acc: 0.1284
Train, Epoch: 1, Batch: 111, Step num: 111, Learning rate: 0.00007756, Avg batch loss: 1.4294, Avg batch acc: 0.1181
Train, Epoch: 1, Batch: 112, Step num: 112, Learning rate: 0.00007826, Avg batch loss: 1.3186, Avg batch acc: 0.1119
Train, Epoch: 1, Batch: 113, Step num: 113, Learning rate: 0.00007896, Avg batch loss: 1.3863, Avg batch acc: 0.1117
Train, Epoch: 1, Batch: 114, Step num: 114, Learning rate: 0.00007966, Avg batch loss: 1.3118, Avg batch acc: 0.1096
Train, Epoch: 1, Batch: 115, Step num: 115, Learning rate: 0.00008036, Avg batch loss: 1.2619, Avg batch acc: 0.1232
Train, Epoch: 1, Batch: 116, Step num: 116, Learning rate: 0.00008106, Avg batch loss: 1.2201, Avg batch acc: 0.1225
Train, Epoch: 1, Batch: 117, Step num: 117, Learning rate: 0.00008176, Avg batch loss: 1.2727, Avg batch acc: 0.1218
Train, Epoch: 1, Batch: 118, Step num: 118, Learning rate: 0.00008246, Avg batch loss: 1.3346, Avg batch acc: 0.1149
Train, Epoch: 1, Batch: 119, Step num: 119, Learning rate: 0.00008315, Avg batch loss: 1.1496, Avg batch acc: 0.1225
Train, Epoch: 1, Batch: 120, Step num: 120, Learning rate: 0.00008385, Avg batch loss: 1.3321, Avg batch acc: 0.1339
Train, Epoch: 1, Batch: 121, Step num: 121, Learning rate: 0.00008455, Avg batch loss: 1.2658, Avg batch acc: 0.1276
Train, Epoch: 1, Batch: 122, Step num: 122, Learning rate: 0.00008525, Avg batch loss: 1.2489, Avg batch acc: 0.1189
Train, Epoch: 1, Batch: 123, Step num: 123, Learning rate: 0.00008595, Avg batch loss: 1.2094, Avg batch acc: 0.1358
Train, Epoch: 1, Batch: 124, Step num: 124, Learning rate: 0.00008665, Avg batch loss: 1.2505, Avg batch acc: 0.1242
Train, Epoch: 1, Batch: 125, Step num: 125, Learning rate: 0.00008735, Avg batch loss: 1.3961, Avg batch acc: 0.1318
Train, Epoch: 1, Batch: 126, Step num: 126, Learning rate: 0.00008805, Avg batch loss: 1.2245, Avg batch acc: 0.1295
Train, Epoch: 1, Batch: 127, Step num: 127, Learning rate: 0.00008874, Avg batch loss: 1.2629, Avg batch acc: 0.1356
Train, Epoch: 1, Batch: 128, Step num: 128, Learning rate: 0.00008944, Avg batch loss: 1.2730, Avg batch acc: 0.1419
Train, Epoch: 1, Batch: 129, Step num: 129, Learning rate: 0.00009014, Avg batch loss: 1.2037, Avg batch acc: 0.1313
Train, Epoch: 1, Batch: 130, Step num: 130, Learning rate: 0.00009084, Avg batch loss: 1.1853, Avg batch acc: 0.1390
Train, Epoch: 1, Batch: 131, Step num: 131, Learning rate: 0.00009154, Avg batch loss: 1.2071, Avg batch acc: 0.1432
Train, Epoch: 1, Batch: 132, Step num: 132, Learning rate: 0.00009224, Avg batch loss: 1.2180, Avg batch acc: 0.1326
Train, Epoch: 1, Batch: 133, Step num: 133, Learning rate: 0.00009294, Avg batch loss: 1.2571, Avg batch acc: 0.1356
Train, Epoch: 1, Batch: 134, Step num: 134, Learning rate: 0.00009364, Avg batch loss: 1.2317, Avg batch acc: 0.1364
Train, Epoch: 1, Batch: 135, Step num: 135, Learning rate: 0.00009433, Avg batch loss: 1.2329, Avg batch acc: 0.1448
Train, Epoch: 1, Batch: 136, Step num: 136, Learning rate: 0.00009503, Avg batch loss: 1.2941, Avg batch acc: 0.1398
Train, Epoch: 1, Batch: 137, Step num: 137, Learning rate: 0.00009573, Avg batch loss: 1.2587, Avg batch acc: 0.1411
Train, Epoch: 1, Batch: 138, Step num: 138, Learning rate: 0.00009643, Avg batch loss: 1.2033, Avg batch acc: 0.1400
Train, Epoch: 1, Batch: 139, Step num: 139, Learning rate: 0.00009713, Avg batch loss: 1.1881, Avg batch acc: 0.1423
Train, Epoch: 1, Batch: 140, Step num: 140, Learning rate: 0.00009783, Avg batch loss: 1.2996, Avg batch acc: 0.1592
Train, Epoch: 1, Batch: 141, Step num: 141, Learning rate: 0.00009853, Avg batch loss: 1.2212, Avg batch acc: 0.1700
Train, Epoch: 1, Batch: 142, Step num: 142, Learning rate: 0.00009923, Avg batch loss: 1.1612, Avg batch acc: 0.1682
Train, Epoch: 1, Batch: 143, Step num: 143, Learning rate: 0.00009992, Avg batch loss: 1.0807, Avg batch acc: 0.1671
Train, Epoch: 1, Batch: 144, Step num: 144, Learning rate: 0.00010062, Avg batch loss: 1.1857, Avg batch acc: 0.1820
Train, Epoch: 1, Batch: 145, Step num: 145, Learning rate: 0.00010132, Avg batch loss: 1.1918, Avg batch acc: 0.1643
Train, Epoch: 1, Batch: 146, Step num: 146, Learning rate: 0.00010202, Avg batch loss: 1.1811, Avg batch acc: 0.1782
Train, Epoch: 1, Batch: 147, Step num: 147, Learning rate: 0.00010272, Avg batch loss: 1.1994, Avg batch acc: 0.1628
Train, Epoch: 1, Batch: 148, Step num: 148, Learning rate: 0.00010342, Avg batch loss: 1.2799, Avg batch acc: 0.1638
Train, Epoch: 1, Batch: 149, Step num: 149, Learning rate: 0.00010412, Avg batch loss: 1.2035, Avg batch acc: 0.1659
Train, Epoch: 1, Batch: 150, Step num: 150, Learning rate: 0.00010482, Avg batch loss: 1.2241, Avg batch acc: 0.1886
Train, Epoch: 1, Batch: 151, Step num: 151, Learning rate: 0.00010551, Avg batch loss: 1.1402, Avg batch acc: 0.1866
Train, Epoch: 1, Batch: 152, Step num: 152, Learning rate: 0.00010621, Avg batch loss: 1.1328, Avg batch acc: 0.1925
Train, Epoch: 1, Batch: 153, Step num: 153, Learning rate: 0.00010691, Avg batch loss: 1.0801, Avg batch acc: 0.1829
Train, Epoch: 1, Batch: 154, Step num: 154, Learning rate: 0.00010761, Avg batch loss: 1.1406, Avg batch acc: 0.1903
Train, Epoch: 1, Batch: 155, Step num: 155, Learning rate: 0.00010831, Avg batch loss: 1.1810, Avg batch acc: 0.1732
Train, Epoch: 1, Batch: 156, Step num: 156, Learning rate: 0.00010901, Avg batch loss: 1.1332, Avg batch acc: 0.1903
Train, Epoch: 1, Batch: 157, Step num: 157, Learning rate: 0.00010971, Avg batch loss: 1.1939, Avg batch acc: 0.1749
Train, Epoch: 1, Batch: 158, Step num: 158, Learning rate: 0.00011041, Avg batch loss: 1.1170, Avg batch acc: 0.1866
Train, Epoch: 1, Batch: 159, Step num: 159, Learning rate: 0.00011110, Avg batch loss: 1.0544, Avg batch acc: 0.1850
Train, Epoch: 1, Batch: 160, Step num: 160, Learning rate: 0.00011180, Avg batch loss: 1.1240, Avg batch acc: 0.1949
Train, Epoch: 1, Batch: 161, Step num: 161, Learning rate: 0.00011250, Avg batch loss: 1.1283, Avg batch acc: 0.2050
Train, Epoch: 1, Batch: 162, Step num: 162, Learning rate: 0.00011320, Avg batch loss: 1.1427, Avg batch acc: 0.1880
Train, Epoch: 1, Batch: 163, Step num: 163, Learning rate: 0.00011390, Avg batch loss: 1.1725, Avg batch acc: 0.1880
Train, Epoch: 1, Batch: 164, Step num: 164, Learning rate: 0.00011460, Avg batch loss: 1.1469, Avg batch acc: 0.1964
Train, Epoch: 1, Batch: 165, Step num: 165, Learning rate: 0.00011530, Avg batch loss: 1.2127, Avg batch acc: 0.1836
Train, Epoch: 1, Batch: 166, Step num: 166, Learning rate: 0.00011600, Avg batch loss: 1.1153, Avg batch acc: 0.1883
Train, Epoch: 1, Batch: 167, Step num: 167, Learning rate: 0.00011669, Avg batch loss: 1.2546, Avg batch acc: 0.1886
Train, Epoch: 1, Batch: 168, Step num: 168, Learning rate: 0.00011739, Avg batch loss: 1.1468, Avg batch acc: 0.2009
Train, Epoch: 1, Batch: 169, Step num: 169, Learning rate: 0.00011809, Avg batch loss: 1.1699, Avg batch acc: 0.2161
Train, Epoch: 1, Batch: 170, Step num: 170, Learning rate: 0.00011879, Avg batch loss: 1.1151, Avg batch acc: 0.1881
Train, Epoch: 1, Batch: 171, Step num: 171, Learning rate: 0.00011949, Avg batch loss: 1.0885, Avg batch acc: 0.2094
Train, Epoch: 1, Batch: 172, Step num: 172, Learning rate: 0.00012019, Avg batch loss: 1.1223, Avg batch acc: 0.2085
Train, Epoch: 1, Batch: 173, Step num: 173, Learning rate: 0.00012089, Avg batch loss: 1.1066, Avg batch acc: 0.2101
Train, Epoch: 1, Batch: 174, Step num: 174, Learning rate: 0.00012159, Avg batch loss: 1.0886, Avg batch acc: 0.2135
Train, Epoch: 1, Batch: 175, Step num: 175, Learning rate: 0.00012228, Avg batch loss: 1.1087, Avg batch acc: 0.2045
Train, Epoch: 1, Batch: 176, Step num: 176, Learning rate: 0.00012298, Avg batch loss: 1.0756, Avg batch acc: 0.2080
Train, Epoch: 1, Batch: 177, Step num: 177, Learning rate: 0.00012368, Avg batch loss: 1.0806, Avg batch acc: 0.2109
Train, Epoch: 1, Batch: 178, Step num: 178, Learning rate: 0.00012438, Avg batch loss: 1.1056, Avg batch acc: 0.2120
Train, Epoch: 1, Batch: 179, Step num: 179, Learning rate: 0.00012508, Avg batch loss: 1.0311, Avg batch acc: 0.2129
Train, Epoch: 1, Batch: 180, Step num: 180, Learning rate: 0.00012578, Avg batch loss: 1.0308, Avg batch acc: 0.2132
Train, Epoch: 1, Batch: 181, Step num: 181, Learning rate: 0.00012648, Avg batch loss: 1.1462, Avg batch acc: 0.2196
Train, Epoch: 1, Batch: 182, Step num: 182, Learning rate: 0.00012718, Avg batch loss: 0.9964, Avg batch acc: 0.2216
Train, Epoch: 1, Batch: 183, Step num: 183, Learning rate: 0.00012788, Avg batch loss: 1.1591, Avg batch acc: 0.2169
Train, Epoch: 1, Batch: 184, Step num: 184, Learning rate: 0.00012857, Avg batch loss: 1.0257, Avg batch acc: 0.2176
Train, Epoch: 1, Batch: 185, Step num: 185, Learning rate: 0.00012927, Avg batch loss: 1.0785, Avg batch acc: 0.2207
Train, Epoch: 1, Batch: 186, Step num: 186, Learning rate: 0.00012997, Avg batch loss: 1.0348, Avg batch acc: 0.2206
Train, Epoch: 1, Batch: 187, Step num: 187, Learning rate: 0.00013067, Avg batch loss: 1.1111, Avg batch acc: 0.2130
Train, Epoch: 1, Batch: 188, Step num: 188, Learning rate: 0.00013137, Avg batch loss: 1.0826, Avg batch acc: 0.2139
Train, Epoch: 1, Batch: 189, Step num: 189, Learning rate: 0.00013207, Avg batch loss: 1.0836, Avg batch acc: 0.2331
Train, Epoch: 1, Batch: 190, Step num: 190, Learning rate: 0.00013277, Avg batch loss: 1.0554, Avg batch acc: 0.2116
Train, Epoch: 1, Batch: 191, Step num: 191, Learning rate: 0.00013347, Avg batch loss: 0.9889, Avg batch acc: 0.2241
Train, Epoch: 1, Batch: 192, Step num: 192, Learning rate: 0.00013416, Avg batch loss: 0.9129, Avg batch acc: 0.2435
Train, Epoch: 1, Batch: 193, Step num: 193, Learning rate: 0.00013486, Avg batch loss: 0.9482, Avg batch acc: 0.2562
Train, Epoch: 1, Batch: 194, Step num: 194, Learning rate: 0.00013556, Avg batch loss: 1.1155, Avg batch acc: 0.2246
Train, Epoch: 1, Batch: 195, Step num: 195, Learning rate: 0.00013626, Avg batch loss: 1.1026, Avg batch acc: 0.2340
Train, Epoch: 1, Batch: 196, Step num: 196, Learning rate: 0.00013696, Avg batch loss: 0.9810, Avg batch acc: 0.2283
Train, Epoch: 1, Batch: 197, Step num: 197, Learning rate: 0.00013766, Avg batch loss: 1.0365, Avg batch acc: 0.2349
Train, Epoch: 1, Batch: 198, Step num: 198, Learning rate: 0.00013836, Avg batch loss: 0.9645, Avg batch acc: 0.2403
Train, Epoch: 1, Batch: 199, Step num: 199, Learning rate: 0.00013906, Avg batch loss: 0.9493, Avg batch acc: 0.2362
Train, Epoch: 1, Batch: 200, Step num: 200, Learning rate: 0.00013975, Avg batch loss: 1.0412, Avg batch acc: 0.2454
Train, Epoch: 1, Batch: 201, Step num: 201, Learning rate: 0.00014045, Avg batch loss: 1.1047, Avg batch acc: 0.2204
Train, Epoch: 1, Batch: 202, Step num: 202, Learning rate: 0.00014115, Avg batch loss: 1.0519, Avg batch acc: 0.2356
Train, Epoch: 1, Batch: 203, Step num: 203, Learning rate: 0.00014185, Avg batch loss: 0.9888, Avg batch acc: 0.2507
Train, Epoch: 1, Batch: 204, Step num: 204, Learning rate: 0.00014255, Avg batch loss: 1.0631, Avg batch acc: 0.2346
Train, Epoch: 1, Batch: 205, Step num: 205, Learning rate: 0.00014325, Avg batch loss: 0.8712, Avg batch acc: 0.2448
Train, Epoch: 1, Batch: 206, Step num: 206, Learning rate: 0.00014395, Avg batch loss: 0.9441, Avg batch acc: 0.2517
Train, Epoch: 1, Batch: 207, Step num: 207, Learning rate: 0.00014465, Avg batch loss: 1.0149, Avg batch acc: 0.2591
Train, Epoch: 1, Batch: 208, Step num: 208, Learning rate: 0.00014534, Avg batch loss: 0.9521, Avg batch acc: 0.2446
Train, Epoch: 1, Batch: 209, Step num: 209, Learning rate: 0.00014604, Avg batch loss: 1.1314, Avg batch acc: 0.2447
Train, Epoch: 1, Batch: 210, Step num: 210, Learning rate: 0.00014674, Avg batch loss: 0.9524, Avg batch acc: 0.2486
Train, Epoch: 1, Batch: 211, Step num: 211, Learning rate: 0.00014744, Avg batch loss: 0.9996, Avg batch acc: 0.2366
Train, Epoch: 1, Batch: 212, Step num: 212, Learning rate: 0.00014814, Avg batch loss: 0.9904, Avg batch acc: 0.2485
Train, Epoch: 1, Batch: 213, Step num: 213, Learning rate: 0.00014884, Avg batch loss: 0.9622, Avg batch acc: 0.2558
Train, Epoch: 1, Batch: 214, Step num: 214, Learning rate: 0.00014954, Avg batch loss: 1.0273, Avg batch acc: 0.2453
Train, Epoch: 1, Batch: 215, Step num: 215, Learning rate: 0.00015024, Avg batch loss: 0.9689, Avg batch acc: 0.2536
Train, Epoch: 1, Batch: 216, Step num: 216, Learning rate: 0.00015093, Avg batch loss: 0.9794, Avg batch acc: 0.2428
Train, Epoch: 1, Batch: 217, Step num: 217, Learning rate: 0.00015163, Avg batch loss: 1.0315, Avg batch acc: 0.2494
Train, Epoch: 1, Batch: 218, Step num: 218, Learning rate: 0.00015233, Avg batch loss: 0.9183, Avg batch acc: 0.2682
Train, Epoch: 1, Batch: 219, Step num: 219, Learning rate: 0.00015303, Avg batch loss: 1.0223, Avg batch acc: 0.2550
Train, Epoch: 1, Batch: 220, Step num: 220, Learning rate: 0.00015373, Avg batch loss: 0.9135, Avg batch acc: 0.2536
Train, Epoch: 1, Batch: 221, Step num: 221, Learning rate: 0.00015443, Avg batch loss: 1.0883, Avg batch acc: 0.2341
Train, Epoch: 1, Batch: 222, Step num: 222, Learning rate: 0.00015513, Avg batch loss: 1.0541, Avg batch acc: 0.2533
Train, Epoch: 1, Batch: 223, Step num: 223, Learning rate: 0.00015583, Avg batch loss: 0.9279, Avg batch acc: 0.2602
Train, Epoch: 1, Batch: 224, Step num: 224, Learning rate: 0.00015652, Avg batch loss: 1.0644, Avg batch acc: 0.2482
Train, Epoch: 1, Batch: 225, Step num: 225, Learning rate: 0.00015722, Avg batch loss: 0.9805, Avg batch acc: 0.2636
Train, Epoch: 1, Batch: 226, Step num: 226, Learning rate: 0.00015792, Avg batch loss: 0.9695, Avg batch acc: 0.2603
Train, Epoch: 1, Batch: 227, Step num: 227, Learning rate: 0.00015862, Avg batch loss: 0.9107, Avg batch acc: 0.2488
Train, Epoch: 1, Batch: 228, Step num: 228, Learning rate: 0.00015932, Avg batch loss: 0.9350, Avg batch acc: 0.2651
Train, Epoch: 1, Batch: 229, Step num: 229, Learning rate: 0.00016002, Avg batch loss: 0.9004, Avg batch acc: 0.2731
Train, Epoch: 1, Batch: 230, Step num: 230, Learning rate: 0.00016072, Avg batch loss: 0.8620, Avg batch acc: 0.2724
Train, Epoch: 1, Batch: 231, Step num: 231, Learning rate: 0.00016142, Avg batch loss: 0.9404, Avg batch acc: 0.2573
Train, Epoch: 1, Batch: 232, Step num: 232, Learning rate: 0.00016211, Avg batch loss: 0.9278, Avg batch acc: 0.2675
Train, Epoch: 1, Batch: 233, Step num: 233, Learning rate: 0.00016281, Avg batch loss: 1.0077, Avg batch acc: 0.2498
Train, Epoch: 1, Batch: 234, Step num: 234, Learning rate: 0.00016351, Avg batch loss: 0.9102, Avg batch acc: 0.2840
Train, Epoch: 1, Batch: 235, Step num: 235, Learning rate: 0.00016421, Avg batch loss: 0.8972, Avg batch acc: 0.2840
Train, Epoch: 1, Batch: 236, Step num: 236, Learning rate: 0.00016491, Avg batch loss: 0.9127, Avg batch acc: 0.2610
Train, Epoch: 1, Batch: 237, Step num: 237, Learning rate: 0.00016561, Avg batch loss: 0.9266, Avg batch acc: 0.2703
Train, Epoch: 1, Batch: 238, Step num: 238, Learning rate: 0.00016631, Avg batch loss: 0.8201, Avg batch acc: 0.2684
Train, Epoch: 1, Batch: 239, Step num: 239, Learning rate: 0.00016701, Avg batch loss: 0.9261, Avg batch acc: 0.2578
Train, Epoch: 1, Batch: 240, Step num: 240, Learning rate: 0.00016771, Avg batch loss: 0.8449, Avg batch acc: 0.2711
Train, Epoch: 1, Batch: 241, Step num: 241, Learning rate: 0.00016840, Avg batch loss: 0.9534, Avg batch acc: 0.2644
Train, Epoch: 1, Batch: 242, Step num: 242, Learning rate: 0.00016910, Avg batch loss: 0.9155, Avg batch acc: 0.2735
Train, Epoch: 1, Batch: 243, Step num: 243, Learning rate: 0.00016980, Avg batch loss: 0.8638, Avg batch acc: 0.2842
Train, Epoch: 1, Batch: 244, Step num: 244, Learning rate: 0.00017050, Avg batch loss: 0.8798, Avg batch acc: 0.2900
Train, Epoch: 1, Batch: 245, Step num: 245, Learning rate: 0.00017120, Avg batch loss: 0.9219, Avg batch acc: 0.2598
Train, Epoch: 1, Batch: 246, Step num: 246, Learning rate: 0.00017190, Avg batch loss: 0.7986, Avg batch acc: 0.2704
Train, Epoch: 1, Batch: 247, Step num: 247, Learning rate: 0.00017260, Avg batch loss: 0.8615, Avg batch acc: 0.2573
Train, Epoch: 1, Batch: 248, Step num: 248, Learning rate: 0.00017330, Avg batch loss: 0.8754, Avg batch acc: 0.2704
Train, Epoch: 1, Batch: 249, Step num: 249, Learning rate: 0.00017399, Avg batch loss: 1.0139, Avg batch acc: 0.2592
Train, Epoch: 1, Batch: 250, Step num: 250, Learning rate: 0.00017469, Avg batch loss: 0.8759, Avg batch acc: 0.2553
Train, Epoch: 1, Batch: 251, Step num: 251, Learning rate: 0.00017539, Avg batch loss: 0.8469, Avg batch acc: 0.2603
Train, Epoch: 1, Batch: 252, Step num: 252, Learning rate: 0.00017609, Avg batch loss: 0.9052, Avg batch acc: 0.2589
Train, Epoch: 1, Batch: 253, Step num: 253, Learning rate: 0.00017679, Avg batch loss: 0.8933, Avg batch acc: 0.2823
Train, Epoch: 1, Batch: 254, Step num: 254, Learning rate: 0.00017749, Avg batch loss: 0.9228, Avg batch acc: 0.2772
Train, Epoch: 1, Batch: 255, Step num: 255, Learning rate: 0.00017819, Avg batch loss: 0.8328, Avg batch acc: 0.2798
Train, Epoch: 1, Batch: 256, Step num: 256, Learning rate: 0.00017889, Avg batch loss: 0.8405, Avg batch acc: 0.2989
Train, Epoch: 1, Batch: 257, Step num: 257, Learning rate: 0.00017958, Avg batch loss: 0.9179, Avg batch acc: 0.2659
Train, Epoch: 1, Batch: 258, Step num: 258, Learning rate: 0.00018028, Avg batch loss: 0.8173, Avg batch acc: 0.3068
Train, Epoch: 1, Batch: 259, Step num: 259, Learning rate: 0.00018098, Avg batch loss: 0.7792, Avg batch acc: 0.2865
Train, Epoch: 1, Batch: 260, Step num: 260, Learning rate: 0.00018168, Avg batch loss: 0.8338, Avg batch acc: 0.2822
Train, Epoch: 1, Batch: 261, Step num: 261, Learning rate: 0.00018238, Avg batch loss: 0.8731, Avg batch acc: 0.2906
Train, Epoch: 1, Batch: 262, Step num: 262, Learning rate: 0.00018308, Avg batch loss: 0.9120, Avg batch acc: 0.2729
Train, Epoch: 1, Batch: 263, Step num: 263, Learning rate: 0.00018378, Avg batch loss: 0.8811, Avg batch acc: 0.2485
Train, Epoch: 1, Batch: 264, Step num: 264, Learning rate: 0.00018448, Avg batch loss: 0.8650, Avg batch acc: 0.2791
Train, Epoch: 1, Batch: 265, Step num: 265, Learning rate: 0.00018517, Avg batch loss: 0.8275, Avg batch acc: 0.2912
Train, Epoch: 1, Batch: 266, Step num: 266, Learning rate: 0.00018587, Avg batch loss: 0.9293, Avg batch acc: 0.2951
Train, Epoch: 1, Batch: 267, Step num: 267, Learning rate: 0.00018657, Avg batch loss: 0.8537, Avg batch acc: 0.2959
Train, Epoch: 1, Batch: 268, Step num: 268, Learning rate: 0.00018727, Avg batch loss: 0.7965, Avg batch acc: 0.2672
Train, Epoch: 1, Batch: 269, Step num: 269, Learning rate: 0.00018797, Avg batch loss: 0.7992, Avg batch acc: 0.3024
Train, Epoch: 1, Batch: 270, Step num: 270, Learning rate: 0.00018867, Avg batch loss: 0.8514, Avg batch acc: 0.3069
Train, Epoch: 1, Batch: 271, Step num: 271, Learning rate: 0.00018937, Avg batch loss: 0.8385, Avg batch acc: 0.2839
Train, Epoch: 1, Batch: 272, Step num: 272, Learning rate: 0.00019007, Avg batch loss: 0.8587, Avg batch acc: 0.3056
Train, Epoch: 1, Batch: 273, Step num: 273, Learning rate: 0.00019076, Avg batch loss: 0.8707, Avg batch acc: 0.2623
Train, Epoch: 1, Batch: 274, Step num: 274, Learning rate: 0.00019146, Avg batch loss: 0.7600, Avg batch acc: 0.3150
Train, Epoch: 1, Batch: 275, Step num: 275, Learning rate: 0.00019216, Avg batch loss: 0.8962, Avg batch acc: 0.2864
Train, Epoch: 1, Batch: 276, Step num: 276, Learning rate: 0.00019286, Avg batch loss: 0.8765, Avg batch acc: 0.2923
Train, Epoch: 1, Batch: 277, Step num: 277, Learning rate: 0.00019356, Avg batch loss: 0.7705, Avg batch acc: 0.2976
Train, Epoch: 1, Batch: 278, Step num: 278, Learning rate: 0.00019426, Avg batch loss: 0.8687, Avg batch acc: 0.2808
Train, Epoch: 1, Batch: 279, Step num: 279, Learning rate: 0.00019496, Avg batch loss: 0.7968, Avg batch acc: 0.2969
Train, Epoch: 1, Batch: 280, Step num: 280, Learning rate: 0.00019566, Avg batch loss: 0.8026, Avg batch acc: 0.2910
Train, Epoch: 1, Batch: 281, Step num: 281, Learning rate: 0.00019635, Avg batch loss: 0.8007, Avg batch acc: 0.2957
Train, Epoch: 1, Batch: 282, Step num: 282, Learning rate: 0.00019705, Avg batch loss: 0.8460, Avg batch acc: 0.2717
Train, Epoch: 1, Batch: 283, Step num: 283, Learning rate: 0.00019775, Avg batch loss: 0.8584, Avg batch acc: 0.2773
Train, Epoch: 1, Batch: 284, Step num: 284, Learning rate: 0.00019845, Avg batch loss: 0.8143, Avg batch acc: 0.3072
Train, Epoch: 1, Batch: 285, Step num: 285, Learning rate: 0.00019915, Avg batch loss: 0.8455, Avg batch acc: 0.2975
Train, Epoch: 1, Batch: 286, Step num: 286, Learning rate: 0.00019985, Avg batch loss: 0.9154, Avg batch acc: 0.2712
Train, Epoch: 1, Batch: 287, Step num: 287, Learning rate: 0.00020055, Avg batch loss: 0.8163, Avg batch acc: 0.3147
Train, Epoch: 1, Batch: 288, Step num: 288, Learning rate: 0.00020125, Avg batch loss: 0.9014, Avg batch acc: 0.2708
Train, Epoch: 1, Batch: 289, Step num: 289, Learning rate: 0.00020194, Avg batch loss: 0.8417, Avg batch acc: 0.2957
Train, Epoch: 1, Batch: 290, Step num: 290, Learning rate: 0.00020264, Avg batch loss: 0.7832, Avg batch acc: 0.2866
Train, Epoch: 1, Batch: 291, Step num: 291, Learning rate: 0.00020334, Avg batch loss: 0.8505, Avg batch acc: 0.3013
Train, Epoch: 1, Batch: 292, Step num: 292, Learning rate: 0.00020404, Avg batch loss: 0.7304, Avg batch acc: 0.3388
Train, Epoch: 1, Batch: 293, Step num: 293, Learning rate: 0.00020474, Avg batch loss: 0.7373, Avg batch acc: 0.2937
Train, Epoch: 1, Batch: 294, Step num: 294, Learning rate: 0.00020544, Avg batch loss: 0.8505, Avg batch acc: 0.3224
Train, Epoch: 1, Batch: 295, Step num: 295, Learning rate: 0.00020614, Avg batch loss: 0.9429, Avg batch acc: 0.2925
Train, Epoch: 1, Batch: 296, Step num: 296, Learning rate: 0.00020684, Avg batch loss: 0.7944, Avg batch acc: 0.3208
Train, Epoch: 1, Batch: 297, Step num: 297, Learning rate: 0.00020754, Avg batch loss: 0.7700, Avg batch acc: 0.3189
Train, Epoch: 1, Batch: 298, Step num: 298, Learning rate: 0.00020823, Avg batch loss: 0.7718, Avg batch acc: 0.3087
Train, Epoch: 1, Batch: 299, Step num: 299, Learning rate: 0.00020893, Avg batch loss: 0.7979, Avg batch acc: 0.3053
Train, Epoch: 1, Batch: 300, Step num: 300, Learning rate: 0.00020963, Avg batch loss: 0.7442, Avg batch acc: 0.3167
Train, Epoch: 1, Batch: 301, Step num: 301, Learning rate: 0.00021033, Avg batch loss: 0.7500, Avg batch acc: 0.3075
Train, Epoch: 1, Batch: 302, Step num: 302, Learning rate: 0.00021103, Avg batch loss: 0.8019, Avg batch acc: 0.2854
Train, Epoch: 1, Batch: 303, Step num: 303, Learning rate: 0.00021173, Avg batch loss: 0.8088, Avg batch acc: 0.3181
Train, Epoch: 1, Batch: 304, Step num: 304, Learning rate: 0.00021243, Avg batch loss: 0.7993, Avg batch acc: 0.3074
Train, Epoch: 1, Batch: 305, Step num: 305, Learning rate: 0.00021313, Avg batch loss: 0.8205, Avg batch acc: 0.3150
Train, Epoch: 1, Batch: 306, Step num: 306, Learning rate: 0.00021382, Avg batch loss: 0.7957, Avg batch acc: 0.3133
Train, Epoch: 1, Batch: 307, Step num: 307, Learning rate: 0.00021452, Avg batch loss: 0.7866, Avg batch acc: 0.3235
Train, Epoch: 1, Batch: 308, Step num: 308, Learning rate: 0.00021522, Avg batch loss: 0.7892, Avg batch acc: 0.2944
Train, Epoch: 1, Batch: 309, Step num: 309, Learning rate: 0.00021592, Avg batch loss: 0.7302, Avg batch acc: 0.3053
Train, Epoch: 1, Batch: 310, Step num: 310, Learning rate: 0.00021662, Avg batch loss: 0.7231, Avg batch acc: 0.3037
Train, Epoch: 1, Batch: 311, Step num: 311, Learning rate: 0.00021732, Avg batch loss: 0.8060, Avg batch acc: 0.2939
Train, Epoch: 1, Batch: 312, Step num: 312, Learning rate: 0.00021802, Avg batch loss: 0.7989, Avg batch acc: 0.3062
Train, Epoch: 1, Batch: 313, Step num: 313, Learning rate: 0.00021872, Avg batch loss: 0.7526, Avg batch acc: 0.3207
Train, Epoch: 1, Batch: 314, Step num: 314, Learning rate: 0.00021941, Avg batch loss: 0.7518, Avg batch acc: 0.3195
Train, Epoch: 1, Batch: 315, Step num: 315, Learning rate: 0.00022011, Avg batch loss: 0.8321, Avg batch acc: 0.3006
Train, Epoch: 1, Batch: 316, Step num: 316, Learning rate: 0.00022081, Avg batch loss: 0.7922, Avg batch acc: 0.3297
Train, Epoch: 1, Batch: 317, Step num: 317, Learning rate: 0.00022151, Avg batch loss: 0.8199, Avg batch acc: 0.3159
Train, Epoch: 1, Batch: 318, Step num: 318, Learning rate: 0.00022221, Avg batch loss: 0.7956, Avg batch acc: 0.3073
Train, Epoch: 1, Batch: 319, Step num: 319, Learning rate: 0.00022291, Avg batch loss: 0.8559, Avg batch acc: 0.2898
Train, Epoch: 1, Batch: 320, Step num: 320, Learning rate: 0.00022361, Avg batch loss: 0.7023, Avg batch acc: 0.3382
Train, Epoch: 1, Batch: 321, Step num: 321, Learning rate: 0.00022431, Avg batch loss: 0.7527, Avg batch acc: 0.3062
Train, Epoch: 1, Batch: 322, Step num: 322, Learning rate: 0.00022500, Avg batch loss: 0.7958, Avg batch acc: 0.3008
Train, Epoch: 1, Batch: 323, Step num: 323, Learning rate: 0.00022570, Avg batch loss: 0.8010, Avg batch acc: 0.3051
Train, Epoch: 1, Batch: 324, Step num: 324, Learning rate: 0.00022640, Avg batch loss: 0.7651, Avg batch acc: 0.3161
Train, Epoch: 1, Batch: 325, Step num: 325, Learning rate: 0.00022710, Avg batch loss: 0.7989, Avg batch acc: 0.3021
Train, Epoch: 1, Batch: 326, Step num: 326, Learning rate: 0.00022780, Avg batch loss: 0.7507, Avg batch acc: 0.3281
Train, Epoch: 1, Batch: 327, Step num: 327, Learning rate: 0.00022850, Avg batch loss: 0.8509, Avg batch acc: 0.3207
Train, Epoch: 1, Batch: 328, Step num: 328, Learning rate: 0.00022920, Avg batch loss: 0.7512, Avg batch acc: 0.3161
Train, Epoch: 1, Batch: 329, Step num: 329, Learning rate: 0.00022990, Avg batch loss: 0.7183, Avg batch acc: 0.3180
Train, Epoch: 1, Batch: 330, Step num: 330, Learning rate: 0.00023059, Avg batch loss: 0.8419, Avg batch acc: 0.2973
Train, Epoch: 1, Batch: 331, Step num: 331, Learning rate: 0.00023129, Avg batch loss: 0.7505, Avg batch acc: 0.3196
Train, Epoch: 1, Batch: 332, Step num: 332, Learning rate: 0.00023199, Avg batch loss: 0.7496, Avg batch acc: 0.3095
Train, Epoch: 1, Batch: 333, Step num: 333, Learning rate: 0.00023269, Avg batch loss: 0.8036, Avg batch acc: 0.3033
Train, Epoch: 1, Batch: 334, Step num: 334, Learning rate: 0.00023339, Avg batch loss: 0.7400, Avg batch acc: 0.2943
Train, Epoch: 1, Batch: 335, Step num: 335, Learning rate: 0.00023409, Avg batch loss: 0.8292, Avg batch acc: 0.3234
Train, Epoch: 1, Batch: 336, Step num: 336, Learning rate: 0.00023479, Avg batch loss: 0.7283, Avg batch acc: 0.3422
Train, Epoch: 1, Batch: 337, Step num: 337, Learning rate: 0.00023549, Avg batch loss: 0.7614, Avg batch acc: 0.3069
Train, Epoch: 1, Batch: 338, Step num: 338, Learning rate: 0.00023618, Avg batch loss: 0.7356, Avg batch acc: 0.3239
Train, Epoch: 1, Batch: 339, Step num: 339, Learning rate: 0.00023688, Avg batch loss: 0.7165, Avg batch acc: 0.3349
Train, Epoch: 1, Batch: 340, Step num: 340, Learning rate: 0.00023758, Avg batch loss: 0.6925, Avg batch acc: 0.3411
Train, Epoch: 1, Batch: 341, Step num: 341, Learning rate: 0.00023828, Avg batch loss: 0.7916, Avg batch acc: 0.3246
Train, Epoch: 1, Batch: 342, Step num: 342, Learning rate: 0.00023898, Avg batch loss: 0.8246, Avg batch acc: 0.3132
Train, Epoch: 1, Batch: 343, Step num: 343, Learning rate: 0.00023968, Avg batch loss: 0.7889, Avg batch acc: 0.3030
Train, Epoch: 1, Batch: 344, Step num: 344, Learning rate: 0.00024038, Avg batch loss: 0.7925, Avg batch acc: 0.3185
Train, Epoch: 1, Batch: 345, Step num: 345, Learning rate: 0.00024108, Avg batch loss: 0.7840, Avg batch acc: 0.3120
Train, Epoch: 1, Batch: 346, Step num: 346, Learning rate: 0.00024177, Avg batch loss: 0.7845, Avg batch acc: 0.3124
Train, Epoch: 1, Batch: 347, Step num: 347, Learning rate: 0.00024247, Avg batch loss: 0.7710, Avg batch acc: 0.3289
Train, Epoch: 1, Batch: 348, Step num: 348, Learning rate: 0.00024317, Avg batch loss: 0.7542, Avg batch acc: 0.3124
Train, Epoch: 1, Batch: 349, Step num: 349, Learning rate: 0.00024387, Avg batch loss: 0.7218, Avg batch acc: 0.3410
Train, Epoch: 1, Batch: 350, Step num: 350, Learning rate: 0.00024457, Avg batch loss: 0.8213, Avg batch acc: 0.2932
Train, Epoch: 1, Batch: 351, Step num: 351, Learning rate: 0.00024527, Avg batch loss: 0.7608, Avg batch acc: 0.3432
Train, Epoch: 1, Batch: 352, Step num: 352, Learning rate: 0.00024597, Avg batch loss: 0.7460, Avg batch acc: 0.3457
Train, Epoch: 1, Batch: 353, Step num: 353, Learning rate: 0.00024667, Avg batch loss: 0.7336, Avg batch acc: 0.3507
Train, Epoch: 1, Batch: 354, Step num: 354, Learning rate: 0.00024737, Avg batch loss: 0.6816, Avg batch acc: 0.3266
Train, Epoch: 1, Batch: 355, Step num: 355, Learning rate: 0.00024806, Avg batch loss: 0.7882, Avg batch acc: 0.3152
Train, Epoch: 1, Batch: 356, Step num: 356, Learning rate: 0.00024876, Avg batch loss: 0.6812, Avg batch acc: 0.3225
Train, Epoch: 1, Batch: 357, Step num: 357, Learning rate: 0.00024946, Avg batch loss: 0.7642, Avg batch acc: 0.3214
Train, Epoch: 1, Batch: 358, Step num: 358, Learning rate: 0.00025016, Avg batch loss: 0.7418, Avg batch acc: 0.3160
Train, Epoch: 1, Batch: 359, Step num: 359, Learning rate: 0.00025086, Avg batch loss: 0.7419, Avg batch acc: 0.3221
Train, Epoch: 1, Batch: 360, Step num: 360, Learning rate: 0.00025156, Avg batch loss: 0.7049, Avg batch acc: 0.3387
Train, Epoch: 1, Batch: 361, Step num: 361, Learning rate: 0.00025226, Avg batch loss: 0.7401, Avg batch acc: 0.3515
Train, Epoch: 1, Batch: 362, Step num: 362, Learning rate: 0.00025296, Avg batch loss: 0.7294, Avg batch acc: 0.3362
Train, Epoch: 1, Batch: 363, Step num: 363, Learning rate: 0.00025365, Avg batch loss: 0.7169, Avg batch acc: 0.3250
Train, Epoch: 1, Batch: 364, Step num: 364, Learning rate: 0.00025435, Avg batch loss: 0.7188, Avg batch acc: 0.3231
Train, Epoch: 1, Batch: 365, Step num: 365, Learning rate: 0.00025505, Avg batch loss: 0.7349, Avg batch acc: 0.3250
Train, Epoch: 1, Batch: 366, Step num: 366, Learning rate: 0.00025575, Avg batch loss: 0.6711, Avg batch acc: 0.3478
Train, Epoch: 1, Batch: 367, Step num: 367, Learning rate: 0.00025645, Avg batch loss: 0.7373, Avg batch acc: 0.3205
Train, Epoch: 1, Batch: 368, Step num: 368, Learning rate: 0.00025715, Avg batch loss: 0.8078, Avg batch acc: 0.3185
Train, Epoch: 1, Batch: 369, Step num: 369, Learning rate: 0.00025785, Avg batch loss: 0.7884, Avg batch acc: 0.3323
Train, Epoch: 1, Batch: 370, Step num: 370, Learning rate: 0.00025855, Avg batch loss: 0.7948, Avg batch acc: 0.3356
Train, Epoch: 1, Batch: 371, Step num: 371, Learning rate: 0.00025924, Avg batch loss: 0.7950, Avg batch acc: 0.3473
Train, Epoch: 1, Batch: 372, Step num: 372, Learning rate: 0.00025994, Avg batch loss: 0.7769, Avg batch acc: 0.3323
Train, Epoch: 1, Batch: 373, Step num: 373, Learning rate: 0.00026064, Avg batch loss: 0.7387, Avg batch acc: 0.3331
Train, Epoch: 1, Batch: 374, Step num: 374, Learning rate: 0.00026134, Avg batch loss: 0.7587, Avg batch acc: 0.3214
Train, Epoch: 1, Batch: 375, Step num: 375, Learning rate: 0.00026204, Avg batch loss: 0.8260, Avg batch acc: 0.3187
Train, Epoch: 1, Batch: 376, Step num: 376, Learning rate: 0.00026274, Avg batch loss: 0.6875, Avg batch acc: 0.3404
Train, Epoch: 1, Batch: 377, Step num: 377, Learning rate: 0.00026344, Avg batch loss: 0.7462, Avg batch acc: 0.3445
Train, Epoch: 1, Batch: 378, Step num: 378, Learning rate: 0.00026414, Avg batch loss: 0.7077, Avg batch acc: 0.3467
Train, Epoch: 1, Batch: 379, Step num: 379, Learning rate: 0.00026483, Avg batch loss: 0.7822, Avg batch acc: 0.3259
Train, Epoch: 1, Batch: 380, Step num: 380, Learning rate: 0.00026553, Avg batch loss: 0.7801, Avg batch acc: 0.3445
Train, Epoch: 1, Batch: 381, Step num: 381, Learning rate: 0.00026623, Avg batch loss: 0.8067, Avg batch acc: 0.3291
Train, Epoch: 1, Batch: 382, Step num: 382, Learning rate: 0.00026693, Avg batch loss: 0.6667, Avg batch acc: 0.3452
Train, Epoch: 1, Batch: 383, Step num: 383, Learning rate: 0.00026763, Avg batch loss: 0.7922, Avg batch acc: 0.3264
Train, Epoch: 1, Batch: 384, Step num: 384, Learning rate: 0.00026833, Avg batch loss: 0.7523, Avg batch acc: 0.3343
Train, Epoch: 1, Batch: 385, Step num: 385, Learning rate: 0.00026903, Avg batch loss: 0.6623, Avg batch acc: 0.3240
Train, Epoch: 1, Batch: 386, Step num: 386, Learning rate: 0.00026973, Avg batch loss: 0.7691, Avg batch acc: 0.3423
Train, Epoch: 1, Batch: 387, Step num: 387, Learning rate: 0.00027042, Avg batch loss: 0.7243, Avg batch acc: 0.3411
Train, Epoch: 1, Batch: 388, Step num: 388, Learning rate: 0.00027112, Avg batch loss: 0.6976, Avg batch acc: 0.3605
Train, Epoch: 1, Batch: 389, Step num: 389, Learning rate: 0.00027182, Avg batch loss: 0.6780, Avg batch acc: 0.3593
Train, Epoch: 1, Batch: 390, Step num: 390, Learning rate: 0.00027252, Avg batch loss: 0.7606, Avg batch acc: 0.3288
Train, Epoch: 1, Batch: 391, Step num: 391, Learning rate: 0.00027322, Avg batch loss: 0.7675, Avg batch acc: 0.3255
Train, Epoch: 1, Batch: 392, Step num: 392, Learning rate: 0.00027392, Avg batch loss: 0.8184, Avg batch acc: 0.3158
Train, Epoch: 1, Batch: 393, Step num: 393, Learning rate: 0.00027462, Avg batch loss: 0.7889, Avg batch acc: 0.3112
Train, Epoch: 1, Batch: 394, Step num: 394, Learning rate: 0.00027532, Avg batch loss: 0.7275, Avg batch acc: 0.3244
Train, Epoch: 1, Batch: 395, Step num: 395, Learning rate: 0.00027601, Avg batch loss: 0.7552, Avg batch acc: 0.3382
Train, Epoch: 1, Batch: 396, Step num: 396, Learning rate: 0.00027671, Avg batch loss: 0.7120, Avg batch acc: 0.3299
Train, Epoch: 1, Batch: 397, Step num: 397, Learning rate: 0.00027741, Avg batch loss: 0.7783, Avg batch acc: 0.3241
Train, Epoch: 1, Batch: 398, Step num: 398, Learning rate: 0.00027811, Avg batch loss: 0.7847, Avg batch acc: 0.3270
Train, Epoch: 1, Batch: 399, Step num: 399, Learning rate: 0.00027881, Avg batch loss: 0.7015, Avg batch acc: 0.3470
Train, Epoch: 1, Batch: 400, Step num: 400, Learning rate: 0.00027951, Avg batch loss: 0.7439, Avg batch acc: 0.3321
Train, Epoch: 1, Batch: 401, Step num: 401, Learning rate: 0.00028021, Avg batch loss: 0.6944, Avg batch acc: 0.3534
Train, Epoch: 1, Batch: 402, Step num: 402, Learning rate: 0.00028091, Avg batch loss: 0.7638, Avg batch acc: 0.3299
Train, Epoch: 1, Batch: 403, Step num: 403, Learning rate: 0.00028160, Avg batch loss: 0.8106, Avg batch acc: 0.3255
Train, Epoch: 1, Batch: 404, Step num: 404, Learning rate: 0.00028230, Avg batch loss: 0.7570, Avg batch acc: 0.3393
Train, Epoch: 1, Batch: 405, Step num: 405, Learning rate: 0.00028300, Avg batch loss: 0.7470, Avg batch acc: 0.3100
Train, Epoch: 1, Batch: 406, Step num: 406, Learning rate: 0.00028370, Avg batch loss: 0.7168, Avg batch acc: 0.3542
Train, Epoch: 1, Batch: 407, Step num: 407, Learning rate: 0.00028440, Avg batch loss: 0.7442, Avg batch acc: 0.3221
Train, Epoch: 1, Batch: 408, Step num: 408, Learning rate: 0.00028510, Avg batch loss: 0.7734, Avg batch acc: 0.3416
Train, Epoch: 1, Batch: 409, Step num: 409, Learning rate: 0.00028580, Avg batch loss: 0.7500, Avg batch acc: 0.3302
Train, Epoch: 1, Batch: 410, Step num: 410, Learning rate: 0.00028650, Avg batch loss: 0.7422, Avg batch acc: 0.3366
Train, Epoch: 1, Batch: 411, Step num: 411, Learning rate: 0.00028719, Avg batch loss: 0.7229, Avg batch acc: 0.3438
Train, Epoch: 1, Batch: 412, Step num: 412, Learning rate: 0.00028789, Avg batch loss: 0.7410, Avg batch acc: 0.3553
Train, Epoch: 1, Batch: 413, Step num: 413, Learning rate: 0.00028859, Avg batch loss: 0.6462, Avg batch acc: 0.3725
Train, Epoch: 1, Batch: 414, Step num: 414, Learning rate: 0.00028929, Avg batch loss: 0.7442, Avg batch acc: 0.3293
Train, Epoch: 1, Batch: 415, Step num: 415, Learning rate: 0.00028999, Avg batch loss: 0.7157, Avg batch acc: 0.3311
Train, Epoch: 1, Batch: 416, Step num: 416, Learning rate: 0.00029069, Avg batch loss: 0.7076, Avg batch acc: 0.3479
Train, Epoch: 1, Batch: 417, Step num: 417, Learning rate: 0.00029139, Avg batch loss: 0.6970, Avg batch acc: 0.3554
Train, Epoch: 1, Batch: 418, Step num: 418, Learning rate: 0.00029209, Avg batch loss: 0.7896, Avg batch acc: 0.3433
Train, Epoch: 1, Batch: 419, Step num: 419, Learning rate: 0.00029279, Avg batch loss: 0.6973, Avg batch acc: 0.3541
Train, Epoch: 1, Batch: 420, Step num: 420, Learning rate: 0.00029348, Avg batch loss: 0.7035, Avg batch acc: 0.3489
Train, Epoch: 1, Batch: 421, Step num: 421, Learning rate: 0.00029418, Avg batch loss: 0.7964, Avg batch acc: 0.3387
Train, Epoch: 1, Batch: 422, Step num: 422, Learning rate: 0.00029488, Avg batch loss: 0.7202, Avg batch acc: 0.3436
Train, Epoch: 1, Batch: 423, Step num: 423, Learning rate: 0.00029558, Avg batch loss: 0.6845, Avg batch acc: 0.3454
Train, Epoch: 1, Batch: 424, Step num: 424, Learning rate: 0.00029628, Avg batch loss: 0.6907, Avg batch acc: 0.3324
Train, Epoch: 1, Batch: 425, Step num: 425, Learning rate: 0.00029698, Avg batch loss: 0.7647, Avg batch acc: 0.3399
Train, Epoch: 1, Batch: 426, Step num: 426, Learning rate: 0.00029768, Avg batch loss: 0.7534, Avg batch acc: 0.3384
Train, Epoch: 1, Batch: 427, Step num: 427, Learning rate: 0.00029838, Avg batch loss: 0.7113, Avg batch acc: 0.3319
Train, Epoch: 1, Batch: 428, Step num: 428, Learning rate: 0.00029907, Avg batch loss: 0.7144, Avg batch acc: 0.3374
Train, Epoch: 1, Batch: 429, Step num: 429, Learning rate: 0.00029977, Avg batch loss: 0.6410, Avg batch acc: 0.3768
Train, Epoch: 1, Batch: 430, Step num: 430, Learning rate: 0.00030047, Avg batch loss: 0.6863, Avg batch acc: 0.3483
Train, Epoch: 1, Batch: 431, Step num: 431, Learning rate: 0.00030117, Avg batch loss: 0.6999, Avg batch acc: 0.3370
Train, Epoch: 1, Batch: 432, Step num: 432, Learning rate: 0.00030187, Avg batch loss: 0.6964, Avg batch acc: 0.3282
Train, Epoch: 1, Batch: 433, Step num: 433, Learning rate: 0.00030257, Avg batch loss: 0.7398, Avg batch acc: 0.3125
Train, Epoch: 1, Batch: 434, Step num: 434, Learning rate: 0.00030327, Avg batch loss: 0.6964, Avg batch acc: 0.3519
Train, Epoch: 1, Batch: 435, Step num: 435, Learning rate: 0.00030397, Avg batch loss: 0.7006, Avg batch acc: 0.3756
Train, Epoch: 1, Batch: 436, Step num: 436, Learning rate: 0.00030466, Avg batch loss: 0.7205, Avg batch acc: 0.3495
Train, Epoch: 1, Batch: 437, Step num: 437, Learning rate: 0.00030536, Avg batch loss: 0.6290, Avg batch acc: 0.3653
Train, Epoch: 1, Batch: 438, Step num: 438, Learning rate: 0.00030606, Avg batch loss: 0.7231, Avg batch acc: 0.3585
Train, Epoch: 1, Batch: 439, Step num: 439, Learning rate: 0.00030676, Avg batch loss: 0.6659, Avg batch acc: 0.3657
Train, Epoch: 1, Batch: 440, Step num: 440, Learning rate: 0.00030746, Avg batch loss: 0.8182, Avg batch acc: 0.3296
Train, Epoch: 1, Batch: 441, Step num: 441, Learning rate: 0.00030816, Avg batch loss: 0.7656, Avg batch acc: 0.3503
Train, Epoch: 1, Batch: 442, Step num: 442, Learning rate: 0.00030886, Avg batch loss: 0.7310, Avg batch acc: 0.3469
Train, Epoch: 1, Batch: 443, Step num: 443, Learning rate: 0.00030956, Avg batch loss: 0.7012, Avg batch acc: 0.3640
Train, Epoch: 1, Batch: 444, Step num: 444, Learning rate: 0.00031025, Avg batch loss: 0.6193, Avg batch acc: 0.3701
Train, Epoch: 1, Batch: 445, Step num: 445, Learning rate: 0.00031095, Avg batch loss: 0.6473, Avg batch acc: 0.3768
Train, Epoch: 1, Batch: 446, Step num: 446, Learning rate: 0.00031165, Avg batch loss: 0.7210, Avg batch acc: 0.3577
Train, Epoch: 1, Batch: 447, Step num: 447, Learning rate: 0.00031235, Avg batch loss: 0.6721, Avg batch acc: 0.3676
Train, Epoch: 1, Batch: 448, Step num: 448, Learning rate: 0.00031305, Avg batch loss: 0.7308, Avg batch acc: 0.3304
Train, Epoch: 1, Batch: 449, Step num: 449, Learning rate: 0.00031375, Avg batch loss: 0.6878, Avg batch acc: 0.3503
Train, Epoch: 1, Batch: 450, Step num: 450, Learning rate: 0.00031445, Avg batch loss: 0.7608, Avg batch acc: 0.3369
Train, Epoch: 1, Batch: 451, Step num: 451, Learning rate: 0.00031515, Avg batch loss: 0.7153, Avg batch acc: 0.3451
Train, Epoch: 1, Batch: 452, Step num: 452, Learning rate: 0.00031584, Avg batch loss: 0.6880, Avg batch acc: 0.3413
Train, Epoch: 1, Batch: 453, Step num: 453, Learning rate: 0.00031654, Avg batch loss: 0.6771, Avg batch acc: 0.3619
Train, Epoch: 1, Batch: 454, Step num: 454, Learning rate: 0.00031724, Avg batch loss: 0.7306, Avg batch acc: 0.3419
Train, Epoch: 1, Batch: 455, Step num: 455, Learning rate: 0.00031794, Avg batch loss: 0.6650, Avg batch acc: 0.3613
Train, Epoch: 1, Batch: 456, Step num: 456, Learning rate: 0.00031864, Avg batch loss: 0.7064, Avg batch acc: 0.3659
Train, Epoch: 1, Batch: 457, Step num: 457, Learning rate: 0.00031934, Avg batch loss: 0.6690, Avg batch acc: 0.3768
Train, Epoch: 1, Batch: 458, Step num: 458, Learning rate: 0.00032004, Avg batch loss: 0.6880, Avg batch acc: 0.3657
Train, Epoch: 1, Batch: 459, Step num: 459, Learning rate: 0.00032074, Avg batch loss: 0.6691, Avg batch acc: 0.3636
Train, Epoch: 1, Batch: 460, Step num: 460, Learning rate: 0.00032143, Avg batch loss: 0.6900, Avg batch acc: 0.3677
Train, Epoch: 1, Batch: 461, Step num: 461, Learning rate: 0.00032213, Avg batch loss: 0.6994, Avg batch acc: 0.3375
Train, Epoch: 1, Batch: 462, Step num: 462, Learning rate: 0.00032283, Avg batch loss: 0.7264, Avg batch acc: 0.3517
Train, Epoch: 1, Batch: 463, Step num: 463, Learning rate: 0.00032353, Avg batch loss: 0.6561, Avg batch acc: 0.3544
Train, Epoch: 1, Batch: 464, Step num: 464, Learning rate: 0.00032423, Avg batch loss: 0.7053, Avg batch acc: 0.3683
Train, Epoch: 1, Batch: 465, Step num: 465, Learning rate: 0.00032493, Avg batch loss: 0.6346, Avg batch acc: 0.3729
Train, Epoch: 1, Batch: 466, Step num: 466, Learning rate: 0.00032563, Avg batch loss: 0.7942, Avg batch acc: 0.3241
Train, Epoch: 1, Batch: 467, Step num: 467, Learning rate: 0.00032633, Avg batch loss: 0.7258, Avg batch acc: 0.3428
Train, Epoch: 1, Batch: 468, Step num: 468, Learning rate: 0.00032702, Avg batch loss: 0.6669, Avg batch acc: 0.3602
Train, Epoch: 1, Batch: 469, Step num: 469, Learning rate: 0.00032772, Avg batch loss: 0.6350, Avg batch acc: 0.3662
Train, Epoch: 1, Batch: 470, Step num: 470, Learning rate: 0.00032842, Avg batch loss: 0.6644, Avg batch acc: 0.3561
Train, Epoch: 1, Batch: 471, Step num: 471, Learning rate: 0.00032912, Avg batch loss: 0.7123, Avg batch acc: 0.3450
Train, Epoch: 1, Batch: 472, Step num: 472, Learning rate: 0.00032982, Avg batch loss: 0.7002, Avg batch acc: 0.3624
Train, Epoch: 1, Batch: 473, Step num: 473, Learning rate: 0.00033052, Avg batch loss: 0.6572, Avg batch acc: 0.3736
Train, Epoch: 1, Batch: 474, Step num: 474, Learning rate: 0.00033122, Avg batch loss: 0.7780, Avg batch acc: 0.3443
Train, Epoch: 1, Batch: 475, Step num: 475, Learning rate: 0.00033192, Avg batch loss: 0.6867, Avg batch acc: 0.3604
Train, Epoch: 1, Batch: 476, Step num: 476, Learning rate: 0.00033262, Avg batch loss: 0.6839, Avg batch acc: 0.3532
Train, Epoch: 1, Batch: 477, Step num: 477, Learning rate: 0.00033331, Avg batch loss: 0.7120, Avg batch acc: 0.3504
Train, Epoch: 1, Batch: 478, Step num: 478, Learning rate: 0.00033401, Avg batch loss: 0.6959, Avg batch acc: 0.3792
Train, Epoch: 1, Batch: 479, Step num: 479, Learning rate: 0.00033471, Avg batch loss: 0.7526, Avg batch acc: 0.3500
Train, Epoch: 1, Batch: 480, Step num: 480, Learning rate: 0.00033541, Avg batch loss: 0.7124, Avg batch acc: 0.3494
Train, Epoch: 1, Batch: 481, Step num: 481, Learning rate: 0.00033611, Avg batch loss: 0.6862, Avg batch acc: 0.3589
Train, Epoch: 1, Batch: 482, Step num: 482, Learning rate: 0.00033681, Avg batch loss: 0.7143, Avg batch acc: 0.3528
Train, Epoch: 1, Batch: 483, Step num: 483, Learning rate: 0.00033751, Avg batch loss: 0.6435, Avg batch acc: 0.3607
Train, Epoch: 1, Batch: 484, Step num: 484, Learning rate: 0.00033821, Avg batch loss: 0.6310, Avg batch acc: 0.3666
Train, Epoch: 1, Batch: 485, Step num: 485, Learning rate: 0.00033890, Avg batch loss: 0.7113, Avg batch acc: 0.3620
Train, Epoch: 1, Batch: 486, Step num: 486, Learning rate: 0.00033960, Avg batch loss: 0.6737, Avg batch acc: 0.3679
Train, Epoch: 1, Batch: 487, Step num: 487, Learning rate: 0.00034030, Avg batch loss: 0.7158, Avg batch acc: 0.3658
Train, Epoch: 1, Batch: 488, Step num: 488, Learning rate: 0.00034100, Avg batch loss: 0.7038, Avg batch acc: 0.3555
Train, Epoch: 1, Batch: 489, Step num: 489, Learning rate: 0.00034170, Avg batch loss: 0.6786, Avg batch acc: 0.3626
Train, Epoch: 1, Batch: 490, Step num: 490, Learning rate: 0.00034240, Avg batch loss: 0.7353, Avg batch acc: 0.3423
Train, Epoch: 1, Batch: 491, Step num: 491, Learning rate: 0.00034310, Avg batch loss: 0.6646, Avg batch acc: 0.3607
Train, Epoch: 1, Batch: 492, Step num: 492, Learning rate: 0.00034380, Avg batch loss: 0.7117, Avg batch acc: 0.3522
Train, Epoch: 1, Batch: 493, Step num: 493, Learning rate: 0.00034449, Avg batch loss: 0.6718, Avg batch acc: 0.3558
Train, Epoch: 1, Batch: 494, Step num: 494, Learning rate: 0.00034519, Avg batch loss: 0.6559, Avg batch acc: 0.3626
Train, Epoch: 1, Batch: 495, Step num: 495, Learning rate: 0.00034589, Avg batch loss: 0.6553, Avg batch acc: 0.3860
Train, Epoch: 1, Batch: 496, Step num: 496, Learning rate: 0.00034659, Avg batch loss: 0.7007, Avg batch acc: 0.3419
Train, Epoch: 1, Batch: 497, Step num: 497, Learning rate: 0.00034729, Avg batch loss: 0.6205, Avg batch acc: 0.3801
Train, Epoch: 1, Batch: 498, Step num: 498, Learning rate: 0.00034799, Avg batch loss: 0.5826, Avg batch acc: 0.3677
Train, Epoch: 1, Batch: 499, Step num: 499, Learning rate: 0.00034869, Avg batch loss: 0.7533, Avg batch acc: 0.3632
Train, Epoch: 1, Batch: 500, Step num: 500, Learning rate: 0.00034939, Avg batch loss: 0.6968, Avg batch acc: 0.3633
Train, Epoch: 1, Batch: 501, Step num: 501, Learning rate: 0.00035008, Avg batch loss: 0.7314, Avg batch acc: 0.3676
Train, Epoch: 1, Batch: 502, Step num: 502, Learning rate: 0.00035078, Avg batch loss: 0.6849, Avg batch acc: 0.3771
Train, Epoch: 1, Batch: 503, Step num: 503, Learning rate: 0.00035148, Avg batch loss: 0.7076, Avg batch acc: 0.3424
Train, Epoch: 1, Batch: 504, Step num: 504, Learning rate: 0.00035218, Avg batch loss: 0.6444, Avg batch acc: 0.3576
Train, Epoch: 1, Batch: 505, Step num: 505, Learning rate: 0.00035288, Avg batch loss: 0.6988, Avg batch acc: 0.3611
Train, Epoch: 1, Batch: 506, Step num: 506, Learning rate: 0.00035358, Avg batch loss: 0.6802, Avg batch acc: 0.3447
Train, Epoch: 1, Batch: 507, Step num: 507, Learning rate: 0.00035428, Avg batch loss: 0.6623, Avg batch acc: 0.3517
Train, Epoch: 1, Batch: 508, Step num: 508, Learning rate: 0.00035498, Avg batch loss: 0.5890, Avg batch acc: 0.3929
Train, Epoch: 1, Batch: 509, Step num: 509, Learning rate: 0.00035567, Avg batch loss: 0.7171, Avg batch acc: 0.3231
Train, Epoch: 1, Batch: 510, Step num: 510, Learning rate: 0.00035637, Avg batch loss: 0.7334, Avg batch acc: 0.3605
Train, Epoch: 1, Batch: 511, Step num: 511, Learning rate: 0.00035707, Avg batch loss: 0.6985, Avg batch acc: 0.3605
Train, Epoch: 1, Batch: 512, Step num: 512, Learning rate: 0.00035777, Avg batch loss: 0.7283, Avg batch acc: 0.3448
Train, Epoch: 1, Batch: 513, Step num: 513, Learning rate: 0.00035847, Avg batch loss: 0.7059, Avg batch acc: 0.3466
Train, Epoch: 1, Batch: 514, Step num: 514, Learning rate: 0.00035917, Avg batch loss: 0.6839, Avg batch acc: 0.3674
Train, Epoch: 1, Batch: 515, Step num: 515, Learning rate: 0.00035987, Avg batch loss: 0.6731, Avg batch acc: 0.3453
Train, Epoch: 1, Batch: 516, Step num: 516, Learning rate: 0.00036057, Avg batch loss: 0.6084, Avg batch acc: 0.3796
Train, Epoch: 1, Batch: 517, Step num: 517, Learning rate: 0.00036126, Avg batch loss: 0.6445, Avg batch acc: 0.3701
Train, Epoch: 1, Batch: 518, Step num: 518, Learning rate: 0.00036196, Avg batch loss: 0.7878, Avg batch acc: 0.3553
Train, Epoch: 1, Batch: 519, Step num: 519, Learning rate: 0.00036266, Avg batch loss: 0.6800, Avg batch acc: 0.3553
Train, Epoch: 1, Batch: 520, Step num: 520, Learning rate: 0.00036336, Avg batch loss: 0.6340, Avg batch acc: 0.3622
Train, Epoch: 1, Batch: 521, Step num: 521, Learning rate: 0.00036406, Avg batch loss: 0.6593, Avg batch acc: 0.3846
Train, Epoch: 1, Batch: 522, Step num: 522, Learning rate: 0.00036476, Avg batch loss: 0.6868, Avg batch acc: 0.3614
Train, Epoch: 1, Batch: 523, Step num: 523, Learning rate: 0.00036546, Avg batch loss: 0.6712, Avg batch acc: 0.3480
Train, Epoch: 1, Batch: 524, Step num: 524, Learning rate: 0.00036616, Avg batch loss: 0.7189, Avg batch acc: 0.3533
Train, Epoch: 1, Batch: 525, Step num: 525, Learning rate: 0.00036685, Avg batch loss: 0.6674, Avg batch acc: 0.3640
Train, Epoch: 1, Batch: 526, Step num: 526, Learning rate: 0.00036755, Avg batch loss: 0.6982, Avg batch acc: 0.3509
Train, Epoch: 1, Batch: 527, Step num: 527, Learning rate: 0.00036825, Avg batch loss: 0.6408, Avg batch acc: 0.3717
Train, Epoch: 1, Batch: 528, Step num: 528, Learning rate: 0.00036895, Avg batch loss: 0.6619, Avg batch acc: 0.3528
Train, Epoch: 1, Batch: 529, Step num: 529, Learning rate: 0.00036965, Avg batch loss: 0.6912, Avg batch acc: 0.3599
Train, Epoch: 1, Batch: 530, Step num: 530, Learning rate: 0.00037035, Avg batch loss: 0.5588, Avg batch acc: 0.3666
Train, Epoch: 1, Batch: 531, Step num: 531, Learning rate: 0.00037105, Avg batch loss: 0.7605, Avg batch acc: 0.3489
Train, Epoch: 1, Batch: 532, Step num: 532, Learning rate: 0.00037175, Avg batch loss: 0.6099, Avg batch acc: 0.3784
Train, Epoch: 1, Batch: 533, Step num: 533, Learning rate: 0.00037245, Avg batch loss: 0.6724, Avg batch acc: 0.3748
Train, Epoch: 1, Batch: 534, Step num: 534, Learning rate: 0.00037314, Avg batch loss: 0.6405, Avg batch acc: 0.3713
Train, Epoch: 1, Batch: 535, Step num: 535, Learning rate: 0.00037384, Avg batch loss: 0.6896, Avg batch acc: 0.3576
Train, Epoch: 1, Batch: 536, Step num: 536, Learning rate: 0.00037454, Avg batch loss: 0.6653, Avg batch acc: 0.3900
Train, Epoch: 1, Batch: 537, Step num: 537, Learning rate: 0.00037524, Avg batch loss: 0.6405, Avg batch acc: 0.3803
Train, Epoch: 1, Batch: 538, Step num: 538, Learning rate: 0.00037594, Avg batch loss: 0.6655, Avg batch acc: 0.3601
Train, Epoch: 1, Batch: 539, Step num: 539, Learning rate: 0.00037664, Avg batch loss: 0.6930, Avg batch acc: 0.3621
Train, Epoch: 1, Batch: 540, Step num: 540, Learning rate: 0.00037734, Avg batch loss: 0.6642, Avg batch acc: 0.3756
Train, Epoch: 1, Batch: 541, Step num: 541, Learning rate: 0.00037804, Avg batch loss: 0.6978, Avg batch acc: 0.3790
Train, Epoch: 1, Batch: 542, Step num: 542, Learning rate: 0.00037873, Avg batch loss: 0.5972, Avg batch acc: 0.3865
Train, Epoch: 1, Batch: 543, Step num: 543, Learning rate: 0.00037943, Avg batch loss: 0.6424, Avg batch acc: 0.3900
Train, Epoch: 1, Batch: 544, Step num: 544, Learning rate: 0.00038013, Avg batch loss: 0.7107, Avg batch acc: 0.3446
Train, Epoch: 1, Batch: 545, Step num: 545, Learning rate: 0.00038083, Avg batch loss: 0.6600, Avg batch acc: 0.3934
Train, Epoch: 1, Batch: 546, Step num: 546, Learning rate: 0.00038153, Avg batch loss: 0.6532, Avg batch acc: 0.3576
Train, Epoch: 1, Batch: 547, Step num: 547, Learning rate: 0.00038223, Avg batch loss: 0.6756, Avg batch acc: 0.3637
Train, Epoch: 1, Batch: 548, Step num: 548, Learning rate: 0.00038293, Avg batch loss: 0.6486, Avg batch acc: 0.3577
Train, Epoch: 1, Batch: 549, Step num: 549, Learning rate: 0.00038363, Avg batch loss: 0.6982, Avg batch acc: 0.3560
Train, Epoch: 1, Batch: 550, Step num: 550, Learning rate: 0.00038432, Avg batch loss: 0.6626, Avg batch acc: 0.3620
Train, Epoch: 1, Batch: 551, Step num: 551, Learning rate: 0.00038502, Avg batch loss: 0.6701, Avg batch acc: 0.3866
Train, Epoch: 1, Batch: 552, Step num: 552, Learning rate: 0.00038572, Avg batch loss: 0.6440, Avg batch acc: 0.3753
Train, Epoch: 1, Batch: 553, Step num: 553, Learning rate: 0.00038642, Avg batch loss: 0.6655, Avg batch acc: 0.3855
Train, Epoch: 1, Batch: 554, Step num: 554, Learning rate: 0.00038712, Avg batch loss: 0.5748, Avg batch acc: 0.4019
Train, Epoch: 1, Batch: 555, Step num: 555, Learning rate: 0.00038782, Avg batch loss: 0.6615, Avg batch acc: 0.3758
Train, Epoch: 1, Batch: 556, Step num: 556, Learning rate: 0.00038852, Avg batch loss: 0.5636, Avg batch acc: 0.3708
Train, Epoch: 1, Batch: 557, Step num: 557, Learning rate: 0.00038922, Avg batch loss: 0.6514, Avg batch acc: 0.3884
Train, Epoch: 1, Batch: 558, Step num: 558, Learning rate: 0.00038991, Avg batch loss: 0.6694, Avg batch acc: 0.3644
Train, Epoch: 1, Batch: 559, Step num: 559, Learning rate: 0.00039061, Avg batch loss: 0.6788, Avg batch acc: 0.3532
Train, Epoch: 1, Batch: 560, Step num: 560, Learning rate: 0.00039131, Avg batch loss: 0.6728, Avg batch acc: 0.3821
Train, Epoch: 1, Batch: 561, Step num: 561, Learning rate: 0.00039201, Avg batch loss: 0.5995, Avg batch acc: 0.3923
Train, Epoch: 1, Batch: 562, Step num: 562, Learning rate: 0.00039271, Avg batch loss: 0.6794, Avg batch acc: 0.3739
Train, Epoch: 1, Batch: 563, Step num: 563, Learning rate: 0.00039341, Avg batch loss: 0.6629, Avg batch acc: 0.3629
Train, Epoch: 1, Batch: 564, Step num: 564, Learning rate: 0.00039411, Avg batch loss: 0.6544, Avg batch acc: 0.3718
Train, Epoch: 1, Batch: 565, Step num: 565, Learning rate: 0.00039481, Avg batch loss: 0.6000, Avg batch acc: 0.3749
Train, Epoch: 1, Batch: 566, Step num: 566, Learning rate: 0.00039550, Avg batch loss: 0.6384, Avg batch acc: 0.3772
Train, Epoch: 1, Batch: 567, Step num: 567, Learning rate: 0.00039620, Avg batch loss: 0.7119, Avg batch acc: 0.3584
Train, Epoch: 1, Batch: 568, Step num: 568, Learning rate: 0.00039690, Avg batch loss: 0.6447, Avg batch acc: 0.3746
Train, Epoch: 1, Batch: 569, Step num: 569, Learning rate: 0.00039760, Avg batch loss: 0.7055, Avg batch acc: 0.3554
Train, Epoch: 1, Batch: 570, Step num: 570, Learning rate: 0.00039830, Avg batch loss: 0.7247, Avg batch acc: 0.3545
Train, Epoch: 1, Batch: 571, Step num: 571, Learning rate: 0.00039900, Avg batch loss: 0.6017, Avg batch acc: 0.3954
Train, Epoch: 1, Batch: 572, Step num: 572, Learning rate: 0.00039970, Avg batch loss: 0.6711, Avg batch acc: 0.3483
Train, Epoch: 1, Batch: 573, Step num: 573, Learning rate: 0.00040040, Avg batch loss: 0.5751, Avg batch acc: 0.4042
Train, Epoch: 1, Batch: 574, Step num: 574, Learning rate: 0.00040109, Avg batch loss: 0.5891, Avg batch acc: 0.3727
Train, Epoch: 1, Batch: 575, Step num: 575, Learning rate: 0.00040179, Avg batch loss: 0.6644, Avg batch acc: 0.3878
Train, Epoch: 1, Batch: 576, Step num: 576, Learning rate: 0.00040249, Avg batch loss: 0.7175, Avg batch acc: 0.3756
Train, Epoch: 1, Batch: 577, Step num: 577, Learning rate: 0.00040319, Avg batch loss: 0.7069, Avg batch acc: 0.3693
Train, Epoch: 1, Batch: 578, Step num: 578, Learning rate: 0.00040389, Avg batch loss: 0.6911, Avg batch acc: 0.3719
Train, Epoch: 1, Batch: 579, Step num: 579, Learning rate: 0.00040459, Avg batch loss: 0.6209, Avg batch acc: 0.3607
Train, Epoch: 1, Batch: 580, Step num: 580, Learning rate: 0.00040529, Avg batch loss: 0.6605, Avg batch acc: 0.3815
Train, Epoch: 1, Batch: 581, Step num: 581, Learning rate: 0.00040599, Avg batch loss: 0.6687, Avg batch acc: 0.3737
Train, Epoch: 1, Batch: 582, Step num: 582, Learning rate: 0.00040668, Avg batch loss: 0.6507, Avg batch acc: 0.3868
Train, Epoch: 1, Batch: 583, Step num: 583, Learning rate: 0.00040738, Avg batch loss: 0.6542, Avg batch acc: 0.3700
Train, Epoch: 1, Batch: 584, Step num: 584, Learning rate: 0.00040808, Avg batch loss: 0.6344, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 585, Step num: 585, Learning rate: 0.00040878, Avg batch loss: 0.6490, Avg batch acc: 0.3544
Train, Epoch: 1, Batch: 586, Step num: 586, Learning rate: 0.00040948, Avg batch loss: 0.6924, Avg batch acc: 0.3584
Train, Epoch: 1, Batch: 587, Step num: 587, Learning rate: 0.00041018, Avg batch loss: 0.6707, Avg batch acc: 0.3517
Train, Epoch: 1, Batch: 588, Step num: 588, Learning rate: 0.00041088, Avg batch loss: 0.7024, Avg batch acc: 0.3604
Train, Epoch: 1, Batch: 589, Step num: 589, Learning rate: 0.00041158, Avg batch loss: 0.6125, Avg batch acc: 0.3542
Train, Epoch: 1, Batch: 590, Step num: 590, Learning rate: 0.00041228, Avg batch loss: 0.6572, Avg batch acc: 0.3743
Train, Epoch: 1, Batch: 591, Step num: 591, Learning rate: 0.00041297, Avg batch loss: 0.7056, Avg batch acc: 0.3534
Train, Epoch: 1, Batch: 592, Step num: 592, Learning rate: 0.00041367, Avg batch loss: 0.6826, Avg batch acc: 0.3552
Train, Epoch: 1, Batch: 593, Step num: 593, Learning rate: 0.00041437, Avg batch loss: 0.6504, Avg batch acc: 0.3871
Train, Epoch: 1, Batch: 594, Step num: 594, Learning rate: 0.00041507, Avg batch loss: 0.6264, Avg batch acc: 0.3852
Train, Epoch: 1, Batch: 595, Step num: 595, Learning rate: 0.00041577, Avg batch loss: 0.6502, Avg batch acc: 0.3759
Train, Epoch: 1, Batch: 596, Step num: 596, Learning rate: 0.00041647, Avg batch loss: 0.6774, Avg batch acc: 0.3659
Train, Epoch: 1, Batch: 597, Step num: 597, Learning rate: 0.00041717, Avg batch loss: 0.6015, Avg batch acc: 0.3947
Train, Epoch: 1, Batch: 598, Step num: 598, Learning rate: 0.00041787, Avg batch loss: 0.6188, Avg batch acc: 0.3939
Train, Epoch: 1, Batch: 599, Step num: 599, Learning rate: 0.00041856, Avg batch loss: 0.6513, Avg batch acc: 0.3685
Train, Epoch: 1, Batch: 600, Step num: 600, Learning rate: 0.00041926, Avg batch loss: 0.6564, Avg batch acc: 0.3849
Train, Epoch: 1, Batch: 601, Step num: 601, Learning rate: 0.00041996, Avg batch loss: 0.6175, Avg batch acc: 0.3982
Train, Epoch: 1, Batch: 602, Step num: 602, Learning rate: 0.00042066, Avg batch loss: 0.6654, Avg batch acc: 0.3892
Train, Epoch: 1, Batch: 603, Step num: 603, Learning rate: 0.00042136, Avg batch loss: 0.6331, Avg batch acc: 0.3657
Train, Epoch: 1, Batch: 604, Step num: 604, Learning rate: 0.00042206, Avg batch loss: 0.6471, Avg batch acc: 0.3679
Train, Epoch: 1, Batch: 605, Step num: 605, Learning rate: 0.00042276, Avg batch loss: 0.6961, Avg batch acc: 0.3384
Train, Epoch: 1, Batch: 606, Step num: 606, Learning rate: 0.00042346, Avg batch loss: 0.6742, Avg batch acc: 0.3578
Train, Epoch: 1, Batch: 607, Step num: 607, Learning rate: 0.00042415, Avg batch loss: 0.6974, Avg batch acc: 0.3737
Train, Epoch: 1, Batch: 608, Step num: 608, Learning rate: 0.00042485, Avg batch loss: 0.6823, Avg batch acc: 0.3653
Train, Epoch: 1, Batch: 609, Step num: 609, Learning rate: 0.00042555, Avg batch loss: 0.6694, Avg batch acc: 0.3661
Train, Epoch: 1, Batch: 610, Step num: 610, Learning rate: 0.00042625, Avg batch loss: 0.6597, Avg batch acc: 0.3831
Train, Epoch: 1, Batch: 611, Step num: 611, Learning rate: 0.00042695, Avg batch loss: 0.6838, Avg batch acc: 0.3748
Train, Epoch: 1, Batch: 612, Step num: 612, Learning rate: 0.00042765, Avg batch loss: 0.6387, Avg batch acc: 0.3714
Train, Epoch: 1, Batch: 613, Step num: 613, Learning rate: 0.00042835, Avg batch loss: 0.6216, Avg batch acc: 0.3861
Train, Epoch: 1, Batch: 614, Step num: 614, Learning rate: 0.00042905, Avg batch loss: 0.5932, Avg batch acc: 0.3905
Train, Epoch: 1, Batch: 615, Step num: 615, Learning rate: 0.00042974, Avg batch loss: 0.6582, Avg batch acc: 0.4000
Train, Epoch: 1, Batch: 616, Step num: 616, Learning rate: 0.00043044, Avg batch loss: 0.7113, Avg batch acc: 0.3650
Train, Epoch: 1, Batch: 617, Step num: 617, Learning rate: 0.00043114, Avg batch loss: 0.6691, Avg batch acc: 0.3842
Train, Epoch: 1, Batch: 618, Step num: 618, Learning rate: 0.00043184, Avg batch loss: 0.6714, Avg batch acc: 0.3899
Train, Epoch: 1, Batch: 619, Step num: 619, Learning rate: 0.00043254, Avg batch loss: 0.6117, Avg batch acc: 0.3806
Train, Epoch: 1, Batch: 620, Step num: 620, Learning rate: 0.00043324, Avg batch loss: 0.6557, Avg batch acc: 0.3946
Train, Epoch: 1, Batch: 621, Step num: 621, Learning rate: 0.00043394, Avg batch loss: 0.6547, Avg batch acc: 0.3755
Train, Epoch: 1, Batch: 622, Step num: 622, Learning rate: 0.00043464, Avg batch loss: 0.6354, Avg batch acc: 0.3870
Train, Epoch: 1, Batch: 623, Step num: 623, Learning rate: 0.00043533, Avg batch loss: 0.7040, Avg batch acc: 0.3827
Train, Epoch: 1, Batch: 624, Step num: 624, Learning rate: 0.00043603, Avg batch loss: 0.6406, Avg batch acc: 0.3757
Train, Epoch: 1, Batch: 625, Step num: 625, Learning rate: 0.00043673, Avg batch loss: 0.6110, Avg batch acc: 0.3835
Train, Epoch: 1, Batch: 626, Step num: 626, Learning rate: 0.00043743, Avg batch loss: 0.6328, Avg batch acc: 0.3830
Train, Epoch: 1, Batch: 627, Step num: 627, Learning rate: 0.00043813, Avg batch loss: 0.5886, Avg batch acc: 0.3840
Train, Epoch: 1, Batch: 628, Step num: 628, Learning rate: 0.00043883, Avg batch loss: 0.6360, Avg batch acc: 0.3756
Train, Epoch: 1, Batch: 629, Step num: 629, Learning rate: 0.00043953, Avg batch loss: 0.6216, Avg batch acc: 0.4014
Train, Epoch: 1, Batch: 630, Step num: 630, Learning rate: 0.00044023, Avg batch loss: 0.6165, Avg batch acc: 0.3782
Train, Epoch: 1, Batch: 631, Step num: 631, Learning rate: 0.00044092, Avg batch loss: 0.5870, Avg batch acc: 0.3912
Train, Epoch: 1, Batch: 632, Step num: 632, Learning rate: 0.00044162, Avg batch loss: 0.6491, Avg batch acc: 0.3698
Train, Epoch: 1, Batch: 633, Step num: 633, Learning rate: 0.00044232, Avg batch loss: 0.6811, Avg batch acc: 0.3845
Train, Epoch: 1, Batch: 634, Step num: 634, Learning rate: 0.00044302, Avg batch loss: 0.6743, Avg batch acc: 0.3669
Train, Epoch: 1, Batch: 635, Step num: 635, Learning rate: 0.00044372, Avg batch loss: 0.6146, Avg batch acc: 0.3874
Train, Epoch: 1, Batch: 636, Step num: 636, Learning rate: 0.00044442, Avg batch loss: 0.6614, Avg batch acc: 0.3613
Train, Epoch: 1, Batch: 637, Step num: 637, Learning rate: 0.00044512, Avg batch loss: 0.6303, Avg batch acc: 0.3660
Train, Epoch: 1, Batch: 638, Step num: 638, Learning rate: 0.00044582, Avg batch loss: 0.6758, Avg batch acc: 0.3568
Train, Epoch: 1, Batch: 639, Step num: 639, Learning rate: 0.00044651, Avg batch loss: 0.5497, Avg batch acc: 0.3904
Train, Epoch: 1, Batch: 640, Step num: 640, Learning rate: 0.00044721, Avg batch loss: 0.6689, Avg batch acc: 0.3679
Train, Epoch: 1, Batch: 641, Step num: 641, Learning rate: 0.00044791, Avg batch loss: 0.6642, Avg batch acc: 0.3777
Train, Epoch: 1, Batch: 642, Step num: 642, Learning rate: 0.00044861, Avg batch loss: 0.7163, Avg batch acc: 0.3536
Train, Epoch: 1, Batch: 643, Step num: 643, Learning rate: 0.00044931, Avg batch loss: 0.6671, Avg batch acc: 0.3674
Train, Epoch: 1, Batch: 644, Step num: 644, Learning rate: 0.00045001, Avg batch loss: 0.6945, Avg batch acc: 0.3805
Train, Epoch: 1, Batch: 645, Step num: 645, Learning rate: 0.00045071, Avg batch loss: 0.6282, Avg batch acc: 0.3804
Train, Epoch: 1, Batch: 646, Step num: 646, Learning rate: 0.00045141, Avg batch loss: 0.5556, Avg batch acc: 0.3969
Train, Epoch: 1, Batch: 647, Step num: 647, Learning rate: 0.00045210, Avg batch loss: 0.6681, Avg batch acc: 0.3739
Train, Epoch: 1, Batch: 648, Step num: 648, Learning rate: 0.00045280, Avg batch loss: 0.6434, Avg batch acc: 0.3891
Train, Epoch: 1, Batch: 649, Step num: 649, Learning rate: 0.00045350, Avg batch loss: 0.7280, Avg batch acc: 0.3761
Train, Epoch: 1, Batch: 650, Step num: 650, Learning rate: 0.00045420, Avg batch loss: 0.6380, Avg batch acc: 0.3890
Train, Epoch: 1, Batch: 651, Step num: 651, Learning rate: 0.00045490, Avg batch loss: 0.6792, Avg batch acc: 0.3714
Train, Epoch: 1, Batch: 652, Step num: 652, Learning rate: 0.00045560, Avg batch loss: 0.7018, Avg batch acc: 0.3704
Train, Epoch: 1, Batch: 653, Step num: 653, Learning rate: 0.00045630, Avg batch loss: 0.7142, Avg batch acc: 0.3619
Train, Epoch: 1, Batch: 654, Step num: 654, Learning rate: 0.00045700, Avg batch loss: 0.6132, Avg batch acc: 0.3807
Train, Epoch: 1, Batch: 655, Step num: 655, Learning rate: 0.00045770, Avg batch loss: 0.6766, Avg batch acc: 0.3696
Train, Epoch: 1, Batch: 656, Step num: 656, Learning rate: 0.00045839, Avg batch loss: 0.6363, Avg batch acc: 0.3883
Train, Epoch: 1, Batch: 657, Step num: 657, Learning rate: 0.00045909, Avg batch loss: 0.6606, Avg batch acc: 0.3879
Train, Epoch: 1, Batch: 658, Step num: 658, Learning rate: 0.00045979, Avg batch loss: 0.5935, Avg batch acc: 0.3807
Train, Epoch: 1, Batch: 659, Step num: 659, Learning rate: 0.00046049, Avg batch loss: 0.6115, Avg batch acc: 0.3810
Train, Epoch: 1, Batch: 660, Step num: 660, Learning rate: 0.00046119, Avg batch loss: 0.6477, Avg batch acc: 0.3802
Train, Epoch: 1, Batch: 661, Step num: 661, Learning rate: 0.00046189, Avg batch loss: 0.6371, Avg batch acc: 0.3968
Train, Epoch: 1, Batch: 662, Step num: 662, Learning rate: 0.00046259, Avg batch loss: 0.6710, Avg batch acc: 0.3775
Train, Epoch: 1, Batch: 663, Step num: 663, Learning rate: 0.00046329, Avg batch loss: 0.6375, Avg batch acc: 0.3891
Train, Epoch: 1, Batch: 664, Step num: 664, Learning rate: 0.00046398, Avg batch loss: 0.6713, Avg batch acc: 0.3654
Train, Epoch: 1, Batch: 665, Step num: 665, Learning rate: 0.00046468, Avg batch loss: 0.5948, Avg batch acc: 0.3890
Train, Epoch: 1, Batch: 666, Step num: 666, Learning rate: 0.00046538, Avg batch loss: 0.5914, Avg batch acc: 0.4091
Train, Epoch: 1, Batch: 667, Step num: 667, Learning rate: 0.00046608, Avg batch loss: 0.6464, Avg batch acc: 0.3979
Train, Epoch: 1, Batch: 668, Step num: 668, Learning rate: 0.00046678, Avg batch loss: 0.6397, Avg batch acc: 0.4053
Train, Epoch: 1, Batch: 669, Step num: 669, Learning rate: 0.00046748, Avg batch loss: 0.6766, Avg batch acc: 0.3933
Train, Epoch: 1, Batch: 670, Step num: 670, Learning rate: 0.00046818, Avg batch loss: 0.6940, Avg batch acc: 0.3772
Train, Epoch: 1, Batch: 671, Step num: 671, Learning rate: 0.00046888, Avg batch loss: 0.6525, Avg batch acc: 0.3947
Train, Epoch: 1, Batch: 672, Step num: 672, Learning rate: 0.00046957, Avg batch loss: 0.6064, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 673, Step num: 673, Learning rate: 0.00047027, Avg batch loss: 0.6567, Avg batch acc: 0.3827
Train, Epoch: 1, Batch: 674, Step num: 674, Learning rate: 0.00047097, Avg batch loss: 0.6317, Avg batch acc: 0.3919
Train, Epoch: 1, Batch: 675, Step num: 675, Learning rate: 0.00047167, Avg batch loss: 0.6669, Avg batch acc: 0.3744
Train, Epoch: 1, Batch: 676, Step num: 676, Learning rate: 0.00047237, Avg batch loss: 0.6598, Avg batch acc: 0.3753
Train, Epoch: 1, Batch: 677, Step num: 677, Learning rate: 0.00047307, Avg batch loss: 0.6225, Avg batch acc: 0.3972
Train, Epoch: 1, Batch: 678, Step num: 678, Learning rate: 0.00047377, Avg batch loss: 0.6114, Avg batch acc: 0.3884
Train, Epoch: 1, Batch: 679, Step num: 679, Learning rate: 0.00047447, Avg batch loss: 0.7033, Avg batch acc: 0.3614
Train, Epoch: 1, Batch: 680, Step num: 680, Learning rate: 0.00047516, Avg batch loss: 0.5688, Avg batch acc: 0.4012
Train, Epoch: 1, Batch: 681, Step num: 681, Learning rate: 0.00047586, Avg batch loss: 0.6403, Avg batch acc: 0.3655
Train, Epoch: 1, Batch: 682, Step num: 682, Learning rate: 0.00047656, Avg batch loss: 0.6913, Avg batch acc: 0.3789
Train, Epoch: 1, Batch: 683, Step num: 683, Learning rate: 0.00047726, Avg batch loss: 0.6753, Avg batch acc: 0.3668
Train, Epoch: 1, Batch: 684, Step num: 684, Learning rate: 0.00047796, Avg batch loss: 0.6673, Avg batch acc: 0.3785
Train, Epoch: 1, Batch: 685, Step num: 685, Learning rate: 0.00047866, Avg batch loss: 0.6127, Avg batch acc: 0.3678
Train, Epoch: 1, Batch: 686, Step num: 686, Learning rate: 0.00047936, Avg batch loss: 0.6107, Avg batch acc: 0.3967
Train, Epoch: 1, Batch: 687, Step num: 687, Learning rate: 0.00048006, Avg batch loss: 0.7078, Avg batch acc: 0.3662
Train, Epoch: 1, Batch: 688, Step num: 688, Learning rate: 0.00048075, Avg batch loss: 0.6996, Avg batch acc: 0.3907
Train, Epoch: 1, Batch: 689, Step num: 689, Learning rate: 0.00048145, Avg batch loss: 0.6380, Avg batch acc: 0.3903
Train, Epoch: 1, Batch: 690, Step num: 690, Learning rate: 0.00048215, Avg batch loss: 0.6244, Avg batch acc: 0.3799
Train, Epoch: 1, Batch: 691, Step num: 691, Learning rate: 0.00048285, Avg batch loss: 0.6368, Avg batch acc: 0.3865
Train, Epoch: 1, Batch: 692, Step num: 692, Learning rate: 0.00048355, Avg batch loss: 0.6240, Avg batch acc: 0.3900
Train, Epoch: 1, Batch: 693, Step num: 693, Learning rate: 0.00048425, Avg batch loss: 0.6825, Avg batch acc: 0.3643
Train, Epoch: 1, Batch: 694, Step num: 694, Learning rate: 0.00048495, Avg batch loss: 0.5977, Avg batch acc: 0.3858
Train, Epoch: 1, Batch: 695, Step num: 695, Learning rate: 0.00048565, Avg batch loss: 0.6477, Avg batch acc: 0.3953
Train, Epoch: 1, Batch: 696, Step num: 696, Learning rate: 0.00048634, Avg batch loss: 0.6497, Avg batch acc: 0.3839
Train, Epoch: 1, Batch: 697, Step num: 697, Learning rate: 0.00048704, Avg batch loss: 0.6028, Avg batch acc: 0.3799
Train, Epoch: 1, Batch: 698, Step num: 698, Learning rate: 0.00048774, Avg batch loss: 0.6188, Avg batch acc: 0.3999
Train, Epoch: 1, Batch: 699, Step num: 699, Learning rate: 0.00048844, Avg batch loss: 0.6024, Avg batch acc: 0.3690
Train, Epoch: 1, Batch: 700, Step num: 700, Learning rate: 0.00048914, Avg batch loss: 0.6179, Avg batch acc: 0.3862
Train, Epoch: 1, Batch: 701, Step num: 701, Learning rate: 0.00048984, Avg batch loss: 0.7033, Avg batch acc: 0.3565
Train, Epoch: 1, Batch: 702, Step num: 702, Learning rate: 0.00049054, Avg batch loss: 0.6098, Avg batch acc: 0.3887
Train, Epoch: 1, Batch: 703, Step num: 703, Learning rate: 0.00049124, Avg batch loss: 0.6668, Avg batch acc: 0.3865
Train, Epoch: 1, Batch: 704, Step num: 704, Learning rate: 0.00049193, Avg batch loss: 0.5807, Avg batch acc: 0.4185
Train, Epoch: 1, Batch: 705, Step num: 705, Learning rate: 0.00049263, Avg batch loss: 0.6551, Avg batch acc: 0.3876
Train, Epoch: 1, Batch: 706, Step num: 706, Learning rate: 0.00049333, Avg batch loss: 0.6713, Avg batch acc: 0.3699
Train, Epoch: 1, Batch: 707, Step num: 707, Learning rate: 0.00049403, Avg batch loss: 0.7058, Avg batch acc: 0.3584
Train, Epoch: 1, Batch: 708, Step num: 708, Learning rate: 0.00049473, Avg batch loss: 0.6408, Avg batch acc: 0.3796
Train, Epoch: 1, Batch: 709, Step num: 709, Learning rate: 0.00049543, Avg batch loss: 0.5989, Avg batch acc: 0.3687
Train, Epoch: 1, Batch: 710, Step num: 710, Learning rate: 0.00049613, Avg batch loss: 0.5946, Avg batch acc: 0.3761
Train, Epoch: 1, Batch: 711, Step num: 711, Learning rate: 0.00049683, Avg batch loss: 0.6826, Avg batch acc: 0.3794
Train, Epoch: 1, Batch: 712, Step num: 712, Learning rate: 0.00049753, Avg batch loss: 0.6706, Avg batch acc: 0.3828
Train, Epoch: 1, Batch: 713, Step num: 713, Learning rate: 0.00049822, Avg batch loss: 0.6134, Avg batch acc: 0.3779
Train, Epoch: 1, Batch: 714, Step num: 714, Learning rate: 0.00049892, Avg batch loss: 0.6222, Avg batch acc: 0.3981
Train, Epoch: 1, Batch: 715, Step num: 715, Learning rate: 0.00049962, Avg batch loss: 0.6322, Avg batch acc: 0.3842
Train, Epoch: 1, Batch: 716, Step num: 716, Learning rate: 0.00050032, Avg batch loss: 0.6185, Avg batch acc: 0.3761
Train, Epoch: 1, Batch: 717, Step num: 717, Learning rate: 0.00050102, Avg batch loss: 0.5669, Avg batch acc: 0.3866
Train, Epoch: 1, Batch: 718, Step num: 718, Learning rate: 0.00050172, Avg batch loss: 0.6948, Avg batch acc: 0.3810
Train, Epoch: 1, Batch: 719, Step num: 719, Learning rate: 0.00050242, Avg batch loss: 0.6580, Avg batch acc: 0.3654
Train, Epoch: 1, Batch: 720, Step num: 720, Learning rate: 0.00050312, Avg batch loss: 0.6543, Avg batch acc: 0.3998
Train, Epoch: 1, Batch: 721, Step num: 721, Learning rate: 0.00050381, Avg batch loss: 0.6426, Avg batch acc: 0.3828
Train, Epoch: 1, Batch: 722, Step num: 722, Learning rate: 0.00050451, Avg batch loss: 0.6470, Avg batch acc: 0.3844
Train, Epoch: 1, Batch: 723, Step num: 723, Learning rate: 0.00050521, Avg batch loss: 0.6939, Avg batch acc: 0.3749
Train, Epoch: 1, Batch: 724, Step num: 724, Learning rate: 0.00050591, Avg batch loss: 0.6326, Avg batch acc: 0.3892
Train, Epoch: 1, Batch: 725, Step num: 725, Learning rate: 0.00050661, Avg batch loss: 0.6297, Avg batch acc: 0.3828
Train, Epoch: 1, Batch: 726, Step num: 726, Learning rate: 0.00050731, Avg batch loss: 0.5688, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 727, Step num: 727, Learning rate: 0.00050801, Avg batch loss: 0.6104, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 728, Step num: 728, Learning rate: 0.00050871, Avg batch loss: 0.6147, Avg batch acc: 0.3934
Train, Epoch: 1, Batch: 729, Step num: 729, Learning rate: 0.00050940, Avg batch loss: 0.6849, Avg batch acc: 0.3681
Train, Epoch: 1, Batch: 730, Step num: 730, Learning rate: 0.00051010, Avg batch loss: 0.6313, Avg batch acc: 0.3839
Train, Epoch: 1, Batch: 731, Step num: 731, Learning rate: 0.00051080, Avg batch loss: 0.6258, Avg batch acc: 0.4040
Train, Epoch: 1, Batch: 732, Step num: 732, Learning rate: 0.00051150, Avg batch loss: 0.6066, Avg batch acc: 0.3874
Train, Epoch: 1, Batch: 733, Step num: 733, Learning rate: 0.00051220, Avg batch loss: 0.6455, Avg batch acc: 0.3880
Train, Epoch: 1, Batch: 734, Step num: 734, Learning rate: 0.00051290, Avg batch loss: 0.6212, Avg batch acc: 0.4136
Train, Epoch: 1, Batch: 735, Step num: 735, Learning rate: 0.00051360, Avg batch loss: 0.5401, Avg batch acc: 0.3969
Train, Epoch: 1, Batch: 736, Step num: 736, Learning rate: 0.00051430, Avg batch loss: 0.6127, Avg batch acc: 0.3833
Train, Epoch: 1, Batch: 737, Step num: 737, Learning rate: 0.00051499, Avg batch loss: 0.6052, Avg batch acc: 0.3938
Train, Epoch: 1, Batch: 738, Step num: 738, Learning rate: 0.00051569, Avg batch loss: 0.6479, Avg batch acc: 0.3925
Train, Epoch: 1, Batch: 739, Step num: 739, Learning rate: 0.00051639, Avg batch loss: 0.6243, Avg batch acc: 0.3841
Train, Epoch: 1, Batch: 740, Step num: 740, Learning rate: 0.00051709, Avg batch loss: 0.6633, Avg batch acc: 0.3734
Train, Epoch: 1, Batch: 741, Step num: 741, Learning rate: 0.00051779, Avg batch loss: 0.6294, Avg batch acc: 0.3898
Train, Epoch: 1, Batch: 742, Step num: 742, Learning rate: 0.00051849, Avg batch loss: 0.6780, Avg batch acc: 0.3743
Train, Epoch: 1, Batch: 743, Step num: 743, Learning rate: 0.00051919, Avg batch loss: 0.7033, Avg batch acc: 0.3849
Train, Epoch: 1, Batch: 744, Step num: 744, Learning rate: 0.00051989, Avg batch loss: 0.6656, Avg batch acc: 0.3792
Train, Epoch: 1, Batch: 745, Step num: 745, Learning rate: 0.00052058, Avg batch loss: 0.6864, Avg batch acc: 0.3742
Train, Epoch: 1, Batch: 746, Step num: 746, Learning rate: 0.00052128, Avg batch loss: 0.6307, Avg batch acc: 0.3805
Train, Epoch: 1, Batch: 747, Step num: 747, Learning rate: 0.00052198, Avg batch loss: 0.6532, Avg batch acc: 0.4031
Train, Epoch: 1, Batch: 748, Step num: 748, Learning rate: 0.00052268, Avg batch loss: 0.6587, Avg batch acc: 0.3954
Train, Epoch: 1, Batch: 749, Step num: 749, Learning rate: 0.00052338, Avg batch loss: 0.6636, Avg batch acc: 0.3898
Train, Epoch: 1, Batch: 750, Step num: 750, Learning rate: 0.00052408, Avg batch loss: 0.6719, Avg batch acc: 0.3772
Train, Epoch: 1, Batch: 751, Step num: 751, Learning rate: 0.00052478, Avg batch loss: 0.5573, Avg batch acc: 0.3919
Train, Epoch: 1, Batch: 752, Step num: 752, Learning rate: 0.00052548, Avg batch loss: 0.5996, Avg batch acc: 0.3903
Train, Epoch: 1, Batch: 753, Step num: 753, Learning rate: 0.00052617, Avg batch loss: 0.6455, Avg batch acc: 0.3939
Train, Epoch: 1, Batch: 754, Step num: 754, Learning rate: 0.00052687, Avg batch loss: 0.6776, Avg batch acc: 0.3699
Train, Epoch: 1, Batch: 755, Step num: 755, Learning rate: 0.00052757, Avg batch loss: 0.6600, Avg batch acc: 0.3776
Train, Epoch: 1, Batch: 756, Step num: 756, Learning rate: 0.00052827, Avg batch loss: 0.6489, Avg batch acc: 0.3784
Train, Epoch: 1, Batch: 757, Step num: 757, Learning rate: 0.00052897, Avg batch loss: 0.6549, Avg batch acc: 0.3884
Train, Epoch: 1, Batch: 758, Step num: 758, Learning rate: 0.00052967, Avg batch loss: 0.6711, Avg batch acc: 0.3678
Train, Epoch: 1, Batch: 759, Step num: 759, Learning rate: 0.00053037, Avg batch loss: 0.6794, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 760, Step num: 760, Learning rate: 0.00053107, Avg batch loss: 0.6183, Avg batch acc: 0.4046
Train, Epoch: 1, Batch: 761, Step num: 761, Learning rate: 0.00053176, Avg batch loss: 0.5964, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 762, Step num: 762, Learning rate: 0.00053246, Avg batch loss: 0.6470, Avg batch acc: 0.3994
Train, Epoch: 1, Batch: 763, Step num: 763, Learning rate: 0.00053316, Avg batch loss: 0.6157, Avg batch acc: 0.4086
Train, Epoch: 1, Batch: 764, Step num: 764, Learning rate: 0.00053386, Avg batch loss: 0.5786, Avg batch acc: 0.3999
Train, Epoch: 1, Batch: 765, Step num: 765, Learning rate: 0.00053456, Avg batch loss: 0.6216, Avg batch acc: 0.3799
Train, Epoch: 1, Batch: 766, Step num: 766, Learning rate: 0.00053526, Avg batch loss: 0.6797, Avg batch acc: 0.3744
Train, Epoch: 1, Batch: 767, Step num: 767, Learning rate: 0.00053596, Avg batch loss: 0.6680, Avg batch acc: 0.3794
Train, Epoch: 1, Batch: 768, Step num: 768, Learning rate: 0.00053666, Avg batch loss: 0.5656, Avg batch acc: 0.4177
Train, Epoch: 1, Batch: 769, Step num: 769, Learning rate: 0.00053736, Avg batch loss: 0.7183, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 770, Step num: 770, Learning rate: 0.00053805, Avg batch loss: 0.6367, Avg batch acc: 0.3967
Train, Epoch: 1, Batch: 771, Step num: 771, Learning rate: 0.00053875, Avg batch loss: 0.6120, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 772, Step num: 772, Learning rate: 0.00053945, Avg batch loss: 0.6131, Avg batch acc: 0.3942
Train, Epoch: 1, Batch: 773, Step num: 773, Learning rate: 0.00054015, Avg batch loss: 0.6536, Avg batch acc: 0.3756
Train, Epoch: 1, Batch: 774, Step num: 774, Learning rate: 0.00054085, Avg batch loss: 0.6225, Avg batch acc: 0.3681
Train, Epoch: 1, Batch: 775, Step num: 775, Learning rate: 0.00054155, Avg batch loss: 0.6057, Avg batch acc: 0.3943
Train, Epoch: 1, Batch: 776, Step num: 776, Learning rate: 0.00054225, Avg batch loss: 0.6130, Avg batch acc: 0.4005
Train, Epoch: 1, Batch: 777, Step num: 777, Learning rate: 0.00054295, Avg batch loss: 0.6341, Avg batch acc: 0.3972
Train, Epoch: 1, Batch: 778, Step num: 778, Learning rate: 0.00054364, Avg batch loss: 0.6930, Avg batch acc: 0.3692
Train, Epoch: 1, Batch: 779, Step num: 779, Learning rate: 0.00054434, Avg batch loss: 0.5289, Avg batch acc: 0.3918
Train, Epoch: 1, Batch: 780, Step num: 780, Learning rate: 0.00054504, Avg batch loss: 0.5668, Avg batch acc: 0.3988
Train, Epoch: 1, Batch: 781, Step num: 781, Learning rate: 0.00054574, Avg batch loss: 0.6341, Avg batch acc: 0.3659
Train, Epoch: 1, Batch: 782, Step num: 782, Learning rate: 0.00054644, Avg batch loss: 0.5501, Avg batch acc: 0.4206
Train, Epoch: 1, Batch: 783, Step num: 783, Learning rate: 0.00054714, Avg batch loss: 0.6361, Avg batch acc: 0.3759
Train, Epoch: 1, Batch: 784, Step num: 784, Learning rate: 0.00054784, Avg batch loss: 0.5753, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 785, Step num: 785, Learning rate: 0.00054854, Avg batch loss: 0.5981, Avg batch acc: 0.4136
Train, Epoch: 1, Batch: 786, Step num: 786, Learning rate: 0.00054923, Avg batch loss: 0.6398, Avg batch acc: 0.3913
Train, Epoch: 1, Batch: 787, Step num: 787, Learning rate: 0.00054993, Avg batch loss: 0.5545, Avg batch acc: 0.3988
Train, Epoch: 1, Batch: 788, Step num: 788, Learning rate: 0.00055063, Avg batch loss: 0.5895, Avg batch acc: 0.3986
Train, Epoch: 1, Batch: 789, Step num: 789, Learning rate: 0.00055133, Avg batch loss: 0.6562, Avg batch acc: 0.3763
Train, Epoch: 1, Batch: 790, Step num: 790, Learning rate: 0.00055203, Avg batch loss: 0.6238, Avg batch acc: 0.4057
Train, Epoch: 1, Batch: 791, Step num: 791, Learning rate: 0.00055273, Avg batch loss: 0.6258, Avg batch acc: 0.3884
Train, Epoch: 1, Batch: 792, Step num: 792, Learning rate: 0.00055343, Avg batch loss: 0.5867, Avg batch acc: 0.4031
Train, Epoch: 1, Batch: 793, Step num: 793, Learning rate: 0.00055413, Avg batch loss: 0.6096, Avg batch acc: 0.3968
Train, Epoch: 1, Batch: 794, Step num: 794, Learning rate: 0.00055482, Avg batch loss: 0.7743, Avg batch acc: 0.3799
Train, Epoch: 1, Batch: 795, Step num: 795, Learning rate: 0.00055552, Avg batch loss: 0.6449, Avg batch acc: 0.3768
Train, Epoch: 1, Batch: 796, Step num: 796, Learning rate: 0.00055622, Avg batch loss: 0.6327, Avg batch acc: 0.3741
Train, Epoch: 1, Batch: 797, Step num: 797, Learning rate: 0.00055692, Avg batch loss: 0.6126, Avg batch acc: 0.3927
Train, Epoch: 1, Batch: 798, Step num: 798, Learning rate: 0.00055762, Avg batch loss: 0.5877, Avg batch acc: 0.3912
Train, Epoch: 1, Batch: 799, Step num: 799, Learning rate: 0.00055832, Avg batch loss: 0.6038, Avg batch acc: 0.3807
Train, Epoch: 1, Batch: 800, Step num: 800, Learning rate: 0.00055902, Avg batch loss: 0.5989, Avg batch acc: 0.3894
Train, Epoch: 1, Batch: 801, Step num: 801, Learning rate: 0.00055972, Avg batch loss: 0.6591, Avg batch acc: 0.3858
Train, Epoch: 1, Batch: 802, Step num: 802, Learning rate: 0.00056041, Avg batch loss: 0.6272, Avg batch acc: 0.3861
Train, Epoch: 1, Batch: 803, Step num: 803, Learning rate: 0.00056111, Avg batch loss: 0.5761, Avg batch acc: 0.4100
Train, Epoch: 1, Batch: 804, Step num: 804, Learning rate: 0.00056181, Avg batch loss: 0.6436, Avg batch acc: 0.3948
Train, Epoch: 1, Batch: 805, Step num: 805, Learning rate: 0.00056251, Avg batch loss: 0.5881, Avg batch acc: 0.4077
Train, Epoch: 1, Batch: 806, Step num: 806, Learning rate: 0.00056321, Avg batch loss: 0.7351, Avg batch acc: 0.3620
Train, Epoch: 1, Batch: 807, Step num: 807, Learning rate: 0.00056391, Avg batch loss: 0.5845, Avg batch acc: 0.4108
Train, Epoch: 1, Batch: 808, Step num: 808, Learning rate: 0.00056461, Avg batch loss: 0.5459, Avg batch acc: 0.4030
Train, Epoch: 1, Batch: 809, Step num: 809, Learning rate: 0.00056531, Avg batch loss: 0.5960, Avg batch acc: 0.3756
Train, Epoch: 1, Batch: 810, Step num: 810, Learning rate: 0.00056600, Avg batch loss: 0.6042, Avg batch acc: 0.3893
Train, Epoch: 1, Batch: 811, Step num: 811, Learning rate: 0.00056670, Avg batch loss: 0.7094, Avg batch acc: 0.3895
Train, Epoch: 1, Batch: 812, Step num: 812, Learning rate: 0.00056740, Avg batch loss: 0.6323, Avg batch acc: 0.3908
Train, Epoch: 1, Batch: 813, Step num: 813, Learning rate: 0.00056810, Avg batch loss: 0.6486, Avg batch acc: 0.3907
Train, Epoch: 1, Batch: 814, Step num: 814, Learning rate: 0.00056880, Avg batch loss: 0.5858, Avg batch acc: 0.4069
Train, Epoch: 1, Batch: 815, Step num: 815, Learning rate: 0.00056950, Avg batch loss: 0.6403, Avg batch acc: 0.4060
Train, Epoch: 1, Batch: 816, Step num: 816, Learning rate: 0.00057020, Avg batch loss: 0.6347, Avg batch acc: 0.3909
Train, Epoch: 1, Batch: 817, Step num: 817, Learning rate: 0.00057090, Avg batch loss: 0.6341, Avg batch acc: 0.3928
Train, Epoch: 1, Batch: 818, Step num: 818, Learning rate: 0.00057159, Avg batch loss: 0.6163, Avg batch acc: 0.4065
Train, Epoch: 1, Batch: 819, Step num: 819, Learning rate: 0.00057229, Avg batch loss: 0.6338, Avg batch acc: 0.3830
Train, Epoch: 1, Batch: 820, Step num: 820, Learning rate: 0.00057299, Avg batch loss: 0.6759, Avg batch acc: 0.3858
Train, Epoch: 1, Batch: 821, Step num: 821, Learning rate: 0.00057369, Avg batch loss: 0.5953, Avg batch acc: 0.4036
Train, Epoch: 1, Batch: 822, Step num: 822, Learning rate: 0.00057439, Avg batch loss: 0.6767, Avg batch acc: 0.3886
Train, Epoch: 1, Batch: 823, Step num: 823, Learning rate: 0.00057509, Avg batch loss: 0.7023, Avg batch acc: 0.3884
Train, Epoch: 1, Batch: 824, Step num: 824, Learning rate: 0.00057579, Avg batch loss: 0.6148, Avg batch acc: 0.4088
Train, Epoch: 1, Batch: 825, Step num: 825, Learning rate: 0.00057649, Avg batch loss: 0.6047, Avg batch acc: 0.3922
Train, Epoch: 1, Batch: 826, Step num: 826, Learning rate: 0.00057719, Avg batch loss: 0.5746, Avg batch acc: 0.4149
Train, Epoch: 1, Batch: 827, Step num: 827, Learning rate: 0.00057788, Avg batch loss: 0.5822, Avg batch acc: 0.4234
Train, Epoch: 1, Batch: 828, Step num: 828, Learning rate: 0.00057858, Avg batch loss: 0.6271, Avg batch acc: 0.3723
Train, Epoch: 1, Batch: 829, Step num: 829, Learning rate: 0.00057928, Avg batch loss: 0.6084, Avg batch acc: 0.3908
Train, Epoch: 1, Batch: 830, Step num: 830, Learning rate: 0.00057998, Avg batch loss: 0.6586, Avg batch acc: 0.3882
Train, Epoch: 1, Batch: 831, Step num: 831, Learning rate: 0.00058068, Avg batch loss: 0.6065, Avg batch acc: 0.4002
Train, Epoch: 1, Batch: 832, Step num: 832, Learning rate: 0.00058138, Avg batch loss: 0.6614, Avg batch acc: 0.3646
Train, Epoch: 1, Batch: 833, Step num: 833, Learning rate: 0.00058208, Avg batch loss: 0.5885, Avg batch acc: 0.4040
Train, Epoch: 1, Batch: 834, Step num: 834, Learning rate: 0.00058278, Avg batch loss: 0.5976, Avg batch acc: 0.4043
Train, Epoch: 1, Batch: 835, Step num: 835, Learning rate: 0.00058347, Avg batch loss: 0.6465, Avg batch acc: 0.3847
Train, Epoch: 1, Batch: 836, Step num: 836, Learning rate: 0.00058417, Avg batch loss: 0.6872, Avg batch acc: 0.3846
Train, Epoch: 1, Batch: 837, Step num: 837, Learning rate: 0.00058487, Avg batch loss: 0.6263, Avg batch acc: 0.4125
Train, Epoch: 1, Batch: 838, Step num: 838, Learning rate: 0.00058557, Avg batch loss: 0.6046, Avg batch acc: 0.3805
Train, Epoch: 1, Batch: 839, Step num: 839, Learning rate: 0.00058627, Avg batch loss: 0.5999, Avg batch acc: 0.3937
Train, Epoch: 1, Batch: 840, Step num: 840, Learning rate: 0.00058697, Avg batch loss: 0.5988, Avg batch acc: 0.3976
Train, Epoch: 1, Batch: 841, Step num: 841, Learning rate: 0.00058767, Avg batch loss: 0.5859, Avg batch acc: 0.4320
Train, Epoch: 1, Batch: 842, Step num: 842, Learning rate: 0.00058837, Avg batch loss: 0.5884, Avg batch acc: 0.3905
Train, Epoch: 1, Batch: 843, Step num: 843, Learning rate: 0.00058906, Avg batch loss: 0.6737, Avg batch acc: 0.3828
Train, Epoch: 1, Batch: 844, Step num: 844, Learning rate: 0.00058976, Avg batch loss: 0.6006, Avg batch acc: 0.3880
Train, Epoch: 1, Batch: 845, Step num: 845, Learning rate: 0.00059046, Avg batch loss: 0.5736, Avg batch acc: 0.3828
Train, Epoch: 1, Batch: 846, Step num: 846, Learning rate: 0.00059116, Avg batch loss: 0.5574, Avg batch acc: 0.4125
Train, Epoch: 1, Batch: 847, Step num: 847, Learning rate: 0.00059186, Avg batch loss: 0.6504, Avg batch acc: 0.3839
Train, Epoch: 1, Batch: 848, Step num: 848, Learning rate: 0.00059256, Avg batch loss: 0.6269, Avg batch acc: 0.3883
Train, Epoch: 1, Batch: 849, Step num: 849, Learning rate: 0.00059326, Avg batch loss: 0.6123, Avg batch acc: 0.4029
Train, Epoch: 1, Batch: 850, Step num: 850, Learning rate: 0.00059396, Avg batch loss: 0.6501, Avg batch acc: 0.3745
Train, Epoch: 1, Batch: 851, Step num: 851, Learning rate: 0.00059465, Avg batch loss: 0.5516, Avg batch acc: 0.4280
Train, Epoch: 1, Batch: 852, Step num: 852, Learning rate: 0.00059535, Avg batch loss: 0.5793, Avg batch acc: 0.4154
Train, Epoch: 1, Batch: 853, Step num: 853, Learning rate: 0.00059605, Avg batch loss: 0.6203, Avg batch acc: 0.3994
Train, Epoch: 1, Batch: 854, Step num: 854, Learning rate: 0.00059675, Avg batch loss: 0.5737, Avg batch acc: 0.3956
Train, Epoch: 1, Batch: 855, Step num: 855, Learning rate: 0.00059745, Avg batch loss: 0.6344, Avg batch acc: 0.4283
Train, Epoch: 1, Batch: 856, Step num: 856, Learning rate: 0.00059815, Avg batch loss: 0.6609, Avg batch acc: 0.3877
Train, Epoch: 1, Batch: 857, Step num: 857, Learning rate: 0.00059885, Avg batch loss: 0.6010, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 858, Step num: 858, Learning rate: 0.00059955, Avg batch loss: 0.6349, Avg batch acc: 0.3840
Train, Epoch: 1, Batch: 859, Step num: 859, Learning rate: 0.00060024, Avg batch loss: 0.6467, Avg batch acc: 0.3947
Train, Epoch: 1, Batch: 860, Step num: 860, Learning rate: 0.00060094, Avg batch loss: 0.6371, Avg batch acc: 0.3810
Train, Epoch: 1, Batch: 861, Step num: 861, Learning rate: 0.00060164, Avg batch loss: 0.5811, Avg batch acc: 0.4007
Train, Epoch: 1, Batch: 862, Step num: 862, Learning rate: 0.00060234, Avg batch loss: 0.5920, Avg batch acc: 0.3994
Train, Epoch: 1, Batch: 863, Step num: 863, Learning rate: 0.00060304, Avg batch loss: 0.6329, Avg batch acc: 0.4199
Train, Epoch: 1, Batch: 864, Step num: 864, Learning rate: 0.00060374, Avg batch loss: 0.6137, Avg batch acc: 0.3902
Train, Epoch: 1, Batch: 865, Step num: 865, Learning rate: 0.00060444, Avg batch loss: 0.5883, Avg batch acc: 0.3983
Train, Epoch: 1, Batch: 866, Step num: 866, Learning rate: 0.00060514, Avg batch loss: 0.6091, Avg batch acc: 0.4038
Train, Epoch: 1, Batch: 867, Step num: 867, Learning rate: 0.00060583, Avg batch loss: 0.5637, Avg batch acc: 0.3945
Train, Epoch: 1, Batch: 868, Step num: 868, Learning rate: 0.00060653, Avg batch loss: 0.6525, Avg batch acc: 0.3872
Train, Epoch: 1, Batch: 869, Step num: 869, Learning rate: 0.00060723, Avg batch loss: 0.6066, Avg batch acc: 0.4008
Train, Epoch: 1, Batch: 870, Step num: 870, Learning rate: 0.00060793, Avg batch loss: 0.6529, Avg batch acc: 0.3729
Train, Epoch: 1, Batch: 871, Step num: 871, Learning rate: 0.00060863, Avg batch loss: 0.5984, Avg batch acc: 0.3818
Train, Epoch: 1, Batch: 872, Step num: 872, Learning rate: 0.00060933, Avg batch loss: 0.6031, Avg batch acc: 0.3821
Train, Epoch: 1, Batch: 873, Step num: 873, Learning rate: 0.00061003, Avg batch loss: 0.6339, Avg batch acc: 0.3918
Train, Epoch: 1, Batch: 874, Step num: 874, Learning rate: 0.00061073, Avg batch loss: 0.5999, Avg batch acc: 0.3942
Train, Epoch: 1, Batch: 875, Step num: 875, Learning rate: 0.00061142, Avg batch loss: 0.5987, Avg batch acc: 0.4166
Train, Epoch: 1, Batch: 876, Step num: 876, Learning rate: 0.00061212, Avg batch loss: 0.5888, Avg batch acc: 0.4070
Train, Epoch: 1, Batch: 877, Step num: 877, Learning rate: 0.00061282, Avg batch loss: 0.6234, Avg batch acc: 0.3931
Train, Epoch: 1, Batch: 878, Step num: 878, Learning rate: 0.00061352, Avg batch loss: 0.5971, Avg batch acc: 0.4100
Train, Epoch: 1, Batch: 879, Step num: 879, Learning rate: 0.00061422, Avg batch loss: 0.6095, Avg batch acc: 0.3858
Train, Epoch: 1, Batch: 880, Step num: 880, Learning rate: 0.00061492, Avg batch loss: 0.5799, Avg batch acc: 0.3975
Train, Epoch: 1, Batch: 881, Step num: 881, Learning rate: 0.00061562, Avg batch loss: 0.6082, Avg batch acc: 0.3905
Train, Epoch: 1, Batch: 882, Step num: 882, Learning rate: 0.00061632, Avg batch loss: 0.5590, Avg batch acc: 0.4243
Train, Epoch: 1, Batch: 883, Step num: 883, Learning rate: 0.00061702, Avg batch loss: 0.6592, Avg batch acc: 0.3855
Train, Epoch: 1, Batch: 884, Step num: 884, Learning rate: 0.00061771, Avg batch loss: 0.5803, Avg batch acc: 0.4026
Train, Epoch: 1, Batch: 885, Step num: 885, Learning rate: 0.00061841, Avg batch loss: 0.5926, Avg batch acc: 0.3931
Train, Epoch: 1, Batch: 886, Step num: 886, Learning rate: 0.00061911, Avg batch loss: 0.6051, Avg batch acc: 0.4057
Train, Epoch: 1, Batch: 887, Step num: 887, Learning rate: 0.00061981, Avg batch loss: 0.5828, Avg batch acc: 0.4047
Train, Epoch: 1, Batch: 888, Step num: 888, Learning rate: 0.00062051, Avg batch loss: 0.5796, Avg batch acc: 0.3872
Train, Epoch: 1, Batch: 889, Step num: 889, Learning rate: 0.00062121, Avg batch loss: 0.6031, Avg batch acc: 0.3941
Train, Epoch: 1, Batch: 890, Step num: 890, Learning rate: 0.00062191, Avg batch loss: 0.5919, Avg batch acc: 0.4051
Train, Epoch: 1, Batch: 891, Step num: 891, Learning rate: 0.00062261, Avg batch loss: 0.5881, Avg batch acc: 0.3912
Train, Epoch: 1, Batch: 892, Step num: 892, Learning rate: 0.00062330, Avg batch loss: 0.6047, Avg batch acc: 0.4000
Train, Epoch: 1, Batch: 893, Step num: 893, Learning rate: 0.00062400, Avg batch loss: 0.6204, Avg batch acc: 0.3942
Train, Epoch: 1, Batch: 894, Step num: 894, Learning rate: 0.00062470, Avg batch loss: 0.5770, Avg batch acc: 0.4023
Train, Epoch: 1, Batch: 895, Step num: 895, Learning rate: 0.00062540, Avg batch loss: 0.6380, Avg batch acc: 0.3976
Train, Epoch: 1, Batch: 896, Step num: 896, Learning rate: 0.00062610, Avg batch loss: 0.6440, Avg batch acc: 0.3885
Train, Epoch: 1, Batch: 897, Step num: 897, Learning rate: 0.00062680, Avg batch loss: 0.5599, Avg batch acc: 0.4213
Train, Epoch: 1, Batch: 898, Step num: 898, Learning rate: 0.00062750, Avg batch loss: 0.6897, Avg batch acc: 0.3778
Train, Epoch: 1, Batch: 899, Step num: 899, Learning rate: 0.00062820, Avg batch loss: 0.5659, Avg batch acc: 0.4061
Train, Epoch: 1, Batch: 900, Step num: 900, Learning rate: 0.00062889, Avg batch loss: 0.6299, Avg batch acc: 0.3877
Train, Epoch: 1, Batch: 901, Step num: 901, Learning rate: 0.00062959, Avg batch loss: 0.5810, Avg batch acc: 0.4169
Train, Epoch: 1, Batch: 902, Step num: 902, Learning rate: 0.00063029, Avg batch loss: 0.6029, Avg batch acc: 0.4102
Train, Epoch: 1, Batch: 903, Step num: 903, Learning rate: 0.00063099, Avg batch loss: 0.6299, Avg batch acc: 0.4015
Train, Epoch: 1, Batch: 904, Step num: 904, Learning rate: 0.00063169, Avg batch loss: 0.5612, Avg batch acc: 0.3923
Train, Epoch: 1, Batch: 905, Step num: 905, Learning rate: 0.00063239, Avg batch loss: 0.6118, Avg batch acc: 0.3973
Train, Epoch: 1, Batch: 906, Step num: 906, Learning rate: 0.00063309, Avg batch loss: 0.5649, Avg batch acc: 0.4020
Train, Epoch: 1, Batch: 907, Step num: 907, Learning rate: 0.00063379, Avg batch loss: 0.6602, Avg batch acc: 0.4006
Train, Epoch: 1, Batch: 908, Step num: 908, Learning rate: 0.00063448, Avg batch loss: 0.6212, Avg batch acc: 0.4093
Train, Epoch: 1, Batch: 909, Step num: 909, Learning rate: 0.00063518, Avg batch loss: 0.6500, Avg batch acc: 0.3943
Train, Epoch: 1, Batch: 910, Step num: 910, Learning rate: 0.00063588, Avg batch loss: 0.6087, Avg batch acc: 0.4079
Train, Epoch: 1, Batch: 911, Step num: 911, Learning rate: 0.00063658, Avg batch loss: 0.6078, Avg batch acc: 0.3854
Train, Epoch: 1, Batch: 912, Step num: 912, Learning rate: 0.00063728, Avg batch loss: 0.5864, Avg batch acc: 0.4197
Train, Epoch: 1, Batch: 913, Step num: 913, Learning rate: 0.00063798, Avg batch loss: 0.5782, Avg batch acc: 0.4078
Train, Epoch: 1, Batch: 914, Step num: 914, Learning rate: 0.00063868, Avg batch loss: 0.5959, Avg batch acc: 0.3946
Train, Epoch: 1, Batch: 915, Step num: 915, Learning rate: 0.00063938, Avg batch loss: 0.5594, Avg batch acc: 0.3912
Train, Epoch: 1, Batch: 916, Step num: 916, Learning rate: 0.00064007, Avg batch loss: 0.5755, Avg batch acc: 0.4044
Train, Epoch: 1, Batch: 917, Step num: 917, Learning rate: 0.00064077, Avg batch loss: 0.6342, Avg batch acc: 0.3991
Train, Epoch: 1, Batch: 918, Step num: 918, Learning rate: 0.00064147, Avg batch loss: 0.5688, Avg batch acc: 0.3976
Train, Epoch: 1, Batch: 919, Step num: 919, Learning rate: 0.00064217, Avg batch loss: 0.6132, Avg batch acc: 0.3861
Train, Epoch: 1, Batch: 920, Step num: 920, Learning rate: 0.00064287, Avg batch loss: 0.5987, Avg batch acc: 0.4034
Train, Epoch: 1, Batch: 921, Step num: 921, Learning rate: 0.00064357, Avg batch loss: 0.5869, Avg batch acc: 0.4187
Train, Epoch: 1, Batch: 922, Step num: 922, Learning rate: 0.00064427, Avg batch loss: 0.5369, Avg batch acc: 0.4284
Train, Epoch: 1, Batch: 923, Step num: 923, Learning rate: 0.00064497, Avg batch loss: 0.5983, Avg batch acc: 0.4016
Train, Epoch: 1, Batch: 924, Step num: 924, Learning rate: 0.00064566, Avg batch loss: 0.6200, Avg batch acc: 0.3935
Train, Epoch: 1, Batch: 925, Step num: 925, Learning rate: 0.00064636, Avg batch loss: 0.5922, Avg batch acc: 0.3883
Train, Epoch: 1, Batch: 926, Step num: 926, Learning rate: 0.00064706, Avg batch loss: 0.6030, Avg batch acc: 0.4101
Train, Epoch: 1, Batch: 927, Step num: 927, Learning rate: 0.00064776, Avg batch loss: 0.6073, Avg batch acc: 0.3923
Train, Epoch: 1, Batch: 928, Step num: 928, Learning rate: 0.00064846, Avg batch loss: 0.6308, Avg batch acc: 0.3960
Train, Epoch: 1, Batch: 929, Step num: 929, Learning rate: 0.00064916, Avg batch loss: 0.6431, Avg batch acc: 0.3930
Train, Epoch: 1, Batch: 930, Step num: 930, Learning rate: 0.00064986, Avg batch loss: 0.5675, Avg batch acc: 0.4027
Train, Epoch: 1, Batch: 931, Step num: 931, Learning rate: 0.00065056, Avg batch loss: 0.5975, Avg batch acc: 0.3857
Train, Epoch: 1, Batch: 932, Step num: 932, Learning rate: 0.00065125, Avg batch loss: 0.6263, Avg batch acc: 0.4102
Train, Epoch: 1, Batch: 933, Step num: 933, Learning rate: 0.00065195, Avg batch loss: 0.5733, Avg batch acc: 0.4133
Train, Epoch: 1, Batch: 934, Step num: 934, Learning rate: 0.00065265, Avg batch loss: 0.6458, Avg batch acc: 0.3855
Train, Epoch: 1, Batch: 935, Step num: 935, Learning rate: 0.00065335, Avg batch loss: 0.6352, Avg batch acc: 0.3809
Train, Epoch: 1, Batch: 936, Step num: 936, Learning rate: 0.00065405, Avg batch loss: 0.5878, Avg batch acc: 0.3849
Train, Epoch: 1, Batch: 937, Step num: 937, Learning rate: 0.00065475, Avg batch loss: 0.5626, Avg batch acc: 0.4133
Train, Epoch: 1, Batch: 938, Step num: 938, Learning rate: 0.00065545, Avg batch loss: 0.5901, Avg batch acc: 0.3980
Train, Epoch: 1, Batch: 939, Step num: 939, Learning rate: 0.00065615, Avg batch loss: 0.6172, Avg batch acc: 0.4114
Train, Epoch: 1, Batch: 940, Step num: 940, Learning rate: 0.00065684, Avg batch loss: 0.5838, Avg batch acc: 0.4008
Train, Epoch: 1, Batch: 941, Step num: 941, Learning rate: 0.00065754, Avg batch loss: 0.5639, Avg batch acc: 0.4086
Train, Epoch: 1, Batch: 942, Step num: 942, Learning rate: 0.00065824, Avg batch loss: 0.6147, Avg batch acc: 0.4170
Train, Epoch: 1, Batch: 943, Step num: 943, Learning rate: 0.00065894, Avg batch loss: 0.5776, Avg batch acc: 0.4221
Train, Epoch: 1, Batch: 944, Step num: 944, Learning rate: 0.00065964, Avg batch loss: 0.5819, Avg batch acc: 0.4375
Train, Epoch: 1, Batch: 945, Step num: 945, Learning rate: 0.00066034, Avg batch loss: 0.5940, Avg batch acc: 0.4126
Train, Epoch: 1, Batch: 946, Step num: 946, Learning rate: 0.00066104, Avg batch loss: 0.5523, Avg batch acc: 0.4080
Train, Epoch: 1, Batch: 947, Step num: 947, Learning rate: 0.00066174, Avg batch loss: 0.5922, Avg batch acc: 0.4044
Train, Epoch: 1, Batch: 948, Step num: 948, Learning rate: 0.00066244, Avg batch loss: 0.5677, Avg batch acc: 0.4003
Train, Epoch: 1, Batch: 949, Step num: 949, Learning rate: 0.00066313, Avg batch loss: 0.5807, Avg batch acc: 0.4324
Train, Epoch: 1, Batch: 950, Step num: 950, Learning rate: 0.00066383, Avg batch loss: 0.5909, Avg batch acc: 0.3941
Train, Epoch: 1, Batch: 951, Step num: 951, Learning rate: 0.00066453, Avg batch loss: 0.6287, Avg batch acc: 0.3975
Train, Epoch: 1, Batch: 952, Step num: 952, Learning rate: 0.00066523, Avg batch loss: 0.5339, Avg batch acc: 0.3962
Train, Epoch: 1, Batch: 953, Step num: 953, Learning rate: 0.00066593, Avg batch loss: 0.6515, Avg batch acc: 0.4014
Train, Epoch: 1, Batch: 954, Step num: 954, Learning rate: 0.00066663, Avg batch loss: 0.6206, Avg batch acc: 0.3995
Train, Epoch: 1, Batch: 955, Step num: 955, Learning rate: 0.00066733, Avg batch loss: 0.6587, Avg batch acc: 0.3831
Train, Epoch: 1, Batch: 956, Step num: 956, Learning rate: 0.00066803, Avg batch loss: 0.4970, Avg batch acc: 0.4261
Train, Epoch: 1, Batch: 957, Step num: 957, Learning rate: 0.00066872, Avg batch loss: 0.5554, Avg batch acc: 0.4127
Train, Epoch: 1, Batch: 958, Step num: 958, Learning rate: 0.00066942, Avg batch loss: 0.5877, Avg batch acc: 0.4039
Train, Epoch: 1, Batch: 959, Step num: 959, Learning rate: 0.00067012, Avg batch loss: 0.6218, Avg batch acc: 0.4003
Train, Epoch: 1, Batch: 960, Step num: 960, Learning rate: 0.00067082, Avg batch loss: 0.6020, Avg batch acc: 0.4042
Train, Epoch: 1, Batch: 961, Step num: 961, Learning rate: 0.00067152, Avg batch loss: 0.5837, Avg batch acc: 0.3996
Train, Epoch: 1, Batch: 962, Step num: 962, Learning rate: 0.00067222, Avg batch loss: 0.5975, Avg batch acc: 0.4013
Train, Epoch: 1, Batch: 963, Step num: 963, Learning rate: 0.00067292, Avg batch loss: 0.6347, Avg batch acc: 0.3923
Train, Epoch: 1, Batch: 964, Step num: 964, Learning rate: 0.00067362, Avg batch loss: 0.5989, Avg batch acc: 0.4168
Train, Epoch: 1, Batch: 965, Step num: 965, Learning rate: 0.00067431, Avg batch loss: 0.5255, Avg batch acc: 0.4340
Train, Epoch: 1, Batch: 966, Step num: 966, Learning rate: 0.00067501, Avg batch loss: 0.5971, Avg batch acc: 0.3996
Train, Epoch: 1, Batch: 967, Step num: 967, Learning rate: 0.00067571, Avg batch loss: 0.5545, Avg batch acc: 0.4075
Train, Epoch: 1, Batch: 968, Step num: 968, Learning rate: 0.00067641, Avg batch loss: 0.5576, Avg batch acc: 0.4342
Train, Epoch: 1, Batch: 969, Step num: 969, Learning rate: 0.00067711, Avg batch loss: 0.4934, Avg batch acc: 0.4270
Train, Epoch: 1, Batch: 970, Step num: 970, Learning rate: 0.00067781, Avg batch loss: 0.6206, Avg batch acc: 0.4035
Train, Epoch: 1, Batch: 971, Step num: 971, Learning rate: 0.00067851, Avg batch loss: 0.5212, Avg batch acc: 0.4053
Train, Epoch: 1, Batch: 972, Step num: 972, Learning rate: 0.00067921, Avg batch loss: 0.6018, Avg batch acc: 0.4095
Train, Epoch: 1, Batch: 973, Step num: 973, Learning rate: 0.00067990, Avg batch loss: 0.5970, Avg batch acc: 0.3926
Train, Epoch: 1, Batch: 974, Step num: 974, Learning rate: 0.00068060, Avg batch loss: 0.5885, Avg batch acc: 0.4122
Train, Epoch: 1, Batch: 975, Step num: 975, Learning rate: 0.00068130, Avg batch loss: 0.5684, Avg batch acc: 0.4177
Train, Epoch: 1, Batch: 976, Step num: 976, Learning rate: 0.00068200, Avg batch loss: 0.5849, Avg batch acc: 0.3878
Train, Epoch: 1, Batch: 977, Step num: 977, Learning rate: 0.00068270, Avg batch loss: 0.5777, Avg batch acc: 0.4001
Train, Epoch: 1, Batch: 978, Step num: 978, Learning rate: 0.00068340, Avg batch loss: 0.5823, Avg batch acc: 0.4051
Train, Epoch: 1, Batch: 979, Step num: 979, Learning rate: 0.00068410, Avg batch loss: 0.6106, Avg batch acc: 0.3841
Train, Epoch: 1, Batch: 980, Step num: 980, Learning rate: 0.00068480, Avg batch loss: 0.5741, Avg batch acc: 0.4104
Train, Epoch: 1, Batch: 981, Step num: 981, Learning rate: 0.00068549, Avg batch loss: 0.5755, Avg batch acc: 0.4004
Train, Epoch: 1, Batch: 982, Step num: 982, Learning rate: 0.00068619, Avg batch loss: 0.5900, Avg batch acc: 0.4278
Train, Epoch: 1, Batch: 983, Step num: 983, Learning rate: 0.00068689, Avg batch loss: 0.6343, Avg batch acc: 0.4005
Train, Epoch: 1, Batch: 984, Step num: 984, Learning rate: 0.00068759, Avg batch loss: 0.5520, Avg batch acc: 0.4252
Train, Epoch: 1, Batch: 985, Step num: 985, Learning rate: 0.00068829, Avg batch loss: 0.6226, Avg batch acc: 0.3772
Train, Epoch: 1, Batch: 986, Step num: 986, Learning rate: 0.00068899, Avg batch loss: 0.6237, Avg batch acc: 0.3977
Train, Epoch: 1, Batch: 987, Step num: 987, Learning rate: 0.00068969, Avg batch loss: 0.6453, Avg batch acc: 0.3908
Train, Epoch: 1, Batch: 988, Step num: 988, Learning rate: 0.00069039, Avg batch loss: 0.6276, Avg batch acc: 0.3935
Train, Epoch: 1, Batch: 989, Step num: 989, Learning rate: 0.00069108, Avg batch loss: 0.6010, Avg batch acc: 0.4086
Train, Epoch: 1, Batch: 990, Step num: 990, Learning rate: 0.00069178, Avg batch loss: 0.5676, Avg batch acc: 0.4225
Train, Epoch: 1, Batch: 991, Step num: 991, Learning rate: 0.00069248, Avg batch loss: 0.5511, Avg batch acc: 0.4167
Train, Epoch: 1, Batch: 992, Step num: 992, Learning rate: 0.00069318, Avg batch loss: 0.6080, Avg batch acc: 0.3910
Train, Epoch: 1, Batch: 993, Step num: 993, Learning rate: 0.00069388, Avg batch loss: 0.6136, Avg batch acc: 0.3948
Train, Epoch: 1, Batch: 994, Step num: 994, Learning rate: 0.00069458, Avg batch loss: 0.5399, Avg batch acc: 0.3992
Train, Epoch: 1, Batch: 995, Step num: 995, Learning rate: 0.00069528, Avg batch loss: 0.6700, Avg batch acc: 0.3638
Train, Epoch: 1, Batch: 996, Step num: 996, Learning rate: 0.00069598, Avg batch loss: 0.5468, Avg batch acc: 0.4233
Train, Epoch: 1, Batch: 997, Step num: 997, Learning rate: 0.00069667, Avg batch loss: 0.6187, Avg batch acc: 0.4032
Train, Epoch: 1, Batch: 998, Step num: 998, Learning rate: 0.00069737, Avg batch loss: 0.6018, Avg batch acc: 0.3901
Train, Epoch: 1, Batch: 999, Step num: 999, Learning rate: 0.00069807, Avg batch loss: 0.5585, Avg batch acc: 0.3919
Train, Epoch: 1, Batch: 1000, Step num: 1000, Learning rate: 0.00069877, Avg batch loss: 0.6462, Avg batch acc: 0.4024
Train, Epoch: 1, Batch: 1001, Step num: 1001, Learning rate: 0.00069947, Avg batch loss: 0.5583, Avg batch acc: 0.4403
Train, Epoch: 1, Batch: 1002, Step num: 1002, Learning rate: 0.00070017, Avg batch loss: 0.5600, Avg batch acc: 0.3938
Train, Epoch: 1, Batch: 1003, Step num: 1003, Learning rate: 0.00070087, Avg batch loss: 0.5371, Avg batch acc: 0.4072
Train, Epoch: 1, Batch: 1004, Step num: 1004, Learning rate: 0.00070157, Avg batch loss: 0.6315, Avg batch acc: 0.3798
Train, Epoch: 1, Batch: 1005, Step num: 1005, Learning rate: 0.00070227, Avg batch loss: 0.6792, Avg batch acc: 0.3840
Train, Epoch: 1, Batch: 1006, Step num: 1006, Learning rate: 0.00070296, Avg batch loss: 0.5727, Avg batch acc: 0.4138
Train, Epoch: 1, Batch: 1007, Step num: 1007, Learning rate: 0.00070366, Avg batch loss: 0.5823, Avg batch acc: 0.4047
Train, Epoch: 1, Batch: 1008, Step num: 1008, Learning rate: 0.00070436, Avg batch loss: 0.6329, Avg batch acc: 0.4049
Train, Epoch: 1, Batch: 1009, Step num: 1009, Learning rate: 0.00070506, Avg batch loss: 0.5677, Avg batch acc: 0.3981
Train, Epoch: 1, Batch: 1010, Step num: 1010, Learning rate: 0.00070576, Avg batch loss: 0.6239, Avg batch acc: 0.3901
Train, Epoch: 1, Batch: 1011, Step num: 1011, Learning rate: 0.00070646, Avg batch loss: 0.5845, Avg batch acc: 0.4018
Train, Epoch: 1, Batch: 1012, Step num: 1012, Learning rate: 0.00070716, Avg batch loss: 0.5747, Avg batch acc: 0.4004
Train, Epoch: 1, Batch: 1013, Step num: 1013, Learning rate: 0.00070786, Avg batch loss: 0.5893, Avg batch acc: 0.4156
Train, Epoch: 1, Batch: 1014, Step num: 1014, Learning rate: 0.00070855, Avg batch loss: 0.6370, Avg batch acc: 0.4071
Train, Epoch: 1, Batch: 1015, Step num: 1015, Learning rate: 0.00070925, Avg batch loss: 0.5560, Avg batch acc: 0.3978
Train, Epoch: 1, Batch: 1016, Step num: 1016, Learning rate: 0.00070995, Avg batch loss: 0.5851, Avg batch acc: 0.4035
Train, Epoch: 1, Batch: 1017, Step num: 1017, Learning rate: 0.00071065, Avg batch loss: 0.6042, Avg batch acc: 0.4201
Train, Epoch: 1, Batch: 1018, Step num: 1018, Learning rate: 0.00071135, Avg batch loss: 0.5494, Avg batch acc: 0.4218
Train, Epoch: 1, Batch: 1019, Step num: 1019, Learning rate: 0.00071205, Avg batch loss: 0.5688, Avg batch acc: 0.3806
Train, Epoch: 1, Batch: 1020, Step num: 1020, Learning rate: 0.00071275, Avg batch loss: 0.6376, Avg batch acc: 0.3941
Train, Epoch: 1, Batch: 1021, Step num: 1021, Learning rate: 0.00071345, Avg batch loss: 0.5749, Avg batch acc: 0.4259
Train, Epoch: 1, Batch: 1022, Step num: 1022, Learning rate: 0.00071414, Avg batch loss: 0.5577, Avg batch acc: 0.4252
Train, Epoch: 1, Batch: 1023, Step num: 1023, Learning rate: 0.00071484, Avg batch loss: 0.5720, Avg batch acc: 0.4101
Train, Epoch: 1, Batch: 1024, Step num: 1024, Learning rate: 0.00071554, Avg batch loss: 0.6069, Avg batch acc: 0.4088
Train, Epoch: 1, Batch: 1025, Step num: 1025, Learning rate: 0.00071624, Avg batch loss: 0.5727, Avg batch acc: 0.4186
Train, Epoch: 1, Batch: 1026, Step num: 1026, Learning rate: 0.00071694, Avg batch loss: 0.5783, Avg batch acc: 0.3996
Train, Epoch: 1, Batch: 1027, Step num: 1027, Learning rate: 0.00071764, Avg batch loss: 0.5392, Avg batch acc: 0.3982
Train, Epoch: 1, Batch: 1028, Step num: 1028, Learning rate: 0.00071834, Avg batch loss: 0.5619, Avg batch acc: 0.4262
Train, Epoch: 1, Batch: 1029, Step num: 1029, Learning rate: 0.00071904, Avg batch loss: 0.6347, Avg batch acc: 0.3857
Train, Epoch: 1, Batch: 1030, Step num: 1030, Learning rate: 0.00071973, Avg batch loss: 0.5771, Avg batch acc: 0.4212
Train, Epoch: 1, Batch: 1031, Step num: 1031, Learning rate: 0.00072043, Avg batch loss: 0.5526, Avg batch acc: 0.3991
Train, Epoch: 1, Batch: 1032, Step num: 1032, Learning rate: 0.00072113, Avg batch loss: 0.5997, Avg batch acc: 0.4158
Train, Epoch: 1, Batch: 1033, Step num: 1033, Learning rate: 0.00072183, Avg batch loss: 0.6031, Avg batch acc: 0.3926
Train, Epoch: 1, Batch: 1034, Step num: 1034, Learning rate: 0.00072253, Avg batch loss: 0.5861, Avg batch acc: 0.4245
Train, Epoch: 1, Batch: 1035, Step num: 1035, Learning rate: 0.00072323, Avg batch loss: 0.6175, Avg batch acc: 0.4083
Train, Epoch: 1, Batch: 1036, Step num: 1036, Learning rate: 0.00072393, Avg batch loss: 0.5642, Avg batch acc: 0.4048
Train, Epoch: 1, Batch: 1037, Step num: 1037, Learning rate: 0.00072463, Avg batch loss: 0.5559, Avg batch acc: 0.4162
Train, Epoch: 1, Batch: 1038, Step num: 1038, Learning rate: 0.00072532, Avg batch loss: 0.5532, Avg batch acc: 0.4454
Train, Epoch: 1, Batch: 1039, Step num: 1039, Learning rate: 0.00072602, Avg batch loss: 0.5801, Avg batch acc: 0.4067
Train, Epoch: 1, Batch: 1040, Step num: 1040, Learning rate: 0.00072672, Avg batch loss: 0.5552, Avg batch acc: 0.4137
Train, Epoch: 1, Batch: 1041, Step num: 1041, Learning rate: 0.00072742, Avg batch loss: 0.5598, Avg batch acc: 0.4091
Train, Epoch: 1, Batch: 1042, Step num: 1042, Learning rate: 0.00072812, Avg batch loss: 0.5554, Avg batch acc: 0.4065
Train, Epoch: 1, Batch: 1043, Step num: 1043, Learning rate: 0.00072882, Avg batch loss: 0.5844, Avg batch acc: 0.3922
Train, Epoch: 1, Batch: 1044, Step num: 1044, Learning rate: 0.00072952, Avg batch loss: 0.5413, Avg batch acc: 0.3911
Train, Epoch: 1, Batch: 1045, Step num: 1045, Learning rate: 0.00073022, Avg batch loss: 0.6074, Avg batch acc: 0.3978
Train, Epoch: 1, Batch: 1046, Step num: 1046, Learning rate: 0.00073091, Avg batch loss: 0.6492, Avg batch acc: 0.3891
Train, Epoch: 1, Batch: 1047, Step num: 1047, Learning rate: 0.00073161, Avg batch loss: 0.6011, Avg batch acc: 0.4050
Train, Epoch: 1, Batch: 1048, Step num: 1048, Learning rate: 0.00073231, Avg batch loss: 0.6244, Avg batch acc: 0.4179
Train, Epoch: 1, Batch: 1049, Step num: 1049, Learning rate: 0.00073301, Avg batch loss: 0.5895, Avg batch acc: 0.4081
Train, Epoch: 1, Batch: 1050, Step num: 1050, Learning rate: 0.00073371, Avg batch loss: 0.5569, Avg batch acc: 0.4198
Train, Epoch: 1, Batch: 1051, Step num: 1051, Learning rate: 0.00073441, Avg batch loss: 0.6181, Avg batch acc: 0.4119
Train, Epoch: 1, Batch: 1052, Step num: 1052, Learning rate: 0.00073511, Avg batch loss: 0.5196, Avg batch acc: 0.4270
Train, Epoch: 1, Batch: 1053, Step num: 1053, Learning rate: 0.00073581, Avg batch loss: 0.6223, Avg batch acc: 0.3949
Train, Epoch: 1, Batch: 1054, Step num: 1054, Learning rate: 0.00073650, Avg batch loss: 0.6002, Avg batch acc: 0.4157
Train, Epoch: 1, Batch: 1055, Step num: 1055, Learning rate: 0.00073720, Avg batch loss: 0.6070, Avg batch acc: 0.3970
Train, Epoch: 1, Batch: 1056, Step num: 1056, Learning rate: 0.00073790, Avg batch loss: 0.5334, Avg batch acc: 0.4334
Train, Epoch: 1, Batch: 1057, Step num: 1057, Learning rate: 0.00073860, Avg batch loss: 0.5881, Avg batch acc: 0.3917
Train, Epoch: 1, Batch: 1058, Step num: 1058, Learning rate: 0.00073930, Avg batch loss: 0.5918, Avg batch acc: 0.3927
Train, Epoch: 1, Batch: 1059, Step num: 1059, Learning rate: 0.00074000, Avg batch loss: 0.5068, Avg batch acc: 0.4383
Train, Epoch: 1, Batch: 1060, Step num: 1060, Learning rate: 0.00074070, Avg batch loss: 0.5643, Avg batch acc: 0.4220
Train, Epoch: 1, Batch: 1061, Step num: 1061, Learning rate: 0.00074140, Avg batch loss: 0.5773, Avg batch acc: 0.3833
Train, Epoch: 1, Batch: 1062, Step num: 1062, Learning rate: 0.00074210, Avg batch loss: 0.6121, Avg batch acc: 0.4206
Train, Epoch: 1, Batch: 1063, Step num: 1063, Learning rate: 0.00074279, Avg batch loss: 0.6237, Avg batch acc: 0.4012
Train, Epoch: 1, Batch: 1064, Step num: 1064, Learning rate: 0.00074349, Avg batch loss: 0.5920, Avg batch acc: 0.4001
Train, Epoch: 1, Batch: 1065, Step num: 1065, Learning rate: 0.00074419, Avg batch loss: 0.6061, Avg batch acc: 0.4100
Train, Epoch: 1, Batch: 1066, Step num: 1066, Learning rate: 0.00074489, Avg batch loss: 0.6051, Avg batch acc: 0.4043
Train, Epoch: 1, Batch: 1067, Step num: 1067, Learning rate: 0.00074559, Avg batch loss: 0.6014, Avg batch acc: 0.4160
Train, Epoch: 1, Batch: 1068, Step num: 1068, Learning rate: 0.00074629, Avg batch loss: 0.5930, Avg batch acc: 0.4064
Train, Epoch: 1, Batch: 1069, Step num: 1069, Learning rate: 0.00074699, Avg batch loss: 0.6209, Avg batch acc: 0.4034
Train, Epoch: 1, Batch: 1070, Step num: 1070, Learning rate: 0.00074769, Avg batch loss: 0.5679, Avg batch acc: 0.4058
Train, Epoch: 1, Batch: 1071, Step num: 1071, Learning rate: 0.00074838, Avg batch loss: 0.6120, Avg batch acc: 0.4053
Train, Epoch: 1, Batch: 1072, Step num: 1072, Learning rate: 0.00074908, Avg batch loss: 0.5689, Avg batch acc: 0.4167
Train, Epoch: 1, Batch: 1073, Step num: 1073, Learning rate: 0.00074978, Avg batch loss: 0.5775, Avg batch acc: 0.4141
Train, Epoch: 1, Batch: 1074, Step num: 1074, Learning rate: 0.00075048, Avg batch loss: 0.6556, Avg batch acc: 0.3875
Train, Epoch: 1, Batch: 1075, Step num: 1075, Learning rate: 0.00075118, Avg batch loss: 0.5077, Avg batch acc: 0.4574
Train, Epoch: 1, Batch: 1076, Step num: 1076, Learning rate: 0.00075188, Avg batch loss: 0.5937, Avg batch acc: 0.4188
Train, Epoch: 1, Batch: 1077, Step num: 1077, Learning rate: 0.00075258, Avg batch loss: 0.6396, Avg batch acc: 0.4141
Train, Epoch: 1, Batch: 1078, Step num: 1078, Learning rate: 0.00075328, Avg batch loss: 0.5635, Avg batch acc: 0.4038
Train, Epoch: 1, Batch: 1079, Step num: 1079, Learning rate: 0.00075397, Avg batch loss: 0.6221, Avg batch acc: 0.4121
Train, Epoch: 1, Batch: 1080, Step num: 1080, Learning rate: 0.00075467, Avg batch loss: 0.5707, Avg batch acc: 0.4103
Train, Epoch: 1, Batch: 1081, Step num: 1081, Learning rate: 0.00075537, Avg batch loss: 0.5808, Avg batch acc: 0.4041
Train, Epoch: 1, Batch: 1082, Step num: 1082, Learning rate: 0.00075607, Avg batch loss: 0.6072, Avg batch acc: 0.4011
Train, Epoch: 1, Batch: 1083, Step num: 1083, Learning rate: 0.00075677, Avg batch loss: 0.6142, Avg batch acc: 0.3991
Train, Epoch: 1, Batch: 1084, Step num: 1084, Learning rate: 0.00075747, Avg batch loss: 0.6105, Avg batch acc: 0.3865
Train, Epoch: 1, Batch: 1085, Step num: 1085, Learning rate: 0.00075817, Avg batch loss: 0.5842, Avg batch acc: 0.4039
Train, Epoch: 1, Batch: 1086, Step num: 1086, Learning rate: 0.00075887, Avg batch loss: 0.5894, Avg batch acc: 0.4178
Train, Epoch: 1, Batch: 1087, Step num: 1087, Learning rate: 0.00075956, Avg batch loss: 0.6109, Avg batch acc: 0.4087
Train, Epoch: 1, Batch: 1088, Step num: 1088, Learning rate: 0.00076026, Avg batch loss: 0.5941, Avg batch acc: 0.4199
Train, Epoch: 1, Batch: 1089, Step num: 1089, Learning rate: 0.00076096, Avg batch loss: 0.5801, Avg batch acc: 0.4229
Train, Epoch: 1, Batch: 1090, Step num: 1090, Learning rate: 0.00076166, Avg batch loss: 0.5801, Avg batch acc: 0.4022
Train, Epoch: 1, Batch: 1091, Step num: 1091, Learning rate: 0.00076236, Avg batch loss: 0.6070, Avg batch acc: 0.3903
Train, Epoch: 1, Batch: 1092, Step num: 1092, Learning rate: 0.00076306, Avg batch loss: 0.5680, Avg batch acc: 0.3837
Train, Epoch: 1, Batch: 1093, Step num: 1093, Learning rate: 0.00076376, Avg batch loss: 0.5730, Avg batch acc: 0.4186
Train, Epoch: 1, Batch: 1094, Step num: 1094, Learning rate: 0.00076446, Avg batch loss: 0.5667, Avg batch acc: 0.4165
Train, Epoch: 1, Batch: 1095, Step num: 1095, Learning rate: 0.00076515, Avg batch loss: 0.5820, Avg batch acc: 0.4003
Train, Epoch: 1, Batch: 1096, Step num: 1096, Learning rate: 0.00076585, Avg batch loss: 0.6213, Avg batch acc: 0.4173
Train, Epoch: 1, Batch: 1097, Step num: 1097, Learning rate: 0.00076655, Avg batch loss: 0.5933, Avg batch acc: 0.4043
Train, Epoch: 1, Batch: 1098, Step num: 1098, Learning rate: 0.00076725, Avg batch loss: 0.5720, Avg batch acc: 0.4119
Train, Epoch: 1, Batch: 1099, Step num: 1099, Learning rate: 0.00076795, Avg batch loss: 0.6066, Avg batch acc: 0.3881
Train, Epoch: 1, Batch: 1100, Step num: 1100, Learning rate: 0.00076865, Avg batch loss: 0.5256, Avg batch acc: 0.4121
Train, Epoch: 1, Batch: 1101, Step num: 1101, Learning rate: 0.00076935, Avg batch loss: 0.5800, Avg batch acc: 0.4001
Train, Epoch: 1, Batch: 1102, Step num: 1102, Learning rate: 0.00077005, Avg batch loss: 0.5615, Avg batch acc: 0.4184
Train, Epoch: 1, Batch: 1103, Step num: 1103, Learning rate: 0.00077074, Avg batch loss: 0.6297, Avg batch acc: 0.3784
Train, Epoch: 1, Batch: 1104, Step num: 1104, Learning rate: 0.00077144, Avg batch loss: 0.5448, Avg batch acc: 0.4081
Train, Epoch: 1, Batch: 1105, Step num: 1105, Learning rate: 0.00077214, Avg batch loss: 0.5279, Avg batch acc: 0.4263
Train, Epoch: 1, Batch: 1106, Step num: 1106, Learning rate: 0.00077284, Avg batch loss: 0.5636, Avg batch acc: 0.4267
Train, Epoch: 1, Batch: 1107, Step num: 1107, Learning rate: 0.00077354, Avg batch loss: 0.5784, Avg batch acc: 0.4033
Train, Epoch: 1, Batch: 1108, Step num: 1108, Learning rate: 0.00077424, Avg batch loss: 0.5621, Avg batch acc: 0.4222
Train, Epoch: 1, Batch: 1109, Step num: 1109, Learning rate: 0.00077494, Avg batch loss: 0.5805, Avg batch acc: 0.4318
Train, Epoch: 1, Batch: 1110, Step num: 1110, Learning rate: 0.00077564, Avg batch loss: 0.5866, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1111, Step num: 1111, Learning rate: 0.00077633, Avg batch loss: 0.5603, Avg batch acc: 0.4097
Train, Epoch: 1, Batch: 1112, Step num: 1112, Learning rate: 0.00077703, Avg batch loss: 0.5443, Avg batch acc: 0.4111
Train, Epoch: 1, Batch: 1113, Step num: 1113, Learning rate: 0.00077773, Avg batch loss: 0.5157, Avg batch acc: 0.4222
Train, Epoch: 1, Batch: 1114, Step num: 1114, Learning rate: 0.00077843, Avg batch loss: 0.5890, Avg batch acc: 0.4030
Train, Epoch: 1, Batch: 1115, Step num: 1115, Learning rate: 0.00077913, Avg batch loss: 0.5639, Avg batch acc: 0.4186
Train, Epoch: 1, Batch: 1116, Step num: 1116, Learning rate: 0.00077983, Avg batch loss: 0.5335, Avg batch acc: 0.4182
Train, Epoch: 1, Batch: 1117, Step num: 1117, Learning rate: 0.00078053, Avg batch loss: 0.5394, Avg batch acc: 0.4065
Train, Epoch: 1, Batch: 1118, Step num: 1118, Learning rate: 0.00078123, Avg batch loss: 0.5375, Avg batch acc: 0.4335
Train, Epoch: 1, Batch: 1119, Step num: 1119, Learning rate: 0.00078193, Avg batch loss: 0.6094, Avg batch acc: 0.3999
Train, Epoch: 1, Batch: 1120, Step num: 1120, Learning rate: 0.00078262, Avg batch loss: 0.6527, Avg batch acc: 0.4039
Train, Epoch: 1, Batch: 1121, Step num: 1121, Learning rate: 0.00078332, Avg batch loss: 0.5362, Avg batch acc: 0.4026
Train, Epoch: 1, Batch: 1122, Step num: 1122, Learning rate: 0.00078402, Avg batch loss: 0.5902, Avg batch acc: 0.4008
Train, Epoch: 1, Batch: 1123, Step num: 1123, Learning rate: 0.00078472, Avg batch loss: 0.5322, Avg batch acc: 0.4082
Train, Epoch: 1, Batch: 1124, Step num: 1124, Learning rate: 0.00078542, Avg batch loss: 0.5683, Avg batch acc: 0.4166
Train, Epoch: 1, Batch: 1125, Step num: 1125, Learning rate: 0.00078612, Avg batch loss: 0.5942, Avg batch acc: 0.4065
Train, Epoch: 1, Batch: 1126, Step num: 1126, Learning rate: 0.00078682, Avg batch loss: 0.5826, Avg batch acc: 0.3908
Train, Epoch: 1, Batch: 1127, Step num: 1127, Learning rate: 0.00078752, Avg batch loss: 0.5320, Avg batch acc: 0.4414
Train, Epoch: 1, Batch: 1128, Step num: 1128, Learning rate: 0.00078821, Avg batch loss: 0.5415, Avg batch acc: 0.4201
Train, Epoch: 1, Batch: 1129, Step num: 1129, Learning rate: 0.00078891, Avg batch loss: 0.5960, Avg batch acc: 0.4101
Train, Epoch: 1, Batch: 1130, Step num: 1130, Learning rate: 0.00078961, Avg batch loss: 0.5850, Avg batch acc: 0.3855
Train, Epoch: 1, Batch: 1131, Step num: 1131, Learning rate: 0.00079031, Avg batch loss: 0.6139, Avg batch acc: 0.4073
Train, Epoch: 1, Batch: 1132, Step num: 1132, Learning rate: 0.00079101, Avg batch loss: 0.5429, Avg batch acc: 0.4461
Train, Epoch: 1, Batch: 1133, Step num: 1133, Learning rate: 0.00079171, Avg batch loss: 0.5311, Avg batch acc: 0.4251
Train, Epoch: 1, Batch: 1134, Step num: 1134, Learning rate: 0.00079241, Avg batch loss: 0.5681, Avg batch acc: 0.4407
Train, Epoch: 1, Batch: 1135, Step num: 1135, Learning rate: 0.00079311, Avg batch loss: 0.6165, Avg batch acc: 0.4006
Train, Epoch: 1, Batch: 1136, Step num: 1136, Learning rate: 0.00079380, Avg batch loss: 0.5804, Avg batch acc: 0.4027
Train, Epoch: 1, Batch: 1137, Step num: 1137, Learning rate: 0.00079450, Avg batch loss: 0.5548, Avg batch acc: 0.4032
Train, Epoch: 1, Batch: 1138, Step num: 1138, Learning rate: 0.00079520, Avg batch loss: 0.6033, Avg batch acc: 0.3992
Train, Epoch: 1, Batch: 1139, Step num: 1139, Learning rate: 0.00079590, Avg batch loss: 0.5683, Avg batch acc: 0.4098
Train, Epoch: 1, Batch: 1140, Step num: 1140, Learning rate: 0.00079660, Avg batch loss: 0.5913, Avg batch acc: 0.4211
Train, Epoch: 1, Batch: 1141, Step num: 1141, Learning rate: 0.00079730, Avg batch loss: 0.5074, Avg batch acc: 0.4273
Train, Epoch: 1, Batch: 1142, Step num: 1142, Learning rate: 0.00079800, Avg batch loss: 0.5791, Avg batch acc: 0.4017
Train, Epoch: 1, Batch: 1143, Step num: 1143, Learning rate: 0.00079870, Avg batch loss: 0.6929, Avg batch acc: 0.3982
Train, Epoch: 1, Batch: 1144, Step num: 1144, Learning rate: 0.00079939, Avg batch loss: 0.5662, Avg batch acc: 0.4111
Train, Epoch: 1, Batch: 1145, Step num: 1145, Learning rate: 0.00080009, Avg batch loss: 0.6073, Avg batch acc: 0.3911
Train, Epoch: 1, Batch: 1146, Step num: 1146, Learning rate: 0.00080079, Avg batch loss: 0.5623, Avg batch acc: 0.4095
Train, Epoch: 1, Batch: 1147, Step num: 1147, Learning rate: 0.00080149, Avg batch loss: 0.5219, Avg batch acc: 0.4060
Train, Epoch: 1, Batch: 1148, Step num: 1148, Learning rate: 0.00080219, Avg batch loss: 0.5953, Avg batch acc: 0.4024
Train, Epoch: 1, Batch: 1149, Step num: 1149, Learning rate: 0.00080289, Avg batch loss: 0.5770, Avg batch acc: 0.4042
Train, Epoch: 1, Batch: 1150, Step num: 1150, Learning rate: 0.00080359, Avg batch loss: 0.5795, Avg batch acc: 0.4085
Train, Epoch: 1, Batch: 1151, Step num: 1151, Learning rate: 0.00080429, Avg batch loss: 0.5918, Avg batch acc: 0.4299
Train, Epoch: 1, Batch: 1152, Step num: 1152, Learning rate: 0.00080498, Avg batch loss: 0.5520, Avg batch acc: 0.4025
Train, Epoch: 1, Batch: 1153, Step num: 1153, Learning rate: 0.00080568, Avg batch loss: 0.5588, Avg batch acc: 0.4244
Train, Epoch: 1, Batch: 1154, Step num: 1154, Learning rate: 0.00080638, Avg batch loss: 0.5279, Avg batch acc: 0.4179
Train, Epoch: 1, Batch: 1155, Step num: 1155, Learning rate: 0.00080708, Avg batch loss: 0.5722, Avg batch acc: 0.4409
Train, Epoch: 1, Batch: 1156, Step num: 1156, Learning rate: 0.00080778, Avg batch loss: 0.6130, Avg batch acc: 0.4268
Train, Epoch: 1, Batch: 1157, Step num: 1157, Learning rate: 0.00080848, Avg batch loss: 0.5316, Avg batch acc: 0.4280
Train, Epoch: 1, Batch: 1158, Step num: 1158, Learning rate: 0.00080918, Avg batch loss: 0.5842, Avg batch acc: 0.4244
Train, Epoch: 1, Batch: 1159, Step num: 1159, Learning rate: 0.00080988, Avg batch loss: 0.5701, Avg batch acc: 0.4267
Train, Epoch: 1, Batch: 1160, Step num: 1160, Learning rate: 0.00081057, Avg batch loss: 0.5700, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 1161, Step num: 1161, Learning rate: 0.00081127, Avg batch loss: 0.6309, Avg batch acc: 0.4002
Train, Epoch: 1, Batch: 1162, Step num: 1162, Learning rate: 0.00081197, Avg batch loss: 0.5301, Avg batch acc: 0.3970
Train, Epoch: 1, Batch: 1163, Step num: 1163, Learning rate: 0.00081267, Avg batch loss: 0.5986, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1164, Step num: 1164, Learning rate: 0.00081337, Avg batch loss: 0.6256, Avg batch acc: 0.4156
Train, Epoch: 1, Batch: 1165, Step num: 1165, Learning rate: 0.00081407, Avg batch loss: 0.5426, Avg batch acc: 0.4461
Train, Epoch: 1, Batch: 1166, Step num: 1166, Learning rate: 0.00081477, Avg batch loss: 0.6120, Avg batch acc: 0.4142
Train, Epoch: 1, Batch: 1167, Step num: 1167, Learning rate: 0.00081547, Avg batch loss: 0.6178, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1168, Step num: 1168, Learning rate: 0.00081616, Avg batch loss: 0.5948, Avg batch acc: 0.4236
Train, Epoch: 1, Batch: 1169, Step num: 1169, Learning rate: 0.00081686, Avg batch loss: 0.5966, Avg batch acc: 0.4118
Train, Epoch: 1, Batch: 1170, Step num: 1170, Learning rate: 0.00081756, Avg batch loss: 0.4856, Avg batch acc: 0.4248
Train, Epoch: 1, Batch: 1171, Step num: 1171, Learning rate: 0.00081826, Avg batch loss: 0.5767, Avg batch acc: 0.4198
Train, Epoch: 1, Batch: 1172, Step num: 1172, Learning rate: 0.00081896, Avg batch loss: 0.5611, Avg batch acc: 0.4244
Train, Epoch: 1, Batch: 1173, Step num: 1173, Learning rate: 0.00081966, Avg batch loss: 0.5987, Avg batch acc: 0.3909
Train, Epoch: 1, Batch: 1174, Step num: 1174, Learning rate: 0.00082036, Avg batch loss: 0.5928, Avg batch acc: 0.4078
Train, Epoch: 1, Batch: 1175, Step num: 1175, Learning rate: 0.00082106, Avg batch loss: 0.5513, Avg batch acc: 0.4033
Train, Epoch: 1, Batch: 1176, Step num: 1176, Learning rate: 0.00082175, Avg batch loss: 0.5733, Avg batch acc: 0.4154
Train, Epoch: 1, Batch: 1177, Step num: 1177, Learning rate: 0.00082245, Avg batch loss: 0.5617, Avg batch acc: 0.3929
Train, Epoch: 1, Batch: 1178, Step num: 1178, Learning rate: 0.00082315, Avg batch loss: 0.6095, Avg batch acc: 0.4193
Train, Epoch: 1, Batch: 1179, Step num: 1179, Learning rate: 0.00082385, Avg batch loss: 0.5292, Avg batch acc: 0.4247
Train, Epoch: 1, Batch: 1180, Step num: 1180, Learning rate: 0.00082455, Avg batch loss: 0.5645, Avg batch acc: 0.4082
Train, Epoch: 1, Batch: 1181, Step num: 1181, Learning rate: 0.00082525, Avg batch loss: 0.5576, Avg batch acc: 0.4126
Train, Epoch: 1, Batch: 1182, Step num: 1182, Learning rate: 0.00082595, Avg batch loss: 0.5784, Avg batch acc: 0.4030
Train, Epoch: 1, Batch: 1183, Step num: 1183, Learning rate: 0.00082665, Avg batch loss: 0.5246, Avg batch acc: 0.4341
Train, Epoch: 1, Batch: 1184, Step num: 1184, Learning rate: 0.00082735, Avg batch loss: 0.5722, Avg batch acc: 0.4219
Train, Epoch: 1, Batch: 1185, Step num: 1185, Learning rate: 0.00082804, Avg batch loss: 0.5755, Avg batch acc: 0.3992
Train, Epoch: 1, Batch: 1186, Step num: 1186, Learning rate: 0.00082874, Avg batch loss: 0.5406, Avg batch acc: 0.4220
Train, Epoch: 1, Batch: 1187, Step num: 1187, Learning rate: 0.00082944, Avg batch loss: 0.5581, Avg batch acc: 0.4245
Train, Epoch: 1, Batch: 1188, Step num: 1188, Learning rate: 0.00083014, Avg batch loss: 0.6082, Avg batch acc: 0.3991
Train, Epoch: 1, Batch: 1189, Step num: 1189, Learning rate: 0.00083084, Avg batch loss: 0.4991, Avg batch acc: 0.4448
Train, Epoch: 1, Batch: 1190, Step num: 1190, Learning rate: 0.00083154, Avg batch loss: 0.5465, Avg batch acc: 0.4299
Train, Epoch: 1, Batch: 1191, Step num: 1191, Learning rate: 0.00083224, Avg batch loss: 0.5512, Avg batch acc: 0.4131
Train, Epoch: 1, Batch: 1192, Step num: 1192, Learning rate: 0.00083294, Avg batch loss: 0.5973, Avg batch acc: 0.4173
Train, Epoch: 1, Batch: 1193, Step num: 1193, Learning rate: 0.00083363, Avg batch loss: 0.5592, Avg batch acc: 0.4263
Train, Epoch: 1, Batch: 1194, Step num: 1194, Learning rate: 0.00083433, Avg batch loss: 0.5658, Avg batch acc: 0.4239
Train, Epoch: 1, Batch: 1195, Step num: 1195, Learning rate: 0.00083503, Avg batch loss: 0.5164, Avg batch acc: 0.4299
Train, Epoch: 1, Batch: 1196, Step num: 1196, Learning rate: 0.00083573, Avg batch loss: 0.5246, Avg batch acc: 0.4428
Train, Epoch: 1, Batch: 1197, Step num: 1197, Learning rate: 0.00083643, Avg batch loss: 0.5394, Avg batch acc: 0.4364
Train, Epoch: 1, Batch: 1198, Step num: 1198, Learning rate: 0.00083713, Avg batch loss: 0.5783, Avg batch acc: 0.4186
Train, Epoch: 1, Batch: 1199, Step num: 1199, Learning rate: 0.00083783, Avg batch loss: 0.5093, Avg batch acc: 0.4265
Train, Epoch: 1, Batch: 1200, Step num: 1200, Learning rate: 0.00083853, Avg batch loss: 0.5834, Avg batch acc: 0.3964
Train, Epoch: 1, Batch: 1201, Step num: 1201, Learning rate: 0.00083922, Avg batch loss: 0.5747, Avg batch acc: 0.4300
Train, Epoch: 1, Batch: 1202, Step num: 1202, Learning rate: 0.00083992, Avg batch loss: 0.6050, Avg batch acc: 0.4072
Train, Epoch: 1, Batch: 1203, Step num: 1203, Learning rate: 0.00084062, Avg batch loss: 0.5542, Avg batch acc: 0.4235
Train, Epoch: 1, Batch: 1204, Step num: 1204, Learning rate: 0.00084132, Avg batch loss: 0.5386, Avg batch acc: 0.4294
Train, Epoch: 1, Batch: 1205, Step num: 1205, Learning rate: 0.00084202, Avg batch loss: 0.5483, Avg batch acc: 0.4101
Train, Epoch: 1, Batch: 1206, Step num: 1206, Learning rate: 0.00084272, Avg batch loss: 0.5712, Avg batch acc: 0.4063
Train, Epoch: 1, Batch: 1207, Step num: 1207, Learning rate: 0.00084342, Avg batch loss: 0.6105, Avg batch acc: 0.3874
Train, Epoch: 1, Batch: 1208, Step num: 1208, Learning rate: 0.00084412, Avg batch loss: 0.5482, Avg batch acc: 0.4306
Train, Epoch: 1, Batch: 1209, Step num: 1209, Learning rate: 0.00084481, Avg batch loss: 0.5438, Avg batch acc: 0.4332
Train, Epoch: 1, Batch: 1210, Step num: 1210, Learning rate: 0.00084551, Avg batch loss: 0.5888, Avg batch acc: 0.4106
Train, Epoch: 1, Batch: 1211, Step num: 1211, Learning rate: 0.00084621, Avg batch loss: 0.5716, Avg batch acc: 0.3971
Train, Epoch: 1, Batch: 1212, Step num: 1212, Learning rate: 0.00084691, Avg batch loss: 0.5404, Avg batch acc: 0.4226
Train, Epoch: 1, Batch: 1213, Step num: 1213, Learning rate: 0.00084761, Avg batch loss: 0.5787, Avg batch acc: 0.4459
Train, Epoch: 1, Batch: 1214, Step num: 1214, Learning rate: 0.00084831, Avg batch loss: 0.5455, Avg batch acc: 0.4229
Train, Epoch: 1, Batch: 1215, Step num: 1215, Learning rate: 0.00084901, Avg batch loss: 0.5639, Avg batch acc: 0.4357
Train, Epoch: 1, Batch: 1216, Step num: 1216, Learning rate: 0.00084971, Avg batch loss: 0.4882, Avg batch acc: 0.4389
Train, Epoch: 1, Batch: 1217, Step num: 1217, Learning rate: 0.00085040, Avg batch loss: 0.5322, Avg batch acc: 0.4192
Train, Epoch: 1, Batch: 1218, Step num: 1218, Learning rate: 0.00085110, Avg batch loss: 0.5793, Avg batch acc: 0.4012
Train, Epoch: 1, Batch: 1219, Step num: 1219, Learning rate: 0.00085180, Avg batch loss: 0.4898, Avg batch acc: 0.4152
Train, Epoch: 1, Batch: 1220, Step num: 1220, Learning rate: 0.00085250, Avg batch loss: 0.5646, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1221, Step num: 1221, Learning rate: 0.00085320, Avg batch loss: 0.5255, Avg batch acc: 0.4053
Train, Epoch: 1, Batch: 1222, Step num: 1222, Learning rate: 0.00085390, Avg batch loss: 0.5243, Avg batch acc: 0.4299
Train, Epoch: 1, Batch: 1223, Step num: 1223, Learning rate: 0.00085460, Avg batch loss: 0.5766, Avg batch acc: 0.4042
Train, Epoch: 1, Batch: 1224, Step num: 1224, Learning rate: 0.00085530, Avg batch loss: 0.6090, Avg batch acc: 0.4103
Train, Epoch: 1, Batch: 1225, Step num: 1225, Learning rate: 0.00085599, Avg batch loss: 0.5719, Avg batch acc: 0.4394
Train, Epoch: 1, Batch: 1226, Step num: 1226, Learning rate: 0.00085669, Avg batch loss: 0.5334, Avg batch acc: 0.4334
Train, Epoch: 1, Batch: 1227, Step num: 1227, Learning rate: 0.00085739, Avg batch loss: 0.6564, Avg batch acc: 0.4161
Train, Epoch: 1, Batch: 1228, Step num: 1228, Learning rate: 0.00085809, Avg batch loss: 0.5356, Avg batch acc: 0.4181
Train, Epoch: 1, Batch: 1229, Step num: 1229, Learning rate: 0.00085879, Avg batch loss: 0.5972, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1230, Step num: 1230, Learning rate: 0.00085949, Avg batch loss: 0.5221, Avg batch acc: 0.4465
Train, Epoch: 1, Batch: 1231, Step num: 1231, Learning rate: 0.00086019, Avg batch loss: 0.5902, Avg batch acc: 0.4060
Train, Epoch: 1, Batch: 1232, Step num: 1232, Learning rate: 0.00086089, Avg batch loss: 0.5888, Avg batch acc: 0.4184
Train, Epoch: 1, Batch: 1233, Step num: 1233, Learning rate: 0.00086158, Avg batch loss: 0.5816, Avg batch acc: 0.4157
Train, Epoch: 1, Batch: 1234, Step num: 1234, Learning rate: 0.00086228, Avg batch loss: 0.6412, Avg batch acc: 0.4091
Train, Epoch: 1, Batch: 1235, Step num: 1235, Learning rate: 0.00086298, Avg batch loss: 0.5573, Avg batch acc: 0.3996
Train, Epoch: 1, Batch: 1236, Step num: 1236, Learning rate: 0.00086368, Avg batch loss: 0.6244, Avg batch acc: 0.3954
Train, Epoch: 1, Batch: 1237, Step num: 1237, Learning rate: 0.00086438, Avg batch loss: 0.5215, Avg batch acc: 0.4403
Train, Epoch: 1, Batch: 1238, Step num: 1238, Learning rate: 0.00086508, Avg batch loss: 0.5786, Avg batch acc: 0.4119
Train, Epoch: 1, Batch: 1239, Step num: 1239, Learning rate: 0.00086578, Avg batch loss: 0.5787, Avg batch acc: 0.4158
Train, Epoch: 1, Batch: 1240, Step num: 1240, Learning rate: 0.00086648, Avg batch loss: 0.5786, Avg batch acc: 0.4179
Train, Epoch: 1, Batch: 1241, Step num: 1241, Learning rate: 0.00086718, Avg batch loss: 0.4932, Avg batch acc: 0.4117
Train, Epoch: 1, Batch: 1242, Step num: 1242, Learning rate: 0.00086787, Avg batch loss: 0.5974, Avg batch acc: 0.4187
Train, Epoch: 1, Batch: 1243, Step num: 1243, Learning rate: 0.00086857, Avg batch loss: 0.5637, Avg batch acc: 0.4198
Train, Epoch: 1, Batch: 1244, Step num: 1244, Learning rate: 0.00086927, Avg batch loss: 0.5783, Avg batch acc: 0.4166
Train, Epoch: 1, Batch: 1245, Step num: 1245, Learning rate: 0.00086997, Avg batch loss: 0.5040, Avg batch acc: 0.4387
Train, Epoch: 1, Batch: 1246, Step num: 1246, Learning rate: 0.00087067, Avg batch loss: 0.5667, Avg batch acc: 0.4153
Train, Epoch: 1, Batch: 1247, Step num: 1247, Learning rate: 0.00087137, Avg batch loss: 0.5162, Avg batch acc: 0.4079
Train, Epoch: 1, Batch: 1248, Step num: 1248, Learning rate: 0.00087207, Avg batch loss: 0.5177, Avg batch acc: 0.4177
Train, Epoch: 1, Batch: 1249, Step num: 1249, Learning rate: 0.00087277, Avg batch loss: 0.5314, Avg batch acc: 0.4194
Train, Epoch: 1, Batch: 1250, Step num: 1250, Learning rate: 0.00087346, Avg batch loss: 0.5028, Avg batch acc: 0.4476
Train, Epoch: 1, Batch: 1251, Step num: 1251, Learning rate: 0.00087416, Avg batch loss: 0.5575, Avg batch acc: 0.4203
Train, Epoch: 1, Batch: 1252, Step num: 1252, Learning rate: 0.00087486, Avg batch loss: 0.5314, Avg batch acc: 0.4201
Train, Epoch: 1, Batch: 1253, Step num: 1253, Learning rate: 0.00087556, Avg batch loss: 0.5471, Avg batch acc: 0.4296
Train, Epoch: 1, Batch: 1254, Step num: 1254, Learning rate: 0.00087626, Avg batch loss: 0.5712, Avg batch acc: 0.4096
Train, Epoch: 1, Batch: 1255, Step num: 1255, Learning rate: 0.00087696, Avg batch loss: 0.5615, Avg batch acc: 0.4165
Train, Epoch: 1, Batch: 1256, Step num: 1256, Learning rate: 0.00087766, Avg batch loss: 0.5505, Avg batch acc: 0.4107
Train, Epoch: 1, Batch: 1257, Step num: 1257, Learning rate: 0.00087836, Avg batch loss: 0.4982, Avg batch acc: 0.4277
Train, Epoch: 1, Batch: 1258, Step num: 1258, Learning rate: 0.00087905, Avg batch loss: 0.5355, Avg batch acc: 0.4322
Train, Epoch: 1, Batch: 1259, Step num: 1259, Learning rate: 0.00087975, Avg batch loss: 0.5421, Avg batch acc: 0.4294
Train, Epoch: 1, Batch: 1260, Step num: 1260, Learning rate: 0.00088045, Avg batch loss: 0.5630, Avg batch acc: 0.4094
Train, Epoch: 1, Batch: 1261, Step num: 1261, Learning rate: 0.00088115, Avg batch loss: 0.5434, Avg batch acc: 0.4179
Train, Epoch: 1, Batch: 1262, Step num: 1262, Learning rate: 0.00088185, Avg batch loss: 0.5944, Avg batch acc: 0.4211
Train, Epoch: 1, Batch: 1263, Step num: 1263, Learning rate: 0.00088255, Avg batch loss: 0.5108, Avg batch acc: 0.4173
Train, Epoch: 1, Batch: 1264, Step num: 1264, Learning rate: 0.00088325, Avg batch loss: 0.5384, Avg batch acc: 0.4313
Train, Epoch: 1, Batch: 1265, Step num: 1265, Learning rate: 0.00088395, Avg batch loss: 0.5841, Avg batch acc: 0.4203
Train, Epoch: 1, Batch: 1266, Step num: 1266, Learning rate: 0.00088464, Avg batch loss: 0.5382, Avg batch acc: 0.4127
Train, Epoch: 1, Batch: 1267, Step num: 1267, Learning rate: 0.00088534, Avg batch loss: 0.5313, Avg batch acc: 0.4259
Train, Epoch: 1, Batch: 1268, Step num: 1268, Learning rate: 0.00088604, Avg batch loss: 0.5166, Avg batch acc: 0.4096
Train, Epoch: 1, Batch: 1269, Step num: 1269, Learning rate: 0.00088674, Avg batch loss: 0.5274, Avg batch acc: 0.4424
Train, Epoch: 1, Batch: 1270, Step num: 1270, Learning rate: 0.00088744, Avg batch loss: 0.5322, Avg batch acc: 0.4218
Train, Epoch: 1, Batch: 1271, Step num: 1271, Learning rate: 0.00088814, Avg batch loss: 0.6250, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1272, Step num: 1272, Learning rate: 0.00088884, Avg batch loss: 0.5347, Avg batch acc: 0.4367
Train, Epoch: 1, Batch: 1273, Step num: 1273, Learning rate: 0.00088954, Avg batch loss: 0.5257, Avg batch acc: 0.4096
Train, Epoch: 1, Batch: 1274, Step num: 1274, Learning rate: 0.00089023, Avg batch loss: 0.5301, Avg batch acc: 0.4173
Train, Epoch: 1, Batch: 1275, Step num: 1275, Learning rate: 0.00089093, Avg batch loss: 0.4741, Avg batch acc: 0.4489
Train, Epoch: 1, Batch: 1276, Step num: 1276, Learning rate: 0.00089163, Avg batch loss: 0.5333, Avg batch acc: 0.4280
Train, Epoch: 1, Batch: 1277, Step num: 1277, Learning rate: 0.00089233, Avg batch loss: 0.5049, Avg batch acc: 0.4468
Train, Epoch: 1, Batch: 1278, Step num: 1278, Learning rate: 0.00089303, Avg batch loss: 0.5462, Avg batch acc: 0.4281
Train, Epoch: 1, Batch: 1279, Step num: 1279, Learning rate: 0.00089373, Avg batch loss: 0.5528, Avg batch acc: 0.4283
Train, Epoch: 1, Batch: 1280, Step num: 1280, Learning rate: 0.00089443, Avg batch loss: 0.4940, Avg batch acc: 0.4260
Train, Epoch: 1, Batch: 1281, Step num: 1281, Learning rate: 0.00089513, Avg batch loss: 0.5878, Avg batch acc: 0.4046
Train, Epoch: 1, Batch: 1282, Step num: 1282, Learning rate: 0.00089582, Avg batch loss: 0.5714, Avg batch acc: 0.4201
Train, Epoch: 1, Batch: 1283, Step num: 1283, Learning rate: 0.00089652, Avg batch loss: 0.5689, Avg batch acc: 0.4224
Train, Epoch: 1, Batch: 1284, Step num: 1284, Learning rate: 0.00089722, Avg batch loss: 0.5363, Avg batch acc: 0.4137
Train, Epoch: 1, Batch: 1285, Step num: 1285, Learning rate: 0.00089792, Avg batch loss: 0.5264, Avg batch acc: 0.4338
Train, Epoch: 1, Batch: 1286, Step num: 1286, Learning rate: 0.00089862, Avg batch loss: 0.5845, Avg batch acc: 0.4135
Train, Epoch: 1, Batch: 1287, Step num: 1287, Learning rate: 0.00089932, Avg batch loss: 0.5628, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1288, Step num: 1288, Learning rate: 0.00090002, Avg batch loss: 0.5934, Avg batch acc: 0.4266
Train, Epoch: 1, Batch: 1289, Step num: 1289, Learning rate: 0.00090072, Avg batch loss: 0.5591, Avg batch acc: 0.4359
Train, Epoch: 1, Batch: 1290, Step num: 1290, Learning rate: 0.00090141, Avg batch loss: 0.5812, Avg batch acc: 0.4321
Train, Epoch: 1, Batch: 1291, Step num: 1291, Learning rate: 0.00090211, Avg batch loss: 0.5163, Avg batch acc: 0.4333
Train, Epoch: 1, Batch: 1292, Step num: 1292, Learning rate: 0.00090281, Avg batch loss: 0.5182, Avg batch acc: 0.4429
Train, Epoch: 1, Batch: 1293, Step num: 1293, Learning rate: 0.00090351, Avg batch loss: 0.5201, Avg batch acc: 0.4144
Train, Epoch: 1, Batch: 1294, Step num: 1294, Learning rate: 0.00090421, Avg batch loss: 0.4967, Avg batch acc: 0.4304
Train, Epoch: 1, Batch: 1295, Step num: 1295, Learning rate: 0.00090491, Avg batch loss: 0.5632, Avg batch acc: 0.4287
Train, Epoch: 1, Batch: 1296, Step num: 1296, Learning rate: 0.00090561, Avg batch loss: 0.6527, Avg batch acc: 0.4055
Train, Epoch: 1, Batch: 1297, Step num: 1297, Learning rate: 0.00090631, Avg batch loss: 0.5724, Avg batch acc: 0.4380
Train, Epoch: 1, Batch: 1298, Step num: 1298, Learning rate: 0.00090701, Avg batch loss: 0.5741, Avg batch acc: 0.4168
Train, Epoch: 1, Batch: 1299, Step num: 1299, Learning rate: 0.00090770, Avg batch loss: 0.5610, Avg batch acc: 0.4155
Train, Epoch: 1, Batch: 1300, Step num: 1300, Learning rate: 0.00090840, Avg batch loss: 0.5555, Avg batch acc: 0.4348
Train, Epoch: 1, Batch: 1301, Step num: 1301, Learning rate: 0.00090910, Avg batch loss: 0.5545, Avg batch acc: 0.4173
Train, Epoch: 1, Batch: 1302, Step num: 1302, Learning rate: 0.00090980, Avg batch loss: 0.5236, Avg batch acc: 0.4290
Train, Epoch: 1, Batch: 1303, Step num: 1303, Learning rate: 0.00091050, Avg batch loss: 0.5934, Avg batch acc: 0.4250
Train, Epoch: 1, Batch: 1304, Step num: 1304, Learning rate: 0.00091120, Avg batch loss: 0.4841, Avg batch acc: 0.4470
Train, Epoch: 1, Batch: 1305, Step num: 1305, Learning rate: 0.00091190, Avg batch loss: 0.5679, Avg batch acc: 0.4249
Train, Epoch: 1, Batch: 1306, Step num: 1306, Learning rate: 0.00091260, Avg batch loss: 0.5679, Avg batch acc: 0.4192
Train, Epoch: 1, Batch: 1307, Step num: 1307, Learning rate: 0.00091329, Avg batch loss: 0.5395, Avg batch acc: 0.4350
Train, Epoch: 1, Batch: 1308, Step num: 1308, Learning rate: 0.00091399, Avg batch loss: 0.5626, Avg batch acc: 0.4104
Train, Epoch: 1, Batch: 1309, Step num: 1309, Learning rate: 0.00091469, Avg batch loss: 0.5164, Avg batch acc: 0.4346
Train, Epoch: 1, Batch: 1310, Step num: 1310, Learning rate: 0.00091539, Avg batch loss: 0.5849, Avg batch acc: 0.4246
Train, Epoch: 1, Batch: 1311, Step num: 1311, Learning rate: 0.00091609, Avg batch loss: 0.5541, Avg batch acc: 0.4074
Train, Epoch: 1, Batch: 1312, Step num: 1312, Learning rate: 0.00091679, Avg batch loss: 0.5651, Avg batch acc: 0.4246
Train, Epoch: 1, Batch: 1313, Step num: 1313, Learning rate: 0.00091749, Avg batch loss: 0.5201, Avg batch acc: 0.4360
Train, Epoch: 1, Batch: 1314, Step num: 1314, Learning rate: 0.00091819, Avg batch loss: 0.5441, Avg batch acc: 0.4170
Train, Epoch: 1, Batch: 1315, Step num: 1315, Learning rate: 0.00091888, Avg batch loss: 0.5448, Avg batch acc: 0.4010
Train, Epoch: 1, Batch: 1316, Step num: 1316, Learning rate: 0.00091958, Avg batch loss: 0.5669, Avg batch acc: 0.4235
Train, Epoch: 1, Batch: 1317, Step num: 1317, Learning rate: 0.00092028, Avg batch loss: 0.5271, Avg batch acc: 0.4359
Train, Epoch: 1, Batch: 1318, Step num: 1318, Learning rate: 0.00092098, Avg batch loss: 0.5628, Avg batch acc: 0.4143
Train, Epoch: 1, Batch: 1319, Step num: 1319, Learning rate: 0.00092168, Avg batch loss: 0.5229, Avg batch acc: 0.4379
Train, Epoch: 1, Batch: 1320, Step num: 1320, Learning rate: 0.00092238, Avg batch loss: 0.5511, Avg batch acc: 0.4078
Train, Epoch: 1, Batch: 1321, Step num: 1321, Learning rate: 0.00092308, Avg batch loss: 0.5953, Avg batch acc: 0.3948
Train, Epoch: 1, Batch: 1322, Step num: 1322, Learning rate: 0.00092378, Avg batch loss: 0.6011, Avg batch acc: 0.4110
Train, Epoch: 1, Batch: 1323, Step num: 1323, Learning rate: 0.00092447, Avg batch loss: 0.4702, Avg batch acc: 0.4456
Train, Epoch: 1, Batch: 1324, Step num: 1324, Learning rate: 0.00092517, Avg batch loss: 0.5542, Avg batch acc: 0.4261
Train, Epoch: 1, Batch: 1325, Step num: 1325, Learning rate: 0.00092587, Avg batch loss: 0.5276, Avg batch acc: 0.4354
Train, Epoch: 1, Batch: 1326, Step num: 1326, Learning rate: 0.00092657, Avg batch loss: 0.4761, Avg batch acc: 0.4441
Train, Epoch: 1, Batch: 1327, Step num: 1327, Learning rate: 0.00092727, Avg batch loss: 0.5307, Avg batch acc: 0.4477
Train, Epoch: 1, Batch: 1328, Step num: 1328, Learning rate: 0.00092797, Avg batch loss: 0.5172, Avg batch acc: 0.4190
Train, Epoch: 1, Batch: 1329, Step num: 1329, Learning rate: 0.00092867, Avg batch loss: 0.5453, Avg batch acc: 0.4247
Train, Epoch: 1, Batch: 1330, Step num: 1330, Learning rate: 0.00092937, Avg batch loss: 0.5729, Avg batch acc: 0.4352
Train, Epoch: 1, Batch: 1331, Step num: 1331, Learning rate: 0.00093006, Avg batch loss: 0.5356, Avg batch acc: 0.4229
Train, Epoch: 1, Batch: 1332, Step num: 1332, Learning rate: 0.00093076, Avg batch loss: 0.5757, Avg batch acc: 0.4148
Train, Epoch: 1, Batch: 1333, Step num: 1333, Learning rate: 0.00093146, Avg batch loss: 0.5209, Avg batch acc: 0.4286
Train, Epoch: 1, Batch: 1334, Step num: 1334, Learning rate: 0.00093216, Avg batch loss: 0.5036, Avg batch acc: 0.4279
Train, Epoch: 1, Batch: 1335, Step num: 1335, Learning rate: 0.00093286, Avg batch loss: 0.5694, Avg batch acc: 0.4262
Train, Epoch: 1, Batch: 1336, Step num: 1336, Learning rate: 0.00093356, Avg batch loss: 0.5607, Avg batch acc: 0.4388
Train, Epoch: 1, Batch: 1337, Step num: 1337, Learning rate: 0.00093426, Avg batch loss: 0.6259, Avg batch acc: 0.4018
Train, Epoch: 1, Batch: 1338, Step num: 1338, Learning rate: 0.00093496, Avg batch loss: 0.6079, Avg batch acc: 0.4363
Train, Epoch: 1, Batch: 1339, Step num: 1339, Learning rate: 0.00093565, Avg batch loss: 0.5430, Avg batch acc: 0.4367
Train, Epoch: 1, Batch: 1340, Step num: 1340, Learning rate: 0.00093635, Avg batch loss: 0.5060, Avg batch acc: 0.4456
Train, Epoch: 1, Batch: 1341, Step num: 1341, Learning rate: 0.00093705, Avg batch loss: 0.5226, Avg batch acc: 0.4357
Train, Epoch: 1, Batch: 1342, Step num: 1342, Learning rate: 0.00093775, Avg batch loss: 0.5190, Avg batch acc: 0.4278
Train, Epoch: 1, Batch: 1343, Step num: 1343, Learning rate: 0.00093845, Avg batch loss: 0.5426, Avg batch acc: 0.4311
Train, Epoch: 1, Batch: 1344, Step num: 1344, Learning rate: 0.00093915, Avg batch loss: 0.5854, Avg batch acc: 0.4338
Train, Epoch: 1, Batch: 1345, Step num: 1345, Learning rate: 0.00093985, Avg batch loss: 0.5213, Avg batch acc: 0.4321
Train, Epoch: 1, Batch: 1346, Step num: 1346, Learning rate: 0.00094055, Avg batch loss: 0.5739, Avg batch acc: 0.4255
Train, Epoch: 1, Batch: 1347, Step num: 1347, Learning rate: 0.00094124, Avg batch loss: 0.5776, Avg batch acc: 0.4464
Train, Epoch: 1, Batch: 1348, Step num: 1348, Learning rate: 0.00094194, Avg batch loss: 0.5575, Avg batch acc: 0.4224
Train, Epoch: 1, Batch: 1349, Step num: 1349, Learning rate: 0.00094264, Avg batch loss: 0.5089, Avg batch acc: 0.4502
Train, Epoch: 1, Batch: 1350, Step num: 1350, Learning rate: 0.00094334, Avg batch loss: 0.4827, Avg batch acc: 0.4261
Train, Epoch: 1, Batch: 1351, Step num: 1351, Learning rate: 0.00094404, Avg batch loss: 0.5362, Avg batch acc: 0.4188
Train, Epoch: 1, Batch: 1352, Step num: 1352, Learning rate: 0.00094474, Avg batch loss: 0.4625, Avg batch acc: 0.4506
Train, Epoch: 1, Batch: 1353, Step num: 1353, Learning rate: 0.00094544, Avg batch loss: 0.5128, Avg batch acc: 0.4323
Train, Epoch: 1, Batch: 1354, Step num: 1354, Learning rate: 0.00094614, Avg batch loss: 0.5118, Avg batch acc: 0.4540
Train, Epoch: 1, Batch: 1355, Step num: 1355, Learning rate: 0.00094684, Avg batch loss: 0.5210, Avg batch acc: 0.4455
Train, Epoch: 1, Batch: 1356, Step num: 1356, Learning rate: 0.00094753, Avg batch loss: 0.5783, Avg batch acc: 0.4146
Train, Epoch: 1, Batch: 1357, Step num: 1357, Learning rate: 0.00094823, Avg batch loss: 0.4682, Avg batch acc: 0.4308
Train, Epoch: 1, Batch: 1358, Step num: 1358, Learning rate: 0.00094893, Avg batch loss: 0.4877, Avg batch acc: 0.4479
Train, Epoch: 1, Batch: 1359, Step num: 1359, Learning rate: 0.00094963, Avg batch loss: 0.5522, Avg batch acc: 0.4490
Train, Epoch: 1, Batch: 1360, Step num: 1360, Learning rate: 0.00095033, Avg batch loss: 0.6079, Avg batch acc: 0.4147
Train, Epoch: 1, Batch: 1361, Step num: 1361, Learning rate: 0.00095103, Avg batch loss: 0.5741, Avg batch acc: 0.4229
Train, Epoch: 1, Batch: 1362, Step num: 1362, Learning rate: 0.00095173, Avg batch loss: 0.5630, Avg batch acc: 0.4209
Train, Epoch: 1, Batch: 1363, Step num: 1363, Learning rate: 0.00095243, Avg batch loss: 0.5591, Avg batch acc: 0.4521
Train, Epoch: 1, Batch: 1364, Step num: 1364, Learning rate: 0.00095312, Avg batch loss: 0.4631, Avg batch acc: 0.4710
Train, Epoch: 1, Batch: 1365, Step num: 1365, Learning rate: 0.00095382, Avg batch loss: 0.4983, Avg batch acc: 0.4446
Train, Epoch: 1, Batch: 1366, Step num: 1366, Learning rate: 0.00095452, Avg batch loss: 0.5332, Avg batch acc: 0.4582
Train, Epoch: 1, Batch: 1367, Step num: 1367, Learning rate: 0.00095522, Avg batch loss: 0.5778, Avg batch acc: 0.4198
Train, Epoch: 1, Batch: 1368, Step num: 1368, Learning rate: 0.00095592, Avg batch loss: 0.5426, Avg batch acc: 0.4441
Train, Epoch: 1, Batch: 1369, Step num: 1369, Learning rate: 0.00095662, Avg batch loss: 0.5761, Avg batch acc: 0.3964
Train, Epoch: 1, Batch: 1370, Step num: 1370, Learning rate: 0.00095732, Avg batch loss: 0.5682, Avg batch acc: 0.4310
Train, Epoch: 1, Batch: 1371, Step num: 1371, Learning rate: 0.00095802, Avg batch loss: 0.5009, Avg batch acc: 0.4436
Train, Epoch: 1, Batch: 1372, Step num: 1372, Learning rate: 0.00095871, Avg batch loss: 0.5626, Avg batch acc: 0.4251
Train, Epoch: 1, Batch: 1373, Step num: 1373, Learning rate: 0.00095941, Avg batch loss: 0.4797, Avg batch acc: 0.4688
Train, Epoch: 1, Batch: 1374, Step num: 1374, Learning rate: 0.00096011, Avg batch loss: 0.5385, Avg batch acc: 0.4058
Train, Epoch: 1, Batch: 1375, Step num: 1375, Learning rate: 0.00096081, Avg batch loss: 0.5438, Avg batch acc: 0.4367
Train, Epoch: 1, Batch: 1376, Step num: 1376, Learning rate: 0.00096151, Avg batch loss: 0.5015, Avg batch acc: 0.4605
Train, Epoch: 1, Batch: 1377, Step num: 1377, Learning rate: 0.00096221, Avg batch loss: 0.5228, Avg batch acc: 0.4169
Train, Epoch: 1, Batch: 1378, Step num: 1378, Learning rate: 0.00096291, Avg batch loss: 0.5600, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 1379, Step num: 1379, Learning rate: 0.00096361, Avg batch loss: 0.5292, Avg batch acc: 0.4088
Train, Epoch: 1, Batch: 1380, Step num: 1380, Learning rate: 0.00096430, Avg batch loss: 0.5540, Avg batch acc: 0.4207
Train, Epoch: 1, Batch: 1381, Step num: 1381, Learning rate: 0.00096500, Avg batch loss: 0.5613, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1382, Step num: 1382, Learning rate: 0.00096570, Avg batch loss: 0.5136, Avg batch acc: 0.4360
Train, Epoch: 1, Batch: 1383, Step num: 1383, Learning rate: 0.00096640, Avg batch loss: 0.5646, Avg batch acc: 0.4157
Train, Epoch: 1, Batch: 1384, Step num: 1384, Learning rate: 0.00096710, Avg batch loss: 0.5885, Avg batch acc: 0.4179
Train, Epoch: 1, Batch: 1385, Step num: 1385, Learning rate: 0.00096780, Avg batch loss: 0.5080, Avg batch acc: 0.4218
Train, Epoch: 1, Batch: 1386, Step num: 1386, Learning rate: 0.00096850, Avg batch loss: 0.4978, Avg batch acc: 0.4476
Train, Epoch: 1, Batch: 1387, Step num: 1387, Learning rate: 0.00096920, Avg batch loss: 0.5183, Avg batch acc: 0.4268
Train, Epoch: 1, Batch: 1388, Step num: 1388, Learning rate: 0.00096989, Avg batch loss: 0.5506, Avg batch acc: 0.4143
Train, Epoch: 1, Batch: 1389, Step num: 1389, Learning rate: 0.00097059, Avg batch loss: 0.5349, Avg batch acc: 0.4325
Train, Epoch: 1, Batch: 1390, Step num: 1390, Learning rate: 0.00097129, Avg batch loss: 0.5000, Avg batch acc: 0.4253
Train, Epoch: 1, Batch: 1391, Step num: 1391, Learning rate: 0.00097199, Avg batch loss: 0.5342, Avg batch acc: 0.4500
Train, Epoch: 1, Batch: 1392, Step num: 1392, Learning rate: 0.00097269, Avg batch loss: 0.5381, Avg batch acc: 0.4239
Train, Epoch: 1, Batch: 1393, Step num: 1393, Learning rate: 0.00097339, Avg batch loss: 0.5865, Avg batch acc: 0.3962
Train, Epoch: 1, Batch: 1394, Step num: 1394, Learning rate: 0.00097409, Avg batch loss: 0.4961, Avg batch acc: 0.4415
Train, Epoch: 1, Batch: 1395, Step num: 1395, Learning rate: 0.00097479, Avg batch loss: 0.5905, Avg batch acc: 0.4311
Train, Epoch: 1, Batch: 1396, Step num: 1396, Learning rate: 0.00097548, Avg batch loss: 0.5591, Avg batch acc: 0.4388
Train, Epoch: 1, Batch: 1397, Step num: 1397, Learning rate: 0.00097618, Avg batch loss: 0.5626, Avg batch acc: 0.4119
Train, Epoch: 1, Batch: 1398, Step num: 1398, Learning rate: 0.00097688, Avg batch loss: 0.5541, Avg batch acc: 0.4282
Train, Epoch: 1, Batch: 1399, Step num: 1399, Learning rate: 0.00097758, Avg batch loss: 0.6067, Avg batch acc: 0.4024
Train, Epoch: 1, Batch: 1400, Step num: 1400, Learning rate: 0.00097828, Avg batch loss: 0.5222, Avg batch acc: 0.4359
Train, Epoch: 1, Batch: 1401, Step num: 1401, Learning rate: 0.00097898, Avg batch loss: 0.5568, Avg batch acc: 0.4139
Train, Epoch: 1, Batch: 1402, Step num: 1402, Learning rate: 0.00097968, Avg batch loss: 0.5481, Avg batch acc: 0.4274
Train, Epoch: 1, Batch: 1403, Step num: 1403, Learning rate: 0.00098038, Avg batch loss: 0.5420, Avg batch acc: 0.4259
Train, Epoch: 1, Batch: 1404, Step num: 1404, Learning rate: 0.00098107, Avg batch loss: 0.5406, Avg batch acc: 0.4293
Train, Epoch: 1, Batch: 1405, Step num: 1405, Learning rate: 0.00098177, Avg batch loss: 0.4846, Avg batch acc: 0.4424
Train, Epoch: 1, Batch: 1406, Step num: 1406, Learning rate: 0.00098247, Avg batch loss: 0.4795, Avg batch acc: 0.4534
Train, Epoch: 1, Batch: 1407, Step num: 1407, Learning rate: 0.00098317, Avg batch loss: 0.4880, Avg batch acc: 0.4445
Train, Epoch: 1, Batch: 1408, Step num: 1408, Learning rate: 0.00098387, Avg batch loss: 0.5479, Avg batch acc: 0.4216
Train, Epoch: 1, Batch: 1409, Step num: 1409, Learning rate: 0.00098457, Avg batch loss: 0.5506, Avg batch acc: 0.4193
Train, Epoch: 1, Batch: 1410, Step num: 1410, Learning rate: 0.00098527, Avg batch loss: 0.5807, Avg batch acc: 0.4087
Train, Epoch: 1, Batch: 1411, Step num: 1411, Learning rate: 0.00098597, Avg batch loss: 0.5754, Avg batch acc: 0.4277
Train, Epoch: 1, Batch: 1412, Step num: 1412, Learning rate: 0.00098666, Avg batch loss: 0.5660, Avg batch acc: 0.4261
Train, Epoch: 1, Batch: 1413, Step num: 1413, Learning rate: 0.00098736, Avg batch loss: 0.4348, Avg batch acc: 0.4698
Train, Epoch: 1, Batch: 1414, Step num: 1414, Learning rate: 0.00098806, Avg batch loss: 0.5125, Avg batch acc: 0.4299
Train, Epoch: 1, Batch: 1415, Step num: 1415, Learning rate: 0.00098876, Avg batch loss: 0.5611, Avg batch acc: 0.4126
Train, Epoch: 1, Batch: 1416, Step num: 1416, Learning rate: 0.00098946, Avg batch loss: 0.5009, Avg batch acc: 0.4331
Train, Epoch: 1, Batch: 1417, Step num: 1417, Learning rate: 0.00099016, Avg batch loss: 0.5405, Avg batch acc: 0.4371
Train, Epoch: 1, Batch: 1418, Step num: 1418, Learning rate: 0.00099086, Avg batch loss: 0.5322, Avg batch acc: 0.4510
Train, Epoch: 1, Batch: 1419, Step num: 1419, Learning rate: 0.00099156, Avg batch loss: 0.5589, Avg batch acc: 0.4405
Train, Epoch: 1, Batch: 1420, Step num: 1420, Learning rate: 0.00099226, Avg batch loss: 0.5624, Avg batch acc: 0.4231
Train, Epoch: 1, Batch: 1421, Step num: 1421, Learning rate: 0.00099295, Avg batch loss: 0.5569, Avg batch acc: 0.4100
Train, Epoch: 1, Batch: 1422, Step num: 1422, Learning rate: 0.00099365, Avg batch loss: 0.4909, Avg batch acc: 0.4297
Train, Epoch: 1, Batch: 1423, Step num: 1423, Learning rate: 0.00099435, Avg batch loss: 0.5247, Avg batch acc: 0.4465
Train, Epoch: 1, Batch: 1424, Step num: 1424, Learning rate: 0.00099505, Avg batch loss: 0.5426, Avg batch acc: 0.4406
Train, Epoch: 1, Batch: 1425, Step num: 1425, Learning rate: 0.00099575, Avg batch loss: 0.5484, Avg batch acc: 0.4210
Train, Epoch: 1, Batch: 1426, Step num: 1426, Learning rate: 0.00099645, Avg batch loss: 0.4984, Avg batch acc: 0.4570
Train, Epoch: 1, Batch: 1427, Step num: 1427, Learning rate: 0.00099715, Avg batch loss: 0.5588, Avg batch acc: 0.4317
Train, Epoch: 1, Batch: 1428, Step num: 1428, Learning rate: 0.00099785, Avg batch loss: 0.5758, Avg batch acc: 0.4108
Train, Epoch: 1, Batch: 1429, Step num: 1429, Learning rate: 0.00099854, Avg batch loss: 0.5256, Avg batch acc: 0.4134
Train, Epoch: 1, Batch: 1430, Step num: 1430, Learning rate: 0.00099924, Avg batch loss: 0.5504, Avg batch acc: 0.4382
Train, Epoch: 1, Batch: 1431, Step num: 1431, Learning rate: 0.00099994, Avg batch loss: 0.5480, Avg batch acc: 0.4305
Train, Epoch: 1, Batch: 1432, Step num: 1432, Learning rate: 0.00100064, Avg batch loss: 0.5405, Avg batch acc: 0.4308
Train, Epoch: 1, Batch: 1433, Step num: 1433, Learning rate: 0.00100134, Avg batch loss: 0.5594, Avg batch acc: 0.4329
Train, Epoch: 1, Batch: 1434, Step num: 1434, Learning rate: 0.00100204, Avg batch loss: 0.5495, Avg batch acc: 0.4376
Train, Epoch: 1, Batch: 1435, Step num: 1435, Learning rate: 0.00100274, Avg batch loss: 0.4889, Avg batch acc: 0.4454
Train, Epoch: 1, Batch: 1436, Step num: 1436, Learning rate: 0.00100344, Avg batch loss: 0.5515, Avg batch acc: 0.4165
Train, Epoch: 1, Batch: 1437, Step num: 1437, Learning rate: 0.00100413, Avg batch loss: 0.5443, Avg batch acc: 0.4177
Train, Epoch: 1, Batch: 1438, Step num: 1438, Learning rate: 0.00100483, Avg batch loss: 0.5049, Avg batch acc: 0.4407
Train, Epoch: 1, Batch: 1439, Step num: 1439, Learning rate: 0.00100553, Avg batch loss: 0.5594, Avg batch acc: 0.4143
Train, Epoch: 1, Batch: 1440, Step num: 1440, Learning rate: 0.00100623, Avg batch loss: 0.5312, Avg batch acc: 0.4304
Train, Epoch: 1, Batch: 1441, Step num: 1441, Learning rate: 0.00100693, Avg batch loss: 0.5153, Avg batch acc: 0.4549
Train, Epoch: 1, Batch: 1442, Step num: 1442, Learning rate: 0.00100763, Avg batch loss: 0.5366, Avg batch acc: 0.4200
Train, Epoch: 1, Batch: 1443, Step num: 1443, Learning rate: 0.00100833, Avg batch loss: 0.5867, Avg batch acc: 0.4244
Train, Epoch: 1, Batch: 1444, Step num: 1444, Learning rate: 0.00100903, Avg batch loss: 0.5714, Avg batch acc: 0.4238
Train, Epoch: 1, Batch: 1445, Step num: 1445, Learning rate: 0.00100972, Avg batch loss: 0.5601, Avg batch acc: 0.4109
Train, Epoch: 1, Batch: 1446, Step num: 1446, Learning rate: 0.00101042, Avg batch loss: 0.5008, Avg batch acc: 0.4270
Train, Epoch: 1, Batch: 1447, Step num: 1447, Learning rate: 0.00101112, Avg batch loss: 0.5157, Avg batch acc: 0.4355
Train, Epoch: 1, Batch: 1448, Step num: 1448, Learning rate: 0.00101182, Avg batch loss: 0.5002, Avg batch acc: 0.4457
Train, Epoch: 1, Batch: 1449, Step num: 1449, Learning rate: 0.00101252, Avg batch loss: 0.5210, Avg batch acc: 0.4592
Train, Epoch: 1, Batch: 1450, Step num: 1450, Learning rate: 0.00101322, Avg batch loss: 0.5372, Avg batch acc: 0.4396
Train, Epoch: 1, Batch: 1451, Step num: 1451, Learning rate: 0.00101392, Avg batch loss: 0.5440, Avg batch acc: 0.4308
Train, Epoch: 1, Batch: 1452, Step num: 1452, Learning rate: 0.00101462, Avg batch loss: 0.4838, Avg batch acc: 0.4399
Train, Epoch: 1, Batch: 1453, Step num: 1453, Learning rate: 0.00101531, Avg batch loss: 0.5329, Avg batch acc: 0.4262
Train, Epoch: 1, Batch: 1454, Step num: 1454, Learning rate: 0.00101601, Avg batch loss: 0.5356, Avg batch acc: 0.4083
Train, Epoch: 1, Batch: 1455, Step num: 1455, Learning rate: 0.00101671, Avg batch loss: 0.5581, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1456, Step num: 1456, Learning rate: 0.00101741, Avg batch loss: 0.5408, Avg batch acc: 0.4338
Train, Epoch: 1, Batch: 1457, Step num: 1457, Learning rate: 0.00101811, Avg batch loss: 0.5445, Avg batch acc: 0.4194
Train, Epoch: 1, Batch: 1458, Step num: 1458, Learning rate: 0.00101881, Avg batch loss: 0.4926, Avg batch acc: 0.4403
Train, Epoch: 1, Batch: 1459, Step num: 1459, Learning rate: 0.00101951, Avg batch loss: 0.5120, Avg batch acc: 0.4228
Train, Epoch: 1, Batch: 1460, Step num: 1460, Learning rate: 0.00102021, Avg batch loss: 0.5542, Avg batch acc: 0.4379
Train, Epoch: 1, Batch: 1461, Step num: 1461, Learning rate: 0.00102090, Avg batch loss: 0.5781, Avg batch acc: 0.4258
Train, Epoch: 1, Batch: 1462, Step num: 1462, Learning rate: 0.00102160, Avg batch loss: 0.5284, Avg batch acc: 0.4324
Train, Epoch: 1, Batch: 1463, Step num: 1463, Learning rate: 0.00102230, Avg batch loss: 0.5254, Avg batch acc: 0.4206
Train, Epoch: 1, Batch: 1464, Step num: 1464, Learning rate: 0.00102300, Avg batch loss: 0.5810, Avg batch acc: 0.4129
Train, Epoch: 1, Batch: 1465, Step num: 1465, Learning rate: 0.00102370, Avg batch loss: 0.5403, Avg batch acc: 0.4446
Train, Epoch: 1, Batch: 1466, Step num: 1466, Learning rate: 0.00102440, Avg batch loss: 0.4869, Avg batch acc: 0.4321
Train, Epoch: 1, Batch: 1467, Step num: 1467, Learning rate: 0.00102510, Avg batch loss: 0.5735, Avg batch acc: 0.4338
Train, Epoch: 1, Batch: 1468, Step num: 1468, Learning rate: 0.00102580, Avg batch loss: 0.5163, Avg batch acc: 0.4340
Train, Epoch: 1, Batch: 1469, Step num: 1469, Learning rate: 0.00102649, Avg batch loss: 0.5418, Avg batch acc: 0.4138
Train, Epoch: 1, Batch: 1470, Step num: 1470, Learning rate: 0.00102719, Avg batch loss: 0.5900, Avg batch acc: 0.4092
Train, Epoch: 1, Batch: 1471, Step num: 1471, Learning rate: 0.00102789, Avg batch loss: 0.5138, Avg batch acc: 0.4261
Train, Epoch: 1, Batch: 1472, Step num: 1472, Learning rate: 0.00102859, Avg batch loss: 0.5001, Avg batch acc: 0.4475
Train, Epoch: 1, Batch: 1473, Step num: 1473, Learning rate: 0.00102929, Avg batch loss: 0.5456, Avg batch acc: 0.4422
Train, Epoch: 1, Batch: 1474, Step num: 1474, Learning rate: 0.00102999, Avg batch loss: 0.5160, Avg batch acc: 0.4198
Train, Epoch: 1, Batch: 1475, Step num: 1475, Learning rate: 0.00103069, Avg batch loss: 0.5257, Avg batch acc: 0.4390
Train, Epoch: 1, Batch: 1476, Step num: 1476, Learning rate: 0.00103139, Avg batch loss: 0.5195, Avg batch acc: 0.4442
Train, Epoch: 1, Batch: 1477, Step num: 1477, Learning rate: 0.00103209, Avg batch loss: 0.4613, Avg batch acc: 0.4634
Train, Epoch: 1, Batch: 1478, Step num: 1478, Learning rate: 0.00103278, Avg batch loss: 0.4993, Avg batch acc: 0.4298
Train, Epoch: 1, Batch: 1479, Step num: 1479, Learning rate: 0.00103348, Avg batch loss: 0.5039, Avg batch acc: 0.4482
Train, Epoch: 1, Batch: 1480, Step num: 1480, Learning rate: 0.00103418, Avg batch loss: 0.4642, Avg batch acc: 0.4560
Train, Epoch: 1, Batch: 1481, Step num: 1481, Learning rate: 0.00103488, Avg batch loss: 0.5063, Avg batch acc: 0.4462
Train, Epoch: 1, Batch: 1482, Step num: 1482, Learning rate: 0.00103558, Avg batch loss: 0.5563, Avg batch acc: 0.4352
Train, Epoch: 1, Batch: 1483, Step num: 1483, Learning rate: 0.00103628, Avg batch loss: 0.5373, Avg batch acc: 0.4340
Train, Epoch: 1, Batch: 1484, Step num: 1484, Learning rate: 0.00103698, Avg batch loss: 0.5676, Avg batch acc: 0.3977
Train, Epoch: 1, Batch: 1485, Step num: 1485, Learning rate: 0.00103768, Avg batch loss: 0.4356, Avg batch acc: 0.4619
Train, Epoch: 1, Batch: 1486, Step num: 1486, Learning rate: 0.00103837, Avg batch loss: 0.5355, Avg batch acc: 0.4531
Train, Epoch: 1, Batch: 1487, Step num: 1487, Learning rate: 0.00103907, Avg batch loss: 0.5277, Avg batch acc: 0.4276
Train, Epoch: 1, Batch: 1488, Step num: 1488, Learning rate: 0.00103977, Avg batch loss: 0.5344, Avg batch acc: 0.4310
Train, Epoch: 1, Batch: 1489, Step num: 1489, Learning rate: 0.00104047, Avg batch loss: 0.5366, Avg batch acc: 0.4385
Train, Epoch: 1, Batch: 1490, Step num: 1490, Learning rate: 0.00104117, Avg batch loss: 0.5048, Avg batch acc: 0.4432
Train, Epoch: 1, Batch: 1491, Step num: 1491, Learning rate: 0.00104187, Avg batch loss: 0.5523, Avg batch acc: 0.4141
Train, Epoch: 1, Batch: 1492, Step num: 1492, Learning rate: 0.00104257, Avg batch loss: 0.5424, Avg batch acc: 0.4258
Train, Epoch: 1, Batch: 1493, Step num: 1493, Learning rate: 0.00104327, Avg batch loss: 0.4989, Avg batch acc: 0.4392
Train, Epoch: 1, Batch: 1494, Step num: 1494, Learning rate: 0.00104396, Avg batch loss: 0.5511, Avg batch acc: 0.4234
Train, Epoch: 1, Batch: 1495, Step num: 1495, Learning rate: 0.00104466, Avg batch loss: 0.5003, Avg batch acc: 0.4499
Train, Epoch: 1, Batch: 1496, Step num: 1496, Learning rate: 0.00104536, Avg batch loss: 0.5396, Avg batch acc: 0.4321
Train, Epoch: 1, Batch: 1497, Step num: 1497, Learning rate: 0.00104606, Avg batch loss: 0.5475, Avg batch acc: 0.4362
Train, Epoch: 1, Batch: 1498, Step num: 1498, Learning rate: 0.00104676, Avg batch loss: 0.5031, Avg batch acc: 0.4415
Train, Epoch: 1, Batch: 1499, Step num: 1499, Learning rate: 0.00104746, Avg batch loss: 0.5525, Avg batch acc: 0.4235
Train, Epoch: 1, Batch: 1500, Step num: 1500, Learning rate: 0.00104816, Avg batch loss: 0.5395, Avg batch acc: 0.4357
Train, Epoch: 1, Batch: 1501, Step num: 1501, Learning rate: 0.00104886, Avg batch loss: 0.5797, Avg batch acc: 0.4078
Train, Epoch: 1, Batch: 1502, Step num: 1502, Learning rate: 0.00104955, Avg batch loss: 0.5478, Avg batch acc: 0.4179
Train, Epoch: 1, Batch: 1503, Step num: 1503, Learning rate: 0.00105025, Avg batch loss: 0.5032, Avg batch acc: 0.4502
Train, Epoch: 1, Batch: 1504, Step num: 1504, Learning rate: 0.00105095, Avg batch loss: 0.5539, Avg batch acc: 0.4309
Train, Epoch: 1, Batch: 1505, Step num: 1505, Learning rate: 0.00105165, Avg batch loss: 0.5478, Avg batch acc: 0.4150
Train, Epoch: 1, Batch: 1506, Step num: 1506, Learning rate: 0.00105235, Avg batch loss: 0.5045, Avg batch acc: 0.4294
Train, Epoch: 1, Batch: 1507, Step num: 1507, Learning rate: 0.00105305, Avg batch loss: 0.4901, Avg batch acc: 0.4457
Train, Epoch: 1, Batch: 1508, Step num: 1508, Learning rate: 0.00105375, Avg batch loss: 0.5179, Avg batch acc: 0.4445
Train, Epoch: 1, Batch: 1509, Step num: 1509, Learning rate: 0.00105445, Avg batch loss: 0.5073, Avg batch acc: 0.4347
Train, Epoch: 1, Batch: 1510, Step num: 1510, Learning rate: 0.00105514, Avg batch loss: 0.5633, Avg batch acc: 0.4237
Train, Epoch: 1, Batch: 1511, Step num: 1511, Learning rate: 0.00105584, Avg batch loss: 0.5401, Avg batch acc: 0.4289
Train, Epoch: 1, Batch: 1512, Step num: 1512, Learning rate: 0.00105654, Avg batch loss: 0.4959, Avg batch acc: 0.4432
Train, Epoch: 1, Batch: 1513, Step num: 1513, Learning rate: 0.00105724, Avg batch loss: 0.5226, Avg batch acc: 0.4301
Train, Epoch: 1, Batch: 1514, Step num: 1514, Learning rate: 0.00105794, Avg batch loss: 0.4498, Avg batch acc: 0.4580
Train, Epoch: 1, Batch: 1515, Step num: 1515, Learning rate: 0.00105864, Avg batch loss: 0.5416, Avg batch acc: 0.4086
Train, Epoch: 1, Batch: 1516, Step num: 1516, Learning rate: 0.00105934, Avg batch loss: 0.5176, Avg batch acc: 0.4477
Train, Epoch: 1, Batch: 1517, Step num: 1517, Learning rate: 0.00106004, Avg batch loss: 0.5433, Avg batch acc: 0.4266
Train, Epoch: 1, Batch: 1518, Step num: 1518, Learning rate: 0.00106073, Avg batch loss: 0.4708, Avg batch acc: 0.4727
Train, Epoch: 1, Batch: 1519, Step num: 1519, Learning rate: 0.00106143, Avg batch loss: 0.5238, Avg batch acc: 0.4474
Train, Epoch: 1, Avg epoch loss: 0.7318, Avg epoch acc: 0.3492, Overall time: 422.0 s, Speed: 10313.7 tokens/s on cuda:3

Validate, Epoch: 1, Batch: 1, Avg batch loss: 0.4381, Avg batch acc: 0.4490
Validate, Epoch: 1, Batch: 2, Avg batch loss: 0.4723, Avg batch acc: 0.4542
Validate, Epoch: 1, Batch: 3, Avg batch loss: 0.5210, Avg batch acc: 0.4177
Validate, Epoch: 1, Batch: 4, Avg batch loss: 0.5056, Avg batch acc: 0.4335
Validate, Epoch: 1, Batch: 5, Avg batch loss: 0.4193, Avg batch acc: 0.4617
Validate, Epoch: 1, Batch: 6, Avg batch loss: 0.5802, Avg batch acc: 0.4213
Validate, Epoch: 1, Batch: 7, Avg batch loss: 0.5993, Avg batch acc: 0.4276
Validate, Epoch: 1, Batch: 8, Avg batch loss: 0.5688, Avg batch acc: 0.4147
Validate, Epoch: 1, Batch: 9, Avg batch loss: 0.5125, Avg batch acc: 0.4299
Validate, Epoch: 1, Batch: 10, Avg batch loss: 0.4647, Avg batch acc: 0.4555
Validate, Epoch: 1, Batch: 11, Avg batch loss: 0.5312, Avg batch acc: 0.4583
Validate, Epoch: 1, Batch: 12, Avg batch loss: 0.5009, Avg batch acc: 0.4464
Validate, Epoch: 1, Batch: 13, Avg batch loss: 0.5528, Avg batch acc: 0.4233
Validate, Epoch: 1, Batch: 14, Avg batch loss: 0.4868, Avg batch acc: 0.4169
Validate, Epoch: 1, Batch: 15, Avg batch loss: 0.5589, Avg batch acc: 0.4165
Validate, Epoch: 1, Batch: 16, Avg batch loss: 0.4810, Avg batch acc: 0.4472
Validate, Epoch: 1, Batch: 17, Avg batch loss: 0.4740, Avg batch acc: 0.4530
Validate, Epoch: 1, Batch: 18, Avg batch loss: 0.5813, Avg batch acc: 0.4351
Validate, Epoch: 1, Batch: 19, Avg batch loss: 0.5473, Avg batch acc: 0.4245
Validate, Epoch: 1, Batch: 20, Avg batch loss: 0.4927, Avg batch acc: 0.4532
Validate, Epoch: 1, Batch: 21, Avg batch loss: 0.5256, Avg batch acc: 0.4536
Validate, Epoch: 1, Batch: 22, Avg batch loss: 0.5809, Avg batch acc: 0.4271
Validate, Epoch: 1, Batch: 23, Avg batch loss: 0.5246, Avg batch acc: 0.4469
Validate, Epoch: 1, Batch: 24, Avg batch loss: 0.5061, Avg batch acc: 0.4375
Validate, Epoch: 1, Batch: 25, Avg batch loss: 0.5168, Avg batch acc: 0.4526
Validate, Epoch: 1, Batch: 26, Avg batch loss: 0.4906, Avg batch acc: 0.4424
Validate, Epoch: 1, Batch: 27, Avg batch loss: 0.4840, Avg batch acc: 0.4545
Validate, Epoch: 1, Batch: 28, Avg batch loss: 0.4994, Avg batch acc: 0.4528
Validate, Epoch: 1, Batch: 29, Avg batch loss: 0.4955, Avg batch acc: 0.4428
Validate, Epoch: 1, Batch: 30, Avg batch loss: 0.5288, Avg batch acc: 0.4388
Validate, Epoch: 1, Batch: 31, Avg batch loss: 0.5580, Avg batch acc: 0.4249
Validate, Epoch: 1, Batch: 32, Avg batch loss: 0.5539, Avg batch acc: 0.4259
Validate, Epoch: 1, Batch: 33, Avg batch loss: 0.5828, Avg batch acc: 0.4115
Validate, Epoch: 1, Batch: 34, Avg batch loss: 0.5469, Avg batch acc: 0.4359
Validate, Epoch: 1, Batch: 35, Avg batch loss: 0.5577, Avg batch acc: 0.4635
Validate, Epoch: 1, Batch: 36, Avg batch loss: 0.5383, Avg batch acc: 0.4291
Validate, Epoch: 1, Batch: 37, Avg batch loss: 0.5318, Avg batch acc: 0.4399
Validate, Epoch: 1, Batch: 38, Avg batch loss: 0.5585, Avg batch acc: 0.4424
Validate, Epoch: 1, Batch: 39, Avg batch loss: 0.5081, Avg batch acc: 0.4476
Validate, Epoch: 1, Batch: 40, Avg batch loss: 0.4780, Avg batch acc: 0.4554
Validate, Epoch: 1, Batch: 41, Avg batch loss: 0.5298, Avg batch acc: 0.4483
Validate, Epoch: 1, Batch: 42, Avg batch loss: 0.4846, Avg batch acc: 0.4717
Validate, Epoch: 1, Batch: 43, Avg batch loss: 0.4957, Avg batch acc: 0.4277
Validate, Epoch: 1, Batch: 44, Avg batch loss: 0.5532, Avg batch acc: 0.4269
Validate, Epoch: 1, Batch: 45, Avg batch loss: 0.5494, Avg batch acc: 0.4301
Validate, Epoch: 1, Batch: 46, Avg batch loss: 0.4694, Avg batch acc: 0.4391
Validate, Epoch: 1, Batch: 47, Avg batch loss: 0.4960, Avg batch acc: 0.4182
Validate, Epoch: 1, Batch: 48, Avg batch loss: 0.5001, Avg batch acc: 0.4558
Validate, Epoch: 1, Batch: 49, Avg batch loss: 0.4736, Avg batch acc: 0.4678
Validate, Epoch: 1, Batch: 50, Avg batch loss: 0.5125, Avg batch acc: 0.4558
Validate, Epoch: 1, Batch: 51, Avg batch loss: 0.5335, Avg batch acc: 0.4599
Validate, Epoch: 1, Batch: 52, Avg batch loss: 0.5049, Avg batch acc: 0.4607
Validate, Epoch: 1, Batch: 53, Avg batch loss: 0.5439, Avg batch acc: 0.4186
Validate, Epoch: 1, Batch: 54, Avg batch loss: 0.5495, Avg batch acc: 0.4324
Validate, Epoch: 1, Batch: 55, Avg batch loss: 0.4938, Avg batch acc: 0.4520
Validate, Epoch: 1, Batch: 56, Avg batch loss: 0.5554, Avg batch acc: 0.4281
Validate, Epoch: 1, Batch: 57, Avg batch loss: 0.4802, Avg batch acc: 0.4467
Validate, Epoch: 1, Batch: 58, Avg batch loss: 0.5065, Avg batch acc: 0.4586
Validate, Epoch: 1, Batch: 59, Avg batch loss: 0.5577, Avg batch acc: 0.4465
Validate, Epoch: 1, Batch: 60, Avg batch loss: 0.4940, Avg batch acc: 0.4643
Validate, Epoch: 1, Batch: 61, Avg batch loss: 0.5346, Avg batch acc: 0.4386
Validate, Epoch: 1, Batch: 62, Avg batch loss: 0.5147, Avg batch acc: 0.4570
Validate, Epoch: 1, Batch: 63, Avg batch loss: 0.5182, Avg batch acc: 0.4425
Validate, Epoch: 1, Batch: 64, Avg batch loss: 0.5693, Avg batch acc: 0.4269
Validate, Epoch: 1, Batch: 65, Avg batch loss: 0.5027, Avg batch acc: 0.4493
Validate, Epoch: 1, Batch: 66, Avg batch loss: 0.5196, Avg batch acc: 0.4508
Validate, Epoch: 1, Batch: 67, Avg batch loss: 0.4664, Avg batch acc: 0.4588
Validate, Epoch: 1, Batch: 68, Avg batch loss: 0.5323, Avg batch acc: 0.4360
Validate, Epoch: 1, Batch: 69, Avg batch loss: 0.4926, Avg batch acc: 0.4341
Validate, Epoch: 1, Batch: 70, Avg batch loss: 0.5359, Avg batch acc: 0.4315
Validate, Epoch: 1, Batch: 71, Avg batch loss: 0.4620, Avg batch acc: 0.4315
Validate, Epoch: 1, Batch: 72, Avg batch loss: 0.4465, Avg batch acc: 0.4551
Validate, Epoch: 1, Batch: 73, Avg batch loss: 0.4712, Avg batch acc: 0.4584
Validate, Epoch: 1, Batch: 74, Avg batch loss: 0.5456, Avg batch acc: 0.4208
Validate, Epoch: 1, Batch: 75, Avg batch loss: 0.5224, Avg batch acc: 0.4249
Validate, Epoch: 1, Batch: 76, Avg batch loss: 0.5210, Avg batch acc: 0.4274
Validate, Epoch: 1, Batch: 77, Avg batch loss: 0.4758, Avg batch acc: 0.4475
Validate, Epoch: 1, Batch: 78, Avg batch loss: 0.5032, Avg batch acc: 0.4349
Validate, Epoch: 1, Batch: 79, Avg batch loss: 0.5395, Avg batch acc: 0.4623
Validate, Epoch: 1, Batch: 80, Avg batch loss: 0.5125, Avg batch acc: 0.4504
Validate, Epoch: 1, Batch: 81, Avg batch loss: 0.4942, Avg batch acc: 0.4460
Validate, Epoch: 1, Batch: 82, Avg batch loss: 0.5141, Avg batch acc: 0.4409
Validate, Epoch: 1, Batch: 83, Avg batch loss: 0.5032, Avg batch acc: 0.4332
Validate, Epoch: 1, Batch: 84, Avg batch loss: 0.5252, Avg batch acc: 0.4424
Validate, Epoch: 1, Batch: 85, Avg batch loss: 0.4775, Avg batch acc: 0.4644
Validate, Epoch: 1, Batch: 86, Avg batch loss: 0.4843, Avg batch acc: 0.4640
Validate, Epoch: 1, Batch: 87, Avg batch loss: 0.4649, Avg batch acc: 0.4656
Validate, Epoch: 1, Batch: 88, Avg batch loss: 0.5224, Avg batch acc: 0.4476
Validate, Epoch: 1, Batch: 89, Avg batch loss: 0.5372, Avg batch acc: 0.4563
Validate, Epoch: 1, Batch: 90, Avg batch loss: 0.5065, Avg batch acc: 0.4368
Validate, Epoch: 1, Batch: 91, Avg batch loss: 0.4967, Avg batch acc: 0.4334
Validate, Epoch: 1, Batch: 92, Avg batch loss: 0.4691, Avg batch acc: 0.4549
Validate, Epoch: 1, Batch: 93, Avg batch loss: 0.5456, Avg batch acc: 0.4275
Validate, Epoch: 1, Batch: 94, Avg batch loss: 0.4618, Avg batch acc: 0.4557
Validate, Epoch: 1, Batch: 95, Avg batch loss: 0.5092, Avg batch acc: 0.4393
Validate, Epoch: 1, Batch: 96, Avg batch loss: 0.5262, Avg batch acc: 0.4295
Validate, Epoch: 1, Batch: 97, Avg batch loss: 0.5432, Avg batch acc: 0.4244
Validate, Epoch: 1, Batch: 98, Avg batch loss: 0.5416, Avg batch acc: 0.4122
Validate, Epoch: 1, Batch: 99, Avg batch loss: 0.5575, Avg batch acc: 0.4519
Validate, Epoch: 1, Batch: 100, Avg batch loss: 0.5326, Avg batch acc: 0.4272
Validate, Epoch: 1, Batch: 101, Avg batch loss: 0.5279, Avg batch acc: 0.4280
Validate, Epoch: 1, Batch: 102, Avg batch loss: 0.5079, Avg batch acc: 0.4441
Validate, Epoch: 1, Batch: 103, Avg batch loss: 0.5351, Avg batch acc: 0.4282
Validate, Epoch: 1, Batch: 104, Avg batch loss: 0.4757, Avg batch acc: 0.4321
Validate, Epoch: 1, Batch: 105, Avg batch loss: 0.4935, Avg batch acc: 0.4358
Validate, Epoch: 1, Batch: 106, Avg batch loss: 0.4775, Avg batch acc: 0.4494
Validate, Epoch: 1, Batch: 107, Avg batch loss: 0.4993, Avg batch acc: 0.4505
Validate, Epoch: 1, Batch: 108, Avg batch loss: 0.5634, Avg batch acc: 0.4223
Validate, Epoch: 1, Batch: 109, Avg batch loss: 0.4954, Avg batch acc: 0.4320
Validate, Epoch: 1, Batch: 110, Avg batch loss: 0.5288, Avg batch acc: 0.4271
Validate, Epoch: 1, Batch: 111, Avg batch loss: 0.4839, Avg batch acc: 0.4364
Validate, Epoch: 1, Batch: 112, Avg batch loss: 0.5238, Avg batch acc: 0.4441
Validate, Epoch: 1, Batch: 113, Avg batch loss: 0.5036, Avg batch acc: 0.4520
Validate, Epoch: 1, Batch: 114, Avg batch loss: 0.5067, Avg batch acc: 0.4430
Validate, Epoch: 1, Batch: 115, Avg batch loss: 0.5639, Avg batch acc: 0.3953
Validate, Epoch: 1, Batch: 116, Avg batch loss: 0.4865, Avg batch acc: 0.4409
Validate, Epoch: 1, Batch: 117, Avg batch loss: 0.5470, Avg batch acc: 0.4430
Validate, Epoch: 1, Batch: 118, Avg batch loss: 0.5885, Avg batch acc: 0.4300
Validate, Epoch: 1, Batch: 119, Avg batch loss: 0.5025, Avg batch acc: 0.4574
Validate, Epoch: 1, Batch: 120, Avg batch loss: 0.5404, Avg batch acc: 0.4360
Validate, Epoch: 1, Batch: 121, Avg batch loss: 0.4626, Avg batch acc: 0.4474
Validate, Epoch: 1, Batch: 122, Avg batch loss: 0.5459, Avg batch acc: 0.4353
Validate, Epoch: 1, Batch: 123, Avg batch loss: 0.4744, Avg batch acc: 0.4477
Validate, Epoch: 1, Batch: 124, Avg batch loss: 0.5254, Avg batch acc: 0.4355
Validate, Epoch: 1, Batch: 125, Avg batch loss: 0.5076, Avg batch acc: 0.4521
Validate, Epoch: 1, Batch: 126, Avg batch loss: 0.4872, Avg batch acc: 0.4607
Validate, Epoch: 1, Batch: 127, Avg batch loss: 0.5091, Avg batch acc: 0.4451
Validate, Epoch: 1, Batch: 128, Avg batch loss: 0.4893, Avg batch acc: 0.4542
Validate, Epoch: 1, Batch: 129, Avg batch loss: 0.5446, Avg batch acc: 0.4379
Validate, Epoch: 1, Batch: 130, Avg batch loss: 0.5241, Avg batch acc: 0.4316
Validate, Epoch: 1, Batch: 131, Avg batch loss: 0.4188, Avg batch acc: 0.4773
Validate, Epoch: 1, Batch: 132, Avg batch loss: 0.5548, Avg batch acc: 0.4356
Validate, Epoch: 1, Batch: 133, Avg batch loss: 0.5156, Avg batch acc: 0.4446
Validate, Epoch: 1, Batch: 134, Avg batch loss: 0.5893, Avg batch acc: 0.4287
Validate, Epoch: 1, Batch: 135, Avg batch loss: 0.5038, Avg batch acc: 0.4253
Validate, Epoch: 1, Batch: 136, Avg batch loss: 0.5242, Avg batch acc: 0.4443
Validate, Epoch: 1, Batch: 137, Avg batch loss: 0.5351, Avg batch acc: 0.4272
Validate, Epoch: 1, Batch: 138, Avg batch loss: 0.5235, Avg batch acc: 0.4277
Validate, Epoch: 1, Batch: 139, Avg batch loss: 0.5328, Avg batch acc: 0.4422
Validate, Epoch: 1, Batch: 140, Avg batch loss: 0.5541, Avg batch acc: 0.4198
Validate, Epoch: 1, Batch: 141, Avg batch loss: 0.5622, Avg batch acc: 0.4144
Validate, Epoch: 1, Batch: 142, Avg batch loss: 0.5218, Avg batch acc: 0.4270
Validate, Epoch: 1, Batch: 143, Avg batch loss: 0.4908, Avg batch acc: 0.4400
Validate, Epoch: 1, Batch: 144, Avg batch loss: 0.5142, Avg batch acc: 0.4400
Validate, Epoch: 1, Batch: 145, Avg batch loss: 0.5489, Avg batch acc: 0.4273
Validate, Epoch: 1, Batch: 146, Avg batch loss: 0.5235, Avg batch acc: 0.4417
Validate, Epoch: 1, Batch: 147, Avg batch loss: 0.6012, Avg batch acc: 0.4222
Validate, Epoch: 1, Batch: 148, Avg batch loss: 0.4749, Avg batch acc: 0.4524
Validate, Epoch: 1, Batch: 149, Avg batch loss: 0.5591, Avg batch acc: 0.4377
Validate, Epoch: 1, Batch: 150, Avg batch loss: 0.4870, Avg batch acc: 0.4477
Validate, Epoch: 1, Batch: 151, Avg batch loss: 0.5341, Avg batch acc: 0.4459
Validate, Epoch: 1, Batch: 152, Avg batch loss: 0.5474, Avg batch acc: 0.4311
Validate, Epoch: 1, Batch: 153, Avg batch loss: 0.5151, Avg batch acc: 0.4556
Validate, Epoch: 1, Batch: 154, Avg batch loss: 0.5480, Avg batch acc: 0.4570
Validate, Epoch: 1, Batch: 155, Avg batch loss: 0.5279, Avg batch acc: 0.4166
Validate, Epoch: 1, Batch: 156, Avg batch loss: 0.5009, Avg batch acc: 0.4403
Validate, Epoch: 1, Batch: 157, Avg batch loss: 0.5001, Avg batch acc: 0.4585
Validate, Epoch: 1, Batch: 158, Avg batch loss: 0.4839, Avg batch acc: 0.4357
Validate, Epoch: 1, Batch: 159, Avg batch loss: 0.4743, Avg batch acc: 0.4611
Validate, Epoch: 1, Batch: 160, Avg batch loss: 0.4792, Avg batch acc: 0.4544
Validate, Epoch: 1, Batch: 161, Avg batch loss: 0.4861, Avg batch acc: 0.4500
Validate, Epoch: 1, Batch: 162, Avg batch loss: 0.5535, Avg batch acc: 0.4313
Validate, Epoch: 1, Batch: 163, Avg batch loss: 0.4884, Avg batch acc: 0.4392
Validate, Epoch: 1, Batch: 164, Avg batch loss: 0.5090, Avg batch acc: 0.4306
Validate, Epoch: 1, Batch: 165, Avg batch loss: 0.5669, Avg batch acc: 0.4257
Validate, Epoch: 1, Batch: 166, Avg batch loss: 0.5239, Avg batch acc: 0.4413
Validate, Epoch: 1, Batch: 167, Avg batch loss: 0.4432, Avg batch acc: 0.4570
Validate, Epoch: 1, Batch: 168, Avg batch loss: 0.5489, Avg batch acc: 0.4262
Validate, Epoch: 1, Batch: 169, Avg batch loss: 0.5455, Avg batch acc: 0.4433
Validate, Epoch: 1, Avg epoch loss: 0.5164, Avg epoch acc: 0.4406, Overall time: 18.2 s, Speed: 26472.7 tokens/s on cuda:3

Train, Epoch: 2, Batch: 1, Step num: 1520, Learning rate: 0.00106213, Avg batch loss: 0.4443, Avg batch acc: 0.4523
Train, Epoch: 2, Batch: 2, Step num: 1521, Learning rate: 0.00106283, Avg batch loss: 0.4883, Avg batch acc: 0.4451
Train, Epoch: 2, Batch: 3, Step num: 1522, Learning rate: 0.00106353, Avg batch loss: 0.5314, Avg batch acc: 0.4355
Train, Epoch: 2, Batch: 4, Step num: 1523, Learning rate: 0.00106423, Avg batch loss: 0.4998, Avg batch acc: 0.4424
Train, Epoch: 2, Batch: 5, Step num: 1524, Learning rate: 0.00106493, Avg batch loss: 0.4940, Avg batch acc: 0.4473
Train, Epoch: 2, Batch: 6, Step num: 1525, Learning rate: 0.00106563, Avg batch loss: 0.5323, Avg batch acc: 0.4315
Train, Epoch: 2, Batch: 7, Step num: 1526, Learning rate: 0.00106632, Avg batch loss: 0.5015, Avg batch acc: 0.4482
Train, Epoch: 2, Batch: 8, Step num: 1527, Learning rate: 0.00106702, Avg batch loss: 0.4957, Avg batch acc: 0.4445
Train, Epoch: 2, Batch: 9, Step num: 1528, Learning rate: 0.00106772, Avg batch loss: 0.4933, Avg batch acc: 0.4579
Train, Epoch: 2, Batch: 10, Step num: 1529, Learning rate: 0.00106842, Avg batch loss: 0.4650, Avg batch acc: 0.4450
Train, Epoch: 2, Batch: 11, Step num: 1530, Learning rate: 0.00106912, Avg batch loss: 0.4554, Avg batch acc: 0.4541
Train, Epoch: 2, Batch: 12, Step num: 1531, Learning rate: 0.00106982, Avg batch loss: 0.5040, Avg batch acc: 0.4308
Train, Epoch: 2, Batch: 13, Step num: 1532, Learning rate: 0.00107052, Avg batch loss: 0.5876, Avg batch acc: 0.4207
Train, Epoch: 2, Batch: 14, Step num: 1533, Learning rate: 0.00107122, Avg batch loss: 0.5305, Avg batch acc: 0.4260
Train, Epoch: 2, Batch: 15, Step num: 1534, Learning rate: 0.00107192, Avg batch loss: 0.5357, Avg batch acc: 0.4345
Train, Epoch: 2, Batch: 16, Step num: 1535, Learning rate: 0.00107261, Avg batch loss: 0.5230, Avg batch acc: 0.4343
Train, Epoch: 2, Batch: 17, Step num: 1536, Learning rate: 0.00107331, Avg batch loss: 0.5616, Avg batch acc: 0.4382
Train, Epoch: 2, Batch: 18, Step num: 1537, Learning rate: 0.00107401, Avg batch loss: 0.5139, Avg batch acc: 0.4207
Train, Epoch: 2, Batch: 19, Step num: 1538, Learning rate: 0.00107471, Avg batch loss: 0.4794, Avg batch acc: 0.4400
Train, Epoch: 2, Batch: 20, Step num: 1539, Learning rate: 0.00107541, Avg batch loss: 0.5507, Avg batch acc: 0.4363
Train, Epoch: 2, Batch: 21, Step num: 1540, Learning rate: 0.00107611, Avg batch loss: 0.5296, Avg batch acc: 0.4487
Train, Epoch: 2, Batch: 22, Step num: 1541, Learning rate: 0.00107681, Avg batch loss: 0.5814, Avg batch acc: 0.4305
Train, Epoch: 2, Batch: 23, Step num: 1542, Learning rate: 0.00107751, Avg batch loss: 0.5139, Avg batch acc: 0.4416
Train, Epoch: 2, Batch: 24, Step num: 1543, Learning rate: 0.00107820, Avg batch loss: 0.5425, Avg batch acc: 0.4153
Train, Epoch: 2, Batch: 25, Step num: 1544, Learning rate: 0.00107890, Avg batch loss: 0.5046, Avg batch acc: 0.4445
Train, Epoch: 2, Batch: 26, Step num: 1545, Learning rate: 0.00107960, Avg batch loss: 0.5206, Avg batch acc: 0.4310
Train, Epoch: 2, Batch: 27, Step num: 1546, Learning rate: 0.00108030, Avg batch loss: 0.4715, Avg batch acc: 0.4305
Train, Epoch: 2, Batch: 28, Step num: 1547, Learning rate: 0.00108100, Avg batch loss: 0.4620, Avg batch acc: 0.4676
Train, Epoch: 2, Batch: 29, Step num: 1548, Learning rate: 0.00108170, Avg batch loss: 0.5876, Avg batch acc: 0.4127
Train, Epoch: 2, Batch: 30, Step num: 1549, Learning rate: 0.00108240, Avg batch loss: 0.4429, Avg batch acc: 0.4608
Train, Epoch: 2, Batch: 31, Step num: 1550, Learning rate: 0.00108310, Avg batch loss: 0.4815, Avg batch acc: 0.4510
Train, Epoch: 2, Batch: 32, Step num: 1551, Learning rate: 0.00108379, Avg batch loss: 0.4815, Avg batch acc: 0.4602
Train, Epoch: 2, Batch: 33, Step num: 1552, Learning rate: 0.00108449, Avg batch loss: 0.5411, Avg batch acc: 0.4365
Train, Epoch: 2, Batch: 34, Step num: 1553, Learning rate: 0.00108519, Avg batch loss: 0.5217, Avg batch acc: 0.4413
Train, Epoch: 2, Batch: 35, Step num: 1554, Learning rate: 0.00108589, Avg batch loss: 0.5236, Avg batch acc: 0.4468
Train, Epoch: 2, Batch: 36, Step num: 1555, Learning rate: 0.00108659, Avg batch loss: 0.4861, Avg batch acc: 0.4553
Train, Epoch: 2, Batch: 37, Step num: 1556, Learning rate: 0.00108729, Avg batch loss: 0.5330, Avg batch acc: 0.4338
Train, Epoch: 2, Batch: 38, Step num: 1557, Learning rate: 0.00108799, Avg batch loss: 0.4869, Avg batch acc: 0.4446
Train, Epoch: 2, Batch: 39, Step num: 1558, Learning rate: 0.00108869, Avg batch loss: 0.4902, Avg batch acc: 0.4532
Train, Epoch: 2, Batch: 40, Step num: 1559, Learning rate: 0.00108938, Avg batch loss: 0.5303, Avg batch acc: 0.4469
Train, Epoch: 2, Batch: 41, Step num: 1560, Learning rate: 0.00109008, Avg batch loss: 0.5483, Avg batch acc: 0.4243
Train, Epoch: 2, Batch: 42, Step num: 1561, Learning rate: 0.00109078, Avg batch loss: 0.4873, Avg batch acc: 0.4376
Train, Epoch: 2, Batch: 43, Step num: 1562, Learning rate: 0.00109148, Avg batch loss: 0.4725, Avg batch acc: 0.4514
Train, Epoch: 2, Batch: 44, Step num: 1563, Learning rate: 0.00109218, Avg batch loss: 0.4921, Avg batch acc: 0.4465
Train, Epoch: 2, Batch: 45, Step num: 1564, Learning rate: 0.00109288, Avg batch loss: 0.5540, Avg batch acc: 0.4400
Train, Epoch: 2, Batch: 46, Step num: 1565, Learning rate: 0.00109358, Avg batch loss: 0.5328, Avg batch acc: 0.4424
Train, Epoch: 2, Batch: 47, Step num: 1566, Learning rate: 0.00109428, Avg batch loss: 0.5117, Avg batch acc: 0.4411
Train, Epoch: 2, Batch: 48, Step num: 1567, Learning rate: 0.00109497, Avg batch loss: 0.5400, Avg batch acc: 0.4480
Train, Epoch: 2, Batch: 49, Step num: 1568, Learning rate: 0.00109567, Avg batch loss: 0.4888, Avg batch acc: 0.4447
Train, Epoch: 2, Batch: 50, Step num: 1569, Learning rate: 0.00109637, Avg batch loss: 0.4862, Avg batch acc: 0.4432
Train, Epoch: 2, Batch: 51, Step num: 1570, Learning rate: 0.00109707, Avg batch loss: 0.5444, Avg batch acc: 0.4442
Train, Epoch: 2, Batch: 52, Step num: 1571, Learning rate: 0.00109777, Avg batch loss: 0.5365, Avg batch acc: 0.4457
Train, Epoch: 2, Batch: 53, Step num: 1572, Learning rate: 0.00109847, Avg batch loss: 0.6301, Avg batch acc: 0.4016
Train, Epoch: 2, Batch: 54, Step num: 1573, Learning rate: 0.00109917, Avg batch loss: 0.5531, Avg batch acc: 0.4304
Train, Epoch: 2, Batch: 55, Step num: 1574, Learning rate: 0.00109987, Avg batch loss: 0.5427, Avg batch acc: 0.4433
Train, Epoch: 2, Batch: 56, Step num: 1575, Learning rate: 0.00110056, Avg batch loss: 0.4923, Avg batch acc: 0.4643
Train, Epoch: 2, Batch: 57, Step num: 1576, Learning rate: 0.00110126, Avg batch loss: 0.5549, Avg batch acc: 0.4234
Train, Epoch: 2, Batch: 58, Step num: 1577, Learning rate: 0.00110196, Avg batch loss: 0.5350, Avg batch acc: 0.4351
Train, Epoch: 2, Batch: 59, Step num: 1578, Learning rate: 0.00110266, Avg batch loss: 0.4760, Avg batch acc: 0.4627
Train, Epoch: 2, Batch: 60, Step num: 1579, Learning rate: 0.00110336, Avg batch loss: 0.5264, Avg batch acc: 0.4587
Train, Epoch: 2, Batch: 61, Step num: 1580, Learning rate: 0.00110406, Avg batch loss: 0.4623, Avg batch acc: 0.4587
Train, Epoch: 2, Batch: 62, Step num: 1581, Learning rate: 0.00110476, Avg batch loss: 0.5128, Avg batch acc: 0.4347
Train, Epoch: 2, Batch: 63, Step num: 1582, Learning rate: 0.00110546, Avg batch loss: 0.4357, Avg batch acc: 0.4646
Train, Epoch: 2, Batch: 64, Step num: 1583, Learning rate: 0.00110615, Avg batch loss: 0.5621, Avg batch acc: 0.4298
Train, Epoch: 2, Batch: 65, Step num: 1584, Learning rate: 0.00110685, Avg batch loss: 0.5005, Avg batch acc: 0.4428
Train, Epoch: 2, Batch: 66, Step num: 1585, Learning rate: 0.00110755, Avg batch loss: 0.5589, Avg batch acc: 0.4191
Train, Epoch: 2, Batch: 67, Step num: 1586, Learning rate: 0.00110825, Avg batch loss: 0.5302, Avg batch acc: 0.4422
Train, Epoch: 2, Batch: 68, Step num: 1587, Learning rate: 0.00110895, Avg batch loss: 0.5287, Avg batch acc: 0.4384
Train, Epoch: 2, Batch: 69, Step num: 1588, Learning rate: 0.00110965, Avg batch loss: 0.5291, Avg batch acc: 0.4358
Train, Epoch: 2, Batch: 70, Step num: 1589, Learning rate: 0.00111035, Avg batch loss: 0.4908, Avg batch acc: 0.4522
Train, Epoch: 2, Batch: 71, Step num: 1590, Learning rate: 0.00111105, Avg batch loss: 0.5148, Avg batch acc: 0.4493
Train, Epoch: 2, Batch: 72, Step num: 1591, Learning rate: 0.00111175, Avg batch loss: 0.5004, Avg batch acc: 0.4373
Train, Epoch: 2, Batch: 73, Step num: 1592, Learning rate: 0.00111244, Avg batch loss: 0.5595, Avg batch acc: 0.4351
Train, Epoch: 2, Batch: 74, Step num: 1593, Learning rate: 0.00111314, Avg batch loss: 0.5651, Avg batch acc: 0.4199
Train, Epoch: 2, Batch: 75, Step num: 1594, Learning rate: 0.00111384, Avg batch loss: 0.5263, Avg batch acc: 0.4339
Train, Epoch: 2, Batch: 76, Step num: 1595, Learning rate: 0.00111454, Avg batch loss: 0.4708, Avg batch acc: 0.4649
Train, Epoch: 2, Batch: 77, Step num: 1596, Learning rate: 0.00111524, Avg batch loss: 0.4638, Avg batch acc: 0.4652
Train, Epoch: 2, Batch: 78, Step num: 1597, Learning rate: 0.00111594, Avg batch loss: 0.4756, Avg batch acc: 0.4529
Train, Epoch: 2, Batch: 79, Step num: 1598, Learning rate: 0.00111664, Avg batch loss: 0.4973, Avg batch acc: 0.4446
Train, Epoch: 2, Batch: 80, Step num: 1599, Learning rate: 0.00111734, Avg batch loss: 0.5552, Avg batch acc: 0.4291
Train, Epoch: 2, Batch: 81, Step num: 1600, Learning rate: 0.00111803, Avg batch loss: 0.5193, Avg batch acc: 0.4367
Train, Epoch: 2, Batch: 82, Step num: 1601, Learning rate: 0.00111873, Avg batch loss: 0.5014, Avg batch acc: 0.4330
Train, Epoch: 2, Batch: 83, Step num: 1602, Learning rate: 0.00111943, Avg batch loss: 0.4728, Avg batch acc: 0.4475
Train, Epoch: 2, Batch: 84, Step num: 1603, Learning rate: 0.00112013, Avg batch loss: 0.4865, Avg batch acc: 0.4353
Train, Epoch: 2, Batch: 85, Step num: 1604, Learning rate: 0.00112083, Avg batch loss: 0.4692, Avg batch acc: 0.4607
Train, Epoch: 2, Batch: 86, Step num: 1605, Learning rate: 0.00112153, Avg batch loss: 0.5313, Avg batch acc: 0.4582
Train, Epoch: 2, Batch: 87, Step num: 1606, Learning rate: 0.00112223, Avg batch loss: 0.4982, Avg batch acc: 0.4387
Train, Epoch: 2, Batch: 88, Step num: 1607, Learning rate: 0.00112293, Avg batch loss: 0.5171, Avg batch acc: 0.4470
Train, Epoch: 2, Batch: 89, Step num: 1608, Learning rate: 0.00112362, Avg batch loss: 0.4790, Avg batch acc: 0.4585
Train, Epoch: 2, Batch: 90, Step num: 1609, Learning rate: 0.00112432, Avg batch loss: 0.5355, Avg batch acc: 0.4417
Train, Epoch: 2, Batch: 91, Step num: 1610, Learning rate: 0.00112502, Avg batch loss: 0.4992, Avg batch acc: 0.4514
Train, Epoch: 2, Batch: 92, Step num: 1611, Learning rate: 0.00112572, Avg batch loss: 0.5349, Avg batch acc: 0.4457
Train, Epoch: 2, Batch: 93, Step num: 1612, Learning rate: 0.00112642, Avg batch loss: 0.4467, Avg batch acc: 0.4590
Train, Epoch: 2, Batch: 94, Step num: 1613, Learning rate: 0.00112712, Avg batch loss: 0.5329, Avg batch acc: 0.4427
Train, Epoch: 2, Batch: 95, Step num: 1614, Learning rate: 0.00112782, Avg batch loss: 0.4806, Avg batch acc: 0.4464
Train, Epoch: 2, Batch: 96, Step num: 1615, Learning rate: 0.00112852, Avg batch loss: 0.5898, Avg batch acc: 0.4306
Train, Epoch: 2, Batch: 97, Step num: 1616, Learning rate: 0.00112921, Avg batch loss: 0.5353, Avg batch acc: 0.4457
Train, Epoch: 2, Batch: 98, Step num: 1617, Learning rate: 0.00112991, Avg batch loss: 0.5322, Avg batch acc: 0.4472
Train, Epoch: 2, Batch: 99, Step num: 1618, Learning rate: 0.00113061, Avg batch loss: 0.4930, Avg batch acc: 0.4540
Train, Epoch: 2, Batch: 100, Step num: 1619, Learning rate: 0.00113131, Avg batch loss: 0.4994, Avg batch acc: 0.4322
Train, Epoch: 2, Batch: 101, Step num: 1620, Learning rate: 0.00113201, Avg batch loss: 0.5660, Avg batch acc: 0.4100
Train, Epoch: 2, Batch: 102, Step num: 1621, Learning rate: 0.00113271, Avg batch loss: 0.4792, Avg batch acc: 0.4656
Train, Epoch: 2, Batch: 103, Step num: 1622, Learning rate: 0.00113341, Avg batch loss: 0.5070, Avg batch acc: 0.4414
Train, Epoch: 2, Batch: 104, Step num: 1623, Learning rate: 0.00113411, Avg batch loss: 0.4666, Avg batch acc: 0.4319
Train, Epoch: 2, Batch: 105, Step num: 1624, Learning rate: 0.00113480, Avg batch loss: 0.5087, Avg batch acc: 0.4353
Train, Epoch: 2, Batch: 106, Step num: 1625, Learning rate: 0.00113550, Avg batch loss: 0.5613, Avg batch acc: 0.4318
Train, Epoch: 2, Batch: 107, Step num: 1626, Learning rate: 0.00113620, Avg batch loss: 0.4977, Avg batch acc: 0.4560
Train, Epoch: 2, Batch: 108, Step num: 1627, Learning rate: 0.00113690, Avg batch loss: 0.5046, Avg batch acc: 0.4592
Train, Epoch: 2, Batch: 109, Step num: 1628, Learning rate: 0.00113760, Avg batch loss: 0.4978, Avg batch acc: 0.4630
Train, Epoch: 2, Batch: 110, Step num: 1629, Learning rate: 0.00113830, Avg batch loss: 0.4842, Avg batch acc: 0.4324
Train, Epoch: 2, Batch: 111, Step num: 1630, Learning rate: 0.00113900, Avg batch loss: 0.4868, Avg batch acc: 0.4767
Train, Epoch: 2, Batch: 112, Step num: 1631, Learning rate: 0.00113970, Avg batch loss: 0.4852, Avg batch acc: 0.4532
Train, Epoch: 2, Batch: 113, Step num: 1632, Learning rate: 0.00114039, Avg batch loss: 0.5328, Avg batch acc: 0.4462
Train, Epoch: 2, Batch: 114, Step num: 1633, Learning rate: 0.00114109, Avg batch loss: 0.5191, Avg batch acc: 0.4621
Train, Epoch: 2, Batch: 115, Step num: 1634, Learning rate: 0.00114179, Avg batch loss: 0.4936, Avg batch acc: 0.4275
Train, Epoch: 2, Batch: 116, Step num: 1635, Learning rate: 0.00114249, Avg batch loss: 0.5461, Avg batch acc: 0.4382
Train, Epoch: 2, Batch: 117, Step num: 1636, Learning rate: 0.00114319, Avg batch loss: 0.4555, Avg batch acc: 0.4690
Train, Epoch: 2, Batch: 118, Step num: 1637, Learning rate: 0.00114389, Avg batch loss: 0.5631, Avg batch acc: 0.4128
Train, Epoch: 2, Batch: 119, Step num: 1638, Learning rate: 0.00114459, Avg batch loss: 0.4855, Avg batch acc: 0.4363
Train, Epoch: 2, Batch: 120, Step num: 1639, Learning rate: 0.00114529, Avg batch loss: 0.4687, Avg batch acc: 0.4649
Train, Epoch: 2, Batch: 121, Step num: 1640, Learning rate: 0.00114598, Avg batch loss: 0.5232, Avg batch acc: 0.4370
Train, Epoch: 2, Batch: 122, Step num: 1641, Learning rate: 0.00114668, Avg batch loss: 0.4685, Avg batch acc: 0.4592
Train, Epoch: 2, Batch: 123, Step num: 1642, Learning rate: 0.00114738, Avg batch loss: 0.5138, Avg batch acc: 0.4359
Train, Epoch: 2, Batch: 124, Step num: 1643, Learning rate: 0.00114808, Avg batch loss: 0.5413, Avg batch acc: 0.4240
Train, Epoch: 2, Batch: 125, Step num: 1644, Learning rate: 0.00114878, Avg batch loss: 0.4986, Avg batch acc: 0.4400
Train, Epoch: 2, Batch: 126, Step num: 1645, Learning rate: 0.00114948, Avg batch loss: 0.4842, Avg batch acc: 0.4604
Train, Epoch: 2, Batch: 127, Step num: 1646, Learning rate: 0.00115018, Avg batch loss: 0.5110, Avg batch acc: 0.4611
Train, Epoch: 2, Batch: 128, Step num: 1647, Learning rate: 0.00115088, Avg batch loss: 0.4666, Avg batch acc: 0.4429
Train, Epoch: 2, Batch: 129, Step num: 1648, Learning rate: 0.00115158, Avg batch loss: 0.4748, Avg batch acc: 0.4432
Train, Epoch: 2, Batch: 130, Step num: 1649, Learning rate: 0.00115227, Avg batch loss: 0.5426, Avg batch acc: 0.4425
Train, Epoch: 2, Batch: 131, Step num: 1650, Learning rate: 0.00115297, Avg batch loss: 0.4931, Avg batch acc: 0.4584
Train, Epoch: 2, Batch: 132, Step num: 1651, Learning rate: 0.00115367, Avg batch loss: 0.6078, Avg batch acc: 0.4325
Train, Epoch: 2, Batch: 133, Step num: 1652, Learning rate: 0.00115437, Avg batch loss: 0.4782, Avg batch acc: 0.4586
Train, Epoch: 2, Batch: 134, Step num: 1653, Learning rate: 0.00115507, Avg batch loss: 0.5102, Avg batch acc: 0.4348
Train, Epoch: 2, Batch: 135, Step num: 1654, Learning rate: 0.00115577, Avg batch loss: 0.5688, Avg batch acc: 0.4248
Train, Epoch: 2, Batch: 136, Step num: 1655, Learning rate: 0.00115647, Avg batch loss: 0.5410, Avg batch acc: 0.4324
Train, Epoch: 2, Batch: 137, Step num: 1656, Learning rate: 0.00115717, Avg batch loss: 0.5096, Avg batch acc: 0.4356
Train, Epoch: 2, Batch: 138, Step num: 1657, Learning rate: 0.00115786, Avg batch loss: 0.5005, Avg batch acc: 0.4586
Train, Epoch: 2, Batch: 139, Step num: 1658, Learning rate: 0.00115856, Avg batch loss: 0.4775, Avg batch acc: 0.4578
Train, Epoch: 2, Batch: 140, Step num: 1659, Learning rate: 0.00115926, Avg batch loss: 0.5529, Avg batch acc: 0.4175
Train, Epoch: 2, Batch: 141, Step num: 1660, Learning rate: 0.00115996, Avg batch loss: 0.5045, Avg batch acc: 0.4463
Train, Epoch: 2, Batch: 142, Step num: 1661, Learning rate: 0.00116066, Avg batch loss: 0.5005, Avg batch acc: 0.4431
Train, Epoch: 2, Batch: 143, Step num: 1662, Learning rate: 0.00116136, Avg batch loss: 0.5135, Avg batch acc: 0.4353
Train, Epoch: 2, Batch: 144, Step num: 1663, Learning rate: 0.00116206, Avg batch loss: 0.5149, Avg batch acc: 0.4352
Train, Epoch: 2, Batch: 145, Step num: 1664, Learning rate: 0.00116276, Avg batch loss: 0.5004, Avg batch acc: 0.4527
Train, Epoch: 2, Batch: 146, Step num: 1665, Learning rate: 0.00116345, Avg batch loss: 0.6101, Avg batch acc: 0.4111
Train, Epoch: 2, Batch: 147, Step num: 1666, Learning rate: 0.00116415, Avg batch loss: 0.4844, Avg batch acc: 0.4509
Train, Epoch: 2, Batch: 148, Step num: 1667, Learning rate: 0.00116485, Avg batch loss: 0.5020, Avg batch acc: 0.4209
Train, Epoch: 2, Batch: 149, Step num: 1668, Learning rate: 0.00116555, Avg batch loss: 0.5216, Avg batch acc: 0.4195
Train, Epoch: 2, Batch: 150, Step num: 1669, Learning rate: 0.00116625, Avg batch loss: 0.4777, Avg batch acc: 0.4446
Train, Epoch: 2, Batch: 151, Step num: 1670, Learning rate: 0.00116695, Avg batch loss: 0.5399, Avg batch acc: 0.4513
Train, Epoch: 2, Batch: 152, Step num: 1671, Learning rate: 0.00116765, Avg batch loss: 0.4916, Avg batch acc: 0.4426
Train, Epoch: 2, Batch: 153, Step num: 1672, Learning rate: 0.00116835, Avg batch loss: 0.5391, Avg batch acc: 0.4674
Train, Epoch: 2, Batch: 154, Step num: 1673, Learning rate: 0.00116904, Avg batch loss: 0.4623, Avg batch acc: 0.4584
Train, Epoch: 2, Batch: 155, Step num: 1674, Learning rate: 0.00116974, Avg batch loss: 0.4435, Avg batch acc: 0.4598
Train, Epoch: 2, Batch: 156, Step num: 1675, Learning rate: 0.00117044, Avg batch loss: 0.5221, Avg batch acc: 0.4345
Train, Epoch: 2, Batch: 157, Step num: 1676, Learning rate: 0.00117114, Avg batch loss: 0.5447, Avg batch acc: 0.4243
Train, Epoch: 2, Batch: 158, Step num: 1677, Learning rate: 0.00117184, Avg batch loss: 0.4993, Avg batch acc: 0.4410
Train, Epoch: 2, Batch: 159, Step num: 1678, Learning rate: 0.00117254, Avg batch loss: 0.5236, Avg batch acc: 0.4256
Train, Epoch: 2, Batch: 160, Step num: 1679, Learning rate: 0.00117324, Avg batch loss: 0.4646, Avg batch acc: 0.4815
Train, Epoch: 2, Batch: 161, Step num: 1680, Learning rate: 0.00117394, Avg batch loss: 0.4985, Avg batch acc: 0.4456
Train, Epoch: 2, Batch: 162, Step num: 1681, Learning rate: 0.00117463, Avg batch loss: 0.5081, Avg batch acc: 0.4430
Train, Epoch: 2, Batch: 163, Step num: 1682, Learning rate: 0.00117533, Avg batch loss: 0.5014, Avg batch acc: 0.4516
Train, Epoch: 2, Batch: 164, Step num: 1683, Learning rate: 0.00117603, Avg batch loss: 0.4567, Avg batch acc: 0.4428
Train, Epoch: 2, Batch: 165, Step num: 1684, Learning rate: 0.00117673, Avg batch loss: 0.4586, Avg batch acc: 0.4649
Train, Epoch: 2, Batch: 166, Step num: 1685, Learning rate: 0.00117743, Avg batch loss: 0.5910, Avg batch acc: 0.4321
Train, Epoch: 2, Batch: 167, Step num: 1686, Learning rate: 0.00117813, Avg batch loss: 0.4649, Avg batch acc: 0.4637
Train, Epoch: 2, Batch: 168, Step num: 1687, Learning rate: 0.00117883, Avg batch loss: 0.5371, Avg batch acc: 0.4313
Train, Epoch: 2, Batch: 169, Step num: 1688, Learning rate: 0.00117953, Avg batch loss: 0.4693, Avg batch acc: 0.4302
Train, Epoch: 2, Batch: 170, Step num: 1689, Learning rate: 0.00118022, Avg batch loss: 0.4927, Avg batch acc: 0.4602
Train, Epoch: 2, Batch: 171, Step num: 1690, Learning rate: 0.00118092, Avg batch loss: 0.5089, Avg batch acc: 0.4646
Train, Epoch: 2, Batch: 172, Step num: 1691, Learning rate: 0.00118162, Avg batch loss: 0.4465, Avg batch acc: 0.4522
Train, Epoch: 2, Batch: 173, Step num: 1692, Learning rate: 0.00118232, Avg batch loss: 0.5115, Avg batch acc: 0.4332
Train, Epoch: 2, Batch: 174, Step num: 1693, Learning rate: 0.00118302, Avg batch loss: 0.4670, Avg batch acc: 0.4338
Train, Epoch: 2, Batch: 175, Step num: 1694, Learning rate: 0.00118372, Avg batch loss: 0.4971, Avg batch acc: 0.4345
Train, Epoch: 2, Batch: 176, Step num: 1695, Learning rate: 0.00118442, Avg batch loss: 0.5044, Avg batch acc: 0.4424
Train, Epoch: 2, Batch: 177, Step num: 1696, Learning rate: 0.00118512, Avg batch loss: 0.4746, Avg batch acc: 0.4320
Train, Epoch: 2, Batch: 178, Step num: 1697, Learning rate: 0.00118581, Avg batch loss: 0.4938, Avg batch acc: 0.4626
Train, Epoch: 2, Batch: 179, Step num: 1698, Learning rate: 0.00118651, Avg batch loss: 0.5026, Avg batch acc: 0.4243
Train, Epoch: 2, Batch: 180, Step num: 1699, Learning rate: 0.00118721, Avg batch loss: 0.5035, Avg batch acc: 0.4449
Train, Epoch: 2, Batch: 181, Step num: 1700, Learning rate: 0.00118791, Avg batch loss: 0.5216, Avg batch acc: 0.4477
Train, Epoch: 2, Batch: 182, Step num: 1701, Learning rate: 0.00118861, Avg batch loss: 0.5431, Avg batch acc: 0.4247
Train, Epoch: 2, Batch: 183, Step num: 1702, Learning rate: 0.00118931, Avg batch loss: 0.5225, Avg batch acc: 0.4333
Train, Epoch: 2, Batch: 184, Step num: 1703, Learning rate: 0.00119001, Avg batch loss: 0.4808, Avg batch acc: 0.4437
Train, Epoch: 2, Batch: 185, Step num: 1704, Learning rate: 0.00119071, Avg batch loss: 0.5039, Avg batch acc: 0.4467
Train, Epoch: 2, Batch: 186, Step num: 1705, Learning rate: 0.00119140, Avg batch loss: 0.4925, Avg batch acc: 0.4440
Train, Epoch: 2, Batch: 187, Step num: 1706, Learning rate: 0.00119210, Avg batch loss: 0.5567, Avg batch acc: 0.4297
Train, Epoch: 2, Batch: 188, Step num: 1707, Learning rate: 0.00119280, Avg batch loss: 0.4858, Avg batch acc: 0.4661
Train, Epoch: 2, Batch: 189, Step num: 1708, Learning rate: 0.00119350, Avg batch loss: 0.5204, Avg batch acc: 0.4626
Train, Epoch: 2, Batch: 190, Step num: 1709, Learning rate: 0.00119420, Avg batch loss: 0.4669, Avg batch acc: 0.4613
Train, Epoch: 2, Batch: 191, Step num: 1710, Learning rate: 0.00119490, Avg batch loss: 0.4968, Avg batch acc: 0.4562
Train, Epoch: 2, Batch: 192, Step num: 1711, Learning rate: 0.00119560, Avg batch loss: 0.5729, Avg batch acc: 0.4439
Train, Epoch: 2, Batch: 193, Step num: 1712, Learning rate: 0.00119630, Avg batch loss: 0.4686, Avg batch acc: 0.4696
Train, Epoch: 2, Batch: 194, Step num: 1713, Learning rate: 0.00119700, Avg batch loss: 0.4667, Avg batch acc: 0.4488
Train, Epoch: 2, Batch: 195, Step num: 1714, Learning rate: 0.00119769, Avg batch loss: 0.4953, Avg batch acc: 0.4444
Train, Epoch: 2, Batch: 196, Step num: 1715, Learning rate: 0.00119839, Avg batch loss: 0.5300, Avg batch acc: 0.4549
Train, Epoch: 2, Batch: 197, Step num: 1716, Learning rate: 0.00119909, Avg batch loss: 0.4959, Avg batch acc: 0.4428
Train, Epoch: 2, Batch: 198, Step num: 1717, Learning rate: 0.00119979, Avg batch loss: 0.5080, Avg batch acc: 0.4395
Train, Epoch: 2, Batch: 199, Step num: 1718, Learning rate: 0.00120049, Avg batch loss: 0.5225, Avg batch acc: 0.4480
Train, Epoch: 2, Batch: 200, Step num: 1719, Learning rate: 0.00120119, Avg batch loss: 0.5078, Avg batch acc: 0.4331
Train, Epoch: 2, Batch: 201, Step num: 1720, Learning rate: 0.00120189, Avg batch loss: 0.5017, Avg batch acc: 0.4436
Train, Epoch: 2, Batch: 202, Step num: 1721, Learning rate: 0.00120259, Avg batch loss: 0.5088, Avg batch acc: 0.4628
Train, Epoch: 2, Batch: 203, Step num: 1722, Learning rate: 0.00120328, Avg batch loss: 0.5061, Avg batch acc: 0.4556
Train, Epoch: 2, Batch: 204, Step num: 1723, Learning rate: 0.00120398, Avg batch loss: 0.4925, Avg batch acc: 0.4699
Train, Epoch: 2, Batch: 205, Step num: 1724, Learning rate: 0.00120468, Avg batch loss: 0.4279, Avg batch acc: 0.4695
Train, Epoch: 2, Batch: 206, Step num: 1725, Learning rate: 0.00120538, Avg batch loss: 0.5620, Avg batch acc: 0.4138
Train, Epoch: 2, Batch: 207, Step num: 1726, Learning rate: 0.00120608, Avg batch loss: 0.4924, Avg batch acc: 0.4580
Train, Epoch: 2, Batch: 208, Step num: 1727, Learning rate: 0.00120678, Avg batch loss: 0.4517, Avg batch acc: 0.4624
Train, Epoch: 2, Batch: 209, Step num: 1728, Learning rate: 0.00120748, Avg batch loss: 0.4880, Avg batch acc: 0.4432
Train, Epoch: 2, Batch: 210, Step num: 1729, Learning rate: 0.00120818, Avg batch loss: 0.5271, Avg batch acc: 0.4358
Train, Epoch: 2, Batch: 211, Step num: 1730, Learning rate: 0.00120887, Avg batch loss: 0.4988, Avg batch acc: 0.4465
Train, Epoch: 2, Batch: 212, Step num: 1731, Learning rate: 0.00120957, Avg batch loss: 0.4389, Avg batch acc: 0.4807
Train, Epoch: 2, Batch: 213, Step num: 1732, Learning rate: 0.00121027, Avg batch loss: 0.5249, Avg batch acc: 0.4593
Train, Epoch: 2, Batch: 214, Step num: 1733, Learning rate: 0.00121097, Avg batch loss: 0.5003, Avg batch acc: 0.4585
Train, Epoch: 2, Batch: 215, Step num: 1734, Learning rate: 0.00121167, Avg batch loss: 0.5164, Avg batch acc: 0.4408
Train, Epoch: 2, Batch: 216, Step num: 1735, Learning rate: 0.00121237, Avg batch loss: 0.5652, Avg batch acc: 0.4157
Train, Epoch: 2, Batch: 217, Step num: 1736, Learning rate: 0.00121307, Avg batch loss: 0.4778, Avg batch acc: 0.4478
Train, Epoch: 2, Batch: 218, Step num: 1737, Learning rate: 0.00121377, Avg batch loss: 0.4543, Avg batch acc: 0.4540
Train, Epoch: 2, Batch: 219, Step num: 1738, Learning rate: 0.00121446, Avg batch loss: 0.5208, Avg batch acc: 0.4624
Train, Epoch: 2, Batch: 220, Step num: 1739, Learning rate: 0.00121516, Avg batch loss: 0.5083, Avg batch acc: 0.4321
Train, Epoch: 2, Batch: 221, Step num: 1740, Learning rate: 0.00121586, Avg batch loss: 0.4808, Avg batch acc: 0.4613
Train, Epoch: 2, Batch: 222, Step num: 1741, Learning rate: 0.00121656, Avg batch loss: 0.5681, Avg batch acc: 0.4462
Train, Epoch: 2, Batch: 223, Step num: 1742, Learning rate: 0.00121726, Avg batch loss: 0.4729, Avg batch acc: 0.4319
Train, Epoch: 2, Batch: 224, Step num: 1743, Learning rate: 0.00121796, Avg batch loss: 0.5184, Avg batch acc: 0.4462
Train, Epoch: 2, Batch: 225, Step num: 1744, Learning rate: 0.00121866, Avg batch loss: 0.4783, Avg batch acc: 0.4408
Train, Epoch: 2, Batch: 226, Step num: 1745, Learning rate: 0.00121936, Avg batch loss: 0.5338, Avg batch acc: 0.4348
Train, Epoch: 2, Batch: 227, Step num: 1746, Learning rate: 0.00122005, Avg batch loss: 0.5233, Avg batch acc: 0.4608
Train, Epoch: 2, Batch: 228, Step num: 1747, Learning rate: 0.00122075, Avg batch loss: 0.5889, Avg batch acc: 0.4311
Train, Epoch: 2, Batch: 229, Step num: 1748, Learning rate: 0.00122145, Avg batch loss: 0.5375, Avg batch acc: 0.4426
Train, Epoch: 2, Batch: 230, Step num: 1749, Learning rate: 0.00122215, Avg batch loss: 0.5239, Avg batch acc: 0.4698
Train, Epoch: 2, Batch: 231, Step num: 1750, Learning rate: 0.00122285, Avg batch loss: 0.5575, Avg batch acc: 0.4429
Train, Epoch: 2, Batch: 232, Step num: 1751, Learning rate: 0.00122355, Avg batch loss: 0.5125, Avg batch acc: 0.4534
Train, Epoch: 2, Batch: 233, Step num: 1752, Learning rate: 0.00122425, Avg batch loss: 0.4596, Avg batch acc: 0.4756
Train, Epoch: 2, Batch: 234, Step num: 1753, Learning rate: 0.00122495, Avg batch loss: 0.4773, Avg batch acc: 0.4304
Train, Epoch: 2, Batch: 235, Step num: 1754, Learning rate: 0.00122564, Avg batch loss: 0.5217, Avg batch acc: 0.4374
Train, Epoch: 2, Batch: 236, Step num: 1755, Learning rate: 0.00122634, Avg batch loss: 0.4771, Avg batch acc: 0.4665
Train, Epoch: 2, Batch: 237, Step num: 1756, Learning rate: 0.00122704, Avg batch loss: 0.4901, Avg batch acc: 0.4616
Train, Epoch: 2, Batch: 238, Step num: 1757, Learning rate: 0.00122774, Avg batch loss: 0.5462, Avg batch acc: 0.4291
Train, Epoch: 2, Batch: 239, Step num: 1758, Learning rate: 0.00122844, Avg batch loss: 0.5700, Avg batch acc: 0.4239
Train, Epoch: 2, Batch: 240, Step num: 1759, Learning rate: 0.00122914, Avg batch loss: 0.4745, Avg batch acc: 0.4560
Train, Epoch: 2, Batch: 241, Step num: 1760, Learning rate: 0.00122984, Avg batch loss: 0.5073, Avg batch acc: 0.4434
Train, Epoch: 2, Batch: 242, Step num: 1761, Learning rate: 0.00123054, Avg batch loss: 0.4703, Avg batch acc: 0.4673
Train, Epoch: 2, Batch: 243, Step num: 1762, Learning rate: 0.00123123, Avg batch loss: 0.5386, Avg batch acc: 0.4308
Train, Epoch: 2, Batch: 244, Step num: 1763, Learning rate: 0.00123193, Avg batch loss: 0.4598, Avg batch acc: 0.4644
Train, Epoch: 2, Batch: 245, Step num: 1764, Learning rate: 0.00123263, Avg batch loss: 0.5079, Avg batch acc: 0.4421
Train, Epoch: 2, Batch: 246, Step num: 1765, Learning rate: 0.00123333, Avg batch loss: 0.4896, Avg batch acc: 0.4571
Train, Epoch: 2, Batch: 247, Step num: 1766, Learning rate: 0.00123403, Avg batch loss: 0.5277, Avg batch acc: 0.4579
Train, Epoch: 2, Batch: 248, Step num: 1767, Learning rate: 0.00123473, Avg batch loss: 0.4882, Avg batch acc: 0.4539
Train, Epoch: 2, Batch: 249, Step num: 1768, Learning rate: 0.00123543, Avg batch loss: 0.4922, Avg batch acc: 0.4530
Train, Epoch: 2, Batch: 250, Step num: 1769, Learning rate: 0.00123613, Avg batch loss: 0.4664, Avg batch acc: 0.4488
Train, Epoch: 2, Batch: 251, Step num: 1770, Learning rate: 0.00123683, Avg batch loss: 0.4974, Avg batch acc: 0.4562
Train, Epoch: 2, Batch: 252, Step num: 1771, Learning rate: 0.00123752, Avg batch loss: 0.5107, Avg batch acc: 0.4324
Train, Epoch: 2, Batch: 253, Step num: 1772, Learning rate: 0.00123822, Avg batch loss: 0.4746, Avg batch acc: 0.4540
Train, Epoch: 2, Batch: 254, Step num: 1773, Learning rate: 0.00123892, Avg batch loss: 0.4767, Avg batch acc: 0.4610
Train, Epoch: 2, Batch: 255, Step num: 1774, Learning rate: 0.00123962, Avg batch loss: 0.5047, Avg batch acc: 0.4515
Train, Epoch: 2, Batch: 256, Step num: 1775, Learning rate: 0.00124032, Avg batch loss: 0.4474, Avg batch acc: 0.4593
Train, Epoch: 2, Batch: 257, Step num: 1776, Learning rate: 0.00124102, Avg batch loss: 0.5270, Avg batch acc: 0.4475
Train, Epoch: 2, Batch: 258, Step num: 1777, Learning rate: 0.00124172, Avg batch loss: 0.5049, Avg batch acc: 0.4309
Train, Epoch: 2, Batch: 259, Step num: 1778, Learning rate: 0.00124242, Avg batch loss: 0.4733, Avg batch acc: 0.4587
Train, Epoch: 2, Batch: 260, Step num: 1779, Learning rate: 0.00124311, Avg batch loss: 0.4673, Avg batch acc: 0.4695
Train, Epoch: 2, Batch: 261, Step num: 1780, Learning rate: 0.00124381, Avg batch loss: 0.4938, Avg batch acc: 0.4380
Train, Epoch: 2, Batch: 262, Step num: 1781, Learning rate: 0.00124451, Avg batch loss: 0.5160, Avg batch acc: 0.4361
Train, Epoch: 2, Batch: 263, Step num: 1782, Learning rate: 0.00124521, Avg batch loss: 0.5117, Avg batch acc: 0.4446
Train, Epoch: 2, Batch: 264, Step num: 1783, Learning rate: 0.00124591, Avg batch loss: 0.5247, Avg batch acc: 0.4390
Train, Epoch: 2, Batch: 265, Step num: 1784, Learning rate: 0.00124661, Avg batch loss: 0.5207, Avg batch acc: 0.4301
Train, Epoch: 2, Batch: 266, Step num: 1785, Learning rate: 0.00124731, Avg batch loss: 0.5254, Avg batch acc: 0.4382
Train, Epoch: 2, Batch: 267, Step num: 1786, Learning rate: 0.00124801, Avg batch loss: 0.5219, Avg batch acc: 0.4658
Train, Epoch: 2, Batch: 268, Step num: 1787, Learning rate: 0.00124870, Avg batch loss: 0.5304, Avg batch acc: 0.4439
Train, Epoch: 2, Batch: 269, Step num: 1788, Learning rate: 0.00124940, Avg batch loss: 0.4850, Avg batch acc: 0.4589
Train, Epoch: 2, Batch: 270, Step num: 1789, Learning rate: 0.00125010, Avg batch loss: 0.4809, Avg batch acc: 0.4500
Train, Epoch: 2, Batch: 271, Step num: 1790, Learning rate: 0.00125080, Avg batch loss: 0.4679, Avg batch acc: 0.4691
Train, Epoch: 2, Batch: 272, Step num: 1791, Learning rate: 0.00125150, Avg batch loss: 0.5310, Avg batch acc: 0.4451
Train, Epoch: 2, Batch: 273, Step num: 1792, Learning rate: 0.00125220, Avg batch loss: 0.4249, Avg batch acc: 0.4942
Train, Epoch: 2, Batch: 274, Step num: 1793, Learning rate: 0.00125290, Avg batch loss: 0.4750, Avg batch acc: 0.4524
Train, Epoch: 2, Batch: 275, Step num: 1794, Learning rate: 0.00125360, Avg batch loss: 0.4818, Avg batch acc: 0.4628
Train, Epoch: 2, Batch: 276, Step num: 1795, Learning rate: 0.00125429, Avg batch loss: 0.4685, Avg batch acc: 0.4530
Train, Epoch: 2, Batch: 277, Step num: 1796, Learning rate: 0.00125499, Avg batch loss: 0.4844, Avg batch acc: 0.4619
Train, Epoch: 2, Batch: 278, Step num: 1797, Learning rate: 0.00125569, Avg batch loss: 0.5164, Avg batch acc: 0.4355
Train, Epoch: 2, Batch: 279, Step num: 1798, Learning rate: 0.00125639, Avg batch loss: 0.4867, Avg batch acc: 0.4650
Train, Epoch: 2, Batch: 280, Step num: 1799, Learning rate: 0.00125709, Avg batch loss: 0.4972, Avg batch acc: 0.4654
Train, Epoch: 2, Batch: 281, Step num: 1800, Learning rate: 0.00125779, Avg batch loss: 0.5006, Avg batch acc: 0.4525
Train, Epoch: 2, Batch: 282, Step num: 1801, Learning rate: 0.00125849, Avg batch loss: 0.5479, Avg batch acc: 0.4329
Train, Epoch: 2, Batch: 283, Step num: 1802, Learning rate: 0.00125919, Avg batch loss: 0.5052, Avg batch acc: 0.4483
Train, Epoch: 2, Batch: 284, Step num: 1803, Learning rate: 0.00125988, Avg batch loss: 0.5378, Avg batch acc: 0.4372
Train, Epoch: 2, Batch: 285, Step num: 1804, Learning rate: 0.00126058, Avg batch loss: 0.4973, Avg batch acc: 0.4483
Train, Epoch: 2, Batch: 286, Step num: 1805, Learning rate: 0.00126128, Avg batch loss: 0.4913, Avg batch acc: 0.4563
Train, Epoch: 2, Batch: 287, Step num: 1806, Learning rate: 0.00126198, Avg batch loss: 0.4720, Avg batch acc: 0.4578
Train, Epoch: 2, Batch: 288, Step num: 1807, Learning rate: 0.00126268, Avg batch loss: 0.5380, Avg batch acc: 0.4583
Train, Epoch: 2, Batch: 289, Step num: 1808, Learning rate: 0.00126338, Avg batch loss: 0.5113, Avg batch acc: 0.4498
Train, Epoch: 2, Batch: 290, Step num: 1809, Learning rate: 0.00126408, Avg batch loss: 0.5119, Avg batch acc: 0.4536
Train, Epoch: 2, Batch: 291, Step num: 1810, Learning rate: 0.00126478, Avg batch loss: 0.5105, Avg batch acc: 0.4612
Train, Epoch: 2, Batch: 292, Step num: 1811, Learning rate: 0.00126547, Avg batch loss: 0.5499, Avg batch acc: 0.4294
Train, Epoch: 2, Batch: 293, Step num: 1812, Learning rate: 0.00126617, Avg batch loss: 0.5175, Avg batch acc: 0.4395
Train, Epoch: 2, Batch: 294, Step num: 1813, Learning rate: 0.00126687, Avg batch loss: 0.4944, Avg batch acc: 0.4571
Train, Epoch: 2, Batch: 295, Step num: 1814, Learning rate: 0.00126757, Avg batch loss: 0.5123, Avg batch acc: 0.4681
Train, Epoch: 2, Batch: 296, Step num: 1815, Learning rate: 0.00126827, Avg batch loss: 0.4494, Avg batch acc: 0.4653
Train, Epoch: 2, Batch: 297, Step num: 1816, Learning rate: 0.00126897, Avg batch loss: 0.4797, Avg batch acc: 0.4572
Train, Epoch: 2, Batch: 298, Step num: 1817, Learning rate: 0.00126967, Avg batch loss: 0.4746, Avg batch acc: 0.4594
Train, Epoch: 2, Batch: 299, Step num: 1818, Learning rate: 0.00127037, Avg batch loss: 0.4549, Avg batch acc: 0.4531
Train, Epoch: 2, Batch: 300, Step num: 1819, Learning rate: 0.00127106, Avg batch loss: 0.4588, Avg batch acc: 0.4491
Train, Epoch: 2, Batch: 301, Step num: 1820, Learning rate: 0.00127176, Avg batch loss: 0.4509, Avg batch acc: 0.4582
Train, Epoch: 2, Batch: 302, Step num: 1821, Learning rate: 0.00127246, Avg batch loss: 0.5473, Avg batch acc: 0.4224
Train, Epoch: 2, Batch: 303, Step num: 1822, Learning rate: 0.00127316, Avg batch loss: 0.4907, Avg batch acc: 0.4312
Train, Epoch: 2, Batch: 304, Step num: 1823, Learning rate: 0.00127386, Avg batch loss: 0.6026, Avg batch acc: 0.4313
Train, Epoch: 2, Batch: 305, Step num: 1824, Learning rate: 0.00127456, Avg batch loss: 0.5012, Avg batch acc: 0.4576
Train, Epoch: 2, Batch: 306, Step num: 1825, Learning rate: 0.00127526, Avg batch loss: 0.5175, Avg batch acc: 0.4629
Train, Epoch: 2, Batch: 307, Step num: 1826, Learning rate: 0.00127596, Avg batch loss: 0.5113, Avg batch acc: 0.4471
Train, Epoch: 2, Batch: 308, Step num: 1827, Learning rate: 0.00127666, Avg batch loss: 0.5209, Avg batch acc: 0.4447
Train, Epoch: 2, Batch: 309, Step num: 1828, Learning rate: 0.00127735, Avg batch loss: 0.5148, Avg batch acc: 0.4334
Train, Epoch: 2, Batch: 310, Step num: 1829, Learning rate: 0.00127805, Avg batch loss: 0.5171, Avg batch acc: 0.4479
Train, Epoch: 2, Batch: 311, Step num: 1830, Learning rate: 0.00127875, Avg batch loss: 0.5349, Avg batch acc: 0.4271
Train, Epoch: 2, Batch: 312, Step num: 1831, Learning rate: 0.00127945, Avg batch loss: 0.4604, Avg batch acc: 0.4562
Train, Epoch: 2, Batch: 313, Step num: 1832, Learning rate: 0.00128015, Avg batch loss: 0.5726, Avg batch acc: 0.4609
Train, Epoch: 2, Batch: 314, Step num: 1833, Learning rate: 0.00128085, Avg batch loss: 0.5073, Avg batch acc: 0.4654
Train, Epoch: 2, Batch: 315, Step num: 1834, Learning rate: 0.00128155, Avg batch loss: 0.4967, Avg batch acc: 0.4556
Train, Epoch: 2, Batch: 316, Step num: 1835, Learning rate: 0.00128225, Avg batch loss: 0.4972, Avg batch acc: 0.4681
Train, Epoch: 2, Batch: 317, Step num: 1836, Learning rate: 0.00128294, Avg batch loss: 0.4771, Avg batch acc: 0.4698
Train, Epoch: 2, Batch: 318, Step num: 1837, Learning rate: 0.00128364, Avg batch loss: 0.5173, Avg batch acc: 0.4366
Train, Epoch: 2, Batch: 319, Step num: 1838, Learning rate: 0.00128434, Avg batch loss: 0.5307, Avg batch acc: 0.4199
Train, Epoch: 2, Batch: 320, Step num: 1839, Learning rate: 0.00128504, Avg batch loss: 0.5125, Avg batch acc: 0.4491
Train, Epoch: 2, Batch: 321, Step num: 1840, Learning rate: 0.00128574, Avg batch loss: 0.5313, Avg batch acc: 0.4543
Train, Epoch: 2, Batch: 322, Step num: 1841, Learning rate: 0.00128644, Avg batch loss: 0.5147, Avg batch acc: 0.4515
Train, Epoch: 2, Batch: 323, Step num: 1842, Learning rate: 0.00128714, Avg batch loss: 0.4935, Avg batch acc: 0.4531
Train, Epoch: 2, Batch: 324, Step num: 1843, Learning rate: 0.00128784, Avg batch loss: 0.4959, Avg batch acc: 0.4595
Train, Epoch: 2, Batch: 325, Step num: 1844, Learning rate: 0.00128853, Avg batch loss: 0.4684, Avg batch acc: 0.4365
Train, Epoch: 2, Batch: 326, Step num: 1845, Learning rate: 0.00128923, Avg batch loss: 0.4490, Avg batch acc: 0.4546
Train, Epoch: 2, Batch: 327, Step num: 1846, Learning rate: 0.00128993, Avg batch loss: 0.4973, Avg batch acc: 0.4407
Train, Epoch: 2, Batch: 328, Step num: 1847, Learning rate: 0.00129063, Avg batch loss: 0.4792, Avg batch acc: 0.4334
Train, Epoch: 2, Batch: 329, Step num: 1848, Learning rate: 0.00129133, Avg batch loss: 0.5013, Avg batch acc: 0.4357
Train, Epoch: 2, Batch: 330, Step num: 1849, Learning rate: 0.00129203, Avg batch loss: 0.4603, Avg batch acc: 0.4715
Train, Epoch: 2, Batch: 331, Step num: 1850, Learning rate: 0.00129273, Avg batch loss: 0.5899, Avg batch acc: 0.4328
Train, Epoch: 2, Batch: 332, Step num: 1851, Learning rate: 0.00129343, Avg batch loss: 0.4160, Avg batch acc: 0.4655
Train, Epoch: 2, Batch: 333, Step num: 1852, Learning rate: 0.00129412, Avg batch loss: 0.4704, Avg batch acc: 0.4590
Train, Epoch: 2, Batch: 334, Step num: 1853, Learning rate: 0.00129482, Avg batch loss: 0.4830, Avg batch acc: 0.4515
Train, Epoch: 2, Batch: 335, Step num: 1854, Learning rate: 0.00129552, Avg batch loss: 0.5260, Avg batch acc: 0.4481
Train, Epoch: 2, Batch: 336, Step num: 1855, Learning rate: 0.00129622, Avg batch loss: 0.4960, Avg batch acc: 0.4484
Train, Epoch: 2, Batch: 337, Step num: 1856, Learning rate: 0.00129692, Avg batch loss: 0.4658, Avg batch acc: 0.4420
Train, Epoch: 2, Batch: 338, Step num: 1857, Learning rate: 0.00129762, Avg batch loss: 0.4716, Avg batch acc: 0.4426
Train, Epoch: 2, Batch: 339, Step num: 1858, Learning rate: 0.00129832, Avg batch loss: 0.5120, Avg batch acc: 0.4724
Train, Epoch: 2, Batch: 340, Step num: 1859, Learning rate: 0.00129902, Avg batch loss: 0.4738, Avg batch acc: 0.4606
Train, Epoch: 2, Batch: 341, Step num: 1860, Learning rate: 0.00129971, Avg batch loss: 0.5514, Avg batch acc: 0.4493
Train, Epoch: 2, Batch: 342, Step num: 1861, Learning rate: 0.00130041, Avg batch loss: 0.4917, Avg batch acc: 0.4502
Train, Epoch: 2, Batch: 343, Step num: 1862, Learning rate: 0.00130111, Avg batch loss: 0.5236, Avg batch acc: 0.4514
Train, Epoch: 2, Batch: 344, Step num: 1863, Learning rate: 0.00130181, Avg batch loss: 0.5123, Avg batch acc: 0.4419
Train, Epoch: 2, Batch: 345, Step num: 1864, Learning rate: 0.00130251, Avg batch loss: 0.4946, Avg batch acc: 0.4276
Train, Epoch: 2, Batch: 346, Step num: 1865, Learning rate: 0.00130321, Avg batch loss: 0.4659, Avg batch acc: 0.4461
Train, Epoch: 2, Batch: 347, Step num: 1866, Learning rate: 0.00130391, Avg batch loss: 0.5529, Avg batch acc: 0.4399
Train, Epoch: 2, Batch: 348, Step num: 1867, Learning rate: 0.00130461, Avg batch loss: 0.4917, Avg batch acc: 0.4657
Train, Epoch: 2, Batch: 349, Step num: 1868, Learning rate: 0.00130530, Avg batch loss: 0.5270, Avg batch acc: 0.4378
Train, Epoch: 2, Batch: 350, Step num: 1869, Learning rate: 0.00130600, Avg batch loss: 0.4523, Avg batch acc: 0.4720
Train, Epoch: 2, Batch: 351, Step num: 1870, Learning rate: 0.00130670, Avg batch loss: 0.4998, Avg batch acc: 0.4564
Train, Epoch: 2, Batch: 352, Step num: 1871, Learning rate: 0.00130740, Avg batch loss: 0.4751, Avg batch acc: 0.4702
Train, Epoch: 2, Batch: 353, Step num: 1872, Learning rate: 0.00130810, Avg batch loss: 0.5161, Avg batch acc: 0.4416
Train, Epoch: 2, Batch: 354, Step num: 1873, Learning rate: 0.00130880, Avg batch loss: 0.4679, Avg batch acc: 0.4671
Train, Epoch: 2, Batch: 355, Step num: 1874, Learning rate: 0.00130950, Avg batch loss: 0.5144, Avg batch acc: 0.4247
Train, Epoch: 2, Batch: 356, Step num: 1875, Learning rate: 0.00131020, Avg batch loss: 0.5443, Avg batch acc: 0.4380
Train, Epoch: 2, Batch: 357, Step num: 1876, Learning rate: 0.00131089, Avg batch loss: 0.5143, Avg batch acc: 0.4624
Train, Epoch: 2, Batch: 358, Step num: 1877, Learning rate: 0.00131159, Avg batch loss: 0.4660, Avg batch acc: 0.4501
Train, Epoch: 2, Batch: 359, Step num: 1878, Learning rate: 0.00131229, Avg batch loss: 0.4839, Avg batch acc: 0.4694
Train, Epoch: 2, Batch: 360, Step num: 1879, Learning rate: 0.00131299, Avg batch loss: 0.5218, Avg batch acc: 0.4415
Train, Epoch: 2, Batch: 361, Step num: 1880, Learning rate: 0.00131369, Avg batch loss: 0.5156, Avg batch acc: 0.4619
Train, Epoch: 2, Batch: 362, Step num: 1881, Learning rate: 0.00131439, Avg batch loss: 0.4524, Avg batch acc: 0.4763
Train, Epoch: 2, Batch: 363, Step num: 1882, Learning rate: 0.00131509, Avg batch loss: 0.4964, Avg batch acc: 0.4685
Train, Epoch: 2, Batch: 364, Step num: 1883, Learning rate: 0.00131579, Avg batch loss: 0.5050, Avg batch acc: 0.4579
Train, Epoch: 2, Batch: 365, Step num: 1884, Learning rate: 0.00131649, Avg batch loss: 0.5717, Avg batch acc: 0.4344
Train, Epoch: 2, Batch: 366, Step num: 1885, Learning rate: 0.00131718, Avg batch loss: 0.4476, Avg batch acc: 0.4618
Train, Epoch: 2, Batch: 367, Step num: 1886, Learning rate: 0.00131788, Avg batch loss: 0.4976, Avg batch acc: 0.4516
Train, Epoch: 2, Batch: 368, Step num: 1887, Learning rate: 0.00131858, Avg batch loss: 0.5387, Avg batch acc: 0.4475
Train, Epoch: 2, Batch: 369, Step num: 1888, Learning rate: 0.00131928, Avg batch loss: 0.4620, Avg batch acc: 0.4463
Train, Epoch: 2, Batch: 370, Step num: 1889, Learning rate: 0.00131998, Avg batch loss: 0.5276, Avg batch acc: 0.4304
Train, Epoch: 2, Batch: 371, Step num: 1890, Learning rate: 0.00132068, Avg batch loss: 0.4711, Avg batch acc: 0.4569
Train, Epoch: 2, Batch: 372, Step num: 1891, Learning rate: 0.00132138, Avg batch loss: 0.4483, Avg batch acc: 0.4603
Train, Epoch: 2, Batch: 373, Step num: 1892, Learning rate: 0.00132208, Avg batch loss: 0.5095, Avg batch acc: 0.4476
Train, Epoch: 2, Batch: 374, Step num: 1893, Learning rate: 0.00132277, Avg batch loss: 0.5503, Avg batch acc: 0.4262
Train, Epoch: 2, Batch: 375, Step num: 1894, Learning rate: 0.00132347, Avg batch loss: 0.4878, Avg batch acc: 0.4644
Train, Epoch: 2, Batch: 376, Step num: 1895, Learning rate: 0.00132417, Avg batch loss: 0.4762, Avg batch acc: 0.4726
Train, Epoch: 2, Batch: 377, Step num: 1896, Learning rate: 0.00132487, Avg batch loss: 0.5199, Avg batch acc: 0.4437
Train, Epoch: 2, Batch: 378, Step num: 1897, Learning rate: 0.00132557, Avg batch loss: 0.5010, Avg batch acc: 0.4459
Train, Epoch: 2, Batch: 379, Step num: 1898, Learning rate: 0.00132627, Avg batch loss: 0.4802, Avg batch acc: 0.4484
Train, Epoch: 2, Batch: 380, Step num: 1899, Learning rate: 0.00132697, Avg batch loss: 0.4686, Avg batch acc: 0.4833
Train, Epoch: 2, Batch: 381, Step num: 1900, Learning rate: 0.00132767, Avg batch loss: 0.4797, Avg batch acc: 0.4725
Train, Epoch: 2, Batch: 382, Step num: 1901, Learning rate: 0.00132836, Avg batch loss: 0.5445, Avg batch acc: 0.4244
Train, Epoch: 2, Batch: 383, Step num: 1902, Learning rate: 0.00132906, Avg batch loss: 0.5038, Avg batch acc: 0.4486
Train, Epoch: 2, Batch: 384, Step num: 1903, Learning rate: 0.00132976, Avg batch loss: 0.5187, Avg batch acc: 0.4487
Train, Epoch: 2, Batch: 385, Step num: 1904, Learning rate: 0.00133046, Avg batch loss: 0.5061, Avg batch acc: 0.4260
Train, Epoch: 2, Batch: 386, Step num: 1905, Learning rate: 0.00133116, Avg batch loss: 0.5146, Avg batch acc: 0.4712
Train, Epoch: 2, Batch: 387, Step num: 1906, Learning rate: 0.00133186, Avg batch loss: 0.5547, Avg batch acc: 0.4472
Train, Epoch: 2, Batch: 388, Step num: 1907, Learning rate: 0.00133256, Avg batch loss: 0.4758, Avg batch acc: 0.4596
Train, Epoch: 2, Batch: 389, Step num: 1908, Learning rate: 0.00133326, Avg batch loss: 0.4411, Avg batch acc: 0.4639
Train, Epoch: 2, Batch: 390, Step num: 1909, Learning rate: 0.00133395, Avg batch loss: 0.5417, Avg batch acc: 0.4581
Train, Epoch: 2, Batch: 391, Step num: 1910, Learning rate: 0.00133465, Avg batch loss: 0.5139, Avg batch acc: 0.4530
Train, Epoch: 2, Batch: 392, Step num: 1911, Learning rate: 0.00133535, Avg batch loss: 0.4326, Avg batch acc: 0.4742
Train, Epoch: 2, Batch: 393, Step num: 1912, Learning rate: 0.00133605, Avg batch loss: 0.5505, Avg batch acc: 0.4461
Train, Epoch: 2, Batch: 394, Step num: 1913, Learning rate: 0.00133675, Avg batch loss: 0.5416, Avg batch acc: 0.4532
Train, Epoch: 2, Batch: 395, Step num: 1914, Learning rate: 0.00133745, Avg batch loss: 0.4745, Avg batch acc: 0.4489
Train, Epoch: 2, Batch: 396, Step num: 1915, Learning rate: 0.00133815, Avg batch loss: 0.5376, Avg batch acc: 0.4507
Train, Epoch: 2, Batch: 397, Step num: 1916, Learning rate: 0.00133885, Avg batch loss: 0.5239, Avg batch acc: 0.4547
Train, Epoch: 2, Batch: 398, Step num: 1917, Learning rate: 0.00133954, Avg batch loss: 0.4403, Avg batch acc: 0.4532
Train, Epoch: 2, Batch: 399, Step num: 1918, Learning rate: 0.00134024, Avg batch loss: 0.4774, Avg batch acc: 0.4783
Train, Epoch: 2, Batch: 400, Step num: 1919, Learning rate: 0.00134094, Avg batch loss: 0.5721, Avg batch acc: 0.4361
Train, Epoch: 2, Batch: 401, Step num: 1920, Learning rate: 0.00134164, Avg batch loss: 0.4887, Avg batch acc: 0.4800
Train, Epoch: 2, Batch: 402, Step num: 1921, Learning rate: 0.00134234, Avg batch loss: 0.4887, Avg batch acc: 0.4599
Train, Epoch: 2, Batch: 403, Step num: 1922, Learning rate: 0.00134304, Avg batch loss: 0.4961, Avg batch acc: 0.4439
Train, Epoch: 2, Batch: 404, Step num: 1923, Learning rate: 0.00134374, Avg batch loss: 0.5030, Avg batch acc: 0.4515
Train, Epoch: 2, Batch: 405, Step num: 1924, Learning rate: 0.00134444, Avg batch loss: 0.4851, Avg batch acc: 0.4492
Train, Epoch: 2, Batch: 406, Step num: 1925, Learning rate: 0.00134513, Avg batch loss: 0.5098, Avg batch acc: 0.4690
Train, Epoch: 2, Batch: 407, Step num: 1926, Learning rate: 0.00134583, Avg batch loss: 0.4723, Avg batch acc: 0.4646
Train, Epoch: 2, Batch: 408, Step num: 1927, Learning rate: 0.00134653, Avg batch loss: 0.5000, Avg batch acc: 0.4544
Train, Epoch: 2, Batch: 409, Step num: 1928, Learning rate: 0.00134723, Avg batch loss: 0.4711, Avg batch acc: 0.4581
Train, Epoch: 2, Batch: 410, Step num: 1929, Learning rate: 0.00134793, Avg batch loss: 0.5244, Avg batch acc: 0.4518
Train, Epoch: 2, Batch: 411, Step num: 1930, Learning rate: 0.00134863, Avg batch loss: 0.5046, Avg batch acc: 0.4479
Train, Epoch: 2, Batch: 412, Step num: 1931, Learning rate: 0.00134933, Avg batch loss: 0.4523, Avg batch acc: 0.4742
Train, Epoch: 2, Batch: 413, Step num: 1932, Learning rate: 0.00135003, Avg batch loss: 0.5209, Avg batch acc: 0.4528
Train, Epoch: 2, Batch: 414, Step num: 1933, Learning rate: 0.00135072, Avg batch loss: 0.5209, Avg batch acc: 0.4326
Train, Epoch: 2, Batch: 415, Step num: 1934, Learning rate: 0.00135142, Avg batch loss: 0.5181, Avg batch acc: 0.4396
Train, Epoch: 2, Batch: 416, Step num: 1935, Learning rate: 0.00135212, Avg batch loss: 0.5073, Avg batch acc: 0.4646
Train, Epoch: 2, Batch: 417, Step num: 1936, Learning rate: 0.00135282, Avg batch loss: 0.5054, Avg batch acc: 0.4760
Train, Epoch: 2, Batch: 418, Step num: 1937, Learning rate: 0.00135352, Avg batch loss: 0.4512, Avg batch acc: 0.4810
Train, Epoch: 2, Batch: 419, Step num: 1938, Learning rate: 0.00135422, Avg batch loss: 0.5015, Avg batch acc: 0.4655
Train, Epoch: 2, Batch: 420, Step num: 1939, Learning rate: 0.00135492, Avg batch loss: 0.4933, Avg batch acc: 0.4492
Train, Epoch: 2, Batch: 421, Step num: 1940, Learning rate: 0.00135562, Avg batch loss: 0.4798, Avg batch acc: 0.4595
Train, Epoch: 2, Batch: 422, Step num: 1941, Learning rate: 0.00135631, Avg batch loss: 0.4875, Avg batch acc: 0.4701
Train, Epoch: 2, Batch: 423, Step num: 1942, Learning rate: 0.00135701, Avg batch loss: 0.4342, Avg batch acc: 0.4727
Train, Epoch: 2, Batch: 424, Step num: 1943, Learning rate: 0.00135771, Avg batch loss: 0.5415, Avg batch acc: 0.4428
Train, Epoch: 2, Batch: 425, Step num: 1944, Learning rate: 0.00135841, Avg batch loss: 0.5236, Avg batch acc: 0.4557
Train, Epoch: 2, Batch: 426, Step num: 1945, Learning rate: 0.00135911, Avg batch loss: 0.4445, Avg batch acc: 0.4711
Train, Epoch: 2, Batch: 427, Step num: 1946, Learning rate: 0.00135981, Avg batch loss: 0.5014, Avg batch acc: 0.4793
Train, Epoch: 2, Batch: 428, Step num: 1947, Learning rate: 0.00136051, Avg batch loss: 0.5018, Avg batch acc: 0.4621
Train, Epoch: 2, Batch: 429, Step num: 1948, Learning rate: 0.00136121, Avg batch loss: 0.4664, Avg batch acc: 0.4545
Train, Epoch: 2, Batch: 430, Step num: 1949, Learning rate: 0.00136191, Avg batch loss: 0.4809, Avg batch acc: 0.4598
Train, Epoch: 2, Batch: 431, Step num: 1950, Learning rate: 0.00136260, Avg batch loss: 0.4538, Avg batch acc: 0.4881
Train, Epoch: 2, Batch: 432, Step num: 1951, Learning rate: 0.00136330, Avg batch loss: 0.4871, Avg batch acc: 0.4790
Train, Epoch: 2, Batch: 433, Step num: 1952, Learning rate: 0.00136400, Avg batch loss: 0.4986, Avg batch acc: 0.4487
Train, Epoch: 2, Batch: 434, Step num: 1953, Learning rate: 0.00136470, Avg batch loss: 0.4704, Avg batch acc: 0.4532
Train, Epoch: 2, Batch: 435, Step num: 1954, Learning rate: 0.00136540, Avg batch loss: 0.5129, Avg batch acc: 0.4577
Train, Epoch: 2, Batch: 436, Step num: 1955, Learning rate: 0.00136610, Avg batch loss: 0.4943, Avg batch acc: 0.4249
Train, Epoch: 2, Batch: 437, Step num: 1956, Learning rate: 0.00136680, Avg batch loss: 0.4824, Avg batch acc: 0.4592
Train, Epoch: 2, Batch: 438, Step num: 1957, Learning rate: 0.00136750, Avg batch loss: 0.4631, Avg batch acc: 0.4535
Train, Epoch: 2, Batch: 439, Step num: 1958, Learning rate: 0.00136819, Avg batch loss: 0.4674, Avg batch acc: 0.4651
Train, Epoch: 2, Batch: 440, Step num: 1959, Learning rate: 0.00136889, Avg batch loss: 0.5055, Avg batch acc: 0.4625
Train, Epoch: 2, Batch: 441, Step num: 1960, Learning rate: 0.00136959, Avg batch loss: 0.4951, Avg batch acc: 0.4664
Train, Epoch: 2, Batch: 442, Step num: 1961, Learning rate: 0.00137029, Avg batch loss: 0.5301, Avg batch acc: 0.4633
Train, Epoch: 2, Batch: 443, Step num: 1962, Learning rate: 0.00137099, Avg batch loss: 0.4449, Avg batch acc: 0.4664
Train, Epoch: 2, Batch: 444, Step num: 1963, Learning rate: 0.00137169, Avg batch loss: 0.4630, Avg batch acc: 0.4847
Train, Epoch: 2, Batch: 445, Step num: 1964, Learning rate: 0.00137239, Avg batch loss: 0.5170, Avg batch acc: 0.4427
Train, Epoch: 2, Batch: 446, Step num: 1965, Learning rate: 0.00137309, Avg batch loss: 0.4961, Avg batch acc: 0.4462
Train, Epoch: 2, Batch: 447, Step num: 1966, Learning rate: 0.00137378, Avg batch loss: 0.4773, Avg batch acc: 0.4584
Train, Epoch: 2, Batch: 448, Step num: 1967, Learning rate: 0.00137448, Avg batch loss: 0.5015, Avg batch acc: 0.4610
Train, Epoch: 2, Batch: 449, Step num: 1968, Learning rate: 0.00137518, Avg batch loss: 0.4822, Avg batch acc: 0.4546
Train, Epoch: 2, Batch: 450, Step num: 1969, Learning rate: 0.00137588, Avg batch loss: 0.5097, Avg batch acc: 0.4542
Train, Epoch: 2, Batch: 451, Step num: 1970, Learning rate: 0.00137658, Avg batch loss: 0.5288, Avg batch acc: 0.4385
Train, Epoch: 2, Batch: 452, Step num: 1971, Learning rate: 0.00137728, Avg batch loss: 0.4492, Avg batch acc: 0.4832
Train, Epoch: 2, Batch: 453, Step num: 1972, Learning rate: 0.00137798, Avg batch loss: 0.4560, Avg batch acc: 0.4773
Train, Epoch: 2, Batch: 454, Step num: 1973, Learning rate: 0.00137868, Avg batch loss: 0.4579, Avg batch acc: 0.4816
Train, Epoch: 2, Batch: 455, Step num: 1974, Learning rate: 0.00137937, Avg batch loss: 0.4646, Avg batch acc: 0.4664
Train, Epoch: 2, Batch: 456, Step num: 1975, Learning rate: 0.00138007, Avg batch loss: 0.4177, Avg batch acc: 0.4765
Train, Epoch: 2, Batch: 457, Step num: 1976, Learning rate: 0.00138077, Avg batch loss: 0.4839, Avg batch acc: 0.4654
Train, Epoch: 2, Batch: 458, Step num: 1977, Learning rate: 0.00138147, Avg batch loss: 0.4566, Avg batch acc: 0.4785
Train, Epoch: 2, Batch: 459, Step num: 1978, Learning rate: 0.00138217, Avg batch loss: 0.4936, Avg batch acc: 0.4535
Train, Epoch: 2, Batch: 460, Step num: 1979, Learning rate: 0.00138287, Avg batch loss: 0.4698, Avg batch acc: 0.4446
Train, Epoch: 2, Batch: 461, Step num: 1980, Learning rate: 0.00138357, Avg batch loss: 0.4374, Avg batch acc: 0.4881
Train, Epoch: 2, Batch: 462, Step num: 1981, Learning rate: 0.00138427, Avg batch loss: 0.4502, Avg batch acc: 0.4672
Train, Epoch: 2, Batch: 463, Step num: 1982, Learning rate: 0.00138496, Avg batch loss: 0.4214, Avg batch acc: 0.4612
Train, Epoch: 2, Batch: 464, Step num: 1983, Learning rate: 0.00138566, Avg batch loss: 0.5538, Avg batch acc: 0.4249
Train, Epoch: 2, Batch: 465, Step num: 1984, Learning rate: 0.00138636, Avg batch loss: 0.4768, Avg batch acc: 0.4764
Train, Epoch: 2, Batch: 466, Step num: 1985, Learning rate: 0.00138706, Avg batch loss: 0.4586, Avg batch acc: 0.4700
Train, Epoch: 2, Batch: 467, Step num: 1986, Learning rate: 0.00138776, Avg batch loss: 0.4863, Avg batch acc: 0.4660
Train, Epoch: 2, Batch: 468, Step num: 1987, Learning rate: 0.00138846, Avg batch loss: 0.5127, Avg batch acc: 0.4790
Train, Epoch: 2, Batch: 469, Step num: 1988, Learning rate: 0.00138916, Avg batch loss: 0.5096, Avg batch acc: 0.4672
Train, Epoch: 2, Batch: 470, Step num: 1989, Learning rate: 0.00138986, Avg batch loss: 0.4987, Avg batch acc: 0.4703
Train, Epoch: 2, Batch: 471, Step num: 1990, Learning rate: 0.00139055, Avg batch loss: 0.4825, Avg batch acc: 0.4782
Train, Epoch: 2, Batch: 472, Step num: 1991, Learning rate: 0.00139125, Avg batch loss: 0.4380, Avg batch acc: 0.4679
Train, Epoch: 2, Batch: 473, Step num: 1992, Learning rate: 0.00139195, Avg batch loss: 0.5349, Avg batch acc: 0.4423
Train, Epoch: 2, Batch: 474, Step num: 1993, Learning rate: 0.00139265, Avg batch loss: 0.4943, Avg batch acc: 0.4482
Train, Epoch: 2, Batch: 475, Step num: 1994, Learning rate: 0.00139335, Avg batch loss: 0.4993, Avg batch acc: 0.4615
Train, Epoch: 2, Batch: 476, Step num: 1995, Learning rate: 0.00139405, Avg batch loss: 0.4926, Avg batch acc: 0.4548
Train, Epoch: 2, Batch: 477, Step num: 1996, Learning rate: 0.00139475, Avg batch loss: 0.4253, Avg batch acc: 0.4818
Train, Epoch: 2, Batch: 478, Step num: 1997, Learning rate: 0.00139545, Avg batch loss: 0.4982, Avg batch acc: 0.4750
Train, Epoch: 2, Batch: 479, Step num: 1998, Learning rate: 0.00139614, Avg batch loss: 0.4623, Avg batch acc: 0.4587
Train, Epoch: 2, Batch: 480, Step num: 1999, Learning rate: 0.00139684, Avg batch loss: 0.4735, Avg batch acc: 0.4533
Train, Epoch: 2, Batch: 481, Step num: 2000, Learning rate: 0.00139754, Avg batch loss: 0.4747, Avg batch acc: 0.4578
Train, Epoch: 2, Batch: 482, Step num: 2001, Learning rate: 0.00139824, Avg batch loss: 0.4603, Avg batch acc: 0.4751
Train, Epoch: 2, Batch: 483, Step num: 2002, Learning rate: 0.00139894, Avg batch loss: 0.5244, Avg batch acc: 0.4302
Train, Epoch: 2, Batch: 484, Step num: 2003, Learning rate: 0.00139964, Avg batch loss: 0.4349, Avg batch acc: 0.4672
Train, Epoch: 2, Batch: 485, Step num: 2004, Learning rate: 0.00140034, Avg batch loss: 0.4596, Avg batch acc: 0.4777
Train, Epoch: 2, Batch: 486, Step num: 2005, Learning rate: 0.00140104, Avg batch loss: 0.5379, Avg batch acc: 0.4459
Train, Epoch: 2, Batch: 487, Step num: 2006, Learning rate: 0.00140174, Avg batch loss: 0.4642, Avg batch acc: 0.4465
Train, Epoch: 2, Batch: 488, Step num: 2007, Learning rate: 0.00140243, Avg batch loss: 0.5362, Avg batch acc: 0.4346
Train, Epoch: 2, Batch: 489, Step num: 2008, Learning rate: 0.00140313, Avg batch loss: 0.4915, Avg batch acc: 0.4680
Train, Epoch: 2, Batch: 490, Step num: 2009, Learning rate: 0.00140383, Avg batch loss: 0.4250, Avg batch acc: 0.4629
Train, Epoch: 2, Batch: 491, Step num: 2010, Learning rate: 0.00140453, Avg batch loss: 0.4822, Avg batch acc: 0.4349
Train, Epoch: 2, Batch: 492, Step num: 2011, Learning rate: 0.00140523, Avg batch loss: 0.5119, Avg batch acc: 0.4434
Train, Epoch: 2, Batch: 493, Step num: 2012, Learning rate: 0.00140593, Avg batch loss: 0.5219, Avg batch acc: 0.4518
Train, Epoch: 2, Batch: 494, Step num: 2013, Learning rate: 0.00140663, Avg batch loss: 0.4708, Avg batch acc: 0.4433
Train, Epoch: 2, Batch: 495, Step num: 2014, Learning rate: 0.00140733, Avg batch loss: 0.5023, Avg batch acc: 0.4362
Train, Epoch: 2, Batch: 496, Step num: 2015, Learning rate: 0.00140802, Avg batch loss: 0.4591, Avg batch acc: 0.4502
Train, Epoch: 2, Batch: 497, Step num: 2016, Learning rate: 0.00140872, Avg batch loss: 0.4803, Avg batch acc: 0.4298
Train, Epoch: 2, Batch: 498, Step num: 2017, Learning rate: 0.00140942, Avg batch loss: 0.4962, Avg batch acc: 0.4514
Train, Epoch: 2, Batch: 499, Step num: 2018, Learning rate: 0.00141012, Avg batch loss: 0.5013, Avg batch acc: 0.4540
Train, Epoch: 2, Batch: 500, Step num: 2019, Learning rate: 0.00141082, Avg batch loss: 0.4868, Avg batch acc: 0.4635
Train, Epoch: 2, Batch: 501, Step num: 2020, Learning rate: 0.00141152, Avg batch loss: 0.4450, Avg batch acc: 0.4594
Train, Epoch: 2, Batch: 502, Step num: 2021, Learning rate: 0.00141222, Avg batch loss: 0.4295, Avg batch acc: 0.4569
Train, Epoch: 2, Batch: 503, Step num: 2022, Learning rate: 0.00141292, Avg batch loss: 0.4945, Avg batch acc: 0.4467
Train, Epoch: 2, Batch: 504, Step num: 2023, Learning rate: 0.00141361, Avg batch loss: 0.4446, Avg batch acc: 0.4480
Train, Epoch: 2, Batch: 505, Step num: 2024, Learning rate: 0.00141431, Avg batch loss: 0.4417, Avg batch acc: 0.4570
Train, Epoch: 2, Batch: 506, Step num: 2025, Learning rate: 0.00141501, Avg batch loss: 0.4870, Avg batch acc: 0.4451
Train, Epoch: 2, Batch: 507, Step num: 2026, Learning rate: 0.00141571, Avg batch loss: 0.4396, Avg batch acc: 0.4859
Train, Epoch: 2, Batch: 508, Step num: 2027, Learning rate: 0.00141641, Avg batch loss: 0.4983, Avg batch acc: 0.4534
Train, Epoch: 2, Batch: 509, Step num: 2028, Learning rate: 0.00141711, Avg batch loss: 0.4345, Avg batch acc: 0.4850
Train, Epoch: 2, Batch: 510, Step num: 2029, Learning rate: 0.00141781, Avg batch loss: 0.4699, Avg batch acc: 0.4368
Train, Epoch: 2, Batch: 511, Step num: 2030, Learning rate: 0.00141851, Avg batch loss: 0.4830, Avg batch acc: 0.4633
Train, Epoch: 2, Batch: 512, Step num: 2031, Learning rate: 0.00141920, Avg batch loss: 0.5339, Avg batch acc: 0.4576
Train, Epoch: 2, Batch: 513, Step num: 2032, Learning rate: 0.00141990, Avg batch loss: 0.4411, Avg batch acc: 0.4611
Train, Epoch: 2, Batch: 514, Step num: 2033, Learning rate: 0.00142060, Avg batch loss: 0.5308, Avg batch acc: 0.4486
Train, Epoch: 2, Batch: 515, Step num: 2034, Learning rate: 0.00142130, Avg batch loss: 0.4656, Avg batch acc: 0.4505
Train, Epoch: 2, Batch: 516, Step num: 2035, Learning rate: 0.00142200, Avg batch loss: 0.4599, Avg batch acc: 0.4540
Train, Epoch: 2, Batch: 517, Step num: 2036, Learning rate: 0.00142270, Avg batch loss: 0.5270, Avg batch acc: 0.4496
Train, Epoch: 2, Batch: 518, Step num: 2037, Learning rate: 0.00142340, Avg batch loss: 0.5668, Avg batch acc: 0.4283
Train, Epoch: 2, Batch: 519, Step num: 2038, Learning rate: 0.00142410, Avg batch loss: 0.5001, Avg batch acc: 0.4687
Train, Epoch: 2, Batch: 520, Step num: 2039, Learning rate: 0.00142479, Avg batch loss: 0.4543, Avg batch acc: 0.4773
Train, Epoch: 2, Batch: 521, Step num: 2040, Learning rate: 0.00142549, Avg batch loss: 0.5019, Avg batch acc: 0.4541
Train, Epoch: 2, Batch: 522, Step num: 2041, Learning rate: 0.00142619, Avg batch loss: 0.5173, Avg batch acc: 0.4237
Train, Epoch: 2, Batch: 523, Step num: 2042, Learning rate: 0.00142689, Avg batch loss: 0.5340, Avg batch acc: 0.4314
Train, Epoch: 2, Batch: 524, Step num: 2043, Learning rate: 0.00142759, Avg batch loss: 0.5022, Avg batch acc: 0.4528
Train, Epoch: 2, Batch: 525, Step num: 2044, Learning rate: 0.00142829, Avg batch loss: 0.4974, Avg batch acc: 0.4572
Train, Epoch: 2, Batch: 526, Step num: 2045, Learning rate: 0.00142899, Avg batch loss: 0.5103, Avg batch acc: 0.4468
Train, Epoch: 2, Batch: 527, Step num: 2046, Learning rate: 0.00142969, Avg batch loss: 0.5255, Avg batch acc: 0.4660
Train, Epoch: 2, Batch: 528, Step num: 2047, Learning rate: 0.00143038, Avg batch loss: 0.5113, Avg batch acc: 0.4513
Train, Epoch: 2, Batch: 529, Step num: 2048, Learning rate: 0.00143108, Avg batch loss: 0.4968, Avg batch acc: 0.4565
Train, Epoch: 2, Batch: 530, Step num: 2049, Learning rate: 0.00143178, Avg batch loss: 0.4519, Avg batch acc: 0.4653
Train, Epoch: 2, Batch: 531, Step num: 2050, Learning rate: 0.00143248, Avg batch loss: 0.4919, Avg batch acc: 0.4640
Train, Epoch: 2, Batch: 532, Step num: 2051, Learning rate: 0.00143318, Avg batch loss: 0.4830, Avg batch acc: 0.4506
Train, Epoch: 2, Batch: 533, Step num: 2052, Learning rate: 0.00143388, Avg batch loss: 0.4763, Avg batch acc: 0.4449
Train, Epoch: 2, Batch: 534, Step num: 2053, Learning rate: 0.00143458, Avg batch loss: 0.4843, Avg batch acc: 0.4733
Train, Epoch: 2, Batch: 535, Step num: 2054, Learning rate: 0.00143528, Avg batch loss: 0.5256, Avg batch acc: 0.4360
Train, Epoch: 2, Batch: 536, Step num: 2055, Learning rate: 0.00143597, Avg batch loss: 0.5588, Avg batch acc: 0.4500
Train, Epoch: 2, Batch: 537, Step num: 2056, Learning rate: 0.00143667, Avg batch loss: 0.4884, Avg batch acc: 0.4440
Train, Epoch: 2, Batch: 538, Step num: 2057, Learning rate: 0.00143737, Avg batch loss: 0.5019, Avg batch acc: 0.4451
Train, Epoch: 2, Batch: 539, Step num: 2058, Learning rate: 0.00143807, Avg batch loss: 0.5683, Avg batch acc: 0.4468
Train, Epoch: 2, Batch: 540, Step num: 2059, Learning rate: 0.00143877, Avg batch loss: 0.4614, Avg batch acc: 0.4624
Train, Epoch: 2, Batch: 541, Step num: 2060, Learning rate: 0.00143947, Avg batch loss: 0.4916, Avg batch acc: 0.4813
Train, Epoch: 2, Batch: 542, Step num: 2061, Learning rate: 0.00144017, Avg batch loss: 0.5142, Avg batch acc: 0.4567
Train, Epoch: 2, Batch: 543, Step num: 2062, Learning rate: 0.00144087, Avg batch loss: 0.4774, Avg batch acc: 0.4553
Train, Epoch: 2, Batch: 544, Step num: 2063, Learning rate: 0.00144157, Avg batch loss: 0.5196, Avg batch acc: 0.4335
Train, Epoch: 2, Batch: 545, Step num: 2064, Learning rate: 0.00144226, Avg batch loss: 0.5242, Avg batch acc: 0.4570
Train, Epoch: 2, Batch: 546, Step num: 2065, Learning rate: 0.00144296, Avg batch loss: 0.5004, Avg batch acc: 0.4398
Train, Epoch: 2, Batch: 547, Step num: 2066, Learning rate: 0.00144366, Avg batch loss: 0.4308, Avg batch acc: 0.4608
Train, Epoch: 2, Batch: 548, Step num: 2067, Learning rate: 0.00144436, Avg batch loss: 0.4398, Avg batch acc: 0.4745
Train, Epoch: 2, Batch: 549, Step num: 2068, Learning rate: 0.00144506, Avg batch loss: 0.4974, Avg batch acc: 0.4545
Train, Epoch: 2, Batch: 550, Step num: 2069, Learning rate: 0.00144576, Avg batch loss: 0.4420, Avg batch acc: 0.4673
Train, Epoch: 2, Batch: 551, Step num: 2070, Learning rate: 0.00144646, Avg batch loss: 0.4831, Avg batch acc: 0.4708
Train, Epoch: 2, Batch: 552, Step num: 2071, Learning rate: 0.00144716, Avg batch loss: 0.4915, Avg batch acc: 0.4673
Train, Epoch: 2, Batch: 553, Step num: 2072, Learning rate: 0.00144785, Avg batch loss: 0.4826, Avg batch acc: 0.4685
Train, Epoch: 2, Batch: 554, Step num: 2073, Learning rate: 0.00144855, Avg batch loss: 0.4861, Avg batch acc: 0.4592
Train, Epoch: 2, Batch: 555, Step num: 2074, Learning rate: 0.00144925, Avg batch loss: 0.4153, Avg batch acc: 0.4831
Train, Epoch: 2, Batch: 556, Step num: 2075, Learning rate: 0.00144995, Avg batch loss: 0.5092, Avg batch acc: 0.4425
Train, Epoch: 2, Batch: 557, Step num: 2076, Learning rate: 0.00145065, Avg batch loss: 0.4738, Avg batch acc: 0.4656
Train, Epoch: 2, Batch: 558, Step num: 2077, Learning rate: 0.00145135, Avg batch loss: 0.5087, Avg batch acc: 0.4658
Train, Epoch: 2, Batch: 559, Step num: 2078, Learning rate: 0.00145205, Avg batch loss: 0.4806, Avg batch acc: 0.4434
Train, Epoch: 2, Batch: 560, Step num: 2079, Learning rate: 0.00145275, Avg batch loss: 0.5241, Avg batch acc: 0.4517
Train, Epoch: 2, Batch: 561, Step num: 2080, Learning rate: 0.00145344, Avg batch loss: 0.4905, Avg batch acc: 0.4595
Train, Epoch: 2, Batch: 562, Step num: 2081, Learning rate: 0.00145414, Avg batch loss: 0.4912, Avg batch acc: 0.4510
Train, Epoch: 2, Batch: 563, Step num: 2082, Learning rate: 0.00145484, Avg batch loss: 0.4711, Avg batch acc: 0.4715
Train, Epoch: 2, Batch: 564, Step num: 2083, Learning rate: 0.00145554, Avg batch loss: 0.4895, Avg batch acc: 0.4488
Train, Epoch: 2, Batch: 565, Step num: 2084, Learning rate: 0.00145624, Avg batch loss: 0.4463, Avg batch acc: 0.4675
Train, Epoch: 2, Batch: 566, Step num: 2085, Learning rate: 0.00145694, Avg batch loss: 0.4814, Avg batch acc: 0.4741
Train, Epoch: 2, Batch: 567, Step num: 2086, Learning rate: 0.00145764, Avg batch loss: 0.4844, Avg batch acc: 0.4722
Train, Epoch: 2, Batch: 568, Step num: 2087, Learning rate: 0.00145834, Avg batch loss: 0.5261, Avg batch acc: 0.4573
Train, Epoch: 2, Batch: 569, Step num: 2088, Learning rate: 0.00145903, Avg batch loss: 0.5099, Avg batch acc: 0.4537
Train, Epoch: 2, Batch: 570, Step num: 2089, Learning rate: 0.00145973, Avg batch loss: 0.4673, Avg batch acc: 0.4783
Train, Epoch: 2, Batch: 571, Step num: 2090, Learning rate: 0.00146043, Avg batch loss: 0.5002, Avg batch acc: 0.4532
Train, Epoch: 2, Batch: 572, Step num: 2091, Learning rate: 0.00146113, Avg batch loss: 0.4327, Avg batch acc: 0.4933
Train, Epoch: 2, Batch: 573, Step num: 2092, Learning rate: 0.00146183, Avg batch loss: 0.4905, Avg batch acc: 0.4622
Train, Epoch: 2, Batch: 574, Step num: 2093, Learning rate: 0.00146253, Avg batch loss: 0.4368, Avg batch acc: 0.4715
Train, Epoch: 2, Batch: 575, Step num: 2094, Learning rate: 0.00146323, Avg batch loss: 0.4621, Avg batch acc: 0.4755
Train, Epoch: 2, Batch: 576, Step num: 2095, Learning rate: 0.00146393, Avg batch loss: 0.4450, Avg batch acc: 0.4737
Train, Epoch: 2, Batch: 577, Step num: 2096, Learning rate: 0.00146462, Avg batch loss: 0.4358, Avg batch acc: 0.4764
Train, Epoch: 2, Batch: 578, Step num: 2097, Learning rate: 0.00146532, Avg batch loss: 0.4699, Avg batch acc: 0.4818
Train, Epoch: 2, Batch: 579, Step num: 2098, Learning rate: 0.00146602, Avg batch loss: 0.4783, Avg batch acc: 0.4739
Train, Epoch: 2, Batch: 580, Step num: 2099, Learning rate: 0.00146672, Avg batch loss: 0.5056, Avg batch acc: 0.4623
Train, Epoch: 2, Batch: 581, Step num: 2100, Learning rate: 0.00146742, Avg batch loss: 0.4899, Avg batch acc: 0.4506
Train, Epoch: 2, Batch: 582, Step num: 2101, Learning rate: 0.00146812, Avg batch loss: 0.5296, Avg batch acc: 0.4384
Train, Epoch: 2, Batch: 583, Step num: 2102, Learning rate: 0.00146882, Avg batch loss: 0.5288, Avg batch acc: 0.4438
Train, Epoch: 2, Batch: 584, Step num: 2103, Learning rate: 0.00146952, Avg batch loss: 0.4889, Avg batch acc: 0.4687
Train, Epoch: 2, Batch: 585, Step num: 2104, Learning rate: 0.00147021, Avg batch loss: 0.4415, Avg batch acc: 0.4881
Train, Epoch: 2, Batch: 586, Step num: 2105, Learning rate: 0.00147091, Avg batch loss: 0.4695, Avg batch acc: 0.4418
Train, Epoch: 2, Batch: 587, Step num: 2106, Learning rate: 0.00147161, Avg batch loss: 0.4473, Avg batch acc: 0.4887
Train, Epoch: 2, Batch: 588, Step num: 2107, Learning rate: 0.00147231, Avg batch loss: 0.4586, Avg batch acc: 0.4689
Train, Epoch: 2, Batch: 589, Step num: 2108, Learning rate: 0.00147301, Avg batch loss: 0.5021, Avg batch acc: 0.4741
Train, Epoch: 2, Batch: 590, Step num: 2109, Learning rate: 0.00147371, Avg batch loss: 0.4517, Avg batch acc: 0.4632
Train, Epoch: 2, Batch: 591, Step num: 2110, Learning rate: 0.00147441, Avg batch loss: 0.4457, Avg batch acc: 0.4702
Train, Epoch: 2, Batch: 592, Step num: 2111, Learning rate: 0.00147511, Avg batch loss: 0.4221, Avg batch acc: 0.4893
Train, Epoch: 2, Batch: 593, Step num: 2112, Learning rate: 0.00147580, Avg batch loss: 0.5263, Avg batch acc: 0.4306
Train, Epoch: 2, Batch: 594, Step num: 2113, Learning rate: 0.00147650, Avg batch loss: 0.4498, Avg batch acc: 0.4680
Train, Epoch: 2, Batch: 595, Step num: 2114, Learning rate: 0.00147720, Avg batch loss: 0.4922, Avg batch acc: 0.4532
Train, Epoch: 2, Batch: 596, Step num: 2115, Learning rate: 0.00147790, Avg batch loss: 0.4738, Avg batch acc: 0.4979
Train, Epoch: 2, Batch: 597, Step num: 2116, Learning rate: 0.00147860, Avg batch loss: 0.4011, Avg batch acc: 0.4870
Train, Epoch: 2, Batch: 598, Step num: 2117, Learning rate: 0.00147930, Avg batch loss: 0.4963, Avg batch acc: 0.4686
Train, Epoch: 2, Batch: 599, Step num: 2118, Learning rate: 0.00148000, Avg batch loss: 0.4506, Avg batch acc: 0.4533
Train, Epoch: 2, Batch: 600, Step num: 2119, Learning rate: 0.00148070, Avg batch loss: 0.5070, Avg batch acc: 0.4536
Train, Epoch: 2, Batch: 601, Step num: 2120, Learning rate: 0.00148140, Avg batch loss: 0.4739, Avg batch acc: 0.4639
Train, Epoch: 2, Batch: 602, Step num: 2121, Learning rate: 0.00148209, Avg batch loss: 0.4964, Avg batch acc: 0.4312
Train, Epoch: 2, Batch: 603, Step num: 2122, Learning rate: 0.00148279, Avg batch loss: 0.4991, Avg batch acc: 0.4482
Train, Epoch: 2, Batch: 604, Step num: 2123, Learning rate: 0.00148349, Avg batch loss: 0.4550, Avg batch acc: 0.4682
Train, Epoch: 2, Batch: 605, Step num: 2124, Learning rate: 0.00148419, Avg batch loss: 0.4988, Avg batch acc: 0.4615
Train, Epoch: 2, Batch: 606, Step num: 2125, Learning rate: 0.00148489, Avg batch loss: 0.5250, Avg batch acc: 0.4343
Train, Epoch: 2, Batch: 607, Step num: 2126, Learning rate: 0.00148559, Avg batch loss: 0.5134, Avg batch acc: 0.4484
Train, Epoch: 2, Batch: 608, Step num: 2127, Learning rate: 0.00148629, Avg batch loss: 0.5202, Avg batch acc: 0.4574
Train, Epoch: 2, Batch: 609, Step num: 2128, Learning rate: 0.00148699, Avg batch loss: 0.4348, Avg batch acc: 0.4617
Train, Epoch: 2, Batch: 610, Step num: 2129, Learning rate: 0.00148768, Avg batch loss: 0.4460, Avg batch acc: 0.4616
Train, Epoch: 2, Batch: 611, Step num: 2130, Learning rate: 0.00148838, Avg batch loss: 0.4528, Avg batch acc: 0.4704
Train, Epoch: 2, Batch: 612, Step num: 2131, Learning rate: 0.00148908, Avg batch loss: 0.4315, Avg batch acc: 0.4742
Train, Epoch: 2, Batch: 613, Step num: 2132, Learning rate: 0.00148978, Avg batch loss: 0.4805, Avg batch acc: 0.4684
Train, Epoch: 2, Batch: 614, Step num: 2133, Learning rate: 0.00149048, Avg batch loss: 0.4608, Avg batch acc: 0.4694
Train, Epoch: 2, Batch: 615, Step num: 2134, Learning rate: 0.00149118, Avg batch loss: 0.4571, Avg batch acc: 0.4571
Train, Epoch: 2, Batch: 616, Step num: 2135, Learning rate: 0.00149188, Avg batch loss: 0.4606, Avg batch acc: 0.4588
Train, Epoch: 2, Batch: 617, Step num: 2136, Learning rate: 0.00149258, Avg batch loss: 0.4789, Avg batch acc: 0.4573
Train, Epoch: 2, Batch: 618, Step num: 2137, Learning rate: 0.00149327, Avg batch loss: 0.5074, Avg batch acc: 0.4712
Train, Epoch: 2, Batch: 619, Step num: 2138, Learning rate: 0.00149397, Avg batch loss: 0.4497, Avg batch acc: 0.4906
Train, Epoch: 2, Batch: 620, Step num: 2139, Learning rate: 0.00149467, Avg batch loss: 0.4301, Avg batch acc: 0.4810
Train, Epoch: 2, Batch: 621, Step num: 2140, Learning rate: 0.00149537, Avg batch loss: 0.4808, Avg batch acc: 0.4443
Train, Epoch: 2, Batch: 622, Step num: 2141, Learning rate: 0.00149607, Avg batch loss: 0.5042, Avg batch acc: 0.4782
Train, Epoch: 2, Batch: 623, Step num: 2142, Learning rate: 0.00149677, Avg batch loss: 0.4813, Avg batch acc: 0.4624
Train, Epoch: 2, Batch: 624, Step num: 2143, Learning rate: 0.00149747, Avg batch loss: 0.4447, Avg batch acc: 0.4918
Train, Epoch: 2, Batch: 625, Step num: 2144, Learning rate: 0.00149817, Avg batch loss: 0.4593, Avg batch acc: 0.4977
Train, Epoch: 2, Batch: 626, Step num: 2145, Learning rate: 0.00149886, Avg batch loss: 0.5337, Avg batch acc: 0.4430
Train, Epoch: 2, Batch: 627, Step num: 2146, Learning rate: 0.00149956, Avg batch loss: 0.4958, Avg batch acc: 0.4629
Train, Epoch: 2, Batch: 628, Step num: 2147, Learning rate: 0.00150026, Avg batch loss: 0.5213, Avg batch acc: 0.4488
Train, Epoch: 2, Batch: 629, Step num: 2148, Learning rate: 0.00150096, Avg batch loss: 0.4642, Avg batch acc: 0.4868
Train, Epoch: 2, Batch: 630, Step num: 2149, Learning rate: 0.00150166, Avg batch loss: 0.4511, Avg batch acc: 0.4668
Train, Epoch: 2, Batch: 631, Step num: 2150, Learning rate: 0.00150236, Avg batch loss: 0.4485, Avg batch acc: 0.4749
Train, Epoch: 2, Batch: 632, Step num: 2151, Learning rate: 0.00150306, Avg batch loss: 0.4987, Avg batch acc: 0.4455
Train, Epoch: 2, Batch: 633, Step num: 2152, Learning rate: 0.00150376, Avg batch loss: 0.4510, Avg batch acc: 0.4651
Train, Epoch: 2, Batch: 634, Step num: 2153, Learning rate: 0.00150445, Avg batch loss: 0.4275, Avg batch acc: 0.4777
Train, Epoch: 2, Batch: 635, Step num: 2154, Learning rate: 0.00150515, Avg batch loss: 0.4084, Avg batch acc: 0.4645
Train, Epoch: 2, Batch: 636, Step num: 2155, Learning rate: 0.00150585, Avg batch loss: 0.4756, Avg batch acc: 0.4678
Train, Epoch: 2, Batch: 637, Step num: 2156, Learning rate: 0.00150655, Avg batch loss: 0.4169, Avg batch acc: 0.4646
Train, Epoch: 2, Batch: 638, Step num: 2157, Learning rate: 0.00150725, Avg batch loss: 0.4831, Avg batch acc: 0.4684
Train, Epoch: 2, Batch: 639, Step num: 2158, Learning rate: 0.00150795, Avg batch loss: 0.4590, Avg batch acc: 0.4504
Train, Epoch: 2, Batch: 640, Step num: 2159, Learning rate: 0.00150865, Avg batch loss: 0.4894, Avg batch acc: 0.4675
Train, Epoch: 2, Batch: 641, Step num: 2160, Learning rate: 0.00150935, Avg batch loss: 0.4911, Avg batch acc: 0.4517
Train, Epoch: 2, Batch: 642, Step num: 2161, Learning rate: 0.00151004, Avg batch loss: 0.4476, Avg batch acc: 0.4621
Train, Epoch: 2, Batch: 643, Step num: 2162, Learning rate: 0.00151074, Avg batch loss: 0.4280, Avg batch acc: 0.4830
Train, Epoch: 2, Batch: 644, Step num: 2163, Learning rate: 0.00151144, Avg batch loss: 0.4743, Avg batch acc: 0.4694
Train, Epoch: 2, Batch: 645, Step num: 2164, Learning rate: 0.00151214, Avg batch loss: 0.4991, Avg batch acc: 0.4678
Train, Epoch: 2, Batch: 646, Step num: 2165, Learning rate: 0.00151284, Avg batch loss: 0.4910, Avg batch acc: 0.4734
Train, Epoch: 2, Batch: 647, Step num: 2166, Learning rate: 0.00151354, Avg batch loss: 0.4874, Avg batch acc: 0.4723
Train, Epoch: 2, Batch: 648, Step num: 2167, Learning rate: 0.00151424, Avg batch loss: 0.4714, Avg batch acc: 0.4691
Train, Epoch: 2, Batch: 649, Step num: 2168, Learning rate: 0.00151494, Avg batch loss: 0.4971, Avg batch acc: 0.4387
Train, Epoch: 2, Batch: 650, Step num: 2169, Learning rate: 0.00151563, Avg batch loss: 0.5107, Avg batch acc: 0.4402
Train, Epoch: 2, Batch: 651, Step num: 2170, Learning rate: 0.00151633, Avg batch loss: 0.5452, Avg batch acc: 0.4624
Train, Epoch: 2, Batch: 652, Step num: 2171, Learning rate: 0.00151703, Avg batch loss: 0.5282, Avg batch acc: 0.4461
Train, Epoch: 2, Batch: 653, Step num: 2172, Learning rate: 0.00151773, Avg batch loss: 0.4783, Avg batch acc: 0.4506
Train, Epoch: 2, Batch: 654, Step num: 2173, Learning rate: 0.00151843, Avg batch loss: 0.5129, Avg batch acc: 0.4717
Train, Epoch: 2, Batch: 655, Step num: 2174, Learning rate: 0.00151913, Avg batch loss: 0.4220, Avg batch acc: 0.4713
Train, Epoch: 2, Batch: 656, Step num: 2175, Learning rate: 0.00151983, Avg batch loss: 0.4683, Avg batch acc: 0.4669
Train, Epoch: 2, Batch: 657, Step num: 2176, Learning rate: 0.00152053, Avg batch loss: 0.4278, Avg batch acc: 0.4830
Train, Epoch: 2, Batch: 658, Step num: 2177, Learning rate: 0.00152122, Avg batch loss: 0.4406, Avg batch acc: 0.4779
Train, Epoch: 2, Batch: 659, Step num: 2178, Learning rate: 0.00152192, Avg batch loss: 0.4628, Avg batch acc: 0.4782
Train, Epoch: 2, Batch: 660, Step num: 2179, Learning rate: 0.00152262, Avg batch loss: 0.4719, Avg batch acc: 0.4701
Train, Epoch: 2, Batch: 661, Step num: 2180, Learning rate: 0.00152332, Avg batch loss: 0.4989, Avg batch acc: 0.4612
Train, Epoch: 2, Batch: 662, Step num: 2181, Learning rate: 0.00152402, Avg batch loss: 0.5007, Avg batch acc: 0.4552
Train, Epoch: 2, Batch: 663, Step num: 2182, Learning rate: 0.00152472, Avg batch loss: 0.4197, Avg batch acc: 0.4708
Train, Epoch: 2, Batch: 664, Step num: 2183, Learning rate: 0.00152542, Avg batch loss: 0.4549, Avg batch acc: 0.4801
Train, Epoch: 2, Batch: 665, Step num: 2184, Learning rate: 0.00152612, Avg batch loss: 0.4472, Avg batch acc: 0.4835
Train, Epoch: 2, Batch: 666, Step num: 2185, Learning rate: 0.00152682, Avg batch loss: 0.5031, Avg batch acc: 0.4514
Train, Epoch: 2, Batch: 667, Step num: 2186, Learning rate: 0.00152751, Avg batch loss: 0.4623, Avg batch acc: 0.4634
Train, Epoch: 2, Batch: 668, Step num: 2187, Learning rate: 0.00152821, Avg batch loss: 0.5107, Avg batch acc: 0.4602
Train, Epoch: 2, Batch: 669, Step num: 2188, Learning rate: 0.00152891, Avg batch loss: 0.4749, Avg batch acc: 0.4708
Train, Epoch: 2, Batch: 670, Step num: 2189, Learning rate: 0.00152961, Avg batch loss: 0.4874, Avg batch acc: 0.4703
Train, Epoch: 2, Batch: 671, Step num: 2190, Learning rate: 0.00153031, Avg batch loss: 0.5036, Avg batch acc: 0.4864
Train, Epoch: 2, Batch: 672, Step num: 2191, Learning rate: 0.00153101, Avg batch loss: 0.4351, Avg batch acc: 0.4791
Train, Epoch: 2, Batch: 673, Step num: 2192, Learning rate: 0.00153171, Avg batch loss: 0.4774, Avg batch acc: 0.4611
Train, Epoch: 2, Batch: 674, Step num: 2193, Learning rate: 0.00153241, Avg batch loss: 0.4427, Avg batch acc: 0.4815
Train, Epoch: 2, Batch: 675, Step num: 2194, Learning rate: 0.00153310, Avg batch loss: 0.4772, Avg batch acc: 0.4668
Train, Epoch: 2, Batch: 676, Step num: 2195, Learning rate: 0.00153380, Avg batch loss: 0.5082, Avg batch acc: 0.4539
Train, Epoch: 2, Batch: 677, Step num: 2196, Learning rate: 0.00153450, Avg batch loss: 0.5409, Avg batch acc: 0.4345
Train, Epoch: 2, Batch: 678, Step num: 2197, Learning rate: 0.00153520, Avg batch loss: 0.4737, Avg batch acc: 0.4565
Train, Epoch: 2, Batch: 679, Step num: 2198, Learning rate: 0.00153590, Avg batch loss: 0.4807, Avg batch acc: 0.4731
Train, Epoch: 2, Batch: 680, Step num: 2199, Learning rate: 0.00153660, Avg batch loss: 0.4712, Avg batch acc: 0.4630
Train, Epoch: 2, Batch: 681, Step num: 2200, Learning rate: 0.00153730, Avg batch loss: 0.5052, Avg batch acc: 0.4516
Train, Epoch: 2, Batch: 682, Step num: 2201, Learning rate: 0.00153800, Avg batch loss: 0.5173, Avg batch acc: 0.4559
Train, Epoch: 2, Batch: 683, Step num: 2202, Learning rate: 0.00153869, Avg batch loss: 0.4873, Avg batch acc: 0.4607
Train, Epoch: 2, Batch: 684, Step num: 2203, Learning rate: 0.00153939, Avg batch loss: 0.5188, Avg batch acc: 0.4462
Train, Epoch: 2, Batch: 685, Step num: 2204, Learning rate: 0.00154009, Avg batch loss: 0.4957, Avg batch acc: 0.4724
Train, Epoch: 2, Batch: 686, Step num: 2205, Learning rate: 0.00154079, Avg batch loss: 0.4562, Avg batch acc: 0.4762
